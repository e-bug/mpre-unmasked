/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
08/28/2020 05:58:36 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
08/28/2020 05:58:37 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
08/28/2020 05:58:37 - INFO - volta.task_utils -   Loading NLVR2 Dataset with batch size 32
08/28/2020 05:59:34 - INFO - volta.utils -   logging file at: ../../logs/volta/nlvr2/NLVR2_lxmert
08/28/2020 05:59:34 - INFO - volta.utils -   loading weights file /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/volta/lxmert/lxmert/pytorch_model_19.bin
08/28/2020 05:59:41 - INFO - volta.utils -   
08/28/2020 05:59:41 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK12.logit_fc.0.weight', 'clfs_dict.TASK12.logit_fc.0.bias', 'clfs_dict.TASK12.logit_fc.2.weight', 'clfs_dict.TASK12.logit_fc.2.bias', 'clfs_dict.TASK12.logit_fc.3.weight', 'clfs_dict.TASK12.logit_fc.3.bias']
08/28/2020 05:59:44 - INFO - __main__ -   >> Trainable Parameters:
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)     |1572864     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(768, 4)        |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.v_embeddings.ImgLayerNorm.weight                        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.v_embeddings.ImgLayerNorm.bias                          |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.v_embeddings.LocLayerNorm.weight                        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.v_embeddings.LocLayerNorm.bias                          |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.predictions.bias                                         |torch.float32    |(30522,)        |30522       |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.predictions.transform.dense.weight                       |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.predictions.transform.dense.bias                         |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.weight                   |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.bi_seq_relationship.weight                               |torch.float32    |(2, 768)        |1536        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.bi_seq_relationship.bias                                 |torch.float32    |(2,)            |2           |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.weight                  |torch.float32    |(768, 768)      |589824      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.3.weight                   |torch.float32    |(1600, 768)     |1228800     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.3.bias                     |torch.float32    |(1600,)         |1600        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.4.weight                   |torch.float32    |(400, 768)      |307200      |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.4.bias                     |torch.float32    |(400,)          |400         |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.5.weight                   |torch.float32    |(2048, 768)     |1572864     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.5.bias                     |torch.float32    |(2048,)         |2048        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.0.weight                           |torch.float32    |(1536, 1536)    |2359296     |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.0.bias                             |torch.float32    |(1536,)         |1536        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.2.weight                           |torch.float32    |(1536,)         |1536        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.2.bias                             |torch.float32    |(1536,)         |1536        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.3.weight                           |torch.float32    |(2, 1536)       |3072        |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.3.bias                             |torch.float32    |(2,)            |2           |
08/28/2020 05:59:44 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 05:59:44 - INFO - __main__ -   >> # TrainableParams:       	214.63	M
08/28/2020 05:59:44 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
08/28/2020 05:59:44 - INFO - __main__ -   >> # TotalParams:           	214.63	M

Epoch:   0%|          | 0/20 [00:00<?, ?it/s]08/28/2020 06:02:19 - INFO - volta.utils -   [NLVR2]: iter 21 Ep: 0.01 loss 0.742 score 0.521 lr 1.0189e-07 
08/28/2020 06:03:07 - INFO - volta.utils -   [NLVR2]: iter 41 Ep: 0.02 loss 0.742 score 0.511 lr 2.91775e-07 
08/28/2020 06:03:40 - INFO - volta.utils -   [NLVR2]: iter 61 Ep: 0.02 loss 0.721 score 0.516 lr 4.77029e-07 
08/28/2020 06:04:17 - INFO - volta.utils -   [NLVR2]: iter 81 Ep: 0.03 loss 0.717 score 0.495 lr 6.62282e-07 
08/28/2020 06:04:39 - INFO - volta.utils -   [NLVR2]: iter 101 Ep: 0.04 loss 0.708 score 0.520 lr 8.47536e-07 
08/28/2020 06:04:58 - INFO - volta.utils -   [NLVR2]: iter 121 Ep: 0.04 loss 0.706 score 0.537 lr 1.03279e-06 
08/28/2020 06:05:07 - INFO - volta.utils -   [NLVR2]: iter 141 Ep: 0.05 loss 0.707 score 0.516 lr 1.21804e-06 
08/28/2020 06:05:15 - INFO - volta.utils -   [NLVR2]: iter 161 Ep: 0.06 loss 0.702 score 0.494 lr 1.4033e-06 
08/28/2020 06:05:24 - INFO - volta.utils -   [NLVR2]: iter 181 Ep: 0.07 loss 0.708 score 0.503 lr 1.58855e-06 
08/28/2020 06:05:32 - INFO - volta.utils -   [NLVR2]: iter 201 Ep: 0.07 loss 0.702 score 0.519 lr 1.77381e-06 
08/28/2020 06:05:41 - INFO - volta.utils -   [NLVR2]: iter 221 Ep: 0.08 loss 0.703 score 0.509 lr 1.95906e-06 
08/28/2020 06:05:49 - INFO - volta.utils -   [NLVR2]: iter 241 Ep: 0.09 loss 0.706 score 0.516 lr 2.14431e-06 
08/28/2020 06:05:58 - INFO - volta.utils -   [NLVR2]: iter 261 Ep: 0.10 loss 0.707 score 0.512 lr 2.32957e-06 
08/28/2020 06:06:06 - INFO - volta.utils -   [NLVR2]: iter 281 Ep: 0.10 loss 0.698 score 0.533 lr 2.51482e-06 
08/28/2020 06:06:14 - INFO - volta.utils -   [NLVR2]: iter 301 Ep: 0.11 loss 0.701 score 0.527 lr 2.70007e-06 
08/28/2020 06:06:22 - INFO - volta.utils -   [NLVR2]: iter 321 Ep: 0.12 loss 0.707 score 0.511 lr 2.88533e-06 
08/28/2020 06:06:31 - INFO - volta.utils -   [NLVR2]: iter 341 Ep: 0.13 loss 0.705 score 0.508 lr 3.07058e-06 
08/28/2020 06:06:39 - INFO - volta.utils -   [NLVR2]: iter 361 Ep: 0.13 loss 0.704 score 0.527 lr 3.25584e-06 
08/28/2020 06:06:47 - INFO - volta.utils -   [NLVR2]: iter 381 Ep: 0.14 loss 0.698 score 0.541 lr 3.44109e-06 
08/28/2020 06:06:56 - INFO - volta.utils -   [NLVR2]: iter 401 Ep: 0.15 loss 0.689 score 0.561 lr 3.62634e-06 
08/28/2020 06:07:04 - INFO - volta.utils -   [NLVR2]: iter 421 Ep: 0.16 loss 0.692 score 0.536 lr 3.8116e-06 
08/28/2020 06:07:13 - INFO - volta.utils -   [NLVR2]: iter 441 Ep: 0.16 loss 0.704 score 0.489 lr 3.99685e-06 
08/28/2020 06:07:21 - INFO - volta.utils -   [NLVR2]: iter 461 Ep: 0.17 loss 0.685 score 0.564 lr 4.1821e-06 
08/28/2020 06:07:29 - INFO - volta.utils -   [NLVR2]: iter 481 Ep: 0.18 loss 0.698 score 0.519 lr 4.36736e-06 
08/28/2020 06:07:37 - INFO - volta.utils -   [NLVR2]: iter 501 Ep: 0.19 loss 0.694 score 0.534 lr 4.55261e-06 
08/28/2020 06:07:46 - INFO - volta.utils -   [NLVR2]: iter 521 Ep: 0.19 loss 0.696 score 0.537 lr 4.73787e-06 
08/28/2020 06:07:54 - INFO - volta.utils -   [NLVR2]: iter 541 Ep: 0.20 loss 0.686 score 0.566 lr 4.92312e-06 
08/28/2020 06:08:02 - INFO - volta.utils -   [NLVR2]: iter 561 Ep: 0.21 loss 0.697 score 0.547 lr 5.10837e-06 
08/28/2020 06:08:10 - INFO - volta.utils -   [NLVR2]: iter 581 Ep: 0.22 loss 0.711 score 0.512 lr 5.29363e-06 
08/28/2020 06:08:18 - INFO - volta.utils -   [NLVR2]: iter 601 Ep: 0.22 loss 0.690 score 0.547 lr 5.47888e-06 
08/28/2020 06:08:28 - INFO - volta.utils -   [NLVR2]: iter 621 Ep: 0.23 loss 0.690 score 0.575 lr 5.66413e-06 
08/28/2020 06:08:37 - INFO - volta.utils -   [NLVR2]: iter 641 Ep: 0.24 loss 0.697 score 0.531 lr 5.84939e-06 
08/28/2020 06:08:45 - INFO - volta.utils -   [NLVR2]: iter 661 Ep: 0.24 loss 0.708 score 0.517 lr 6.03464e-06 
08/28/2020 06:08:54 - INFO - volta.utils -   [NLVR2]: iter 681 Ep: 0.25 loss 0.703 score 0.500 lr 6.2199e-06 
08/28/2020 06:09:02 - INFO - volta.utils -   [NLVR2]: iter 701 Ep: 0.26 loss 0.685 score 0.577 lr 6.40515e-06 
08/28/2020 06:09:10 - INFO - volta.utils -   [NLVR2]: iter 721 Ep: 0.27 loss 0.690 score 0.558 lr 6.5904e-06 
08/28/2020 06:09:18 - INFO - volta.utils -   [NLVR2]: iter 741 Ep: 0.27 loss 0.690 score 0.545 lr 6.77566e-06 
08/28/2020 06:09:26 - INFO - volta.utils -   [NLVR2]: iter 761 Ep: 0.28 loss 0.699 score 0.541 lr 6.96091e-06 
08/28/2020 06:09:34 - INFO - volta.utils -   [NLVR2]: iter 781 Ep: 0.29 loss 0.686 score 0.544 lr 7.14617e-06 
08/28/2020 06:09:43 - INFO - volta.utils -   [NLVR2]: iter 801 Ep: 0.30 loss 0.687 score 0.566 lr 7.33142e-06 
08/28/2020 06:09:51 - INFO - volta.utils -   [NLVR2]: iter 821 Ep: 0.30 loss 0.675 score 0.591 lr 7.51667e-06 
08/28/2020 06:09:58 - INFO - volta.utils -   [NLVR2]: iter 841 Ep: 0.31 loss 0.708 score 0.508 lr 7.70193e-06 
08/28/2020 06:10:07 - INFO - volta.utils -   [NLVR2]: iter 861 Ep: 0.32 loss 0.679 score 0.578 lr 7.88718e-06 
08/28/2020 06:10:15 - INFO - volta.utils -   [NLVR2]: iter 881 Ep: 0.33 loss 0.693 score 0.566 lr 8.07243e-06 
08/28/2020 06:10:23 - INFO - volta.utils -   [NLVR2]: iter 901 Ep: 0.33 loss 0.689 score 0.564 lr 8.25769e-06 
08/28/2020 06:10:31 - INFO - volta.utils -   [NLVR2]: iter 921 Ep: 0.34 loss 0.696 score 0.561 lr 8.44294e-06 
08/28/2020 06:10:39 - INFO - volta.utils -   [NLVR2]: iter 941 Ep: 0.35 loss 0.677 score 0.539 lr 8.6282e-06 
08/28/2020 06:10:47 - INFO - volta.utils -   [NLVR2]: iter 961 Ep: 0.36 loss 0.682 score 0.572 lr 8.81345e-06 
08/28/2020 06:10:55 - INFO - volta.utils -   [NLVR2]: iter 981 Ep: 0.36 loss 0.689 score 0.548 lr 8.9987e-06 
08/28/2020 06:11:03 - INFO - volta.utils -   [NLVR2]: iter 1001 Ep: 0.37 loss 0.680 score 0.570 lr 9.18396e-06 
08/28/2020 06:11:11 - INFO - volta.utils -   [NLVR2]: iter 1021 Ep: 0.38 loss 0.690 score 0.564 lr 9.36921e-06 
08/28/2020 06:11:19 - INFO - volta.utils -   [NLVR2]: iter 1041 Ep: 0.39 loss 0.680 score 0.559 lr 9.55446e-06 
08/28/2020 06:11:28 - INFO - volta.utils -   [NLVR2]: iter 1061 Ep: 0.39 loss 0.683 score 0.562 lr 9.73972e-06 
08/28/2020 06:11:36 - INFO - volta.utils -   [NLVR2]: iter 1081 Ep: 0.40 loss 0.660 score 0.595 lr 9.92497e-06 
08/28/2020 06:11:44 - INFO - volta.utils -   [NLVR2]: iter 1101 Ep: 0.41 loss 0.667 score 0.591 lr 1.01102e-05 
08/28/2020 06:11:52 - INFO - volta.utils -   [NLVR2]: iter 1121 Ep: 0.42 loss 0.660 score 0.602 lr 1.02955e-05 
08/28/2020 06:12:01 - INFO - volta.utils -   [NLVR2]: iter 1141 Ep: 0.42 loss 0.676 score 0.588 lr 1.04807e-05 
08/28/2020 06:12:09 - INFO - volta.utils -   [NLVR2]: iter 1161 Ep: 0.43 loss 0.675 score 0.572 lr 1.0666e-05 
08/28/2020 06:12:17 - INFO - volta.utils -   [NLVR2]: iter 1181 Ep: 0.44 loss 0.668 score 0.572 lr 1.08512e-05 
08/28/2020 06:12:26 - INFO - volta.utils -   [NLVR2]: iter 1201 Ep: 0.44 loss 0.680 score 0.586 lr 1.10365e-05 
08/28/2020 06:12:34 - INFO - volta.utils -   [NLVR2]: iter 1221 Ep: 0.45 loss 0.674 score 0.578 lr 1.12217e-05 
08/28/2020 06:12:42 - INFO - volta.utils -   [NLVR2]: iter 1241 Ep: 0.46 loss 0.668 score 0.569 lr 1.1407e-05 
08/28/2020 06:12:50 - INFO - volta.utils -   [NLVR2]: iter 1261 Ep: 0.47 loss 0.660 score 0.605 lr 1.15923e-05 
08/28/2020 06:12:58 - INFO - volta.utils -   [NLVR2]: iter 1281 Ep: 0.47 loss 0.653 score 0.611 lr 1.17775e-05 
08/28/2020 06:13:06 - INFO - volta.utils -   [NLVR2]: iter 1301 Ep: 0.48 loss 0.664 score 0.569 lr 1.19628e-05 
08/28/2020 06:13:14 - INFO - volta.utils -   [NLVR2]: iter 1321 Ep: 0.49 loss 0.668 score 0.561 lr 1.2148e-05 
08/28/2020 06:13:22 - INFO - volta.utils -   [NLVR2]: iter 1341 Ep: 0.50 loss 0.680 score 0.545 lr 1.23333e-05 
08/28/2020 06:13:30 - INFO - volta.utils -   [NLVR2]: iter 1361 Ep: 0.50 loss 0.660 score 0.586 lr 1.25185e-05 
08/28/2020 06:13:38 - INFO - volta.utils -   [NLVR2]: iter 1381 Ep: 0.51 loss 0.667 score 0.581 lr 1.27038e-05 
08/28/2020 06:13:46 - INFO - volta.utils -   [NLVR2]: iter 1401 Ep: 0.52 loss 0.679 score 0.581 lr 1.2889e-05 
08/28/2020 06:13:54 - INFO - volta.utils -   [NLVR2]: iter 1421 Ep: 0.53 loss 0.674 score 0.584 lr 1.30743e-05 
08/28/2020 06:14:02 - INFO - volta.utils -   [NLVR2]: iter 1441 Ep: 0.53 loss 0.683 score 0.541 lr 1.32595e-05 
08/28/2020 06:14:10 - INFO - volta.utils -   [NLVR2]: iter 1461 Ep: 0.54 loss 0.649 score 0.617 lr 1.34448e-05 
08/28/2020 06:14:19 - INFO - volta.utils -   [NLVR2]: iter 1481 Ep: 0.55 loss 0.647 score 0.592 lr 1.363e-05 
08/28/2020 06:14:27 - INFO - volta.utils -   [NLVR2]: iter 1501 Ep: 0.56 loss 0.666 score 0.594 lr 1.38153e-05 
08/28/2020 06:14:36 - INFO - volta.utils -   [NLVR2]: iter 1521 Ep: 0.56 loss 0.672 score 0.572 lr 1.40006e-05 
08/28/2020 06:14:44 - INFO - volta.utils -   [NLVR2]: iter 1541 Ep: 0.57 loss 0.667 score 0.581 lr 1.41858e-05 
08/28/2020 06:14:52 - INFO - volta.utils -   [NLVR2]: iter 1561 Ep: 0.58 loss 0.656 score 0.605 lr 1.43711e-05 
08/28/2020 06:15:00 - INFO - volta.utils -   [NLVR2]: iter 1581 Ep: 0.59 loss 0.653 score 0.588 lr 1.45563e-05 
08/28/2020 06:15:08 - INFO - volta.utils -   [NLVR2]: iter 1601 Ep: 0.59 loss 0.667 score 0.573 lr 1.47416e-05 
08/28/2020 06:15:16 - INFO - volta.utils -   [NLVR2]: iter 1621 Ep: 0.60 loss 0.674 score 0.566 lr 1.49268e-05 
08/28/2020 06:15:24 - INFO - volta.utils -   [NLVR2]: iter 1641 Ep: 0.61 loss 0.658 score 0.598 lr 1.51121e-05 
08/28/2020 06:15:32 - INFO - volta.utils -   [NLVR2]: iter 1661 Ep: 0.62 loss 0.675 score 0.580 lr 1.52973e-05 
08/28/2020 06:15:40 - INFO - volta.utils -   [NLVR2]: iter 1681 Ep: 0.62 loss 0.664 score 0.566 lr 1.54826e-05 
08/28/2020 06:15:48 - INFO - volta.utils -   [NLVR2]: iter 1701 Ep: 0.63 loss 0.643 score 0.592 lr 1.56678e-05 
08/28/2020 06:15:56 - INFO - volta.utils -   [NLVR2]: iter 1721 Ep: 0.64 loss 0.668 score 0.589 lr 1.58531e-05 
08/28/2020 06:16:05 - INFO - volta.utils -   [NLVR2]: iter 1741 Ep: 0.65 loss 0.665 score 0.588 lr 1.60383e-05 
08/28/2020 06:16:13 - INFO - volta.utils -   [NLVR2]: iter 1761 Ep: 0.65 loss 0.668 score 0.598 lr 1.62236e-05 
08/28/2020 06:16:21 - INFO - volta.utils -   [NLVR2]: iter 1781 Ep: 0.66 loss 0.657 score 0.600 lr 1.64089e-05 
08/28/2020 06:16:29 - INFO - volta.utils -   [NLVR2]: iter 1801 Ep: 0.67 loss 0.652 score 0.595 lr 1.65941e-05 
08/28/2020 06:16:38 - INFO - volta.utils -   [NLVR2]: iter 1821 Ep: 0.67 loss 0.650 score 0.597 lr 1.67794e-05 
08/28/2020 06:16:46 - INFO - volta.utils -   [NLVR2]: iter 1841 Ep: 0.68 loss 0.645 score 0.620 lr 1.69646e-05 
08/28/2020 06:16:55 - INFO - volta.utils -   [NLVR2]: iter 1861 Ep: 0.69 loss 0.654 score 0.616 lr 1.71499e-05 
08/28/2020 06:17:03 - INFO - volta.utils -   [NLVR2]: iter 1881 Ep: 0.70 loss 0.644 score 0.619 lr 1.73351e-05 
08/28/2020 06:17:12 - INFO - volta.utils -   [NLVR2]: iter 1901 Ep: 0.70 loss 0.645 score 0.623 lr 1.75204e-05 
08/28/2020 06:17:20 - INFO - volta.utils -   [NLVR2]: iter 1921 Ep: 0.71 loss 0.667 score 0.559 lr 1.77056e-05 
08/28/2020 06:17:28 - INFO - volta.utils -   [NLVR2]: iter 1941 Ep: 0.72 loss 0.665 score 0.583 lr 1.78909e-05 
08/28/2020 06:17:36 - INFO - volta.utils -   [NLVR2]: iter 1961 Ep: 0.73 loss 0.657 score 0.588 lr 1.80761e-05 
08/28/2020 06:17:44 - INFO - volta.utils -   [NLVR2]: iter 1981 Ep: 0.73 loss 0.672 score 0.575 lr 1.82614e-05 
08/28/2020 06:17:52 - INFO - volta.utils -   [NLVR2]: iter 2001 Ep: 0.74 loss 0.647 score 0.581 lr 1.84466e-05 
08/28/2020 06:18:01 - INFO - volta.utils -   [NLVR2]: iter 2021 Ep: 0.75 loss 0.653 score 0.581 lr 1.86319e-05 
08/28/2020 06:18:10 - INFO - volta.utils -   [NLVR2]: iter 2041 Ep: 0.76 loss 0.640 score 0.613 lr 1.88172e-05 
08/28/2020 06:18:18 - INFO - volta.utils -   [NLVR2]: iter 2061 Ep: 0.76 loss 0.642 score 0.594 lr 1.90024e-05 
08/28/2020 06:18:27 - INFO - volta.utils -   [NLVR2]: iter 2081 Ep: 0.77 loss 0.642 score 0.625 lr 1.91877e-05 
08/28/2020 06:18:36 - INFO - volta.utils -   [NLVR2]: iter 2101 Ep: 0.78 loss 0.647 score 0.609 lr 1.93729e-05 
08/28/2020 06:18:44 - INFO - volta.utils -   [NLVR2]: iter 2121 Ep: 0.79 loss 0.661 score 0.634 lr 1.95582e-05 
08/28/2020 06:18:51 - INFO - volta.utils -   [NLVR2]: iter 2141 Ep: 0.79 loss 0.650 score 0.608 lr 1.97434e-05 
08/28/2020 06:18:59 - INFO - volta.utils -   [NLVR2]: iter 2161 Ep: 0.80 loss 0.659 score 0.577 lr 1.99287e-05 
08/28/2020 06:19:08 - INFO - volta.utils -   [NLVR2]: iter 2181 Ep: 0.81 loss 0.631 score 0.616 lr 2.01139e-05 
08/28/2020 06:19:16 - INFO - volta.utils -   [NLVR2]: iter 2201 Ep: 0.82 loss 0.671 score 0.597 lr 2.02992e-05 
08/28/2020 06:19:24 - INFO - volta.utils -   [NLVR2]: iter 2221 Ep: 0.82 loss 0.652 score 0.609 lr 2.04844e-05 
08/28/2020 06:19:32 - INFO - volta.utils -   [NLVR2]: iter 2241 Ep: 0.83 loss 0.661 score 0.575 lr 2.06697e-05 
08/28/2020 06:19:40 - INFO - volta.utils -   [NLVR2]: iter 2261 Ep: 0.84 loss 0.665 score 0.578 lr 2.08549e-05 
08/28/2020 06:19:48 - INFO - volta.utils -   [NLVR2]: iter 2281 Ep: 0.85 loss 0.656 score 0.581 lr 2.10402e-05 
08/28/2020 06:19:56 - INFO - volta.utils -   [NLVR2]: iter 2301 Ep: 0.85 loss 0.636 score 0.622 lr 2.12255e-05 
08/28/2020 06:20:03 - INFO - volta.utils -   [NLVR2]: iter 2321 Ep: 0.86 loss 0.657 score 0.611 lr 2.14107e-05 
08/28/2020 06:20:11 - INFO - volta.utils -   [NLVR2]: iter 2341 Ep: 0.87 loss 0.661 score 0.598 lr 2.1596e-05 
08/28/2020 06:20:19 - INFO - volta.utils -   [NLVR2]: iter 2361 Ep: 0.87 loss 0.643 score 0.594 lr 2.17812e-05 
08/28/2020 06:20:27 - INFO - volta.utils -   [NLVR2]: iter 2381 Ep: 0.88 loss 0.602 score 0.673 lr 2.19665e-05 
08/28/2020 06:20:35 - INFO - volta.utils -   [NLVR2]: iter 2401 Ep: 0.89 loss 0.654 score 0.581 lr 2.21517e-05 
08/28/2020 06:20:43 - INFO - volta.utils -   [NLVR2]: iter 2421 Ep: 0.90 loss 0.661 score 0.569 lr 2.2337e-05 
08/28/2020 06:20:50 - INFO - volta.utils -   [NLVR2]: iter 2441 Ep: 0.90 loss 0.662 score 0.598 lr 2.25222e-05 
08/28/2020 06:20:58 - INFO - volta.utils -   [NLVR2]: iter 2461 Ep: 0.91 loss 0.656 score 0.580 lr 2.27075e-05 
08/28/2020 06:21:06 - INFO - volta.utils -   [NLVR2]: iter 2481 Ep: 0.92 loss 0.648 score 0.589 lr 2.28927e-05 
08/28/2020 06:21:14 - INFO - volta.utils -   [NLVR2]: iter 2501 Ep: 0.93 loss 0.670 score 0.583 lr 2.3078e-05 
08/28/2020 06:21:22 - INFO - volta.utils -   [NLVR2]: iter 2521 Ep: 0.93 loss 0.654 score 0.595 lr 2.32632e-05 
08/28/2020 06:21:30 - INFO - volta.utils -   [NLVR2]: iter 2541 Ep: 0.94 loss 0.630 score 0.617 lr 2.34485e-05 
08/28/2020 06:21:38 - INFO - volta.utils -   [NLVR2]: iter 2561 Ep: 0.95 loss 0.657 score 0.597 lr 2.36338e-05 
08/28/2020 06:21:46 - INFO - volta.utils -   [NLVR2]: iter 2581 Ep: 0.96 loss 0.647 score 0.595 lr 2.3819e-05 
08/28/2020 06:21:54 - INFO - volta.utils -   [NLVR2]: iter 2601 Ep: 0.96 loss 0.641 score 0.617 lr 2.40043e-05 
08/28/2020 06:22:02 - INFO - volta.utils -   [NLVR2]: iter 2621 Ep: 0.97 loss 0.646 score 0.633 lr 2.41895e-05 
08/28/2020 06:22:10 - INFO - volta.utils -   [NLVR2]: iter 2641 Ep: 0.98 loss 0.659 score 0.597 lr 2.43748e-05 
08/28/2020 06:22:18 - INFO - volta.utils -   [NLVR2]: iter 2661 Ep: 0.99 loss 0.657 score 0.592 lr 2.456e-05 
08/28/2020 06:22:25 - INFO - volta.utils -   [NLVR2]: iter 2681 Ep: 0.99 loss 0.640 score 0.633 lr 2.47453e-05 
08/28/2020 06:22:32 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:   5%|         | 1/20 [22:52<7:14:35, 1372.38s/it]08/28/2020 06:25:41 - INFO - volta.utils -   Eval task TASK12 on iteration 2700 
08/28/2020 06:25:41 - INFO - volta.utils -   Validation [NLVR2]: loss 0.633 score 63.102 
08/28/2020 06:25:49 - INFO - volta.utils -   [NLVR2]: iter 2720 Ep: 1.01 loss 0.609 score 0.660 lr 2.50185e-05 
08/28/2020 06:25:57 - INFO - volta.utils -   [NLVR2]: iter 2740 Ep: 1.02 loss 0.595 score 0.666 lr 2.52918e-05 
08/28/2020 06:26:05 - INFO - volta.utils -   [NLVR2]: iter 2760 Ep: 1.02 loss 0.640 score 0.623 lr 2.5477e-05 
08/28/2020 06:26:12 - INFO - volta.utils -   [NLVR2]: iter 2780 Ep: 1.03 loss 0.599 score 0.670 lr 2.56623e-05 
08/28/2020 06:26:20 - INFO - volta.utils -   [NLVR2]: iter 2800 Ep: 1.04 loss 0.604 score 0.678 lr 2.58475e-05 
08/28/2020 06:26:28 - INFO - volta.utils -   [NLVR2]: iter 2820 Ep: 1.04 loss 0.625 score 0.644 lr 2.60328e-05 
08/28/2020 06:26:36 - INFO - volta.utils -   [NLVR2]: iter 2840 Ep: 1.05 loss 0.629 score 0.627 lr 2.6218e-05 
08/28/2020 06:26:43 - INFO - volta.utils -   [NLVR2]: iter 2860 Ep: 1.06 loss 0.612 score 0.659 lr 2.64033e-05 
08/28/2020 06:26:51 - INFO - volta.utils -   [NLVR2]: iter 2880 Ep: 1.07 loss 0.620 score 0.631 lr 2.65886e-05 
08/28/2020 06:26:59 - INFO - volta.utils -   [NLVR2]: iter 2900 Ep: 1.07 loss 0.594 score 0.677 lr 2.67738e-05 
08/28/2020 06:27:07 - INFO - volta.utils -   [NLVR2]: iter 2920 Ep: 1.08 loss 0.643 score 0.617 lr 2.69591e-05 
08/28/2020 06:27:15 - INFO - volta.utils -   [NLVR2]: iter 2940 Ep: 1.09 loss 0.637 score 0.616 lr 2.71443e-05 
08/28/2020 06:27:23 - INFO - volta.utils -   [NLVR2]: iter 2960 Ep: 1.10 loss 0.612 score 0.677 lr 2.73296e-05 
08/28/2020 06:27:32 - INFO - volta.utils -   [NLVR2]: iter 2980 Ep: 1.10 loss 0.600 score 0.647 lr 2.75148e-05 
08/28/2020 06:27:39 - INFO - volta.utils -   [NLVR2]: iter 3000 Ep: 1.11 loss 0.624 score 0.639 lr 2.77001e-05 
08/28/2020 06:27:47 - INFO - volta.utils -   [NLVR2]: iter 3020 Ep: 1.12 loss 0.606 score 0.670 lr 2.78853e-05 
08/28/2020 06:27:55 - INFO - volta.utils -   [NLVR2]: iter 3040 Ep: 1.13 loss 0.642 score 0.595 lr 2.80706e-05 
08/28/2020 06:28:03 - INFO - volta.utils -   [NLVR2]: iter 3060 Ep: 1.13 loss 0.627 score 0.645 lr 2.82558e-05 
08/28/2020 06:28:11 - INFO - volta.utils -   [NLVR2]: iter 3080 Ep: 1.14 loss 0.600 score 0.669 lr 2.84411e-05 
08/28/2020 06:28:20 - INFO - volta.utils -   [NLVR2]: iter 3100 Ep: 1.15 loss 0.620 score 0.659 lr 2.86263e-05 
08/28/2020 06:28:28 - INFO - volta.utils -   [NLVR2]: iter 3120 Ep: 1.16 loss 0.629 score 0.636 lr 2.88116e-05 
08/28/2020 06:28:36 - INFO - volta.utils -   [NLVR2]: iter 3140 Ep: 1.16 loss 0.613 score 0.650 lr 2.89969e-05 
08/28/2020 06:28:44 - INFO - volta.utils -   [NLVR2]: iter 3160 Ep: 1.17 loss 0.625 score 0.619 lr 2.91821e-05 
08/28/2020 06:28:52 - INFO - volta.utils -   [NLVR2]: iter 3180 Ep: 1.18 loss 0.605 score 0.652 lr 2.93674e-05 
08/28/2020 06:29:00 - INFO - volta.utils -   [NLVR2]: iter 3200 Ep: 1.19 loss 0.588 score 0.658 lr 2.95526e-05 
08/28/2020 06:29:08 - INFO - volta.utils -   [NLVR2]: iter 3220 Ep: 1.19 loss 0.645 score 0.608 lr 2.97379e-05 
08/28/2020 06:29:15 - INFO - volta.utils -   [NLVR2]: iter 3240 Ep: 1.20 loss 0.624 score 0.650 lr 2.99231e-05 
08/28/2020 06:29:23 - INFO - volta.utils -   [NLVR2]: iter 3260 Ep: 1.21 loss 0.635 score 0.644 lr 3.01084e-05 
08/28/2020 06:29:31 - INFO - volta.utils -   [NLVR2]: iter 3280 Ep: 1.22 loss 0.616 score 0.617 lr 3.02936e-05 
08/28/2020 06:29:39 - INFO - volta.utils -   [NLVR2]: iter 3300 Ep: 1.22 loss 0.608 score 0.666 lr 3.04789e-05 
08/28/2020 06:29:47 - INFO - volta.utils -   [NLVR2]: iter 3320 Ep: 1.23 loss 0.607 score 0.656 lr 3.06641e-05 
08/28/2020 06:29:55 - INFO - volta.utils -   [NLVR2]: iter 3340 Ep: 1.24 loss 0.610 score 0.628 lr 3.08494e-05 
08/28/2020 06:30:03 - INFO - volta.utils -   [NLVR2]: iter 3360 Ep: 1.24 loss 0.599 score 0.647 lr 3.10346e-05 
08/28/2020 06:30:10 - INFO - volta.utils -   [NLVR2]: iter 3380 Ep: 1.25 loss 0.608 score 0.644 lr 3.12199e-05 
08/28/2020 06:30:18 - INFO - volta.utils -   [NLVR2]: iter 3400 Ep: 1.26 loss 0.603 score 0.647 lr 3.14052e-05 
08/28/2020 06:30:26 - INFO - volta.utils -   [NLVR2]: iter 3420 Ep: 1.27 loss 0.628 score 0.631 lr 3.15904e-05 
08/28/2020 06:30:34 - INFO - volta.utils -   [NLVR2]: iter 3440 Ep: 1.27 loss 0.609 score 0.648 lr 3.17757e-05 
08/28/2020 06:30:42 - INFO - volta.utils -   [NLVR2]: iter 3460 Ep: 1.28 loss 0.604 score 0.661 lr 3.19609e-05 
08/28/2020 06:30:50 - INFO - volta.utils -   [NLVR2]: iter 3480 Ep: 1.29 loss 0.590 score 0.688 lr 3.21462e-05 
08/28/2020 06:30:58 - INFO - volta.utils -   [NLVR2]: iter 3500 Ep: 1.30 loss 0.621 score 0.625 lr 3.23314e-05 
08/28/2020 06:31:06 - INFO - volta.utils -   [NLVR2]: iter 3520 Ep: 1.30 loss 0.619 score 0.627 lr 3.25167e-05 
08/28/2020 06:31:13 - INFO - volta.utils -   [NLVR2]: iter 3540 Ep: 1.31 loss 0.623 score 0.631 lr 3.27019e-05 
08/28/2020 06:31:21 - INFO - volta.utils -   [NLVR2]: iter 3560 Ep: 1.32 loss 0.640 score 0.606 lr 3.28872e-05 
08/28/2020 06:31:30 - INFO - volta.utils -   [NLVR2]: iter 3580 Ep: 1.33 loss 0.618 score 0.655 lr 3.30724e-05 
08/28/2020 06:31:39 - INFO - volta.utils -   [NLVR2]: iter 3600 Ep: 1.33 loss 0.619 score 0.619 lr 3.32577e-05 
08/28/2020 06:31:47 - INFO - volta.utils -   [NLVR2]: iter 3620 Ep: 1.34 loss 0.623 score 0.658 lr 3.34429e-05 
08/28/2020 06:31:55 - INFO - volta.utils -   [NLVR2]: iter 3640 Ep: 1.35 loss 0.614 score 0.666 lr 3.36282e-05 
08/28/2020 06:32:03 - INFO - volta.utils -   [NLVR2]: iter 3660 Ep: 1.36 loss 0.589 score 0.680 lr 3.38134e-05 
08/28/2020 06:32:11 - INFO - volta.utils -   [NLVR2]: iter 3680 Ep: 1.36 loss 0.587 score 0.700 lr 3.39987e-05 
08/28/2020 06:32:19 - INFO - volta.utils -   [NLVR2]: iter 3700 Ep: 1.37 loss 0.606 score 0.642 lr 3.4184e-05 
08/28/2020 06:32:27 - INFO - volta.utils -   [NLVR2]: iter 3720 Ep: 1.38 loss 0.604 score 0.648 lr 3.43692e-05 
08/28/2020 06:32:35 - INFO - volta.utils -   [NLVR2]: iter 3740 Ep: 1.39 loss 0.635 score 0.641 lr 3.45545e-05 
08/28/2020 06:32:44 - INFO - volta.utils -   [NLVR2]: iter 3760 Ep: 1.39 loss 0.627 score 0.648 lr 3.47397e-05 
08/28/2020 06:32:51 - INFO - volta.utils -   [NLVR2]: iter 3780 Ep: 1.40 loss 0.569 score 0.683 lr 3.4925e-05 
08/28/2020 06:32:59 - INFO - volta.utils -   [NLVR2]: iter 3800 Ep: 1.41 loss 0.637 score 0.625 lr 3.51102e-05 
08/28/2020 06:33:07 - INFO - volta.utils -   [NLVR2]: iter 3820 Ep: 1.42 loss 0.610 score 0.636 lr 3.52955e-05 
08/28/2020 06:33:15 - INFO - volta.utils -   [NLVR2]: iter 3840 Ep: 1.42 loss 0.612 score 0.609 lr 3.54807e-05 
08/28/2020 06:33:23 - INFO - volta.utils -   [NLVR2]: iter 3860 Ep: 1.43 loss 0.614 score 0.666 lr 3.5666e-05 
08/28/2020 06:33:31 - INFO - volta.utils -   [NLVR2]: iter 3880 Ep: 1.44 loss 0.597 score 0.642 lr 3.58512e-05 
08/28/2020 06:33:38 - INFO - volta.utils -   [NLVR2]: iter 3900 Ep: 1.44 loss 0.624 score 0.639 lr 3.60365e-05 
08/28/2020 06:33:46 - INFO - volta.utils -   [NLVR2]: iter 3920 Ep: 1.45 loss 0.616 score 0.622 lr 3.62217e-05 
08/28/2020 06:33:54 - INFO - volta.utils -   [NLVR2]: iter 3940 Ep: 1.46 loss 0.608 score 0.637 lr 3.6407e-05 
08/28/2020 06:34:02 - INFO - volta.utils -   [NLVR2]: iter 3960 Ep: 1.47 loss 0.617 score 0.653 lr 3.65923e-05 
08/28/2020 06:34:10 - INFO - volta.utils -   [NLVR2]: iter 3980 Ep: 1.47 loss 0.616 score 0.658 lr 3.67775e-05 
08/28/2020 06:34:18 - INFO - volta.utils -   [NLVR2]: iter 4000 Ep: 1.48 loss 0.598 score 0.666 lr 3.69628e-05 
08/28/2020 06:34:27 - INFO - volta.utils -   [NLVR2]: iter 4020 Ep: 1.49 loss 0.622 score 0.637 lr 3.7148e-05 
08/28/2020 06:34:35 - INFO - volta.utils -   [NLVR2]: iter 4040 Ep: 1.50 loss 0.593 score 0.637 lr 3.73333e-05 
08/28/2020 06:34:42 - INFO - volta.utils -   [NLVR2]: iter 4060 Ep: 1.50 loss 0.609 score 0.648 lr 3.75185e-05 
08/28/2020 06:34:50 - INFO - volta.utils -   [NLVR2]: iter 4080 Ep: 1.51 loss 0.616 score 0.650 lr 3.77038e-05 
08/28/2020 06:34:58 - INFO - volta.utils -   [NLVR2]: iter 4100 Ep: 1.52 loss 0.616 score 0.656 lr 3.7889e-05 
08/28/2020 06:35:06 - INFO - volta.utils -   [NLVR2]: iter 4120 Ep: 1.53 loss 0.658 score 0.609 lr 3.80743e-05 
08/28/2020 06:35:14 - INFO - volta.utils -   [NLVR2]: iter 4140 Ep: 1.53 loss 0.604 score 0.678 lr 3.82595e-05 
08/28/2020 06:35:22 - INFO - volta.utils -   [NLVR2]: iter 4160 Ep: 1.54 loss 0.601 score 0.633 lr 3.84448e-05 
08/28/2020 06:35:30 - INFO - volta.utils -   [NLVR2]: iter 4180 Ep: 1.55 loss 0.581 score 0.681 lr 3.863e-05 
08/28/2020 06:35:38 - INFO - volta.utils -   [NLVR2]: iter 4200 Ep: 1.56 loss 0.632 score 0.633 lr 3.88153e-05 
08/28/2020 06:35:46 - INFO - volta.utils -   [NLVR2]: iter 4220 Ep: 1.56 loss 0.602 score 0.653 lr 3.90006e-05 
08/28/2020 06:35:54 - INFO - volta.utils -   [NLVR2]: iter 4240 Ep: 1.57 loss 0.593 score 0.648 lr 3.91858e-05 
08/28/2020 06:36:02 - INFO - volta.utils -   [NLVR2]: iter 4260 Ep: 1.58 loss 0.617 score 0.628 lr 3.93711e-05 
08/28/2020 06:36:10 - INFO - volta.utils -   [NLVR2]: iter 4280 Ep: 1.59 loss 0.585 score 0.678 lr 3.95563e-05 
08/28/2020 06:36:18 - INFO - volta.utils -   [NLVR2]: iter 4300 Ep: 1.59 loss 0.600 score 0.633 lr 3.97416e-05 
08/28/2020 06:36:26 - INFO - volta.utils -   [NLVR2]: iter 4320 Ep: 1.60 loss 0.597 score 0.656 lr 3.99268e-05 
08/28/2020 06:36:34 - INFO - volta.utils -   [NLVR2]: iter 4340 Ep: 1.61 loss 0.588 score 0.662 lr 4.01121e-05 
08/28/2020 06:36:42 - INFO - volta.utils -   [NLVR2]: iter 4360 Ep: 1.62 loss 0.605 score 0.662 lr 4.02973e-05 
08/28/2020 06:36:50 - INFO - volta.utils -   [NLVR2]: iter 4380 Ep: 1.62 loss 0.628 score 0.614 lr 4.04826e-05 
08/28/2020 06:36:58 - INFO - volta.utils -   [NLVR2]: iter 4400 Ep: 1.63 loss 0.627 score 0.622 lr 4.06678e-05 
08/28/2020 06:37:06 - INFO - volta.utils -   [NLVR2]: iter 4420 Ep: 1.64 loss 0.592 score 0.675 lr 4.08531e-05 
08/28/2020 06:37:14 - INFO - volta.utils -   [NLVR2]: iter 4440 Ep: 1.65 loss 0.612 score 0.655 lr 4.10383e-05 
08/28/2020 06:37:21 - INFO - volta.utils -   [NLVR2]: iter 4460 Ep: 1.65 loss 0.609 score 0.659 lr 4.12236e-05 
08/28/2020 06:37:29 - INFO - volta.utils -   [NLVR2]: iter 4480 Ep: 1.66 loss 0.602 score 0.666 lr 4.14089e-05 
08/28/2020 06:37:37 - INFO - volta.utils -   [NLVR2]: iter 4500 Ep: 1.67 loss 0.615 score 0.650 lr 4.15941e-05 
08/28/2020 06:37:45 - INFO - volta.utils -   [NLVR2]: iter 4520 Ep: 1.67 loss 0.634 score 0.617 lr 4.17794e-05 
08/28/2020 06:37:53 - INFO - volta.utils -   [NLVR2]: iter 4540 Ep: 1.68 loss 0.626 score 0.623 lr 4.19646e-05 
08/28/2020 06:38:01 - INFO - volta.utils -   [NLVR2]: iter 4560 Ep: 1.69 loss 0.607 score 0.655 lr 4.21499e-05 
08/28/2020 06:38:09 - INFO - volta.utils -   [NLVR2]: iter 4580 Ep: 1.70 loss 0.661 score 0.617 lr 4.23351e-05 
08/28/2020 06:38:17 - INFO - volta.utils -   [NLVR2]: iter 4600 Ep: 1.70 loss 0.627 score 0.634 lr 4.25204e-05 
08/28/2020 06:38:25 - INFO - volta.utils -   [NLVR2]: iter 4620 Ep: 1.71 loss 0.672 score 0.636 lr 4.27056e-05 
08/28/2020 06:38:33 - INFO - volta.utils -   [NLVR2]: iter 4640 Ep: 1.72 loss 0.608 score 0.628 lr 4.28909e-05 
08/28/2020 06:38:42 - INFO - volta.utils -   [NLVR2]: iter 4660 Ep: 1.73 loss 0.629 score 0.644 lr 4.30761e-05 
08/28/2020 06:38:50 - INFO - volta.utils -   [NLVR2]: iter 4680 Ep: 1.73 loss 0.600 score 0.639 lr 4.32614e-05 
08/28/2020 06:38:58 - INFO - volta.utils -   [NLVR2]: iter 4700 Ep: 1.74 loss 0.629 score 0.608 lr 4.34466e-05 
08/28/2020 06:39:07 - INFO - volta.utils -   [NLVR2]: iter 4720 Ep: 1.75 loss 0.618 score 0.636 lr 4.36319e-05 
08/28/2020 06:39:15 - INFO - volta.utils -   [NLVR2]: iter 4740 Ep: 1.76 loss 0.612 score 0.644 lr 4.38172e-05 
08/28/2020 06:39:23 - INFO - volta.utils -   [NLVR2]: iter 4760 Ep: 1.76 loss 0.629 score 0.617 lr 4.40024e-05 
08/28/2020 06:39:32 - INFO - volta.utils -   [NLVR2]: iter 4780 Ep: 1.77 loss 0.579 score 0.666 lr 4.41877e-05 
08/28/2020 06:39:40 - INFO - volta.utils -   [NLVR2]: iter 4800 Ep: 1.78 loss 0.625 score 0.666 lr 4.43729e-05 
08/28/2020 06:39:49 - INFO - volta.utils -   [NLVR2]: iter 4820 Ep: 1.79 loss 0.620 score 0.661 lr 4.45582e-05 
08/28/2020 06:39:56 - INFO - volta.utils -   [NLVR2]: iter 4840 Ep: 1.79 loss 0.594 score 0.656 lr 4.47434e-05 
08/28/2020 06:40:04 - INFO - volta.utils -   [NLVR2]: iter 4860 Ep: 1.80 loss 0.574 score 0.662 lr 4.49287e-05 
08/28/2020 06:40:12 - INFO - volta.utils -   [NLVR2]: iter 4880 Ep: 1.81 loss 0.604 score 0.645 lr 4.51139e-05 
08/28/2020 06:40:21 - INFO - volta.utils -   [NLVR2]: iter 4900 Ep: 1.82 loss 0.586 score 0.662 lr 4.52992e-05 
08/28/2020 06:40:30 - INFO - volta.utils -   [NLVR2]: iter 4920 Ep: 1.82 loss 0.587 score 0.669 lr 4.54844e-05 
08/28/2020 06:40:37 - INFO - volta.utils -   [NLVR2]: iter 4940 Ep: 1.83 loss 0.578 score 0.659 lr 4.56697e-05 
08/28/2020 06:40:45 - INFO - volta.utils -   [NLVR2]: iter 4960 Ep: 1.84 loss 0.611 score 0.683 lr 4.58549e-05 
08/28/2020 06:40:53 - INFO - volta.utils -   [NLVR2]: iter 4980 Ep: 1.85 loss 0.576 score 0.667 lr 4.60402e-05 
08/28/2020 06:41:01 - INFO - volta.utils -   [NLVR2]: iter 5000 Ep: 1.85 loss 0.613 score 0.648 lr 4.62255e-05 
08/28/2020 06:41:09 - INFO - volta.utils -   [NLVR2]: iter 5020 Ep: 1.86 loss 0.591 score 0.667 lr 4.64107e-05 
08/28/2020 06:41:17 - INFO - volta.utils -   [NLVR2]: iter 5040 Ep: 1.87 loss 0.611 score 0.662 lr 4.6596e-05 
08/28/2020 06:41:25 - INFO - volta.utils -   [NLVR2]: iter 5060 Ep: 1.87 loss 0.610 score 0.642 lr 4.67812e-05 
08/28/2020 06:41:33 - INFO - volta.utils -   [NLVR2]: iter 5080 Ep: 1.88 loss 0.638 score 0.616 lr 4.69665e-05 
08/28/2020 06:41:41 - INFO - volta.utils -   [NLVR2]: iter 5100 Ep: 1.89 loss 0.574 score 0.680 lr 4.71517e-05 
08/28/2020 06:41:50 - INFO - volta.utils -   [NLVR2]: iter 5120 Ep: 1.90 loss 0.597 score 0.672 lr 4.7337e-05 
08/28/2020 06:41:58 - INFO - volta.utils -   [NLVR2]: iter 5140 Ep: 1.90 loss 0.615 score 0.637 lr 4.75222e-05 
08/28/2020 06:42:06 - INFO - volta.utils -   [NLVR2]: iter 5160 Ep: 1.91 loss 0.587 score 0.670 lr 4.77075e-05 
08/28/2020 06:42:14 - INFO - volta.utils -   [NLVR2]: iter 5180 Ep: 1.92 loss 0.604 score 0.641 lr 4.78927e-05 
08/28/2020 06:42:22 - INFO - volta.utils -   [NLVR2]: iter 5200 Ep: 1.93 loss 0.604 score 0.631 lr 4.8078e-05 
08/28/2020 06:42:30 - INFO - volta.utils -   [NLVR2]: iter 5220 Ep: 1.93 loss 0.629 score 0.636 lr 4.82632e-05 
08/28/2020 06:42:38 - INFO - volta.utils -   [NLVR2]: iter 5240 Ep: 1.94 loss 0.597 score 0.680 lr 4.84485e-05 
08/28/2020 06:42:46 - INFO - volta.utils -   [NLVR2]: iter 5260 Ep: 1.95 loss 0.589 score 0.681 lr 4.86338e-05 
08/28/2020 06:42:54 - INFO - volta.utils -   [NLVR2]: iter 5280 Ep: 1.96 loss 0.608 score 0.655 lr 4.8819e-05 
08/28/2020 06:43:02 - INFO - volta.utils -   [NLVR2]: iter 5300 Ep: 1.96 loss 0.615 score 0.634 lr 4.90043e-05 
08/28/2020 06:43:10 - INFO - volta.utils -   [NLVR2]: iter 5320 Ep: 1.97 loss 0.591 score 0.642 lr 4.91895e-05 
08/28/2020 06:43:18 - INFO - volta.utils -   [NLVR2]: iter 5340 Ep: 1.98 loss 0.586 score 0.681 lr 4.93748e-05 
08/28/2020 06:43:26 - INFO - volta.utils -   [NLVR2]: iter 5360 Ep: 1.99 loss 0.609 score 0.662 lr 4.956e-05 
08/28/2020 06:43:34 - INFO - volta.utils -   [NLVR2]: iter 5380 Ep: 1.99 loss 0.607 score 0.630 lr 4.97453e-05 
08/28/2020 06:43:41 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  10%|         | 2/20 [44:01<6:42:24, 1341.37s/it]08/28/2020 06:45:32 - INFO - volta.utils -   Eval task TASK12 on iteration 5399 
08/28/2020 06:45:32 - INFO - volta.utils -   Validation [NLVR2]: loss 0.610 score 65.009 
08/28/2020 06:45:40 - INFO - volta.utils -   [NLVR2]: iter 5419 Ep: 2.01 loss 0.569 score 0.700 lr 4.99576e-05 
08/28/2020 06:45:49 - INFO - volta.utils -   [NLVR2]: iter 5439 Ep: 2.02 loss 0.543 score 0.706 lr 4.99676e-05 
08/28/2020 06:45:57 - INFO - volta.utils -   [NLVR2]: iter 5459 Ep: 2.02 loss 0.579 score 0.689 lr 4.9947e-05 
08/28/2020 06:46:05 - INFO - volta.utils -   [NLVR2]: iter 5479 Ep: 2.03 loss 0.548 score 0.711 lr 4.99264e-05 
08/28/2020 06:46:13 - INFO - volta.utils -   [NLVR2]: iter 5499 Ep: 2.04 loss 0.544 score 0.708 lr 4.99058e-05 
08/28/2020 06:46:21 - INFO - volta.utils -   [NLVR2]: iter 5519 Ep: 2.04 loss 0.575 score 0.664 lr 4.98852e-05 
08/28/2020 06:46:29 - INFO - volta.utils -   [NLVR2]: iter 5539 Ep: 2.05 loss 0.531 score 0.713 lr 4.98647e-05 
08/28/2020 06:46:38 - INFO - volta.utils -   [NLVR2]: iter 5559 Ep: 2.06 loss 0.543 score 0.755 lr 4.98441e-05 
08/28/2020 06:46:46 - INFO - volta.utils -   [NLVR2]: iter 5579 Ep: 2.07 loss 0.561 score 0.691 lr 4.98235e-05 
08/28/2020 06:46:54 - INFO - volta.utils -   [NLVR2]: iter 5599 Ep: 2.07 loss 0.573 score 0.689 lr 4.98029e-05 
08/28/2020 06:47:02 - INFO - volta.utils -   [NLVR2]: iter 5619 Ep: 2.08 loss 0.568 score 0.688 lr 4.97823e-05 
08/28/2020 06:47:10 - INFO - volta.utils -   [NLVR2]: iter 5639 Ep: 2.09 loss 0.528 score 0.722 lr 4.97617e-05 
08/28/2020 06:47:19 - INFO - volta.utils -   [NLVR2]: iter 5659 Ep: 2.10 loss 0.551 score 0.708 lr 4.97412e-05 
08/28/2020 06:47:27 - INFO - volta.utils -   [NLVR2]: iter 5679 Ep: 2.10 loss 0.583 score 0.677 lr 4.97206e-05 
08/28/2020 06:47:35 - INFO - volta.utils -   [NLVR2]: iter 5699 Ep: 2.11 loss 0.545 score 0.713 lr 4.97e-05 
08/28/2020 06:47:43 - INFO - volta.utils -   [NLVR2]: iter 5719 Ep: 2.12 loss 0.566 score 0.686 lr 4.96794e-05 
08/28/2020 06:47:52 - INFO - volta.utils -   [NLVR2]: iter 5739 Ep: 2.13 loss 0.566 score 0.688 lr 4.96588e-05 
08/28/2020 06:48:00 - INFO - volta.utils -   [NLVR2]: iter 5759 Ep: 2.13 loss 0.538 score 0.706 lr 4.96382e-05 
08/28/2020 06:48:09 - INFO - volta.utils -   [NLVR2]: iter 5779 Ep: 2.14 loss 0.539 score 0.711 lr 4.96177e-05 
08/28/2020 06:48:17 - INFO - volta.utils -   [NLVR2]: iter 5799 Ep: 2.15 loss 0.530 score 0.716 lr 4.95971e-05 
08/28/2020 06:48:26 - INFO - volta.utils -   [NLVR2]: iter 5819 Ep: 2.16 loss 0.580 score 0.648 lr 4.95765e-05 
08/28/2020 06:48:33 - INFO - volta.utils -   [NLVR2]: iter 5839 Ep: 2.16 loss 0.582 score 0.666 lr 4.95559e-05 
08/28/2020 06:48:42 - INFO - volta.utils -   [NLVR2]: iter 5859 Ep: 2.17 loss 0.553 score 0.683 lr 4.95353e-05 
08/28/2020 06:48:51 - INFO - volta.utils -   [NLVR2]: iter 5879 Ep: 2.18 loss 0.580 score 0.666 lr 4.95147e-05 
08/28/2020 06:48:59 - INFO - volta.utils -   [NLVR2]: iter 5899 Ep: 2.19 loss 0.534 score 0.716 lr 4.94942e-05 
08/28/2020 06:49:07 - INFO - volta.utils -   [NLVR2]: iter 5919 Ep: 2.19 loss 0.552 score 0.703 lr 4.94736e-05 
08/28/2020 06:49:15 - INFO - volta.utils -   [NLVR2]: iter 5939 Ep: 2.20 loss 0.535 score 0.705 lr 4.9453e-05 
08/28/2020 06:49:23 - INFO - volta.utils -   [NLVR2]: iter 5959 Ep: 2.21 loss 0.586 score 0.661 lr 4.94324e-05 
08/28/2020 06:49:32 - INFO - volta.utils -   [NLVR2]: iter 5979 Ep: 2.22 loss 0.554 score 0.689 lr 4.94118e-05 
08/28/2020 06:49:40 - INFO - volta.utils -   [NLVR2]: iter 5999 Ep: 2.22 loss 0.583 score 0.661 lr 4.93912e-05 
08/28/2020 06:49:48 - INFO - volta.utils -   [NLVR2]: iter 6019 Ep: 2.23 loss 0.573 score 0.680 lr 4.93707e-05 
08/28/2020 06:49:56 - INFO - volta.utils -   [NLVR2]: iter 6039 Ep: 2.24 loss 0.558 score 0.717 lr 4.93501e-05 
08/28/2020 06:50:03 - INFO - volta.utils -   [NLVR2]: iter 6059 Ep: 2.24 loss 0.534 score 0.738 lr 4.93295e-05 
08/28/2020 06:50:12 - INFO - volta.utils -   [NLVR2]: iter 6079 Ep: 2.25 loss 0.543 score 0.698 lr 4.93089e-05 
08/28/2020 06:50:20 - INFO - volta.utils -   [NLVR2]: iter 6099 Ep: 2.26 loss 0.561 score 0.695 lr 4.92883e-05 
08/28/2020 06:50:29 - INFO - volta.utils -   [NLVR2]: iter 6119 Ep: 2.27 loss 0.563 score 0.706 lr 4.92677e-05 
08/28/2020 06:50:36 - INFO - volta.utils -   [NLVR2]: iter 6139 Ep: 2.27 loss 0.614 score 0.641 lr 4.92471e-05 
08/28/2020 06:50:44 - INFO - volta.utils -   [NLVR2]: iter 6159 Ep: 2.28 loss 0.549 score 0.692 lr 4.92266e-05 
08/28/2020 06:50:52 - INFO - volta.utils -   [NLVR2]: iter 6179 Ep: 2.29 loss 0.554 score 0.700 lr 4.9206e-05 
08/28/2020 06:51:01 - INFO - volta.utils -   [NLVR2]: iter 6199 Ep: 2.30 loss 0.570 score 0.691 lr 4.91854e-05 
08/28/2020 06:51:09 - INFO - volta.utils -   [NLVR2]: iter 6219 Ep: 2.30 loss 0.553 score 0.698 lr 4.91648e-05 
08/28/2020 06:51:17 - INFO - volta.utils -   [NLVR2]: iter 6239 Ep: 2.31 loss 0.564 score 0.686 lr 4.91442e-05 
08/28/2020 06:51:25 - INFO - volta.utils -   [NLVR2]: iter 6259 Ep: 2.32 loss 0.556 score 0.708 lr 4.91236e-05 
08/28/2020 06:51:33 - INFO - volta.utils -   [NLVR2]: iter 6279 Ep: 2.33 loss 0.515 score 0.734 lr 4.91031e-05 
08/28/2020 06:51:41 - INFO - volta.utils -   [NLVR2]: iter 6299 Ep: 2.33 loss 0.560 score 0.697 lr 4.90825e-05 
08/28/2020 06:51:50 - INFO - volta.utils -   [NLVR2]: iter 6319 Ep: 2.34 loss 0.555 score 0.688 lr 4.90619e-05 
08/28/2020 06:51:58 - INFO - volta.utils -   [NLVR2]: iter 6339 Ep: 2.35 loss 0.573 score 0.695 lr 4.90413e-05 
08/28/2020 06:52:06 - INFO - volta.utils -   [NLVR2]: iter 6359 Ep: 2.36 loss 0.555 score 0.702 lr 4.90207e-05 
08/28/2020 06:52:14 - INFO - volta.utils -   [NLVR2]: iter 6379 Ep: 2.36 loss 0.554 score 0.708 lr 4.90001e-05 
08/28/2020 06:52:21 - INFO - volta.utils -   [NLVR2]: iter 6399 Ep: 2.37 loss 0.584 score 0.659 lr 4.89796e-05 
08/28/2020 06:52:30 - INFO - volta.utils -   [NLVR2]: iter 6419 Ep: 2.38 loss 0.519 score 0.731 lr 4.8959e-05 
08/28/2020 06:52:37 - INFO - volta.utils -   [NLVR2]: iter 6439 Ep: 2.39 loss 0.558 score 0.702 lr 4.89384e-05 
08/28/2020 06:52:45 - INFO - volta.utils -   [NLVR2]: iter 6459 Ep: 2.39 loss 0.536 score 0.702 lr 4.89178e-05 
08/28/2020 06:52:53 - INFO - volta.utils -   [NLVR2]: iter 6479 Ep: 2.40 loss 0.558 score 0.684 lr 4.88972e-05 
08/28/2020 06:53:01 - INFO - volta.utils -   [NLVR2]: iter 6499 Ep: 2.41 loss 0.566 score 0.695 lr 4.88766e-05 
08/28/2020 06:53:09 - INFO - volta.utils -   [NLVR2]: iter 6519 Ep: 2.42 loss 0.576 score 0.700 lr 4.88561e-05 
08/28/2020 06:53:18 - INFO - volta.utils -   [NLVR2]: iter 6539 Ep: 2.42 loss 0.532 score 0.709 lr 4.88355e-05 
08/28/2020 06:53:26 - INFO - volta.utils -   [NLVR2]: iter 6559 Ep: 2.43 loss 0.582 score 0.669 lr 4.88149e-05 
08/28/2020 06:53:34 - INFO - volta.utils -   [NLVR2]: iter 6579 Ep: 2.44 loss 0.524 score 0.734 lr 4.87943e-05 
08/28/2020 06:53:41 - INFO - volta.utils -   [NLVR2]: iter 6599 Ep: 2.44 loss 0.564 score 0.706 lr 4.87737e-05 
08/28/2020 06:53:49 - INFO - volta.utils -   [NLVR2]: iter 6619 Ep: 2.45 loss 0.585 score 0.681 lr 4.87531e-05 
08/28/2020 06:53:57 - INFO - volta.utils -   [NLVR2]: iter 6639 Ep: 2.46 loss 0.518 score 0.723 lr 4.87326e-05 
08/28/2020 06:54:05 - INFO - volta.utils -   [NLVR2]: iter 6659 Ep: 2.47 loss 0.573 score 0.706 lr 4.8712e-05 
08/28/2020 06:54:13 - INFO - volta.utils -   [NLVR2]: iter 6679 Ep: 2.47 loss 0.576 score 0.694 lr 4.86914e-05 
08/28/2020 06:54:21 - INFO - volta.utils -   [NLVR2]: iter 6699 Ep: 2.48 loss 0.551 score 0.706 lr 4.86708e-05 
08/28/2020 06:54:29 - INFO - volta.utils -   [NLVR2]: iter 6719 Ep: 2.49 loss 0.560 score 0.686 lr 4.86502e-05 
08/28/2020 06:54:37 - INFO - volta.utils -   [NLVR2]: iter 6739 Ep: 2.50 loss 0.543 score 0.705 lr 4.86296e-05 
08/28/2020 06:54:45 - INFO - volta.utils -   [NLVR2]: iter 6759 Ep: 2.50 loss 0.565 score 0.686 lr 4.86091e-05 
08/28/2020 06:54:53 - INFO - volta.utils -   [NLVR2]: iter 6779 Ep: 2.51 loss 0.558 score 0.689 lr 4.85885e-05 
08/28/2020 06:55:02 - INFO - volta.utils -   [NLVR2]: iter 6799 Ep: 2.52 loss 0.562 score 0.678 lr 4.85679e-05 
08/28/2020 06:55:09 - INFO - volta.utils -   [NLVR2]: iter 6819 Ep: 2.53 loss 0.580 score 0.672 lr 4.85473e-05 
08/28/2020 06:55:18 - INFO - volta.utils -   [NLVR2]: iter 6839 Ep: 2.53 loss 0.530 score 0.698 lr 4.85267e-05 
08/28/2020 06:55:26 - INFO - volta.utils -   [NLVR2]: iter 6859 Ep: 2.54 loss 0.552 score 0.708 lr 4.85061e-05 
08/28/2020 06:55:34 - INFO - volta.utils -   [NLVR2]: iter 6879 Ep: 2.55 loss 0.529 score 0.705 lr 4.84856e-05 
08/28/2020 06:55:42 - INFO - volta.utils -   [NLVR2]: iter 6899 Ep: 2.56 loss 0.566 score 0.700 lr 4.8465e-05 
08/28/2020 06:55:50 - INFO - volta.utils -   [NLVR2]: iter 6919 Ep: 2.56 loss 0.548 score 0.709 lr 4.84444e-05 
08/28/2020 06:55:58 - INFO - volta.utils -   [NLVR2]: iter 6939 Ep: 2.57 loss 0.579 score 0.673 lr 4.84238e-05 
08/28/2020 06:56:06 - INFO - volta.utils -   [NLVR2]: iter 6959 Ep: 2.58 loss 0.563 score 0.714 lr 4.84032e-05 
08/28/2020 06:56:14 - INFO - volta.utils -   [NLVR2]: iter 6979 Ep: 2.59 loss 0.558 score 0.698 lr 4.83826e-05 
08/28/2020 06:56:22 - INFO - volta.utils -   [NLVR2]: iter 6999 Ep: 2.59 loss 0.552 score 0.709 lr 4.8362e-05 
08/28/2020 06:56:30 - INFO - volta.utils -   [NLVR2]: iter 7019 Ep: 2.60 loss 0.557 score 0.702 lr 4.83415e-05 
08/28/2020 06:56:38 - INFO - volta.utils -   [NLVR2]: iter 7039 Ep: 2.61 loss 0.570 score 0.678 lr 4.83209e-05 
08/28/2020 06:56:46 - INFO - volta.utils -   [NLVR2]: iter 7059 Ep: 2.62 loss 0.551 score 0.717 lr 4.83003e-05 
08/28/2020 06:56:54 - INFO - volta.utils -   [NLVR2]: iter 7079 Ep: 2.62 loss 0.544 score 0.719 lr 4.82797e-05 
08/28/2020 06:57:02 - INFO - volta.utils -   [NLVR2]: iter 7099 Ep: 2.63 loss 0.529 score 0.741 lr 4.82591e-05 
08/28/2020 06:57:10 - INFO - volta.utils -   [NLVR2]: iter 7119 Ep: 2.64 loss 0.584 score 0.662 lr 4.82385e-05 
08/28/2020 06:57:18 - INFO - volta.utils -   [NLVR2]: iter 7139 Ep: 2.65 loss 0.553 score 0.708 lr 4.8218e-05 
08/28/2020 06:57:26 - INFO - volta.utils -   [NLVR2]: iter 7159 Ep: 2.65 loss 0.564 score 0.681 lr 4.81974e-05 
08/28/2020 06:57:34 - INFO - volta.utils -   [NLVR2]: iter 7179 Ep: 2.66 loss 0.522 score 0.734 lr 4.81768e-05 
08/28/2020 06:57:42 - INFO - volta.utils -   [NLVR2]: iter 7199 Ep: 2.67 loss 0.507 score 0.741 lr 4.81562e-05 
08/28/2020 06:57:50 - INFO - volta.utils -   [NLVR2]: iter 7219 Ep: 2.67 loss 0.570 score 0.684 lr 4.81356e-05 
08/28/2020 06:57:58 - INFO - volta.utils -   [NLVR2]: iter 7239 Ep: 2.68 loss 0.572 score 0.675 lr 4.8115e-05 
08/28/2020 06:58:06 - INFO - volta.utils -   [NLVR2]: iter 7259 Ep: 2.69 loss 0.555 score 0.698 lr 4.80945e-05 
08/28/2020 06:58:14 - INFO - volta.utils -   [NLVR2]: iter 7279 Ep: 2.70 loss 0.560 score 0.669 lr 4.80739e-05 
08/28/2020 06:58:22 - INFO - volta.utils -   [NLVR2]: iter 7299 Ep: 2.70 loss 0.565 score 0.705 lr 4.80533e-05 
08/28/2020 06:58:30 - INFO - volta.utils -   [NLVR2]: iter 7319 Ep: 2.71 loss 0.543 score 0.700 lr 4.80327e-05 
08/28/2020 06:58:38 - INFO - volta.utils -   [NLVR2]: iter 7339 Ep: 2.72 loss 0.542 score 0.705 lr 4.80121e-05 
08/28/2020 06:58:46 - INFO - volta.utils -   [NLVR2]: iter 7359 Ep: 2.73 loss 0.555 score 0.705 lr 4.79915e-05 
08/28/2020 06:58:54 - INFO - volta.utils -   [NLVR2]: iter 7379 Ep: 2.73 loss 0.532 score 0.717 lr 4.7971e-05 
08/28/2020 06:59:02 - INFO - volta.utils -   [NLVR2]: iter 7399 Ep: 2.74 loss 0.568 score 0.694 lr 4.79504e-05 
08/28/2020 06:59:10 - INFO - volta.utils -   [NLVR2]: iter 7419 Ep: 2.75 loss 0.549 score 0.714 lr 4.79298e-05 
08/28/2020 06:59:18 - INFO - volta.utils -   [NLVR2]: iter 7439 Ep: 2.76 loss 0.542 score 0.700 lr 4.79092e-05 
08/28/2020 06:59:26 - INFO - volta.utils -   [NLVR2]: iter 7459 Ep: 2.76 loss 0.555 score 0.703 lr 4.78886e-05 
08/28/2020 06:59:34 - INFO - volta.utils -   [NLVR2]: iter 7479 Ep: 2.77 loss 0.549 score 0.700 lr 4.7868e-05 
08/28/2020 06:59:42 - INFO - volta.utils -   [NLVR2]: iter 7499 Ep: 2.78 loss 0.574 score 0.698 lr 4.78475e-05 
08/28/2020 06:59:49 - INFO - volta.utils -   [NLVR2]: iter 7519 Ep: 2.79 loss 0.544 score 0.689 lr 4.78269e-05 
08/28/2020 06:59:58 - INFO - volta.utils -   [NLVR2]: iter 7539 Ep: 2.79 loss 0.549 score 0.716 lr 4.78063e-05 
08/28/2020 07:00:06 - INFO - volta.utils -   [NLVR2]: iter 7559 Ep: 2.80 loss 0.558 score 0.694 lr 4.77857e-05 
08/28/2020 07:00:13 - INFO - volta.utils -   [NLVR2]: iter 7579 Ep: 2.81 loss 0.528 score 0.722 lr 4.77651e-05 
08/28/2020 07:00:22 - INFO - volta.utils -   [NLVR2]: iter 7599 Ep: 2.82 loss 0.570 score 0.686 lr 4.77445e-05 
08/28/2020 07:00:29 - INFO - volta.utils -   [NLVR2]: iter 7619 Ep: 2.82 loss 0.533 score 0.706 lr 4.7724e-05 
08/28/2020 07:00:37 - INFO - volta.utils -   [NLVR2]: iter 7639 Ep: 2.83 loss 0.565 score 0.698 lr 4.77034e-05 
08/28/2020 07:00:45 - INFO - volta.utils -   [NLVR2]: iter 7659 Ep: 2.84 loss 0.542 score 0.689 lr 4.76828e-05 
08/28/2020 07:00:53 - INFO - volta.utils -   [NLVR2]: iter 7679 Ep: 2.85 loss 0.550 score 0.716 lr 4.76622e-05 
08/28/2020 07:01:01 - INFO - volta.utils -   [NLVR2]: iter 7699 Ep: 2.85 loss 0.572 score 0.700 lr 4.76416e-05 
08/28/2020 07:01:08 - INFO - volta.utils -   [NLVR2]: iter 7719 Ep: 2.86 loss 0.560 score 0.700 lr 4.7621e-05 
08/28/2020 07:01:15 - INFO - volta.utils -   [NLVR2]: iter 7739 Ep: 2.87 loss 0.556 score 0.686 lr 4.76004e-05 
08/28/2020 07:01:23 - INFO - volta.utils -   [NLVR2]: iter 7759 Ep: 2.87 loss 0.527 score 0.713 lr 4.75799e-05 
08/28/2020 07:01:31 - INFO - volta.utils -   [NLVR2]: iter 7779 Ep: 2.88 loss 0.515 score 0.702 lr 4.75593e-05 
08/28/2020 07:01:39 - INFO - volta.utils -   [NLVR2]: iter 7799 Ep: 2.89 loss 0.544 score 0.688 lr 4.75387e-05 
08/28/2020 07:01:47 - INFO - volta.utils -   [NLVR2]: iter 7819 Ep: 2.90 loss 0.568 score 0.714 lr 4.75181e-05 
08/28/2020 07:01:55 - INFO - volta.utils -   [NLVR2]: iter 7839 Ep: 2.90 loss 0.562 score 0.667 lr 4.74975e-05 
08/28/2020 07:02:03 - INFO - volta.utils -   [NLVR2]: iter 7859 Ep: 2.91 loss 0.544 score 0.716 lr 4.74769e-05 
08/28/2020 07:02:12 - INFO - volta.utils -   [NLVR2]: iter 7879 Ep: 2.92 loss 0.562 score 0.695 lr 4.74564e-05 
08/28/2020 07:02:19 - INFO - volta.utils -   [NLVR2]: iter 7899 Ep: 2.93 loss 0.555 score 0.678 lr 4.74358e-05 
08/28/2020 07:02:27 - INFO - volta.utils -   [NLVR2]: iter 7919 Ep: 2.93 loss 0.535 score 0.722 lr 4.74152e-05 
08/28/2020 07:02:36 - INFO - volta.utils -   [NLVR2]: iter 7939 Ep: 2.94 loss 0.558 score 0.700 lr 4.73946e-05 
08/28/2020 07:02:43 - INFO - volta.utils -   [NLVR2]: iter 7959 Ep: 2.95 loss 0.560 score 0.677 lr 4.7374e-05 
08/28/2020 07:02:52 - INFO - volta.utils -   [NLVR2]: iter 7979 Ep: 2.96 loss 0.515 score 0.734 lr 4.73534e-05 
08/28/2020 07:03:00 - INFO - volta.utils -   [NLVR2]: iter 7999 Ep: 2.96 loss 0.579 score 0.691 lr 4.73329e-05 
08/28/2020 07:03:08 - INFO - volta.utils -   [NLVR2]: iter 8019 Ep: 2.97 loss 0.559 score 0.678 lr 4.73123e-05 
08/28/2020 07:03:15 - INFO - volta.utils -   [NLVR2]: iter 8039 Ep: 2.98 loss 0.546 score 0.700 lr 4.72917e-05 
08/28/2020 07:03:23 - INFO - volta.utils -   [NLVR2]: iter 8059 Ep: 2.99 loss 0.568 score 0.686 lr 4.72711e-05 
08/28/2020 07:03:31 - INFO - volta.utils -   [NLVR2]: iter 8079 Ep: 2.99 loss 0.545 score 0.692 lr 4.72505e-05 
08/28/2020 07:03:39 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  15%|        | 3/20 [1:03:59<6:07:54, 1298.47s/it]08/28/2020 07:06:18 - INFO - volta.utils -   Eval task TASK12 on iteration 8098 
08/28/2020 07:06:18 - INFO - volta.utils -   Validation [NLVR2]: loss 0.596 score 67.904 
08/28/2020 07:06:26 - INFO - volta.utils -   [NLVR2]: iter 8118 Ep: 3.01 loss 0.487 score 0.767 lr 4.72202e-05 
08/28/2020 07:06:34 - INFO - volta.utils -   [NLVR2]: iter 8138 Ep: 3.02 loss 0.482 score 0.750 lr 4.71898e-05 
08/28/2020 07:06:42 - INFO - volta.utils -   [NLVR2]: iter 8158 Ep: 3.02 loss 0.448 score 0.783 lr 4.71692e-05 
08/28/2020 07:06:51 - INFO - volta.utils -   [NLVR2]: iter 8178 Ep: 3.03 loss 0.463 score 0.767 lr 4.71486e-05 
08/28/2020 07:06:59 - INFO - volta.utils -   [NLVR2]: iter 8198 Ep: 3.04 loss 0.449 score 0.780 lr 4.71281e-05 
08/28/2020 07:07:07 - INFO - volta.utils -   [NLVR2]: iter 8218 Ep: 3.04 loss 0.503 score 0.727 lr 4.71075e-05 
08/28/2020 07:07:15 - INFO - volta.utils -   [NLVR2]: iter 8238 Ep: 3.05 loss 0.470 score 0.770 lr 4.70869e-05 
08/28/2020 07:08:15 - INFO - volta.utils -   [NLVR2]: iter 8258 Ep: 3.06 loss 0.473 score 0.764 lr 4.70663e-05 
08/28/2020 07:08:51 - INFO - volta.utils -   [NLVR2]: iter 8278 Ep: 3.07 loss 0.445 score 0.777 lr 4.70457e-05 
08/28/2020 07:09:03 - INFO - volta.utils -   [NLVR2]: iter 8298 Ep: 3.07 loss 0.460 score 0.789 lr 4.70251e-05 
08/28/2020 07:09:12 - INFO - volta.utils -   [NLVR2]: iter 8318 Ep: 3.08 loss 0.477 score 0.761 lr 4.70045e-05 
08/28/2020 07:09:20 - INFO - volta.utils -   [NLVR2]: iter 8338 Ep: 3.09 loss 0.477 score 0.736 lr 4.6984e-05 
08/28/2020 07:09:28 - INFO - volta.utils -   [NLVR2]: iter 8358 Ep: 3.10 loss 0.415 score 0.791 lr 4.69634e-05 
08/28/2020 07:09:37 - INFO - volta.utils -   [NLVR2]: iter 8378 Ep: 3.10 loss 0.468 score 0.773 lr 4.69428e-05 
08/28/2020 07:09:45 - INFO - volta.utils -   [NLVR2]: iter 8398 Ep: 3.11 loss 0.449 score 0.759 lr 4.69222e-05 
08/28/2020 07:09:54 - INFO - volta.utils -   [NLVR2]: iter 8418 Ep: 3.12 loss 0.462 score 0.750 lr 4.69016e-05 
08/28/2020 07:10:02 - INFO - volta.utils -   [NLVR2]: iter 8438 Ep: 3.13 loss 0.468 score 0.767 lr 4.6881e-05 
08/28/2020 07:10:10 - INFO - volta.utils -   [NLVR2]: iter 8458 Ep: 3.13 loss 0.480 score 0.766 lr 4.68605e-05 
08/28/2020 07:10:38 - INFO - volta.utils -   [NLVR2]: iter 8478 Ep: 3.14 loss 0.435 score 0.802 lr 4.68399e-05 
08/28/2020 07:11:35 - INFO - volta.utils -   [NLVR2]: iter 8498 Ep: 3.15 loss 0.504 score 0.734 lr 4.68193e-05 
08/28/2020 07:11:52 - INFO - volta.utils -   [NLVR2]: iter 8518 Ep: 3.16 loss 0.451 score 0.753 lr 4.67987e-05 
08/28/2020 07:12:01 - INFO - volta.utils -   [NLVR2]: iter 8538 Ep: 3.16 loss 0.440 score 0.783 lr 4.67781e-05 
08/28/2020 07:12:09 - INFO - volta.utils -   [NLVR2]: iter 8558 Ep: 3.17 loss 0.446 score 0.789 lr 4.67575e-05 
08/28/2020 07:12:16 - INFO - volta.utils -   [NLVR2]: iter 8578 Ep: 3.18 loss 0.455 score 0.767 lr 4.6737e-05 
08/28/2020 07:12:25 - INFO - volta.utils -   [NLVR2]: iter 8598 Ep: 3.19 loss 0.488 score 0.728 lr 4.67164e-05 
08/28/2020 07:12:33 - INFO - volta.utils -   [NLVR2]: iter 8618 Ep: 3.19 loss 0.492 score 0.748 lr 4.66958e-05 
08/28/2020 07:12:41 - INFO - volta.utils -   [NLVR2]: iter 8638 Ep: 3.20 loss 0.470 score 0.769 lr 4.66752e-05 
08/28/2020 07:12:49 - INFO - volta.utils -   [NLVR2]: iter 8658 Ep: 3.21 loss 0.498 score 0.755 lr 4.66546e-05 
08/28/2020 07:12:59 - INFO - volta.utils -   [NLVR2]: iter 8678 Ep: 3.22 loss 0.476 score 0.750 lr 4.6634e-05 
08/28/2020 07:13:06 - INFO - volta.utils -   [NLVR2]: iter 8698 Ep: 3.22 loss 0.457 score 0.766 lr 4.66135e-05 
08/28/2020 07:13:15 - INFO - volta.utils -   [NLVR2]: iter 8718 Ep: 3.23 loss 0.486 score 0.742 lr 4.65929e-05 
08/28/2020 07:14:20 - INFO - volta.utils -   [NLVR2]: iter 8738 Ep: 3.24 loss 0.478 score 0.745 lr 4.65723e-05 
08/28/2020 07:14:41 - INFO - volta.utils -   [NLVR2]: iter 8758 Ep: 3.24 loss 0.469 score 0.759 lr 4.65517e-05 
08/28/2020 07:14:49 - INFO - volta.utils -   [NLVR2]: iter 8778 Ep: 3.25 loss 0.469 score 0.784 lr 4.65311e-05 
08/28/2020 07:15:09 - INFO - volta.utils -   [NLVR2]: iter 8798 Ep: 3.26 loss 0.476 score 0.741 lr 4.65105e-05 
08/28/2020 07:15:17 - INFO - volta.utils -   [NLVR2]: iter 8818 Ep: 3.27 loss 0.479 score 0.756 lr 4.649e-05 
08/28/2020 07:15:26 - INFO - volta.utils -   [NLVR2]: iter 8838 Ep: 3.27 loss 0.494 score 0.772 lr 4.64694e-05 
08/28/2020 07:15:34 - INFO - volta.utils -   [NLVR2]: iter 8858 Ep: 3.28 loss 0.457 score 0.758 lr 4.64488e-05 
08/28/2020 07:15:42 - INFO - volta.utils -   [NLVR2]: iter 8878 Ep: 3.29 loss 0.486 score 0.758 lr 4.64282e-05 
08/28/2020 07:15:50 - INFO - volta.utils -   [NLVR2]: iter 8898 Ep: 3.30 loss 0.480 score 0.756 lr 4.64076e-05 
08/28/2020 07:15:59 - INFO - volta.utils -   [NLVR2]: iter 8918 Ep: 3.30 loss 0.462 score 0.753 lr 4.6387e-05 
08/28/2020 07:16:07 - INFO - volta.utils -   [NLVR2]: iter 8938 Ep: 3.31 loss 0.444 score 0.778 lr 4.63665e-05 
08/28/2020 07:16:15 - INFO - volta.utils -   [NLVR2]: iter 8958 Ep: 3.32 loss 0.500 score 0.744 lr 4.63459e-05 
08/28/2020 07:16:23 - INFO - volta.utils -   [NLVR2]: iter 8978 Ep: 3.33 loss 0.512 score 0.717 lr 4.63253e-05 
08/28/2020 07:16:32 - INFO - volta.utils -   [NLVR2]: iter 8998 Ep: 3.33 loss 0.490 score 0.739 lr 4.63047e-05 
08/28/2020 07:16:40 - INFO - volta.utils -   [NLVR2]: iter 9018 Ep: 3.34 loss 0.487 score 0.755 lr 4.62841e-05 
08/28/2020 07:16:48 - INFO - volta.utils -   [NLVR2]: iter 9038 Ep: 3.35 loss 0.433 score 0.783 lr 4.62635e-05 
08/28/2020 07:16:56 - INFO - volta.utils -   [NLVR2]: iter 9058 Ep: 3.36 loss 0.502 score 0.745 lr 4.6243e-05 
08/28/2020 07:17:04 - INFO - volta.utils -   [NLVR2]: iter 9078 Ep: 3.36 loss 0.459 score 0.769 lr 4.62224e-05 
08/28/2020 07:17:12 - INFO - volta.utils -   [NLVR2]: iter 9098 Ep: 3.37 loss 0.459 score 0.752 lr 4.62018e-05 
08/28/2020 07:17:20 - INFO - volta.utils -   [NLVR2]: iter 9118 Ep: 3.38 loss 0.467 score 0.745 lr 4.61812e-05 
08/28/2020 07:17:29 - INFO - volta.utils -   [NLVR2]: iter 9138 Ep: 3.39 loss 0.465 score 0.780 lr 4.61606e-05 
08/28/2020 07:17:37 - INFO - volta.utils -   [NLVR2]: iter 9158 Ep: 3.39 loss 0.485 score 0.758 lr 4.614e-05 
08/28/2020 07:18:46 - INFO - volta.utils -   [NLVR2]: iter 9178 Ep: 3.40 loss 0.487 score 0.762 lr 4.61194e-05 
08/28/2020 07:19:01 - INFO - volta.utils -   [NLVR2]: iter 9198 Ep: 3.41 loss 0.467 score 0.752 lr 4.60989e-05 
08/28/2020 07:19:10 - INFO - volta.utils -   [NLVR2]: iter 9218 Ep: 3.42 loss 0.455 score 0.756 lr 4.60783e-05 
08/28/2020 07:19:19 - INFO - volta.utils -   [NLVR2]: iter 9238 Ep: 3.42 loss 0.492 score 0.731 lr 4.60577e-05 
08/28/2020 07:19:27 - INFO - volta.utils -   [NLVR2]: iter 9258 Ep: 3.43 loss 0.511 score 0.753 lr 4.60371e-05 
08/28/2020 07:19:36 - INFO - volta.utils -   [NLVR2]: iter 9278 Ep: 3.44 loss 0.520 score 0.716 lr 4.60165e-05 
08/28/2020 07:19:44 - INFO - volta.utils -   [NLVR2]: iter 9298 Ep: 3.44 loss 0.478 score 0.758 lr 4.59959e-05 
08/28/2020 07:19:53 - INFO - volta.utils -   [NLVR2]: iter 9318 Ep: 3.45 loss 0.500 score 0.755 lr 4.59754e-05 
08/28/2020 07:20:00 - INFO - volta.utils -   [NLVR2]: iter 9338 Ep: 3.46 loss 0.464 score 0.766 lr 4.59548e-05 
08/28/2020 07:20:09 - INFO - volta.utils -   [NLVR2]: iter 9358 Ep: 3.47 loss 0.484 score 0.744 lr 4.59342e-05 
08/28/2020 07:20:55 - INFO - volta.utils -   [NLVR2]: iter 9378 Ep: 3.47 loss 0.484 score 0.745 lr 4.59136e-05 
08/28/2020 07:21:30 - INFO - volta.utils -   [NLVR2]: iter 9398 Ep: 3.48 loss 0.451 score 0.761 lr 4.5893e-05 
08/28/2020 07:21:46 - INFO - volta.utils -   [NLVR2]: iter 9418 Ep: 3.49 loss 0.458 score 0.747 lr 4.58724e-05 
08/28/2020 07:21:54 - INFO - volta.utils -   [NLVR2]: iter 9438 Ep: 3.50 loss 0.469 score 0.764 lr 4.58519e-05 
08/28/2020 07:22:02 - INFO - volta.utils -   [NLVR2]: iter 9458 Ep: 3.50 loss 0.450 score 0.769 lr 4.58313e-05 
08/28/2020 07:22:11 - INFO - volta.utils -   [NLVR2]: iter 9478 Ep: 3.51 loss 0.447 score 0.769 lr 4.58107e-05 
08/28/2020 07:22:19 - INFO - volta.utils -   [NLVR2]: iter 9498 Ep: 3.52 loss 0.430 score 0.773 lr 4.57901e-05 
08/28/2020 07:22:27 - INFO - volta.utils -   [NLVR2]: iter 9518 Ep: 3.53 loss 0.459 score 0.764 lr 4.57695e-05 
08/28/2020 07:22:35 - INFO - volta.utils -   [NLVR2]: iter 9538 Ep: 3.53 loss 0.469 score 0.767 lr 4.57489e-05 
08/28/2020 07:22:44 - INFO - volta.utils -   [NLVR2]: iter 9558 Ep: 3.54 loss 0.502 score 0.720 lr 4.57284e-05 
08/28/2020 07:22:52 - INFO - volta.utils -   [NLVR2]: iter 9578 Ep: 3.55 loss 0.482 score 0.744 lr 4.57078e-05 
08/28/2020 07:23:00 - INFO - volta.utils -   [NLVR2]: iter 9598 Ep: 3.56 loss 0.452 score 0.792 lr 4.56872e-05 
08/28/2020 07:24:14 - INFO - volta.utils -   [NLVR2]: iter 9618 Ep: 3.56 loss 0.474 score 0.783 lr 4.56666e-05 
08/28/2020 07:24:34 - INFO - volta.utils -   [NLVR2]: iter 9638 Ep: 3.57 loss 0.469 score 0.742 lr 4.5646e-05 
08/28/2020 07:24:43 - INFO - volta.utils -   [NLVR2]: iter 9658 Ep: 3.58 loss 0.467 score 0.758 lr 4.56254e-05 
08/28/2020 07:24:51 - INFO - volta.utils -   [NLVR2]: iter 9678 Ep: 3.59 loss 0.474 score 0.762 lr 4.56049e-05 
08/28/2020 07:24:59 - INFO - volta.utils -   [NLVR2]: iter 9698 Ep: 3.59 loss 0.483 score 0.770 lr 4.55843e-05 
08/28/2020 07:25:07 - INFO - volta.utils -   [NLVR2]: iter 9718 Ep: 3.60 loss 0.489 score 0.753 lr 4.55637e-05 
08/28/2020 07:25:16 - INFO - volta.utils -   [NLVR2]: iter 9738 Ep: 3.61 loss 0.494 score 0.739 lr 4.55431e-05 
08/28/2020 07:25:24 - INFO - volta.utils -   [NLVR2]: iter 9758 Ep: 3.62 loss 0.473 score 0.750 lr 4.55225e-05 
08/28/2020 07:25:32 - INFO - volta.utils -   [NLVR2]: iter 9778 Ep: 3.62 loss 0.471 score 0.741 lr 4.55019e-05 
08/28/2020 07:25:40 - INFO - volta.utils -   [NLVR2]: iter 9798 Ep: 3.63 loss 0.468 score 0.759 lr 4.54814e-05 
08/28/2020 07:25:55 - INFO - volta.utils -   [NLVR2]: iter 9818 Ep: 3.64 loss 0.499 score 0.744 lr 4.54608e-05 
08/28/2020 07:26:52 - INFO - volta.utils -   [NLVR2]: iter 9838 Ep: 3.65 loss 0.495 score 0.755 lr 4.54402e-05 
08/28/2020 07:27:21 - INFO - volta.utils -   [NLVR2]: iter 9858 Ep: 3.65 loss 0.469 score 0.748 lr 4.54196e-05 
08/28/2020 07:27:39 - INFO - volta.utils -   [NLVR2]: iter 9878 Ep: 3.66 loss 0.468 score 0.747 lr 4.5399e-05 
08/28/2020 07:27:47 - INFO - volta.utils -   [NLVR2]: iter 9898 Ep: 3.67 loss 0.475 score 0.753 lr 4.53784e-05 
08/28/2020 07:27:59 - INFO - volta.utils -   [NLVR2]: iter 9918 Ep: 3.67 loss 0.476 score 0.766 lr 4.53578e-05 
08/28/2020 07:28:06 - INFO - volta.utils -   [NLVR2]: iter 9938 Ep: 3.68 loss 0.470 score 0.778 lr 4.53373e-05 
08/28/2020 07:28:14 - INFO - volta.utils -   [NLVR2]: iter 9958 Ep: 3.69 loss 0.496 score 0.734 lr 4.53167e-05 
08/28/2020 07:28:22 - INFO - volta.utils -   [NLVR2]: iter 9978 Ep: 3.70 loss 0.451 score 0.775 lr 4.52961e-05 
08/28/2020 07:28:31 - INFO - volta.utils -   [NLVR2]: iter 9998 Ep: 3.70 loss 0.465 score 0.756 lr 4.52755e-05 
08/28/2020 07:28:38 - INFO - volta.utils -   [NLVR2]: iter 10018 Ep: 3.71 loss 0.468 score 0.731 lr 4.52549e-05 
08/28/2020 07:28:46 - INFO - volta.utils -   [NLVR2]: iter 10038 Ep: 3.72 loss 0.491 score 0.753 lr 4.52343e-05 
08/28/2020 07:28:54 - INFO - volta.utils -   [NLVR2]: iter 10058 Ep: 3.73 loss 0.479 score 0.752 lr 4.52138e-05 
08/28/2020 07:29:03 - INFO - volta.utils -   [NLVR2]: iter 10078 Ep: 3.73 loss 0.472 score 0.738 lr 4.51932e-05 
08/28/2020 07:29:11 - INFO - volta.utils -   [NLVR2]: iter 10098 Ep: 3.74 loss 0.463 score 0.745 lr 4.51726e-05 
08/28/2020 07:29:19 - INFO - volta.utils -   [NLVR2]: iter 10118 Ep: 3.75 loss 0.453 score 0.773 lr 4.5152e-05 
08/28/2020 07:29:27 - INFO - volta.utils -   [NLVR2]: iter 10138 Ep: 3.76 loss 0.478 score 0.759 lr 4.51314e-05 
08/28/2020 07:29:35 - INFO - volta.utils -   [NLVR2]: iter 10158 Ep: 3.76 loss 0.471 score 0.750 lr 4.51108e-05 
08/28/2020 07:29:43 - INFO - volta.utils -   [NLVR2]: iter 10178 Ep: 3.77 loss 0.506 score 0.761 lr 4.50903e-05 
08/28/2020 07:29:52 - INFO - volta.utils -   [NLVR2]: iter 10198 Ep: 3.78 loss 0.527 score 0.728 lr 4.50697e-05 
08/28/2020 07:30:01 - INFO - volta.utils -   [NLVR2]: iter 10218 Ep: 3.79 loss 0.468 score 0.752 lr 4.50491e-05 
08/28/2020 07:30:08 - INFO - volta.utils -   [NLVR2]: iter 10238 Ep: 3.79 loss 0.460 score 0.756 lr 4.50285e-05 
08/28/2020 07:30:16 - INFO - volta.utils -   [NLVR2]: iter 10258 Ep: 3.80 loss 0.524 score 0.734 lr 4.50079e-05 
08/28/2020 07:30:24 - INFO - volta.utils -   [NLVR2]: iter 10278 Ep: 3.81 loss 0.462 score 0.759 lr 4.49873e-05 
08/28/2020 07:30:33 - INFO - volta.utils -   [NLVR2]: iter 10298 Ep: 3.82 loss 0.500 score 0.752 lr 4.49668e-05 
08/28/2020 07:30:41 - INFO - volta.utils -   [NLVR2]: iter 10318 Ep: 3.82 loss 0.475 score 0.769 lr 4.49462e-05 
08/28/2020 07:31:26 - INFO - volta.utils -   [NLVR2]: iter 10338 Ep: 3.83 loss 0.466 score 0.745 lr 4.49256e-05 
08/28/2020 07:31:46 - INFO - volta.utils -   [NLVR2]: iter 10358 Ep: 3.84 loss 0.474 score 0.775 lr 4.4905e-05 
08/28/2020 07:31:54 - INFO - volta.utils -   [NLVR2]: iter 10378 Ep: 3.85 loss 0.471 score 0.762 lr 4.48844e-05 
08/28/2020 07:32:10 - INFO - volta.utils -   [NLVR2]: iter 10398 Ep: 3.85 loss 0.490 score 0.739 lr 4.48638e-05 
08/28/2020 07:32:19 - INFO - volta.utils -   [NLVR2]: iter 10418 Ep: 3.86 loss 0.505 score 0.711 lr 4.48433e-05 
08/28/2020 07:32:29 - INFO - volta.utils -   [NLVR2]: iter 10438 Ep: 3.87 loss 0.480 score 0.734 lr 4.48227e-05 
08/28/2020 07:32:37 - INFO - volta.utils -   [NLVR2]: iter 10458 Ep: 3.87 loss 0.489 score 0.722 lr 4.48021e-05 
08/28/2020 07:32:45 - INFO - volta.utils -   [NLVR2]: iter 10478 Ep: 3.88 loss 0.478 score 0.739 lr 4.47815e-05 
08/28/2020 07:33:18 - INFO - volta.utils -   [NLVR2]: iter 10498 Ep: 3.89 loss 0.513 score 0.719 lr 4.47609e-05 
08/28/2020 07:34:12 - INFO - volta.utils -   [NLVR2]: iter 10518 Ep: 3.90 loss 0.508 score 0.739 lr 4.47403e-05 
08/28/2020 07:34:21 - INFO - volta.utils -   [NLVR2]: iter 10538 Ep: 3.90 loss 0.485 score 0.745 lr 4.47198e-05 
08/28/2020 07:34:34 - INFO - volta.utils -   [NLVR2]: iter 10558 Ep: 3.91 loss 0.492 score 0.759 lr 4.46992e-05 
08/28/2020 07:34:43 - INFO - volta.utils -   [NLVR2]: iter 10578 Ep: 3.92 loss 0.500 score 0.730 lr 4.46786e-05 
08/28/2020 07:34:51 - INFO - volta.utils -   [NLVR2]: iter 10598 Ep: 3.93 loss 0.436 score 0.783 lr 4.4658e-05 
08/28/2020 07:34:59 - INFO - volta.utils -   [NLVR2]: iter 10618 Ep: 3.93 loss 0.501 score 0.752 lr 4.46374e-05 
08/28/2020 07:35:09 - INFO - volta.utils -   [NLVR2]: iter 10638 Ep: 3.94 loss 0.469 score 0.761 lr 4.46168e-05 
08/28/2020 07:35:17 - INFO - volta.utils -   [NLVR2]: iter 10658 Ep: 3.95 loss 0.457 score 0.780 lr 4.45962e-05 
08/28/2020 07:35:42 - INFO - volta.utils -   [NLVR2]: iter 10678 Ep: 3.96 loss 0.502 score 0.727 lr 4.45757e-05 
08/28/2020 07:36:08 - INFO - volta.utils -   [NLVR2]: iter 10698 Ep: 3.96 loss 0.465 score 0.783 lr 4.45551e-05 
08/28/2020 07:36:23 - INFO - volta.utils -   [NLVR2]: iter 10718 Ep: 3.97 loss 0.464 score 0.752 lr 4.45345e-05 
08/28/2020 07:36:31 - INFO - volta.utils -   [NLVR2]: iter 10738 Ep: 3.98 loss 0.498 score 0.725 lr 4.45139e-05 
08/28/2020 07:36:40 - INFO - volta.utils -   [NLVR2]: iter 10758 Ep: 3.99 loss 0.457 score 0.752 lr 4.44933e-05 
08/28/2020 07:36:48 - INFO - volta.utils -   [NLVR2]: iter 10778 Ep: 3.99 loss 0.425 score 0.781 lr 4.44727e-05 
08/28/2020 07:36:55 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  20%|        | 4/20 [1:37:16<6:42:09, 1508.09s/it]08/28/2020 07:41:29 - INFO - volta.utils -   Eval task TASK12 on iteration 10797 
08/28/2020 07:41:29 - INFO - volta.utils -   Validation [NLVR2]: loss 0.567 score 69.567 
08/28/2020 07:41:37 - INFO - volta.utils -   [NLVR2]: iter 10817 Ep: 4.01 loss 0.421 score 0.814 lr 4.44424e-05 
08/28/2020 07:41:46 - INFO - volta.utils -   [NLVR2]: iter 10837 Ep: 4.02 loss 0.378 score 0.827 lr 4.4412e-05 
08/28/2020 07:42:05 - INFO - volta.utils -   [NLVR2]: iter 10857 Ep: 4.02 loss 0.340 score 0.852 lr 4.43914e-05 
08/28/2020 07:42:41 - INFO - volta.utils -   [NLVR2]: iter 10877 Ep: 4.03 loss 0.399 score 0.827 lr 4.43709e-05 
08/28/2020 07:42:53 - INFO - volta.utils -   [NLVR2]: iter 10897 Ep: 4.04 loss 0.385 score 0.809 lr 4.43503e-05 
08/28/2020 07:43:01 - INFO - volta.utils -   [NLVR2]: iter 10917 Ep: 4.04 loss 0.360 score 0.845 lr 4.43297e-05 
08/28/2020 07:43:09 - INFO - volta.utils -   [NLVR2]: iter 10937 Ep: 4.05 loss 0.323 score 0.842 lr 4.43091e-05 
08/28/2020 07:43:17 - INFO - volta.utils -   [NLVR2]: iter 10957 Ep: 4.06 loss 0.349 score 0.830 lr 4.42885e-05 
08/28/2020 07:43:26 - INFO - volta.utils -   [NLVR2]: iter 10977 Ep: 4.07 loss 0.375 score 0.841 lr 4.42679e-05 
08/28/2020 07:43:34 - INFO - volta.utils -   [NLVR2]: iter 10997 Ep: 4.07 loss 0.396 score 0.814 lr 4.42474e-05 
08/28/2020 07:43:46 - INFO - volta.utils -   [NLVR2]: iter 11017 Ep: 4.08 loss 0.371 score 0.816 lr 4.42268e-05 
08/28/2020 07:44:27 - INFO - volta.utils -   [NLVR2]: iter 11037 Ep: 4.09 loss 0.361 score 0.831 lr 4.42062e-05 
08/28/2020 07:44:44 - INFO - volta.utils -   [NLVR2]: iter 11057 Ep: 4.10 loss 0.406 score 0.792 lr 4.41856e-05 
08/28/2020 07:44:52 - INFO - volta.utils -   [NLVR2]: iter 11077 Ep: 4.10 loss 0.404 score 0.802 lr 4.4165e-05 
08/28/2020 07:45:00 - INFO - volta.utils -   [NLVR2]: iter 11097 Ep: 4.11 loss 0.353 score 0.841 lr 4.41444e-05 
08/28/2020 07:45:09 - INFO - volta.utils -   [NLVR2]: iter 11117 Ep: 4.12 loss 0.380 score 0.819 lr 4.41239e-05 
08/28/2020 07:45:17 - INFO - volta.utils -   [NLVR2]: iter 11137 Ep: 4.13 loss 0.362 score 0.839 lr 4.41033e-05 
08/28/2020 07:45:31 - INFO - volta.utils -   [NLVR2]: iter 11157 Ep: 4.13 loss 0.383 score 0.798 lr 4.40827e-05 
08/28/2020 07:46:00 - INFO - volta.utils -   [NLVR2]: iter 11177 Ep: 4.14 loss 0.358 score 0.833 lr 4.40621e-05 
08/28/2020 07:46:23 - INFO - volta.utils -   [NLVR2]: iter 11197 Ep: 4.15 loss 0.385 score 0.812 lr 4.40415e-05 
08/28/2020 07:46:34 - INFO - volta.utils -   [NLVR2]: iter 11217 Ep: 4.16 loss 0.371 score 0.822 lr 4.40209e-05 
08/28/2020 07:46:43 - INFO - volta.utils -   [NLVR2]: iter 11237 Ep: 4.16 loss 0.371 score 0.838 lr 4.40003e-05 
08/28/2020 07:46:51 - INFO - volta.utils -   [NLVR2]: iter 11257 Ep: 4.17 loss 0.408 score 0.805 lr 4.39798e-05 
08/28/2020 07:46:59 - INFO - volta.utils -   [NLVR2]: iter 11277 Ep: 4.18 loss 0.378 score 0.833 lr 4.39592e-05 
08/28/2020 07:47:23 - INFO - volta.utils -   [NLVR2]: iter 11297 Ep: 4.19 loss 0.365 score 0.834 lr 4.39386e-05 
08/28/2020 07:47:52 - INFO - volta.utils -   [NLVR2]: iter 11317 Ep: 4.19 loss 0.429 score 0.792 lr 4.3918e-05 
08/28/2020 07:48:04 - INFO - volta.utils -   [NLVR2]: iter 11337 Ep: 4.20 loss 0.364 score 0.828 lr 4.38974e-05 
08/28/2020 07:48:15 - INFO - volta.utils -   [NLVR2]: iter 11357 Ep: 4.21 loss 0.349 score 0.845 lr 4.38768e-05 
08/28/2020 07:48:24 - INFO - volta.utils -   [NLVR2]: iter 11377 Ep: 4.22 loss 0.402 score 0.798 lr 4.38563e-05 
08/28/2020 07:48:33 - INFO - volta.utils -   [NLVR2]: iter 11397 Ep: 4.22 loss 0.353 score 0.850 lr 4.38357e-05 
08/28/2020 07:48:41 - INFO - volta.utils -   [NLVR2]: iter 11417 Ep: 4.23 loss 0.374 score 0.830 lr 4.38151e-05 
08/28/2020 07:48:49 - INFO - volta.utils -   [NLVR2]: iter 11437 Ep: 4.24 loss 0.406 score 0.805 lr 4.37945e-05 
08/28/2020 07:49:11 - INFO - volta.utils -   [NLVR2]: iter 11457 Ep: 4.24 loss 0.426 score 0.792 lr 4.37739e-05 
08/28/2020 07:49:34 - INFO - volta.utils -   [NLVR2]: iter 11477 Ep: 4.25 loss 0.363 score 0.841 lr 4.37533e-05 
08/28/2020 07:49:57 - INFO - volta.utils -   [NLVR2]: iter 11497 Ep: 4.26 loss 0.343 score 0.853 lr 4.37328e-05 
08/28/2020 07:50:05 - INFO - volta.utils -   [NLVR2]: iter 11517 Ep: 4.27 loss 0.390 score 0.817 lr 4.37122e-05 
08/28/2020 07:50:14 - INFO - volta.utils -   [NLVR2]: iter 11537 Ep: 4.27 loss 0.389 score 0.827 lr 4.36916e-05 
08/28/2020 07:50:21 - INFO - volta.utils -   [NLVR2]: iter 11557 Ep: 4.28 loss 0.355 score 0.827 lr 4.3671e-05 
08/28/2020 07:50:30 - INFO - volta.utils -   [NLVR2]: iter 11577 Ep: 4.29 loss 0.387 score 0.817 lr 4.36504e-05 
08/28/2020 07:50:38 - INFO - volta.utils -   [NLVR2]: iter 11597 Ep: 4.30 loss 0.377 score 0.797 lr 4.36298e-05 
08/28/2020 07:51:00 - INFO - volta.utils -   [NLVR2]: iter 11617 Ep: 4.30 loss 0.377 score 0.816 lr 4.36093e-05 
08/28/2020 07:51:26 - INFO - volta.utils -   [NLVR2]: iter 11637 Ep: 4.31 loss 0.393 score 0.820 lr 4.35887e-05 
08/28/2020 07:51:41 - INFO - volta.utils -   [NLVR2]: iter 11657 Ep: 4.32 loss 0.413 score 0.816 lr 4.35681e-05 
08/28/2020 07:51:51 - INFO - volta.utils -   [NLVR2]: iter 11677 Ep: 4.33 loss 0.339 score 0.836 lr 4.35475e-05 
08/28/2020 07:52:05 - INFO - volta.utils -   [NLVR2]: iter 11697 Ep: 4.33 loss 0.405 score 0.800 lr 4.35269e-05 
08/28/2020 07:52:14 - INFO - volta.utils -   [NLVR2]: iter 11717 Ep: 4.34 loss 0.387 score 0.798 lr 4.35063e-05 
08/28/2020 07:52:22 - INFO - volta.utils -   [NLVR2]: iter 11737 Ep: 4.35 loss 0.389 score 0.808 lr 4.34858e-05 
08/28/2020 07:52:41 - INFO - volta.utils -   [NLVR2]: iter 11757 Ep: 4.36 loss 0.399 score 0.811 lr 4.34652e-05 
08/28/2020 07:53:14 - INFO - volta.utils -   [NLVR2]: iter 11777 Ep: 4.36 loss 0.374 score 0.819 lr 4.34446e-05 
08/28/2020 07:53:32 - INFO - volta.utils -   [NLVR2]: iter 11797 Ep: 4.37 loss 0.367 score 0.830 lr 4.3424e-05 
08/28/2020 07:53:40 - INFO - volta.utils -   [NLVR2]: iter 11817 Ep: 4.38 loss 0.403 score 0.777 lr 4.34034e-05 
08/28/2020 07:53:49 - INFO - volta.utils -   [NLVR2]: iter 11837 Ep: 4.39 loss 0.414 score 0.786 lr 4.33828e-05 
08/28/2020 07:53:57 - INFO - volta.utils -   [NLVR2]: iter 11857 Ep: 4.39 loss 0.385 score 0.823 lr 4.33623e-05 
08/28/2020 07:54:05 - INFO - volta.utils -   [NLVR2]: iter 11877 Ep: 4.40 loss 0.400 score 0.806 lr 4.33417e-05 
08/28/2020 07:54:14 - INFO - volta.utils -   [NLVR2]: iter 11897 Ep: 4.41 loss 0.414 score 0.797 lr 4.33211e-05 
08/28/2020 07:54:36 - INFO - volta.utils -   [NLVR2]: iter 11917 Ep: 4.42 loss 0.400 score 0.816 lr 4.33005e-05 
08/28/2020 07:55:14 - INFO - volta.utils -   [NLVR2]: iter 11937 Ep: 4.42 loss 0.425 score 0.787 lr 4.32799e-05 
08/28/2020 07:55:34 - INFO - volta.utils -   [NLVR2]: iter 11957 Ep: 4.43 loss 0.386 score 0.820 lr 4.32593e-05 
08/28/2020 07:55:43 - INFO - volta.utils -   [NLVR2]: iter 11977 Ep: 4.44 loss 0.405 score 0.809 lr 4.32388e-05 
08/28/2020 07:55:51 - INFO - volta.utils -   [NLVR2]: iter 11997 Ep: 4.44 loss 0.401 score 0.809 lr 4.32182e-05 
08/28/2020 07:56:08 - INFO - volta.utils -   [NLVR2]: iter 12017 Ep: 4.45 loss 0.368 score 0.822 lr 4.31976e-05 
08/28/2020 07:56:45 - INFO - volta.utils -   [NLVR2]: iter 12037 Ep: 4.46 loss 0.409 score 0.806 lr 4.3177e-05 
08/28/2020 07:57:02 - INFO - volta.utils -   [NLVR2]: iter 12057 Ep: 4.47 loss 0.400 score 0.806 lr 4.31564e-05 
08/28/2020 07:57:11 - INFO - volta.utils -   [NLVR2]: iter 12077 Ep: 4.47 loss 0.360 score 0.823 lr 4.31358e-05 
08/28/2020 07:57:19 - INFO - volta.utils -   [NLVR2]: iter 12097 Ep: 4.48 loss 0.394 score 0.792 lr 4.31152e-05 
08/28/2020 07:57:28 - INFO - volta.utils -   [NLVR2]: iter 12117 Ep: 4.49 loss 0.409 score 0.805 lr 4.30947e-05 
08/28/2020 07:57:36 - INFO - volta.utils -   [NLVR2]: iter 12137 Ep: 4.50 loss 0.421 score 0.809 lr 4.30741e-05 
08/28/2020 07:57:44 - INFO - volta.utils -   [NLVR2]: iter 12157 Ep: 4.50 loss 0.357 score 0.820 lr 4.30535e-05 
08/28/2020 07:58:12 - INFO - volta.utils -   [NLVR2]: iter 12177 Ep: 4.51 loss 0.418 score 0.812 lr 4.30329e-05 
08/28/2020 07:58:38 - INFO - volta.utils -   [NLVR2]: iter 12197 Ep: 4.52 loss 0.406 score 0.794 lr 4.30123e-05 
08/28/2020 07:58:50 - INFO - volta.utils -   [NLVR2]: iter 12217 Ep: 4.53 loss 0.428 score 0.802 lr 4.29917e-05 
08/28/2020 07:58:58 - INFO - volta.utils -   [NLVR2]: iter 12237 Ep: 4.53 loss 0.406 score 0.808 lr 4.29712e-05 
08/28/2020 07:59:06 - INFO - volta.utils -   [NLVR2]: iter 12257 Ep: 4.54 loss 0.397 score 0.811 lr 4.29506e-05 
08/28/2020 07:59:15 - INFO - volta.utils -   [NLVR2]: iter 12277 Ep: 4.55 loss 0.423 score 0.781 lr 4.293e-05 
08/28/2020 07:59:23 - INFO - volta.utils -   [NLVR2]: iter 12297 Ep: 4.56 loss 0.384 score 0.828 lr 4.29094e-05 
08/28/2020 07:59:31 - INFO - volta.utils -   [NLVR2]: iter 12317 Ep: 4.56 loss 0.385 score 0.812 lr 4.28888e-05 
08/28/2020 07:59:40 - INFO - volta.utils -   [NLVR2]: iter 12337 Ep: 4.57 loss 0.408 score 0.806 lr 4.28682e-05 
08/28/2020 08:00:02 - INFO - volta.utils -   [NLVR2]: iter 12357 Ep: 4.58 loss 0.359 score 0.819 lr 4.28477e-05 
08/28/2020 08:00:30 - INFO - volta.utils -   [NLVR2]: iter 12377 Ep: 4.59 loss 0.399 score 0.791 lr 4.28271e-05 
08/28/2020 08:00:48 - INFO - volta.utils -   [NLVR2]: iter 12397 Ep: 4.59 loss 0.395 score 0.802 lr 4.28065e-05 
08/28/2020 08:00:57 - INFO - volta.utils -   [NLVR2]: iter 12417 Ep: 4.60 loss 0.362 score 0.839 lr 4.27859e-05 
08/28/2020 08:01:05 - INFO - volta.utils -   [NLVR2]: iter 12437 Ep: 4.61 loss 0.355 score 0.834 lr 4.27653e-05 
08/28/2020 08:01:13 - INFO - volta.utils -   [NLVR2]: iter 12457 Ep: 4.62 loss 0.422 score 0.780 lr 4.27447e-05 
08/28/2020 08:01:22 - INFO - volta.utils -   [NLVR2]: iter 12477 Ep: 4.62 loss 0.388 score 0.814 lr 4.27242e-05 
08/28/2020 08:01:31 - INFO - volta.utils -   [NLVR2]: iter 12497 Ep: 4.63 loss 0.396 score 0.803 lr 4.27036e-05 
08/28/2020 08:01:39 - INFO - volta.utils -   [NLVR2]: iter 12517 Ep: 4.64 loss 0.394 score 0.805 lr 4.2683e-05 
08/28/2020 08:02:10 - INFO - volta.utils -   [NLVR2]: iter 12537 Ep: 4.65 loss 0.395 score 0.805 lr 4.26624e-05 
08/28/2020 08:02:33 - INFO - volta.utils -   [NLVR2]: iter 12557 Ep: 4.65 loss 0.373 score 0.830 lr 4.26418e-05 
08/28/2020 08:02:46 - INFO - volta.utils -   [NLVR2]: iter 12577 Ep: 4.66 loss 0.378 score 0.828 lr 4.26212e-05 
08/28/2020 08:02:54 - INFO - volta.utils -   [NLVR2]: iter 12597 Ep: 4.67 loss 0.379 score 0.819 lr 4.26007e-05 
08/28/2020 08:03:03 - INFO - volta.utils -   [NLVR2]: iter 12617 Ep: 4.67 loss 0.374 score 0.827 lr 4.25801e-05 
08/28/2020 08:03:11 - INFO - volta.utils -   [NLVR2]: iter 12637 Ep: 4.68 loss 0.398 score 0.809 lr 4.25595e-05 
08/28/2020 08:03:19 - INFO - volta.utils -   [NLVR2]: iter 12657 Ep: 4.69 loss 0.362 score 0.812 lr 4.25389e-05 
08/28/2020 08:03:37 - INFO - volta.utils -   [NLVR2]: iter 12677 Ep: 4.70 loss 0.406 score 0.797 lr 4.25183e-05 
08/28/2020 08:04:06 - INFO - volta.utils -   [NLVR2]: iter 12697 Ep: 4.70 loss 0.403 score 0.792 lr 4.24977e-05 
08/28/2020 08:04:22 - INFO - volta.utils -   [NLVR2]: iter 12717 Ep: 4.71 loss 0.370 score 0.839 lr 4.24772e-05 
08/28/2020 08:04:30 - INFO - volta.utils -   [NLVR2]: iter 12737 Ep: 4.72 loss 0.395 score 0.795 lr 4.24566e-05 
08/28/2020 08:04:38 - INFO - volta.utils -   [NLVR2]: iter 12757 Ep: 4.73 loss 0.347 score 0.827 lr 4.2436e-05 
08/28/2020 08:04:47 - INFO - volta.utils -   [NLVR2]: iter 12777 Ep: 4.73 loss 0.427 score 0.791 lr 4.24154e-05 
08/28/2020 08:04:55 - INFO - volta.utils -   [NLVR2]: iter 12797 Ep: 4.74 loss 0.388 score 0.819 lr 4.23948e-05 
08/28/2020 08:05:03 - INFO - volta.utils -   [NLVR2]: iter 12817 Ep: 4.75 loss 0.407 score 0.800 lr 4.23742e-05 
08/28/2020 08:05:18 - INFO - volta.utils -   [NLVR2]: iter 12837 Ep: 4.76 loss 0.389 score 0.800 lr 4.23536e-05 
08/28/2020 08:05:52 - INFO - volta.utils -   [NLVR2]: iter 12857 Ep: 4.76 loss 0.386 score 0.834 lr 4.23331e-05 
08/28/2020 08:06:12 - INFO - volta.utils -   [NLVR2]: iter 12877 Ep: 4.77 loss 0.360 score 0.823 lr 4.23125e-05 
08/28/2020 08:06:25 - INFO - volta.utils -   [NLVR2]: iter 12897 Ep: 4.78 loss 0.379 score 0.823 lr 4.22919e-05 
08/28/2020 08:06:34 - INFO - volta.utils -   [NLVR2]: iter 12917 Ep: 4.79 loss 0.380 score 0.819 lr 4.22713e-05 
08/28/2020 08:06:42 - INFO - volta.utils -   [NLVR2]: iter 12937 Ep: 4.79 loss 0.396 score 0.806 lr 4.22507e-05 
08/28/2020 08:06:50 - INFO - volta.utils -   [NLVR2]: iter 12957 Ep: 4.80 loss 0.385 score 0.819 lr 4.22301e-05 
08/28/2020 08:06:58 - INFO - volta.utils -   [NLVR2]: iter 12977 Ep: 4.81 loss 0.408 score 0.795 lr 4.22096e-05 
08/28/2020 08:07:11 - INFO - volta.utils -   [NLVR2]: iter 12997 Ep: 4.82 loss 0.402 score 0.812 lr 4.2189e-05 
08/28/2020 08:07:57 - INFO - volta.utils -   [NLVR2]: iter 13017 Ep: 4.82 loss 0.379 score 0.797 lr 4.21684e-05 
08/28/2020 08:08:15 - INFO - volta.utils -   [NLVR2]: iter 13037 Ep: 4.83 loss 0.399 score 0.792 lr 4.21478e-05 
08/28/2020 08:08:26 - INFO - volta.utils -   [NLVR2]: iter 13057 Ep: 4.84 loss 0.414 score 0.800 lr 4.21272e-05 
08/28/2020 08:08:34 - INFO - volta.utils -   [NLVR2]: iter 13077 Ep: 4.85 loss 0.378 score 0.820 lr 4.21066e-05 
08/28/2020 08:08:43 - INFO - volta.utils -   [NLVR2]: iter 13097 Ep: 4.85 loss 0.440 score 0.778 lr 4.20861e-05 
08/28/2020 08:08:51 - INFO - volta.utils -   [NLVR2]: iter 13117 Ep: 4.86 loss 0.374 score 0.817 lr 4.20655e-05 
08/28/2020 08:09:28 - INFO - volta.utils -   [NLVR2]: iter 13137 Ep: 4.87 loss 0.408 score 0.778 lr 4.20449e-05 
08/28/2020 08:09:43 - INFO - volta.utils -   [NLVR2]: iter 13157 Ep: 4.87 loss 0.395 score 0.800 lr 4.20243e-05 
08/28/2020 08:10:02 - INFO - volta.utils -   [NLVR2]: iter 13177 Ep: 4.88 loss 0.361 score 0.820 lr 4.20037e-05 
08/28/2020 08:10:19 - INFO - volta.utils -   [NLVR2]: iter 13197 Ep: 4.89 loss 0.431 score 0.802 lr 4.19831e-05 
08/28/2020 08:10:27 - INFO - volta.utils -   [NLVR2]: iter 13217 Ep: 4.90 loss 0.383 score 0.831 lr 4.19626e-05 
08/28/2020 08:10:35 - INFO - volta.utils -   [NLVR2]: iter 13237 Ep: 4.90 loss 0.410 score 0.811 lr 4.1942e-05 
08/28/2020 08:10:55 - INFO - volta.utils -   [NLVR2]: iter 13257 Ep: 4.91 loss 0.410 score 0.798 lr 4.19214e-05 
08/28/2020 08:11:30 - INFO - volta.utils -   [NLVR2]: iter 13277 Ep: 4.92 loss 0.386 score 0.798 lr 4.19008e-05 
08/28/2020 08:11:41 - INFO - volta.utils -   [NLVR2]: iter 13297 Ep: 4.93 loss 0.415 score 0.798 lr 4.18802e-05 
08/28/2020 08:11:53 - INFO - volta.utils -   [NLVR2]: iter 13317 Ep: 4.93 loss 0.409 score 0.797 lr 4.18596e-05 
08/28/2020 08:12:04 - INFO - volta.utils -   [NLVR2]: iter 13337 Ep: 4.94 loss 0.392 score 0.812 lr 4.18391e-05 
08/28/2020 08:12:12 - INFO - volta.utils -   [NLVR2]: iter 13357 Ep: 4.95 loss 0.422 score 0.798 lr 4.18185e-05 
08/28/2020 08:12:20 - INFO - volta.utils -   [NLVR2]: iter 13377 Ep: 4.96 loss 0.413 score 0.789 lr 4.17979e-05 
08/28/2020 08:12:46 - INFO - volta.utils -   [NLVR2]: iter 13397 Ep: 4.96 loss 0.370 score 0.844 lr 4.17773e-05 
08/28/2020 08:13:18 - INFO - volta.utils -   [NLVR2]: iter 13417 Ep: 4.97 loss 0.398 score 0.791 lr 4.17567e-05 
08/28/2020 08:13:30 - INFO - volta.utils -   [NLVR2]: iter 13437 Ep: 4.98 loss 0.397 score 0.809 lr 4.17361e-05 
08/28/2020 08:13:43 - INFO - volta.utils -   [NLVR2]: iter 13457 Ep: 4.99 loss 0.405 score 0.797 lr 4.17156e-05 
08/28/2020 08:13:53 - INFO - volta.utils -   [NLVR2]: iter 13477 Ep: 4.99 loss 0.393 score 0.814 lr 4.1695e-05 
08/28/2020 08:14:00 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  25%|       | 5/20 [2:14:20<7:10:42, 1722.84s/it]08/28/2020 08:20:06 - INFO - volta.utils -   Eval task TASK12 on iteration 13496 
08/28/2020 08:20:06 - INFO - volta.utils -   Validation [NLVR2]: loss 0.650 score 69.624 
08/28/2020 08:20:14 - INFO - volta.utils -   [NLVR2]: iter 13516 Ep: 5.01 loss 0.309 score 0.865 lr 4.16646e-05 
08/28/2020 08:20:23 - INFO - volta.utils -   [NLVR2]: iter 13536 Ep: 5.02 loss 0.273 score 0.881 lr 4.16342e-05 
08/28/2020 08:20:50 - INFO - volta.utils -   [NLVR2]: iter 13556 Ep: 5.02 loss 0.231 score 0.903 lr 4.16137e-05 
08/28/2020 08:21:16 - INFO - volta.utils -   [NLVR2]: iter 13576 Ep: 5.03 loss 0.283 score 0.861 lr 4.15931e-05 
08/28/2020 08:21:31 - INFO - volta.utils -   [NLVR2]: iter 13596 Ep: 5.04 loss 0.241 score 0.884 lr 4.15725e-05 
08/28/2020 08:21:44 - INFO - volta.utils -   [NLVR2]: iter 13616 Ep: 5.04 loss 0.226 score 0.900 lr 4.15519e-05 
08/28/2020 08:21:52 - INFO - volta.utils -   [NLVR2]: iter 13636 Ep: 5.05 loss 0.284 score 0.881 lr 4.15313e-05 
08/28/2020 08:22:00 - INFO - volta.utils -   [NLVR2]: iter 13656 Ep: 5.06 loss 0.276 score 0.866 lr 4.15107e-05 
08/28/2020 08:22:08 - INFO - volta.utils -   [NLVR2]: iter 13676 Ep: 5.07 loss 0.283 score 0.883 lr 4.14902e-05 
08/28/2020 08:22:42 - INFO - volta.utils -   [NLVR2]: iter 13696 Ep: 5.07 loss 0.252 score 0.875 lr 4.14696e-05 
08/28/2020 08:23:04 - INFO - volta.utils -   [NLVR2]: iter 13716 Ep: 5.08 loss 0.260 score 0.898 lr 4.1449e-05 
08/28/2020 08:23:20 - INFO - volta.utils -   [NLVR2]: iter 13736 Ep: 5.09 loss 0.287 score 0.877 lr 4.14284e-05 
08/28/2020 08:23:28 - INFO - volta.utils -   [NLVR2]: iter 13756 Ep: 5.10 loss 0.279 score 0.877 lr 4.14078e-05 
08/28/2020 08:23:38 - INFO - volta.utils -   [NLVR2]: iter 13776 Ep: 5.10 loss 0.235 score 0.905 lr 4.13872e-05 
08/28/2020 08:23:46 - INFO - volta.utils -   [NLVR2]: iter 13796 Ep: 5.11 loss 0.294 score 0.870 lr 4.13667e-05 
08/28/2020 08:23:54 - INFO - volta.utils -   [NLVR2]: iter 13816 Ep: 5.12 loss 0.269 score 0.872 lr 4.13461e-05 
08/28/2020 08:24:36 - INFO - volta.utils -   [NLVR2]: iter 13836 Ep: 5.13 loss 0.286 score 0.881 lr 4.13255e-05 
08/28/2020 08:24:57 - INFO - volta.utils -   [NLVR2]: iter 13856 Ep: 5.13 loss 0.300 score 0.864 lr 4.13049e-05 
08/28/2020 08:25:07 - INFO - volta.utils -   [NLVR2]: iter 13876 Ep: 5.14 loss 0.247 score 0.895 lr 4.12843e-05 
08/28/2020 08:25:20 - INFO - volta.utils -   [NLVR2]: iter 13896 Ep: 5.15 loss 0.290 score 0.872 lr 4.12637e-05 
08/28/2020 08:25:28 - INFO - volta.utils -   [NLVR2]: iter 13916 Ep: 5.16 loss 0.345 score 0.845 lr 4.12432e-05 
08/28/2020 08:25:51 - INFO - volta.utils -   [NLVR2]: iter 13936 Ep: 5.16 loss 0.262 score 0.881 lr 4.12226e-05 
08/28/2020 08:26:24 - INFO - volta.utils -   [NLVR2]: iter 13956 Ep: 5.17 loss 0.277 score 0.886 lr 4.1202e-05 
08/28/2020 08:26:42 - INFO - volta.utils -   [NLVR2]: iter 13976 Ep: 5.18 loss 0.340 score 0.850 lr 4.11814e-05 
08/28/2020 08:26:51 - INFO - volta.utils -   [NLVR2]: iter 13996 Ep: 5.19 loss 0.264 score 0.884 lr 4.11608e-05 
08/28/2020 08:26:59 - INFO - volta.utils -   [NLVR2]: iter 14016 Ep: 5.19 loss 0.262 score 0.894 lr 4.11402e-05 
08/28/2020 08:27:07 - INFO - volta.utils -   [NLVR2]: iter 14036 Ep: 5.20 loss 0.317 score 0.859 lr 4.11197e-05 
08/28/2020 08:27:26 - INFO - volta.utils -   [NLVR2]: iter 14056 Ep: 5.21 loss 0.288 score 0.861 lr 4.10991e-05 
08/28/2020 08:27:58 - INFO - volta.utils -   [NLVR2]: iter 14076 Ep: 5.22 loss 0.331 score 0.838 lr 4.10785e-05 
08/28/2020 08:28:23 - INFO - volta.utils -   [NLVR2]: iter 14096 Ep: 5.22 loss 0.303 score 0.864 lr 4.10579e-05 
08/28/2020 08:28:31 - INFO - volta.utils -   [NLVR2]: iter 14116 Ep: 5.23 loss 0.345 score 0.853 lr 4.10373e-05 
08/28/2020 08:28:42 - INFO - volta.utils -   [NLVR2]: iter 14136 Ep: 5.24 loss 0.275 score 0.884 lr 4.10167e-05 
08/28/2020 08:28:50 - INFO - volta.utils -   [NLVR2]: iter 14156 Ep: 5.24 loss 0.304 score 0.869 lr 4.09962e-05 
08/28/2020 08:28:58 - INFO - volta.utils -   [NLVR2]: iter 14176 Ep: 5.25 loss 0.241 score 0.905 lr 4.09756e-05 
08/28/2020 08:29:07 - INFO - volta.utils -   [NLVR2]: iter 14196 Ep: 5.26 loss 0.295 score 0.863 lr 4.0955e-05 
08/28/2020 08:29:45 - INFO - volta.utils -   [NLVR2]: iter 14216 Ep: 5.27 loss 0.298 score 0.878 lr 4.09344e-05 
08/28/2020 08:30:09 - INFO - volta.utils -   [NLVR2]: iter 14236 Ep: 5.27 loss 0.274 score 0.877 lr 4.09138e-05 
08/28/2020 08:30:18 - INFO - volta.utils -   [NLVR2]: iter 14256 Ep: 5.28 loss 0.270 score 0.873 lr 4.08932e-05 
08/28/2020 08:30:26 - INFO - volta.utils -   [NLVR2]: iter 14276 Ep: 5.29 loss 0.290 score 0.873 lr 4.08726e-05 
08/28/2020 08:30:34 - INFO - volta.utils -   [NLVR2]: iter 14296 Ep: 5.30 loss 0.296 score 0.856 lr 4.08521e-05 
08/28/2020 08:30:42 - INFO - volta.utils -   [NLVR2]: iter 14316 Ep: 5.30 loss 0.287 score 0.887 lr 4.08315e-05 
08/28/2020 08:31:14 - INFO - volta.utils -   [NLVR2]: iter 14336 Ep: 5.31 loss 0.297 score 0.864 lr 4.08109e-05 
08/28/2020 08:31:43 - INFO - volta.utils -   [NLVR2]: iter 14356 Ep: 5.32 loss 0.263 score 0.880 lr 4.07903e-05 
08/28/2020 08:31:56 - INFO - volta.utils -   [NLVR2]: iter 14376 Ep: 5.33 loss 0.291 score 0.873 lr 4.07697e-05 
08/28/2020 08:32:04 - INFO - volta.utils -   [NLVR2]: iter 14396 Ep: 5.33 loss 0.319 score 0.861 lr 4.07491e-05 
08/28/2020 08:32:13 - INFO - volta.utils -   [NLVR2]: iter 14416 Ep: 5.34 loss 0.309 score 0.858 lr 4.07286e-05 
08/28/2020 08:32:22 - INFO - volta.utils -   [NLVR2]: iter 14436 Ep: 5.35 loss 0.260 score 0.887 lr 4.0708e-05 
08/28/2020 08:32:41 - INFO - volta.utils -   [NLVR2]: iter 14456 Ep: 5.36 loss 0.265 score 0.889 lr 4.06874e-05 
08/28/2020 08:33:17 - INFO - volta.utils -   [NLVR2]: iter 14476 Ep: 5.36 loss 0.327 score 0.869 lr 4.06668e-05 
08/28/2020 08:33:39 - INFO - volta.utils -   [NLVR2]: iter 14496 Ep: 5.37 loss 0.307 score 0.852 lr 4.06462e-05 
08/28/2020 08:33:49 - INFO - volta.utils -   [NLVR2]: iter 14516 Ep: 5.38 loss 0.254 score 0.886 lr 4.06256e-05 
08/28/2020 08:34:01 - INFO - volta.utils -   [NLVR2]: iter 14536 Ep: 5.39 loss 0.271 score 0.872 lr 4.06051e-05 
08/28/2020 08:34:42 - INFO - volta.utils -   [NLVR2]: iter 14556 Ep: 5.39 loss 0.305 score 0.869 lr 4.05845e-05 
08/28/2020 08:35:07 - INFO - volta.utils -   [NLVR2]: iter 14576 Ep: 5.40 loss 0.276 score 0.875 lr 4.05639e-05 
08/28/2020 08:35:17 - INFO - volta.utils -   [NLVR2]: iter 14596 Ep: 5.41 loss 0.289 score 0.867 lr 4.05433e-05 
08/28/2020 08:35:27 - INFO - volta.utils -   [NLVR2]: iter 14616 Ep: 5.42 loss 0.314 score 0.850 lr 4.05227e-05 
08/28/2020 08:35:37 - INFO - volta.utils -   [NLVR2]: iter 14636 Ep: 5.42 loss 0.301 score 0.881 lr 4.05021e-05 
08/28/2020 08:35:45 - INFO - volta.utils -   [NLVR2]: iter 14656 Ep: 5.43 loss 0.296 score 0.861 lr 4.04816e-05 
08/28/2020 08:36:15 - INFO - volta.utils -   [NLVR2]: iter 14676 Ep: 5.44 loss 0.325 score 0.864 lr 4.0461e-05 
08/28/2020 08:36:45 - INFO - volta.utils -   [NLVR2]: iter 14696 Ep: 5.44 loss 0.309 score 0.863 lr 4.04404e-05 
08/28/2020 08:37:01 - INFO - volta.utils -   [NLVR2]: iter 14716 Ep: 5.45 loss 0.281 score 0.877 lr 4.04198e-05 
08/28/2020 08:37:10 - INFO - volta.utils -   [NLVR2]: iter 14736 Ep: 5.46 loss 0.325 score 0.852 lr 4.03992e-05 
08/28/2020 08:37:20 - INFO - volta.utils -   [NLVR2]: iter 14756 Ep: 5.47 loss 0.299 score 0.875 lr 4.03786e-05 
08/28/2020 08:37:28 - INFO - volta.utils -   [NLVR2]: iter 14776 Ep: 5.47 loss 0.321 score 0.839 lr 4.03581e-05 
08/28/2020 08:37:37 - INFO - volta.utils -   [NLVR2]: iter 14796 Ep: 5.48 loss 0.301 score 0.855 lr 4.03375e-05 
08/28/2020 08:38:00 - INFO - volta.utils -   [NLVR2]: iter 14816 Ep: 5.49 loss 0.252 score 0.902 lr 4.03169e-05 
08/28/2020 08:38:24 - INFO - volta.utils -   [NLVR2]: iter 14836 Ep: 5.50 loss 0.290 score 0.878 lr 4.02963e-05 
08/28/2020 08:38:47 - INFO - volta.utils -   [NLVR2]: iter 14856 Ep: 5.50 loss 0.287 score 0.867 lr 4.02757e-05 
08/28/2020 08:39:05 - INFO - volta.utils -   [NLVR2]: iter 14876 Ep: 5.51 loss 0.307 score 0.856 lr 4.02551e-05 
08/28/2020 08:39:13 - INFO - volta.utils -   [NLVR2]: iter 14896 Ep: 5.52 loss 0.323 score 0.856 lr 4.02346e-05 
08/28/2020 08:39:21 - INFO - volta.utils -   [NLVR2]: iter 14916 Ep: 5.53 loss 0.299 score 0.864 lr 4.0214e-05 
08/28/2020 08:39:30 - INFO - volta.utils -   [NLVR2]: iter 14936 Ep: 5.53 loss 0.343 score 0.841 lr 4.01934e-05 
08/28/2020 08:40:42 - INFO - volta.utils -   [NLVR2]: iter 14956 Ep: 5.54 loss 0.312 score 0.866 lr 4.01728e-05 
08/28/2020 08:41:16 - INFO - volta.utils -   [NLVR2]: iter 14976 Ep: 5.55 loss 0.295 score 0.869 lr 4.01522e-05 
08/28/2020 08:41:29 - INFO - volta.utils -   [NLVR2]: iter 14996 Ep: 5.56 loss 0.332 score 0.847 lr 4.01316e-05 
08/28/2020 08:41:39 - INFO - volta.utils -   [NLVR2]: iter 15016 Ep: 5.56 loss 0.323 score 0.845 lr 4.0111e-05 
08/28/2020 08:41:53 - INFO - volta.utils -   [NLVR2]: iter 15036 Ep: 5.57 loss 0.317 score 0.841 lr 4.00905e-05 
08/28/2020 08:43:02 - INFO - volta.utils -   [NLVR2]: iter 15056 Ep: 5.58 loss 0.304 score 0.838 lr 4.00699e-05 
08/28/2020 08:43:45 - INFO - volta.utils -   [NLVR2]: iter 15076 Ep: 5.59 loss 0.314 score 0.861 lr 4.00493e-05 
08/28/2020 08:43:59 - INFO - volta.utils -   [NLVR2]: iter 15096 Ep: 5.59 loss 0.304 score 0.848 lr 4.00287e-05 
08/28/2020 08:45:29 - INFO - volta.utils -   [NLVR2]: iter 15116 Ep: 5.60 loss 0.300 score 0.867 lr 4.00081e-05 
08/28/2020 08:45:48 - INFO - volta.utils -   [NLVR2]: iter 15136 Ep: 5.61 loss 0.335 score 0.855 lr 3.99875e-05 
08/28/2020 08:46:01 - INFO - volta.utils -   [NLVR2]: iter 15156 Ep: 5.62 loss 0.302 score 0.850 lr 3.9967e-05 
08/28/2020 08:47:20 - INFO - volta.utils -   [NLVR2]: iter 15176 Ep: 5.62 loss 0.286 score 0.866 lr 3.99464e-05 
08/28/2020 08:47:38 - INFO - volta.utils -   [NLVR2]: iter 15196 Ep: 5.63 loss 0.271 score 0.866 lr 3.99258e-05 
08/28/2020 08:47:46 - INFO - volta.utils -   [NLVR2]: iter 15216 Ep: 5.64 loss 0.349 score 0.836 lr 3.99052e-05 
08/28/2020 08:47:55 - INFO - volta.utils -   [NLVR2]: iter 15236 Ep: 5.65 loss 0.288 score 0.864 lr 3.98846e-05 
08/28/2020 08:48:03 - INFO - volta.utils -   [NLVR2]: iter 15256 Ep: 5.65 loss 0.267 score 0.859 lr 3.9864e-05 
08/28/2020 08:49:15 - INFO - volta.utils -   [NLVR2]: iter 15276 Ep: 5.66 loss 0.326 score 0.848 lr 3.98435e-05 
08/28/2020 08:49:59 - INFO - volta.utils -   [NLVR2]: iter 15296 Ep: 5.67 loss 0.298 score 0.878 lr 3.98229e-05 
08/28/2020 08:50:12 - INFO - volta.utils -   [NLVR2]: iter 15316 Ep: 5.67 loss 0.337 score 0.831 lr 3.98023e-05 
08/28/2020 08:50:20 - INFO - volta.utils -   [NLVR2]: iter 15336 Ep: 5.68 loss 0.299 score 0.873 lr 3.97817e-05 
08/28/2020 08:50:57 - INFO - volta.utils -   [NLVR2]: iter 15356 Ep: 5.69 loss 0.289 score 0.883 lr 3.97611e-05 
08/28/2020 08:52:08 - INFO - volta.utils -   [NLVR2]: iter 15376 Ep: 5.70 loss 0.301 score 0.872 lr 3.97405e-05 
08/28/2020 08:52:27 - INFO - volta.utils -   [NLVR2]: iter 15396 Ep: 5.70 loss 0.333 score 0.844 lr 3.972e-05 
08/28/2020 08:53:19 - INFO - volta.utils -   [NLVR2]: iter 15416 Ep: 5.71 loss 0.302 score 0.866 lr 3.96994e-05 
08/28/2020 08:53:51 - INFO - volta.utils -   [NLVR2]: iter 15436 Ep: 5.72 loss 0.271 score 0.869 lr 3.96788e-05 
08/28/2020 08:54:03 - INFO - volta.utils -   [NLVR2]: iter 15456 Ep: 5.73 loss 0.345 score 0.848 lr 3.96582e-05 
08/28/2020 08:54:22 - INFO - volta.utils -   [NLVR2]: iter 15476 Ep: 5.73 loss 0.350 score 0.839 lr 3.96376e-05 
08/28/2020 08:55:02 - INFO - volta.utils -   [NLVR2]: iter 15496 Ep: 5.74 loss 0.317 score 0.858 lr 3.9617e-05 
08/28/2020 08:55:21 - INFO - volta.utils -   [NLVR2]: iter 15516 Ep: 5.75 loss 0.322 score 0.858 lr 3.95965e-05 
08/28/2020 08:55:46 - INFO - volta.utils -   [NLVR2]: iter 15536 Ep: 5.76 loss 0.283 score 0.870 lr 3.95759e-05 
08/28/2020 08:56:40 - INFO - volta.utils -   [NLVR2]: iter 15556 Ep: 5.76 loss 0.310 score 0.859 lr 3.95553e-05 
08/28/2020 08:57:40 - INFO - volta.utils -   [NLVR2]: iter 15576 Ep: 5.77 loss 0.304 score 0.863 lr 3.95347e-05 
08/28/2020 08:57:49 - INFO - volta.utils -   [NLVR2]: iter 15596 Ep: 5.78 loss 0.350 score 0.831 lr 3.95141e-05 
08/28/2020 08:57:59 - INFO - volta.utils -   [NLVR2]: iter 15616 Ep: 5.79 loss 0.271 score 0.898 lr 3.94935e-05 
08/28/2020 08:58:09 - INFO - volta.utils -   [NLVR2]: iter 15636 Ep: 5.79 loss 0.396 score 0.833 lr 3.9473e-05 
08/28/2020 08:59:35 - INFO - volta.utils -   [NLVR2]: iter 15656 Ep: 5.80 loss 0.520 score 0.739 lr 3.94524e-05 
08/28/2020 09:00:03 - INFO - volta.utils -   [NLVR2]: iter 15676 Ep: 5.81 loss 0.456 score 0.770 lr 3.94318e-05 
08/28/2020 09:00:17 - INFO - volta.utils -   [NLVR2]: iter 15696 Ep: 5.82 loss 0.408 score 0.802 lr 3.94112e-05 
08/28/2020 09:00:52 - INFO - volta.utils -   [NLVR2]: iter 15716 Ep: 5.82 loss 0.358 score 0.844 lr 3.93906e-05 
08/28/2020 09:01:18 - INFO - volta.utils -   [NLVR2]: iter 15736 Ep: 5.83 loss 0.399 score 0.814 lr 3.937e-05 
08/28/2020 09:01:36 - INFO - volta.utils -   [NLVR2]: iter 15756 Ep: 5.84 loss 0.339 score 0.833 lr 3.93495e-05 
08/28/2020 09:01:50 - INFO - volta.utils -   [NLVR2]: iter 15776 Ep: 5.85 loss 0.374 score 0.819 lr 3.93289e-05 
08/28/2020 09:01:59 - INFO - volta.utils -   [NLVR2]: iter 15796 Ep: 5.85 loss 0.342 score 0.831 lr 3.93083e-05 
08/28/2020 09:02:43 - INFO - volta.utils -   [NLVR2]: iter 15816 Ep: 5.86 loss 0.395 score 0.819 lr 3.92877e-05 
08/28/2020 09:03:42 - INFO - volta.utils -   [NLVR2]: iter 15836 Ep: 5.87 loss 0.370 score 0.834 lr 3.92671e-05 
08/28/2020 09:04:09 - INFO - volta.utils -   [NLVR2]: iter 15856 Ep: 5.87 loss 0.423 score 0.781 lr 3.92465e-05 
08/28/2020 09:04:30 - INFO - volta.utils -   [NLVR2]: iter 15876 Ep: 5.88 loss 0.382 score 0.828 lr 3.92259e-05 
08/28/2020 09:05:34 - INFO - volta.utils -   [NLVR2]: iter 15896 Ep: 5.89 loss 0.345 score 0.844 lr 3.92054e-05 
08/28/2020 09:06:12 - INFO - volta.utils -   [NLVR2]: iter 15916 Ep: 5.90 loss 0.327 score 0.842 lr 3.91848e-05 
08/28/2020 09:06:37 - INFO - volta.utils -   [NLVR2]: iter 15936 Ep: 5.90 loss 0.377 score 0.819 lr 3.91642e-05 
08/28/2020 09:07:23 - INFO - volta.utils -   [NLVR2]: iter 15956 Ep: 5.91 loss 0.373 score 0.828 lr 3.91436e-05 
08/28/2020 09:07:48 - INFO - volta.utils -   [NLVR2]: iter 15976 Ep: 5.92 loss 0.351 score 0.834 lr 3.9123e-05 
08/28/2020 09:08:10 - INFO - volta.utils -   [NLVR2]: iter 15996 Ep: 5.93 loss 0.382 score 0.803 lr 3.91024e-05 
08/28/2020 09:08:26 - INFO - volta.utils -   [NLVR2]: iter 16016 Ep: 5.93 loss 0.374 score 0.828 lr 3.90819e-05 
08/28/2020 09:08:33 - INFO - volta.utils -   [NLVR2]: iter 16036 Ep: 5.94 loss 0.371 score 0.819 lr 3.90613e-05 
08/28/2020 09:10:05 - INFO - volta.utils -   [NLVR2]: iter 16056 Ep: 5.95 loss 0.330 score 0.838 lr 3.90407e-05 
08/28/2020 09:10:21 - INFO - volta.utils -   [NLVR2]: iter 16076 Ep: 5.96 loss 0.354 score 0.830 lr 3.90201e-05 
08/28/2020 09:10:31 - INFO - volta.utils -   [NLVR2]: iter 16096 Ep: 5.96 loss 0.293 score 0.863 lr 3.89995e-05 
08/28/2020 09:11:45 - INFO - volta.utils -   [NLVR2]: iter 16116 Ep: 5.97 loss 0.343 score 0.853 lr 3.89789e-05 
08/28/2020 09:12:31 - INFO - volta.utils -   [NLVR2]: iter 16136 Ep: 5.98 loss 0.315 score 0.859 lr 3.89584e-05 
08/28/2020 09:12:43 - INFO - volta.utils -   [NLVR2]: iter 16156 Ep: 5.99 loss 0.339 score 0.842 lr 3.89378e-05 
08/28/2020 09:12:52 - INFO - volta.utils -   [NLVR2]: iter 16176 Ep: 5.99 loss 0.365 score 0.834 lr 3.89172e-05 
08/28/2020 09:13:06 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  30%|       | 6/20 [3:13:27<8:49:39, 2269.94s/it]08/28/2020 09:21:30 - INFO - volta.utils -   Eval task TASK12 on iteration 16195 
08/28/2020 09:21:30 - INFO - volta.utils -   Validation [NLVR2]: loss 0.795 score 69.567 
08/28/2020 09:21:38 - INFO - volta.utils -   [NLVR2]: iter 16215 Ep: 6.01 loss 0.254 score 0.893 lr 3.88868e-05 
08/28/2020 09:21:46 - INFO - volta.utils -   [NLVR2]: iter 16235 Ep: 6.02 loss 0.215 score 0.916 lr 3.88565e-05 
08/28/2020 09:22:35 - INFO - volta.utils -   [NLVR2]: iter 16255 Ep: 6.02 loss 0.244 score 0.894 lr 3.88359e-05 
08/28/2020 09:22:49 - INFO - volta.utils -   [NLVR2]: iter 16275 Ep: 6.03 loss 0.233 score 0.909 lr 3.88153e-05 
08/28/2020 09:23:05 - INFO - volta.utils -   [NLVR2]: iter 16295 Ep: 6.04 loss 0.239 score 0.894 lr 3.87947e-05 
08/28/2020 09:23:13 - INFO - volta.utils -   [NLVR2]: iter 16315 Ep: 6.04 loss 0.218 score 0.909 lr 3.87741e-05 
08/28/2020 09:23:21 - INFO - volta.utils -   [NLVR2]: iter 16335 Ep: 6.05 loss 0.227 score 0.902 lr 3.87536e-05 
08/28/2020 09:23:56 - INFO - volta.utils -   [NLVR2]: iter 16355 Ep: 6.06 loss 0.224 score 0.916 lr 3.8733e-05 
08/28/2020 09:24:24 - INFO - volta.utils -   [NLVR2]: iter 16375 Ep: 6.07 loss 0.209 score 0.917 lr 3.87124e-05 
08/28/2020 09:24:36 - INFO - volta.utils -   [NLVR2]: iter 16395 Ep: 6.07 loss 0.233 score 0.886 lr 3.86918e-05 
08/28/2020 09:24:46 - INFO - volta.utils -   [NLVR2]: iter 16415 Ep: 6.08 loss 0.214 score 0.920 lr 3.86712e-05 
08/28/2020 09:24:55 - INFO - volta.utils -   [NLVR2]: iter 16435 Ep: 6.09 loss 0.283 score 0.883 lr 3.86506e-05 
08/28/2020 09:25:03 - INFO - volta.utils -   [NLVR2]: iter 16455 Ep: 6.10 loss 0.246 score 0.905 lr 3.863e-05 
08/28/2020 09:25:18 - INFO - volta.utils -   [NLVR2]: iter 16475 Ep: 6.10 loss 0.214 score 0.906 lr 3.86095e-05 
08/28/2020 09:25:54 - INFO - volta.utils -   [NLVR2]: iter 16495 Ep: 6.11 loss 0.225 score 0.911 lr 3.85889e-05 
08/28/2020 09:26:11 - INFO - volta.utils -   [NLVR2]: iter 16515 Ep: 6.12 loss 0.232 score 0.895 lr 3.85683e-05 
08/28/2020 09:26:20 - INFO - volta.utils -   [NLVR2]: iter 16535 Ep: 6.13 loss 0.241 score 0.897 lr 3.85477e-05 
08/28/2020 09:26:29 - INFO - volta.utils -   [NLVR2]: iter 16555 Ep: 6.13 loss 0.172 score 0.938 lr 3.85271e-05 
08/28/2020 09:26:38 - INFO - volta.utils -   [NLVR2]: iter 16575 Ep: 6.14 loss 0.242 score 0.905 lr 3.85065e-05 
08/28/2020 09:26:46 - INFO - volta.utils -   [NLVR2]: iter 16595 Ep: 6.15 loss 0.215 score 0.916 lr 3.8486e-05 
08/28/2020 09:27:12 - INFO - volta.utils -   [NLVR2]: iter 16615 Ep: 6.16 loss 0.237 score 0.889 lr 3.84654e-05 
08/28/2020 09:27:41 - INFO - volta.utils -   [NLVR2]: iter 16635 Ep: 6.16 loss 0.245 score 0.902 lr 3.84448e-05 
08/28/2020 09:28:00 - INFO - volta.utils -   [NLVR2]: iter 16655 Ep: 6.17 loss 0.228 score 0.906 lr 3.84242e-05 
08/28/2020 09:28:14 - INFO - volta.utils -   [NLVR2]: iter 16675 Ep: 6.18 loss 0.261 score 0.892 lr 3.84036e-05 
08/28/2020 09:28:23 - INFO - volta.utils -   [NLVR2]: iter 16695 Ep: 6.19 loss 0.242 score 0.905 lr 3.8383e-05 
08/28/2020 09:28:32 - INFO - volta.utils -   [NLVR2]: iter 16715 Ep: 6.19 loss 0.255 score 0.897 lr 3.83625e-05 
08/28/2020 09:28:42 - INFO - volta.utils -   [NLVR2]: iter 16735 Ep: 6.20 loss 0.271 score 0.878 lr 3.83419e-05 
08/28/2020 09:29:28 - INFO - volta.utils -   [NLVR2]: iter 16755 Ep: 6.21 loss 0.246 score 0.895 lr 3.83213e-05 
08/28/2020 09:29:45 - INFO - volta.utils -   [NLVR2]: iter 16775 Ep: 6.22 loss 0.192 score 0.916 lr 3.83007e-05 
08/28/2020 09:29:58 - INFO - volta.utils -   [NLVR2]: iter 16795 Ep: 6.22 loss 0.215 score 0.911 lr 3.82801e-05 
08/28/2020 09:30:10 - INFO - volta.utils -   [NLVR2]: iter 16815 Ep: 6.23 loss 0.211 score 0.908 lr 3.82595e-05 
08/28/2020 09:30:18 - INFO - volta.utils -   [NLVR2]: iter 16835 Ep: 6.24 loss 0.229 score 0.911 lr 3.8239e-05 
08/28/2020 09:30:39 - INFO - volta.utils -   [NLVR2]: iter 16855 Ep: 6.24 loss 0.188 score 0.919 lr 3.82184e-05 
08/28/2020 09:31:17 - INFO - volta.utils -   [NLVR2]: iter 16875 Ep: 6.25 loss 0.202 score 0.914 lr 3.81978e-05 
08/28/2020 09:31:32 - INFO - volta.utils -   [NLVR2]: iter 16895 Ep: 6.26 loss 0.230 score 0.902 lr 3.81772e-05 
08/28/2020 09:31:48 - INFO - volta.utils -   [NLVR2]: iter 16915 Ep: 6.27 loss 0.248 score 0.891 lr 3.81566e-05 
08/28/2020 09:31:56 - INFO - volta.utils -   [NLVR2]: iter 16935 Ep: 6.27 loss 0.250 score 0.898 lr 3.8136e-05 
08/28/2020 09:32:04 - INFO - volta.utils -   [NLVR2]: iter 16955 Ep: 6.28 loss 0.193 score 0.927 lr 3.81155e-05 
08/28/2020 09:32:50 - INFO - volta.utils -   [NLVR2]: iter 16975 Ep: 6.29 loss 0.208 score 0.905 lr 3.80949e-05 
08/28/2020 09:33:11 - INFO - volta.utils -   [NLVR2]: iter 16995 Ep: 6.30 loss 0.236 score 0.906 lr 3.80743e-05 
08/28/2020 09:33:28 - INFO - volta.utils -   [NLVR2]: iter 17015 Ep: 6.30 loss 0.271 score 0.877 lr 3.80537e-05 
08/28/2020 09:33:36 - INFO - volta.utils -   [NLVR2]: iter 17035 Ep: 6.31 loss 0.217 score 0.912 lr 3.80331e-05 
08/28/2020 09:33:55 - INFO - volta.utils -   [NLVR2]: iter 17055 Ep: 6.32 loss 0.213 score 0.916 lr 3.80125e-05 
08/28/2020 09:34:30 - INFO - volta.utils -   [NLVR2]: iter 17075 Ep: 6.33 loss 0.233 score 0.905 lr 3.7992e-05 
08/28/2020 09:34:49 - INFO - volta.utils -   [NLVR2]: iter 17095 Ep: 6.33 loss 0.217 score 0.902 lr 3.79714e-05 
08/28/2020 09:35:07 - INFO - volta.utils -   [NLVR2]: iter 17115 Ep: 6.34 loss 0.231 score 0.891 lr 3.79508e-05 
08/28/2020 09:35:15 - INFO - volta.utils -   [NLVR2]: iter 17135 Ep: 6.35 loss 0.197 score 0.902 lr 3.79302e-05 
08/28/2020 09:35:24 - INFO - volta.utils -   [NLVR2]: iter 17155 Ep: 6.36 loss 0.260 score 0.889 lr 3.79096e-05 
08/28/2020 09:35:32 - INFO - volta.utils -   [NLVR2]: iter 17175 Ep: 6.36 loss 0.231 score 0.902 lr 3.7889e-05 
08/28/2020 09:35:57 - INFO - volta.utils -   [NLVR2]: iter 17195 Ep: 6.37 loss 0.227 score 0.900 lr 3.78684e-05 
08/28/2020 09:36:38 - INFO - volta.utils -   [NLVR2]: iter 17215 Ep: 6.38 loss 0.223 score 0.905 lr 3.78479e-05 
08/28/2020 09:36:52 - INFO - volta.utils -   [NLVR2]: iter 17235 Ep: 6.39 loss 0.218 score 0.906 lr 3.78273e-05 
08/28/2020 09:37:03 - INFO - volta.utils -   [NLVR2]: iter 17255 Ep: 6.39 loss 0.245 score 0.887 lr 3.78067e-05 
08/28/2020 09:37:12 - INFO - volta.utils -   [NLVR2]: iter 17275 Ep: 6.40 loss 0.223 score 0.911 lr 3.77861e-05 
08/28/2020 09:37:20 - INFO - volta.utils -   [NLVR2]: iter 17295 Ep: 6.41 loss 0.251 score 0.894 lr 3.77655e-05 
08/28/2020 09:37:44 - INFO - volta.utils -   [NLVR2]: iter 17315 Ep: 6.42 loss 0.243 score 0.902 lr 3.77449e-05 
08/28/2020 09:38:24 - INFO - volta.utils -   [NLVR2]: iter 17335 Ep: 6.42 loss 0.312 score 0.858 lr 3.77244e-05 
08/28/2020 09:38:39 - INFO - volta.utils -   [NLVR2]: iter 17355 Ep: 6.43 loss 0.256 score 0.883 lr 3.77038e-05 
08/28/2020 09:38:52 - INFO - volta.utils -   [NLVR2]: iter 17375 Ep: 6.44 loss 0.236 score 0.895 lr 3.76832e-05 
08/28/2020 09:39:00 - INFO - volta.utils -   [NLVR2]: iter 17395 Ep: 6.44 loss 0.221 score 0.906 lr 3.76626e-05 
08/28/2020 09:39:08 - INFO - volta.utils -   [NLVR2]: iter 17415 Ep: 6.45 loss 0.236 score 0.914 lr 3.7642e-05 
08/28/2020 09:39:44 - INFO - volta.utils -   [NLVR2]: iter 17435 Ep: 6.46 loss 0.257 score 0.881 lr 3.76214e-05 
08/28/2020 09:40:11 - INFO - volta.utils -   [NLVR2]: iter 17455 Ep: 6.47 loss 0.223 score 0.906 lr 3.76009e-05 
08/28/2020 09:40:23 - INFO - volta.utils -   [NLVR2]: iter 17475 Ep: 6.47 loss 0.242 score 0.897 lr 3.75803e-05 
08/28/2020 09:40:34 - INFO - volta.utils -   [NLVR2]: iter 17495 Ep: 6.48 loss 0.243 score 0.891 lr 3.75597e-05 
08/28/2020 09:40:43 - INFO - volta.utils -   [NLVR2]: iter 17515 Ep: 6.49 loss 0.253 score 0.883 lr 3.75391e-05 
08/28/2020 09:40:51 - INFO - volta.utils -   [NLVR2]: iter 17535 Ep: 6.50 loss 0.252 score 0.905 lr 3.75185e-05 
08/28/2020 09:41:04 - INFO - volta.utils -   [NLVR2]: iter 17555 Ep: 6.50 loss 0.257 score 0.891 lr 3.74979e-05 
08/28/2020 09:41:33 - INFO - volta.utils -   [NLVR2]: iter 17575 Ep: 6.51 loss 0.246 score 0.895 lr 3.74774e-05 
08/28/2020 09:42:06 - INFO - volta.utils -   [NLVR2]: iter 17595 Ep: 6.52 loss 0.265 score 0.889 lr 3.74568e-05 
08/28/2020 09:42:14 - INFO - volta.utils -   [NLVR2]: iter 17615 Ep: 6.53 loss 0.206 score 0.912 lr 3.74362e-05 
08/28/2020 09:42:23 - INFO - volta.utils -   [NLVR2]: iter 17635 Ep: 6.53 loss 0.231 score 0.900 lr 3.74156e-05 
08/28/2020 09:42:31 - INFO - volta.utils -   [NLVR2]: iter 17655 Ep: 6.54 loss 0.252 score 0.902 lr 3.7395e-05 
08/28/2020 09:42:40 - INFO - volta.utils -   [NLVR2]: iter 17675 Ep: 6.55 loss 0.289 score 0.875 lr 3.73744e-05 
08/28/2020 09:42:47 - INFO - volta.utils -   [NLVR2]: iter 17695 Ep: 6.56 loss 0.255 score 0.895 lr 3.73539e-05 
08/28/2020 09:43:42 - INFO - volta.utils -   [NLVR2]: iter 17715 Ep: 6.56 loss 0.241 score 0.895 lr 3.73333e-05 
08/28/2020 09:43:58 - INFO - volta.utils -   [NLVR2]: iter 17735 Ep: 6.57 loss 0.269 score 0.884 lr 3.73127e-05 
08/28/2020 09:44:06 - INFO - volta.utils -   [NLVR2]: iter 17755 Ep: 6.58 loss 0.224 score 0.898 lr 3.72921e-05 
08/28/2020 09:44:14 - INFO - volta.utils -   [NLVR2]: iter 17775 Ep: 6.59 loss 0.271 score 0.889 lr 3.72715e-05 
08/28/2020 09:44:23 - INFO - volta.utils -   [NLVR2]: iter 17795 Ep: 6.59 loss 0.218 score 0.902 lr 3.72509e-05 
08/28/2020 09:44:31 - INFO - volta.utils -   [NLVR2]: iter 17815 Ep: 6.60 loss 0.250 score 0.880 lr 3.72304e-05 
08/28/2020 09:45:01 - INFO - volta.utils -   [NLVR2]: iter 17835 Ep: 6.61 loss 0.256 score 0.883 lr 3.72098e-05 
08/28/2020 09:45:31 - INFO - volta.utils -   [NLVR2]: iter 17855 Ep: 6.62 loss 0.210 score 0.908 lr 3.71892e-05 
08/28/2020 09:45:47 - INFO - volta.utils -   [NLVR2]: iter 17875 Ep: 6.62 loss 0.243 score 0.892 lr 3.71686e-05 
08/28/2020 09:46:02 - INFO - volta.utils -   [NLVR2]: iter 17895 Ep: 6.63 loss 0.239 score 0.892 lr 3.7148e-05 
08/28/2020 09:46:11 - INFO - volta.utils -   [NLVR2]: iter 17915 Ep: 6.64 loss 0.280 score 0.883 lr 3.71274e-05 
08/28/2020 09:46:21 - INFO - volta.utils -   [NLVR2]: iter 17935 Ep: 6.65 loss 0.290 score 0.872 lr 3.71069e-05 
08/28/2020 09:46:57 - INFO - volta.utils -   [NLVR2]: iter 17955 Ep: 6.65 loss 0.226 score 0.897 lr 3.70863e-05 
08/28/2020 09:47:20 - INFO - volta.utils -   [NLVR2]: iter 17975 Ep: 6.66 loss 0.249 score 0.897 lr 3.70657e-05 
08/28/2020 09:47:29 - INFO - volta.utils -   [NLVR2]: iter 17995 Ep: 6.67 loss 0.301 score 0.878 lr 3.70451e-05 
08/28/2020 09:47:42 - INFO - volta.utils -   [NLVR2]: iter 18015 Ep: 6.67 loss 0.250 score 0.892 lr 3.70245e-05 
08/28/2020 09:47:50 - INFO - volta.utils -   [NLVR2]: iter 18035 Ep: 6.68 loss 0.263 score 0.892 lr 3.70039e-05 
08/28/2020 09:47:59 - INFO - volta.utils -   [NLVR2]: iter 18055 Ep: 6.69 loss 0.289 score 0.883 lr 3.69833e-05 
08/28/2020 09:48:23 - INFO - volta.utils -   [NLVR2]: iter 18075 Ep: 6.70 loss 0.260 score 0.902 lr 3.69628e-05 
08/28/2020 09:48:53 - INFO - volta.utils -   [NLVR2]: iter 18095 Ep: 6.70 loss 0.232 score 0.906 lr 3.69422e-05 
08/28/2020 09:49:13 - INFO - volta.utils -   [NLVR2]: iter 18115 Ep: 6.71 loss 0.277 score 0.869 lr 3.69216e-05 
08/28/2020 09:49:22 - INFO - volta.utils -   [NLVR2]: iter 18135 Ep: 6.72 loss 0.236 score 0.897 lr 3.6901e-05 
08/28/2020 09:49:33 - INFO - volta.utils -   [NLVR2]: iter 18155 Ep: 6.73 loss 0.279 score 0.891 lr 3.68804e-05 
08/28/2020 09:49:41 - INFO - volta.utils -   [NLVR2]: iter 18175 Ep: 6.73 loss 0.298 score 0.856 lr 3.68598e-05 
08/28/2020 09:49:50 - INFO - volta.utils -   [NLVR2]: iter 18195 Ep: 6.74 loss 0.270 score 0.887 lr 3.68393e-05 
08/28/2020 09:49:58 - INFO - volta.utils -   [NLVR2]: iter 18215 Ep: 6.75 loss 0.220 score 0.911 lr 3.68187e-05 
08/28/2020 09:50:19 - INFO - volta.utils -   [NLVR2]: iter 18235 Ep: 6.76 loss 0.250 score 0.894 lr 3.67981e-05 
08/28/2020 09:50:55 - INFO - volta.utils -   [NLVR2]: iter 18255 Ep: 6.76 loss 0.252 score 0.891 lr 3.67775e-05 
08/28/2020 09:51:11 - INFO - volta.utils -   [NLVR2]: iter 18275 Ep: 6.77 loss 0.250 score 0.873 lr 3.67569e-05 
08/28/2020 09:51:21 - INFO - volta.utils -   [NLVR2]: iter 18295 Ep: 6.78 loss 0.271 score 0.887 lr 3.67363e-05 
08/28/2020 09:51:29 - INFO - volta.utils -   [NLVR2]: iter 18315 Ep: 6.79 loss 0.253 score 0.892 lr 3.67158e-05 
08/28/2020 09:51:37 - INFO - volta.utils -   [NLVR2]: iter 18335 Ep: 6.79 loss 0.254 score 0.887 lr 3.66952e-05 
08/28/2020 09:52:02 - INFO - volta.utils -   [NLVR2]: iter 18355 Ep: 6.80 loss 0.233 score 0.887 lr 3.66746e-05 
08/28/2020 09:52:31 - INFO - volta.utils -   [NLVR2]: iter 18375 Ep: 6.81 loss 0.230 score 0.891 lr 3.6654e-05 
08/28/2020 09:52:51 - INFO - volta.utils -   [NLVR2]: iter 18395 Ep: 6.82 loss 0.232 score 0.912 lr 3.66334e-05 
08/28/2020 09:53:04 - INFO - volta.utils -   [NLVR2]: iter 18415 Ep: 6.82 loss 0.251 score 0.884 lr 3.66128e-05 
08/28/2020 09:53:17 - INFO - volta.utils -   [NLVR2]: iter 18435 Ep: 6.83 loss 0.298 score 0.883 lr 3.65923e-05 
08/28/2020 09:53:25 - INFO - volta.utils -   [NLVR2]: iter 18455 Ep: 6.84 loss 0.247 score 0.880 lr 3.65717e-05 
08/28/2020 09:54:03 - INFO - volta.utils -   [NLVR2]: iter 18475 Ep: 6.85 loss 0.294 score 0.863 lr 3.65511e-05 
08/28/2020 09:54:33 - INFO - volta.utils -   [NLVR2]: iter 18495 Ep: 6.85 loss 0.241 score 0.894 lr 3.65305e-05 
08/28/2020 09:54:46 - INFO - volta.utils -   [NLVR2]: iter 18515 Ep: 6.86 loss 0.251 score 0.894 lr 3.65099e-05 
08/28/2020 09:54:55 - INFO - volta.utils -   [NLVR2]: iter 18535 Ep: 6.87 loss 0.261 score 0.878 lr 3.64893e-05 
08/28/2020 09:55:03 - INFO - volta.utils -   [NLVR2]: iter 18555 Ep: 6.87 loss 0.263 score 0.878 lr 3.64688e-05 
08/28/2020 09:55:38 - INFO - volta.utils -   [NLVR2]: iter 18575 Ep: 6.88 loss 0.271 score 0.884 lr 3.64482e-05 
08/28/2020 09:56:09 - INFO - volta.utils -   [NLVR2]: iter 18595 Ep: 6.89 loss 0.263 score 0.889 lr 3.64276e-05 
08/28/2020 09:56:27 - INFO - volta.utils -   [NLVR2]: iter 18615 Ep: 6.90 loss 0.240 score 0.894 lr 3.6407e-05 
08/28/2020 09:56:37 - INFO - volta.utils -   [NLVR2]: iter 18635 Ep: 6.90 loss 0.255 score 0.900 lr 3.63864e-05 
08/28/2020 09:56:45 - INFO - volta.utils -   [NLVR2]: iter 18655 Ep: 6.91 loss 0.291 score 0.870 lr 3.63658e-05 
08/28/2020 09:56:53 - INFO - volta.utils -   [NLVR2]: iter 18675 Ep: 6.92 loss 0.294 score 0.867 lr 3.63453e-05 
08/28/2020 09:57:26 - INFO - volta.utils -   [NLVR2]: iter 18695 Ep: 6.93 loss 0.226 score 0.905 lr 3.63247e-05 
08/28/2020 09:57:53 - INFO - volta.utils -   [NLVR2]: iter 18715 Ep: 6.93 loss 0.270 score 0.884 lr 3.63041e-05 
08/28/2020 09:58:11 - INFO - volta.utils -   [NLVR2]: iter 18735 Ep: 6.94 loss 0.262 score 0.883 lr 3.62835e-05 
08/28/2020 09:58:19 - INFO - volta.utils -   [NLVR2]: iter 18755 Ep: 6.95 loss 0.260 score 0.897 lr 3.62629e-05 
08/28/2020 09:58:29 - INFO - volta.utils -   [NLVR2]: iter 18775 Ep: 6.96 loss 0.236 score 0.900 lr 3.62423e-05 
08/28/2020 09:58:42 - INFO - volta.utils -   [NLVR2]: iter 18795 Ep: 6.96 loss 0.234 score 0.895 lr 3.62217e-05 
08/28/2020 09:59:26 - INFO - volta.utils -   [NLVR2]: iter 18815 Ep: 6.97 loss 0.255 score 0.883 lr 3.62012e-05 
08/28/2020 09:59:36 - INFO - volta.utils -   [NLVR2]: iter 18835 Ep: 6.98 loss 0.273 score 0.886 lr 3.61806e-05 
08/28/2020 09:59:55 - INFO - volta.utils -   [NLVR2]: iter 18855 Ep: 6.99 loss 0.226 score 0.908 lr 3.616e-05 
08/28/2020 10:00:07 - INFO - volta.utils -   [NLVR2]: iter 18875 Ep: 6.99 loss 0.276 score 0.884 lr 3.61394e-05 
08/28/2020 10:00:13 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  35%|      | 7/20 [4:00:35<8:48:07, 2437.46s/it]08/28/2020 10:06:35 - INFO - volta.utils -   Eval task TASK12 on iteration 18894 
08/28/2020 10:06:35 - INFO - volta.utils -   Validation [NLVR2]: loss 0.859 score 69.409 
08/28/2020 10:06:43 - INFO - volta.utils -   [NLVR2]: iter 18914 Ep: 7.01 loss 0.187 score 0.920 lr 3.61091e-05 
08/28/2020 10:07:09 - INFO - volta.utils -   [NLVR2]: iter 18934 Ep: 7.02 loss 0.113 score 0.967 lr 3.60787e-05 
08/28/2020 10:07:44 - INFO - volta.utils -   [NLVR2]: iter 18954 Ep: 7.02 loss 0.131 score 0.945 lr 3.60581e-05 
08/28/2020 10:07:52 - INFO - volta.utils -   [NLVR2]: iter 18974 Ep: 7.03 loss 0.166 score 0.934 lr 3.60375e-05 
08/28/2020 10:08:03 - INFO - volta.utils -   [NLVR2]: iter 18994 Ep: 7.04 loss 0.122 score 0.947 lr 3.60169e-05 
08/28/2020 10:08:15 - INFO - volta.utils -   [NLVR2]: iter 19014 Ep: 7.04 loss 0.171 score 0.933 lr 3.59964e-05 
08/28/2020 10:08:24 - INFO - volta.utils -   [NLVR2]: iter 19034 Ep: 7.05 loss 0.170 score 0.933 lr 3.59758e-05 
08/28/2020 10:08:55 - INFO - volta.utils -   [NLVR2]: iter 19054 Ep: 7.06 loss 0.153 score 0.938 lr 3.59552e-05 
08/28/2020 10:09:15 - INFO - volta.utils -   [NLVR2]: iter 19074 Ep: 7.07 loss 0.164 score 0.930 lr 3.59346e-05 
08/28/2020 10:09:37 - INFO - volta.utils -   [NLVR2]: iter 19094 Ep: 7.07 loss 0.192 score 0.917 lr 3.5914e-05 
08/28/2020 10:09:53 - INFO - volta.utils -   [NLVR2]: iter 19114 Ep: 7.08 loss 0.152 score 0.941 lr 3.58934e-05 
08/28/2020 10:10:02 - INFO - volta.utils -   [NLVR2]: iter 19134 Ep: 7.09 loss 0.155 score 0.928 lr 3.58729e-05 
08/28/2020 10:10:10 - INFO - volta.utils -   [NLVR2]: iter 19154 Ep: 7.10 loss 0.214 score 0.919 lr 3.58523e-05 
08/28/2020 10:10:35 - INFO - volta.utils -   [NLVR2]: iter 19174 Ep: 7.10 loss 0.159 score 0.947 lr 3.58317e-05 
08/28/2020 10:11:13 - INFO - volta.utils -   [NLVR2]: iter 19194 Ep: 7.11 loss 0.166 score 0.947 lr 3.58111e-05 
08/28/2020 10:11:22 - INFO - volta.utils -   [NLVR2]: iter 19214 Ep: 7.12 loss 0.166 score 0.936 lr 3.57905e-05 
08/28/2020 10:11:35 - INFO - volta.utils -   [NLVR2]: iter 19234 Ep: 7.13 loss 0.189 score 0.938 lr 3.57699e-05 
08/28/2020 10:11:46 - INFO - volta.utils -   [NLVR2]: iter 19254 Ep: 7.13 loss 0.174 score 0.931 lr 3.57494e-05 
08/28/2020 10:12:09 - INFO - volta.utils -   [NLVR2]: iter 19274 Ep: 7.14 loss 0.156 score 0.939 lr 3.57288e-05 
08/28/2020 10:12:43 - INFO - volta.utils -   [NLVR2]: iter 19294 Ep: 7.15 loss 0.163 score 0.934 lr 3.57082e-05 
08/28/2020 10:13:00 - INFO - volta.utils -   [NLVR2]: iter 19314 Ep: 7.16 loss 0.161 score 0.925 lr 3.56876e-05 
08/28/2020 10:13:13 - INFO - volta.utils -   [NLVR2]: iter 19334 Ep: 7.16 loss 0.175 score 0.928 lr 3.5667e-05 
08/28/2020 10:13:25 - INFO - volta.utils -   [NLVR2]: iter 19354 Ep: 7.17 loss 0.148 score 0.931 lr 3.56464e-05 
08/28/2020 10:13:34 - INFO - volta.utils -   [NLVR2]: iter 19374 Ep: 7.18 loss 0.125 score 0.941 lr 3.56258e-05 
08/28/2020 10:13:59 - INFO - volta.utils -   [NLVR2]: iter 19394 Ep: 7.19 loss 0.190 score 0.922 lr 3.56053e-05 
08/28/2020 10:14:30 - INFO - volta.utils -   [NLVR2]: iter 19414 Ep: 7.19 loss 0.159 score 0.934 lr 3.55847e-05 
08/28/2020 10:14:46 - INFO - volta.utils -   [NLVR2]: iter 19434 Ep: 7.20 loss 0.179 score 0.936 lr 3.55641e-05 
08/28/2020 10:14:59 - INFO - volta.utils -   [NLVR2]: iter 19454 Ep: 7.21 loss 0.155 score 0.930 lr 3.55435e-05 
08/28/2020 10:15:09 - INFO - volta.utils -   [NLVR2]: iter 19474 Ep: 7.22 loss 0.138 score 0.948 lr 3.55229e-05 
08/28/2020 10:15:22 - INFO - volta.utils -   [NLVR2]: iter 19494 Ep: 7.22 loss 0.149 score 0.942 lr 3.55023e-05 
08/28/2020 10:16:11 - INFO - volta.utils -   [NLVR2]: iter 19514 Ep: 7.23 loss 0.153 score 0.931 lr 3.54818e-05 
08/28/2020 10:16:28 - INFO - volta.utils -   [NLVR2]: iter 19534 Ep: 7.24 loss 0.199 score 0.923 lr 3.54612e-05 
08/28/2020 10:16:36 - INFO - volta.utils -   [NLVR2]: iter 19554 Ep: 7.24 loss 0.195 score 0.927 lr 3.54406e-05 
08/28/2020 10:16:46 - INFO - volta.utils -   [NLVR2]: iter 19574 Ep: 7.25 loss 0.167 score 0.934 lr 3.542e-05 
08/28/2020 10:16:54 - INFO - volta.utils -   [NLVR2]: iter 19594 Ep: 7.26 loss 0.203 score 0.919 lr 3.53994e-05 
08/28/2020 10:17:12 - INFO - volta.utils -   [NLVR2]: iter 19614 Ep: 7.27 loss 0.127 score 0.948 lr 3.53788e-05 
08/28/2020 10:17:49 - INFO - volta.utils -   [NLVR2]: iter 19634 Ep: 7.27 loss 0.156 score 0.941 lr 3.53583e-05 
08/28/2020 10:18:02 - INFO - volta.utils -   [NLVR2]: iter 19654 Ep: 7.28 loss 0.171 score 0.931 lr 3.53377e-05 
08/28/2020 10:18:14 - INFO - volta.utils -   [NLVR2]: iter 19674 Ep: 7.29 loss 0.165 score 0.927 lr 3.53171e-05 
08/28/2020 10:18:32 - INFO - volta.utils -   [NLVR2]: iter 19694 Ep: 7.30 loss 0.186 score 0.933 lr 3.52965e-05 
08/28/2020 10:18:40 - INFO - volta.utils -   [NLVR2]: iter 19714 Ep: 7.30 loss 0.150 score 0.933 lr 3.52759e-05 
08/28/2020 10:18:59 - INFO - volta.utils -   [NLVR2]: iter 19734 Ep: 7.31 loss 0.179 score 0.934 lr 3.52553e-05 
08/28/2020 10:19:33 - INFO - volta.utils -   [NLVR2]: iter 19754 Ep: 7.32 loss 0.194 score 0.936 lr 3.52348e-05 
08/28/2020 10:19:51 - INFO - volta.utils -   [NLVR2]: iter 19774 Ep: 7.33 loss 0.177 score 0.936 lr 3.52142e-05 
08/28/2020 10:20:01 - INFO - volta.utils -   [NLVR2]: iter 19794 Ep: 7.33 loss 0.160 score 0.934 lr 3.51936e-05 
08/28/2020 10:20:09 - INFO - volta.utils -   [NLVR2]: iter 19814 Ep: 7.34 loss 0.166 score 0.931 lr 3.5173e-05 
08/28/2020 10:20:18 - INFO - volta.utils -   [NLVR2]: iter 19834 Ep: 7.35 loss 0.176 score 0.927 lr 3.51524e-05 
08/28/2020 10:20:27 - INFO - volta.utils -   [NLVR2]: iter 19854 Ep: 7.36 loss 0.160 score 0.931 lr 3.51318e-05 
08/28/2020 10:21:02 - INFO - volta.utils -   [NLVR2]: iter 19874 Ep: 7.36 loss 0.212 score 0.914 lr 3.51113e-05 
08/28/2020 10:21:37 - INFO - volta.utils -   [NLVR2]: iter 19894 Ep: 7.37 loss 0.172 score 0.933 lr 3.50907e-05 
08/28/2020 10:21:48 - INFO - volta.utils -   [NLVR2]: iter 19914 Ep: 7.38 loss 0.176 score 0.930 lr 3.50701e-05 
08/28/2020 10:22:00 - INFO - volta.utils -   [NLVR2]: iter 19934 Ep: 7.39 loss 0.206 score 0.909 lr 3.50495e-05 
08/28/2020 10:22:08 - INFO - volta.utils -   [NLVR2]: iter 19954 Ep: 7.39 loss 0.250 score 0.880 lr 3.50289e-05 
08/28/2020 10:22:16 - INFO - volta.utils -   [NLVR2]: iter 19974 Ep: 7.40 loss 0.239 score 0.881 lr 3.50083e-05 
08/28/2020 10:23:02 - INFO - volta.utils -   [NLVR2]: iter 19994 Ep: 7.41 loss 0.232 score 0.880 lr 3.49878e-05 
08/28/2020 10:23:26 - INFO - volta.utils -   [NLVR2]: iter 20014 Ep: 7.42 loss 0.237 score 0.887 lr 3.49672e-05 
08/28/2020 10:23:39 - INFO - volta.utils -   [NLVR2]: iter 20034 Ep: 7.42 loss 0.234 score 0.900 lr 3.49466e-05 
08/28/2020 10:23:47 - INFO - volta.utils -   [NLVR2]: iter 20054 Ep: 7.43 loss 0.220 score 0.903 lr 3.4926e-05 
08/28/2020 10:23:56 - INFO - volta.utils -   [NLVR2]: iter 20074 Ep: 7.44 loss 0.246 score 0.884 lr 3.49054e-05 
08/28/2020 10:24:04 - INFO - volta.utils -   [NLVR2]: iter 20094 Ep: 7.44 loss 0.191 score 0.917 lr 3.48848e-05 
08/28/2020 10:24:37 - INFO - volta.utils -   [NLVR2]: iter 20114 Ep: 7.45 loss 0.198 score 0.908 lr 3.48643e-05 
08/28/2020 10:25:20 - INFO - volta.utils -   [NLVR2]: iter 20134 Ep: 7.46 loss 0.201 score 0.914 lr 3.48437e-05 
08/28/2020 10:25:29 - INFO - volta.utils -   [NLVR2]: iter 20154 Ep: 7.47 loss 0.260 score 0.903 lr 3.48231e-05 
08/28/2020 10:25:37 - INFO - volta.utils -   [NLVR2]: iter 20174 Ep: 7.47 loss 0.197 score 0.911 lr 3.48025e-05 
08/28/2020 10:25:47 - INFO - volta.utils -   [NLVR2]: iter 20194 Ep: 7.48 loss 0.190 score 0.916 lr 3.47819e-05 
08/28/2020 10:26:41 - INFO - volta.utils -   [NLVR2]: iter 20214 Ep: 7.49 loss 0.215 score 0.906 lr 3.47613e-05 
08/28/2020 10:27:03 - INFO - volta.utils -   [NLVR2]: iter 20234 Ep: 7.50 loss 0.203 score 0.903 lr 3.47407e-05 
08/28/2020 10:27:12 - INFO - volta.utils -   [NLVR2]: iter 20254 Ep: 7.50 loss 0.238 score 0.887 lr 3.47202e-05 
08/28/2020 10:27:21 - INFO - volta.utils -   [NLVR2]: iter 20274 Ep: 7.51 loss 0.252 score 0.881 lr 3.46996e-05 
08/28/2020 10:27:37 - INFO - volta.utils -   [NLVR2]: iter 20294 Ep: 7.52 loss 0.190 score 0.906 lr 3.4679e-05 
08/28/2020 10:28:06 - INFO - volta.utils -   [NLVR2]: iter 20314 Ep: 7.53 loss 0.225 score 0.895 lr 3.46584e-05 
08/28/2020 10:28:40 - INFO - volta.utils -   [NLVR2]: iter 20334 Ep: 7.53 loss 0.227 score 0.902 lr 3.46378e-05 
08/28/2020 10:28:50 - INFO - volta.utils -   [NLVR2]: iter 20354 Ep: 7.54 loss 0.248 score 0.872 lr 3.46172e-05 
08/28/2020 10:29:02 - INFO - volta.utils -   [NLVR2]: iter 20374 Ep: 7.55 loss 0.221 score 0.903 lr 3.45967e-05 
08/28/2020 10:29:10 - INFO - volta.utils -   [NLVR2]: iter 20394 Ep: 7.56 loss 0.210 score 0.908 lr 3.45761e-05 
08/28/2020 10:29:56 - INFO - volta.utils -   [NLVR2]: iter 20414 Ep: 7.56 loss 0.267 score 0.864 lr 3.45555e-05 
08/28/2020 10:30:25 - INFO - volta.utils -   [NLVR2]: iter 20434 Ep: 7.57 loss 0.212 score 0.903 lr 3.45349e-05 
08/28/2020 10:30:33 - INFO - volta.utils -   [NLVR2]: iter 20454 Ep: 7.58 loss 0.260 score 0.887 lr 3.45143e-05 
08/28/2020 10:30:41 - INFO - volta.utils -   [NLVR2]: iter 20474 Ep: 7.59 loss 0.216 score 0.897 lr 3.44937e-05 
08/28/2020 10:31:13 - INFO - volta.utils -   [NLVR2]: iter 20494 Ep: 7.59 loss 0.263 score 0.877 lr 3.44732e-05 
08/28/2020 10:31:44 - INFO - volta.utils -   [NLVR2]: iter 20514 Ep: 7.60 loss 0.191 score 0.927 lr 3.44526e-05 
08/28/2020 10:31:56 - INFO - volta.utils -   [NLVR2]: iter 20534 Ep: 7.61 loss 0.229 score 0.894 lr 3.4432e-05 
08/28/2020 10:32:15 - INFO - volta.utils -   [NLVR2]: iter 20554 Ep: 7.62 loss 0.257 score 0.881 lr 3.44114e-05 
08/28/2020 10:32:23 - INFO - volta.utils -   [NLVR2]: iter 20574 Ep: 7.62 loss 0.218 score 0.906 lr 3.43908e-05 
08/28/2020 10:32:32 - INFO - volta.utils -   [NLVR2]: iter 20594 Ep: 7.63 loss 0.224 score 0.911 lr 3.43702e-05 
08/28/2020 10:33:07 - INFO - volta.utils -   [NLVR2]: iter 20614 Ep: 7.64 loss 0.229 score 0.872 lr 3.43497e-05 
08/28/2020 10:33:46 - INFO - volta.utils -   [NLVR2]: iter 20634 Ep: 7.65 loss 0.215 score 0.902 lr 3.43291e-05 
08/28/2020 10:34:01 - INFO - volta.utils -   [NLVR2]: iter 20654 Ep: 7.65 loss 0.253 score 0.881 lr 3.43085e-05 
08/28/2020 10:34:10 - INFO - volta.utils -   [NLVR2]: iter 20674 Ep: 7.66 loss 0.224 score 0.897 lr 3.42879e-05 
08/28/2020 10:34:18 - INFO - volta.utils -   [NLVR2]: iter 20694 Ep: 7.67 loss 0.233 score 0.881 lr 3.42673e-05 
08/28/2020 10:35:00 - INFO - volta.utils -   [NLVR2]: iter 20714 Ep: 7.67 loss 0.229 score 0.894 lr 3.42467e-05 
08/28/2020 10:35:22 - INFO - volta.utils -   [NLVR2]: iter 20734 Ep: 7.68 loss 0.182 score 0.925 lr 3.42262e-05 
08/28/2020 10:35:34 - INFO - volta.utils -   [NLVR2]: iter 20754 Ep: 7.69 loss 0.228 score 0.895 lr 3.42056e-05 
08/28/2020 10:35:46 - INFO - volta.utils -   [NLVR2]: iter 20774 Ep: 7.70 loss 0.215 score 0.894 lr 3.4185e-05 
08/28/2020 10:36:00 - INFO - volta.utils -   [NLVR2]: iter 20794 Ep: 7.70 loss 0.238 score 0.897 lr 3.41644e-05 
08/28/2020 10:36:08 - INFO - volta.utils -   [NLVR2]: iter 20814 Ep: 7.71 loss 0.240 score 0.892 lr 3.41438e-05 
08/28/2020 10:36:50 - INFO - volta.utils -   [NLVR2]: iter 20834 Ep: 7.72 loss 0.223 score 0.900 lr 3.41232e-05 
08/28/2020 10:37:23 - INFO - volta.utils -   [NLVR2]: iter 20854 Ep: 7.73 loss 0.206 score 0.898 lr 3.41027e-05 
08/28/2020 10:37:31 - INFO - volta.utils -   [NLVR2]: iter 20874 Ep: 7.73 loss 0.239 score 0.906 lr 3.40821e-05 
08/28/2020 10:37:41 - INFO - volta.utils -   [NLVR2]: iter 20894 Ep: 7.74 loss 0.245 score 0.902 lr 3.40615e-05 
08/28/2020 10:37:51 - INFO - volta.utils -   [NLVR2]: iter 20914 Ep: 7.75 loss 0.244 score 0.873 lr 3.40409e-05 
08/28/2020 10:38:08 - INFO - volta.utils -   [NLVR2]: iter 20934 Ep: 7.76 loss 0.276 score 0.867 lr 3.40203e-05 
08/28/2020 10:38:55 - INFO - volta.utils -   [NLVR2]: iter 20954 Ep: 7.76 loss 0.241 score 0.898 lr 3.39997e-05 
08/28/2020 10:39:08 - INFO - volta.utils -   [NLVR2]: iter 20974 Ep: 7.77 loss 0.231 score 0.906 lr 3.39791e-05 
08/28/2020 10:39:18 - INFO - volta.utils -   [NLVR2]: iter 20994 Ep: 7.78 loss 0.215 score 0.906 lr 3.39586e-05 
08/28/2020 10:39:28 - INFO - volta.utils -   [NLVR2]: iter 21014 Ep: 7.79 loss 0.246 score 0.884 lr 3.3938e-05 
08/28/2020 10:39:43 - INFO - volta.utils -   [NLVR2]: iter 21034 Ep: 7.79 loss 0.256 score 0.884 lr 3.39174e-05 
08/28/2020 10:40:18 - INFO - volta.utils -   [NLVR2]: iter 21054 Ep: 7.80 loss 0.244 score 0.894 lr 3.38968e-05 
08/28/2020 10:40:45 - INFO - volta.utils -   [NLVR2]: iter 21074 Ep: 7.81 loss 0.246 score 0.881 lr 3.38762e-05 
08/28/2020 10:40:56 - INFO - volta.utils -   [NLVR2]: iter 21094 Ep: 7.82 loss 0.203 score 0.911 lr 3.38556e-05 
08/28/2020 10:41:05 - INFO - volta.utils -   [NLVR2]: iter 21114 Ep: 7.82 loss 0.223 score 0.900 lr 3.38351e-05 
08/28/2020 10:41:13 - INFO - volta.utils -   [NLVR2]: iter 21134 Ep: 7.83 loss 0.256 score 0.881 lr 3.38145e-05 
08/28/2020 10:41:21 - INFO - volta.utils -   [NLVR2]: iter 21154 Ep: 7.84 loss 0.249 score 0.897 lr 3.37939e-05 
08/28/2020 10:41:41 - INFO - volta.utils -   [NLVR2]: iter 21174 Ep: 7.85 loss 0.242 score 0.877 lr 3.37733e-05 
08/28/2020 10:42:21 - INFO - volta.utils -   [NLVR2]: iter 21194 Ep: 7.85 loss 0.218 score 0.889 lr 3.37527e-05 
08/28/2020 10:42:35 - INFO - volta.utils -   [NLVR2]: iter 21214 Ep: 7.86 loss 0.273 score 0.856 lr 3.37321e-05 
08/28/2020 10:42:50 - INFO - volta.utils -   [NLVR2]: iter 21234 Ep: 7.87 loss 0.246 score 0.891 lr 3.37116e-05 
08/28/2020 10:42:59 - INFO - volta.utils -   [NLVR2]: iter 21254 Ep: 7.87 loss 0.249 score 0.900 lr 3.3691e-05 
08/28/2020 10:43:07 - INFO - volta.utils -   [NLVR2]: iter 21274 Ep: 7.88 loss 0.257 score 0.878 lr 3.36704e-05 
08/28/2020 10:43:38 - INFO - volta.utils -   [NLVR2]: iter 21294 Ep: 7.89 loss 0.282 score 0.883 lr 3.36498e-05 
08/28/2020 10:44:07 - INFO - volta.utils -   [NLVR2]: iter 21314 Ep: 7.90 loss 0.221 score 0.906 lr 3.36292e-05 
08/28/2020 10:44:26 - INFO - volta.utils -   [NLVR2]: iter 21334 Ep: 7.90 loss 0.217 score 0.891 lr 3.36086e-05 
08/28/2020 10:44:36 - INFO - volta.utils -   [NLVR2]: iter 21354 Ep: 7.91 loss 0.256 score 0.886 lr 3.35881e-05 
08/28/2020 10:44:45 - INFO - volta.utils -   [NLVR2]: iter 21374 Ep: 7.92 loss 0.229 score 0.891 lr 3.35675e-05 
08/28/2020 10:44:53 - INFO - volta.utils -   [NLVR2]: iter 21394 Ep: 7.93 loss 0.248 score 0.883 lr 3.35469e-05 
08/28/2020 10:45:32 - INFO - volta.utils -   [NLVR2]: iter 21414 Ep: 7.93 loss 0.246 score 0.884 lr 3.35263e-05 
08/28/2020 10:46:03 - INFO - volta.utils -   [NLVR2]: iter 21434 Ep: 7.94 loss 0.222 score 0.895 lr 3.35057e-05 
08/28/2020 10:46:17 - INFO - volta.utils -   [NLVR2]: iter 21454 Ep: 7.95 loss 0.249 score 0.873 lr 3.34851e-05 
08/28/2020 10:46:25 - INFO - volta.utils -   [NLVR2]: iter 21474 Ep: 7.96 loss 0.205 score 0.911 lr 3.34646e-05 
08/28/2020 10:46:34 - INFO - volta.utils -   [NLVR2]: iter 21494 Ep: 7.96 loss 0.222 score 0.891 lr 3.3444e-05 
08/28/2020 10:46:45 - INFO - volta.utils -   [NLVR2]: iter 21514 Ep: 7.97 loss 0.248 score 0.884 lr 3.34234e-05 
08/28/2020 10:47:39 - INFO - volta.utils -   [NLVR2]: iter 21534 Ep: 7.98 loss 0.227 score 0.902 lr 3.34028e-05 
08/28/2020 10:48:01 - INFO - volta.utils -   [NLVR2]: iter 21554 Ep: 7.99 loss 0.247 score 0.894 lr 3.33822e-05 
08/28/2020 10:48:09 - INFO - volta.utils -   [NLVR2]: iter 21574 Ep: 7.99 loss 0.245 score 0.880 lr 3.33616e-05 
08/28/2020 10:48:16 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  40%|      | 8/20 [4:48:38<8:34:13, 2571.08s/it]08/28/2020 10:55:49 - INFO - volta.utils -   Eval task TASK12 on iteration 21593 
08/28/2020 10:55:49 - INFO - volta.utils -   Validation [NLVR2]: loss 0.878 score 68.005 
08/28/2020 10:55:58 - INFO - volta.utils -   [NLVR2]: iter 21613 Ep: 8.01 loss 0.194 score 0.910 lr 3.33313e-05 
08/28/2020 10:56:06 - INFO - volta.utils -   [NLVR2]: iter 21633 Ep: 8.02 loss 0.153 score 0.931 lr 3.33009e-05 
08/28/2020 10:56:14 - INFO - volta.utils -   [NLVR2]: iter 21653 Ep: 8.02 loss 0.162 score 0.931 lr 3.32803e-05 
08/28/2020 10:56:25 - INFO - volta.utils -   [NLVR2]: iter 21673 Ep: 8.03 loss 0.135 score 0.947 lr 3.32597e-05 
08/28/2020 10:57:19 - INFO - volta.utils -   [NLVR2]: iter 21693 Ep: 8.04 loss 0.156 score 0.934 lr 3.32392e-05 
08/28/2020 10:57:31 - INFO - volta.utils -   [NLVR2]: iter 21713 Ep: 8.04 loss 0.151 score 0.941 lr 3.32186e-05 
08/28/2020 10:57:42 - INFO - volta.utils -   [NLVR2]: iter 21733 Ep: 8.05 loss 0.132 score 0.952 lr 3.3198e-05 
08/28/2020 10:58:00 - INFO - volta.utils -   [NLVR2]: iter 21753 Ep: 8.06 loss 0.168 score 0.931 lr 3.31774e-05 
08/28/2020 10:58:31 - INFO - volta.utils -   [NLVR2]: iter 21773 Ep: 8.07 loss 0.178 score 0.928 lr 3.31568e-05 
08/28/2020 10:58:54 - INFO - volta.utils -   [NLVR2]: iter 21793 Ep: 8.07 loss 0.153 score 0.939 lr 3.31362e-05 
08/28/2020 10:59:16 - INFO - volta.utils -   [NLVR2]: iter 21813 Ep: 8.08 loss 0.151 score 0.944 lr 3.31157e-05 
08/28/2020 10:59:31 - INFO - volta.utils -   [NLVR2]: iter 21833 Ep: 8.09 loss 0.166 score 0.933 lr 3.30951e-05 
08/28/2020 10:59:40 - INFO - volta.utils -   [NLVR2]: iter 21853 Ep: 8.10 loss 0.155 score 0.938 lr 3.30745e-05 
08/28/2020 10:59:48 - INFO - volta.utils -   [NLVR2]: iter 21873 Ep: 8.10 loss 0.191 score 0.919 lr 3.30539e-05 
08/28/2020 11:00:44 - INFO - volta.utils -   [NLVR2]: iter 21893 Ep: 8.11 loss 0.153 score 0.944 lr 3.30333e-05 
08/28/2020 11:01:00 - INFO - volta.utils -   [NLVR2]: iter 21913 Ep: 8.12 loss 0.192 score 0.922 lr 3.30127e-05 
08/28/2020 11:01:10 - INFO - volta.utils -   [NLVR2]: iter 21933 Ep: 8.13 loss 0.134 score 0.939 lr 3.29922e-05 
08/28/2020 11:01:21 - INFO - volta.utils -   [NLVR2]: iter 21953 Ep: 8.13 loss 0.138 score 0.939 lr 3.29716e-05 
08/28/2020 11:01:29 - INFO - volta.utils -   [NLVR2]: iter 21973 Ep: 8.14 loss 0.191 score 0.914 lr 3.2951e-05 
08/28/2020 11:02:00 - INFO - volta.utils -   [NLVR2]: iter 21993 Ep: 8.15 loss 0.168 score 0.928 lr 3.29304e-05 
08/28/2020 11:02:37 - INFO - volta.utils -   [NLVR2]: iter 22013 Ep: 8.16 loss 0.145 score 0.938 lr 3.29098e-05 
08/28/2020 11:02:53 - INFO - volta.utils -   [NLVR2]: iter 22033 Ep: 8.16 loss 0.205 score 0.911 lr 3.28892e-05 
08/28/2020 11:03:01 - INFO - volta.utils -   [NLVR2]: iter 22053 Ep: 8.17 loss 0.133 score 0.942 lr 3.28687e-05 
08/28/2020 11:03:11 - INFO - volta.utils -   [NLVR2]: iter 22073 Ep: 8.18 loss 0.166 score 0.923 lr 3.28481e-05 
08/28/2020 11:03:21 - INFO - volta.utils -   [NLVR2]: iter 22093 Ep: 8.19 loss 0.172 score 0.934 lr 3.28275e-05 
08/28/2020 11:04:02 - INFO - volta.utils -   [NLVR2]: iter 22113 Ep: 8.19 loss 0.165 score 0.939 lr 3.28069e-05 
08/28/2020 11:04:21 - INFO - volta.utils -   [NLVR2]: iter 22133 Ep: 8.20 loss 0.183 score 0.931 lr 3.27863e-05 
08/28/2020 11:04:37 - INFO - volta.utils -   [NLVR2]: iter 22153 Ep: 8.21 loss 0.140 score 0.944 lr 3.27657e-05 
08/28/2020 11:04:49 - INFO - volta.utils -   [NLVR2]: iter 22173 Ep: 8.22 loss 0.158 score 0.934 lr 3.27452e-05 
08/28/2020 11:04:57 - INFO - volta.utils -   [NLVR2]: iter 22193 Ep: 8.22 loss 0.150 score 0.941 lr 3.27246e-05 
08/28/2020 11:05:05 - INFO - volta.utils -   [NLVR2]: iter 22213 Ep: 8.23 loss 0.165 score 0.939 lr 3.2704e-05 
08/28/2020 11:05:39 - INFO - volta.utils -   [NLVR2]: iter 22233 Ep: 8.24 loss 0.159 score 0.934 lr 3.26834e-05 
08/28/2020 11:06:02 - INFO - volta.utils -   [NLVR2]: iter 22253 Ep: 8.24 loss 0.189 score 0.922 lr 3.26628e-05 
08/28/2020 11:06:18 - INFO - volta.utils -   [NLVR2]: iter 22273 Ep: 8.25 loss 0.177 score 0.917 lr 3.26422e-05 
08/28/2020 11:06:30 - INFO - volta.utils -   [NLVR2]: iter 22293 Ep: 8.26 loss 0.155 score 0.931 lr 3.26216e-05 
08/28/2020 11:06:38 - INFO - volta.utils -   [NLVR2]: iter 22313 Ep: 8.27 loss 0.169 score 0.922 lr 3.26011e-05 
08/28/2020 11:06:46 - INFO - volta.utils -   [NLVR2]: iter 22333 Ep: 8.27 loss 0.161 score 0.923 lr 3.25805e-05 
08/28/2020 11:07:24 - INFO - volta.utils -   [NLVR2]: iter 22353 Ep: 8.28 loss 0.168 score 0.934 lr 3.25599e-05 
08/28/2020 11:07:51 - INFO - volta.utils -   [NLVR2]: iter 22373 Ep: 8.29 loss 0.164 score 0.938 lr 3.25393e-05 
08/28/2020 11:08:07 - INFO - volta.utils -   [NLVR2]: iter 22393 Ep: 8.30 loss 0.154 score 0.933 lr 3.25187e-05 
08/28/2020 11:08:21 - INFO - volta.utils -   [NLVR2]: iter 22413 Ep: 8.30 loss 0.136 score 0.934 lr 3.24981e-05 
08/28/2020 11:08:33 - INFO - volta.utils -   [NLVR2]: iter 22433 Ep: 8.31 loss 0.150 score 0.939 lr 3.24776e-05 
08/28/2020 11:08:56 - INFO - volta.utils -   [NLVR2]: iter 22453 Ep: 8.32 loss 0.198 score 0.912 lr 3.2457e-05 
08/28/2020 11:09:25 - INFO - volta.utils -   [NLVR2]: iter 22473 Ep: 8.33 loss 0.160 score 0.920 lr 3.24364e-05 
08/28/2020 11:09:47 - INFO - volta.utils -   [NLVR2]: iter 22493 Ep: 8.33 loss 0.131 score 0.939 lr 3.24158e-05 
08/28/2020 11:10:01 - INFO - volta.utils -   [NLVR2]: iter 22513 Ep: 8.34 loss 0.218 score 0.916 lr 3.23952e-05 
08/28/2020 11:10:17 - INFO - volta.utils -   [NLVR2]: iter 22533 Ep: 8.35 loss 0.188 score 0.920 lr 3.23746e-05 
08/28/2020 11:10:47 - INFO - volta.utils -   [NLVR2]: iter 22553 Ep: 8.36 loss 0.204 score 0.919 lr 3.23541e-05 
08/28/2020 11:11:12 - INFO - volta.utils -   [NLVR2]: iter 22573 Ep: 8.36 loss 0.182 score 0.917 lr 3.23335e-05 
08/28/2020 11:11:34 - INFO - volta.utils -   [NLVR2]: iter 22593 Ep: 8.37 loss 0.172 score 0.916 lr 3.23129e-05 
08/28/2020 11:11:44 - INFO - volta.utils -   [NLVR2]: iter 22613 Ep: 8.38 loss 0.171 score 0.933 lr 3.22923e-05 
08/28/2020 11:11:53 - INFO - volta.utils -   [NLVR2]: iter 22633 Ep: 8.39 loss 0.165 score 0.931 lr 3.22717e-05 
08/28/2020 11:12:01 - INFO - volta.utils -   [NLVR2]: iter 22653 Ep: 8.39 loss 0.158 score 0.922 lr 3.22511e-05 
08/28/2020 11:12:30 - INFO - volta.utils -   [NLVR2]: iter 22673 Ep: 8.40 loss 0.195 score 0.912 lr 3.22306e-05 
08/28/2020 11:13:02 - INFO - volta.utils -   [NLVR2]: iter 22693 Ep: 8.41 loss 0.164 score 0.920 lr 3.221e-05 
08/28/2020 11:13:14 - INFO - volta.utils -   [NLVR2]: iter 22713 Ep: 8.42 loss 0.132 score 0.948 lr 3.21894e-05 
08/28/2020 11:13:25 - INFO - volta.utils -   [NLVR2]: iter 22733 Ep: 8.42 loss 0.163 score 0.931 lr 3.21688e-05 
08/28/2020 11:13:33 - INFO - volta.utils -   [NLVR2]: iter 22753 Ep: 8.43 loss 0.187 score 0.927 lr 3.21482e-05 
08/28/2020 11:13:41 - INFO - volta.utils -   [NLVR2]: iter 22773 Ep: 8.44 loss 0.150 score 0.930 lr 3.21276e-05 
08/28/2020 11:13:49 - INFO - volta.utils -   [NLVR2]: iter 22793 Ep: 8.44 loss 0.182 score 0.911 lr 3.21071e-05 
08/28/2020 11:14:39 - INFO - volta.utils -   [NLVR2]: iter 22813 Ep: 8.45 loss 0.181 score 0.917 lr 3.20865e-05 
08/28/2020 11:14:58 - INFO - volta.utils -   [NLVR2]: iter 22833 Ep: 8.46 loss 0.177 score 0.920 lr 3.20659e-05 
08/28/2020 11:15:10 - INFO - volta.utils -   [NLVR2]: iter 22853 Ep: 8.47 loss 0.161 score 0.931 lr 3.20453e-05 
08/28/2020 11:15:18 - INFO - volta.utils -   [NLVR2]: iter 22873 Ep: 8.47 loss 0.188 score 0.928 lr 3.20247e-05 
08/28/2020 11:15:26 - INFO - volta.utils -   [NLVR2]: iter 22893 Ep: 8.48 loss 0.174 score 0.920 lr 3.20041e-05 
08/28/2020 11:15:34 - INFO - volta.utils -   [NLVR2]: iter 22913 Ep: 8.49 loss 0.172 score 0.920 lr 3.19836e-05 
08/28/2020 11:15:49 - INFO - volta.utils -   [NLVR2]: iter 22933 Ep: 8.50 loss 0.181 score 0.914 lr 3.1963e-05 
08/28/2020 11:16:26 - INFO - volta.utils -   [NLVR2]: iter 22953 Ep: 8.50 loss 0.168 score 0.936 lr 3.19424e-05 
08/28/2020 11:16:51 - INFO - volta.utils -   [NLVR2]: iter 22973 Ep: 8.51 loss 0.209 score 0.923 lr 3.19218e-05 
08/28/2020 11:17:05 - INFO - volta.utils -   [NLVR2]: iter 22993 Ep: 8.52 loss 0.164 score 0.920 lr 3.19012e-05 
08/28/2020 11:17:17 - INFO - volta.utils -   [NLVR2]: iter 23013 Ep: 8.53 loss 0.175 score 0.922 lr 3.18806e-05 
08/28/2020 11:17:40 - INFO - volta.utils -   [NLVR2]: iter 23033 Ep: 8.53 loss 0.183 score 0.928 lr 3.18601e-05 
08/28/2020 11:18:16 - INFO - volta.utils -   [NLVR2]: iter 23053 Ep: 8.54 loss 0.167 score 0.927 lr 3.18395e-05 
08/28/2020 11:18:36 - INFO - volta.utils -   [NLVR2]: iter 23073 Ep: 8.55 loss 0.220 score 0.903 lr 3.18189e-05 
08/28/2020 11:18:43 - INFO - volta.utils -   [NLVR2]: iter 23093 Ep: 8.56 loss 0.164 score 0.923 lr 3.17983e-05 
08/28/2020 11:18:55 - INFO - volta.utils -   [NLVR2]: iter 23113 Ep: 8.56 loss 0.171 score 0.927 lr 3.17777e-05 
08/28/2020 11:19:42 - INFO - volta.utils -   [NLVR2]: iter 23133 Ep: 8.57 loss 0.175 score 0.909 lr 3.17571e-05 
08/28/2020 11:20:09 - INFO - volta.utils -   [NLVR2]: iter 23153 Ep: 8.58 loss 0.159 score 0.928 lr 3.17365e-05 
08/28/2020 11:20:23 - INFO - volta.utils -   [NLVR2]: iter 23173 Ep: 8.59 loss 0.173 score 0.920 lr 3.1716e-05 
08/28/2020 11:20:36 - INFO - volta.utils -   [NLVR2]: iter 23193 Ep: 8.59 loss 0.163 score 0.933 lr 3.16954e-05 
08/28/2020 11:20:44 - INFO - volta.utils -   [NLVR2]: iter 23213 Ep: 8.60 loss 0.159 score 0.927 lr 3.16748e-05 
08/28/2020 11:21:51 - INFO - volta.utils -   [NLVR2]: iter 23233 Ep: 8.61 loss 0.213 score 0.927 lr 3.16542e-05 
08/28/2020 11:22:08 - INFO - volta.utils -   [NLVR2]: iter 23253 Ep: 8.62 loss 0.181 score 0.933 lr 3.16336e-05 
08/28/2020 11:22:18 - INFO - volta.utils -   [NLVR2]: iter 23273 Ep: 8.62 loss 0.200 score 0.927 lr 3.1613e-05 
08/28/2020 11:22:27 - INFO - volta.utils -   [NLVR2]: iter 23293 Ep: 8.63 loss 0.175 score 0.930 lr 3.15925e-05 
08/28/2020 11:23:20 - INFO - volta.utils -   [NLVR2]: iter 23313 Ep: 8.64 loss 0.189 score 0.933 lr 3.15719e-05 
08/28/2020 11:23:41 - INFO - volta.utils -   [NLVR2]: iter 23333 Ep: 8.65 loss 0.209 score 0.911 lr 3.15513e-05 
08/28/2020 11:24:02 - INFO - volta.utils -   [NLVR2]: iter 23353 Ep: 8.65 loss 0.190 score 0.916 lr 3.15307e-05 
08/28/2020 11:24:10 - INFO - volta.utils -   [NLVR2]: iter 23373 Ep: 8.66 loss 0.162 score 0.928 lr 3.15101e-05 
08/28/2020 11:24:32 - INFO - volta.utils -   [NLVR2]: iter 23393 Ep: 8.67 loss 0.179 score 0.922 lr 3.14895e-05 
08/28/2020 11:25:19 - INFO - volta.utils -   [NLVR2]: iter 23413 Ep: 8.67 loss 0.191 score 0.912 lr 3.1469e-05 
08/28/2020 11:25:33 - INFO - volta.utils -   [NLVR2]: iter 23433 Ep: 8.68 loss 0.183 score 0.925 lr 3.14484e-05 
08/28/2020 11:25:47 - INFO - volta.utils -   [NLVR2]: iter 23453 Ep: 8.69 loss 0.195 score 0.905 lr 3.14278e-05 
08/28/2020 11:25:54 - INFO - volta.utils -   [NLVR2]: iter 23473 Ep: 8.70 loss 0.188 score 0.917 lr 3.14072e-05 
08/28/2020 11:26:26 - INFO - volta.utils -   [NLVR2]: iter 23493 Ep: 8.70 loss 0.215 score 0.903 lr 3.13866e-05 
08/28/2020 11:27:00 - INFO - volta.utils -   [NLVR2]: iter 23513 Ep: 8.71 loss 0.204 score 0.909 lr 3.1366e-05 
08/28/2020 11:27:17 - INFO - volta.utils -   [NLVR2]: iter 23533 Ep: 8.72 loss 0.177 score 0.922 lr 3.13455e-05 
08/28/2020 11:27:26 - INFO - volta.utils -   [NLVR2]: iter 23553 Ep: 8.73 loss 0.191 score 0.923 lr 3.13249e-05 
08/28/2020 11:27:35 - INFO - volta.utils -   [NLVR2]: iter 23573 Ep: 8.73 loss 0.193 score 0.922 lr 3.13043e-05 
08/28/2020 11:27:44 - INFO - volta.utils -   [NLVR2]: iter 23593 Ep: 8.74 loss 0.202 score 0.917 lr 3.12837e-05 
08/28/2020 11:28:47 - INFO - volta.utils -   [NLVR2]: iter 23613 Ep: 8.75 loss 0.171 score 0.927 lr 3.12631e-05 
08/28/2020 11:29:00 - INFO - volta.utils -   [NLVR2]: iter 23633 Ep: 8.76 loss 0.217 score 0.905 lr 3.12425e-05 
08/28/2020 11:29:11 - INFO - volta.utils -   [NLVR2]: iter 23653 Ep: 8.76 loss 0.197 score 0.908 lr 3.1222e-05 
08/28/2020 11:29:20 - INFO - volta.utils -   [NLVR2]: iter 23673 Ep: 8.77 loss 0.213 score 0.909 lr 3.12014e-05 
08/28/2020 11:29:55 - INFO - volta.utils -   [NLVR2]: iter 23693 Ep: 8.78 loss 0.176 score 0.920 lr 3.11808e-05 
08/28/2020 11:30:21 - INFO - volta.utils -   [NLVR2]: iter 23713 Ep: 8.79 loss 0.196 score 0.916 lr 3.11602e-05 
08/28/2020 11:30:46 - INFO - volta.utils -   [NLVR2]: iter 23733 Ep: 8.79 loss 0.154 score 0.938 lr 3.11396e-05 
08/28/2020 11:30:55 - INFO - volta.utils -   [NLVR2]: iter 23753 Ep: 8.80 loss 0.173 score 0.914 lr 3.1119e-05 
08/28/2020 11:31:03 - INFO - volta.utils -   [NLVR2]: iter 23773 Ep: 8.81 loss 0.191 score 0.919 lr 3.10985e-05 
08/28/2020 11:31:36 - INFO - volta.utils -   [NLVR2]: iter 23793 Ep: 8.82 loss 0.192 score 0.914 lr 3.10779e-05 
08/28/2020 11:32:11 - INFO - volta.utils -   [NLVR2]: iter 23813 Ep: 8.82 loss 0.247 score 0.908 lr 3.10573e-05 
08/28/2020 11:32:31 - INFO - volta.utils -   [NLVR2]: iter 23833 Ep: 8.83 loss 0.185 score 0.923 lr 3.10367e-05 
08/28/2020 11:32:41 - INFO - volta.utils -   [NLVR2]: iter 23853 Ep: 8.84 loss 0.200 score 0.917 lr 3.10161e-05 
08/28/2020 11:32:52 - INFO - volta.utils -   [NLVR2]: iter 23873 Ep: 8.85 loss 0.191 score 0.911 lr 3.09955e-05 
08/28/2020 11:33:37 - INFO - volta.utils -   [NLVR2]: iter 23893 Ep: 8.85 loss 0.196 score 0.912 lr 3.09749e-05 
08/28/2020 11:34:01 - INFO - volta.utils -   [NLVR2]: iter 23913 Ep: 8.86 loss 0.203 score 0.903 lr 3.09544e-05 
08/28/2020 11:34:20 - INFO - volta.utils -   [NLVR2]: iter 23933 Ep: 8.87 loss 0.207 score 0.909 lr 3.09338e-05 
08/28/2020 11:34:29 - INFO - volta.utils -   [NLVR2]: iter 23953 Ep: 8.87 loss 0.157 score 0.928 lr 3.09132e-05 
08/28/2020 11:34:43 - INFO - volta.utils -   [NLVR2]: iter 23973 Ep: 8.88 loss 0.190 score 0.923 lr 3.08926e-05 
08/28/2020 11:35:18 - INFO - volta.utils -   [NLVR2]: iter 23993 Ep: 8.89 loss 0.171 score 0.931 lr 3.0872e-05 
08/28/2020 11:35:38 - INFO - volta.utils -   [NLVR2]: iter 24013 Ep: 8.90 loss 0.170 score 0.914 lr 3.08514e-05 
08/28/2020 11:35:51 - INFO - volta.utils -   [NLVR2]: iter 24033 Ep: 8.90 loss 0.194 score 0.912 lr 3.08309e-05 
08/28/2020 11:36:00 - INFO - volta.utils -   [NLVR2]: iter 24053 Ep: 8.91 loss 0.199 score 0.914 lr 3.08103e-05 
08/28/2020 11:36:08 - INFO - volta.utils -   [NLVR2]: iter 24073 Ep: 8.92 loss 0.179 score 0.927 lr 3.07897e-05 
08/28/2020 11:36:26 - INFO - volta.utils -   [NLVR2]: iter 24093 Ep: 8.93 loss 0.173 score 0.923 lr 3.07691e-05 
08/28/2020 11:36:59 - INFO - volta.utils -   [NLVR2]: iter 24113 Ep: 8.93 loss 0.167 score 0.934 lr 3.07485e-05 
08/28/2020 11:37:22 - INFO - volta.utils -   [NLVR2]: iter 24133 Ep: 8.94 loss 0.189 score 0.920 lr 3.07279e-05 
08/28/2020 11:37:43 - INFO - volta.utils -   [NLVR2]: iter 24153 Ep: 8.95 loss 0.154 score 0.941 lr 3.07074e-05 
08/28/2020 11:37:51 - INFO - volta.utils -   [NLVR2]: iter 24173 Ep: 8.96 loss 0.152 score 0.947 lr 3.06868e-05 
08/28/2020 11:38:00 - INFO - volta.utils -   [NLVR2]: iter 24193 Ep: 8.96 loss 0.130 score 0.948 lr 3.06662e-05 
08/28/2020 11:38:27 - INFO - volta.utils -   [NLVR2]: iter 24213 Ep: 8.97 loss 0.156 score 0.936 lr 3.06456e-05 
08/28/2020 11:38:55 - INFO - volta.utils -   [NLVR2]: iter 24233 Ep: 8.98 loss 0.169 score 0.936 lr 3.0625e-05 
08/28/2020 11:39:20 - INFO - volta.utils -   [NLVR2]: iter 24253 Ep: 8.99 loss 0.143 score 0.945 lr 3.06044e-05 
08/28/2020 11:39:32 - INFO - volta.utils -   [NLVR2]: iter 24273 Ep: 8.99 loss 0.156 score 0.938 lr 3.05839e-05 
08/28/2020 11:39:39 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  45%|     | 9/20 [5:40:00<8:19:29, 2724.46s/it]08/28/2020 11:47:51 - INFO - volta.utils -   Eval task TASK12 on iteration 24292 
08/28/2020 11:47:51 - INFO - volta.utils -   Validation [NLVR2]: loss 1.041 score 69.997 
08/28/2020 11:47:59 - INFO - volta.utils -   [NLVR2]: iter 24312 Ep: 9.01 loss 0.102 score 0.967 lr 3.05535e-05 
08/28/2020 11:48:24 - INFO - volta.utils -   [NLVR2]: iter 24332 Ep: 9.02 loss 0.075 score 0.981 lr 3.05231e-05 
08/28/2020 11:48:36 - INFO - volta.utils -   [NLVR2]: iter 24352 Ep: 9.02 loss 0.071 score 0.970 lr 3.05026e-05 
08/28/2020 11:48:50 - INFO - volta.utils -   [NLVR2]: iter 24372 Ep: 9.03 loss 0.088 score 0.966 lr 3.0482e-05 
08/28/2020 11:49:17 - INFO - volta.utils -   [NLVR2]: iter 24392 Ep: 9.04 loss 0.078 score 0.972 lr 3.04614e-05 
08/28/2020 11:49:45 - INFO - volta.utils -   [NLVR2]: iter 24412 Ep: 9.04 loss 0.076 score 0.970 lr 3.04408e-05 
08/28/2020 11:50:13 - INFO - volta.utils -   [NLVR2]: iter 24432 Ep: 9.05 loss 0.099 score 0.956 lr 3.04202e-05 
08/28/2020 11:50:23 - INFO - volta.utils -   [NLVR2]: iter 24452 Ep: 9.06 loss 0.107 score 0.967 lr 3.03996e-05 
08/28/2020 11:50:36 - INFO - volta.utils -   [NLVR2]: iter 24472 Ep: 9.07 loss 0.110 score 0.952 lr 3.0379e-05 
08/28/2020 11:51:02 - INFO - volta.utils -   [NLVR2]: iter 24492 Ep: 9.07 loss 0.087 score 0.969 lr 3.03585e-05 
08/28/2020 11:51:32 - INFO - volta.utils -   [NLVR2]: iter 24512 Ep: 9.08 loss 0.081 score 0.964 lr 3.03379e-05 
08/28/2020 11:51:50 - INFO - volta.utils -   [NLVR2]: iter 24532 Ep: 9.09 loss 0.107 score 0.963 lr 3.03173e-05 
08/28/2020 11:52:05 - INFO - volta.utils -   [NLVR2]: iter 24552 Ep: 9.10 loss 0.110 score 0.958 lr 3.02967e-05 
08/28/2020 11:52:13 - INFO - volta.utils -   [NLVR2]: iter 24572 Ep: 9.10 loss 0.102 score 0.961 lr 3.02761e-05 
08/28/2020 11:52:39 - INFO - volta.utils -   [NLVR2]: iter 24592 Ep: 9.11 loss 0.109 score 0.955 lr 3.02555e-05 
08/28/2020 11:53:29 - INFO - volta.utils -   [NLVR2]: iter 24612 Ep: 9.12 loss 0.092 score 0.963 lr 3.0235e-05 
08/28/2020 11:53:41 - INFO - volta.utils -   [NLVR2]: iter 24632 Ep: 9.13 loss 0.098 score 0.963 lr 3.02144e-05 
08/28/2020 11:53:50 - INFO - volta.utils -   [NLVR2]: iter 24652 Ep: 9.13 loss 0.070 score 0.972 lr 3.01938e-05 
08/28/2020 11:53:58 - INFO - volta.utils -   [NLVR2]: iter 24672 Ep: 9.14 loss 0.085 score 0.963 lr 3.01732e-05 
08/28/2020 11:54:26 - INFO - volta.utils -   [NLVR2]: iter 24692 Ep: 9.15 loss 0.126 score 0.953 lr 3.01526e-05 
08/28/2020 11:55:02 - INFO - volta.utils -   [NLVR2]: iter 24712 Ep: 9.16 loss 0.082 score 0.970 lr 3.0132e-05 
08/28/2020 11:55:20 - INFO - volta.utils -   [NLVR2]: iter 24732 Ep: 9.16 loss 0.090 score 0.973 lr 3.01115e-05 
08/28/2020 11:55:29 - INFO - volta.utils -   [NLVR2]: iter 24752 Ep: 9.17 loss 0.101 score 0.964 lr 3.00909e-05 
08/28/2020 11:55:37 - INFO - volta.utils -   [NLVR2]: iter 24772 Ep: 9.18 loss 0.104 score 0.959 lr 3.00703e-05 
08/28/2020 11:56:04 - INFO - volta.utils -   [NLVR2]: iter 24792 Ep: 9.19 loss 0.056 score 0.978 lr 3.00497e-05 
08/28/2020 11:56:38 - INFO - volta.utils -   [NLVR2]: iter 24812 Ep: 9.19 loss 0.090 score 0.972 lr 3.00291e-05 
08/28/2020 11:57:00 - INFO - volta.utils -   [NLVR2]: iter 24832 Ep: 9.20 loss 0.125 score 0.956 lr 3.00085e-05 
08/28/2020 11:57:12 - INFO - volta.utils -   [NLVR2]: iter 24852 Ep: 9.21 loss 0.091 score 0.969 lr 2.9988e-05 
08/28/2020 11:57:22 - INFO - volta.utils -   [NLVR2]: iter 24872 Ep: 9.22 loss 0.094 score 0.964 lr 2.99674e-05 
08/28/2020 11:58:01 - INFO - volta.utils -   [NLVR2]: iter 24892 Ep: 9.22 loss 0.102 score 0.967 lr 2.99468e-05 
08/28/2020 11:58:27 - INFO - volta.utils -   [NLVR2]: iter 24912 Ep: 9.23 loss 0.091 score 0.963 lr 2.99262e-05 
08/28/2020 11:58:39 - INFO - volta.utils -   [NLVR2]: iter 24932 Ep: 9.24 loss 0.104 score 0.961 lr 2.99056e-05 
08/28/2020 11:58:47 - INFO - volta.utils -   [NLVR2]: iter 24952 Ep: 9.24 loss 0.115 score 0.963 lr 2.9885e-05 
08/28/2020 11:58:57 - INFO - volta.utils -   [NLVR2]: iter 24972 Ep: 9.25 loss 0.118 score 0.956 lr 2.98645e-05 
08/28/2020 11:59:06 - INFO - volta.utils -   [NLVR2]: iter 24992 Ep: 9.26 loss 0.137 score 0.958 lr 2.98439e-05 
08/28/2020 11:59:16 - INFO - volta.utils -   [NLVR2]: iter 25012 Ep: 9.27 loss 0.112 score 0.958 lr 2.98233e-05 
08/28/2020 12:00:18 - INFO - volta.utils -   [NLVR2]: iter 25032 Ep: 9.27 loss 0.130 score 0.963 lr 2.98027e-05 
08/28/2020 12:00:31 - INFO - volta.utils -   [NLVR2]: iter 25052 Ep: 9.28 loss 0.105 score 0.966 lr 2.97821e-05 
08/28/2020 12:00:40 - INFO - volta.utils -   [NLVR2]: iter 25072 Ep: 9.29 loss 0.122 score 0.963 lr 2.97615e-05 
08/28/2020 12:00:53 - INFO - volta.utils -   [NLVR2]: iter 25092 Ep: 9.30 loss 0.122 score 0.956 lr 2.9741e-05 
08/28/2020 12:01:47 - INFO - volta.utils -   [NLVR2]: iter 25112 Ep: 9.30 loss 0.100 score 0.956 lr 2.97204e-05 
08/28/2020 12:02:07 - INFO - volta.utils -   [NLVR2]: iter 25132 Ep: 9.31 loss 0.095 score 0.967 lr 2.96998e-05 
08/28/2020 12:02:20 - INFO - volta.utils -   [NLVR2]: iter 25152 Ep: 9.32 loss 0.108 score 0.961 lr 2.96792e-05 
08/28/2020 12:02:28 - INFO - volta.utils -   [NLVR2]: iter 25172 Ep: 9.33 loss 0.099 score 0.963 lr 2.96586e-05 
08/28/2020 12:02:56 - INFO - volta.utils -   [NLVR2]: iter 25192 Ep: 9.33 loss 0.107 score 0.961 lr 2.9638e-05 
08/28/2020 12:03:27 - INFO - volta.utils -   [NLVR2]: iter 25212 Ep: 9.34 loss 0.127 score 0.956 lr 2.96175e-05 
08/28/2020 12:03:54 - INFO - volta.utils -   [NLVR2]: iter 25232 Ep: 9.35 loss 0.127 score 0.948 lr 2.95969e-05 
08/28/2020 12:04:03 - INFO - volta.utils -   [NLVR2]: iter 25252 Ep: 9.36 loss 0.101 score 0.966 lr 2.95763e-05 
08/28/2020 12:04:12 - INFO - volta.utils -   [NLVR2]: iter 25272 Ep: 9.36 loss 0.089 score 0.961 lr 2.95557e-05 
08/28/2020 12:04:30 - INFO - volta.utils -   [NLVR2]: iter 25292 Ep: 9.37 loss 0.103 score 0.966 lr 2.95351e-05 
08/28/2020 12:05:12 - INFO - volta.utils -   [NLVR2]: iter 25312 Ep: 9.38 loss 0.103 score 0.963 lr 2.95145e-05 
08/28/2020 12:05:31 - INFO - volta.utils -   [NLVR2]: iter 25332 Ep: 9.39 loss 0.129 score 0.955 lr 2.94939e-05 
08/28/2020 12:05:45 - INFO - volta.utils -   [NLVR2]: iter 25352 Ep: 9.39 loss 0.127 score 0.952 lr 2.94734e-05 
08/28/2020 12:05:59 - INFO - volta.utils -   [NLVR2]: iter 25372 Ep: 9.40 loss 0.127 score 0.950 lr 2.94528e-05 
08/28/2020 12:06:41 - INFO - volta.utils -   [NLVR2]: iter 25392 Ep: 9.41 loss 0.115 score 0.956 lr 2.94322e-05 
08/28/2020 12:07:08 - INFO - volta.utils -   [NLVR2]: iter 25412 Ep: 9.42 loss 0.136 score 0.948 lr 2.94116e-05 
08/28/2020 12:07:19 - INFO - volta.utils -   [NLVR2]: iter 25432 Ep: 9.42 loss 0.103 score 0.958 lr 2.9391e-05 
08/28/2020 12:07:32 - INFO - volta.utils -   [NLVR2]: iter 25452 Ep: 9.43 loss 0.099 score 0.959 lr 2.93704e-05 
08/28/2020 12:07:41 - INFO - volta.utils -   [NLVR2]: iter 25472 Ep: 9.44 loss 0.099 score 0.958 lr 2.93499e-05 
08/28/2020 12:08:22 - INFO - volta.utils -   [NLVR2]: iter 25492 Ep: 9.44 loss 0.091 score 0.966 lr 2.93293e-05 
08/28/2020 12:08:56 - INFO - volta.utils -   [NLVR2]: iter 25512 Ep: 9.45 loss 0.102 score 0.964 lr 2.93087e-05 
08/28/2020 12:09:05 - INFO - volta.utils -   [NLVR2]: iter 25532 Ep: 9.46 loss 0.106 score 0.969 lr 2.92881e-05 
08/28/2020 12:09:16 - INFO - volta.utils -   [NLVR2]: iter 25552 Ep: 9.47 loss 0.080 score 0.967 lr 2.92675e-05 
08/28/2020 12:09:24 - INFO - volta.utils -   [NLVR2]: iter 25572 Ep: 9.47 loss 0.124 score 0.961 lr 2.92469e-05 
08/28/2020 12:10:11 - INFO - volta.utils -   [NLVR2]: iter 25592 Ep: 9.48 loss 0.087 score 0.970 lr 2.92264e-05 
08/28/2020 12:10:34 - INFO - volta.utils -   [NLVR2]: iter 25612 Ep: 9.49 loss 0.104 score 0.963 lr 2.92058e-05 
08/28/2020 12:10:47 - INFO - volta.utils -   [NLVR2]: iter 25632 Ep: 9.50 loss 0.143 score 0.956 lr 2.91852e-05 
08/28/2020 12:10:55 - INFO - volta.utils -   [NLVR2]: iter 25652 Ep: 9.50 loss 0.095 score 0.967 lr 2.91646e-05 
08/28/2020 12:11:04 - INFO - volta.utils -   [NLVR2]: iter 25672 Ep: 9.51 loss 0.121 score 0.953 lr 2.9144e-05 
08/28/2020 12:11:12 - INFO - volta.utils -   [NLVR2]: iter 25692 Ep: 9.52 loss 0.131 score 0.955 lr 2.91234e-05 
08/28/2020 12:12:11 - INFO - volta.utils -   [NLVR2]: iter 25712 Ep: 9.53 loss 0.117 score 0.956 lr 2.91029e-05 
08/28/2020 12:12:30 - INFO - volta.utils -   [NLVR2]: iter 25732 Ep: 9.53 loss 0.112 score 0.959 lr 2.90823e-05 
08/28/2020 12:12:39 - INFO - volta.utils -   [NLVR2]: iter 25752 Ep: 9.54 loss 0.127 score 0.948 lr 2.90617e-05 
08/28/2020 12:12:49 - INFO - volta.utils -   [NLVR2]: iter 25772 Ep: 9.55 loss 0.081 score 0.978 lr 2.90411e-05 
08/28/2020 12:13:35 - INFO - volta.utils -   [NLVR2]: iter 25792 Ep: 9.56 loss 0.145 score 0.947 lr 2.90205e-05 
08/28/2020 12:14:01 - INFO - volta.utils -   [NLVR2]: iter 25812 Ep: 9.56 loss 0.147 score 0.948 lr 2.89999e-05 
08/28/2020 12:14:19 - INFO - volta.utils -   [NLVR2]: iter 25832 Ep: 9.57 loss 0.137 score 0.945 lr 2.89794e-05 
08/28/2020 12:14:37 - INFO - volta.utils -   [NLVR2]: iter 25852 Ep: 9.58 loss 0.163 score 0.945 lr 2.89588e-05 
08/28/2020 12:15:17 - INFO - volta.utils -   [NLVR2]: iter 25872 Ep: 9.59 loss 0.142 score 0.945 lr 2.89382e-05 
08/28/2020 12:15:42 - INFO - volta.utils -   [NLVR2]: iter 25892 Ep: 9.59 loss 0.125 score 0.956 lr 2.89176e-05 
08/28/2020 12:15:55 - INFO - volta.utils -   [NLVR2]: iter 25912 Ep: 9.60 loss 0.144 score 0.958 lr 2.8897e-05 
08/28/2020 12:16:18 - INFO - volta.utils -   [NLVR2]: iter 25932 Ep: 9.61 loss 0.130 score 0.950 lr 2.88764e-05 
08/28/2020 12:16:55 - INFO - volta.utils -   [NLVR2]: iter 25952 Ep: 9.62 loss 0.155 score 0.939 lr 2.88559e-05 
08/28/2020 12:17:20 - INFO - volta.utils -   [NLVR2]: iter 25972 Ep: 9.62 loss 0.123 score 0.953 lr 2.88353e-05 
08/28/2020 12:17:34 - INFO - volta.utils -   [NLVR2]: iter 25992 Ep: 9.63 loss 0.134 score 0.952 lr 2.88147e-05 
08/28/2020 12:17:43 - INFO - volta.utils -   [NLVR2]: iter 26012 Ep: 9.64 loss 0.142 score 0.945 lr 2.87941e-05 
08/28/2020 12:17:52 - INFO - volta.utils -   [NLVR2]: iter 26032 Ep: 9.65 loss 0.136 score 0.952 lr 2.87735e-05 
08/28/2020 12:18:27 - INFO - volta.utils -   [NLVR2]: iter 26052 Ep: 9.65 loss 0.136 score 0.950 lr 2.87529e-05 
08/28/2020 12:18:58 - INFO - volta.utils -   [NLVR2]: iter 26072 Ep: 9.66 loss 0.117 score 0.955 lr 2.87323e-05 
08/28/2020 12:19:11 - INFO - volta.utils -   [NLVR2]: iter 26092 Ep: 9.67 loss 0.120 score 0.966 lr 2.87118e-05 
08/28/2020 12:19:26 - INFO - volta.utils -   [NLVR2]: iter 26112 Ep: 9.67 loss 0.127 score 0.955 lr 2.86912e-05 
08/28/2020 12:20:01 - INFO - volta.utils -   [NLVR2]: iter 26132 Ep: 9.68 loss 0.143 score 0.947 lr 2.86706e-05 
08/28/2020 12:20:40 - INFO - volta.utils -   [NLVR2]: iter 26152 Ep: 9.69 loss 0.147 score 0.948 lr 2.865e-05 
08/28/2020 12:20:54 - INFO - volta.utils -   [NLVR2]: iter 26172 Ep: 9.70 loss 0.094 score 0.961 lr 2.86294e-05 
08/28/2020 12:21:11 - INFO - volta.utils -   [NLVR2]: iter 26192 Ep: 9.70 loss 0.105 score 0.955 lr 2.86088e-05 
08/28/2020 12:21:19 - INFO - volta.utils -   [NLVR2]: iter 26212 Ep: 9.71 loss 0.123 score 0.956 lr 2.85883e-05 
08/28/2020 12:21:57 - INFO - volta.utils -   [NLVR2]: iter 26232 Ep: 9.72 loss 0.159 score 0.938 lr 2.85677e-05 
08/28/2020 12:22:27 - INFO - volta.utils -   [NLVR2]: iter 26252 Ep: 9.73 loss 0.128 score 0.948 lr 2.85471e-05 
08/28/2020 12:22:36 - INFO - volta.utils -   [NLVR2]: iter 26272 Ep: 9.73 loss 0.135 score 0.948 lr 2.85265e-05 
08/28/2020 12:22:47 - INFO - volta.utils -   [NLVR2]: iter 26292 Ep: 9.74 loss 0.145 score 0.945 lr 2.85059e-05 
08/28/2020 12:22:59 - INFO - volta.utils -   [NLVR2]: iter 26312 Ep: 9.75 loss 0.131 score 0.956 lr 2.84853e-05 
08/28/2020 12:23:28 - INFO - volta.utils -   [NLVR2]: iter 26332 Ep: 9.76 loss 0.136 score 0.950 lr 2.84648e-05 
08/28/2020 12:23:57 - INFO - volta.utils -   [NLVR2]: iter 26352 Ep: 9.76 loss 0.149 score 0.945 lr 2.84442e-05 
08/28/2020 12:24:19 - INFO - volta.utils -   [NLVR2]: iter 26372 Ep: 9.77 loss 0.139 score 0.948 lr 2.84236e-05 
08/28/2020 12:24:33 - INFO - volta.utils -   [NLVR2]: iter 26392 Ep: 9.78 loss 0.115 score 0.956 lr 2.8403e-05 
08/28/2020 12:24:44 - INFO - volta.utils -   [NLVR2]: iter 26412 Ep: 9.79 loss 0.093 score 0.970 lr 2.83824e-05 
08/28/2020 12:24:58 - INFO - volta.utils -   [NLVR2]: iter 26432 Ep: 9.79 loss 0.139 score 0.959 lr 2.83618e-05 
08/28/2020 12:25:43 - INFO - volta.utils -   [NLVR2]: iter 26452 Ep: 9.80 loss 0.134 score 0.948 lr 2.83413e-05 
08/28/2020 12:26:05 - INFO - volta.utils -   [NLVR2]: iter 26472 Ep: 9.81 loss 0.124 score 0.948 lr 2.83207e-05 
08/28/2020 12:26:23 - INFO - volta.utils -   [NLVR2]: iter 26492 Ep: 9.82 loss 0.130 score 0.947 lr 2.83001e-05 
08/28/2020 12:26:31 - INFO - volta.utils -   [NLVR2]: iter 26512 Ep: 9.82 loss 0.131 score 0.955 lr 2.82795e-05 
08/28/2020 12:27:07 - INFO - volta.utils -   [NLVR2]: iter 26532 Ep: 9.83 loss 0.152 score 0.934 lr 2.82589e-05 
08/28/2020 12:27:42 - INFO - volta.utils -   [NLVR2]: iter 26552 Ep: 9.84 loss 0.150 score 0.938 lr 2.82383e-05 
08/28/2020 12:27:52 - INFO - volta.utils -   [NLVR2]: iter 26572 Ep: 9.85 loss 0.127 score 0.953 lr 2.82178e-05 
08/28/2020 12:28:01 - INFO - volta.utils -   [NLVR2]: iter 26592 Ep: 9.85 loss 0.142 score 0.947 lr 2.81972e-05 
08/28/2020 12:28:09 - INFO - volta.utils -   [NLVR2]: iter 26612 Ep: 9.86 loss 0.097 score 0.959 lr 2.81766e-05 
08/28/2020 12:28:17 - INFO - volta.utils -   [NLVR2]: iter 26632 Ep: 9.87 loss 0.178 score 0.927 lr 2.8156e-05 
08/28/2020 12:29:02 - INFO - volta.utils -   [NLVR2]: iter 26652 Ep: 9.87 loss 0.105 score 0.961 lr 2.81354e-05 
08/28/2020 12:29:26 - INFO - volta.utils -   [NLVR2]: iter 26672 Ep: 9.88 loss 0.125 score 0.952 lr 2.81148e-05 
08/28/2020 12:29:46 - INFO - volta.utils -   [NLVR2]: iter 26692 Ep: 9.89 loss 0.140 score 0.950 lr 2.80943e-05 
08/28/2020 12:30:02 - INFO - volta.utils -   [NLVR2]: iter 26712 Ep: 9.90 loss 0.077 score 0.969 lr 2.80737e-05 
08/28/2020 12:30:22 - INFO - volta.utils -   [NLVR2]: iter 26732 Ep: 9.90 loss 0.122 score 0.958 lr 2.80531e-05 
08/28/2020 12:31:05 - INFO - volta.utils -   [NLVR2]: iter 26752 Ep: 9.91 loss 0.160 score 0.938 lr 2.80325e-05 
08/28/2020 12:31:38 - INFO - volta.utils -   [NLVR2]: iter 26772 Ep: 9.92 loss 0.146 score 0.952 lr 2.80119e-05 
08/28/2020 12:32:00 - INFO - volta.utils -   [NLVR2]: iter 26792 Ep: 9.93 loss 0.153 score 0.941 lr 2.79913e-05 
08/28/2020 12:32:58 - INFO - volta.utils -   [NLVR2]: iter 26812 Ep: 9.93 loss 0.149 score 0.942 lr 2.79708e-05 
08/28/2020 12:33:20 - INFO - volta.utils -   [NLVR2]: iter 26832 Ep: 9.94 loss 0.125 score 0.952 lr 2.79502e-05 
08/28/2020 12:33:37 - INFO - volta.utils -   [NLVR2]: iter 26852 Ep: 9.95 loss 0.115 score 0.956 lr 2.79296e-05 
08/28/2020 12:33:50 - INFO - volta.utils -   [NLVR2]: iter 26872 Ep: 9.96 loss 0.122 score 0.955 lr 2.7909e-05 
08/28/2020 12:34:04 - INFO - volta.utils -   [NLVR2]: iter 26892 Ep: 9.96 loss 0.139 score 0.948 lr 2.78884e-05 
08/28/2020 12:35:09 - INFO - volta.utils -   [NLVR2]: iter 26912 Ep: 9.97 loss 0.113 score 0.964 lr 2.78678e-05 
08/28/2020 12:35:34 - INFO - volta.utils -   [NLVR2]: iter 26932 Ep: 9.98 loss 0.148 score 0.941 lr 2.78472e-05 
08/28/2020 12:35:48 - INFO - volta.utils -   [NLVR2]: iter 26952 Ep: 9.99 loss 0.132 score 0.942 lr 2.78267e-05 
08/28/2020 12:36:55 - INFO - volta.utils -   [NLVR2]: iter 26972 Ep: 9.99 loss 0.121 score 0.950 lr 2.78061e-05 
08/28/2020 12:37:04 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  50%|     | 10/20 [6:37:27<8:10:10, 2941.04s/it]08/28/2020 12:46:09 - INFO - volta.utils -   Eval task TASK12 on iteration 26991 
08/28/2020 12:46:09 - INFO - volta.utils -   Validation [NLVR2]: loss 1.120 score 69.925 
08/28/2020 12:46:17 - INFO - volta.utils -   [NLVR2]: iter 27011 Ep: 10.01 loss 0.103 score 0.966 lr 2.77757e-05 
08/28/2020 12:46:57 - INFO - volta.utils -   [NLVR2]: iter 27031 Ep: 10.02 loss 0.076 score 0.970 lr 2.77454e-05 
08/28/2020 12:47:21 - INFO - volta.utils -   [NLVR2]: iter 27051 Ep: 10.02 loss 0.091 score 0.964 lr 2.77248e-05 
08/28/2020 12:47:32 - INFO - volta.utils -   [NLVR2]: iter 27071 Ep: 10.03 loss 0.083 score 0.969 lr 2.77042e-05 
08/28/2020 12:48:31 - INFO - volta.utils -   [NLVR2]: iter 27091 Ep: 10.04 loss 0.075 score 0.980 lr 2.76836e-05 
08/28/2020 12:48:52 - INFO - volta.utils -   [NLVR2]: iter 27111 Ep: 10.04 loss 0.071 score 0.978 lr 2.7663e-05 
08/28/2020 12:49:20 - INFO - volta.utils -   [NLVR2]: iter 27131 Ep: 10.05 loss 0.069 score 0.977 lr 2.76424e-05 
08/28/2020 12:49:38 - INFO - volta.utils -   [NLVR2]: iter 27151 Ep: 10.06 loss 0.078 score 0.973 lr 2.76219e-05 
08/28/2020 12:49:48 - INFO - volta.utils -   [NLVR2]: iter 27171 Ep: 10.07 loss 0.082 score 0.970 lr 2.76013e-05 
08/28/2020 12:50:41 - INFO - volta.utils -   [NLVR2]: iter 27191 Ep: 10.07 loss 0.093 score 0.967 lr 2.75807e-05 
08/28/2020 12:51:07 - INFO - volta.utils -   [NLVR2]: iter 27211 Ep: 10.08 loss 0.103 score 0.966 lr 2.75601e-05 
08/28/2020 12:51:20 - INFO - volta.utils -   [NLVR2]: iter 27231 Ep: 10.09 loss 0.081 score 0.970 lr 2.75395e-05 
08/28/2020 12:51:28 - INFO - volta.utils -   [NLVR2]: iter 27251 Ep: 10.10 loss 0.087 score 0.966 lr 2.75189e-05 
08/28/2020 12:51:36 - INFO - volta.utils -   [NLVR2]: iter 27271 Ep: 10.10 loss 0.069 score 0.977 lr 2.74984e-05 
08/28/2020 12:52:17 - INFO - volta.utils -   [NLVR2]: iter 27291 Ep: 10.11 loss 0.045 score 0.981 lr 2.74778e-05 
08/28/2020 12:52:57 - INFO - volta.utils -   [NLVR2]: iter 27311 Ep: 10.12 loss 0.109 score 0.964 lr 2.74572e-05 
08/28/2020 12:53:12 - INFO - volta.utils -   [NLVR2]: iter 27331 Ep: 10.13 loss 0.080 score 0.975 lr 2.74366e-05 
08/28/2020 12:53:22 - INFO - volta.utils -   [NLVR2]: iter 27351 Ep: 10.13 loss 0.066 score 0.977 lr 2.7416e-05 
08/28/2020 12:53:48 - INFO - volta.utils -   [NLVR2]: iter 27371 Ep: 10.14 loss 0.099 score 0.966 lr 2.73954e-05 
08/28/2020 12:54:27 - INFO - volta.utils -   [NLVR2]: iter 27391 Ep: 10.15 loss 0.077 score 0.975 lr 2.73749e-05 
08/28/2020 12:54:40 - INFO - volta.utils -   [NLVR2]: iter 27411 Ep: 10.16 loss 0.065 score 0.970 lr 2.73543e-05 
08/28/2020 12:54:48 - INFO - volta.utils -   [NLVR2]: iter 27431 Ep: 10.16 loss 0.082 score 0.973 lr 2.73337e-05 
08/28/2020 12:54:58 - INFO - volta.utils -   [NLVR2]: iter 27451 Ep: 10.17 loss 0.067 score 0.980 lr 2.73131e-05 
08/28/2020 12:55:30 - INFO - volta.utils -   [NLVR2]: iter 27471 Ep: 10.18 loss 0.102 score 0.959 lr 2.72925e-05 
08/28/2020 12:56:01 - INFO - volta.utils -   [NLVR2]: iter 27491 Ep: 10.19 loss 0.095 score 0.969 lr 2.72719e-05 
08/28/2020 12:56:19 - INFO - volta.utils -   [NLVR2]: iter 27511 Ep: 10.19 loss 0.061 score 0.981 lr 2.72513e-05 
08/28/2020 12:56:34 - INFO - volta.utils -   [NLVR2]: iter 27531 Ep: 10.20 loss 0.079 score 0.973 lr 2.72308e-05 
08/28/2020 12:56:59 - INFO - volta.utils -   [NLVR2]: iter 27551 Ep: 10.21 loss 0.129 score 0.958 lr 2.72102e-05 
08/28/2020 12:57:31 - INFO - volta.utils -   [NLVR2]: iter 27571 Ep: 10.22 loss 0.035 score 0.986 lr 2.71896e-05 
08/28/2020 12:58:01 - INFO - volta.utils -   [NLVR2]: iter 27591 Ep: 10.22 loss 0.080 score 0.970 lr 2.7169e-05 
08/28/2020 12:58:15 - INFO - volta.utils -   [NLVR2]: iter 27611 Ep: 10.23 loss 0.076 score 0.967 lr 2.71484e-05 
08/28/2020 12:58:29 - INFO - volta.utils -   [NLVR2]: iter 27631 Ep: 10.24 loss 0.053 score 0.973 lr 2.71278e-05 
08/28/2020 12:58:37 - INFO - volta.utils -   [NLVR2]: iter 27651 Ep: 10.24 loss 0.078 score 0.977 lr 2.71073e-05 
08/28/2020 12:59:17 - INFO - volta.utils -   [NLVR2]: iter 27671 Ep: 10.25 loss 0.056 score 0.977 lr 2.70867e-05 
08/28/2020 12:59:46 - INFO - volta.utils -   [NLVR2]: iter 27691 Ep: 10.26 loss 0.091 score 0.969 lr 2.70661e-05 
08/28/2020 13:00:04 - INFO - volta.utils -   [NLVR2]: iter 27711 Ep: 10.27 loss 0.097 score 0.964 lr 2.70455e-05 
08/28/2020 13:00:15 - INFO - volta.utils -   [NLVR2]: iter 27731 Ep: 10.27 loss 0.091 score 0.969 lr 2.70249e-05 
08/28/2020 13:00:24 - INFO - volta.utils -   [NLVR2]: iter 27751 Ep: 10.28 loss 0.081 score 0.967 lr 2.70043e-05 
08/28/2020 13:01:27 - INFO - volta.utils -   [NLVR2]: iter 27771 Ep: 10.29 loss 0.098 score 0.961 lr 2.69838e-05 
08/28/2020 13:01:43 - INFO - volta.utils -   [NLVR2]: iter 27791 Ep: 10.30 loss 0.100 score 0.966 lr 2.69632e-05 
08/28/2020 13:01:55 - INFO - volta.utils -   [NLVR2]: iter 27811 Ep: 10.30 loss 0.048 score 0.984 lr 2.69426e-05 
08/28/2020 13:02:05 - INFO - volta.utils -   [NLVR2]: iter 27831 Ep: 10.31 loss 0.065 score 0.984 lr 2.6922e-05 
08/28/2020 13:02:21 - INFO - volta.utils -   [NLVR2]: iter 27851 Ep: 10.32 loss 0.079 score 0.975 lr 2.69014e-05 
08/28/2020 13:03:00 - INFO - volta.utils -   [NLVR2]: iter 27871 Ep: 10.33 loss 0.080 score 0.978 lr 2.68808e-05 
08/28/2020 13:03:23 - INFO - volta.utils -   [NLVR2]: iter 27891 Ep: 10.33 loss 0.101 score 0.966 lr 2.68603e-05 
08/28/2020 13:03:44 - INFO - volta.utils -   [NLVR2]: iter 27911 Ep: 10.34 loss 0.086 score 0.970 lr 2.68397e-05 
08/28/2020 13:04:14 - INFO - volta.utils -   [NLVR2]: iter 27931 Ep: 10.35 loss 0.065 score 0.973 lr 2.68191e-05 
08/28/2020 13:04:41 - INFO - volta.utils -   [NLVR2]: iter 27951 Ep: 10.36 loss 0.080 score 0.980 lr 2.67985e-05 
08/28/2020 13:05:03 - INFO - volta.utils -   [NLVR2]: iter 27971 Ep: 10.36 loss 0.052 score 0.984 lr 2.67779e-05 
08/28/2020 13:05:17 - INFO - volta.utils -   [NLVR2]: iter 27991 Ep: 10.37 loss 0.090 score 0.966 lr 2.67573e-05 
08/28/2020 13:05:27 - INFO - volta.utils -   [NLVR2]: iter 28011 Ep: 10.38 loss 0.069 score 0.973 lr 2.67368e-05 
08/28/2020 13:05:36 - INFO - volta.utils -   [NLVR2]: iter 28031 Ep: 10.39 loss 0.122 score 0.958 lr 2.67162e-05 
08/28/2020 13:06:00 - INFO - volta.utils -   [NLVR2]: iter 28051 Ep: 10.39 loss 0.093 score 0.961 lr 2.66956e-05 
08/28/2020 13:06:31 - INFO - volta.utils -   [NLVR2]: iter 28071 Ep: 10.40 loss 0.092 score 0.967 lr 2.6675e-05 
08/28/2020 13:07:02 - INFO - volta.utils -   [NLVR2]: iter 28091 Ep: 10.41 loss 0.068 score 0.972 lr 2.66544e-05 
08/28/2020 13:07:16 - INFO - volta.utils -   [NLVR2]: iter 28111 Ep: 10.42 loss 0.072 score 0.966 lr 2.66338e-05 
08/28/2020 13:07:25 - INFO - volta.utils -   [NLVR2]: iter 28131 Ep: 10.42 loss 0.078 score 0.964 lr 2.66133e-05 
08/28/2020 13:07:40 - INFO - volta.utils -   [NLVR2]: iter 28151 Ep: 10.43 loss 0.096 score 0.966 lr 2.65927e-05 
08/28/2020 13:08:33 - INFO - volta.utils -   [NLVR2]: iter 28171 Ep: 10.44 loss 0.087 score 0.972 lr 2.65721e-05 
08/28/2020 13:09:00 - INFO - volta.utils -   [NLVR2]: iter 28191 Ep: 10.44 loss 0.095 score 0.963 lr 2.65515e-05 
08/28/2020 13:09:08 - INFO - volta.utils -   [NLVR2]: iter 28211 Ep: 10.45 loss 0.101 score 0.959 lr 2.65309e-05 
08/28/2020 13:09:16 - INFO - volta.utils -   [NLVR2]: iter 28231 Ep: 10.46 loss 0.086 score 0.975 lr 2.65103e-05 
08/28/2020 13:10:06 - INFO - volta.utils -   [NLVR2]: iter 28251 Ep: 10.47 loss 0.126 score 0.950 lr 2.64897e-05 
08/28/2020 13:10:38 - INFO - volta.utils -   [NLVR2]: iter 28271 Ep: 10.47 loss 0.058 score 0.981 lr 2.64692e-05 
08/28/2020 13:10:53 - INFO - volta.utils -   [NLVR2]: iter 28291 Ep: 10.48 loss 0.060 score 0.977 lr 2.64486e-05 
08/28/2020 13:11:40 - INFO - volta.utils -   [NLVR2]: iter 28311 Ep: 10.49 loss 0.096 score 0.969 lr 2.6428e-05 
08/28/2020 13:12:12 - INFO - volta.utils -   [NLVR2]: iter 28331 Ep: 10.50 loss 0.088 score 0.966 lr 2.64074e-05 
08/28/2020 13:12:24 - INFO - volta.utils -   [NLVR2]: iter 28351 Ep: 10.50 loss 0.086 score 0.975 lr 2.63868e-05 
08/28/2020 13:12:35 - INFO - volta.utils -   [NLVR2]: iter 28371 Ep: 10.51 loss 0.125 score 0.948 lr 2.63662e-05 
08/28/2020 13:12:46 - INFO - volta.utils -   [NLVR2]: iter 28391 Ep: 10.52 loss 0.086 score 0.973 lr 2.63457e-05 
08/28/2020 13:13:25 - INFO - volta.utils -   [NLVR2]: iter 28411 Ep: 10.53 loss 0.075 score 0.973 lr 2.63251e-05 
08/28/2020 13:14:09 - INFO - volta.utils -   [NLVR2]: iter 28431 Ep: 10.53 loss 0.126 score 0.959 lr 2.63045e-05 
08/28/2020 13:14:19 - INFO - volta.utils -   [NLVR2]: iter 28451 Ep: 10.54 loss 0.097 score 0.953 lr 2.62839e-05 
08/28/2020 13:14:29 - INFO - volta.utils -   [NLVR2]: iter 28471 Ep: 10.55 loss 0.079 score 0.978 lr 2.62633e-05 
08/28/2020 13:14:37 - INFO - volta.utils -   [NLVR2]: iter 28491 Ep: 10.56 loss 0.050 score 0.983 lr 2.62427e-05 
08/28/2020 13:15:05 - INFO - volta.utils -   [NLVR2]: iter 28511 Ep: 10.56 loss 0.099 score 0.963 lr 2.62222e-05 
08/28/2020 13:15:53 - INFO - volta.utils -   [NLVR2]: iter 28531 Ep: 10.57 loss 0.076 score 0.978 lr 2.62016e-05 
08/28/2020 13:16:04 - INFO - volta.utils -   [NLVR2]: iter 28551 Ep: 10.58 loss 0.115 score 0.956 lr 2.6181e-05 
08/28/2020 13:16:17 - INFO - volta.utils -   [NLVR2]: iter 28571 Ep: 10.59 loss 0.085 score 0.973 lr 2.61604e-05 
08/28/2020 13:16:37 - INFO - volta.utils -   [NLVR2]: iter 28591 Ep: 10.59 loss 0.074 score 0.972 lr 2.61398e-05 
08/28/2020 13:17:25 - INFO - volta.utils -   [NLVR2]: iter 28611 Ep: 10.60 loss 0.069 score 0.975 lr 2.61192e-05 
08/28/2020 13:17:44 - INFO - volta.utils -   [NLVR2]: iter 28631 Ep: 10.61 loss 0.067 score 0.980 lr 2.60987e-05 
08/28/2020 13:18:02 - INFO - volta.utils -   [NLVR2]: iter 28651 Ep: 10.62 loss 0.081 score 0.969 lr 2.60781e-05 
08/28/2020 13:18:18 - INFO - volta.utils -   [NLVR2]: iter 28671 Ep: 10.62 loss 0.099 score 0.963 lr 2.60575e-05 
08/28/2020 13:19:05 - INFO - volta.utils -   [NLVR2]: iter 28691 Ep: 10.63 loss 0.082 score 0.966 lr 2.60369e-05 
08/28/2020 13:19:31 - INFO - volta.utils -   [NLVR2]: iter 28711 Ep: 10.64 loss 0.069 score 0.967 lr 2.60163e-05 
08/28/2020 13:19:46 - INFO - volta.utils -   [NLVR2]: iter 28731 Ep: 10.65 loss 0.100 score 0.963 lr 2.59957e-05 
08/28/2020 13:19:56 - INFO - volta.utils -   [NLVR2]: iter 28751 Ep: 10.65 loss 0.077 score 0.973 lr 2.59752e-05 
08/28/2020 13:20:12 - INFO - volta.utils -   [NLVR2]: iter 28771 Ep: 10.66 loss 0.083 score 0.975 lr 2.59546e-05 
08/28/2020 13:21:03 - INFO - volta.utils -   [NLVR2]: iter 28791 Ep: 10.67 loss 0.073 score 0.975 lr 2.5934e-05 
08/28/2020 13:21:23 - INFO - volta.utils -   [NLVR2]: iter 28811 Ep: 10.67 loss 0.073 score 0.973 lr 2.59134e-05 
08/28/2020 13:21:31 - INFO - volta.utils -   [NLVR2]: iter 28831 Ep: 10.68 loss 0.102 score 0.964 lr 2.58928e-05 
08/28/2020 13:21:41 - INFO - volta.utils -   [NLVR2]: iter 28851 Ep: 10.69 loss 0.054 score 0.975 lr 2.58722e-05 
08/28/2020 13:22:26 - INFO - volta.utils -   [NLVR2]: iter 28871 Ep: 10.70 loss 0.075 score 0.970 lr 2.58517e-05 
08/28/2020 13:22:54 - INFO - volta.utils -   [NLVR2]: iter 28891 Ep: 10.70 loss 0.068 score 0.981 lr 2.58311e-05 
08/28/2020 13:23:05 - INFO - volta.utils -   [NLVR2]: iter 28911 Ep: 10.71 loss 0.083 score 0.970 lr 2.58105e-05 
08/28/2020 13:23:16 - INFO - volta.utils -   [NLVR2]: iter 28931 Ep: 10.72 loss 0.083 score 0.970 lr 2.57899e-05 
08/28/2020 13:23:26 - INFO - volta.utils -   [NLVR2]: iter 28951 Ep: 10.73 loss 0.094 score 0.964 lr 2.57693e-05 
08/28/2020 13:23:58 - INFO - volta.utils -   [NLVR2]: iter 28971 Ep: 10.73 loss 0.114 score 0.963 lr 2.57487e-05 
08/28/2020 13:24:37 - INFO - volta.utils -   [NLVR2]: iter 28991 Ep: 10.74 loss 0.081 score 0.969 lr 2.57282e-05 
08/28/2020 13:25:06 - INFO - volta.utils -   [NLVR2]: iter 29011 Ep: 10.75 loss 0.083 score 0.980 lr 2.57076e-05 
08/28/2020 13:25:25 - INFO - volta.utils -   [NLVR2]: iter 29031 Ep: 10.76 loss 0.085 score 0.967 lr 2.5687e-05 
08/28/2020 13:26:18 - INFO - volta.utils -   [NLVR2]: iter 29051 Ep: 10.76 loss 0.080 score 0.973 lr 2.56664e-05 
08/28/2020 13:26:44 - INFO - volta.utils -   [NLVR2]: iter 29071 Ep: 10.77 loss 0.118 score 0.961 lr 2.56458e-05 
08/28/2020 13:26:56 - INFO - volta.utils -   [NLVR2]: iter 29091 Ep: 10.78 loss 0.085 score 0.973 lr 2.56252e-05 
08/28/2020 13:27:26 - INFO - volta.utils -   [NLVR2]: iter 29111 Ep: 10.79 loss 0.080 score 0.969 lr 2.56046e-05 
08/28/2020 13:28:09 - INFO - volta.utils -   [NLVR2]: iter 29131 Ep: 10.79 loss 0.089 score 0.966 lr 2.55841e-05 
08/28/2020 13:28:32 - INFO - volta.utils -   [NLVR2]: iter 29151 Ep: 10.80 loss 0.100 score 0.967 lr 2.55635e-05 
08/28/2020 13:28:50 - INFO - volta.utils -   [NLVR2]: iter 29171 Ep: 10.81 loss 0.083 score 0.969 lr 2.55429e-05 
08/28/2020 13:29:24 - INFO - volta.utils -   [NLVR2]: iter 29191 Ep: 10.82 loss 0.107 score 0.950 lr 2.55223e-05 
08/28/2020 13:29:56 - INFO - volta.utils -   [NLVR2]: iter 29211 Ep: 10.82 loss 0.107 score 0.956 lr 2.55017e-05 
08/28/2020 13:30:20 - INFO - volta.utils -   [NLVR2]: iter 29231 Ep: 10.83 loss 0.075 score 0.973 lr 2.54811e-05 
08/28/2020 13:30:38 - INFO - volta.utils -   [NLVR2]: iter 29251 Ep: 10.84 loss 0.085 score 0.970 lr 2.54606e-05 
08/28/2020 13:31:06 - INFO - volta.utils -   [NLVR2]: iter 29271 Ep: 10.85 loss 0.071 score 0.973 lr 2.544e-05 
08/28/2020 13:31:39 - INFO - volta.utils -   [NLVR2]: iter 29291 Ep: 10.85 loss 0.081 score 0.969 lr 2.54194e-05 
08/28/2020 13:32:05 - INFO - volta.utils -   [NLVR2]: iter 29311 Ep: 10.86 loss 0.116 score 0.963 lr 2.53988e-05 
08/28/2020 13:32:16 - INFO - volta.utils -   [NLVR2]: iter 29331 Ep: 10.87 loss 0.057 score 0.980 lr 2.53782e-05 
08/28/2020 13:33:03 - INFO - volta.utils -   [NLVR2]: iter 29351 Ep: 10.87 loss 0.104 score 0.969 lr 2.53576e-05 
08/28/2020 13:33:35 - INFO - volta.utils -   [NLVR2]: iter 29371 Ep: 10.88 loss 0.086 score 0.969 lr 2.53371e-05 
08/28/2020 13:33:52 - INFO - volta.utils -   [NLVR2]: iter 29391 Ep: 10.89 loss 0.094 score 0.963 lr 2.53165e-05 
08/28/2020 13:34:02 - INFO - volta.utils -   [NLVR2]: iter 29411 Ep: 10.90 loss 0.088 score 0.970 lr 2.52959e-05 
08/28/2020 13:34:10 - INFO - volta.utils -   [NLVR2]: iter 29431 Ep: 10.90 loss 0.077 score 0.972 lr 2.52753e-05 
08/28/2020 13:34:18 - INFO - volta.utils -   [NLVR2]: iter 29451 Ep: 10.91 loss 0.086 score 0.970 lr 2.52547e-05 
08/28/2020 13:35:26 - INFO - volta.utils -   [NLVR2]: iter 29471 Ep: 10.92 loss 0.093 score 0.967 lr 2.52341e-05 
08/28/2020 13:35:39 - INFO - volta.utils -   [NLVR2]: iter 29491 Ep: 10.93 loss 0.088 score 0.970 lr 2.52136e-05 
08/28/2020 13:35:48 - INFO - volta.utils -   [NLVR2]: iter 29511 Ep: 10.93 loss 0.082 score 0.969 lr 2.5193e-05 
08/28/2020 13:35:59 - INFO - volta.utils -   [NLVR2]: iter 29531 Ep: 10.94 loss 0.083 score 0.969 lr 2.51724e-05 
08/28/2020 13:36:33 - INFO - volta.utils -   [NLVR2]: iter 29551 Ep: 10.95 loss 0.112 score 0.969 lr 2.51518e-05 
08/28/2020 13:37:08 - INFO - volta.utils -   [NLVR2]: iter 29571 Ep: 10.96 loss 0.077 score 0.970 lr 2.51312e-05 
08/28/2020 13:37:23 - INFO - volta.utils -   [NLVR2]: iter 29591 Ep: 10.96 loss 0.113 score 0.961 lr 2.51106e-05 
08/28/2020 13:37:39 - INFO - volta.utils -   [NLVR2]: iter 29611 Ep: 10.97 loss 0.111 score 0.959 lr 2.50901e-05 
08/28/2020 13:37:49 - INFO - volta.utils -   [NLVR2]: iter 29631 Ep: 10.98 loss 0.079 score 0.972 lr 2.50695e-05 
08/28/2020 13:37:57 - INFO - volta.utils -   [NLVR2]: iter 29651 Ep: 10.99 loss 0.089 score 0.970 lr 2.50489e-05 
08/28/2020 13:38:10 - INFO - volta.utils -   [NLVR2]: iter 29671 Ep: 10.99 loss 0.104 score 0.964 lr 2.50283e-05 
08/28/2020 13:38:20 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  55%|    | 11/20 [7:38:42<7:54:10, 3161.22s/it]08/28/2020 13:47:27 - INFO - volta.utils -   Eval task TASK12 on iteration 29690 
08/28/2020 13:47:27 - INFO - volta.utils -   Validation [NLVR2]: loss 1.199 score 70.212 
08/28/2020 13:47:35 - INFO - volta.utils -   [NLVR2]: iter 29710 Ep: 11.01 loss 0.076 score 0.971 lr 2.49979e-05 
08/28/2020 13:47:49 - INFO - volta.utils -   [NLVR2]: iter 29730 Ep: 11.02 loss 0.048 score 0.980 lr 2.49676e-05 
08/28/2020 13:48:29 - INFO - volta.utils -   [NLVR2]: iter 29750 Ep: 11.02 loss 0.077 score 0.977 lr 2.4947e-05 
08/28/2020 13:48:52 - INFO - volta.utils -   [NLVR2]: iter 29770 Ep: 11.03 loss 0.039 score 0.983 lr 2.49264e-05 
08/28/2020 13:49:07 - INFO - volta.utils -   [NLVR2]: iter 29790 Ep: 11.04 loss 0.054 score 0.984 lr 2.49058e-05 
08/28/2020 13:49:20 - INFO - volta.utils -   [NLVR2]: iter 29810 Ep: 11.04 loss 0.026 score 0.994 lr 2.48852e-05 
08/28/2020 13:49:29 - INFO - volta.utils -   [NLVR2]: iter 29830 Ep: 11.05 loss 0.072 score 0.978 lr 2.48647e-05 
08/28/2020 13:49:40 - INFO - volta.utils -   [NLVR2]: iter 29850 Ep: 11.06 loss 0.063 score 0.980 lr 2.48441e-05 
08/28/2020 13:50:24 - INFO - volta.utils -   [NLVR2]: iter 29870 Ep: 11.07 loss 0.046 score 0.983 lr 2.48235e-05 
08/28/2020 13:50:50 - INFO - volta.utils -   [NLVR2]: iter 29890 Ep: 11.07 loss 0.050 score 0.981 lr 2.48029e-05 
08/28/2020 13:51:05 - INFO - volta.utils -   [NLVR2]: iter 29910 Ep: 11.08 loss 0.061 score 0.983 lr 2.47823e-05 
08/28/2020 13:51:13 - INFO - volta.utils -   [NLVR2]: iter 29930 Ep: 11.09 loss 0.064 score 0.973 lr 2.47617e-05 
08/28/2020 13:51:42 - INFO - volta.utils -   [NLVR2]: iter 29950 Ep: 11.10 loss 0.041 score 0.988 lr 2.47412e-05 
08/28/2020 13:52:27 - INFO - volta.utils -   [NLVR2]: iter 29970 Ep: 11.10 loss 0.051 score 0.977 lr 2.47206e-05 
08/28/2020 13:52:49 - INFO - volta.utils -   [NLVR2]: iter 29990 Ep: 11.11 loss 0.046 score 0.984 lr 2.47e-05 
08/28/2020 13:52:59 - INFO - volta.utils -   [NLVR2]: iter 30010 Ep: 11.12 loss 0.082 score 0.972 lr 2.46794e-05 
08/28/2020 13:53:41 - INFO - volta.utils -   [NLVR2]: iter 30030 Ep: 11.13 loss 0.072 score 0.975 lr 2.46588e-05 
08/28/2020 13:54:09 - INFO - volta.utils -   [NLVR2]: iter 30050 Ep: 11.13 loss 0.049 score 0.981 lr 2.46382e-05 
08/28/2020 13:54:28 - INFO - volta.utils -   [NLVR2]: iter 30070 Ep: 11.14 loss 0.038 score 0.986 lr 2.46177e-05 
08/28/2020 13:54:39 - INFO - volta.utils -   [NLVR2]: iter 30090 Ep: 11.15 loss 0.027 score 0.988 lr 2.45971e-05 
08/28/2020 13:54:47 - INFO - volta.utils -   [NLVR2]: iter 30110 Ep: 11.16 loss 0.045 score 0.980 lr 2.45765e-05 
08/28/2020 13:55:26 - INFO - volta.utils -   [NLVR2]: iter 30130 Ep: 11.16 loss 0.071 score 0.978 lr 2.45559e-05 
