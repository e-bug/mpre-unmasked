/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
08/28/2020 16:33:57 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
08/28/2020 16:33:58 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
08/28/2020 16:33:58 - INFO - volta.task_utils -   Loading NLVR2 Dataset with batch size 32
08/28/2020 16:33:58 - INFO - volta.datasets.nlvr2_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/nlvr2/data/cache/NLVR2_train_20.pkl
08/28/2020 16:34:29 - INFO - volta.datasets.nlvr2_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/nlvr2/data/cache/NLVR2_dev_20.pkl
08/28/2020 16:34:32 - INFO - volta.utils -   logging file at: ../../logs/volta/nlvr2/NLVR2_lxmert
08/28/2020 16:34:32 - INFO - volta.utils -   loading weights file /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/volta/lxmert/lxmert/pytorch_model_19.bin
08/28/2020 16:34:39 - INFO - volta.utils -   
08/28/2020 16:34:39 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK12.logit_fc.0.weight', 'clfs_dict.TASK12.logit_fc.0.bias', 'clfs_dict.TASK12.logit_fc.2.weight', 'clfs_dict.TASK12.logit_fc.2.bias', 'clfs_dict.TASK12.logit_fc.3.weight', 'clfs_dict.TASK12.logit_fc.3.bias']
08/28/2020 16:34:47 - INFO - __main__ -   >> Trainable Parameters:
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)     |1572864     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(768, 4)        |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.v_embeddings.ImgLayerNorm.weight                        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.v_embeddings.ImgLayerNorm.bias                          |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.v_embeddings.LocLayerNorm.weight                        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.v_embeddings.LocLayerNorm.bias                          |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.predictions.bias                                         |torch.float32    |(30522,)        |30522       |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.predictions.transform.dense.weight                       |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.predictions.transform.dense.bias                         |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.weight                   |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.bi_seq_relationship.weight                               |torch.float32    |(2, 768)        |1536        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.bi_seq_relationship.bias                                 |torch.float32    |(2,)            |2           |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.weight                  |torch.float32    |(768, 768)      |589824      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.bias                    |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.weight              |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.bias                |torch.float32    |(768,)          |768         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.3.weight                   |torch.float32    |(1600, 768)     |1228800     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.3.bias                     |torch.float32    |(1600,)         |1600        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.4.weight                   |torch.float32    |(400, 768)      |307200      |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.4.bias                     |torch.float32    |(400,)          |400         |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.5.weight                   |torch.float32    |(2048, 768)     |1572864     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.5.bias                     |torch.float32    |(2048,)         |2048        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.0.weight                           |torch.float32    |(1536, 1536)    |2359296     |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.0.bias                             |torch.float32    |(1536,)         |1536        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.2.weight                           |torch.float32    |(1536,)         |1536        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.2.bias                             |torch.float32    |(1536,)         |1536        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.3.weight                           |torch.float32    |(2, 1536)       |3072        |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   |module.clfs_dict.TASK12.logit_fc.3.bias                             |torch.float32    |(2,)            |2           |
08/28/2020 16:34:47 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 16:34:47 - INFO - __main__ -   >> # TrainableParams:       	214.63	M
08/28/2020 16:34:47 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
08/28/2020 16:34:47 - INFO - __main__ -   >> # TotalParams:           	214.63	M

Epoch:   0%|          | 0/9 [00:00<?, ?it/s]08/28/2020 16:42:31 - INFO - volta.utils -   Eval task TASK12 on iteration 29690 
08/28/2020 16:42:31 - INFO - volta.utils -   Validation [NLVR2]: loss 1.194 score 70.069 
08/28/2020 16:42:54 - INFO - volta.utils -   [NLVR2]: iter 29710 Ep: 11.01 loss 0.089 score 0.971 lr 2.49979e-05 
08/28/2020 16:43:17 - INFO - volta.utils -   [NLVR2]: iter 29730 Ep: 11.02 loss 0.041 score 0.984 lr 2.49676e-05 
08/28/2020 16:43:34 - INFO - volta.utils -   [NLVR2]: iter 29750 Ep: 11.02 loss 0.063 score 0.981 lr 2.4947e-05 
08/28/2020 16:43:51 - INFO - volta.utils -   [NLVR2]: iter 29770 Ep: 11.03 loss 0.064 score 0.983 lr 2.49264e-05 
08/28/2020 16:44:04 - INFO - volta.utils -   [NLVR2]: iter 29790 Ep: 11.04 loss 0.026 score 0.992 lr 2.49058e-05 
08/28/2020 16:44:16 - INFO - volta.utils -   [NLVR2]: iter 29810 Ep: 11.04 loss 0.072 score 0.981 lr 2.48852e-05 
08/28/2020 16:44:27 - INFO - volta.utils -   [NLVR2]: iter 29830 Ep: 11.05 loss 0.042 score 0.988 lr 2.48647e-05 
08/28/2020 16:44:39 - INFO - volta.utils -   [NLVR2]: iter 29850 Ep: 11.06 loss 0.048 score 0.977 lr 2.48441e-05 
08/28/2020 16:44:48 - INFO - volta.utils -   [NLVR2]: iter 29870 Ep: 11.07 loss 0.039 score 0.986 lr 2.48235e-05 
08/28/2020 16:45:04 - INFO - volta.utils -   [NLVR2]: iter 29890 Ep: 11.07 loss 0.055 score 0.983 lr 2.48029e-05 
08/28/2020 16:45:16 - INFO - volta.utils -   [NLVR2]: iter 29910 Ep: 11.08 loss 0.035 score 0.991 lr 2.47823e-05 
08/28/2020 16:45:31 - INFO - volta.utils -   [NLVR2]: iter 29930 Ep: 11.09 loss 0.041 score 0.986 lr 2.47617e-05 
08/28/2020 16:45:39 - INFO - volta.utils -   [NLVR2]: iter 29950 Ep: 11.10 loss 0.083 score 0.973 lr 2.47412e-05 
08/28/2020 16:45:48 - INFO - volta.utils -   [NLVR2]: iter 29970 Ep: 11.10 loss 0.068 score 0.973 lr 2.47206e-05 
08/28/2020 16:45:56 - INFO - volta.utils -   [NLVR2]: iter 29990 Ep: 11.11 loss 0.034 score 0.989 lr 2.47e-05 
08/28/2020 16:46:14 - INFO - volta.utils -   [NLVR2]: iter 30010 Ep: 11.12 loss 0.047 score 0.988 lr 2.46794e-05 
08/28/2020 16:46:21 - INFO - volta.utils -   [NLVR2]: iter 30030 Ep: 11.13 loss 0.071 score 0.978 lr 2.46588e-05 
08/28/2020 16:46:31 - INFO - volta.utils -   [NLVR2]: iter 30050 Ep: 11.13 loss 0.052 score 0.973 lr 2.46382e-05 
08/28/2020 16:46:39 - INFO - volta.utils -   [NLVR2]: iter 30070 Ep: 11.14 loss 0.054 score 0.977 lr 2.46177e-05 
08/28/2020 16:46:47 - INFO - volta.utils -   [NLVR2]: iter 30090 Ep: 11.15 loss 0.056 score 0.980 lr 2.45971e-05 
08/28/2020 16:47:04 - INFO - volta.utils -   [NLVR2]: iter 30110 Ep: 11.16 loss 0.052 score 0.983 lr 2.45765e-05 
08/28/2020 16:47:22 - INFO - volta.utils -   [NLVR2]: iter 30130 Ep: 11.16 loss 0.039 score 0.988 lr 2.45559e-05 
08/28/2020 16:47:42 - INFO - volta.utils -   [NLVR2]: iter 30150 Ep: 11.17 loss 0.052 score 0.983 lr 2.45353e-05 
08/28/2020 16:48:03 - INFO - volta.utils -   [NLVR2]: iter 30170 Ep: 11.18 loss 0.052 score 0.980 lr 2.45147e-05 
08/28/2020 16:48:32 - INFO - volta.utils -   [NLVR2]: iter 30190 Ep: 11.19 loss 0.056 score 0.973 lr 2.44942e-05 
08/28/2020 16:48:51 - INFO - volta.utils -   [NLVR2]: iter 30210 Ep: 11.19 loss 0.051 score 0.986 lr 2.44736e-05 
08/28/2020 16:49:08 - INFO - volta.utils -   [NLVR2]: iter 30230 Ep: 11.20 loss 0.048 score 0.981 lr 2.4453e-05 
08/28/2020 16:49:19 - INFO - volta.utils -   [NLVR2]: iter 30250 Ep: 11.21 loss 0.072 score 0.970 lr 2.44324e-05 
08/28/2020 16:49:33 - INFO - volta.utils -   [NLVR2]: iter 30270 Ep: 11.22 loss 0.058 score 0.984 lr 2.44118e-05 
08/28/2020 16:49:43 - INFO - volta.utils -   [NLVR2]: iter 30290 Ep: 11.22 loss 0.063 score 0.977 lr 2.43912e-05 
08/28/2020 16:49:57 - INFO - volta.utils -   [NLVR2]: iter 30310 Ep: 11.23 loss 0.046 score 0.986 lr 2.43707e-05 
08/28/2020 16:50:10 - INFO - volta.utils -   [NLVR2]: iter 30330 Ep: 11.24 loss 0.045 score 0.983 lr 2.43501e-05 
08/28/2020 16:50:21 - INFO - volta.utils -   [NLVR2]: iter 30350 Ep: 11.24 loss 0.048 score 0.988 lr 2.43295e-05 
08/28/2020 16:50:33 - INFO - volta.utils -   [NLVR2]: iter 30370 Ep: 11.25 loss 0.064 score 0.980 lr 2.43089e-05 
08/28/2020 16:50:43 - INFO - volta.utils -   [NLVR2]: iter 30390 Ep: 11.26 loss 0.048 score 0.977 lr 2.42883e-05 
08/28/2020 16:50:56 - INFO - volta.utils -   [NLVR2]: iter 30410 Ep: 11.27 loss 0.080 score 0.978 lr 2.42677e-05 
08/28/2020 16:51:06 - INFO - volta.utils -   [NLVR2]: iter 30430 Ep: 11.27 loss 0.057 score 0.980 lr 2.42471e-05 
08/28/2020 16:51:14 - INFO - volta.utils -   [NLVR2]: iter 30450 Ep: 11.28 loss 0.055 score 0.983 lr 2.42266e-05 
08/28/2020 16:51:24 - INFO - volta.utils -   [NLVR2]: iter 30470 Ep: 11.29 loss 0.072 score 0.981 lr 2.4206e-05 
08/28/2020 16:51:35 - INFO - volta.utils -   [NLVR2]: iter 30490 Ep: 11.30 loss 0.043 score 0.986 lr 2.41854e-05 
08/28/2020 16:51:44 - INFO - volta.utils -   [NLVR2]: iter 30510 Ep: 11.30 loss 0.053 score 0.977 lr 2.41648e-05 
08/28/2020 16:51:53 - INFO - volta.utils -   [NLVR2]: iter 30530 Ep: 11.31 loss 0.048 score 0.983 lr 2.41442e-05 
08/28/2020 16:52:02 - INFO - volta.utils -   [NLVR2]: iter 30550 Ep: 11.32 loss 0.051 score 0.977 lr 2.41236e-05 
08/28/2020 16:52:10 - INFO - volta.utils -   [NLVR2]: iter 30570 Ep: 11.33 loss 0.072 score 0.966 lr 2.41031e-05 
08/28/2020 16:52:19 - INFO - volta.utils -   [NLVR2]: iter 30590 Ep: 11.33 loss 0.065 score 0.972 lr 2.40825e-05 
08/28/2020 16:52:27 - INFO - volta.utils -   [NLVR2]: iter 30610 Ep: 11.34 loss 0.090 score 0.969 lr 2.40619e-05 
08/28/2020 16:52:36 - INFO - volta.utils -   [NLVR2]: iter 30630 Ep: 11.35 loss 0.071 score 0.978 lr 2.40413e-05 
08/28/2020 16:52:44 - INFO - volta.utils -   [NLVR2]: iter 30650 Ep: 11.36 loss 0.040 score 0.986 lr 2.40207e-05 
08/28/2020 16:52:52 - INFO - volta.utils -   [NLVR2]: iter 30670 Ep: 11.36 loss 0.047 score 0.980 lr 2.40001e-05 
08/28/2020 16:53:00 - INFO - volta.utils -   [NLVR2]: iter 30690 Ep: 11.37 loss 0.090 score 0.973 lr 2.39796e-05 
08/28/2020 16:53:09 - INFO - volta.utils -   [NLVR2]: iter 30710 Ep: 11.38 loss 0.035 score 0.986 lr 2.3959e-05 
08/28/2020 16:53:17 - INFO - volta.utils -   [NLVR2]: iter 30730 Ep: 11.39 loss 0.065 score 0.977 lr 2.39384e-05 
08/28/2020 16:53:26 - INFO - volta.utils -   [NLVR2]: iter 30750 Ep: 11.39 loss 0.056 score 0.983 lr 2.39178e-05 
08/28/2020 16:53:34 - INFO - volta.utils -   [NLVR2]: iter 30770 Ep: 11.40 loss 0.056 score 0.984 lr 2.38972e-05 
08/28/2020 16:53:42 - INFO - volta.utils -   [NLVR2]: iter 30790 Ep: 11.41 loss 0.048 score 0.978 lr 2.38766e-05 
08/28/2020 16:53:51 - INFO - volta.utils -   [NLVR2]: iter 30810 Ep: 11.42 loss 0.060 score 0.980 lr 2.38561e-05 
08/28/2020 16:53:59 - INFO - volta.utils -   [NLVR2]: iter 30830 Ep: 11.42 loss 0.039 score 0.988 lr 2.38355e-05 
08/28/2020 16:54:15 - INFO - volta.utils -   [NLVR2]: iter 30850 Ep: 11.43 loss 0.048 score 0.988 lr 2.38149e-05 
08/28/2020 16:54:23 - INFO - volta.utils -   [NLVR2]: iter 30870 Ep: 11.44 loss 0.060 score 0.981 lr 2.37943e-05 
08/28/2020 16:54:46 - INFO - volta.utils -   [NLVR2]: iter 30890 Ep: 11.44 loss 0.044 score 0.988 lr 2.37737e-05 
08/28/2020 16:54:54 - INFO - volta.utils -   [NLVR2]: iter 30910 Ep: 11.45 loss 0.055 score 0.984 lr 2.37531e-05 
08/28/2020 16:55:04 - INFO - volta.utils -   [NLVR2]: iter 30930 Ep: 11.46 loss 0.065 score 0.981 lr 2.37326e-05 
08/28/2020 16:55:12 - INFO - volta.utils -   [NLVR2]: iter 30950 Ep: 11.47 loss 0.061 score 0.978 lr 2.3712e-05 
08/28/2020 16:55:21 - INFO - volta.utils -   [NLVR2]: iter 30970 Ep: 11.47 loss 0.098 score 0.966 lr 2.36914e-05 
08/28/2020 16:55:29 - INFO - volta.utils -   [NLVR2]: iter 30990 Ep: 11.48 loss 0.077 score 0.978 lr 2.36708e-05 
08/28/2020 16:55:38 - INFO - volta.utils -   [NLVR2]: iter 31010 Ep: 11.49 loss 0.091 score 0.966 lr 2.36502e-05 
08/28/2020 16:55:46 - INFO - volta.utils -   [NLVR2]: iter 31030 Ep: 11.50 loss 0.045 score 0.983 lr 2.36296e-05 
08/28/2020 16:55:56 - INFO - volta.utils -   [NLVR2]: iter 31050 Ep: 11.50 loss 0.086 score 0.977 lr 2.36091e-05 
08/28/2020 16:56:04 - INFO - volta.utils -   [NLVR2]: iter 31070 Ep: 11.51 loss 0.055 score 0.983 lr 2.35885e-05 
08/28/2020 16:56:13 - INFO - volta.utils -   [NLVR2]: iter 31090 Ep: 11.52 loss 0.076 score 0.975 lr 2.35679e-05 
08/28/2020 16:56:21 - INFO - volta.utils -   [NLVR2]: iter 31110 Ep: 11.53 loss 0.092 score 0.969 lr 2.35473e-05 
08/28/2020 16:56:29 - INFO - volta.utils -   [NLVR2]: iter 31130 Ep: 11.53 loss 0.050 score 0.983 lr 2.35267e-05 
08/28/2020 16:56:37 - INFO - volta.utils -   [NLVR2]: iter 31150 Ep: 11.54 loss 0.064 score 0.972 lr 2.35061e-05 
08/28/2020 16:56:46 - INFO - volta.utils -   [NLVR2]: iter 31170 Ep: 11.55 loss 0.070 score 0.975 lr 2.34856e-05 
08/28/2020 16:56:54 - INFO - volta.utils -   [NLVR2]: iter 31190 Ep: 11.56 loss 0.055 score 0.981 lr 2.3465e-05 
08/28/2020 16:57:12 - INFO - volta.utils -   [NLVR2]: iter 31210 Ep: 11.56 loss 0.051 score 0.983 lr 2.34444e-05 
08/28/2020 16:57:20 - INFO - volta.utils -   [NLVR2]: iter 31230 Ep: 11.57 loss 0.076 score 0.973 lr 2.34238e-05 
08/28/2020 16:57:29 - INFO - volta.utils -   [NLVR2]: iter 31250 Ep: 11.58 loss 0.049 score 0.988 lr 2.34032e-05 
08/28/2020 16:57:37 - INFO - volta.utils -   [NLVR2]: iter 31270 Ep: 11.59 loss 0.062 score 0.980 lr 2.33826e-05 
08/28/2020 16:57:45 - INFO - volta.utils -   [NLVR2]: iter 31290 Ep: 11.59 loss 0.067 score 0.977 lr 2.3362e-05 
08/28/2020 16:57:53 - INFO - volta.utils -   [NLVR2]: iter 31310 Ep: 11.60 loss 0.046 score 0.984 lr 2.33415e-05 
08/28/2020 16:58:02 - INFO - volta.utils -   [NLVR2]: iter 31330 Ep: 11.61 loss 0.077 score 0.973 lr 2.33209e-05 
08/28/2020 16:58:10 - INFO - volta.utils -   [NLVR2]: iter 31350 Ep: 11.62 loss 0.048 score 0.988 lr 2.33003e-05 
08/28/2020 16:58:19 - INFO - volta.utils -   [NLVR2]: iter 31370 Ep: 11.62 loss 0.087 score 0.972 lr 2.32797e-05 
08/28/2020 16:58:27 - INFO - volta.utils -   [NLVR2]: iter 31390 Ep: 11.63 loss 0.041 score 0.986 lr 2.32591e-05 
08/28/2020 16:58:36 - INFO - volta.utils -   [NLVR2]: iter 31410 Ep: 11.64 loss 0.082 score 0.973 lr 2.32385e-05 
08/28/2020 16:58:45 - INFO - volta.utils -   [NLVR2]: iter 31430 Ep: 11.65 loss 0.087 score 0.970 lr 2.3218e-05 
08/28/2020 16:58:53 - INFO - volta.utils -   [NLVR2]: iter 31450 Ep: 11.65 loss 0.042 score 0.983 lr 2.31974e-05 
08/28/2020 16:59:02 - INFO - volta.utils -   [NLVR2]: iter 31470 Ep: 11.66 loss 0.053 score 0.983 lr 2.31768e-05 
08/28/2020 16:59:10 - INFO - volta.utils -   [NLVR2]: iter 31490 Ep: 11.67 loss 0.084 score 0.973 lr 2.31562e-05 
08/28/2020 16:59:19 - INFO - volta.utils -   [NLVR2]: iter 31510 Ep: 11.67 loss 0.055 score 0.986 lr 2.31356e-05 
08/28/2020 16:59:27 - INFO - volta.utils -   [NLVR2]: iter 31530 Ep: 11.68 loss 0.063 score 0.981 lr 2.3115e-05 
08/28/2020 16:59:35 - INFO - volta.utils -   [NLVR2]: iter 31550 Ep: 11.69 loss 0.084 score 0.977 lr 2.30945e-05 
08/28/2020 16:59:43 - INFO - volta.utils -   [NLVR2]: iter 31570 Ep: 11.70 loss 0.071 score 0.973 lr 2.30739e-05 
08/28/2020 16:59:52 - INFO - volta.utils -   [NLVR2]: iter 31590 Ep: 11.70 loss 0.060 score 0.980 lr 2.30533e-05 
08/28/2020 17:00:00 - INFO - volta.utils -   [NLVR2]: iter 31610 Ep: 11.71 loss 0.066 score 0.977 lr 2.30327e-05 
08/28/2020 17:00:10 - INFO - volta.utils -   [NLVR2]: iter 31630 Ep: 11.72 loss 0.101 score 0.967 lr 2.30121e-05 
08/28/2020 17:00:18 - INFO - volta.utils -   [NLVR2]: iter 31650 Ep: 11.73 loss 0.055 score 0.981 lr 2.29915e-05 
08/28/2020 17:00:27 - INFO - volta.utils -   [NLVR2]: iter 31670 Ep: 11.73 loss 0.090 score 0.970 lr 2.2971e-05 
08/28/2020 17:00:35 - INFO - volta.utils -   [NLVR2]: iter 31690 Ep: 11.74 loss 0.070 score 0.972 lr 2.29504e-05 
08/28/2020 17:00:44 - INFO - volta.utils -   [NLVR2]: iter 31710 Ep: 11.75 loss 0.054 score 0.984 lr 2.29298e-05 
08/28/2020 17:00:52 - INFO - volta.utils -   [NLVR2]: iter 31730 Ep: 11.76 loss 0.079 score 0.977 lr 2.29092e-05 
08/28/2020 17:01:02 - INFO - volta.utils -   [NLVR2]: iter 31750 Ep: 11.76 loss 0.096 score 0.969 lr 2.28886e-05 
08/28/2020 17:01:10 - INFO - volta.utils -   [NLVR2]: iter 31770 Ep: 11.77 loss 0.086 score 0.969 lr 2.2868e-05 
08/28/2020 17:01:19 - INFO - volta.utils -   [NLVR2]: iter 31790 Ep: 11.78 loss 0.080 score 0.980 lr 2.28475e-05 
08/28/2020 17:01:26 - INFO - volta.utils -   [NLVR2]: iter 31810 Ep: 11.79 loss 0.072 score 0.973 lr 2.28269e-05 
08/28/2020 17:01:35 - INFO - volta.utils -   [NLVR2]: iter 31830 Ep: 11.79 loss 0.074 score 0.970 lr 2.28063e-05 
08/28/2020 17:01:43 - INFO - volta.utils -   [NLVR2]: iter 31850 Ep: 11.80 loss 0.069 score 0.972 lr 2.27857e-05 
08/28/2020 17:01:52 - INFO - volta.utils -   [NLVR2]: iter 31870 Ep: 11.81 loss 0.097 score 0.969 lr 2.27651e-05 
08/28/2020 17:02:00 - INFO - volta.utils -   [NLVR2]: iter 31890 Ep: 11.82 loss 0.042 score 0.986 lr 2.27445e-05 
08/28/2020 17:02:09 - INFO - volta.utils -   [NLVR2]: iter 31910 Ep: 11.82 loss 0.103 score 0.970 lr 2.2724e-05 
08/28/2020 17:02:16 - INFO - volta.utils -   [NLVR2]: iter 31930 Ep: 11.83 loss 0.090 score 0.967 lr 2.27034e-05 
08/28/2020 17:02:25 - INFO - volta.utils -   [NLVR2]: iter 31950 Ep: 11.84 loss 0.071 score 0.975 lr 2.26828e-05 
08/28/2020 17:02:33 - INFO - volta.utils -   [NLVR2]: iter 31970 Ep: 11.85 loss 0.084 score 0.975 lr 2.26622e-05 
08/28/2020 17:02:43 - INFO - volta.utils -   [NLVR2]: iter 31990 Ep: 11.85 loss 0.066 score 0.978 lr 2.26416e-05 
08/28/2020 17:02:51 - INFO - volta.utils -   [NLVR2]: iter 32010 Ep: 11.86 loss 0.066 score 0.975 lr 2.2621e-05 
08/28/2020 17:03:00 - INFO - volta.utils -   [NLVR2]: iter 32030 Ep: 11.87 loss 0.081 score 0.975 lr 2.26004e-05 
08/28/2020 17:03:09 - INFO - volta.utils -   [NLVR2]: iter 32050 Ep: 11.87 loss 0.069 score 0.973 lr 2.25799e-05 
08/28/2020 17:03:18 - INFO - volta.utils -   [NLVR2]: iter 32070 Ep: 11.88 loss 0.062 score 0.978 lr 2.25593e-05 
08/28/2020 17:03:34 - INFO - volta.utils -   [NLVR2]: iter 32090 Ep: 11.89 loss 0.057 score 0.975 lr 2.25387e-05 
08/28/2020 17:03:44 - INFO - volta.utils -   [NLVR2]: iter 32110 Ep: 11.90 loss 0.066 score 0.981 lr 2.25181e-05 
08/28/2020 17:03:52 - INFO - volta.utils -   [NLVR2]: iter 32130 Ep: 11.90 loss 0.067 score 0.980 lr 2.24975e-05 
08/28/2020 17:04:01 - INFO - volta.utils -   [NLVR2]: iter 32150 Ep: 11.91 loss 0.075 score 0.969 lr 2.24769e-05 
08/28/2020 17:04:09 - INFO - volta.utils -   [NLVR2]: iter 32170 Ep: 11.92 loss 0.129 score 0.955 lr 2.24564e-05 
08/28/2020 17:04:17 - INFO - volta.utils -   [NLVR2]: iter 32190 Ep: 11.93 loss 0.085 score 0.977 lr 2.24358e-05 
08/28/2020 17:04:26 - INFO - volta.utils -   [NLVR2]: iter 32210 Ep: 11.93 loss 0.077 score 0.967 lr 2.24152e-05 
08/28/2020 17:04:33 - INFO - volta.utils -   [NLVR2]: iter 32230 Ep: 11.94 loss 0.056 score 0.991 lr 2.23946e-05 
08/28/2020 17:04:42 - INFO - volta.utils -   [NLVR2]: iter 32250 Ep: 11.95 loss 0.072 score 0.977 lr 2.2374e-05 
08/28/2020 17:04:51 - INFO - volta.utils -   [NLVR2]: iter 32270 Ep: 11.96 loss 0.081 score 0.970 lr 2.23534e-05 
08/28/2020 17:05:00 - INFO - volta.utils -   [NLVR2]: iter 32290 Ep: 11.96 loss 0.080 score 0.970 lr 2.23329e-05 
08/28/2020 17:05:09 - INFO - volta.utils -   [NLVR2]: iter 32310 Ep: 11.97 loss 0.078 score 0.977 lr 2.23123e-05 
08/28/2020 17:05:17 - INFO - volta.utils -   [NLVR2]: iter 32330 Ep: 11.98 loss 0.067 score 0.980 lr 2.22917e-05 
08/28/2020 17:05:25 - INFO - volta.utils -   [NLVR2]: iter 32350 Ep: 11.99 loss 0.067 score 0.970 lr 2.22711e-05 
08/28/2020 17:05:33 - INFO - volta.utils -   [NLVR2]: iter 32370 Ep: 11.99 loss 0.043 score 0.986 lr 2.22505e-05 
08/28/2020 17:05:40 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  11%|█         | 1/9 [31:03<4:08:24, 1863.05s/it]08/28/2020 17:08:08 - INFO - volta.utils -   Eval task TASK12 on iteration 32389 
08/28/2020 17:08:08 - INFO - volta.utils -   Validation [NLVR2]: loss 1.343 score 70.370 
08/28/2020 17:08:16 - INFO - volta.utils -   [NLVR2]: iter 32409 Ep: 12.01 loss 0.057 score 0.979 lr 2.22202e-05 
08/28/2020 17:08:24 - INFO - volta.utils -   [NLVR2]: iter 32429 Ep: 12.02 loss 0.054 score 0.978 lr 2.21898e-05 
08/28/2020 17:08:32 - INFO - volta.utils -   [NLVR2]: iter 32449 Ep: 12.02 loss 0.025 score 0.992 lr 2.21692e-05 
08/28/2020 17:08:41 - INFO - volta.utils -   [NLVR2]: iter 32469 Ep: 12.03 loss 0.040 score 0.984 lr 2.21486e-05 
08/28/2020 17:08:48 - INFO - volta.utils -   [NLVR2]: iter 32489 Ep: 12.04 loss 0.065 score 0.983 lr 2.21281e-05 
08/28/2020 17:08:57 - INFO - volta.utils -   [NLVR2]: iter 32509 Ep: 12.04 loss 0.036 score 0.988 lr 2.21075e-05 
08/28/2020 17:09:05 - INFO - volta.utils -   [NLVR2]: iter 32529 Ep: 12.05 loss 0.066 score 0.980 lr 2.20869e-05 
08/28/2020 17:09:13 - INFO - volta.utils -   [NLVR2]: iter 32549 Ep: 12.06 loss 0.052 score 0.983 lr 2.20663e-05 
08/28/2020 17:09:21 - INFO - volta.utils -   [NLVR2]: iter 32569 Ep: 12.07 loss 0.034 score 0.986 lr 2.20457e-05 
08/28/2020 17:09:30 - INFO - volta.utils -   [NLVR2]: iter 32589 Ep: 12.07 loss 0.058 score 0.980 lr 2.20251e-05 
08/28/2020 17:09:37 - INFO - volta.utils -   [NLVR2]: iter 32609 Ep: 12.08 loss 0.030 score 0.991 lr 2.20045e-05 
08/28/2020 17:09:46 - INFO - volta.utils -   [NLVR2]: iter 32629 Ep: 12.09 loss 0.040 score 0.986 lr 2.1984e-05 
08/28/2020 17:09:54 - INFO - volta.utils -   [NLVR2]: iter 32649 Ep: 12.10 loss 0.040 score 0.981 lr 2.19634e-05 
08/28/2020 17:10:02 - INFO - volta.utils -   [NLVR2]: iter 32669 Ep: 12.10 loss 0.053 score 0.980 lr 2.19428e-05 
08/28/2020 17:10:10 - INFO - volta.utils -   [NLVR2]: iter 32689 Ep: 12.11 loss 0.043 score 0.986 lr 2.19222e-05 
08/28/2020 17:10:19 - INFO - volta.utils -   [NLVR2]: iter 32709 Ep: 12.12 loss 0.046 score 0.983 lr 2.19016e-05 
08/28/2020 17:10:27 - INFO - volta.utils -   [NLVR2]: iter 32729 Ep: 12.13 loss 0.043 score 0.983 lr 2.1881e-05 
08/28/2020 17:10:35 - INFO - volta.utils -   [NLVR2]: iter 32749 Ep: 12.13 loss 0.035 score 0.991 lr 2.18605e-05 
08/28/2020 17:10:43 - INFO - volta.utils -   [NLVR2]: iter 32769 Ep: 12.14 loss 0.033 score 0.991 lr 2.18399e-05 
08/28/2020 17:10:52 - INFO - volta.utils -   [NLVR2]: iter 32789 Ep: 12.15 loss 0.033 score 0.988 lr 2.18193e-05 
08/28/2020 17:11:00 - INFO - volta.utils -   [NLVR2]: iter 32809 Ep: 12.16 loss 0.075 score 0.980 lr 2.17987e-05 
08/28/2020 17:11:09 - INFO - volta.utils -   [NLVR2]: iter 32829 Ep: 12.16 loss 0.037 score 0.986 lr 2.17781e-05 
08/28/2020 17:11:17 - INFO - volta.utils -   [NLVR2]: iter 32849 Ep: 12.17 loss 0.052 score 0.986 lr 2.17575e-05 
08/28/2020 17:11:25 - INFO - volta.utils -   [NLVR2]: iter 32869 Ep: 12.18 loss 0.031 score 0.988 lr 2.1737e-05 
08/28/2020 17:11:33 - INFO - volta.utils -   [NLVR2]: iter 32889 Ep: 12.19 loss 0.054 score 0.978 lr 2.17164e-05 
08/28/2020 17:11:42 - INFO - volta.utils -   [NLVR2]: iter 32909 Ep: 12.19 loss 0.033 score 0.988 lr 2.16958e-05 
08/28/2020 17:11:49 - INFO - volta.utils -   [NLVR2]: iter 32929 Ep: 12.20 loss 0.043 score 0.989 lr 2.16752e-05 
08/28/2020 17:11:57 - INFO - volta.utils -   [NLVR2]: iter 32949 Ep: 12.21 loss 0.051 score 0.981 lr 2.16546e-05 
08/28/2020 17:12:05 - INFO - volta.utils -   [NLVR2]: iter 32969 Ep: 12.22 loss 0.033 score 0.988 lr 2.1634e-05 
08/28/2020 17:12:13 - INFO - volta.utils -   [NLVR2]: iter 32989 Ep: 12.22 loss 0.044 score 0.980 lr 2.16135e-05 
08/28/2020 17:12:22 - INFO - volta.utils -   [NLVR2]: iter 33009 Ep: 12.23 loss 0.044 score 0.986 lr 2.15929e-05 
08/28/2020 17:12:29 - INFO - volta.utils -   [NLVR2]: iter 33029 Ep: 12.24 loss 0.037 score 0.992 lr 2.15723e-05 
08/28/2020 17:12:38 - INFO - volta.utils -   [NLVR2]: iter 33049 Ep: 12.24 loss 0.024 score 0.992 lr 2.15517e-05 
08/28/2020 17:12:45 - INFO - volta.utils -   [NLVR2]: iter 33069 Ep: 12.25 loss 0.042 score 0.988 lr 2.15311e-05 
08/28/2020 17:12:54 - INFO - volta.utils -   [NLVR2]: iter 33089 Ep: 12.26 loss 0.053 score 0.988 lr 2.15105e-05 
08/28/2020 17:13:02 - INFO - volta.utils -   [NLVR2]: iter 33109 Ep: 12.27 loss 0.038 score 0.989 lr 2.149e-05 
08/28/2020 17:13:10 - INFO - volta.utils -   [NLVR2]: iter 33129 Ep: 12.27 loss 0.066 score 0.980 lr 2.14694e-05 
08/28/2020 17:13:18 - INFO - volta.utils -   [NLVR2]: iter 33149 Ep: 12.28 loss 0.045 score 0.988 lr 2.14488e-05 
08/28/2020 17:13:26 - INFO - volta.utils -   [NLVR2]: iter 33169 Ep: 12.29 loss 0.062 score 0.978 lr 2.14282e-05 
08/28/2020 17:13:34 - INFO - volta.utils -   [NLVR2]: iter 33189 Ep: 12.30 loss 0.035 score 0.988 lr 2.14076e-05 
08/28/2020 17:13:43 - INFO - volta.utils -   [NLVR2]: iter 33209 Ep: 12.30 loss 0.026 score 0.991 lr 2.1387e-05 
08/28/2020 17:13:50 - INFO - volta.utils -   [NLVR2]: iter 33229 Ep: 12.31 loss 0.049 score 0.981 lr 2.13665e-05 
08/28/2020 17:13:59 - INFO - volta.utils -   [NLVR2]: iter 33249 Ep: 12.32 loss 0.046 score 0.981 lr 2.13459e-05 
08/28/2020 17:14:07 - INFO - volta.utils -   [NLVR2]: iter 33269 Ep: 12.33 loss 0.035 score 0.989 lr 2.13253e-05 
08/28/2020 17:14:15 - INFO - volta.utils -   [NLVR2]: iter 33289 Ep: 12.33 loss 0.039 score 0.989 lr 2.13047e-05 
08/28/2020 17:14:23 - INFO - volta.utils -   [NLVR2]: iter 33309 Ep: 12.34 loss 0.043 score 0.988 lr 2.12841e-05 
08/28/2020 17:14:32 - INFO - volta.utils -   [NLVR2]: iter 33329 Ep: 12.35 loss 0.057 score 0.981 lr 2.12635e-05 
08/28/2020 17:14:39 - INFO - volta.utils -   [NLVR2]: iter 33349 Ep: 12.36 loss 0.051 score 0.989 lr 2.1243e-05 
08/28/2020 17:14:48 - INFO - volta.utils -   [NLVR2]: iter 33369 Ep: 12.36 loss 0.048 score 0.981 lr 2.12224e-05 
08/28/2020 17:14:56 - INFO - volta.utils -   [NLVR2]: iter 33389 Ep: 12.37 loss 0.062 score 0.981 lr 2.12018e-05 
08/28/2020 17:15:04 - INFO - volta.utils -   [NLVR2]: iter 33409 Ep: 12.38 loss 0.059 score 0.977 lr 2.11812e-05 
08/28/2020 17:15:12 - INFO - volta.utils -   [NLVR2]: iter 33429 Ep: 12.39 loss 0.040 score 0.986 lr 2.11606e-05 
08/28/2020 17:15:21 - INFO - volta.utils -   [NLVR2]: iter 33449 Ep: 12.39 loss 0.051 score 0.986 lr 2.114e-05 
08/28/2020 17:15:30 - INFO - volta.utils -   [NLVR2]: iter 33469 Ep: 12.40 loss 0.038 score 0.989 lr 2.11194e-05 
08/28/2020 17:15:39 - INFO - volta.utils -   [NLVR2]: iter 33489 Ep: 12.41 loss 0.044 score 0.986 lr 2.10989e-05 
08/28/2020 17:15:48 - INFO - volta.utils -   [NLVR2]: iter 33509 Ep: 12.42 loss 0.039 score 0.991 lr 2.10783e-05 
08/28/2020 17:15:57 - INFO - volta.utils -   [NLVR2]: iter 33529 Ep: 12.42 loss 0.030 score 0.991 lr 2.10577e-05 
08/28/2020 17:16:05 - INFO - volta.utils -   [NLVR2]: iter 33549 Ep: 12.43 loss 0.053 score 0.986 lr 2.10371e-05 
08/28/2020 17:16:14 - INFO - volta.utils -   [NLVR2]: iter 33569 Ep: 12.44 loss 0.042 score 0.984 lr 2.10165e-05 
08/28/2020 17:16:22 - INFO - volta.utils -   [NLVR2]: iter 33589 Ep: 12.44 loss 0.023 score 0.992 lr 2.09959e-05 
08/28/2020 17:16:30 - INFO - volta.utils -   [NLVR2]: iter 33609 Ep: 12.45 loss 0.064 score 0.983 lr 2.09754e-05 
08/28/2020 17:16:38 - INFO - volta.utils -   [NLVR2]: iter 33629 Ep: 12.46 loss 0.047 score 0.983 lr 2.09548e-05 
08/28/2020 17:16:46 - INFO - volta.utils -   [NLVR2]: iter 33649 Ep: 12.47 loss 0.074 score 0.978 lr 2.09342e-05 
08/28/2020 17:16:55 - INFO - volta.utils -   [NLVR2]: iter 33669 Ep: 12.47 loss 0.029 score 0.991 lr 2.09136e-05 
08/28/2020 17:17:03 - INFO - volta.utils -   [NLVR2]: iter 33689 Ep: 12.48 loss 0.040 score 0.988 lr 2.0893e-05 
08/28/2020 17:17:12 - INFO - volta.utils -   [NLVR2]: iter 33709 Ep: 12.49 loss 0.066 score 0.984 lr 2.08724e-05 
08/28/2020 17:17:19 - INFO - volta.utils -   [NLVR2]: iter 33729 Ep: 12.50 loss 0.060 score 0.984 lr 2.08519e-05 
08/28/2020 17:17:28 - INFO - volta.utils -   [NLVR2]: iter 33749 Ep: 12.50 loss 0.066 score 0.983 lr 2.08313e-05 
08/28/2020 17:17:36 - INFO - volta.utils -   [NLVR2]: iter 33769 Ep: 12.51 loss 0.072 score 0.967 lr 2.08107e-05 
08/28/2020 17:17:45 - INFO - volta.utils -   [NLVR2]: iter 33789 Ep: 12.52 loss 0.030 score 0.989 lr 2.07901e-05 
08/28/2020 17:17:53 - INFO - volta.utils -   [NLVR2]: iter 33809 Ep: 12.53 loss 0.075 score 0.977 lr 2.07695e-05 
08/28/2020 17:18:01 - INFO - volta.utils -   [NLVR2]: iter 33829 Ep: 12.53 loss 0.052 score 0.981 lr 2.07489e-05 
08/28/2020 17:18:09 - INFO - volta.utils -   [NLVR2]: iter 33849 Ep: 12.54 loss 0.056 score 0.986 lr 2.07284e-05 
08/28/2020 17:18:18 - INFO - volta.utils -   [NLVR2]: iter 33869 Ep: 12.55 loss 0.058 score 0.978 lr 2.07078e-05 
08/28/2020 17:18:25 - INFO - volta.utils -   [NLVR2]: iter 33889 Ep: 12.56 loss 0.054 score 0.983 lr 2.06872e-05 
08/28/2020 17:18:34 - INFO - volta.utils -   [NLVR2]: iter 33909 Ep: 12.56 loss 0.069 score 0.978 lr 2.06666e-05 
08/28/2020 17:18:41 - INFO - volta.utils -   [NLVR2]: iter 33929 Ep: 12.57 loss 0.039 score 0.984 lr 2.0646e-05 
08/28/2020 17:18:50 - INFO - volta.utils -   [NLVR2]: iter 33949 Ep: 12.58 loss 0.055 score 0.981 lr 2.06254e-05 
08/28/2020 17:18:57 - INFO - volta.utils -   [NLVR2]: iter 33969 Ep: 12.59 loss 0.042 score 0.981 lr 2.06049e-05 
08/28/2020 17:19:06 - INFO - volta.utils -   [NLVR2]: iter 33989 Ep: 12.59 loss 0.035 score 0.988 lr 2.05843e-05 
08/28/2020 17:19:14 - INFO - volta.utils -   [NLVR2]: iter 34009 Ep: 12.60 loss 0.046 score 0.980 lr 2.05637e-05 
08/28/2020 17:19:22 - INFO - volta.utils -   [NLVR2]: iter 34029 Ep: 12.61 loss 0.043 score 0.978 lr 2.05431e-05 
08/28/2020 17:19:30 - INFO - volta.utils -   [NLVR2]: iter 34049 Ep: 12.62 loss 0.061 score 0.981 lr 2.05225e-05 
08/28/2020 17:19:38 - INFO - volta.utils -   [NLVR2]: iter 34069 Ep: 12.62 loss 0.066 score 0.983 lr 2.05019e-05 
08/28/2020 17:19:46 - INFO - volta.utils -   [NLVR2]: iter 34089 Ep: 12.63 loss 0.056 score 0.984 lr 2.04814e-05 
08/28/2020 17:19:55 - INFO - volta.utils -   [NLVR2]: iter 34109 Ep: 12.64 loss 0.059 score 0.984 lr 2.04608e-05 
08/28/2020 17:20:03 - INFO - volta.utils -   [NLVR2]: iter 34129 Ep: 12.65 loss 0.066 score 0.977 lr 2.04402e-05 
08/28/2020 17:20:12 - INFO - volta.utils -   [NLVR2]: iter 34149 Ep: 12.65 loss 0.043 score 0.989 lr 2.04196e-05 
08/28/2020 17:20:20 - INFO - volta.utils -   [NLVR2]: iter 34169 Ep: 12.66 loss 0.061 score 0.973 lr 2.0399e-05 
08/28/2020 17:20:29 - INFO - volta.utils -   [NLVR2]: iter 34189 Ep: 12.67 loss 0.036 score 0.994 lr 2.03784e-05 
08/28/2020 17:20:37 - INFO - volta.utils -   [NLVR2]: iter 34209 Ep: 12.67 loss 0.042 score 0.983 lr 2.03578e-05 
08/28/2020 17:20:46 - INFO - volta.utils -   [NLVR2]: iter 34229 Ep: 12.68 loss 0.072 score 0.973 lr 2.03373e-05 
08/28/2020 17:20:53 - INFO - volta.utils -   [NLVR2]: iter 34249 Ep: 12.69 loss 0.055 score 0.980 lr 2.03167e-05 
08/28/2020 17:21:02 - INFO - volta.utils -   [NLVR2]: iter 34269 Ep: 12.70 loss 0.038 score 0.989 lr 2.02961e-05 
08/28/2020 17:21:09 - INFO - volta.utils -   [NLVR2]: iter 34289 Ep: 12.70 loss 0.019 score 0.992 lr 2.02755e-05 
08/28/2020 17:21:18 - INFO - volta.utils -   [NLVR2]: iter 34309 Ep: 12.71 loss 0.036 score 0.988 lr 2.02549e-05 
08/28/2020 17:21:25 - INFO - volta.utils -   [NLVR2]: iter 34329 Ep: 12.72 loss 0.050 score 0.983 lr 2.02343e-05 
08/28/2020 17:21:34 - INFO - volta.utils -   [NLVR2]: iter 34349 Ep: 12.73 loss 0.042 score 0.991 lr 2.02138e-05 
08/28/2020 17:21:42 - INFO - volta.utils -   [NLVR2]: iter 34369 Ep: 12.73 loss 0.039 score 0.989 lr 2.01932e-05 
08/28/2020 17:21:49 - INFO - volta.utils -   [NLVR2]: iter 34389 Ep: 12.74 loss 0.048 score 0.981 lr 2.01726e-05 
08/28/2020 17:21:58 - INFO - volta.utils -   [NLVR2]: iter 34409 Ep: 12.75 loss 0.055 score 0.984 lr 2.0152e-05 
08/28/2020 17:22:05 - INFO - volta.utils -   [NLVR2]: iter 34429 Ep: 12.76 loss 0.029 score 0.986 lr 2.01314e-05 
08/28/2020 17:22:14 - INFO - volta.utils -   [NLVR2]: iter 34449 Ep: 12.76 loss 0.065 score 0.977 lr 2.01108e-05 
08/28/2020 17:22:22 - INFO - volta.utils -   [NLVR2]: iter 34469 Ep: 12.77 loss 0.074 score 0.975 lr 2.00903e-05 
08/28/2020 17:22:30 - INFO - volta.utils -   [NLVR2]: iter 34489 Ep: 12.78 loss 0.058 score 0.983 lr 2.00697e-05 
08/28/2020 17:22:38 - INFO - volta.utils -   [NLVR2]: iter 34509 Ep: 12.79 loss 0.048 score 0.983 lr 2.00491e-05 
08/28/2020 17:22:46 - INFO - volta.utils -   [NLVR2]: iter 34529 Ep: 12.79 loss 0.063 score 0.980 lr 2.00285e-05 
08/28/2020 17:22:54 - INFO - volta.utils -   [NLVR2]: iter 34549 Ep: 12.80 loss 0.043 score 0.989 lr 2.00079e-05 
08/28/2020 17:23:02 - INFO - volta.utils -   [NLVR2]: iter 34569 Ep: 12.81 loss 0.053 score 0.983 lr 1.99873e-05 
08/28/2020 17:23:10 - INFO - volta.utils -   [NLVR2]: iter 34589 Ep: 12.82 loss 0.076 score 0.973 lr 1.99668e-05 
08/28/2020 17:23:19 - INFO - volta.utils -   [NLVR2]: iter 34609 Ep: 12.82 loss 0.062 score 0.977 lr 1.99462e-05 
08/28/2020 17:23:26 - INFO - volta.utils -   [NLVR2]: iter 34629 Ep: 12.83 loss 0.063 score 0.978 lr 1.99256e-05 
08/28/2020 17:23:35 - INFO - volta.utils -   [NLVR2]: iter 34649 Ep: 12.84 loss 0.046 score 0.983 lr 1.9905e-05 
08/28/2020 17:23:43 - INFO - volta.utils -   [NLVR2]: iter 34669 Ep: 12.85 loss 0.043 score 0.983 lr 1.98844e-05 
08/28/2020 17:23:51 - INFO - volta.utils -   [NLVR2]: iter 34689 Ep: 12.85 loss 0.041 score 0.983 lr 1.98638e-05 
08/28/2020 17:23:59 - INFO - volta.utils -   [NLVR2]: iter 34709 Ep: 12.86 loss 0.042 score 0.989 lr 1.98433e-05 
08/28/2020 17:24:08 - INFO - volta.utils -   [NLVR2]: iter 34729 Ep: 12.87 loss 0.057 score 0.980 lr 1.98227e-05 
08/28/2020 17:24:15 - INFO - volta.utils -   [NLVR2]: iter 34749 Ep: 12.87 loss 0.050 score 0.986 lr 1.98021e-05 
08/28/2020 17:24:24 - INFO - volta.utils -   [NLVR2]: iter 34769 Ep: 12.88 loss 0.035 score 0.986 lr 1.97815e-05 
08/28/2020 17:24:31 - INFO - volta.utils -   [NLVR2]: iter 34789 Ep: 12.89 loss 0.054 score 0.984 lr 1.97609e-05 
08/28/2020 17:24:40 - INFO - volta.utils -   [NLVR2]: iter 34809 Ep: 12.90 loss 0.041 score 0.980 lr 1.97403e-05 
08/28/2020 17:24:48 - INFO - volta.utils -   [NLVR2]: iter 34829 Ep: 12.90 loss 0.050 score 0.984 lr 1.97198e-05 
08/28/2020 17:24:57 - INFO - volta.utils -   [NLVR2]: iter 34849 Ep: 12.91 loss 0.035 score 0.984 lr 1.96992e-05 
08/28/2020 17:25:05 - INFO - volta.utils -   [NLVR2]: iter 34869 Ep: 12.92 loss 0.039 score 0.988 lr 1.96786e-05 
08/28/2020 17:25:14 - INFO - volta.utils -   [NLVR2]: iter 34889 Ep: 12.93 loss 0.064 score 0.978 lr 1.9658e-05 
08/28/2020 17:25:21 - INFO - volta.utils -   [NLVR2]: iter 34909 Ep: 12.93 loss 0.034 score 0.988 lr 1.96374e-05 
08/28/2020 17:25:30 - INFO - volta.utils -   [NLVR2]: iter 34929 Ep: 12.94 loss 0.072 score 0.980 lr 1.96168e-05 
08/28/2020 17:25:38 - INFO - volta.utils -   [NLVR2]: iter 34949 Ep: 12.95 loss 0.045 score 0.980 lr 1.95962e-05 
08/28/2020 17:25:46 - INFO - volta.utils -   [NLVR2]: iter 34969 Ep: 12.96 loss 0.049 score 0.986 lr 1.95757e-05 
08/28/2020 17:25:54 - INFO - volta.utils -   [NLVR2]: iter 34989 Ep: 12.96 loss 0.053 score 0.983 lr 1.95551e-05 
08/28/2020 17:26:02 - INFO - volta.utils -   [NLVR2]: iter 35009 Ep: 12.97 loss 0.058 score 0.983 lr 1.95345e-05 
08/28/2020 17:26:10 - INFO - volta.utils -   [NLVR2]: iter 35029 Ep: 12.98 loss 0.050 score 0.980 lr 1.95139e-05 
08/28/2020 17:26:19 - INFO - volta.utils -   [NLVR2]: iter 35049 Ep: 12.99 loss 0.070 score 0.975 lr 1.94933e-05 
08/28/2020 17:26:26 - INFO - volta.utils -   [NLVR2]: iter 35069 Ep: 12.99 loss 0.065 score 0.980 lr 1.94727e-05 
08/28/2020 17:26:34 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  22%|██▏       | 2/9 [51:52<3:15:51, 1678.83s/it]08/28/2020 17:27:24 - INFO - volta.utils -   Eval task TASK12 on iteration 35088 
08/28/2020 17:27:24 - INFO - volta.utils -   Validation [NLVR2]: loss 1.324 score 69.409 
08/28/2020 17:27:33 - INFO - volta.utils -   [NLVR2]: iter 35108 Ep: 13.01 loss 0.048 score 0.980 lr 1.94424e-05 
08/28/2020 17:27:41 - INFO - volta.utils -   [NLVR2]: iter 35128 Ep: 13.02 loss 0.058 score 0.983 lr 1.9412e-05 
08/28/2020 17:27:50 - INFO - volta.utils -   [NLVR2]: iter 35148 Ep: 13.02 loss 0.041 score 0.984 lr 1.93914e-05 
08/28/2020 17:27:57 - INFO - volta.utils -   [NLVR2]: iter 35168 Ep: 13.03 loss 0.035 score 0.989 lr 1.93709e-05 
08/28/2020 17:28:06 - INFO - volta.utils -   [NLVR2]: iter 35188 Ep: 13.04 loss 0.030 score 0.991 lr 1.93503e-05 
08/28/2020 17:28:14 - INFO - volta.utils -   [NLVR2]: iter 35208 Ep: 13.04 loss 0.040 score 0.986 lr 1.93297e-05 
08/28/2020 17:28:22 - INFO - volta.utils -   [NLVR2]: iter 35228 Ep: 13.05 loss 0.021 score 0.994 lr 1.93091e-05 
08/28/2020 17:28:30 - INFO - volta.utils -   [NLVR2]: iter 35248 Ep: 13.06 loss 0.020 score 0.992 lr 1.92885e-05 
08/28/2020 17:28:38 - INFO - volta.utils -   [NLVR2]: iter 35268 Ep: 13.07 loss 0.027 score 0.989 lr 1.92679e-05 
08/28/2020 17:28:46 - INFO - volta.utils -   [NLVR2]: iter 35288 Ep: 13.07 loss 0.046 score 0.983 lr 1.92474e-05 
08/28/2020 17:28:55 - INFO - volta.utils -   [NLVR2]: iter 35308 Ep: 13.08 loss 0.022 score 0.997 lr 1.92268e-05 
08/28/2020 17:29:03 - INFO - volta.utils -   [NLVR2]: iter 35328 Ep: 13.09 loss 0.027 score 0.991 lr 1.92062e-05 
08/28/2020 17:29:11 - INFO - volta.utils -   [NLVR2]: iter 35348 Ep: 13.10 loss 0.027 score 0.989 lr 1.91856e-05 
08/28/2020 17:29:19 - INFO - volta.utils -   [NLVR2]: iter 35368 Ep: 13.10 loss 0.036 score 0.989 lr 1.9165e-05 
08/28/2020 17:29:28 - INFO - volta.utils -   [NLVR2]: iter 35388 Ep: 13.11 loss 0.050 score 0.986 lr 1.91444e-05 
08/28/2020 17:29:36 - INFO - volta.utils -   [NLVR2]: iter 35408 Ep: 13.12 loss 0.035 score 0.991 lr 1.91239e-05 
08/28/2020 17:29:44 - INFO - volta.utils -   [NLVR2]: iter 35428 Ep: 13.13 loss 0.023 score 0.991 lr 1.91033e-05 
08/28/2020 17:29:52 - INFO - volta.utils -   [NLVR2]: iter 35448 Ep: 13.13 loss 0.035 score 0.992 lr 1.90827e-05 
08/28/2020 17:30:00 - INFO - volta.utils -   [NLVR2]: iter 35468 Ep: 13.14 loss 0.026 score 0.991 lr 1.90621e-05 
08/28/2020 17:30:08 - INFO - volta.utils -   [NLVR2]: iter 35488 Ep: 13.15 loss 0.033 score 0.991 lr 1.90415e-05 
08/28/2020 17:30:15 - INFO - volta.utils -   [NLVR2]: iter 35508 Ep: 13.16 loss 0.049 score 0.988 lr 1.90209e-05 
08/28/2020 17:30:24 - INFO - volta.utils -   [NLVR2]: iter 35528 Ep: 13.16 loss 0.033 score 0.988 lr 1.90003e-05 
08/28/2020 17:30:31 - INFO - volta.utils -   [NLVR2]: iter 35548 Ep: 13.17 loss 0.049 score 0.986 lr 1.89798e-05 
08/28/2020 17:30:40 - INFO - volta.utils -   [NLVR2]: iter 35568 Ep: 13.18 loss 0.011 score 0.994 lr 1.89592e-05 
08/28/2020 17:30:48 - INFO - volta.utils -   [NLVR2]: iter 35588 Ep: 13.19 loss 0.013 score 0.992 lr 1.89386e-05 
08/28/2020 17:30:57 - INFO - volta.utils -   [NLVR2]: iter 35608 Ep: 13.19 loss 0.029 score 0.989 lr 1.8918e-05 
08/28/2020 17:31:05 - INFO - volta.utils -   [NLVR2]: iter 35628 Ep: 13.20 loss 0.031 score 0.989 lr 1.88974e-05 
08/28/2020 17:31:14 - INFO - volta.utils -   [NLVR2]: iter 35648 Ep: 13.21 loss 0.015 score 0.995 lr 1.88768e-05 
08/28/2020 17:31:22 - INFO - volta.utils -   [NLVR2]: iter 35668 Ep: 13.22 loss 0.020 score 0.994 lr 1.88563e-05 
08/28/2020 17:31:30 - INFO - volta.utils -   [NLVR2]: iter 35688 Ep: 13.22 loss 0.028 score 0.994 lr 1.88357e-05 
08/28/2020 17:31:37 - INFO - volta.utils -   [NLVR2]: iter 35708 Ep: 13.23 loss 0.032 score 0.988 lr 1.88151e-05 
08/28/2020 17:31:46 - INFO - volta.utils -   [NLVR2]: iter 35728 Ep: 13.24 loss 0.027 score 0.992 lr 1.87945e-05 
08/28/2020 17:31:53 - INFO - volta.utils -   [NLVR2]: iter 35748 Ep: 13.24 loss 0.046 score 0.984 lr 1.87739e-05 
08/28/2020 17:32:02 - INFO - volta.utils -   [NLVR2]: iter 35768 Ep: 13.25 loss 0.019 score 0.994 lr 1.87533e-05 
08/28/2020 17:32:09 - INFO - volta.utils -   [NLVR2]: iter 35788 Ep: 13.26 loss 0.040 score 0.991 lr 1.87328e-05 
08/28/2020 17:32:17 - INFO - volta.utils -   [NLVR2]: iter 35808 Ep: 13.27 loss 0.059 score 0.983 lr 1.87122e-05 
08/28/2020 17:32:25 - INFO - volta.utils -   [NLVR2]: iter 35828 Ep: 13.27 loss 0.033 score 0.988 lr 1.86916e-05 
08/28/2020 17:32:33 - INFO - volta.utils -   [NLVR2]: iter 35848 Ep: 13.28 loss 0.010 score 0.997 lr 1.8671e-05 
08/28/2020 17:32:41 - INFO - volta.utils -   [NLVR2]: iter 35868 Ep: 13.29 loss 0.032 score 0.992 lr 1.86504e-05 
08/28/2020 17:32:49 - INFO - volta.utils -   [NLVR2]: iter 35888 Ep: 13.30 loss 0.041 score 0.984 lr 1.86298e-05 
08/28/2020 17:32:56 - INFO - volta.utils -   [NLVR2]: iter 35908 Ep: 13.30 loss 0.043 score 0.986 lr 1.86093e-05 
08/28/2020 17:33:05 - INFO - volta.utils -   [NLVR2]: iter 35928 Ep: 13.31 loss 0.036 score 0.986 lr 1.85887e-05 
08/28/2020 17:33:12 - INFO - volta.utils -   [NLVR2]: iter 35948 Ep: 13.32 loss 0.052 score 0.983 lr 1.85681e-05 
08/28/2020 17:33:21 - INFO - volta.utils -   [NLVR2]: iter 35968 Ep: 13.33 loss 0.056 score 0.984 lr 1.85475e-05 
08/28/2020 17:33:28 - INFO - volta.utils -   [NLVR2]: iter 35988 Ep: 13.33 loss 0.043 score 0.984 lr 1.85269e-05 
08/28/2020 17:33:36 - INFO - volta.utils -   [NLVR2]: iter 36008 Ep: 13.34 loss 0.057 score 0.973 lr 1.85063e-05 
08/28/2020 17:33:44 - INFO - volta.utils -   [NLVR2]: iter 36028 Ep: 13.35 loss 0.030 score 0.991 lr 1.84858e-05 
08/28/2020 17:33:53 - INFO - volta.utils -   [NLVR2]: iter 36048 Ep: 13.36 loss 0.031 score 0.992 lr 1.84652e-05 
08/28/2020 17:34:00 - INFO - volta.utils -   [NLVR2]: iter 36068 Ep: 13.36 loss 0.032 score 0.988 lr 1.84446e-05 
08/28/2020 17:34:09 - INFO - volta.utils -   [NLVR2]: iter 36088 Ep: 13.37 loss 0.054 score 0.980 lr 1.8424e-05 
08/28/2020 17:34:17 - INFO - volta.utils -   [NLVR2]: iter 36108 Ep: 13.38 loss 0.033 score 0.991 lr 1.84034e-05 
08/28/2020 17:34:26 - INFO - volta.utils -   [NLVR2]: iter 36128 Ep: 13.39 loss 0.034 score 0.989 lr 1.83828e-05 
08/28/2020 17:34:33 - INFO - volta.utils -   [NLVR2]: iter 36148 Ep: 13.39 loss 0.032 score 0.989 lr 1.83623e-05 
08/28/2020 17:34:42 - INFO - volta.utils -   [NLVR2]: iter 36168 Ep: 13.40 loss 0.038 score 0.992 lr 1.83417e-05 
08/28/2020 17:34:49 - INFO - volta.utils -   [NLVR2]: iter 36188 Ep: 13.41 loss 0.038 score 0.984 lr 1.83211e-05 
08/28/2020 17:34:57 - INFO - volta.utils -   [NLVR2]: iter 36208 Ep: 13.42 loss 0.030 score 0.991 lr 1.83005e-05 
08/28/2020 17:35:05 - INFO - volta.utils -   [NLVR2]: iter 36228 Ep: 13.42 loss 0.033 score 0.989 lr 1.82799e-05 
08/28/2020 17:35:12 - INFO - volta.utils -   [NLVR2]: iter 36248 Ep: 13.43 loss 0.045 score 0.984 lr 1.82593e-05 
08/28/2020 17:35:21 - INFO - volta.utils -   [NLVR2]: iter 36268 Ep: 13.44 loss 0.039 score 0.991 lr 1.82388e-05 
08/28/2020 17:35:28 - INFO - volta.utils -   [NLVR2]: iter 36288 Ep: 13.44 loss 0.020 score 0.995 lr 1.82182e-05 
08/28/2020 17:35:37 - INFO - volta.utils -   [NLVR2]: iter 36308 Ep: 13.45 loss 0.021 score 0.995 lr 1.81976e-05 
08/28/2020 17:35:44 - INFO - volta.utils -   [NLVR2]: iter 36328 Ep: 13.46 loss 0.034 score 0.984 lr 1.8177e-05 
08/28/2020 17:35:52 - INFO - volta.utils -   [NLVR2]: iter 36348 Ep: 13.47 loss 0.026 score 0.991 lr 1.81564e-05 
08/28/2020 17:36:00 - INFO - volta.utils -   [NLVR2]: iter 36368 Ep: 13.47 loss 0.029 score 0.991 lr 1.81358e-05 
08/28/2020 17:36:08 - INFO - volta.utils -   [NLVR2]: iter 36388 Ep: 13.48 loss 0.021 score 0.997 lr 1.81152e-05 
08/28/2020 17:36:16 - INFO - volta.utils -   [NLVR2]: iter 36408 Ep: 13.49 loss 0.029 score 0.988 lr 1.80947e-05 
08/28/2020 17:36:25 - INFO - volta.utils -   [NLVR2]: iter 36428 Ep: 13.50 loss 0.050 score 0.986 lr 1.80741e-05 
08/28/2020 17:36:33 - INFO - volta.utils -   [NLVR2]: iter 36448 Ep: 13.50 loss 0.037 score 0.988 lr 1.80535e-05 
08/28/2020 17:36:41 - INFO - volta.utils -   [NLVR2]: iter 36468 Ep: 13.51 loss 0.055 score 0.983 lr 1.80329e-05 
08/28/2020 17:36:49 - INFO - volta.utils -   [NLVR2]: iter 36488 Ep: 13.52 loss 0.031 score 0.989 lr 1.80123e-05 
08/28/2020 17:36:58 - INFO - volta.utils -   [NLVR2]: iter 36508 Ep: 13.53 loss 0.051 score 0.984 lr 1.79917e-05 
08/28/2020 17:37:06 - INFO - volta.utils -   [NLVR2]: iter 36528 Ep: 13.53 loss 0.042 score 0.989 lr 1.79712e-05 
08/28/2020 17:37:14 - INFO - volta.utils -   [NLVR2]: iter 36548 Ep: 13.54 loss 0.029 score 0.992 lr 1.79506e-05 
08/28/2020 17:37:22 - INFO - volta.utils -   [NLVR2]: iter 36568 Ep: 13.55 loss 0.045 score 0.984 lr 1.793e-05 
08/28/2020 17:37:31 - INFO - volta.utils -   [NLVR2]: iter 36588 Ep: 13.56 loss 0.031 score 0.991 lr 1.79094e-05 
08/28/2020 17:37:38 - INFO - volta.utils -   [NLVR2]: iter 36608 Ep: 13.56 loss 0.027 score 0.992 lr 1.78888e-05 
08/28/2020 17:37:47 - INFO - volta.utils -   [NLVR2]: iter 36628 Ep: 13.57 loss 0.011 score 0.998 lr 1.78682e-05 
08/28/2020 17:37:54 - INFO - volta.utils -   [NLVR2]: iter 36648 Ep: 13.58 loss 0.036 score 0.991 lr 1.78477e-05 
08/28/2020 17:38:03 - INFO - volta.utils -   [NLVR2]: iter 36668 Ep: 13.59 loss 0.026 score 0.992 lr 1.78271e-05 
08/28/2020 17:38:10 - INFO - volta.utils -   [NLVR2]: iter 36688 Ep: 13.59 loss 0.027 score 0.992 lr 1.78065e-05 
08/28/2020 17:38:19 - INFO - volta.utils -   [NLVR2]: iter 36708 Ep: 13.60 loss 0.017 score 0.992 lr 1.77859e-05 
08/28/2020 17:38:26 - INFO - volta.utils -   [NLVR2]: iter 36728 Ep: 13.61 loss 0.046 score 0.986 lr 1.77653e-05 
08/28/2020 17:38:34 - INFO - volta.utils -   [NLVR2]: iter 36748 Ep: 13.62 loss 0.027 score 0.991 lr 1.77447e-05 
08/28/2020 17:38:42 - INFO - volta.utils -   [NLVR2]: iter 36768 Ep: 13.62 loss 0.043 score 0.992 lr 1.77242e-05 
08/28/2020 17:38:51 - INFO - volta.utils -   [NLVR2]: iter 36788 Ep: 13.63 loss 0.052 score 0.986 lr 1.77036e-05 
08/28/2020 17:38:59 - INFO - volta.utils -   [NLVR2]: iter 36808 Ep: 13.64 loss 0.033 score 0.989 lr 1.7683e-05 
08/28/2020 17:39:07 - INFO - volta.utils -   [NLVR2]: iter 36828 Ep: 13.65 loss 0.063 score 0.977 lr 1.76624e-05 
08/28/2020 17:39:15 - INFO - volta.utils -   [NLVR2]: iter 36848 Ep: 13.65 loss 0.030 score 0.986 lr 1.76418e-05 
08/28/2020 17:39:24 - INFO - volta.utils -   [NLVR2]: iter 36868 Ep: 13.66 loss 0.020 score 0.995 lr 1.76212e-05 
08/28/2020 17:39:31 - INFO - volta.utils -   [NLVR2]: iter 36888 Ep: 13.67 loss 0.039 score 0.986 lr 1.76007e-05 
08/28/2020 17:39:40 - INFO - volta.utils -   [NLVR2]: iter 36908 Ep: 13.67 loss 0.055 score 0.984 lr 1.75801e-05 
08/28/2020 17:39:48 - INFO - volta.utils -   [NLVR2]: iter 36928 Ep: 13.68 loss 0.031 score 0.994 lr 1.75595e-05 
08/28/2020 17:39:55 - INFO - volta.utils -   [NLVR2]: iter 36948 Ep: 13.69 loss 0.029 score 0.991 lr 1.75389e-05 
08/28/2020 17:40:04 - INFO - volta.utils -   [NLVR2]: iter 36968 Ep: 13.70 loss 0.047 score 0.981 lr 1.75183e-05 
08/28/2020 17:40:12 - INFO - volta.utils -   [NLVR2]: iter 36988 Ep: 13.70 loss 0.027 score 0.986 lr 1.74977e-05 
08/28/2020 17:40:20 - INFO - volta.utils -   [NLVR2]: iter 37008 Ep: 13.71 loss 0.018 score 0.994 lr 1.74772e-05 
08/28/2020 17:40:28 - INFO - volta.utils -   [NLVR2]: iter 37028 Ep: 13.72 loss 0.035 score 0.991 lr 1.74566e-05 
08/28/2020 17:40:36 - INFO - volta.utils -   [NLVR2]: iter 37048 Ep: 13.73 loss 0.053 score 0.986 lr 1.7436e-05 
08/28/2020 17:40:44 - INFO - volta.utils -   [NLVR2]: iter 37068 Ep: 13.73 loss 0.034 score 0.986 lr 1.74154e-05 
08/28/2020 17:40:52 - INFO - volta.utils -   [NLVR2]: iter 37088 Ep: 13.74 loss 0.028 score 0.992 lr 1.73948e-05 
08/28/2020 17:41:00 - INFO - volta.utils -   [NLVR2]: iter 37108 Ep: 13.75 loss 0.041 score 0.983 lr 1.73742e-05 
08/28/2020 17:41:09 - INFO - volta.utils -   [NLVR2]: iter 37128 Ep: 13.76 loss 0.027 score 0.991 lr 1.73536e-05 
08/28/2020 17:41:16 - INFO - volta.utils -   [NLVR2]: iter 37148 Ep: 13.76 loss 0.057 score 0.981 lr 1.73331e-05 
08/28/2020 17:41:25 - INFO - volta.utils -   [NLVR2]: iter 37168 Ep: 13.77 loss 0.042 score 0.984 lr 1.73125e-05 
08/28/2020 17:41:33 - INFO - volta.utils -   [NLVR2]: iter 37188 Ep: 13.78 loss 0.024 score 0.992 lr 1.72919e-05 
08/28/2020 17:41:41 - INFO - volta.utils -   [NLVR2]: iter 37208 Ep: 13.79 loss 0.039 score 0.989 lr 1.72713e-05 
08/28/2020 17:41:49 - INFO - volta.utils -   [NLVR2]: iter 37228 Ep: 13.79 loss 0.041 score 0.986 lr 1.72507e-05 
08/28/2020 17:41:58 - INFO - volta.utils -   [NLVR2]: iter 37248 Ep: 13.80 loss 0.047 score 0.983 lr 1.72301e-05 
08/28/2020 17:42:05 - INFO - volta.utils -   [NLVR2]: iter 37268 Ep: 13.81 loss 0.049 score 0.989 lr 1.72096e-05 
08/28/2020 17:42:14 - INFO - volta.utils -   [NLVR2]: iter 37288 Ep: 13.82 loss 0.027 score 0.992 lr 1.7189e-05 
08/28/2020 17:42:22 - INFO - volta.utils -   [NLVR2]: iter 37308 Ep: 13.82 loss 0.031 score 0.988 lr 1.71684e-05 
08/28/2020 17:42:30 - INFO - volta.utils -   [NLVR2]: iter 37328 Ep: 13.83 loss 0.051 score 0.989 lr 1.71478e-05 
08/28/2020 17:42:38 - INFO - volta.utils -   [NLVR2]: iter 37348 Ep: 13.84 loss 0.020 score 0.991 lr 1.71272e-05 
08/28/2020 17:42:47 - INFO - volta.utils -   [NLVR2]: iter 37368 Ep: 13.85 loss 0.054 score 0.988 lr 1.71066e-05 
08/28/2020 17:42:55 - INFO - volta.utils -   [NLVR2]: iter 37388 Ep: 13.85 loss 0.021 score 0.992 lr 1.70861e-05 
08/28/2020 17:43:04 - INFO - volta.utils -   [NLVR2]: iter 37408 Ep: 13.86 loss 0.030 score 0.988 lr 1.70655e-05 
08/28/2020 17:43:11 - INFO - volta.utils -   [NLVR2]: iter 37428 Ep: 13.87 loss 0.066 score 0.977 lr 1.70449e-05 
08/28/2020 17:43:20 - INFO - volta.utils -   [NLVR2]: iter 37448 Ep: 13.87 loss 0.036 score 0.983 lr 1.70243e-05 
08/28/2020 17:43:28 - INFO - volta.utils -   [NLVR2]: iter 37468 Ep: 13.88 loss 0.041 score 0.983 lr 1.70037e-05 
08/28/2020 17:43:37 - INFO - volta.utils -   [NLVR2]: iter 37488 Ep: 13.89 loss 0.022 score 0.995 lr 1.69831e-05 
08/28/2020 17:43:45 - INFO - volta.utils -   [NLVR2]: iter 37508 Ep: 13.90 loss 0.013 score 0.994 lr 1.69626e-05 
08/28/2020 17:43:54 - INFO - volta.utils -   [NLVR2]: iter 37528 Ep: 13.90 loss 0.045 score 0.988 lr 1.6942e-05 
08/28/2020 17:44:01 - INFO - volta.utils -   [NLVR2]: iter 37548 Ep: 13.91 loss 0.039 score 0.988 lr 1.69214e-05 
08/28/2020 17:44:10 - INFO - volta.utils -   [NLVR2]: iter 37568 Ep: 13.92 loss 0.032 score 0.991 lr 1.69008e-05 
08/28/2020 17:44:18 - INFO - volta.utils -   [NLVR2]: iter 37588 Ep: 13.93 loss 0.050 score 0.984 lr 1.68802e-05 
08/28/2020 17:44:27 - INFO - volta.utils -   [NLVR2]: iter 37608 Ep: 13.93 loss 0.035 score 0.989 lr 1.68596e-05 
08/28/2020 17:44:35 - INFO - volta.utils -   [NLVR2]: iter 37628 Ep: 13.94 loss 0.041 score 0.986 lr 1.68391e-05 
08/28/2020 17:44:44 - INFO - volta.utils -   [NLVR2]: iter 37648 Ep: 13.95 loss 0.039 score 0.989 lr 1.68185e-05 
08/28/2020 17:44:52 - INFO - volta.utils -   [NLVR2]: iter 37668 Ep: 13.96 loss 0.047 score 0.984 lr 1.67979e-05 
08/28/2020 17:45:00 - INFO - volta.utils -   [NLVR2]: iter 37688 Ep: 13.96 loss 0.061 score 0.981 lr 1.67773e-05 
08/28/2020 17:45:09 - INFO - volta.utils -   [NLVR2]: iter 37708 Ep: 13.97 loss 0.031 score 0.989 lr 1.67567e-05 
08/28/2020 17:45:16 - INFO - volta.utils -   [NLVR2]: iter 37728 Ep: 13.98 loss 0.050 score 0.986 lr 1.67361e-05 
08/28/2020 17:45:25 - INFO - volta.utils -   [NLVR2]: iter 37748 Ep: 13.99 loss 0.036 score 0.989 lr 1.67156e-05 
08/28/2020 17:45:32 - INFO - volta.utils -   [NLVR2]: iter 37768 Ep: 13.99 loss 0.029 score 0.991 lr 1.6695e-05 
08/28/2020 17:45:40 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  33%|███▎      | 3/9 [1:10:58<2:31:54, 1519.02s/it]08/28/2020 17:46:30 - INFO - volta.utils -   Eval task TASK12 on iteration 37787 
08/28/2020 17:46:30 - INFO - volta.utils -   Validation [NLVR2]: loss 1.462 score 70.069 
08/28/2020 17:46:38 - INFO - volta.utils -   [NLVR2]: iter 37807 Ep: 14.01 loss 0.027 score 0.992 lr 1.66646e-05 
08/28/2020 17:46:47 - INFO - volta.utils -   [NLVR2]: iter 37827 Ep: 14.02 loss 0.036 score 0.991 lr 1.66342e-05 
08/28/2020 17:46:54 - INFO - volta.utils -   [NLVR2]: iter 37847 Ep: 14.02 loss 0.029 score 0.992 lr 1.66137e-05 
08/28/2020 17:47:02 - INFO - volta.utils -   [NLVR2]: iter 37867 Ep: 14.03 loss 0.018 score 0.995 lr 1.65931e-05 
08/28/2020 17:47:10 - INFO - volta.utils -   [NLVR2]: iter 37887 Ep: 14.04 loss 0.011 score 0.995 lr 1.65725e-05 
08/28/2020 17:47:18 - INFO - volta.utils -   [NLVR2]: iter 37907 Ep: 14.04 loss 0.023 score 0.995 lr 1.65519e-05 
08/28/2020 17:47:26 - INFO - volta.utils -   [NLVR2]: iter 37927 Ep: 14.05 loss 0.032 score 0.991 lr 1.65313e-05 
08/28/2020 17:47:33 - INFO - volta.utils -   [NLVR2]: iter 37947 Ep: 14.06 loss 0.029 score 0.991 lr 1.65107e-05 
08/28/2020 17:47:42 - INFO - volta.utils -   [NLVR2]: iter 37967 Ep: 14.07 loss 0.015 score 0.995 lr 1.64902e-05 
08/28/2020 17:47:49 - INFO - volta.utils -   [NLVR2]: iter 37987 Ep: 14.07 loss 0.025 score 0.997 lr 1.64696e-05 
08/28/2020 17:47:58 - INFO - volta.utils -   [NLVR2]: iter 38007 Ep: 14.08 loss 0.024 score 0.992 lr 1.6449e-05 
08/28/2020 17:48:05 - INFO - volta.utils -   [NLVR2]: iter 38027 Ep: 14.09 loss 0.033 score 0.992 lr 1.64284e-05 
08/28/2020 17:48:14 - INFO - volta.utils -   [NLVR2]: iter 38047 Ep: 14.10 loss 0.019 score 0.994 lr 1.64078e-05 
08/28/2020 17:48:21 - INFO - volta.utils -   [NLVR2]: iter 38067 Ep: 14.10 loss 0.030 score 0.994 lr 1.63872e-05 
08/28/2020 17:48:30 - INFO - volta.utils -   [NLVR2]: iter 38087 Ep: 14.11 loss 0.035 score 0.992 lr 1.63667e-05 
08/28/2020 17:48:38 - INFO - volta.utils -   [NLVR2]: iter 38107 Ep: 14.12 loss 0.011 score 0.997 lr 1.63461e-05 
08/28/2020 17:48:47 - INFO - volta.utils -   [NLVR2]: iter 38127 Ep: 14.13 loss 0.023 score 0.992 lr 1.63255e-05 
08/28/2020 17:48:55 - INFO - volta.utils -   [NLVR2]: iter 38147 Ep: 14.13 loss 0.023 score 0.995 lr 1.63049e-05 
08/28/2020 17:49:03 - INFO - volta.utils -   [NLVR2]: iter 38167 Ep: 14.14 loss 0.016 score 0.994 lr 1.62843e-05 
08/28/2020 17:49:11 - INFO - volta.utils -   [NLVR2]: iter 38187 Ep: 14.15 loss 0.033 score 0.986 lr 1.62637e-05 
08/28/2020 17:49:19 - INFO - volta.utils -   [NLVR2]: iter 38207 Ep: 14.16 loss 0.015 score 0.995 lr 1.62432e-05 
08/28/2020 17:49:26 - INFO - volta.utils -   [NLVR2]: iter 38227 Ep: 14.16 loss 0.018 score 0.992 lr 1.62226e-05 
08/28/2020 17:49:35 - INFO - volta.utils -   [NLVR2]: iter 38247 Ep: 14.17 loss 0.017 score 0.995 lr 1.6202e-05 
08/28/2020 17:49:42 - INFO - volta.utils -   [NLVR2]: iter 38267 Ep: 14.18 loss 0.011 score 0.997 lr 1.61814e-05 
08/28/2020 17:49:51 - INFO - volta.utils -   [NLVR2]: iter 38287 Ep: 14.19 loss 0.049 score 0.986 lr 1.61608e-05 
08/28/2020 17:49:58 - INFO - volta.utils -   [NLVR2]: iter 38307 Ep: 14.19 loss 0.021 score 0.994 lr 1.61402e-05 
08/28/2020 17:50:07 - INFO - volta.utils -   [NLVR2]: iter 38327 Ep: 14.20 loss 0.031 score 0.988 lr 1.61197e-05 
08/28/2020 17:50:15 - INFO - volta.utils -   [NLVR2]: iter 38347 Ep: 14.21 loss 0.011 score 0.992 lr 1.60991e-05 
08/28/2020 17:50:23 - INFO - volta.utils -   [NLVR2]: iter 38367 Ep: 14.22 loss 0.038 score 0.989 lr 1.60785e-05 
08/28/2020 17:50:31 - INFO - volta.utils -   [NLVR2]: iter 38387 Ep: 14.22 loss 0.044 score 0.981 lr 1.60579e-05 
08/28/2020 17:50:39 - INFO - volta.utils -   [NLVR2]: iter 38407 Ep: 14.23 loss 0.031 score 0.991 lr 1.60373e-05 
08/28/2020 17:50:47 - INFO - volta.utils -   [NLVR2]: iter 38427 Ep: 14.24 loss 0.029 score 0.992 lr 1.60167e-05 
08/28/2020 17:50:55 - INFO - volta.utils -   [NLVR2]: iter 38447 Ep: 14.24 loss 0.024 score 0.989 lr 1.59962e-05 
08/28/2020 17:51:03 - INFO - volta.utils -   [NLVR2]: iter 38467 Ep: 14.25 loss 0.032 score 0.991 lr 1.59756e-05 
08/28/2020 17:51:12 - INFO - volta.utils -   [NLVR2]: iter 38487 Ep: 14.26 loss 0.021 score 0.991 lr 1.5955e-05 
08/28/2020 17:51:19 - INFO - volta.utils -   [NLVR2]: iter 38507 Ep: 14.27 loss 0.010 score 0.997 lr 1.59344e-05 
08/28/2020 17:51:28 - INFO - volta.utils -   [NLVR2]: iter 38527 Ep: 14.27 loss 0.023 score 0.992 lr 1.59138e-05 
08/28/2020 17:51:35 - INFO - volta.utils -   [NLVR2]: iter 38547 Ep: 14.28 loss 0.042 score 0.988 lr 1.58932e-05 
08/28/2020 17:51:44 - INFO - volta.utils -   [NLVR2]: iter 38567 Ep: 14.29 loss 0.023 score 0.994 lr 1.58726e-05 
08/28/2020 17:51:51 - INFO - volta.utils -   [NLVR2]: iter 38587 Ep: 14.30 loss 0.028 score 0.991 lr 1.58521e-05 
08/28/2020 17:52:00 - INFO - volta.utils -   [NLVR2]: iter 38607 Ep: 14.30 loss 0.039 score 0.989 lr 1.58315e-05 
08/28/2020 17:52:08 - INFO - volta.utils -   [NLVR2]: iter 38627 Ep: 14.31 loss 0.028 score 0.992 lr 1.58109e-05 
08/28/2020 17:52:15 - INFO - volta.utils -   [NLVR2]: iter 38647 Ep: 14.32 loss 0.013 score 0.997 lr 1.57903e-05 
08/28/2020 17:52:24 - INFO - volta.utils -   [NLVR2]: iter 38667 Ep: 14.33 loss 0.024 score 0.991 lr 1.57697e-05 
08/28/2020 17:52:32 - INFO - volta.utils -   [NLVR2]: iter 38687 Ep: 14.33 loss 0.023 score 0.994 lr 1.57491e-05 
08/28/2020 17:52:40 - INFO - volta.utils -   [NLVR2]: iter 38707 Ep: 14.34 loss 0.039 score 0.986 lr 1.57286e-05 
08/28/2020 17:52:48 - INFO - volta.utils -   [NLVR2]: iter 38727 Ep: 14.35 loss 0.016 score 0.994 lr 1.5708e-05 
08/28/2020 17:52:57 - INFO - volta.utils -   [NLVR2]: iter 38747 Ep: 14.36 loss 0.048 score 0.989 lr 1.56874e-05 
08/28/2020 17:53:06 - INFO - volta.utils -   [NLVR2]: iter 38767 Ep: 14.36 loss 0.021 score 0.992 lr 1.56668e-05 
08/28/2020 17:53:14 - INFO - volta.utils -   [NLVR2]: iter 38787 Ep: 14.37 loss 0.037 score 0.991 lr 1.56462e-05 
08/28/2020 17:53:22 - INFO - volta.utils -   [NLVR2]: iter 38807 Ep: 14.38 loss 0.028 score 0.988 lr 1.56256e-05 
08/28/2020 17:53:30 - INFO - volta.utils -   [NLVR2]: iter 38827 Ep: 14.39 loss 0.018 score 0.994 lr 1.56051e-05 
08/28/2020 17:53:38 - INFO - volta.utils -   [NLVR2]: iter 38847 Ep: 14.39 loss 0.047 score 0.989 lr 1.55845e-05 
08/28/2020 17:53:46 - INFO - volta.utils -   [NLVR2]: iter 38867 Ep: 14.40 loss 0.021 score 0.994 lr 1.55639e-05 
08/28/2020 17:53:54 - INFO - volta.utils -   [NLVR2]: iter 38887 Ep: 14.41 loss 0.027 score 0.989 lr 1.55433e-05 
08/28/2020 17:54:03 - INFO - volta.utils -   [NLVR2]: iter 38907 Ep: 14.42 loss 0.009 score 0.997 lr 1.55227e-05 
08/28/2020 17:54:10 - INFO - volta.utils -   [NLVR2]: iter 38927 Ep: 14.42 loss 0.030 score 0.988 lr 1.55021e-05 
08/28/2020 17:54:19 - INFO - volta.utils -   [NLVR2]: iter 38947 Ep: 14.43 loss 0.021 score 0.992 lr 1.54816e-05 
08/28/2020 17:54:26 - INFO - volta.utils -   [NLVR2]: iter 38967 Ep: 14.44 loss 0.029 score 0.994 lr 1.5461e-05 
08/28/2020 17:54:35 - INFO - volta.utils -   [NLVR2]: iter 38987 Ep: 14.44 loss 0.011 score 0.998 lr 1.54404e-05 
08/28/2020 17:54:44 - INFO - volta.utils -   [NLVR2]: iter 39007 Ep: 14.45 loss 0.039 score 0.989 lr 1.54198e-05 
08/28/2020 17:54:53 - INFO - volta.utils -   [NLVR2]: iter 39027 Ep: 14.46 loss 0.040 score 0.991 lr 1.53992e-05 
08/28/2020 17:55:01 - INFO - volta.utils -   [NLVR2]: iter 39047 Ep: 14.47 loss 0.023 score 0.991 lr 1.53786e-05 
08/28/2020 17:55:10 - INFO - volta.utils -   [NLVR2]: iter 39067 Ep: 14.47 loss 0.030 score 0.989 lr 1.53581e-05 
08/28/2020 17:55:17 - INFO - volta.utils -   [NLVR2]: iter 39087 Ep: 14.48 loss 0.009 score 0.998 lr 1.53375e-05 
08/28/2020 17:55:26 - INFO - volta.utils -   [NLVR2]: iter 39107 Ep: 14.49 loss 0.038 score 0.989 lr 1.53169e-05 
08/28/2020 17:55:33 - INFO - volta.utils -   [NLVR2]: iter 39127 Ep: 14.50 loss 0.046 score 0.984 lr 1.52963e-05 
08/28/2020 17:55:42 - INFO - volta.utils -   [NLVR2]: iter 39147 Ep: 14.50 loss 0.018 score 0.995 lr 1.52757e-05 
08/28/2020 17:55:49 - INFO - volta.utils -   [NLVR2]: iter 39167 Ep: 14.51 loss 0.021 score 0.991 lr 1.52551e-05 
08/28/2020 17:55:58 - INFO - volta.utils -   [NLVR2]: iter 39187 Ep: 14.52 loss 0.016 score 0.995 lr 1.52346e-05 
08/28/2020 17:56:05 - INFO - volta.utils -   [NLVR2]: iter 39207 Ep: 14.53 loss 0.015 score 0.994 lr 1.5214e-05 
08/28/2020 17:56:15 - INFO - volta.utils -   [NLVR2]: iter 39227 Ep: 14.53 loss 0.029 score 0.992 lr 1.51934e-05 
08/28/2020 17:56:22 - INFO - volta.utils -   [NLVR2]: iter 39247 Ep: 14.54 loss 0.047 score 0.986 lr 1.51728e-05 
08/28/2020 17:56:31 - INFO - volta.utils -   [NLVR2]: iter 39267 Ep: 14.55 loss 0.031 score 0.994 lr 1.51522e-05 
08/28/2020 17:56:39 - INFO - volta.utils -   [NLVR2]: iter 39287 Ep: 14.56 loss 0.015 score 0.995 lr 1.51316e-05 
08/28/2020 17:56:48 - INFO - volta.utils -   [NLVR2]: iter 39307 Ep: 14.56 loss 0.030 score 0.992 lr 1.5111e-05 
08/28/2020 17:56:56 - INFO - volta.utils -   [NLVR2]: iter 39327 Ep: 14.57 loss 0.014 score 0.994 lr 1.50905e-05 
08/28/2020 17:57:04 - INFO - volta.utils -   [NLVR2]: iter 39347 Ep: 14.58 loss 0.034 score 0.988 lr 1.50699e-05 
08/28/2020 17:57:12 - INFO - volta.utils -   [NLVR2]: iter 39367 Ep: 14.59 loss 0.020 score 0.992 lr 1.50493e-05 
08/28/2020 17:57:20 - INFO - volta.utils -   [NLVR2]: iter 39387 Ep: 14.59 loss 0.013 score 0.997 lr 1.50287e-05 
08/28/2020 17:57:29 - INFO - volta.utils -   [NLVR2]: iter 39407 Ep: 14.60 loss 0.010 score 0.995 lr 1.50081e-05 
08/28/2020 17:57:37 - INFO - volta.utils -   [NLVR2]: iter 39427 Ep: 14.61 loss 0.017 score 0.994 lr 1.49875e-05 
08/28/2020 17:57:45 - INFO - volta.utils -   [NLVR2]: iter 39447 Ep: 14.62 loss 0.026 score 0.995 lr 1.4967e-05 
08/28/2020 17:57:53 - INFO - volta.utils -   [NLVR2]: iter 39467 Ep: 14.62 loss 0.012 score 0.994 lr 1.49464e-05 
08/28/2020 17:58:02 - INFO - volta.utils -   [NLVR2]: iter 39487 Ep: 14.63 loss 0.012 score 0.997 lr 1.49258e-05 
08/28/2020 17:58:09 - INFO - volta.utils -   [NLVR2]: iter 39507 Ep: 14.64 loss 0.033 score 0.992 lr 1.49052e-05 
08/28/2020 17:58:18 - INFO - volta.utils -   [NLVR2]: iter 39527 Ep: 14.65 loss 0.012 score 0.997 lr 1.48846e-05 
08/28/2020 17:58:26 - INFO - volta.utils -   [NLVR2]: iter 39547 Ep: 14.65 loss 0.051 score 0.988 lr 1.4864e-05 
08/28/2020 17:58:35 - INFO - volta.utils -   [NLVR2]: iter 39567 Ep: 14.66 loss 0.020 score 0.991 lr 1.48435e-05 
08/28/2020 17:58:43 - INFO - volta.utils -   [NLVR2]: iter 39587 Ep: 14.67 loss 0.038 score 0.991 lr 1.48229e-05 
08/28/2020 17:58:52 - INFO - volta.utils -   [NLVR2]: iter 39607 Ep: 14.67 loss 0.024 score 0.991 lr 1.48023e-05 
08/28/2020 17:58:59 - INFO - volta.utils -   [NLVR2]: iter 39627 Ep: 14.68 loss 0.030 score 0.991 lr 1.47817e-05 
08/28/2020 17:59:08 - INFO - volta.utils -   [NLVR2]: iter 39647 Ep: 14.69 loss 0.015 score 0.997 lr 1.47611e-05 
08/28/2020 17:59:15 - INFO - volta.utils -   [NLVR2]: iter 39667 Ep: 14.70 loss 0.035 score 0.986 lr 1.47405e-05 
08/28/2020 17:59:24 - INFO - volta.utils -   [NLVR2]: iter 39687 Ep: 14.70 loss 0.046 score 0.983 lr 1.472e-05 
08/28/2020 17:59:31 - INFO - volta.utils -   [NLVR2]: iter 39707 Ep: 14.71 loss 0.036 score 0.991 lr 1.46994e-05 
08/28/2020 17:59:40 - INFO - volta.utils -   [NLVR2]: iter 39727 Ep: 14.72 loss 0.025 score 0.992 lr 1.46788e-05 
08/28/2020 17:59:47 - INFO - volta.utils -   [NLVR2]: iter 39747 Ep: 14.73 loss 0.046 score 0.978 lr 1.46582e-05 
08/28/2020 17:59:56 - INFO - volta.utils -   [NLVR2]: iter 39767 Ep: 14.73 loss 0.022 score 0.992 lr 1.46376e-05 
08/28/2020 18:00:03 - INFO - volta.utils -   [NLVR2]: iter 39787 Ep: 14.74 loss 0.032 score 0.994 lr 1.4617e-05 
08/28/2020 18:00:13 - INFO - volta.utils -   [NLVR2]: iter 39807 Ep: 14.75 loss 0.022 score 0.992 lr 1.45965e-05 
08/28/2020 18:00:21 - INFO - volta.utils -   [NLVR2]: iter 39827 Ep: 14.76 loss 0.019 score 0.997 lr 1.45759e-05 
08/28/2020 18:00:31 - INFO - volta.utils -   [NLVR2]: iter 39847 Ep: 14.76 loss 0.050 score 0.980 lr 1.45553e-05 
08/28/2020 18:00:38 - INFO - volta.utils -   [NLVR2]: iter 39867 Ep: 14.77 loss 0.038 score 0.988 lr 1.45347e-05 
08/28/2020 18:00:47 - INFO - volta.utils -   [NLVR2]: iter 39887 Ep: 14.78 loss 0.040 score 0.989 lr 1.45141e-05 
08/28/2020 18:00:54 - INFO - volta.utils -   [NLVR2]: iter 39907 Ep: 14.79 loss 0.034 score 0.992 lr 1.44935e-05 
08/28/2020 18:01:03 - INFO - volta.utils -   [NLVR2]: iter 39927 Ep: 14.79 loss 0.014 score 0.992 lr 1.4473e-05 
08/28/2020 18:01:11 - INFO - volta.utils -   [NLVR2]: iter 39947 Ep: 14.80 loss 0.036 score 0.991 lr 1.44524e-05 
08/28/2020 18:01:20 - INFO - volta.utils -   [NLVR2]: iter 39967 Ep: 14.81 loss 0.025 score 0.991 lr 1.44318e-05 
08/28/2020 18:01:27 - INFO - volta.utils -   [NLVR2]: iter 39987 Ep: 14.82 loss 0.028 score 0.991 lr 1.44112e-05 
08/28/2020 18:01:36 - INFO - volta.utils -   [NLVR2]: iter 40007 Ep: 14.82 loss 0.027 score 0.991 lr 1.43906e-05 
08/28/2020 18:01:43 - INFO - volta.utils -   [NLVR2]: iter 40027 Ep: 14.83 loss 0.038 score 0.984 lr 1.437e-05 
08/28/2020 18:01:52 - INFO - volta.utils -   [NLVR2]: iter 40047 Ep: 14.84 loss 0.039 score 0.986 lr 1.43495e-05 
08/28/2020 18:02:00 - INFO - volta.utils -   [NLVR2]: iter 40067 Ep: 14.85 loss 0.027 score 0.992 lr 1.43289e-05 
08/28/2020 18:02:07 - INFO - volta.utils -   [NLVR2]: iter 40087 Ep: 14.85 loss 0.027 score 0.992 lr 1.43083e-05 
08/28/2020 18:02:16 - INFO - volta.utils -   [NLVR2]: iter 40107 Ep: 14.86 loss 0.047 score 0.986 lr 1.42877e-05 
08/28/2020 18:02:23 - INFO - volta.utils -   [NLVR2]: iter 40127 Ep: 14.87 loss 0.033 score 0.991 lr 1.42671e-05 
08/28/2020 18:02:32 - INFO - volta.utils -   [NLVR2]: iter 40147 Ep: 14.87 loss 0.022 score 0.991 lr 1.42465e-05 
08/28/2020 18:02:40 - INFO - volta.utils -   [NLVR2]: iter 40167 Ep: 14.88 loss 0.055 score 0.983 lr 1.42259e-05 
08/28/2020 18:02:49 - INFO - volta.utils -   [NLVR2]: iter 40187 Ep: 14.89 loss 0.023 score 0.994 lr 1.42054e-05 
08/28/2020 18:02:57 - INFO - volta.utils -   [NLVR2]: iter 40207 Ep: 14.90 loss 0.039 score 0.989 lr 1.41848e-05 
08/28/2020 18:03:05 - INFO - volta.utils -   [NLVR2]: iter 40227 Ep: 14.90 loss 0.025 score 0.989 lr 1.41642e-05 
08/28/2020 18:03:13 - INFO - volta.utils -   [NLVR2]: iter 40247 Ep: 14.91 loss 0.046 score 0.988 lr 1.41436e-05 
08/28/2020 18:03:21 - INFO - volta.utils -   [NLVR2]: iter 40267 Ep: 14.92 loss 0.034 score 0.989 lr 1.4123e-05 
08/28/2020 18:03:30 - INFO - volta.utils -   [NLVR2]: iter 40287 Ep: 14.93 loss 0.020 score 0.994 lr 1.41024e-05 
08/28/2020 18:03:39 - INFO - volta.utils -   [NLVR2]: iter 40307 Ep: 14.93 loss 0.050 score 0.988 lr 1.40819e-05 
08/28/2020 18:03:47 - INFO - volta.utils -   [NLVR2]: iter 40327 Ep: 14.94 loss 0.035 score 0.988 lr 1.40613e-05 
08/28/2020 18:03:57 - INFO - volta.utils -   [NLVR2]: iter 40347 Ep: 14.95 loss 0.026 score 0.992 lr 1.40407e-05 
08/28/2020 18:04:05 - INFO - volta.utils -   [NLVR2]: iter 40367 Ep: 14.96 loss 0.023 score 0.991 lr 1.40201e-05 
08/28/2020 18:04:13 - INFO - volta.utils -   [NLVR2]: iter 40387 Ep: 14.96 loss 0.017 score 0.994 lr 1.39995e-05 
08/28/2020 18:04:21 - INFO - volta.utils -   [NLVR2]: iter 40407 Ep: 14.97 loss 0.019 score 0.991 lr 1.39789e-05 
08/28/2020 18:04:30 - INFO - volta.utils -   [NLVR2]: iter 40427 Ep: 14.98 loss 0.036 score 0.988 lr 1.39584e-05 
08/28/2020 18:04:38 - INFO - volta.utils -   [NLVR2]: iter 40447 Ep: 14.99 loss 0.019 score 0.994 lr 1.39378e-05 
08/28/2020 18:04:48 - INFO - volta.utils -   [NLVR2]: iter 40467 Ep: 14.99 loss 0.055 score 0.983 lr 1.39172e-05 
08/28/2020 18:04:55 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  44%|████▍     | 4/9 [1:30:12<1:57:28, 1409.63s/it]08/28/2020 18:05:47 - INFO - volta.utils -   Eval task TASK12 on iteration 40486 
08/28/2020 18:05:47 - INFO - volta.utils -   Validation [NLVR2]: loss 1.553 score 69.983 
08/28/2020 18:05:55 - INFO - volta.utils -   [NLVR2]: iter 40506 Ep: 15.01 loss 0.028 score 0.990 lr 1.38868e-05 
08/28/2020 18:06:03 - INFO - volta.utils -   [NLVR2]: iter 40526 Ep: 15.02 loss 0.017 score 0.994 lr 1.38565e-05 
08/28/2020 18:06:11 - INFO - volta.utils -   [NLVR2]: iter 40546 Ep: 15.02 loss 0.024 score 0.994 lr 1.38359e-05 
08/28/2020 18:06:20 - INFO - volta.utils -   [NLVR2]: iter 40566 Ep: 15.03 loss 0.021 score 0.992 lr 1.38153e-05 
08/28/2020 18:06:27 - INFO - volta.utils -   [NLVR2]: iter 40586 Ep: 15.04 loss 0.023 score 0.994 lr 1.37947e-05 
08/28/2020 18:06:36 - INFO - volta.utils -   [NLVR2]: iter 40606 Ep: 15.04 loss 0.010 score 0.998 lr 1.37741e-05 
08/28/2020 18:06:44 - INFO - volta.utils -   [NLVR2]: iter 40626 Ep: 15.05 loss 0.015 score 0.992 lr 1.37536e-05 
08/28/2020 18:06:52 - INFO - volta.utils -   [NLVR2]: iter 40646 Ep: 15.06 loss 0.009 score 0.998 lr 1.3733e-05 
08/28/2020 18:07:00 - INFO - volta.utils -   [NLVR2]: iter 40666 Ep: 15.07 loss 0.023 score 0.991 lr 1.37124e-05 
08/28/2020 18:07:08 - INFO - volta.utils -   [NLVR2]: iter 40686 Ep: 15.07 loss 0.032 score 0.991 lr 1.36918e-05 
08/28/2020 18:07:16 - INFO - volta.utils -   [NLVR2]: iter 40706 Ep: 15.08 loss 0.007 score 0.998 lr 1.36712e-05 
08/28/2020 18:07:24 - INFO - volta.utils -   [NLVR2]: iter 40726 Ep: 15.09 loss 0.016 score 0.995 lr 1.36506e-05 
08/28/2020 18:07:32 - INFO - volta.utils -   [NLVR2]: iter 40746 Ep: 15.10 loss 0.021 score 0.995 lr 1.363e-05 
08/28/2020 18:07:40 - INFO - volta.utils -   [NLVR2]: iter 40766 Ep: 15.10 loss 0.012 score 0.997 lr 1.36095e-05 
08/28/2020 18:07:48 - INFO - volta.utils -   [NLVR2]: iter 40786 Ep: 15.11 loss 0.007 score 0.998 lr 1.35889e-05 
08/28/2020 18:07:57 - INFO - volta.utils -   [NLVR2]: iter 40806 Ep: 15.12 loss 0.023 score 0.992 lr 1.35683e-05 
08/28/2020 18:08:04 - INFO - volta.utils -   [NLVR2]: iter 40826 Ep: 15.13 loss 0.011 score 0.997 lr 1.35477e-05 
08/28/2020 18:08:13 - INFO - volta.utils -   [NLVR2]: iter 40846 Ep: 15.13 loss 0.011 score 0.995 lr 1.35271e-05 
08/28/2020 18:08:20 - INFO - volta.utils -   [NLVR2]: iter 40866 Ep: 15.14 loss 0.026 score 0.992 lr 1.35065e-05 
08/28/2020 18:08:29 - INFO - volta.utils -   [NLVR2]: iter 40886 Ep: 15.15 loss 0.002 score 1.000 lr 1.3486e-05 
08/28/2020 18:08:37 - INFO - volta.utils -   [NLVR2]: iter 40906 Ep: 15.16 loss 0.016 score 0.995 lr 1.34654e-05 
08/28/2020 18:08:45 - INFO - volta.utils -   [NLVR2]: iter 40926 Ep: 15.16 loss 0.023 score 0.994 lr 1.34448e-05 
08/28/2020 18:08:53 - INFO - volta.utils -   [NLVR2]: iter 40946 Ep: 15.17 loss 0.011 score 0.995 lr 1.34242e-05 
08/28/2020 18:09:01 - INFO - volta.utils -   [NLVR2]: iter 40966 Ep: 15.18 loss 0.029 score 0.994 lr 1.34036e-05 
08/28/2020 18:09:09 - INFO - volta.utils -   [NLVR2]: iter 40986 Ep: 15.19 loss 0.009 score 0.997 lr 1.3383e-05 
08/28/2020 18:09:17 - INFO - volta.utils -   [NLVR2]: iter 41006 Ep: 15.19 loss 0.013 score 0.994 lr 1.33625e-05 
08/28/2020 18:09:25 - INFO - volta.utils -   [NLVR2]: iter 41026 Ep: 15.20 loss 0.005 score 1.000 lr 1.33419e-05 
08/28/2020 18:09:33 - INFO - volta.utils -   [NLVR2]: iter 41046 Ep: 15.21 loss 0.036 score 0.989 lr 1.33213e-05 
08/28/2020 18:09:41 - INFO - volta.utils -   [NLVR2]: iter 41066 Ep: 15.22 loss 0.022 score 0.989 lr 1.33007e-05 
08/28/2020 18:09:48 - INFO - volta.utils -   [NLVR2]: iter 41086 Ep: 15.22 loss 0.022 score 0.994 lr 1.32801e-05 
08/28/2020 18:09:57 - INFO - volta.utils -   [NLVR2]: iter 41106 Ep: 15.23 loss 0.011 score 0.997 lr 1.32595e-05 
08/28/2020 18:10:04 - INFO - volta.utils -   [NLVR2]: iter 41126 Ep: 15.24 loss 0.012 score 0.994 lr 1.3239e-05 
08/28/2020 18:10:13 - INFO - volta.utils -   [NLVR2]: iter 41146 Ep: 15.24 loss 0.017 score 0.995 lr 1.32184e-05 
08/28/2020 18:10:20 - INFO - volta.utils -   [NLVR2]: iter 41166 Ep: 15.25 loss 0.027 score 0.992 lr 1.31978e-05 
08/28/2020 18:10:29 - INFO - volta.utils -   [NLVR2]: iter 41186 Ep: 15.26 loss 0.027 score 0.994 lr 1.31772e-05 
08/28/2020 18:10:36 - INFO - volta.utils -   [NLVR2]: iter 41206 Ep: 15.27 loss 0.031 score 0.992 lr 1.31566e-05 
08/28/2020 18:10:45 - INFO - volta.utils -   [NLVR2]: iter 41226 Ep: 15.27 loss 0.021 score 0.991 lr 1.3136e-05 
08/28/2020 18:10:53 - INFO - volta.utils -   [NLVR2]: iter 41246 Ep: 15.28 loss 0.014 score 0.992 lr 1.31155e-05 
08/28/2020 18:11:02 - INFO - volta.utils -   [NLVR2]: iter 41266 Ep: 15.29 loss 0.010 score 0.997 lr 1.30949e-05 
08/28/2020 18:11:10 - INFO - volta.utils -   [NLVR2]: iter 41286 Ep: 15.30 loss 0.001 score 1.000 lr 1.30743e-05 
08/28/2020 18:11:19 - INFO - volta.utils -   [NLVR2]: iter 41306 Ep: 15.30 loss 0.020 score 0.994 lr 1.30537e-05 
08/28/2020 18:11:27 - INFO - volta.utils -   [NLVR2]: iter 41326 Ep: 15.31 loss 0.024 score 0.994 lr 1.30331e-05 
08/28/2020 18:11:36 - INFO - volta.utils -   [NLVR2]: iter 41346 Ep: 15.32 loss 0.022 score 0.995 lr 1.30125e-05 
08/28/2020 18:11:44 - INFO - volta.utils -   [NLVR2]: iter 41366 Ep: 15.33 loss 0.008 score 0.998 lr 1.2992e-05 
08/28/2020 18:11:53 - INFO - volta.utils -   [NLVR2]: iter 41386 Ep: 15.33 loss 0.022 score 0.989 lr 1.29714e-05 
08/28/2020 18:12:01 - INFO - volta.utils -   [NLVR2]: iter 41406 Ep: 15.34 loss 0.014 score 0.997 lr 1.29508e-05 
08/28/2020 18:12:10 - INFO - volta.utils -   [NLVR2]: iter 41426 Ep: 15.35 loss 0.029 score 0.994 lr 1.29302e-05 
08/28/2020 18:12:18 - INFO - volta.utils -   [NLVR2]: iter 41446 Ep: 15.36 loss 0.010 score 0.997 lr 1.29096e-05 
08/28/2020 18:12:27 - INFO - volta.utils -   [NLVR2]: iter 41466 Ep: 15.36 loss 0.032 score 0.994 lr 1.2889e-05 
08/28/2020 18:12:35 - INFO - volta.utils -   [NLVR2]: iter 41486 Ep: 15.37 loss 0.011 score 0.998 lr 1.28684e-05 
08/28/2020 18:12:44 - INFO - volta.utils -   [NLVR2]: iter 41506 Ep: 15.38 loss 0.034 score 0.994 lr 1.28479e-05 
08/28/2020 18:12:51 - INFO - volta.utils -   [NLVR2]: iter 41526 Ep: 15.39 loss 0.016 score 0.994 lr 1.28273e-05 
08/28/2020 18:13:00 - INFO - volta.utils -   [NLVR2]: iter 41546 Ep: 15.39 loss 0.026 score 0.991 lr 1.28067e-05 
08/28/2020 18:13:08 - INFO - volta.utils -   [NLVR2]: iter 41566 Ep: 15.40 loss 0.018 score 0.997 lr 1.27861e-05 
08/28/2020 18:13:17 - INFO - volta.utils -   [NLVR2]: iter 41586 Ep: 15.41 loss 0.018 score 0.994 lr 1.27655e-05 
08/28/2020 18:13:25 - INFO - volta.utils -   [NLVR2]: iter 41606 Ep: 15.42 loss 0.017 score 0.995 lr 1.27449e-05 
08/28/2020 18:13:33 - INFO - volta.utils -   [NLVR2]: iter 41626 Ep: 15.42 loss 0.021 score 0.997 lr 1.27244e-05 
08/28/2020 18:13:41 - INFO - volta.utils -   [NLVR2]: iter 41646 Ep: 15.43 loss 0.029 score 0.994 lr 1.27038e-05 
08/28/2020 18:13:50 - INFO - volta.utils -   [NLVR2]: iter 41666 Ep: 15.44 loss 0.011 score 0.994 lr 1.26832e-05 
08/28/2020 18:13:58 - INFO - volta.utils -   [NLVR2]: iter 41686 Ep: 15.44 loss 0.033 score 0.989 lr 1.26626e-05 
08/28/2020 18:14:06 - INFO - volta.utils -   [NLVR2]: iter 41706 Ep: 15.45 loss 0.022 score 0.992 lr 1.2642e-05 
08/28/2020 18:14:14 - INFO - volta.utils -   [NLVR2]: iter 41726 Ep: 15.46 loss 0.026 score 0.991 lr 1.26214e-05 
08/28/2020 18:14:23 - INFO - volta.utils -   [NLVR2]: iter 41746 Ep: 15.47 loss 0.023 score 0.991 lr 1.26009e-05 
08/28/2020 18:14:30 - INFO - volta.utils -   [NLVR2]: iter 41766 Ep: 15.47 loss 0.026 score 0.992 lr 1.25803e-05 
08/28/2020 18:14:39 - INFO - volta.utils -   [NLVR2]: iter 41786 Ep: 15.48 loss 0.024 score 0.995 lr 1.25597e-05 
08/28/2020 18:14:47 - INFO - volta.utils -   [NLVR2]: iter 41806 Ep: 15.49 loss 0.008 score 0.997 lr 1.25391e-05 
08/28/2020 18:14:54 - INFO - volta.utils -   [NLVR2]: iter 41826 Ep: 15.50 loss 0.019 score 0.994 lr 1.25185e-05 
08/28/2020 18:15:03 - INFO - volta.utils -   [NLVR2]: iter 41846 Ep: 15.50 loss 0.007 score 0.997 lr 1.24979e-05 
08/28/2020 18:15:11 - INFO - volta.utils -   [NLVR2]: iter 41866 Ep: 15.51 loss 0.047 score 0.989 lr 1.24774e-05 
08/28/2020 18:15:20 - INFO - volta.utils -   [NLVR2]: iter 41886 Ep: 15.52 loss 0.013 score 0.994 lr 1.24568e-05 
08/28/2020 18:15:27 - INFO - volta.utils -   [NLVR2]: iter 41906 Ep: 15.53 loss 0.011 score 0.995 lr 1.24362e-05 
08/28/2020 18:15:36 - INFO - volta.utils -   [NLVR2]: iter 41926 Ep: 15.53 loss 0.005 score 1.000 lr 1.24156e-05 
08/28/2020 18:15:43 - INFO - volta.utils -   [NLVR2]: iter 41946 Ep: 15.54 loss 0.002 score 1.000 lr 1.2395e-05 
08/28/2020 18:15:52 - INFO - volta.utils -   [NLVR2]: iter 41966 Ep: 15.55 loss 0.029 score 0.989 lr 1.23744e-05 
08/28/2020 18:16:00 - INFO - volta.utils -   [NLVR2]: iter 41986 Ep: 15.56 loss 0.018 score 0.994 lr 1.23539e-05 
08/28/2020 18:16:08 - INFO - volta.utils -   [NLVR2]: iter 42006 Ep: 15.56 loss 0.004 score 0.998 lr 1.23333e-05 
08/28/2020 18:16:16 - INFO - volta.utils -   [NLVR2]: iter 42026 Ep: 15.57 loss 0.011 score 0.995 lr 1.23127e-05 
08/28/2020 18:16:24 - INFO - volta.utils -   [NLVR2]: iter 42046 Ep: 15.58 loss 0.014 score 0.997 lr 1.22921e-05 
08/28/2020 18:16:32 - INFO - volta.utils -   [NLVR2]: iter 42066 Ep: 15.59 loss 0.004 score 0.998 lr 1.22715e-05 
08/28/2020 18:16:40 - INFO - volta.utils -   [NLVR2]: iter 42086 Ep: 15.59 loss 0.014 score 0.994 lr 1.22509e-05 
08/28/2020 18:16:48 - INFO - volta.utils -   [NLVR2]: iter 42106 Ep: 15.60 loss 0.016 score 0.994 lr 1.22304e-05 
08/28/2020 18:16:56 - INFO - volta.utils -   [NLVR2]: iter 42126 Ep: 15.61 loss 0.033 score 0.994 lr 1.22098e-05 
08/28/2020 18:17:04 - INFO - volta.utils -   [NLVR2]: iter 42146 Ep: 15.62 loss 0.018 score 0.994 lr 1.21892e-05 
08/28/2020 18:17:13 - INFO - volta.utils -   [NLVR2]: iter 42166 Ep: 15.62 loss 0.012 score 0.995 lr 1.21686e-05 
08/28/2020 18:17:21 - INFO - volta.utils -   [NLVR2]: iter 42186 Ep: 15.63 loss 0.015 score 0.998 lr 1.2148e-05 
08/28/2020 18:17:30 - INFO - volta.utils -   [NLVR2]: iter 42206 Ep: 15.64 loss 0.055 score 0.988 lr 1.21274e-05 
08/28/2020 18:17:38 - INFO - volta.utils -   [NLVR2]: iter 42226 Ep: 15.65 loss 0.004 score 0.997 lr 1.21069e-05 
08/28/2020 18:17:47 - INFO - volta.utils -   [NLVR2]: iter 42246 Ep: 15.65 loss 0.012 score 0.994 lr 1.20863e-05 
08/28/2020 18:17:55 - INFO - volta.utils -   [NLVR2]: iter 42266 Ep: 15.66 loss 0.018 score 0.994 lr 1.20657e-05 
08/28/2020 18:18:04 - INFO - volta.utils -   [NLVR2]: iter 42286 Ep: 15.67 loss 0.036 score 0.991 lr 1.20451e-05 
08/28/2020 18:18:12 - INFO - volta.utils -   [NLVR2]: iter 42306 Ep: 15.67 loss 0.032 score 0.991 lr 1.20245e-05 
08/28/2020 18:18:21 - INFO - volta.utils -   [NLVR2]: iter 42326 Ep: 15.68 loss 0.023 score 0.994 lr 1.20039e-05 
08/28/2020 18:18:28 - INFO - volta.utils -   [NLVR2]: iter 42346 Ep: 15.69 loss 0.025 score 0.994 lr 1.19833e-05 
08/28/2020 18:18:37 - INFO - volta.utils -   [NLVR2]: iter 42366 Ep: 15.70 loss 0.027 score 0.992 lr 1.19628e-05 
08/28/2020 18:18:44 - INFO - volta.utils -   [NLVR2]: iter 42386 Ep: 15.70 loss 0.025 score 0.992 lr 1.19422e-05 
08/28/2020 18:18:53 - INFO - volta.utils -   [NLVR2]: iter 42406 Ep: 15.71 loss 0.015 score 0.994 lr 1.19216e-05 
08/28/2020 18:19:01 - INFO - volta.utils -   [NLVR2]: iter 42426 Ep: 15.72 loss 0.012 score 0.997 lr 1.1901e-05 
08/28/2020 18:19:10 - INFO - volta.utils -   [NLVR2]: iter 42446 Ep: 15.73 loss 0.009 score 0.997 lr 1.18804e-05 
08/28/2020 18:19:18 - INFO - volta.utils -   [NLVR2]: iter 42466 Ep: 15.73 loss 0.042 score 0.988 lr 1.18598e-05 
08/28/2020 18:19:26 - INFO - volta.utils -   [NLVR2]: iter 42486 Ep: 15.74 loss 0.012 score 0.997 lr 1.18393e-05 
08/28/2020 18:19:34 - INFO - volta.utils -   [NLVR2]: iter 42506 Ep: 15.75 loss 0.033 score 0.992 lr 1.18187e-05 
08/28/2020 18:19:42 - INFO - volta.utils -   [NLVR2]: iter 42526 Ep: 15.76 loss 0.016 score 0.994 lr 1.17981e-05 
08/28/2020 18:19:50 - INFO - volta.utils -   [NLVR2]: iter 42546 Ep: 15.76 loss 0.018 score 0.995 lr 1.17775e-05 
08/28/2020 18:19:58 - INFO - volta.utils -   [NLVR2]: iter 42566 Ep: 15.77 loss 0.010 score 0.997 lr 1.17569e-05 
08/28/2020 18:20:06 - INFO - volta.utils -   [NLVR2]: iter 42586 Ep: 15.78 loss 0.048 score 0.988 lr 1.17363e-05 
08/28/2020 18:20:14 - INFO - volta.utils -   [NLVR2]: iter 42606 Ep: 15.79 loss 0.008 score 0.998 lr 1.17158e-05 
08/28/2020 18:20:22 - INFO - volta.utils -   [NLVR2]: iter 42626 Ep: 15.79 loss 0.010 score 0.997 lr 1.16952e-05 
08/28/2020 18:20:30 - INFO - volta.utils -   [NLVR2]: iter 42646 Ep: 15.80 loss 0.015 score 0.995 lr 1.16746e-05 
08/28/2020 18:20:38 - INFO - volta.utils -   [NLVR2]: iter 42666 Ep: 15.81 loss 0.018 score 0.994 lr 1.1654e-05 
08/28/2020 18:20:46 - INFO - volta.utils -   [NLVR2]: iter 42686 Ep: 15.82 loss 0.020 score 0.995 lr 1.16334e-05 
08/28/2020 18:20:54 - INFO - volta.utils -   [NLVR2]: iter 42706 Ep: 15.82 loss 0.052 score 0.988 lr 1.16128e-05 
08/28/2020 18:21:02 - INFO - volta.utils -   [NLVR2]: iter 42726 Ep: 15.83 loss 0.007 score 0.997 lr 1.15923e-05 
08/28/2020 18:21:11 - INFO - volta.utils -   [NLVR2]: iter 42746 Ep: 15.84 loss 0.041 score 0.992 lr 1.15717e-05 
08/28/2020 18:21:18 - INFO - volta.utils -   [NLVR2]: iter 42766 Ep: 15.85 loss 0.022 score 0.992 lr 1.15511e-05 
08/28/2020 18:21:27 - INFO - volta.utils -   [NLVR2]: iter 42786 Ep: 15.85 loss 0.016 score 0.994 lr 1.15305e-05 
08/28/2020 18:21:35 - INFO - volta.utils -   [NLVR2]: iter 42806 Ep: 15.86 loss 0.027 score 0.992 lr 1.15099e-05 
08/28/2020 18:21:43 - INFO - volta.utils -   [NLVR2]: iter 42826 Ep: 15.87 loss 0.006 score 0.998 lr 1.14893e-05 
08/28/2020 18:21:51 - INFO - volta.utils -   [NLVR2]: iter 42846 Ep: 15.87 loss 0.023 score 0.991 lr 1.14688e-05 
08/28/2020 18:22:00 - INFO - volta.utils -   [NLVR2]: iter 42866 Ep: 15.88 loss 0.010 score 0.995 lr 1.14482e-05 
08/28/2020 18:22:07 - INFO - volta.utils -   [NLVR2]: iter 42886 Ep: 15.89 loss 0.023 score 0.994 lr 1.14276e-05 
08/28/2020 18:22:16 - INFO - volta.utils -   [NLVR2]: iter 42906 Ep: 15.90 loss 0.015 score 0.995 lr 1.1407e-05 
08/28/2020 18:22:24 - INFO - volta.utils -   [NLVR2]: iter 42926 Ep: 15.90 loss 0.018 score 0.995 lr 1.13864e-05 
08/28/2020 18:22:32 - INFO - volta.utils -   [NLVR2]: iter 42946 Ep: 15.91 loss 0.026 score 0.991 lr 1.13658e-05 
08/28/2020 18:22:40 - INFO - volta.utils -   [NLVR2]: iter 42966 Ep: 15.92 loss 0.022 score 0.988 lr 1.13453e-05 
08/28/2020 18:22:49 - INFO - volta.utils -   [NLVR2]: iter 42986 Ep: 15.93 loss 0.029 score 0.989 lr 1.13247e-05 
08/28/2020 18:22:56 - INFO - volta.utils -   [NLVR2]: iter 43006 Ep: 15.93 loss 0.016 score 0.994 lr 1.13041e-05 
08/28/2020 18:23:05 - INFO - volta.utils -   [NLVR2]: iter 43026 Ep: 15.94 loss 0.025 score 0.994 lr 1.12835e-05 
08/28/2020 18:23:12 - INFO - volta.utils -   [NLVR2]: iter 43046 Ep: 15.95 loss 0.017 score 0.995 lr 1.12629e-05 
08/28/2020 18:23:21 - INFO - volta.utils -   [NLVR2]: iter 43066 Ep: 15.96 loss 0.029 score 0.994 lr 1.12423e-05 
08/28/2020 18:23:29 - INFO - volta.utils -   [NLVR2]: iter 43086 Ep: 15.96 loss 0.019 score 0.997 lr 1.12217e-05 
08/28/2020 18:23:37 - INFO - volta.utils -   [NLVR2]: iter 43106 Ep: 15.97 loss 0.019 score 0.992 lr 1.12012e-05 
08/28/2020 18:23:45 - INFO - volta.utils -   [NLVR2]: iter 43126 Ep: 15.98 loss 0.009 score 0.997 lr 1.11806e-05 
08/28/2020 18:23:53 - INFO - volta.utils -   [NLVR2]: iter 43146 Ep: 15.99 loss 0.023 score 0.994 lr 1.116e-05 
08/28/2020 18:24:00 - INFO - volta.utils -   [NLVR2]: iter 43166 Ep: 15.99 loss 0.004 score 1.000 lr 1.11394e-05 
08/28/2020 18:24:07 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  56%|█████▌    | 5/9 [1:49:26<1:28:51, 1332.81s/it]08/28/2020 18:25:04 - INFO - volta.utils -   Eval task TASK12 on iteration 43185 
08/28/2020 18:25:04 - INFO - volta.utils -   Validation [NLVR2]: loss 1.717 score 70.011 
08/28/2020 18:25:12 - INFO - volta.utils -   [NLVR2]: iter 43205 Ep: 16.01 loss 0.026 score 0.993 lr 1.11091e-05 
08/28/2020 18:25:20 - INFO - volta.utils -   [NLVR2]: iter 43225 Ep: 16.02 loss 0.010 score 0.994 lr 1.10787e-05 
08/28/2020 18:25:29 - INFO - volta.utils -   [NLVR2]: iter 43245 Ep: 16.02 loss 0.006 score 0.998 lr 1.10581e-05 
08/28/2020 18:25:37 - INFO - volta.utils -   [NLVR2]: iter 43265 Ep: 16.03 loss 0.023 score 0.994 lr 1.10375e-05 
08/28/2020 18:25:46 - INFO - volta.utils -   [NLVR2]: iter 43285 Ep: 16.04 loss 0.003 score 1.000 lr 1.10169e-05 
08/28/2020 18:25:53 - INFO - volta.utils -   [NLVR2]: iter 43305 Ep: 16.04 loss 0.026 score 0.992 lr 1.09964e-05 
08/28/2020 18:26:02 - INFO - volta.utils -   [NLVR2]: iter 43325 Ep: 16.05 loss 0.026 score 0.994 lr 1.09758e-05 
08/28/2020 18:26:09 - INFO - volta.utils -   [NLVR2]: iter 43345 Ep: 16.06 loss 0.014 score 0.995 lr 1.09552e-05 
08/28/2020 18:26:18 - INFO - volta.utils -   [NLVR2]: iter 43365 Ep: 16.07 loss 0.002 score 1.000 lr 1.09346e-05 
08/28/2020 18:26:25 - INFO - volta.utils -   [NLVR2]: iter 43385 Ep: 16.07 loss 0.006 score 0.998 lr 1.0914e-05 
08/28/2020 18:26:34 - INFO - volta.utils -   [NLVR2]: iter 43405 Ep: 16.08 loss 0.008 score 0.997 lr 1.08934e-05 
08/28/2020 18:26:41 - INFO - volta.utils -   [NLVR2]: iter 43425 Ep: 16.09 loss 0.006 score 0.997 lr 1.08729e-05 
08/28/2020 18:26:49 - INFO - volta.utils -   [NLVR2]: iter 43445 Ep: 16.10 loss 0.010 score 0.998 lr 1.08523e-05 
08/28/2020 18:26:58 - INFO - volta.utils -   [NLVR2]: iter 43465 Ep: 16.10 loss 0.012 score 0.994 lr 1.08317e-05 
08/28/2020 18:27:05 - INFO - volta.utils -   [NLVR2]: iter 43485 Ep: 16.11 loss 0.022 score 0.997 lr 1.08111e-05 
08/28/2020 18:27:14 - INFO - volta.utils -   [NLVR2]: iter 43505 Ep: 16.12 loss 0.006 score 0.997 lr 1.07905e-05 
08/28/2020 18:27:22 - INFO - volta.utils -   [NLVR2]: iter 43525 Ep: 16.13 loss 0.010 score 0.997 lr 1.07699e-05 
08/28/2020 18:27:30 - INFO - volta.utils -   [NLVR2]: iter 43545 Ep: 16.13 loss 0.005 score 0.998 lr 1.07494e-05 
08/28/2020 18:27:38 - INFO - volta.utils -   [NLVR2]: iter 43565 Ep: 16.14 loss 0.004 score 0.998 lr 1.07288e-05 
08/28/2020 18:27:46 - INFO - volta.utils -   [NLVR2]: iter 43585 Ep: 16.15 loss 0.012 score 0.995 lr 1.07082e-05 
08/28/2020 18:27:54 - INFO - volta.utils -   [NLVR2]: iter 43605 Ep: 16.16 loss 0.001 score 1.000 lr 1.06876e-05 
08/28/2020 18:28:03 - INFO - volta.utils -   [NLVR2]: iter 43625 Ep: 16.16 loss 0.011 score 0.997 lr 1.0667e-05 
08/28/2020 18:28:11 - INFO - volta.utils -   [NLVR2]: iter 43645 Ep: 16.17 loss 0.004 score 0.998 lr 1.06464e-05 
08/28/2020 18:28:19 - INFO - volta.utils -   [NLVR2]: iter 43665 Ep: 16.18 loss 0.001 score 1.000 lr 1.06258e-05 
08/28/2020 18:28:27 - INFO - volta.utils -   [NLVR2]: iter 43685 Ep: 16.19 loss 0.004 score 0.998 lr 1.06053e-05 
08/28/2020 18:28:36 - INFO - volta.utils -   [NLVR2]: iter 43705 Ep: 16.19 loss 0.033 score 0.992 lr 1.05847e-05 
08/28/2020 18:28:44 - INFO - volta.utils -   [NLVR2]: iter 43725 Ep: 16.20 loss 0.008 score 0.995 lr 1.05641e-05 
08/28/2020 18:28:52 - INFO - volta.utils -   [NLVR2]: iter 43745 Ep: 16.21 loss 0.016 score 0.997 lr 1.05435e-05 
08/28/2020 18:29:00 - INFO - volta.utils -   [NLVR2]: iter 43765 Ep: 16.22 loss 0.014 score 0.995 lr 1.05229e-05 
08/28/2020 18:29:08 - INFO - volta.utils -   [NLVR2]: iter 43785 Ep: 16.22 loss 0.012 score 0.995 lr 1.05023e-05 
08/28/2020 18:29:16 - INFO - volta.utils -   [NLVR2]: iter 43805 Ep: 16.23 loss 0.005 score 0.997 lr 1.04818e-05 
08/28/2020 18:29:25 - INFO - volta.utils -   [NLVR2]: iter 43825 Ep: 16.24 loss 0.011 score 0.997 lr 1.04612e-05 
08/28/2020 18:29:32 - INFO - volta.utils -   [NLVR2]: iter 43845 Ep: 16.24 loss 0.005 score 0.998 lr 1.04406e-05 
08/28/2020 18:29:41 - INFO - volta.utils -   [NLVR2]: iter 43865 Ep: 16.25 loss 0.009 score 0.998 lr 1.042e-05 
08/28/2020 18:29:48 - INFO - volta.utils -   [NLVR2]: iter 43885 Ep: 16.26 loss 0.021 score 0.997 lr 1.03994e-05 
08/28/2020 18:29:57 - INFO - volta.utils -   [NLVR2]: iter 43905 Ep: 16.27 loss 0.022 score 0.995 lr 1.03788e-05 
08/28/2020 18:30:05 - INFO - volta.utils -   [NLVR2]: iter 43925 Ep: 16.27 loss 0.013 score 0.998 lr 1.03583e-05 
08/28/2020 18:30:14 - INFO - volta.utils -   [NLVR2]: iter 43945 Ep: 16.28 loss 0.017 score 0.994 lr 1.03377e-05 
08/28/2020 18:30:21 - INFO - volta.utils -   [NLVR2]: iter 43965 Ep: 16.29 loss 0.004 score 0.998 lr 1.03171e-05 
08/28/2020 18:30:30 - INFO - volta.utils -   [NLVR2]: iter 43985 Ep: 16.30 loss 0.006 score 0.997 lr 1.02965e-05 
08/28/2020 18:30:38 - INFO - volta.utils -   [NLVR2]: iter 44005 Ep: 16.30 loss 0.005 score 0.998 lr 1.02759e-05 
08/28/2020 18:30:47 - INFO - volta.utils -   [NLVR2]: iter 44025 Ep: 16.31 loss 0.026 score 0.991 lr 1.02553e-05 
08/28/2020 18:30:56 - INFO - volta.utils -   [NLVR2]: iter 44045 Ep: 16.32 loss 0.022 score 0.991 lr 1.02348e-05 
08/28/2020 18:31:05 - INFO - volta.utils -   [NLVR2]: iter 44065 Ep: 16.33 loss 0.029 score 0.992 lr 1.02142e-05 
08/28/2020 18:31:13 - INFO - volta.utils -   [NLVR2]: iter 44085 Ep: 16.33 loss 0.003 score 1.000 lr 1.01936e-05 
08/28/2020 18:31:22 - INFO - volta.utils -   [NLVR2]: iter 44105 Ep: 16.34 loss 0.031 score 0.991 lr 1.0173e-05 
08/28/2020 18:31:30 - INFO - volta.utils -   [NLVR2]: iter 44125 Ep: 16.35 loss 0.004 score 0.998 lr 1.01524e-05 
08/28/2020 18:31:38 - INFO - volta.utils -   [NLVR2]: iter 44145 Ep: 16.36 loss 0.011 score 0.997 lr 1.01318e-05 
08/28/2020 18:31:47 - INFO - volta.utils -   [NLVR2]: iter 44165 Ep: 16.36 loss 0.015 score 0.997 lr 1.01113e-05 
08/28/2020 18:31:54 - INFO - volta.utils -   [NLVR2]: iter 44185 Ep: 16.37 loss 0.016 score 0.997 lr 1.00907e-05 
08/28/2020 18:32:03 - INFO - volta.utils -   [NLVR2]: iter 44205 Ep: 16.38 loss 0.022 score 0.995 lr 1.00701e-05 
08/28/2020 18:32:10 - INFO - volta.utils -   [NLVR2]: iter 44225 Ep: 16.39 loss 0.003 score 0.998 lr 1.00495e-05 
08/28/2020 18:32:19 - INFO - volta.utils -   [NLVR2]: iter 44245 Ep: 16.39 loss 0.014 score 0.995 lr 1.00289e-05 
08/28/2020 18:32:26 - INFO - volta.utils -   [NLVR2]: iter 44265 Ep: 16.40 loss 0.009 score 0.997 lr 1.00083e-05 
08/28/2020 18:32:35 - INFO - volta.utils -   [NLVR2]: iter 44285 Ep: 16.41 loss 0.006 score 0.998 lr 9.98775e-06 
08/28/2020 18:32:42 - INFO - volta.utils -   [NLVR2]: iter 44305 Ep: 16.42 loss 0.033 score 0.994 lr 9.96717e-06 
08/28/2020 18:32:51 - INFO - volta.utils -   [NLVR2]: iter 44325 Ep: 16.42 loss 0.010 score 0.995 lr 9.94659e-06 
08/28/2020 18:32:58 - INFO - volta.utils -   [NLVR2]: iter 44345 Ep: 16.43 loss 0.019 score 0.995 lr 9.926e-06 
08/28/2020 18:33:07 - INFO - volta.utils -   [NLVR2]: iter 44365 Ep: 16.44 loss 0.016 score 0.997 lr 9.90542e-06 
08/28/2020 18:33:14 - INFO - volta.utils -   [NLVR2]: iter 44385 Ep: 16.44 loss 0.014 score 0.994 lr 9.88483e-06 
08/28/2020 18:33:23 - INFO - volta.utils -   [NLVR2]: iter 44405 Ep: 16.45 loss 0.012 score 0.992 lr 9.86425e-06 
08/28/2020 18:33:31 - INFO - volta.utils -   [NLVR2]: iter 44425 Ep: 16.46 loss 0.002 score 1.000 lr 9.84367e-06 
08/28/2020 18:33:39 - INFO - volta.utils -   [NLVR2]: iter 44445 Ep: 16.47 loss 0.012 score 0.995 lr 9.82308e-06 
08/28/2020 18:33:47 - INFO - volta.utils -   [NLVR2]: iter 44465 Ep: 16.47 loss 0.024 score 0.994 lr 9.8025e-06 
08/28/2020 18:33:56 - INFO - volta.utils -   [NLVR2]: iter 44485 Ep: 16.48 loss 0.029 score 0.991 lr 9.78192e-06 
08/28/2020 18:34:03 - INFO - volta.utils -   [NLVR2]: iter 44505 Ep: 16.49 loss 0.028 score 0.994 lr 9.76133e-06 
08/28/2020 18:34:12 - INFO - volta.utils -   [NLVR2]: iter 44525 Ep: 16.50 loss 0.013 score 0.995 lr 9.74075e-06 
08/28/2020 18:34:20 - INFO - volta.utils -   [NLVR2]: iter 44545 Ep: 16.50 loss 0.011 score 0.997 lr 9.72016e-06 
08/28/2020 18:34:29 - INFO - volta.utils -   [NLVR2]: iter 44565 Ep: 16.51 loss 0.016 score 0.995 lr 9.69958e-06 
08/28/2020 18:34:36 - INFO - volta.utils -   [NLVR2]: iter 44585 Ep: 16.52 loss 0.014 score 0.995 lr 9.679e-06 
08/28/2020 18:34:45 - INFO - volta.utils -   [NLVR2]: iter 44605 Ep: 16.53 loss 0.006 score 0.998 lr 9.65841e-06 
08/28/2020 18:34:52 - INFO - volta.utils -   [NLVR2]: iter 44625 Ep: 16.53 loss 0.013 score 0.994 lr 9.63783e-06 
08/28/2020 18:35:01 - INFO - volta.utils -   [NLVR2]: iter 44645 Ep: 16.54 loss 0.022 score 0.995 lr 9.61725e-06 
08/28/2020 18:35:09 - INFO - volta.utils -   [NLVR2]: iter 44665 Ep: 16.55 loss 0.020 score 0.997 lr 9.59666e-06 
08/28/2020 18:35:18 - INFO - volta.utils -   [NLVR2]: iter 44685 Ep: 16.56 loss 0.004 score 0.998 lr 9.57608e-06 
08/28/2020 18:35:27 - INFO - volta.utils -   [NLVR2]: iter 44705 Ep: 16.56 loss 0.008 score 0.994 lr 9.55549e-06 
08/28/2020 18:35:36 - INFO - volta.utils -   [NLVR2]: iter 44725 Ep: 16.57 loss 0.005 score 0.998 lr 9.53491e-06 
08/28/2020 18:35:44 - INFO - volta.utils -   [NLVR2]: iter 44745 Ep: 16.58 loss 0.002 score 1.000 lr 9.51433e-06 
08/28/2020 18:35:53 - INFO - volta.utils -   [NLVR2]: iter 44765 Ep: 16.59 loss 0.004 score 0.998 lr 9.49374e-06 
08/28/2020 18:36:00 - INFO - volta.utils -   [NLVR2]: iter 44785 Ep: 16.59 loss 0.013 score 0.995 lr 9.47316e-06 
08/28/2020 18:36:09 - INFO - volta.utils -   [NLVR2]: iter 44805 Ep: 16.60 loss 0.016 score 0.995 lr 9.45258e-06 
08/28/2020 18:36:17 - INFO - volta.utils -   [NLVR2]: iter 44825 Ep: 16.61 loss 0.022 score 0.994 lr 9.43199e-06 
08/28/2020 18:36:26 - INFO - volta.utils -   [NLVR2]: iter 44845 Ep: 16.62 loss 0.012 score 0.995 lr 9.41141e-06 
08/28/2020 18:36:34 - INFO - volta.utils -   [NLVR2]: iter 44865 Ep: 16.62 loss 0.014 score 0.995 lr 9.39082e-06 
08/28/2020 18:36:42 - INFO - volta.utils -   [NLVR2]: iter 44885 Ep: 16.63 loss 0.010 score 0.995 lr 9.37024e-06 
08/28/2020 18:36:50 - INFO - volta.utils -   [NLVR2]: iter 44905 Ep: 16.64 loss 0.019 score 0.995 lr 9.34966e-06 
08/28/2020 18:36:58 - INFO - volta.utils -   [NLVR2]: iter 44925 Ep: 16.65 loss 0.011 score 0.995 lr 9.32907e-06 
08/28/2020 18:37:07 - INFO - volta.utils -   [NLVR2]: iter 44945 Ep: 16.65 loss 0.011 score 0.998 lr 9.30849e-06 
08/28/2020 18:37:15 - INFO - volta.utils -   [NLVR2]: iter 44965 Ep: 16.66 loss 0.010 score 0.997 lr 9.2879e-06 
08/28/2020 18:37:24 - INFO - volta.utils -   [NLVR2]: iter 44985 Ep: 16.67 loss 0.011 score 0.997 lr 9.26732e-06 
08/28/2020 18:37:32 - INFO - volta.utils -   [NLVR2]: iter 45005 Ep: 16.67 loss 0.036 score 0.991 lr 9.24674e-06 
08/28/2020 18:37:40 - INFO - volta.utils -   [NLVR2]: iter 45025 Ep: 16.68 loss 0.010 score 0.997 lr 9.22615e-06 
08/28/2020 18:37:48 - INFO - volta.utils -   [NLVR2]: iter 45045 Ep: 16.69 loss 0.001 score 1.000 lr 9.20557e-06 
08/28/2020 18:37:56 - INFO - volta.utils -   [NLVR2]: iter 45065 Ep: 16.70 loss 0.016 score 0.994 lr 9.18499e-06 
08/28/2020 18:38:04 - INFO - volta.utils -   [NLVR2]: iter 45085 Ep: 16.70 loss 0.003 score 0.998 lr 9.1644e-06 
08/28/2020 18:38:13 - INFO - volta.utils -   [NLVR2]: iter 45105 Ep: 16.71 loss 0.030 score 0.991 lr 9.14382e-06 
08/28/2020 18:38:22 - INFO - volta.utils -   [NLVR2]: iter 45125 Ep: 16.72 loss 0.012 score 0.998 lr 9.12323e-06 
08/28/2020 18:38:31 - INFO - volta.utils -   [NLVR2]: iter 45145 Ep: 16.73 loss 0.012 score 0.997 lr 9.10265e-06 
08/28/2020 18:38:40 - INFO - volta.utils -   [NLVR2]: iter 45165 Ep: 16.73 loss 0.005 score 0.998 lr 9.08207e-06 
08/28/2020 18:38:49 - INFO - volta.utils -   [NLVR2]: iter 45185 Ep: 16.74 loss 0.011 score 0.998 lr 9.06148e-06 
08/28/2020 18:38:56 - INFO - volta.utils -   [NLVR2]: iter 45205 Ep: 16.75 loss 0.015 score 0.995 lr 9.0409e-06 
08/28/2020 18:39:05 - INFO - volta.utils -   [NLVR2]: iter 45225 Ep: 16.76 loss 0.021 score 0.995 lr 9.02032e-06 
08/28/2020 18:39:12 - INFO - volta.utils -   [NLVR2]: iter 45245 Ep: 16.76 loss 0.008 score 0.998 lr 8.99973e-06 
08/28/2020 18:39:21 - INFO - volta.utils -   [NLVR2]: iter 45265 Ep: 16.77 loss 0.022 score 0.995 lr 8.97915e-06 
08/28/2020 18:39:29 - INFO - volta.utils -   [NLVR2]: iter 45285 Ep: 16.78 loss 0.006 score 0.997 lr 8.95856e-06 
08/28/2020 18:39:37 - INFO - volta.utils -   [NLVR2]: iter 45305 Ep: 16.79 loss 0.009 score 0.997 lr 8.93798e-06 
08/28/2020 18:39:45 - INFO - volta.utils -   [NLVR2]: iter 45325 Ep: 16.79 loss 0.030 score 0.992 lr 8.9174e-06 
08/28/2020 18:39:54 - INFO - volta.utils -   [NLVR2]: iter 45345 Ep: 16.80 loss 0.003 score 1.000 lr 8.89681e-06 
08/28/2020 18:40:03 - INFO - volta.utils -   [NLVR2]: iter 45365 Ep: 16.81 loss 0.016 score 0.994 lr 8.87623e-06 
08/28/2020 18:40:12 - INFO - volta.utils -   [NLVR2]: iter 45385 Ep: 16.82 loss 0.015 score 0.997 lr 8.85565e-06 
08/28/2020 18:40:19 - INFO - volta.utils -   [NLVR2]: iter 45405 Ep: 16.82 loss 0.014 score 0.997 lr 8.83506e-06 
08/28/2020 18:40:28 - INFO - volta.utils -   [NLVR2]: iter 45425 Ep: 16.83 loss 0.018 score 0.995 lr 8.81448e-06 
08/28/2020 18:40:39 - INFO - volta.utils -   [NLVR2]: iter 45445 Ep: 16.84 loss 0.047 score 0.988 lr 8.79389e-06 
08/28/2020 18:40:49 - INFO - volta.utils -   [NLVR2]: iter 45465 Ep: 16.85 loss 0.005 score 0.998 lr 8.77331e-06 
08/28/2020 18:40:58 - INFO - volta.utils -   [NLVR2]: iter 45485 Ep: 16.85 loss 0.031 score 0.992 lr 8.75273e-06 
08/28/2020 18:41:08 - INFO - volta.utils -   [NLVR2]: iter 45505 Ep: 16.86 loss 0.014 score 0.997 lr 8.73214e-06 
08/28/2020 18:41:15 - INFO - volta.utils -   [NLVR2]: iter 45525 Ep: 16.87 loss 0.013 score 0.997 lr 8.71156e-06 
08/28/2020 18:41:24 - INFO - volta.utils -   [NLVR2]: iter 45545 Ep: 16.87 loss 0.002 score 1.000 lr 8.69098e-06 
08/28/2020 18:41:32 - INFO - volta.utils -   [NLVR2]: iter 45565 Ep: 16.88 loss 0.004 score 0.998 lr 8.67039e-06 
08/28/2020 18:41:41 - INFO - volta.utils -   [NLVR2]: iter 45585 Ep: 16.89 loss 0.030 score 0.991 lr 8.64981e-06 
08/28/2020 18:41:50 - INFO - volta.utils -   [NLVR2]: iter 45605 Ep: 16.90 loss 0.007 score 0.998 lr 8.62922e-06 
08/28/2020 18:41:58 - INFO - volta.utils -   [NLVR2]: iter 45625 Ep: 16.90 loss 0.007 score 0.998 lr 8.60864e-06 
08/28/2020 18:42:08 - INFO - volta.utils -   [NLVR2]: iter 45645 Ep: 16.91 loss 0.010 score 0.997 lr 8.58806e-06 
08/28/2020 18:42:15 - INFO - volta.utils -   [NLVR2]: iter 45665 Ep: 16.92 loss 0.003 score 1.000 lr 8.56747e-06 
08/28/2020 18:42:24 - INFO - volta.utils -   [NLVR2]: iter 45685 Ep: 16.93 loss 0.018 score 0.994 lr 8.54689e-06 
08/28/2020 18:42:32 - INFO - volta.utils -   [NLVR2]: iter 45705 Ep: 16.93 loss 0.004 score 0.998 lr 8.52631e-06 
08/28/2020 18:42:42 - INFO - volta.utils -   [NLVR2]: iter 45725 Ep: 16.94 loss 0.005 score 0.998 lr 8.50572e-06 
08/28/2020 18:42:50 - INFO - volta.utils -   [NLVR2]: iter 45745 Ep: 16.95 loss 0.005 score 0.998 lr 8.48514e-06 
08/28/2020 18:43:00 - INFO - volta.utils -   [NLVR2]: iter 45765 Ep: 16.96 loss 0.008 score 0.997 lr 8.46455e-06 
08/28/2020 18:43:08 - INFO - volta.utils -   [NLVR2]: iter 45785 Ep: 16.96 loss 0.002 score 1.000 lr 8.44397e-06 
08/28/2020 18:43:18 - INFO - volta.utils -   [NLVR2]: iter 45805 Ep: 16.97 loss 0.006 score 0.997 lr 8.42339e-06 
08/28/2020 18:43:27 - INFO - volta.utils -   [NLVR2]: iter 45825 Ep: 16.98 loss 0.013 score 0.997 lr 8.4028e-06 
08/28/2020 18:43:35 - INFO - volta.utils -   [NLVR2]: iter 45845 Ep: 16.99 loss 0.008 score 0.998 lr 8.38222e-06 
08/28/2020 18:43:43 - INFO - volta.utils -   [NLVR2]: iter 45865 Ep: 16.99 loss 0.013 score 0.997 lr 8.36164e-06 
08/28/2020 18:43:51 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  67%|██████▋   | 6/9 [2:09:07<1:04:22, 1287.52s/it]08/28/2020 18:47:14 - INFO - volta.utils -   Eval task TASK12 on iteration 45884 
08/28/2020 18:47:14 - INFO - volta.utils -   Validation [NLVR2]: loss 1.971 score 70.241 
08/28/2020 18:47:24 - INFO - volta.utils -   [NLVR2]: iter 45904 Ep: 17.01 loss 0.002 score 1.000 lr 8.33127e-06 
08/28/2020 18:47:32 - INFO - volta.utils -   [NLVR2]: iter 45924 Ep: 17.02 loss 0.009 score 0.998 lr 8.30091e-06 
08/28/2020 18:47:42 - INFO - volta.utils -   [NLVR2]: iter 45944 Ep: 17.02 loss 0.003 score 0.998 lr 8.28033e-06 
08/28/2020 18:47:50 - INFO - volta.utils -   [NLVR2]: iter 45964 Ep: 17.03 loss 0.007 score 0.998 lr 8.25975e-06 
08/28/2020 18:48:00 - INFO - volta.utils -   [NLVR2]: iter 45984 Ep: 17.04 loss 0.015 score 0.997 lr 8.23916e-06 
08/28/2020 18:48:08 - INFO - volta.utils -   [NLVR2]: iter 46004 Ep: 17.04 loss 0.003 score 1.000 lr 8.21858e-06 
08/28/2020 18:48:17 - INFO - volta.utils -   [NLVR2]: iter 46024 Ep: 17.05 loss 0.007 score 0.997 lr 8.198e-06 
08/28/2020 18:48:41 - INFO - volta.utils -   [NLVR2]: iter 46044 Ep: 17.06 loss 0.009 score 0.997 lr 8.17741e-06 
08/28/2020 18:48:59 - INFO - volta.utils -   [NLVR2]: iter 46064 Ep: 17.07 loss 0.002 score 1.000 lr 8.15683e-06 
08/28/2020 18:49:12 - INFO - volta.utils -   [NLVR2]: iter 46084 Ep: 17.07 loss 0.012 score 0.998 lr 8.13624e-06 
08/28/2020 18:49:21 - INFO - volta.utils -   [NLVR2]: iter 46104 Ep: 17.08 loss 0.001 score 1.000 lr 8.11566e-06 
08/28/2020 18:49:29 - INFO - volta.utils -   [NLVR2]: iter 46124 Ep: 17.09 loss 0.013 score 0.994 lr 8.09508e-06 
08/28/2020 18:49:38 - INFO - volta.utils -   [NLVR2]: iter 46144 Ep: 17.10 loss 0.025 score 0.995 lr 8.07449e-06 
08/28/2020 18:49:45 - INFO - volta.utils -   [NLVR2]: iter 46164 Ep: 17.10 loss 0.007 score 0.998 lr 8.05391e-06 
08/28/2020 18:49:54 - INFO - volta.utils -   [NLVR2]: iter 46184 Ep: 17.11 loss 0.001 score 1.000 lr 8.03333e-06 
08/28/2020 18:50:02 - INFO - volta.utils -   [NLVR2]: iter 46204 Ep: 17.12 loss 0.002 score 1.000 lr 8.01274e-06 
08/28/2020 18:50:10 - INFO - volta.utils -   [NLVR2]: iter 46224 Ep: 17.13 loss 0.019 score 0.995 lr 7.99216e-06 
08/28/2020 18:50:29 - INFO - volta.utils -   [NLVR2]: iter 46244 Ep: 17.13 loss 0.010 score 0.997 lr 7.97157e-06 
08/28/2020 18:50:46 - INFO - volta.utils -   [NLVR2]: iter 46264 Ep: 17.14 loss 0.015 score 0.995 lr 7.95099e-06 
08/28/2020 18:51:00 - INFO - volta.utils -   [NLVR2]: iter 46284 Ep: 17.15 loss 0.005 score 0.998 lr 7.93041e-06 
08/28/2020 18:51:08 - INFO - volta.utils -   [NLVR2]: iter 46304 Ep: 17.16 loss 0.009 score 0.997 lr 7.90982e-06 
08/28/2020 18:51:17 - INFO - volta.utils -   [NLVR2]: iter 46324 Ep: 17.16 loss 0.015 score 0.995 lr 7.88924e-06 
08/28/2020 18:51:25 - INFO - volta.utils -   [NLVR2]: iter 46344 Ep: 17.17 loss 0.018 score 0.997 lr 7.86866e-06 
08/28/2020 18:51:34 - INFO - volta.utils -   [NLVR2]: iter 46364 Ep: 17.18 loss 0.006 score 0.995 lr 7.84807e-06 
08/28/2020 18:51:42 - INFO - volta.utils -   [NLVR2]: iter 46384 Ep: 17.19 loss 0.010 score 0.997 lr 7.82749e-06 
08/28/2020 18:51:51 - INFO - volta.utils -   [NLVR2]: iter 46404 Ep: 17.19 loss 0.001 score 1.000 lr 7.8069e-06 
08/28/2020 18:51:59 - INFO - volta.utils -   [NLVR2]: iter 46424 Ep: 17.20 loss 0.001 score 1.000 lr 7.78632e-06 
08/28/2020 18:52:08 - INFO - volta.utils -   [NLVR2]: iter 46444 Ep: 17.21 loss 0.011 score 0.997 lr 7.76574e-06 
08/28/2020 18:52:17 - INFO - volta.utils -   [NLVR2]: iter 46464 Ep: 17.22 loss 0.012 score 0.997 lr 7.74515e-06 
08/28/2020 18:52:26 - INFO - volta.utils -   [NLVR2]: iter 46484 Ep: 17.22 loss 0.009 score 0.998 lr 7.72457e-06 
08/28/2020 18:52:48 - INFO - volta.utils -   [NLVR2]: iter 46504 Ep: 17.23 loss 0.009 score 0.998 lr 7.70399e-06 
08/28/2020 18:53:09 - INFO - volta.utils -   [NLVR2]: iter 46524 Ep: 17.24 loss 0.004 score 0.998 lr 7.6834e-06 
08/28/2020 18:53:21 - INFO - volta.utils -   [NLVR2]: iter 46544 Ep: 17.24 loss 0.001 score 1.000 lr 7.66282e-06 
08/28/2020 18:53:30 - INFO - volta.utils -   [NLVR2]: iter 46564 Ep: 17.25 loss 0.011 score 0.995 lr 7.64223e-06 
08/28/2020 18:53:38 - INFO - volta.utils -   [NLVR2]: iter 46584 Ep: 17.26 loss 0.033 score 0.989 lr 7.62165e-06 
08/28/2020 18:53:47 - INFO - volta.utils -   [NLVR2]: iter 46604 Ep: 17.27 loss 0.015 score 0.995 lr 7.60107e-06 
08/28/2020 18:53:55 - INFO - volta.utils -   [NLVR2]: iter 46624 Ep: 17.27 loss 0.013 score 0.995 lr 7.58048e-06 
08/28/2020 18:54:05 - INFO - volta.utils -   [NLVR2]: iter 46644 Ep: 17.28 loss 0.007 score 0.998 lr 7.5599e-06 
08/28/2020 18:54:16 - INFO - volta.utils -   [NLVR2]: iter 46664 Ep: 17.29 loss 0.002 score 0.998 lr 7.53931e-06 
08/28/2020 18:54:33 - INFO - volta.utils -   [NLVR2]: iter 46684 Ep: 17.30 loss 0.005 score 0.998 lr 7.51873e-06 
08/28/2020 18:54:48 - INFO - volta.utils -   [NLVR2]: iter 46704 Ep: 17.30 loss 0.006 score 0.997 lr 7.49815e-06 
08/28/2020 18:54:59 - INFO - volta.utils -   [NLVR2]: iter 46724 Ep: 17.31 loss 0.004 score 0.997 lr 7.47756e-06 
08/28/2020 18:55:10 - INFO - volta.utils -   [NLVR2]: iter 46744 Ep: 17.32 loss 0.002 score 0.998 lr 7.45698e-06 
08/28/2020 18:55:19 - INFO - volta.utils -   [NLVR2]: iter 46764 Ep: 17.33 loss 0.027 score 0.994 lr 7.4364e-06 
08/28/2020 18:55:27 - INFO - volta.utils -   [NLVR2]: iter 46784 Ep: 17.33 loss 0.022 score 0.994 lr 7.41581e-06 
08/28/2020 18:55:36 - INFO - volta.utils -   [NLVR2]: iter 46804 Ep: 17.34 loss 0.009 score 0.998 lr 7.39523e-06 
08/28/2020 18:55:45 - INFO - volta.utils -   [NLVR2]: iter 46824 Ep: 17.35 loss 0.001 score 1.000 lr 7.37464e-06 
08/28/2020 18:55:54 - INFO - volta.utils -   [NLVR2]: iter 46844 Ep: 17.36 loss 0.003 score 0.998 lr 7.35406e-06 
08/28/2020 18:56:02 - INFO - volta.utils -   [NLVR2]: iter 46864 Ep: 17.36 loss 0.001 score 1.000 lr 7.33348e-06 
08/28/2020 18:56:11 - INFO - volta.utils -   [NLVR2]: iter 46884 Ep: 17.37 loss 0.012 score 0.998 lr 7.31289e-06 
08/28/2020 18:56:19 - INFO - volta.utils -   [NLVR2]: iter 46904 Ep: 17.38 loss 0.002 score 1.000 lr 7.29231e-06 
08/28/2020 18:56:27 - INFO - volta.utils -   [NLVR2]: iter 46924 Ep: 17.39 loss 0.001 score 1.000 lr 7.27173e-06 
08/28/2020 18:56:36 - INFO - volta.utils -   [NLVR2]: iter 46944 Ep: 17.39 loss 0.013 score 0.997 lr 7.25114e-06 
08/28/2020 18:56:44 - INFO - volta.utils -   [NLVR2]: iter 46964 Ep: 17.40 loss 0.005 score 0.998 lr 7.23056e-06 
08/28/2020 18:57:01 - INFO - volta.utils -   [NLVR2]: iter 46984 Ep: 17.41 loss 0.011 score 0.995 lr 7.20997e-06 
08/28/2020 18:57:21 - INFO - volta.utils -   [NLVR2]: iter 47004 Ep: 17.42 loss 0.003 score 0.998 lr 7.18939e-06 
08/28/2020 18:57:38 - INFO - volta.utils -   [NLVR2]: iter 47024 Ep: 17.42 loss 0.012 score 0.997 lr 7.16881e-06 
08/28/2020 18:57:46 - INFO - volta.utils -   [NLVR2]: iter 47044 Ep: 17.43 loss 0.016 score 0.997 lr 7.14822e-06 
08/28/2020 18:57:55 - INFO - volta.utils -   [NLVR2]: iter 47064 Ep: 17.44 loss 0.003 score 0.997 lr 7.12764e-06 
08/28/2020 18:58:04 - INFO - volta.utils -   [NLVR2]: iter 47084 Ep: 17.44 loss 0.007 score 0.998 lr 7.10706e-06 
08/28/2020 18:58:13 - INFO - volta.utils -   [NLVR2]: iter 47104 Ep: 17.45 loss 0.000 score 1.000 lr 7.08647e-06 
08/28/2020 18:58:21 - INFO - volta.utils -   [NLVR2]: iter 47124 Ep: 17.46 loss 0.001 score 1.000 lr 7.06589e-06 
08/28/2020 18:58:31 - INFO - volta.utils -   [NLVR2]: iter 47144 Ep: 17.47 loss 0.000 score 1.000 lr 7.0453e-06 
08/28/2020 18:58:39 - INFO - volta.utils -   [NLVR2]: iter 47164 Ep: 17.47 loss 0.009 score 0.997 lr 7.02472e-06 
08/28/2020 18:58:48 - INFO - volta.utils -   [NLVR2]: iter 47184 Ep: 17.48 loss 0.001 score 1.000 lr 7.00414e-06 
08/28/2020 18:59:12 - INFO - volta.utils -   [NLVR2]: iter 47204 Ep: 17.49 loss 0.009 score 0.994 lr 6.98355e-06 
08/28/2020 18:59:28 - INFO - volta.utils -   [NLVR2]: iter 47224 Ep: 17.50 loss 0.001 score 1.000 lr 6.96297e-06 
08/28/2020 18:59:41 - INFO - volta.utils -   [NLVR2]: iter 47244 Ep: 17.50 loss 0.002 score 0.998 lr 6.94239e-06 
08/28/2020 18:59:53 - INFO - volta.utils -   [NLVR2]: iter 47264 Ep: 17.51 loss 0.007 score 0.998 lr 6.9218e-06 
08/28/2020 19:00:01 - INFO - volta.utils -   [NLVR2]: iter 47284 Ep: 17.52 loss 0.016 score 0.995 lr 6.90122e-06 
08/28/2020 19:00:09 - INFO - volta.utils -   [NLVR2]: iter 47304 Ep: 17.53 loss 0.001 score 1.000 lr 6.88063e-06 
08/28/2020 19:01:06 - INFO - volta.utils -   [NLVR2]: iter 47324 Ep: 17.53 loss 0.020 score 0.995 lr 6.86005e-06 
08/28/2020 19:01:15 - INFO - volta.utils -   [NLVR2]: iter 47344 Ep: 17.54 loss 0.006 score 0.998 lr 6.83947e-06 
08/28/2020 19:01:24 - INFO - volta.utils -   [NLVR2]: iter 47364 Ep: 17.55 loss 0.002 score 0.998 lr 6.81888e-06 
08/28/2020 19:01:33 - INFO - volta.utils -   [NLVR2]: iter 47384 Ep: 17.56 loss 0.001 score 1.000 lr 6.7983e-06 
08/28/2020 19:01:41 - INFO - volta.utils -   [NLVR2]: iter 47404 Ep: 17.56 loss 0.002 score 0.998 lr 6.77772e-06 
08/28/2020 19:01:51 - INFO - volta.utils -   [NLVR2]: iter 47424 Ep: 17.57 loss 0.019 score 0.995 lr 6.75713e-06 
08/28/2020 19:01:59 - INFO - volta.utils -   [NLVR2]: iter 47444 Ep: 17.58 loss 0.015 score 0.998 lr 6.73655e-06 
08/28/2020 19:02:17 - INFO - volta.utils -   [NLVR2]: iter 47464 Ep: 17.59 loss 0.006 score 0.998 lr 6.71596e-06 
08/28/2020 19:02:36 - INFO - volta.utils -   [NLVR2]: iter 47484 Ep: 17.59 loss 0.011 score 0.997 lr 6.69538e-06 
08/28/2020 19:02:57 - INFO - volta.utils -   [NLVR2]: iter 47504 Ep: 17.60 loss 0.004 score 0.997 lr 6.6748e-06 
08/28/2020 19:03:05 - INFO - volta.utils -   [NLVR2]: iter 47524 Ep: 17.61 loss 0.001 score 1.000 lr 6.65421e-06 
08/28/2020 19:03:14 - INFO - volta.utils -   [NLVR2]: iter 47544 Ep: 17.62 loss 0.011 score 0.998 lr 6.63363e-06 
08/28/2020 19:03:21 - INFO - volta.utils -   [NLVR2]: iter 47564 Ep: 17.62 loss 0.001 score 1.000 lr 6.61305e-06 
08/28/2020 19:03:30 - INFO - volta.utils -   [NLVR2]: iter 47584 Ep: 17.63 loss 0.004 score 0.998 lr 6.59246e-06 
08/28/2020 19:03:38 - INFO - volta.utils -   [NLVR2]: iter 47604 Ep: 17.64 loss 0.020 score 0.994 lr 6.57188e-06 
08/28/2020 19:03:46 - INFO - volta.utils -   [NLVR2]: iter 47624 Ep: 17.65 loss 0.013 score 0.998 lr 6.55129e-06 
08/28/2020 19:03:54 - INFO - volta.utils -   [NLVR2]: iter 47644 Ep: 17.65 loss 0.002 score 0.998 lr 6.53071e-06 
08/28/2020 19:04:05 - INFO - volta.utils -   [NLVR2]: iter 47664 Ep: 17.66 loss 0.009 score 0.998 lr 6.51013e-06 
08/28/2020 19:04:14 - INFO - volta.utils -   [NLVR2]: iter 47684 Ep: 17.67 loss 0.013 score 0.997 lr 6.48954e-06 
08/28/2020 19:04:32 - INFO - volta.utils -   [NLVR2]: iter 47704 Ep: 17.67 loss 0.001 score 1.000 lr 6.46896e-06 
08/28/2020 19:04:55 - INFO - volta.utils -   [NLVR2]: iter 47724 Ep: 17.68 loss 0.000 score 1.000 lr 6.44838e-06 
08/28/2020 19:05:08 - INFO - volta.utils -   [NLVR2]: iter 47744 Ep: 17.69 loss 0.012 score 0.997 lr 6.42779e-06 
08/28/2020 19:05:22 - INFO - volta.utils -   [NLVR2]: iter 47764 Ep: 17.70 loss 0.018 score 0.995 lr 6.40721e-06 
08/28/2020 19:05:30 - INFO - volta.utils -   [NLVR2]: iter 47784 Ep: 17.70 loss 0.005 score 0.998 lr 6.38662e-06 
08/28/2020 19:05:39 - INFO - volta.utils -   [NLVR2]: iter 47804 Ep: 17.71 loss 0.008 score 0.998 lr 6.36604e-06 
08/28/2020 19:05:48 - INFO - volta.utils -   [NLVR2]: iter 47824 Ep: 17.72 loss 0.001 score 1.000 lr 6.34546e-06 
08/28/2020 19:05:57 - INFO - volta.utils -   [NLVR2]: iter 47844 Ep: 17.73 loss 0.013 score 0.998 lr 6.32487e-06 
08/28/2020 19:06:05 - INFO - volta.utils -   [NLVR2]: iter 47864 Ep: 17.73 loss 0.011 score 0.998 lr 6.30429e-06 
08/28/2020 19:06:14 - INFO - volta.utils -   [NLVR2]: iter 47884 Ep: 17.74 loss 0.001 score 1.000 lr 6.28371e-06 
08/28/2020 19:06:22 - INFO - volta.utils -   [NLVR2]: iter 47904 Ep: 17.75 loss 0.011 score 0.997 lr 6.26312e-06 
08/28/2020 19:06:31 - INFO - volta.utils -   [NLVR2]: iter 47924 Ep: 17.76 loss 0.002 score 1.000 lr 6.24254e-06 
08/28/2020 19:06:39 - INFO - volta.utils -   [NLVR2]: iter 47944 Ep: 17.76 loss 0.011 score 0.994 lr 6.22195e-06 
08/28/2020 19:07:00 - INFO - volta.utils -   [NLVR2]: iter 47964 Ep: 17.77 loss 0.006 score 0.998 lr 6.20137e-06 
08/28/2020 19:07:18 - INFO - volta.utils -   [NLVR2]: iter 47984 Ep: 17.78 loss 0.004 score 0.997 lr 6.18079e-06 
08/28/2020 19:07:33 - INFO - volta.utils -   [NLVR2]: iter 48004 Ep: 17.79 loss 0.001 score 1.000 lr 6.1602e-06 
08/28/2020 19:07:41 - INFO - volta.utils -   [NLVR2]: iter 48024 Ep: 17.79 loss 0.004 score 0.997 lr 6.13962e-06 
08/28/2020 19:07:50 - INFO - volta.utils -   [NLVR2]: iter 48044 Ep: 17.80 loss 0.000 score 1.000 lr 6.11904e-06 
08/28/2020 19:07:58 - INFO - volta.utils -   [NLVR2]: iter 48064 Ep: 17.81 loss 0.005 score 0.998 lr 6.09845e-06 
08/28/2020 19:08:07 - INFO - volta.utils -   [NLVR2]: iter 48084 Ep: 17.82 loss 0.004 score 0.997 lr 6.07787e-06 
08/28/2020 19:08:15 - INFO - volta.utils -   [NLVR2]: iter 48104 Ep: 17.82 loss 0.001 score 1.000 lr 6.05728e-06 
08/28/2020 19:08:24 - INFO - volta.utils -   [NLVR2]: iter 48124 Ep: 17.83 loss 0.003 score 0.998 lr 6.0367e-06 
08/28/2020 19:08:32 - INFO - volta.utils -   [NLVR2]: iter 48144 Ep: 17.84 loss 0.007 score 0.997 lr 6.01612e-06 
08/28/2020 19:08:41 - INFO - volta.utils -   [NLVR2]: iter 48164 Ep: 17.85 loss 0.003 score 0.998 lr 5.99553e-06 
08/28/2020 19:09:03 - INFO - volta.utils -   [NLVR2]: iter 48184 Ep: 17.85 loss 0.004 score 0.997 lr 5.97495e-06 
08/28/2020 19:09:26 - INFO - volta.utils -   [NLVR2]: iter 48204 Ep: 17.86 loss 0.008 score 0.998 lr 5.95437e-06 
08/28/2020 19:09:38 - INFO - volta.utils -   [NLVR2]: iter 48224 Ep: 17.87 loss 0.003 score 0.998 lr 5.93378e-06 
08/28/2020 19:09:47 - INFO - volta.utils -   [NLVR2]: iter 48244 Ep: 17.87 loss 0.006 score 0.998 lr 5.9132e-06 
08/28/2020 19:09:55 - INFO - volta.utils -   [NLVR2]: iter 48264 Ep: 17.88 loss 0.039 score 0.994 lr 5.89261e-06 
08/28/2020 19:10:04 - INFO - volta.utils -   [NLVR2]: iter 48284 Ep: 17.89 loss 0.003 score 0.998 lr 5.87203e-06 
08/28/2020 19:10:12 - INFO - volta.utils -   [NLVR2]: iter 48304 Ep: 17.90 loss 0.010 score 0.995 lr 5.85145e-06 
08/28/2020 19:10:20 - INFO - volta.utils -   [NLVR2]: iter 48324 Ep: 17.90 loss 0.016 score 0.995 lr 5.83086e-06 
08/28/2020 19:10:33 - INFO - volta.utils -   [NLVR2]: iter 48344 Ep: 17.91 loss 0.005 score 0.997 lr 5.81028e-06 
08/28/2020 19:10:41 - INFO - volta.utils -   [NLVR2]: iter 48364 Ep: 17.92 loss 0.002 score 0.998 lr 5.7897e-06 
08/28/2020 19:10:50 - INFO - volta.utils -   [NLVR2]: iter 48384 Ep: 17.93 loss 0.008 score 0.995 lr 5.76911e-06 
08/28/2020 19:11:01 - INFO - volta.utils -   [NLVR2]: iter 48404 Ep: 17.93 loss 0.009 score 0.998 lr 5.74853e-06 
08/28/2020 19:11:32 - INFO - volta.utils -   [NLVR2]: iter 48424 Ep: 17.94 loss 0.013 score 0.998 lr 5.72794e-06 
08/28/2020 19:11:45 - INFO - volta.utils -   [NLVR2]: iter 48444 Ep: 17.95 loss 0.018 score 0.995 lr 5.70736e-06 
08/28/2020 19:11:56 - INFO - volta.utils -   [NLVR2]: iter 48464 Ep: 17.96 loss 0.006 score 0.998 lr 5.68678e-06 
08/28/2020 19:12:04 - INFO - volta.utils -   [NLVR2]: iter 48484 Ep: 17.96 loss 0.012 score 0.998 lr 5.66619e-06 
08/28/2020 19:12:14 - INFO - volta.utils -   [NLVR2]: iter 48504 Ep: 17.97 loss 0.012 score 0.998 lr 5.64561e-06 
08/28/2020 19:12:22 - INFO - volta.utils -   [NLVR2]: iter 48524 Ep: 17.98 loss 0.012 score 0.997 lr 5.62503e-06 
08/28/2020 19:12:31 - INFO - volta.utils -   [NLVR2]: iter 48544 Ep: 17.99 loss 0.004 score 0.998 lr 5.60444e-06 
08/28/2020 19:12:39 - INFO - volta.utils -   [NLVR2]: iter 48564 Ep: 17.99 loss 0.001 score 1.000 lr 5.58386e-06 
08/28/2020 19:12:46 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  78%|███████▊  | 7/9 [2:38:04<47:24, 1422.19s/it]  08/28/2020 19:17:26 - INFO - volta.utils -   Eval task TASK12 on iteration 48583 
08/28/2020 19:17:26 - INFO - volta.utils -   Validation [NLVR2]: loss 2.029 score 70.628 
08/28/2020 19:17:35 - INFO - volta.utils -   [NLVR2]: iter 48603 Ep: 18.01 loss 0.005 score 0.998 lr 5.5535e-06 
08/28/2020 19:17:56 - INFO - volta.utils -   [NLVR2]: iter 48623 Ep: 18.02 loss 0.008 score 0.998 lr 5.52314e-06 
08/28/2020 19:18:15 - INFO - volta.utils -   [NLVR2]: iter 48643 Ep: 18.02 loss 0.003 score 0.998 lr 5.50255e-06 
08/28/2020 19:18:22 - INFO - volta.utils -   [NLVR2]: iter 48663 Ep: 18.03 loss 0.001 score 1.000 lr 5.48197e-06 
08/28/2020 19:18:35 - INFO - volta.utils -   [NLVR2]: iter 48683 Ep: 18.04 loss 0.006 score 0.998 lr 5.46138e-06 
08/28/2020 19:18:43 - INFO - volta.utils -   [NLVR2]: iter 48703 Ep: 18.04 loss 0.000 score 1.000 lr 5.4408e-06 
08/28/2020 19:18:53 - INFO - volta.utils -   [NLVR2]: iter 48723 Ep: 18.05 loss 0.003 score 0.998 lr 5.42022e-06 
08/28/2020 19:19:01 - INFO - volta.utils -   [NLVR2]: iter 48743 Ep: 18.06 loss 0.007 score 0.998 lr 5.39963e-06 
08/28/2020 19:19:09 - INFO - volta.utils -   [NLVR2]: iter 48763 Ep: 18.07 loss 0.012 score 0.995 lr 5.37905e-06 
08/28/2020 19:19:17 - INFO - volta.utils -   [NLVR2]: iter 48783 Ep: 18.07 loss 0.013 score 0.998 lr 5.35847e-06 
08/28/2020 19:19:37 - INFO - volta.utils -   [NLVR2]: iter 48803 Ep: 18.08 loss 0.011 score 0.997 lr 5.33788e-06 
08/28/2020 19:20:08 - INFO - volta.utils -   [NLVR2]: iter 48823 Ep: 18.09 loss 0.008 score 0.997 lr 5.3173e-06 
08/28/2020 19:20:18 - INFO - volta.utils -   [NLVR2]: iter 48843 Ep: 18.10 loss 0.003 score 0.998 lr 5.29671e-06 
08/28/2020 19:20:26 - INFO - volta.utils -   [NLVR2]: iter 48863 Ep: 18.10 loss 0.009 score 0.998 lr 5.27613e-06 
08/28/2020 19:20:34 - INFO - volta.utils -   [NLVR2]: iter 48883 Ep: 18.11 loss 0.001 score 1.000 lr 5.25555e-06 
08/28/2020 19:20:43 - INFO - volta.utils -   [NLVR2]: iter 48903 Ep: 18.12 loss 0.005 score 0.998 lr 5.23496e-06 
08/28/2020 19:20:51 - INFO - volta.utils -   [NLVR2]: iter 48923 Ep: 18.13 loss 0.001 score 1.000 lr 5.21438e-06 
08/28/2020 19:21:00 - INFO - volta.utils -   [NLVR2]: iter 48943 Ep: 18.13 loss 0.001 score 1.000 lr 5.1938e-06 
08/28/2020 19:21:23 - INFO - volta.utils -   [NLVR2]: iter 48963 Ep: 18.14 loss 0.018 score 0.997 lr 5.17321e-06 
08/28/2020 19:21:40 - INFO - volta.utils -   [NLVR2]: iter 48983 Ep: 18.15 loss 0.000 score 1.000 lr 5.15263e-06 
08/28/2020 19:21:54 - INFO - volta.utils -   [NLVR2]: iter 49003 Ep: 18.16 loss 0.014 score 0.998 lr 5.13204e-06 
08/28/2020 19:22:04 - INFO - volta.utils -   [NLVR2]: iter 49023 Ep: 18.16 loss 0.003 score 0.998 lr 5.11146e-06 
08/28/2020 19:22:13 - INFO - volta.utils -   [NLVR2]: iter 49043 Ep: 18.17 loss 0.001 score 1.000 lr 5.09088e-06 
08/28/2020 19:22:21 - INFO - volta.utils -   [NLVR2]: iter 49063 Ep: 18.18 loss 0.007 score 0.998 lr 5.07029e-06 
08/28/2020 19:22:29 - INFO - volta.utils -   [NLVR2]: iter 49083 Ep: 18.19 loss 0.003 score 0.998 lr 5.04971e-06 
08/28/2020 19:22:39 - INFO - volta.utils -   [NLVR2]: iter 49103 Ep: 18.19 loss 0.014 score 0.997 lr 5.02913e-06 
08/28/2020 19:22:47 - INFO - volta.utils -   [NLVR2]: iter 49123 Ep: 18.20 loss 0.001 score 1.000 lr 5.00854e-06 
08/28/2020 19:22:59 - INFO - volta.utils -   [NLVR2]: iter 49143 Ep: 18.21 loss 0.001 score 1.000 lr 4.98796e-06 
08/28/2020 19:23:20 - INFO - volta.utils -   [NLVR2]: iter 49163 Ep: 18.22 loss 0.002 score 0.998 lr 4.96737e-06 
08/28/2020 19:23:39 - INFO - volta.utils -   [NLVR2]: iter 49183 Ep: 18.22 loss 0.011 score 0.997 lr 4.94679e-06 
08/28/2020 19:23:51 - INFO - volta.utils -   [NLVR2]: iter 49203 Ep: 18.23 loss 0.010 score 0.997 lr 4.92621e-06 
08/28/2020 19:24:01 - INFO - volta.utils -   [NLVR2]: iter 49223 Ep: 18.24 loss 0.003 score 0.998 lr 4.90562e-06 
08/28/2020 19:24:09 - INFO - volta.utils -   [NLVR2]: iter 49243 Ep: 18.24 loss 0.000 score 1.000 lr 4.88504e-06 
08/28/2020 19:24:18 - INFO - volta.utils -   [NLVR2]: iter 49263 Ep: 18.25 loss 0.008 score 0.998 lr 4.86446e-06 
08/28/2020 19:24:26 - INFO - volta.utils -   [NLVR2]: iter 49283 Ep: 18.26 loss 0.000 score 1.000 lr 4.84387e-06 
08/28/2020 19:24:35 - INFO - volta.utils -   [NLVR2]: iter 49303 Ep: 18.27 loss 0.006 score 0.998 lr 4.82329e-06 
08/28/2020 19:24:43 - INFO - volta.utils -   [NLVR2]: iter 49323 Ep: 18.27 loss 0.000 score 1.000 lr 4.8027e-06 
08/28/2020 19:25:09 - INFO - volta.utils -   [NLVR2]: iter 49343 Ep: 18.28 loss 0.020 score 0.994 lr 4.78212e-06 
08/28/2020 19:25:29 - INFO - volta.utils -   [NLVR2]: iter 49363 Ep: 18.29 loss 0.007 score 0.998 lr 4.76154e-06 
08/28/2020 19:25:46 - INFO - volta.utils -   [NLVR2]: iter 49383 Ep: 18.30 loss 0.014 score 0.998 lr 4.74095e-06 
08/28/2020 19:25:55 - INFO - volta.utils -   [NLVR2]: iter 49403 Ep: 18.30 loss 0.006 score 0.997 lr 4.72037e-06 
08/28/2020 19:26:04 - INFO - volta.utils -   [NLVR2]: iter 49423 Ep: 18.31 loss 0.007 score 0.998 lr 4.69979e-06 
08/28/2020 19:26:13 - INFO - volta.utils -   [NLVR2]: iter 49443 Ep: 18.32 loss 0.001 score 1.000 lr 4.6792e-06 
08/28/2020 19:26:22 - INFO - volta.utils -   [NLVR2]: iter 49463 Ep: 18.33 loss 0.009 score 0.995 lr 4.65862e-06 
08/28/2020 19:26:47 - INFO - volta.utils -   [NLVR2]: iter 49483 Ep: 18.33 loss 0.003 score 0.998 lr 4.63803e-06 
08/28/2020 19:27:10 - INFO - volta.utils -   [NLVR2]: iter 49503 Ep: 18.34 loss 0.000 score 1.000 lr 4.61745e-06 
08/28/2020 19:27:20 - INFO - volta.utils -   [NLVR2]: iter 49523 Ep: 18.35 loss 0.000 score 1.000 lr 4.59687e-06 
08/28/2020 19:27:31 - INFO - volta.utils -   [NLVR2]: iter 49543 Ep: 18.36 loss 0.000 score 1.000 lr 4.57628e-06 
08/28/2020 19:27:38 - INFO - volta.utils -   [NLVR2]: iter 49563 Ep: 18.36 loss 0.002 score 0.998 lr 4.5557e-06 
08/28/2020 19:27:47 - INFO - volta.utils -   [NLVR2]: iter 49583 Ep: 18.37 loss 0.012 score 0.997 lr 4.53512e-06 
08/28/2020 19:27:56 - INFO - volta.utils -   [NLVR2]: iter 49603 Ep: 18.38 loss 0.010 score 0.997 lr 4.51453e-06 
08/28/2020 19:28:04 - INFO - volta.utils -   [NLVR2]: iter 49623 Ep: 18.39 loss 0.006 score 0.997 lr 4.49395e-06 
08/28/2020 19:28:13 - INFO - volta.utils -   [NLVR2]: iter 49643 Ep: 18.39 loss 0.000 score 1.000 lr 4.47336e-06 
08/28/2020 19:28:28 - INFO - volta.utils -   [NLVR2]: iter 49663 Ep: 18.40 loss 0.005 score 0.998 lr 4.45278e-06 
08/28/2020 19:28:56 - INFO - volta.utils -   [NLVR2]: iter 49683 Ep: 18.41 loss 0.001 score 1.000 lr 4.4322e-06 
08/28/2020 19:29:07 - INFO - volta.utils -   [NLVR2]: iter 49703 Ep: 18.42 loss 0.002 score 0.998 lr 4.41161e-06 
08/28/2020 19:29:18 - INFO - volta.utils -   [NLVR2]: iter 49723 Ep: 18.42 loss 0.000 score 1.000 lr 4.39103e-06 
08/28/2020 19:29:28 - INFO - volta.utils -   [NLVR2]: iter 49743 Ep: 18.43 loss 0.000 score 1.000 lr 4.37045e-06 
08/28/2020 19:29:37 - INFO - volta.utils -   [NLVR2]: iter 49763 Ep: 18.44 loss 0.001 score 1.000 lr 4.34986e-06 
08/28/2020 19:29:47 - INFO - volta.utils -   [NLVR2]: iter 49783 Ep: 18.44 loss 0.006 score 0.997 lr 4.32928e-06 
08/28/2020 19:29:56 - INFO - volta.utils -   [NLVR2]: iter 49803 Ep: 18.45 loss 0.009 score 0.997 lr 4.30869e-06 
08/28/2020 19:30:09 - INFO - volta.utils -   [NLVR2]: iter 49823 Ep: 18.46 loss 0.007 score 0.997 lr 4.28811e-06 
08/28/2020 19:30:36 - INFO - volta.utils -   [NLVR2]: iter 49843 Ep: 18.47 loss 0.001 score 1.000 lr 4.26753e-06 
08/28/2020 19:30:55 - INFO - volta.utils -   [NLVR2]: iter 49863 Ep: 18.47 loss 0.006 score 0.997 lr 4.24694e-06 
08/28/2020 19:31:06 - INFO - volta.utils -   [NLVR2]: iter 49883 Ep: 18.48 loss 0.004 score 0.998 lr 4.22636e-06 
08/28/2020 19:31:17 - INFO - volta.utils -   [NLVR2]: iter 49903 Ep: 18.49 loss 0.035 score 0.992 lr 4.20578e-06 
08/28/2020 19:31:26 - INFO - volta.utils -   [NLVR2]: iter 49923 Ep: 18.50 loss 0.001 score 1.000 lr 4.18519e-06 
08/28/2020 19:31:34 - INFO - volta.utils -   [NLVR2]: iter 49943 Ep: 18.50 loss 0.009 score 0.998 lr 4.16461e-06 
08/28/2020 19:31:43 - INFO - volta.utils -   [NLVR2]: iter 49963 Ep: 18.51 loss 0.001 score 1.000 lr 4.14402e-06 
08/28/2020 19:32:05 - INFO - volta.utils -   [NLVR2]: iter 49983 Ep: 18.52 loss 0.009 score 0.998 lr 4.12344e-06 
08/28/2020 19:32:24 - INFO - volta.utils -   [NLVR2]: iter 50003 Ep: 18.53 loss 0.013 score 0.995 lr 4.10286e-06 
08/28/2020 19:32:34 - INFO - volta.utils -   [NLVR2]: iter 50023 Ep: 18.53 loss 0.001 score 1.000 lr 4.08227e-06 
08/28/2020 19:32:47 - INFO - volta.utils -   [NLVR2]: iter 50043 Ep: 18.54 loss 0.004 score 0.998 lr 4.06169e-06 
08/28/2020 19:32:55 - INFO - volta.utils -   [NLVR2]: iter 50063 Ep: 18.55 loss 0.005 score 0.997 lr 4.04111e-06 
08/28/2020 19:33:04 - INFO - volta.utils -   [NLVR2]: iter 50083 Ep: 18.56 loss 0.001 score 1.000 lr 4.02052e-06 
08/28/2020 19:33:13 - INFO - volta.utils -   [NLVR2]: iter 50103 Ep: 18.56 loss 0.012 score 0.997 lr 3.99994e-06 
08/28/2020 19:33:23 - INFO - volta.utils -   [NLVR2]: iter 50123 Ep: 18.57 loss 0.002 score 0.998 lr 3.97935e-06 
08/28/2020 19:33:31 - INFO - volta.utils -   [NLVR2]: iter 50143 Ep: 18.58 loss 0.003 score 0.998 lr 3.95877e-06 
08/28/2020 19:33:57 - INFO - volta.utils -   [NLVR2]: iter 50163 Ep: 18.59 loss 0.000 score 1.000 lr 3.93819e-06 
08/28/2020 19:34:19 - INFO - volta.utils -   [NLVR2]: iter 50183 Ep: 18.59 loss 0.000 score 1.000 lr 3.9176e-06 
08/28/2020 19:34:30 - INFO - volta.utils -   [NLVR2]: iter 50203 Ep: 18.60 loss 0.001 score 1.000 lr 3.89702e-06 
08/28/2020 19:34:41 - INFO - volta.utils -   [NLVR2]: iter 50223 Ep: 18.61 loss 0.003 score 0.998 lr 3.87644e-06 
08/28/2020 19:34:49 - INFO - volta.utils -   [NLVR2]: iter 50243 Ep: 18.62 loss 0.006 score 0.998 lr 3.85585e-06 
08/28/2020 19:34:59 - INFO - volta.utils -   [NLVR2]: iter 50263 Ep: 18.62 loss 0.013 score 0.997 lr 3.83527e-06 
08/28/2020 19:35:07 - INFO - volta.utils -   [NLVR2]: iter 50283 Ep: 18.63 loss 0.007 score 0.998 lr 3.81468e-06 
08/28/2020 19:35:16 - INFO - volta.utils -   [NLVR2]: iter 50303 Ep: 18.64 loss 0.000 score 1.000 lr 3.7941e-06 
08/28/2020 19:35:26 - INFO - volta.utils -   [NLVR2]: iter 50323 Ep: 18.65 loss 0.001 score 1.000 lr 3.77352e-06 
08/28/2020 19:35:55 - INFO - volta.utils -   [NLVR2]: iter 50343 Ep: 18.65 loss 0.016 score 0.997 lr 3.75293e-06 
08/28/2020 19:36:14 - INFO - volta.utils -   [NLVR2]: iter 50363 Ep: 18.66 loss 0.000 score 1.000 lr 3.73235e-06 
08/28/2020 19:36:26 - INFO - volta.utils -   [NLVR2]: iter 50383 Ep: 18.67 loss 0.010 score 0.998 lr 3.71177e-06 
08/28/2020 19:36:35 - INFO - volta.utils -   [NLVR2]: iter 50403 Ep: 18.67 loss 0.015 score 0.997 lr 3.69118e-06 
08/28/2020 19:36:45 - INFO - volta.utils -   [NLVR2]: iter 50423 Ep: 18.68 loss 0.001 score 1.000 lr 3.6706e-06 
08/28/2020 19:36:53 - INFO - volta.utils -   [NLVR2]: iter 50443 Ep: 18.69 loss 0.005 score 0.998 lr 3.65001e-06 
08/28/2020 19:37:02 - INFO - volta.utils -   [NLVR2]: iter 50463 Ep: 18.70 loss 0.004 score 0.998 lr 3.62943e-06 
08/28/2020 19:37:10 - INFO - volta.utils -   [NLVR2]: iter 50483 Ep: 18.70 loss 0.011 score 0.998 lr 3.60885e-06 
08/28/2020 19:37:34 - INFO - volta.utils -   [NLVR2]: iter 50503 Ep: 18.71 loss 0.003 score 0.998 lr 3.58826e-06 
08/28/2020 19:37:55 - INFO - volta.utils -   [NLVR2]: iter 50523 Ep: 18.72 loss 0.006 score 0.998 lr 3.56768e-06 
08/28/2020 19:38:08 - INFO - volta.utils -   [NLVR2]: iter 50543 Ep: 18.73 loss 0.000 score 1.000 lr 3.5471e-06 
08/28/2020 19:38:21 - INFO - volta.utils -   [NLVR2]: iter 50563 Ep: 18.73 loss 0.004 score 0.998 lr 3.52651e-06 
08/28/2020 19:38:30 - INFO - volta.utils -   [NLVR2]: iter 50583 Ep: 18.74 loss 0.000 score 1.000 lr 3.50593e-06 
08/28/2020 19:38:38 - INFO - volta.utils -   [NLVR2]: iter 50603 Ep: 18.75 loss 0.005 score 0.998 lr 3.48534e-06 
08/28/2020 19:38:48 - INFO - volta.utils -   [NLVR2]: iter 50623 Ep: 18.76 loss 0.009 score 0.998 lr 3.46476e-06 
08/28/2020 19:38:56 - INFO - volta.utils -   [NLVR2]: iter 50643 Ep: 18.76 loss 0.011 score 0.997 lr 3.44418e-06 
08/28/2020 19:39:06 - INFO - volta.utils -   [NLVR2]: iter 50663 Ep: 18.77 loss 0.005 score 0.998 lr 3.42359e-06 
08/28/2020 19:39:23 - INFO - volta.utils -   [NLVR2]: iter 50683 Ep: 18.78 loss 0.000 score 1.000 lr 3.40301e-06 
08/28/2020 19:39:52 - INFO - volta.utils -   [NLVR2]: iter 50703 Ep: 18.79 loss 0.000 score 1.000 lr 3.38243e-06 
08/28/2020 19:40:00 - INFO - volta.utils -   [NLVR2]: iter 50723 Ep: 18.79 loss 0.010 score 0.995 lr 3.36184e-06 
08/28/2020 19:40:09 - INFO - volta.utils -   [NLVR2]: iter 50743 Ep: 18.80 loss 0.003 score 0.998 lr 3.34126e-06 
08/28/2020 19:40:17 - INFO - volta.utils -   [NLVR2]: iter 50763 Ep: 18.81 loss 0.006 score 0.998 lr 3.32067e-06 
08/28/2020 19:40:26 - INFO - volta.utils -   [NLVR2]: iter 50783 Ep: 18.82 loss 0.007 score 0.998 lr 3.30009e-06 
08/28/2020 19:40:35 - INFO - volta.utils -   [NLVR2]: iter 50803 Ep: 18.82 loss 0.001 score 1.000 lr 3.27951e-06 
08/28/2020 19:40:44 - INFO - volta.utils -   [NLVR2]: iter 50823 Ep: 18.83 loss 0.009 score 0.997 lr 3.25892e-06 
08/28/2020 19:40:52 - INFO - volta.utils -   [NLVR2]: iter 50843 Ep: 18.84 loss 0.008 score 0.997 lr 3.23834e-06 
08/28/2020 19:41:01 - INFO - volta.utils -   [NLVR2]: iter 50863 Ep: 18.85 loss 0.020 score 0.995 lr 3.21776e-06 
08/28/2020 19:41:17 - INFO - volta.utils -   [NLVR2]: iter 50883 Ep: 18.85 loss 0.001 score 1.000 lr 3.19717e-06 
08/28/2020 19:41:43 - INFO - volta.utils -   [NLVR2]: iter 50903 Ep: 18.86 loss 0.009 score 0.998 lr 3.17659e-06 
08/28/2020 19:41:59 - INFO - volta.utils -   [NLVR2]: iter 50923 Ep: 18.87 loss 0.001 score 1.000 lr 3.156e-06 
08/28/2020 19:42:11 - INFO - volta.utils -   [NLVR2]: iter 50943 Ep: 18.87 loss 0.000 score 1.000 lr 3.13542e-06 
08/28/2020 19:42:21 - INFO - volta.utils -   [NLVR2]: iter 50963 Ep: 18.88 loss 0.000 score 1.000 lr 3.11484e-06 
08/28/2020 19:42:29 - INFO - volta.utils -   [NLVR2]: iter 50983 Ep: 18.89 loss 0.000 score 1.000 lr 3.09425e-06 
08/28/2020 19:42:38 - INFO - volta.utils -   [NLVR2]: iter 51003 Ep: 18.90 loss 0.006 score 0.998 lr 3.07367e-06 
08/28/2020 19:42:46 - INFO - volta.utils -   [NLVR2]: iter 51023 Ep: 18.90 loss 0.008 score 0.998 lr 3.05309e-06 
08/28/2020 19:43:07 - INFO - volta.utils -   [NLVR2]: iter 51043 Ep: 18.91 loss 0.001 score 1.000 lr 3.0325e-06 
08/28/2020 19:43:33 - INFO - volta.utils -   [NLVR2]: iter 51063 Ep: 18.92 loss 0.006 score 0.998 lr 3.01192e-06 
08/28/2020 19:43:45 - INFO - volta.utils -   [NLVR2]: iter 51083 Ep: 18.93 loss 0.000 score 1.000 lr 2.99133e-06 
08/28/2020 19:43:53 - INFO - volta.utils -   [NLVR2]: iter 51103 Ep: 18.93 loss 0.001 score 1.000 lr 2.97075e-06 
08/28/2020 19:44:03 - INFO - volta.utils -   [NLVR2]: iter 51123 Ep: 18.94 loss 0.001 score 1.000 lr 2.95017e-06 
08/28/2020 19:44:11 - INFO - volta.utils -   [NLVR2]: iter 51143 Ep: 18.95 loss 0.002 score 0.998 lr 2.92958e-06 
08/28/2020 19:44:20 - INFO - volta.utils -   [NLVR2]: iter 51163 Ep: 18.96 loss 0.000 score 1.000 lr 2.909e-06 
08/28/2020 19:44:28 - INFO - volta.utils -   [NLVR2]: iter 51183 Ep: 18.96 loss 0.011 score 0.997 lr 2.88842e-06 
08/28/2020 19:44:37 - INFO - volta.utils -   [NLVR2]: iter 51203 Ep: 18.97 loss 0.008 score 0.998 lr 2.86783e-06 
08/28/2020 19:44:45 - INFO - volta.utils -   [NLVR2]: iter 51223 Ep: 18.98 loss 0.003 score 0.997 lr 2.84725e-06 
08/28/2020 19:45:26 - INFO - volta.utils -   [NLVR2]: iter 51243 Ep: 18.99 loss 0.003 score 0.998 lr 2.82666e-06 
08/28/2020 19:45:41 - INFO - volta.utils -   [NLVR2]: iter 51263 Ep: 18.99 loss 0.010 score 0.998 lr 2.80608e-06 
08/28/2020 19:45:49 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  89%|████████▉ | 8/9 [3:11:09<26:31, 1591.17s/it]08/28/2020 19:50:44 - INFO - volta.utils -   Eval task TASK12 on iteration 51282 
08/28/2020 19:50:44 - INFO - volta.utils -   Validation [NLVR2]: loss 2.178 score 70.743 
08/28/2020 19:50:52 - INFO - volta.utils -   [NLVR2]: iter 51302 Ep: 19.01 loss 0.008 score 0.998 lr 2.77572e-06 
08/28/2020 19:51:01 - INFO - volta.utils -   [NLVR2]: iter 51322 Ep: 19.02 loss 0.005 score 0.998 lr 2.74536e-06 
08/28/2020 19:51:09 - INFO - volta.utils -   [NLVR2]: iter 51342 Ep: 19.02 loss 0.000 score 1.000 lr 2.72477e-06 
08/28/2020 19:51:34 - INFO - volta.utils -   [NLVR2]: iter 51362 Ep: 19.03 loss 0.001 score 1.000 lr 2.70419e-06 
08/28/2020 19:51:57 - INFO - volta.utils -   [NLVR2]: iter 51382 Ep: 19.04 loss 0.000 score 1.000 lr 2.68361e-06 
08/28/2020 19:52:07 - INFO - volta.utils -   [NLVR2]: iter 51402 Ep: 19.04 loss 0.000 score 1.000 lr 2.66302e-06 
08/28/2020 19:52:15 - INFO - volta.utils -   [NLVR2]: iter 51422 Ep: 19.05 loss 0.012 score 0.998 lr 2.64244e-06 
08/28/2020 19:52:24 - INFO - volta.utils -   [NLVR2]: iter 51442 Ep: 19.06 loss 0.000 score 1.000 lr 2.62186e-06 
08/28/2020 19:52:32 - INFO - volta.utils -   [NLVR2]: iter 51462 Ep: 19.07 loss 0.008 score 0.998 lr 2.60127e-06 
08/28/2020 19:52:41 - INFO - volta.utils -   [NLVR2]: iter 51482 Ep: 19.07 loss 0.000 score 1.000 lr 2.58069e-06 
08/28/2020 19:52:49 - INFO - volta.utils -   [NLVR2]: iter 51502 Ep: 19.08 loss 0.002 score 1.000 lr 2.5601e-06 
08/28/2020 19:53:02 - INFO - volta.utils -   [NLVR2]: iter 51522 Ep: 19.09 loss 0.000 score 1.000 lr 2.53952e-06 
08/28/2020 19:53:33 - INFO - volta.utils -   [NLVR2]: iter 51542 Ep: 19.10 loss 0.001 score 1.000 lr 2.51894e-06 
08/28/2020 19:53:46 - INFO - volta.utils -   [NLVR2]: iter 51562 Ep: 19.10 loss 0.000 score 1.000 lr 2.49835e-06 
08/28/2020 19:53:54 - INFO - volta.utils -   [NLVR2]: iter 51582 Ep: 19.11 loss 0.006 score 0.998 lr 2.47777e-06 
08/28/2020 19:54:05 - INFO - volta.utils -   [NLVR2]: iter 51602 Ep: 19.12 loss 0.002 score 0.998 lr 2.45719e-06 
08/28/2020 19:54:13 - INFO - volta.utils -   [NLVR2]: iter 51622 Ep: 19.13 loss 0.001 score 1.000 lr 2.4366e-06 
08/28/2020 19:54:22 - INFO - volta.utils -   [NLVR2]: iter 51642 Ep: 19.13 loss 0.001 score 1.000 lr 2.41602e-06 
08/28/2020 19:54:30 - INFO - volta.utils -   [NLVR2]: iter 51662 Ep: 19.14 loss 0.000 score 1.000 lr 2.39543e-06 
08/28/2020 19:54:39 - INFO - volta.utils -   [NLVR2]: iter 51682 Ep: 19.15 loss 0.001 score 1.000 lr 2.37485e-06 
08/28/2020 19:54:47 - INFO - volta.utils -   [NLVR2]: iter 51702 Ep: 19.16 loss 0.002 score 0.998 lr 2.35427e-06 
08/28/2020 19:55:15 - INFO - volta.utils -   [NLVR2]: iter 51722 Ep: 19.16 loss 0.004 score 0.998 lr 2.33368e-06 
08/28/2020 19:55:32 - INFO - volta.utils -   [NLVR2]: iter 51742 Ep: 19.17 loss 0.002 score 0.998 lr 2.3131e-06 
08/28/2020 19:55:46 - INFO - volta.utils -   [NLVR2]: iter 51762 Ep: 19.18 loss 0.003 score 0.998 lr 2.29252e-06 
08/28/2020 19:55:55 - INFO - volta.utils -   [NLVR2]: iter 51782 Ep: 19.19 loss 0.006 score 0.998 lr 2.27193e-06 
08/28/2020 19:56:03 - INFO - volta.utils -   [NLVR2]: iter 51802 Ep: 19.19 loss 0.000 score 1.000 lr 2.25135e-06 
08/28/2020 19:56:12 - INFO - volta.utils -   [NLVR2]: iter 51822 Ep: 19.20 loss 0.010 score 0.997 lr 2.23076e-06 
08/28/2020 19:56:20 - INFO - volta.utils -   [NLVR2]: iter 51842 Ep: 19.21 loss 0.000 score 1.000 lr 2.21018e-06 
08/28/2020 19:56:29 - INFO - volta.utils -   [NLVR2]: iter 51862 Ep: 19.22 loss 0.006 score 0.998 lr 2.1896e-06 
08/28/2020 19:56:50 - INFO - volta.utils -   [NLVR2]: iter 51882 Ep: 19.22 loss 0.000 score 1.000 lr 2.16901e-06 
08/28/2020 19:57:14 - INFO - volta.utils -   [NLVR2]: iter 51902 Ep: 19.23 loss 0.005 score 0.998 lr 2.14843e-06 
08/28/2020 19:57:25 - INFO - volta.utils -   [NLVR2]: iter 51922 Ep: 19.24 loss 0.001 score 1.000 lr 2.12785e-06 
08/28/2020 19:57:35 - INFO - volta.utils -   [NLVR2]: iter 51942 Ep: 19.24 loss 0.000 score 1.000 lr 2.10726e-06 
08/28/2020 19:57:43 - INFO - volta.utils -   [NLVR2]: iter 51962 Ep: 19.25 loss 0.002 score 0.998 lr 2.08668e-06 
08/28/2020 19:57:53 - INFO - volta.utils -   [NLVR2]: iter 51982 Ep: 19.26 loss 0.000 score 1.000 lr 2.06609e-06 
08/28/2020 19:58:01 - INFO - volta.utils -   [NLVR2]: iter 52002 Ep: 19.27 loss 0.000 score 1.000 lr 2.04551e-06 
08/28/2020 19:58:10 - INFO - volta.utils -   [NLVR2]: iter 52022 Ep: 19.27 loss 0.000 score 1.000 lr 2.02493e-06 
08/28/2020 19:58:36 - INFO - volta.utils -   [NLVR2]: iter 52042 Ep: 19.28 loss 0.001 score 1.000 lr 2.00434e-06 
08/28/2020 19:58:57 - INFO - volta.utils -   [NLVR2]: iter 52062 Ep: 19.29 loss 0.000 score 1.000 lr 1.98376e-06 
08/28/2020 19:59:09 - INFO - volta.utils -   [NLVR2]: iter 52082 Ep: 19.30 loss 0.012 score 0.997 lr 1.96318e-06 
08/28/2020 19:59:18 - INFO - volta.utils -   [NLVR2]: iter 52102 Ep: 19.30 loss 0.003 score 0.997 lr 1.94259e-06 
08/28/2020 19:59:26 - INFO - volta.utils -   [NLVR2]: iter 52122 Ep: 19.31 loss 0.012 score 0.997 lr 1.92201e-06 
08/28/2020 19:59:35 - INFO - volta.utils -   [NLVR2]: iter 52142 Ep: 19.32 loss 0.000 score 1.000 lr 1.90142e-06 
08/28/2020 19:59:43 - INFO - volta.utils -   [NLVR2]: iter 52162 Ep: 19.33 loss 0.000 score 1.000 lr 1.88084e-06 
08/28/2020 19:59:52 - INFO - volta.utils -   [NLVR2]: iter 52182 Ep: 19.33 loss 0.003 score 0.998 lr 1.86026e-06 
08/28/2020 20:00:06 - INFO - volta.utils -   [NLVR2]: iter 52202 Ep: 19.34 loss 0.000 score 1.000 lr 1.83967e-06 
08/28/2020 20:00:42 - INFO - volta.utils -   [NLVR2]: iter 52222 Ep: 19.35 loss 0.014 score 0.995 lr 1.81909e-06 
08/28/2020 20:00:52 - INFO - volta.utils -   [NLVR2]: iter 52242 Ep: 19.36 loss 0.000 score 1.000 lr 1.79851e-06 
08/28/2020 20:01:02 - INFO - volta.utils -   [NLVR2]: iter 52262 Ep: 19.36 loss 0.008 score 0.997 lr 1.77792e-06 
08/28/2020 20:01:10 - INFO - volta.utils -   [NLVR2]: iter 52282 Ep: 19.37 loss 0.003 score 0.998 lr 1.75734e-06 
08/28/2020 20:01:19 - INFO - volta.utils -   [NLVR2]: iter 52302 Ep: 19.38 loss 0.000 score 1.000 lr 1.73675e-06 
08/28/2020 20:01:27 - INFO - volta.utils -   [NLVR2]: iter 52322 Ep: 19.39 loss 0.000 score 1.000 lr 1.71617e-06 
08/28/2020 20:01:35 - INFO - volta.utils -   [NLVR2]: iter 52342 Ep: 19.39 loss 0.013 score 0.998 lr 1.69559e-06 
08/28/2020 20:01:44 - INFO - volta.utils -   [NLVR2]: iter 52362 Ep: 19.40 loss 0.000 score 1.000 lr 1.675e-06 
08/28/2020 20:02:14 - INFO - volta.utils -   [NLVR2]: iter 52382 Ep: 19.41 loss 0.000 score 1.000 lr 1.65442e-06 
08/28/2020 20:02:31 - INFO - volta.utils -   [NLVR2]: iter 52402 Ep: 19.42 loss 0.001 score 1.000 lr 1.63384e-06 
08/28/2020 20:02:41 - INFO - volta.utils -   [NLVR2]: iter 52422 Ep: 19.42 loss 0.002 score 0.998 lr 1.61325e-06 
08/28/2020 20:02:51 - INFO - volta.utils -   [NLVR2]: iter 52442 Ep: 19.43 loss 0.000 score 1.000 lr 1.59267e-06 
08/28/2020 20:02:59 - INFO - volta.utils -   [NLVR2]: iter 52462 Ep: 19.44 loss 0.001 score 1.000 lr 1.57208e-06 
08/28/2020 20:03:08 - INFO - volta.utils -   [NLVR2]: iter 52482 Ep: 19.44 loss 0.006 score 0.998 lr 1.5515e-06 
08/28/2020 20:03:17 - INFO - volta.utils -   [NLVR2]: iter 52502 Ep: 19.45 loss 0.000 score 1.000 lr 1.53092e-06 
08/28/2020 20:03:26 - INFO - volta.utils -   [NLVR2]: iter 52522 Ep: 19.46 loss 0.006 score 0.997 lr 1.51033e-06 
08/28/2020 20:03:34 - INFO - volta.utils -   [NLVR2]: iter 52542 Ep: 19.47 loss 0.000 score 1.000 lr 1.48975e-06 
08/28/2020 20:03:45 - INFO - volta.utils -   [NLVR2]: iter 52562 Ep: 19.47 loss 0.000 score 1.000 lr 1.46917e-06 
08/28/2020 20:04:16 - INFO - volta.utils -   [NLVR2]: iter 52582 Ep: 19.48 loss 0.007 score 0.998 lr 1.44858e-06 
08/28/2020 20:04:26 - INFO - volta.utils -   [NLVR2]: iter 52602 Ep: 19.49 loss 0.004 score 0.998 lr 1.428e-06 
08/28/2020 20:04:40 - INFO - volta.utils -   [NLVR2]: iter 52622 Ep: 19.50 loss 0.006 score 0.998 lr 1.40741e-06 
08/28/2020 20:04:49 - INFO - volta.utils -   [NLVR2]: iter 52642 Ep: 19.50 loss 0.000 score 1.000 lr 1.38683e-06 
08/28/2020 20:04:58 - INFO - volta.utils -   [NLVR2]: iter 52662 Ep: 19.51 loss 0.014 score 0.998 lr 1.36625e-06 
08/28/2020 20:05:06 - INFO - volta.utils -   [NLVR2]: iter 52682 Ep: 19.52 loss 0.002 score 1.000 lr 1.34566e-06 
08/28/2020 20:05:15 - INFO - volta.utils -   [NLVR2]: iter 52702 Ep: 19.53 loss 0.005 score 0.998 lr 1.32508e-06 
08/28/2020 20:05:28 - INFO - volta.utils -   [NLVR2]: iter 52722 Ep: 19.53 loss 0.004 score 0.998 lr 1.3045e-06 
08/28/2020 20:05:59 - INFO - volta.utils -   [NLVR2]: iter 52742 Ep: 19.54 loss 0.001 score 1.000 lr 1.28391e-06 
08/28/2020 20:06:19 - INFO - volta.utils -   [NLVR2]: iter 52762 Ep: 19.55 loss 0.002 score 1.000 lr 1.26333e-06 
08/28/2020 20:06:27 - INFO - volta.utils -   [NLVR2]: iter 52782 Ep: 19.56 loss 0.001 score 1.000 lr 1.24274e-06 
08/28/2020 20:06:36 - INFO - volta.utils -   [NLVR2]: iter 52802 Ep: 19.56 loss 0.003 score 0.998 lr 1.22216e-06 
08/28/2020 20:06:44 - INFO - volta.utils -   [NLVR2]: iter 52822 Ep: 19.57 loss 0.000 score 1.000 lr 1.20158e-06 
08/28/2020 20:06:53 - INFO - volta.utils -   [NLVR2]: iter 52842 Ep: 19.58 loss 0.000 score 1.000 lr 1.18099e-06 
08/28/2020 20:07:01 - INFO - volta.utils -   [NLVR2]: iter 52862 Ep: 19.59 loss 0.011 score 0.998 lr 1.16041e-06 
08/28/2020 20:07:23 - INFO - volta.utils -   [NLVR2]: iter 52882 Ep: 19.59 loss 0.007 score 0.998 lr 1.13983e-06 
08/28/2020 20:07:49 - INFO - volta.utils -   [NLVR2]: iter 52902 Ep: 19.60 loss 0.000 score 1.000 lr 1.11924e-06 
08/28/2020 20:07:58 - INFO - volta.utils -   [NLVR2]: iter 52922 Ep: 19.61 loss 0.001 score 1.000 lr 1.09866e-06 
08/28/2020 20:08:08 - INFO - volta.utils -   [NLVR2]: iter 52942 Ep: 19.62 loss 0.000 score 1.000 lr 1.07807e-06 
08/28/2020 20:08:21 - INFO - volta.utils -   [NLVR2]: iter 52962 Ep: 19.62 loss 0.001 score 1.000 lr 1.05749e-06 
08/28/2020 20:08:29 - INFO - volta.utils -   [NLVR2]: iter 52982 Ep: 19.63 loss 0.015 score 0.998 lr 1.03691e-06 
08/28/2020 20:08:38 - INFO - volta.utils -   [NLVR2]: iter 53002 Ep: 19.64 loss 0.000 score 1.000 lr 1.01632e-06 
08/28/2020 20:08:46 - INFO - volta.utils -   [NLVR2]: iter 53022 Ep: 19.65 loss 0.000 score 1.000 lr 9.95739e-07 
08/28/2020 20:09:08 - INFO - volta.utils -   [NLVR2]: iter 53042 Ep: 19.65 loss 0.011 score 0.997 lr 9.75155e-07 
08/28/2020 20:09:28 - INFO - volta.utils -   [NLVR2]: iter 53062 Ep: 19.66 loss 0.000 score 1.000 lr 9.54572e-07 
08/28/2020 20:09:41 - INFO - volta.utils -   [NLVR2]: iter 53082 Ep: 19.67 loss 0.017 score 0.998 lr 9.33988e-07 
08/28/2020 20:09:54 - INFO - volta.utils -   [NLVR2]: iter 53102 Ep: 19.67 loss 0.006 score 0.998 lr 9.13404e-07 
08/28/2020 20:10:02 - INFO - volta.utils -   [NLVR2]: iter 53122 Ep: 19.68 loss 0.001 score 0.998 lr 8.9282e-07 
08/28/2020 20:10:11 - INFO - volta.utils -   [NLVR2]: iter 53142 Ep: 19.69 loss 0.000 score 1.000 lr 8.72237e-07 
08/28/2020 20:10:20 - INFO - volta.utils -   [NLVR2]: iter 53162 Ep: 19.70 loss 0.001 score 1.000 lr 8.51653e-07 
08/28/2020 20:10:29 - INFO - volta.utils -   [NLVR2]: iter 53182 Ep: 19.70 loss 0.000 score 1.000 lr 8.31069e-07 
08/28/2020 20:10:38 - INFO - volta.utils -   [NLVR2]: iter 53202 Ep: 19.71 loss 0.001 score 1.000 lr 8.10485e-07 
08/28/2020 20:11:04 - INFO - volta.utils -   [NLVR2]: iter 53222 Ep: 19.72 loss 0.001 score 1.000 lr 7.89902e-07 
08/28/2020 20:11:25 - INFO - volta.utils -   [NLVR2]: iter 53242 Ep: 19.73 loss 0.000 score 1.000 lr 7.69318e-07 
08/28/2020 20:11:37 - INFO - volta.utils -   [NLVR2]: iter 53262 Ep: 19.73 loss 0.006 score 0.998 lr 7.48734e-07 
08/28/2020 20:11:45 - INFO - volta.utils -   [NLVR2]: iter 53282 Ep: 19.74 loss 0.013 score 0.997 lr 7.2815e-07 
08/28/2020 20:11:55 - INFO - volta.utils -   [NLVR2]: iter 53302 Ep: 19.75 loss 0.000 score 1.000 lr 7.07567e-07 
08/28/2020 20:12:03 - INFO - volta.utils -   [NLVR2]: iter 53322 Ep: 19.76 loss 0.000 score 1.000 lr 6.86983e-07 
08/28/2020 20:12:13 - INFO - volta.utils -   [NLVR2]: iter 53342 Ep: 19.76 loss 0.003 score 0.998 lr 6.66399e-07 
08/28/2020 20:12:21 - INFO - volta.utils -   [NLVR2]: iter 53362 Ep: 19.77 loss 0.002 score 0.998 lr 6.45815e-07 
08/28/2020 20:12:31 - INFO - volta.utils -   [NLVR2]: iter 53382 Ep: 19.78 loss 0.003 score 0.998 lr 6.25232e-07 
08/28/2020 20:13:11 - INFO - volta.utils -   [NLVR2]: iter 53402 Ep: 19.79 loss 0.001 score 1.000 lr 6.04648e-07 
08/28/2020 20:13:24 - INFO - volta.utils -   [NLVR2]: iter 53422 Ep: 19.79 loss 0.003 score 0.998 lr 5.84064e-07 
08/28/2020 20:13:33 - INFO - volta.utils -   [NLVR2]: iter 53442 Ep: 19.80 loss 0.010 score 0.998 lr 5.6348e-07 
08/28/2020 20:13:46 - INFO - volta.utils -   [NLVR2]: iter 53462 Ep: 19.81 loss 0.001 score 1.000 lr 5.42897e-07 
08/28/2020 20:13:54 - INFO - volta.utils -   [NLVR2]: iter 53482 Ep: 19.82 loss 0.000 score 1.000 lr 5.22313e-07 
08/28/2020 20:14:03 - INFO - volta.utils -   [NLVR2]: iter 53502 Ep: 19.82 loss 0.000 score 1.000 lr 5.01729e-07 
08/28/2020 20:14:11 - INFO - volta.utils -   [NLVR2]: iter 53522 Ep: 19.83 loss 0.000 score 1.000 lr 4.81145e-07 
08/28/2020 20:14:35 - INFO - volta.utils -   [NLVR2]: iter 53542 Ep: 19.84 loss 0.013 score 0.997 lr 4.60562e-07 
08/28/2020 20:15:05 - INFO - volta.utils -   [NLVR2]: iter 53562 Ep: 19.85 loss 0.000 score 1.000 lr 4.39978e-07 
08/28/2020 20:15:16 - INFO - volta.utils -   [NLVR2]: iter 53582 Ep: 19.85 loss 0.001 score 1.000 lr 4.19394e-07 
08/28/2020 20:15:24 - INFO - volta.utils -   [NLVR2]: iter 53602 Ep: 19.86 loss 0.000 score 1.000 lr 3.9881e-07 
08/28/2020 20:15:35 - INFO - volta.utils -   [NLVR2]: iter 53622 Ep: 19.87 loss 0.000 score 1.000 lr 3.78227e-07 
08/28/2020 20:15:43 - INFO - volta.utils -   [NLVR2]: iter 53642 Ep: 19.87 loss 0.000 score 1.000 lr 3.57643e-07 
08/28/2020 20:16:10 - INFO - volta.utils -   [NLVR2]: iter 53662 Ep: 19.88 loss 0.000 score 1.000 lr 3.37059e-07 
08/28/2020 20:16:31 - INFO - volta.utils -   [NLVR2]: iter 53682 Ep: 19.89 loss 0.002 score 0.998 lr 3.16475e-07 
08/28/2020 20:16:46 - INFO - volta.utils -   [NLVR2]: iter 53702 Ep: 19.90 loss 0.000 score 1.000 lr 2.95891e-07 
08/28/2020 20:16:55 - INFO - volta.utils -   [NLVR2]: iter 53722 Ep: 19.90 loss 0.001 score 1.000 lr 2.75308e-07 
08/28/2020 20:17:05 - INFO - volta.utils -   [NLVR2]: iter 53742 Ep: 19.91 loss 0.000 score 1.000 lr 2.54724e-07 
08/28/2020 20:17:13 - INFO - volta.utils -   [NLVR2]: iter 53762 Ep: 19.92 loss 0.006 score 0.997 lr 2.3414e-07 
08/28/2020 20:17:23 - INFO - volta.utils -   [NLVR2]: iter 53782 Ep: 19.93 loss 0.000 score 1.000 lr 2.13556e-07 
08/28/2020 20:17:31 - INFO - volta.utils -   [NLVR2]: iter 53802 Ep: 19.93 loss 0.003 score 0.998 lr 1.92973e-07 
08/28/2020 20:17:39 - INFO - volta.utils -   [NLVR2]: iter 53822 Ep: 19.94 loss 0.000 score 1.000 lr 1.72389e-07 
08/28/2020 20:18:11 - INFO - volta.utils -   [NLVR2]: iter 53842 Ep: 19.95 loss 0.001 score 1.000 lr 1.51805e-07 
08/28/2020 20:18:34 - INFO - volta.utils -   [NLVR2]: iter 53862 Ep: 19.96 loss 0.008 score 0.998 lr 1.31221e-07 
08/28/2020 20:18:52 - INFO - volta.utils -   [NLVR2]: iter 53882 Ep: 19.96 loss 0.000 score 1.000 lr 1.10638e-07 
08/28/2020 20:19:00 - INFO - volta.utils -   [NLVR2]: iter 53902 Ep: 19.97 loss 0.000 score 1.000 lr 9.00539e-08 
08/28/2020 20:19:09 - INFO - volta.utils -   [NLVR2]: iter 53922 Ep: 19.98 loss 0.000 score 1.000 lr 6.94702e-08 
08/28/2020 20:19:16 - INFO - volta.utils -   [NLVR2]: iter 53942 Ep: 19.99 loss 0.014 score 0.995 lr 4.88864e-08 
08/28/2020 20:19:30 - INFO - volta.utils -   [NLVR2]: iter 53962 Ep: 19.99 loss 0.000 score 1.000 lr 2.83027e-08 
08/28/2020 20:24:04 - INFO - volta.utils -   Eval task TASK12 on iteration 53980 
08/28/2020 20:24:04 - INFO - volta.utils -   Validation [NLVR2]: loss 2.259 score 71.015 
08/28/2020 20:24:04 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch: 100%|██████████| 9/9 [3:49:21<00:00, 1801.31s/it]
