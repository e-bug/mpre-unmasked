/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
09/22/2020 07:31:42 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
09/22/2020 07:31:43 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/22/2020 07:31:44 - INFO - volta.task_utils -   Loading GQA Dataset with batch size 32
09/22/2020 07:31:44 - INFO - volta.datasets.gqa_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/gqa/cache/GQA_train_20.pkl
09/22/2020 07:36:35 - INFO - volta.datasets.gqa_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/gqa/cache/GQA_val_20.pkl
09/22/2020 07:37:19 - INFO - volta.utils -   logging file at: ../../logs/volta/gqa/GQA_lxmert
09/22/2020 07:37:19 - INFO - volta.utils -   loading weights file /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/volta/lxmert/lxmert/pytorch_model_19.bin
09/22/2020 07:37:25 - INFO - volta.utils -   
09/22/2020 07:37:25 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK15.logit_fc.0.weight', 'clfs_dict.TASK15.logit_fc.0.bias', 'clfs_dict.TASK15.logit_fc.2.weight', 'clfs_dict.TASK15.logit_fc.2.bias', 'clfs_dict.TASK15.logit_fc.3.weight', 'clfs_dict.TASK15.logit_fc.3.bias']
09/22/2020 07:37:25 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.3.weight', 'cls.imagePredictions.decoder_dict.3.bias', 'cls.imagePredictions.decoder_dict.4.weight', 'cls.imagePredictions.decoder_dict.4.bias', 'cls.imagePredictions.decoder_dict.5.weight', 'cls.imagePredictions.decoder_dict.5.bias']
09/22/2020 07:37:34 - INFO - __main__ -   >> Trainable Parameters:
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)     |1572864     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(768, 4)        |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.v_embeddings.ImgLayerNorm.weight                        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.v_embeddings.ImgLayerNorm.bias                          |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.v_embeddings.LocLayerNorm.weight                        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.v_embeddings.LocLayerNorm.bias                          |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(768, 768)      |589824      |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(768,)          |768         |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.0.weight                           |torch.float32    |(1536, 768)     |1179648     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.0.bias                             |torch.float32    |(1536,)         |1536        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.2.weight                           |torch.float32    |(1536,)         |1536        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.2.bias                             |torch.float32    |(1536,)         |1536        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.3.weight                           |torch.float32    |(1842, 1536)    |2829312     |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.3.bias                             |torch.float32    |(1842,)         |1842        |
09/22/2020 07:37:34 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/22/2020 07:37:34 - INFO - __main__ -   >> # TrainableParams:       	211.95	M
09/22/2020 07:37:34 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
09/22/2020 07:37:34 - INFO - __main__ -   >> # TotalParams:           	211.95	M

Epoch:   0%|          | 0/11 [00:00<?, ?it/s]09/22/2020 07:57:51 - INFO - volta.utils -   Eval task TASK15 on iteration 265222 
09/22/2020 07:57:51 - INFO - volta.utils -   Validation [GQA]: loss 2.762 score 63.970 
09/22/2020 07:57:59 - INFO - volta.utils -   [GQA]: iter 265242 Ep: 9.00 loss 0.402 score 0.941 lr 6.11098e-06 
09/22/2020 07:58:10 - INFO - volta.utils -   [GQA]: iter 265262 Ep: 9.00 loss 0.424 score 0.936 lr 6.11052e-06 
09/22/2020 07:58:25 - INFO - volta.utils -   [GQA]: iter 265282 Ep: 9.00 loss 0.451 score 0.922 lr 6.11014e-06 
09/22/2020 07:58:40 - INFO - volta.utils -   [GQA]: iter 265302 Ep: 9.00 loss 0.380 score 0.948 lr 6.10976e-06 
09/22/2020 07:59:01 - INFO - volta.utils -   [GQA]: iter 265322 Ep: 9.00 loss 0.412 score 0.928 lr 6.10939e-06 
09/22/2020 07:59:11 - INFO - volta.utils -   [GQA]: iter 265342 Ep: 9.00 loss 0.411 score 0.933 lr 6.10901e-06 
09/22/2020 07:59:19 - INFO - volta.utils -   [GQA]: iter 265362 Ep: 9.00 loss 0.366 score 0.936 lr 6.10863e-06 
09/22/2020 07:59:29 - INFO - volta.utils -   [GQA]: iter 265382 Ep: 9.01 loss 0.335 score 0.944 lr 6.10826e-06 
09/22/2020 07:59:37 - INFO - volta.utils -   [GQA]: iter 265402 Ep: 9.01 loss 0.399 score 0.947 lr 6.10788e-06 
09/22/2020 07:59:45 - INFO - volta.utils -   [GQA]: iter 265422 Ep: 9.01 loss 0.363 score 0.942 lr 6.1075e-06 
09/22/2020 08:00:09 - INFO - volta.utils -   [GQA]: iter 265442 Ep: 9.01 loss 0.460 score 0.917 lr 6.10712e-06 
09/22/2020 08:00:18 - INFO - volta.utils -   [GQA]: iter 265462 Ep: 9.01 loss 0.395 score 0.934 lr 6.10675e-06 
09/22/2020 08:00:32 - INFO - volta.utils -   [GQA]: iter 265482 Ep: 9.01 loss 0.342 score 0.956 lr 6.10637e-06 
09/22/2020 08:00:40 - INFO - volta.utils -   [GQA]: iter 265502 Ep: 9.01 loss 0.361 score 0.952 lr 6.10599e-06 
09/22/2020 08:00:54 - INFO - volta.utils -   [GQA]: iter 265522 Ep: 9.01 loss 0.445 score 0.928 lr 6.10562e-06 
09/22/2020 08:01:04 - INFO - volta.utils -   [GQA]: iter 265542 Ep: 9.01 loss 0.435 score 0.936 lr 6.10524e-06 
09/22/2020 08:01:13 - INFO - volta.utils -   [GQA]: iter 265562 Ep: 9.01 loss 0.389 score 0.941 lr 6.10486e-06 
09/22/2020 08:01:21 - INFO - volta.utils -   [GQA]: iter 265582 Ep: 9.01 loss 0.386 score 0.927 lr 6.10448e-06 
09/22/2020 08:01:31 - INFO - volta.utils -   [GQA]: iter 265602 Ep: 9.01 loss 0.464 score 0.930 lr 6.10411e-06 
09/22/2020 08:01:52 - INFO - volta.utils -   [GQA]: iter 265622 Ep: 9.01 loss 0.334 score 0.953 lr 6.10373e-06 
09/22/2020 08:02:08 - INFO - volta.utils -   [GQA]: iter 265642 Ep: 9.01 loss 0.372 score 0.956 lr 6.10335e-06 
09/22/2020 08:02:20 - INFO - volta.utils -   [GQA]: iter 265662 Ep: 9.01 loss 0.385 score 0.939 lr 6.10298e-06 
09/22/2020 08:02:29 - INFO - volta.utils -   [GQA]: iter 265682 Ep: 9.02 loss 0.354 score 0.953 lr 6.1026e-06 
09/22/2020 08:02:40 - INFO - volta.utils -   [GQA]: iter 265702 Ep: 9.02 loss 0.424 score 0.941 lr 6.10222e-06 
09/22/2020 08:02:54 - INFO - volta.utils -   [GQA]: iter 265722 Ep: 9.02 loss 0.388 score 0.938 lr 6.10185e-06 
09/22/2020 08:03:05 - INFO - volta.utils -   [GQA]: iter 265742 Ep: 9.02 loss 0.354 score 0.953 lr 6.10147e-06 
09/22/2020 08:03:28 - INFO - volta.utils -   [GQA]: iter 265762 Ep: 9.02 loss 0.378 score 0.944 lr 6.10109e-06 
09/22/2020 08:03:40 - INFO - volta.utils -   [GQA]: iter 265782 Ep: 9.02 loss 0.395 score 0.936 lr 6.10071e-06 
09/22/2020 08:04:00 - INFO - volta.utils -   [GQA]: iter 265802 Ep: 9.02 loss 0.476 score 0.922 lr 6.10034e-06 
09/22/2020 08:04:10 - INFO - volta.utils -   [GQA]: iter 265822 Ep: 9.02 loss 0.466 score 0.928 lr 6.09996e-06 
09/22/2020 08:04:19 - INFO - volta.utils -   [GQA]: iter 265842 Ep: 9.02 loss 0.370 score 0.950 lr 6.09958e-06 
09/22/2020 08:04:31 - INFO - volta.utils -   [GQA]: iter 265862 Ep: 9.02 loss 0.316 score 0.959 lr 6.09921e-06 
09/22/2020 08:04:57 - INFO - volta.utils -   [GQA]: iter 265882 Ep: 9.02 loss 0.385 score 0.934 lr 6.09883e-06 
09/22/2020 08:05:08 - INFO - volta.utils -   [GQA]: iter 265902 Ep: 9.02 loss 0.392 score 0.945 lr 6.09845e-06 
09/22/2020 08:05:19 - INFO - volta.utils -   [GQA]: iter 265922 Ep: 9.02 loss 0.430 score 0.928 lr 6.09807e-06 
09/22/2020 08:05:35 - INFO - volta.utils -   [GQA]: iter 265942 Ep: 9.02 loss 0.410 score 0.931 lr 6.0977e-06 
09/22/2020 08:05:47 - INFO - volta.utils -   [GQA]: iter 265962 Ep: 9.03 loss 0.324 score 0.956 lr 6.09732e-06 
09/22/2020 08:05:55 - INFO - volta.utils -   [GQA]: iter 265982 Ep: 9.03 loss 0.361 score 0.936 lr 6.09694e-06 
09/22/2020 08:06:03 - INFO - volta.utils -   [GQA]: iter 266002 Ep: 9.03 loss 0.370 score 0.945 lr 6.09657e-06 
09/22/2020 08:06:10 - INFO - volta.utils -   [GQA]: iter 266022 Ep: 9.03 loss 0.364 score 0.947 lr 6.09619e-06 
09/22/2020 08:06:28 - INFO - volta.utils -   [GQA]: iter 266042 Ep: 9.03 loss 0.405 score 0.938 lr 6.09581e-06 
09/22/2020 08:06:48 - INFO - volta.utils -   [GQA]: iter 266062 Ep: 9.03 loss 0.345 score 0.956 lr 6.09544e-06 
09/22/2020 08:07:04 - INFO - volta.utils -   [GQA]: iter 266082 Ep: 9.03 loss 0.428 score 0.927 lr 6.09506e-06 
09/22/2020 08:07:19 - INFO - volta.utils -   [GQA]: iter 266102 Ep: 9.03 loss 0.435 score 0.936 lr 6.09468e-06 
09/22/2020 08:07:28 - INFO - volta.utils -   [GQA]: iter 266122 Ep: 9.03 loss 0.353 score 0.939 lr 6.0943e-06 
09/22/2020 08:07:36 - INFO - volta.utils -   [GQA]: iter 266142 Ep: 9.03 loss 0.345 score 0.948 lr 6.09393e-06 
09/22/2020 08:07:49 - INFO - volta.utils -   [GQA]: iter 266162 Ep: 9.03 loss 0.435 score 0.920 lr 6.09355e-06 
09/22/2020 08:08:05 - INFO - volta.utils -   [GQA]: iter 266182 Ep: 9.03 loss 0.369 score 0.941 lr 6.09317e-06 
09/22/2020 08:08:29 - INFO - volta.utils -   [GQA]: iter 266202 Ep: 9.03 loss 0.374 score 0.948 lr 6.0928e-06 
09/22/2020 08:08:45 - INFO - volta.utils -   [GQA]: iter 266222 Ep: 9.03 loss 0.393 score 0.939 lr 6.09242e-06 
09/22/2020 08:08:54 - INFO - volta.utils -   [GQA]: iter 266242 Ep: 9.03 loss 0.375 score 0.947 lr 6.09204e-06 
09/22/2020 08:09:02 - INFO - volta.utils -   [GQA]: iter 266262 Ep: 9.04 loss 0.378 score 0.948 lr 6.09167e-06 
09/22/2020 08:09:15 - INFO - volta.utils -   [GQA]: iter 266282 Ep: 9.04 loss 0.297 score 0.966 lr 6.09129e-06 
09/22/2020 08:09:46 - INFO - volta.utils -   [GQA]: iter 266302 Ep: 9.04 loss 0.327 score 0.955 lr 6.09091e-06 
09/22/2020 08:09:55 - INFO - volta.utils -   [GQA]: iter 266322 Ep: 9.04 loss 0.480 score 0.930 lr 6.09053e-06 
09/22/2020 08:10:04 - INFO - volta.utils -   [GQA]: iter 266342 Ep: 9.04 loss 0.353 score 0.953 lr 6.09016e-06 
09/22/2020 08:10:14 - INFO - volta.utils -   [GQA]: iter 266362 Ep: 9.04 loss 0.282 score 0.961 lr 6.08978e-06 
09/22/2020 08:10:26 - INFO - volta.utils -   [GQA]: iter 266382 Ep: 9.04 loss 0.397 score 0.939 lr 6.0894e-06 
09/22/2020 08:10:33 - INFO - volta.utils -   [GQA]: iter 266402 Ep: 9.04 loss 0.375 score 0.945 lr 6.08903e-06 
09/22/2020 08:10:54 - INFO - volta.utils -   [GQA]: iter 266422 Ep: 9.04 loss 0.350 score 0.941 lr 6.08865e-06 
09/22/2020 08:11:10 - INFO - volta.utils -   [GQA]: iter 266442 Ep: 9.04 loss 0.395 score 0.938 lr 6.08827e-06 
09/22/2020 08:11:23 - INFO - volta.utils -   [GQA]: iter 266462 Ep: 9.04 loss 0.340 score 0.939 lr 6.08789e-06 
09/22/2020 08:11:41 - INFO - volta.utils -   [GQA]: iter 266482 Ep: 9.04 loss 0.343 score 0.948 lr 6.08752e-06 
09/22/2020 08:11:52 - INFO - volta.utils -   [GQA]: iter 266502 Ep: 9.04 loss 0.443 score 0.941 lr 6.08714e-06 
09/22/2020 08:12:06 - INFO - volta.utils -   [GQA]: iter 266522 Ep: 9.04 loss 0.325 score 0.945 lr 6.08676e-06 
09/22/2020 08:12:14 - INFO - volta.utils -   [GQA]: iter 266542 Ep: 9.04 loss 0.278 score 0.948 lr 6.08639e-06 
09/22/2020 08:12:34 - INFO - volta.utils -   [GQA]: iter 266562 Ep: 9.05 loss 0.353 score 0.953 lr 6.08601e-06 
09/22/2020 08:12:46 - INFO - volta.utils -   [GQA]: iter 266582 Ep: 9.05 loss 0.342 score 0.958 lr 6.08563e-06 
09/22/2020 08:13:02 - INFO - volta.utils -   [GQA]: iter 266602 Ep: 9.05 loss 0.398 score 0.938 lr 6.08526e-06 
09/22/2020 08:13:13 - INFO - volta.utils -   [GQA]: iter 266622 Ep: 9.05 loss 0.400 score 0.939 lr 6.08488e-06 
09/22/2020 08:13:23 - INFO - volta.utils -   [GQA]: iter 266642 Ep: 9.05 loss 0.358 score 0.945 lr 6.0845e-06 
09/22/2020 08:13:34 - INFO - volta.utils -   [GQA]: iter 266662 Ep: 9.05 loss 0.383 score 0.933 lr 6.08412e-06 
09/22/2020 08:13:41 - INFO - volta.utils -   [GQA]: iter 266682 Ep: 9.05 loss 0.313 score 0.948 lr 6.08375e-06 
09/22/2020 08:14:05 - INFO - volta.utils -   [GQA]: iter 266702 Ep: 9.05 loss 0.359 score 0.938 lr 6.08337e-06 
09/22/2020 08:14:18 - INFO - volta.utils -   [GQA]: iter 266722 Ep: 9.05 loss 0.381 score 0.939 lr 6.08299e-06 
09/22/2020 08:14:33 - INFO - volta.utils -   [GQA]: iter 266742 Ep: 9.05 loss 0.369 score 0.931 lr 6.08262e-06 
09/22/2020 08:14:47 - INFO - volta.utils -   [GQA]: iter 266762 Ep: 9.05 loss 0.459 score 0.936 lr 6.08224e-06 
09/22/2020 08:15:13 - INFO - volta.utils -   [GQA]: iter 266782 Ep: 9.05 loss 0.332 score 0.948 lr 6.08186e-06 
09/22/2020 08:15:20 - INFO - volta.utils -   [GQA]: iter 266802 Ep: 9.05 loss 0.381 score 0.942 lr 6.08148e-06 
09/22/2020 08:15:32 - INFO - volta.utils -   [GQA]: iter 266822 Ep: 9.05 loss 0.501 score 0.916 lr 6.08111e-06 
09/22/2020 08:15:52 - INFO - volta.utils -   [GQA]: iter 266842 Ep: 9.06 loss 0.522 score 0.916 lr 6.08073e-06 
09/22/2020 08:16:07 - INFO - volta.utils -   [GQA]: iter 266862 Ep: 9.06 loss 0.391 score 0.942 lr 6.08035e-06 
09/22/2020 08:16:29 - INFO - volta.utils -   [GQA]: iter 266882 Ep: 9.06 loss 0.392 score 0.934 lr 6.07998e-06 
09/22/2020 08:16:38 - INFO - volta.utils -   [GQA]: iter 266902 Ep: 9.06 loss 0.298 score 0.956 lr 6.0796e-06 
09/22/2020 08:16:48 - INFO - volta.utils -   [GQA]: iter 266922 Ep: 9.06 loss 0.399 score 0.947 lr 6.07922e-06 
09/22/2020 08:16:59 - INFO - volta.utils -   [GQA]: iter 266942 Ep: 9.06 loss 0.403 score 0.948 lr 6.07885e-06 
09/22/2020 08:17:10 - INFO - volta.utils -   [GQA]: iter 266962 Ep: 9.06 loss 0.362 score 0.947 lr 6.07847e-06 
09/22/2020 08:17:36 - INFO - volta.utils -   [GQA]: iter 266982 Ep: 9.06 loss 0.418 score 0.927 lr 6.07809e-06 
09/22/2020 08:17:53 - INFO - volta.utils -   [GQA]: iter 267002 Ep: 9.06 loss 0.381 score 0.947 lr 6.07771e-06 
09/22/2020 08:18:05 - INFO - volta.utils -   [GQA]: iter 267022 Ep: 9.06 loss 0.419 score 0.930 lr 6.07734e-06 
09/22/2020 08:18:18 - INFO - volta.utils -   [GQA]: iter 267042 Ep: 9.06 loss 0.450 score 0.927 lr 6.07696e-06 
09/22/2020 08:18:32 - INFO - volta.utils -   [GQA]: iter 267062 Ep: 9.06 loss 0.557 score 0.912 lr 6.07658e-06 
09/22/2020 08:18:47 - INFO - volta.utils -   [GQA]: iter 267082 Ep: 9.06 loss 0.385 score 0.952 lr 6.07621e-06 
09/22/2020 08:19:07 - INFO - volta.utils -   [GQA]: iter 267102 Ep: 9.06 loss 0.353 score 0.941 lr 6.07583e-06 
09/22/2020 08:19:26 - INFO - volta.utils -   [GQA]: iter 267122 Ep: 9.06 loss 0.455 score 0.923 lr 6.07545e-06 
09/22/2020 08:19:35 - INFO - volta.utils -   [GQA]: iter 267142 Ep: 9.07 loss 0.373 score 0.947 lr 6.07508e-06 
09/22/2020 08:19:46 - INFO - volta.utils -   [GQA]: iter 267162 Ep: 9.07 loss 0.296 score 0.956 lr 6.0747e-06 
09/22/2020 08:20:08 - INFO - volta.utils -   [GQA]: iter 267182 Ep: 9.07 loss 0.315 score 0.952 lr 6.07432e-06 
09/22/2020 08:20:15 - INFO - volta.utils -   [GQA]: iter 267202 Ep: 9.07 loss 0.506 score 0.912 lr 6.07394e-06 
09/22/2020 08:20:37 - INFO - volta.utils -   [GQA]: iter 267222 Ep: 9.07 loss 0.363 score 0.945 lr 6.07357e-06 
09/22/2020 08:20:52 - INFO - volta.utils -   [GQA]: iter 267242 Ep: 9.07 loss 0.374 score 0.944 lr 6.07319e-06 
09/22/2020 08:21:04 - INFO - volta.utils -   [GQA]: iter 267262 Ep: 9.07 loss 0.367 score 0.945 lr 6.07281e-06 
09/22/2020 08:21:18 - INFO - volta.utils -   [GQA]: iter 267282 Ep: 9.07 loss 0.355 score 0.948 lr 6.07244e-06 
09/22/2020 08:21:28 - INFO - volta.utils -   [GQA]: iter 267302 Ep: 9.07 loss 0.356 score 0.944 lr 6.07206e-06 
09/22/2020 08:21:35 - INFO - volta.utils -   [GQA]: iter 267322 Ep: 9.07 loss 0.360 score 0.942 lr 6.07168e-06 
09/22/2020 08:21:44 - INFO - volta.utils -   [GQA]: iter 267342 Ep: 9.07 loss 0.375 score 0.933 lr 6.0713e-06 
09/22/2020 08:21:57 - INFO - volta.utils -   [GQA]: iter 267362 Ep: 9.07 loss 0.455 score 0.938 lr 6.07093e-06 
09/22/2020 08:22:16 - INFO - volta.utils -   [GQA]: iter 267382 Ep: 9.07 loss 0.501 score 0.928 lr 6.07055e-06 
09/22/2020 08:22:31 - INFO - volta.utils -   [GQA]: iter 267402 Ep: 9.07 loss 0.386 score 0.941 lr 6.07017e-06 
09/22/2020 08:22:51 - INFO - volta.utils -   [GQA]: iter 267422 Ep: 9.07 loss 0.393 score 0.934 lr 6.0698e-06 
09/22/2020 08:22:59 - INFO - volta.utils -   [GQA]: iter 267442 Ep: 9.08 loss 0.386 score 0.938 lr 6.06942e-06 
09/22/2020 08:23:06 - INFO - volta.utils -   [GQA]: iter 267462 Ep: 9.08 loss 0.320 score 0.955 lr 6.06904e-06 
09/22/2020 08:23:22 - INFO - volta.utils -   [GQA]: iter 267482 Ep: 9.08 loss 0.354 score 0.948 lr 6.06867e-06 
09/22/2020 08:23:48 - INFO - volta.utils -   [GQA]: iter 267502 Ep: 9.08 loss 0.357 score 0.950 lr 6.06829e-06 
09/22/2020 08:24:03 - INFO - volta.utils -   [GQA]: iter 267522 Ep: 9.08 loss 0.386 score 0.945 lr 6.06791e-06 
09/22/2020 08:24:15 - INFO - volta.utils -   [GQA]: iter 267542 Ep: 9.08 loss 0.287 score 0.963 lr 6.06753e-06 
09/22/2020 08:24:23 - INFO - volta.utils -   [GQA]: iter 267562 Ep: 9.08 loss 0.387 score 0.948 lr 6.06716e-06 
09/22/2020 08:24:35 - INFO - volta.utils -   [GQA]: iter 267582 Ep: 9.08 loss 0.345 score 0.947 lr 6.06678e-06 
09/22/2020 08:24:45 - INFO - volta.utils -   [GQA]: iter 267602 Ep: 9.08 loss 0.448 score 0.923 lr 6.0664e-06 
09/22/2020 08:25:06 - INFO - volta.utils -   [GQA]: iter 267622 Ep: 9.08 loss 0.364 score 0.942 lr 6.06603e-06 
09/22/2020 08:25:23 - INFO - volta.utils -   [GQA]: iter 267642 Ep: 9.08 loss 0.351 score 0.945 lr 6.06565e-06 
09/22/2020 08:25:41 - INFO - volta.utils -   [GQA]: iter 267662 Ep: 9.08 loss 0.402 score 0.941 lr 6.06527e-06 
09/22/2020 08:25:50 - INFO - volta.utils -   [GQA]: iter 267682 Ep: 9.08 loss 0.389 score 0.950 lr 6.06489e-06 
09/22/2020 08:26:02 - INFO - volta.utils -   [GQA]: iter 267702 Ep: 9.08 loss 0.431 score 0.931 lr 6.06452e-06 
09/22/2020 08:26:09 - INFO - volta.utils -   [GQA]: iter 267722 Ep: 9.08 loss 0.462 score 0.922 lr 6.06414e-06 
09/22/2020 08:26:19 - INFO - volta.utils -   [GQA]: iter 267742 Ep: 9.09 loss 0.362 score 0.947 lr 6.06376e-06 
09/22/2020 08:26:39 - INFO - volta.utils -   [GQA]: iter 267762 Ep: 9.09 loss 0.415 score 0.931 lr 6.06339e-06 
09/22/2020 08:27:02 - INFO - volta.utils -   [GQA]: iter 267782 Ep: 9.09 loss 0.425 score 0.952 lr 6.06301e-06 
09/22/2020 08:27:15 - INFO - volta.utils -   [GQA]: iter 267802 Ep: 9.09 loss 0.333 score 0.953 lr 6.06263e-06 
09/22/2020 08:27:27 - INFO - volta.utils -   [GQA]: iter 267822 Ep: 9.09 loss 0.385 score 0.942 lr 6.06226e-06 
09/22/2020 08:27:36 - INFO - volta.utils -   [GQA]: iter 267842 Ep: 9.09 loss 0.423 score 0.936 lr 6.06188e-06 
09/22/2020 08:27:43 - INFO - volta.utils -   [GQA]: iter 267862 Ep: 9.09 loss 0.406 score 0.942 lr 6.0615e-06 
09/22/2020 08:27:59 - INFO - volta.utils -   [GQA]: iter 267882 Ep: 9.09 loss 0.394 score 0.941 lr 6.06112e-06 
09/22/2020 08:28:24 - INFO - volta.utils -   [GQA]: iter 267902 Ep: 9.09 loss 0.375 score 0.945 lr 6.06075e-06 
09/22/2020 08:28:51 - INFO - volta.utils -   [GQA]: iter 267922 Ep: 9.09 loss 0.391 score 0.942 lr 6.06037e-06 
09/22/2020 08:29:00 - INFO - volta.utils -   [GQA]: iter 267942 Ep: 9.09 loss 0.364 score 0.945 lr 6.05999e-06 
09/22/2020 08:29:12 - INFO - volta.utils -   [GQA]: iter 267962 Ep: 9.09 loss 0.341 score 0.944 lr 6.05962e-06 
09/22/2020 08:29:25 - INFO - volta.utils -   [GQA]: iter 267982 Ep: 9.09 loss 0.389 score 0.948 lr 6.05924e-06 
09/22/2020 08:29:33 - INFO - volta.utils -   [GQA]: iter 268002 Ep: 9.09 loss 0.355 score 0.942 lr 6.05886e-06 
09/22/2020 08:29:53 - INFO - volta.utils -   [GQA]: iter 268022 Ep: 9.10 loss 0.366 score 0.942 lr 6.05849e-06 
09/22/2020 08:30:14 - INFO - volta.utils -   [GQA]: iter 268042 Ep: 9.10 loss 0.407 score 0.936 lr 6.05811e-06 
09/22/2020 08:30:38 - INFO - volta.utils -   [GQA]: iter 268062 Ep: 9.10 loss 0.299 score 0.955 lr 6.05773e-06 
09/22/2020 08:30:45 - INFO - volta.utils -   [GQA]: iter 268082 Ep: 9.10 loss 0.423 score 0.933 lr 6.05735e-06 
09/22/2020 08:30:54 - INFO - volta.utils -   [GQA]: iter 268102 Ep: 9.10 loss 0.364 score 0.938 lr 6.05698e-06 
09/22/2020 08:31:02 - INFO - volta.utils -   [GQA]: iter 268122 Ep: 9.10 loss 0.399 score 0.925 lr 6.0566e-06 
09/22/2020 08:31:24 - INFO - volta.utils -   [GQA]: iter 268142 Ep: 9.10 loss 0.404 score 0.945 lr 6.05622e-06 
09/22/2020 08:31:43 - INFO - volta.utils -   [GQA]: iter 268162 Ep: 9.10 loss 0.349 score 0.938 lr 6.05585e-06 
09/22/2020 08:32:01 - INFO - volta.utils -   [GQA]: iter 268182 Ep: 9.10 loss 0.389 score 0.948 lr 6.05547e-06 
09/22/2020 08:32:12 - INFO - volta.utils -   [GQA]: iter 268202 Ep: 9.10 loss 0.374 score 0.939 lr 6.05509e-06 
09/22/2020 08:32:22 - INFO - volta.utils -   [GQA]: iter 268222 Ep: 9.10 loss 0.356 score 0.944 lr 6.05471e-06 
09/22/2020 08:32:31 - INFO - volta.utils -   [GQA]: iter 268242 Ep: 9.10 loss 0.390 score 0.931 lr 6.05434e-06 
09/22/2020 08:32:41 - INFO - volta.utils -   [GQA]: iter 268262 Ep: 9.10 loss 0.436 score 0.928 lr 6.05396e-06 
09/22/2020 08:33:05 - INFO - volta.utils -   [GQA]: iter 268282 Ep: 9.10 loss 0.372 score 0.939 lr 6.05358e-06 
09/22/2020 08:33:20 - INFO - volta.utils -   [GQA]: iter 268302 Ep: 9.10 loss 0.370 score 0.942 lr 6.05321e-06 
09/22/2020 08:33:36 - INFO - volta.utils -   [GQA]: iter 268322 Ep: 9.11 loss 0.545 score 0.914 lr 6.05283e-06 
09/22/2020 08:33:47 - INFO - volta.utils -   [GQA]: iter 268342 Ep: 9.11 loss 0.388 score 0.931 lr 6.05245e-06 
09/22/2020 08:33:59 - INFO - volta.utils -   [GQA]: iter 268362 Ep: 9.11 loss 0.334 score 0.944 lr 6.05208e-06 
09/22/2020 08:34:07 - INFO - volta.utils -   [GQA]: iter 268382 Ep: 9.11 loss 0.401 score 0.944 lr 6.0517e-06 
09/22/2020 08:34:18 - INFO - volta.utils -   [GQA]: iter 268402 Ep: 9.11 loss 0.376 score 0.934 lr 6.05132e-06 
09/22/2020 08:34:38 - INFO - volta.utils -   [GQA]: iter 268422 Ep: 9.11 loss 0.367 score 0.944 lr 6.05094e-06 
09/22/2020 08:34:58 - INFO - volta.utils -   [GQA]: iter 268442 Ep: 9.11 loss 0.360 score 0.952 lr 6.05057e-06 
09/22/2020 08:35:11 - INFO - volta.utils -   [GQA]: iter 268462 Ep: 9.11 loss 0.327 score 0.958 lr 6.05019e-06 
09/22/2020 08:35:28 - INFO - volta.utils -   [GQA]: iter 268482 Ep: 9.11 loss 0.417 score 0.928 lr 6.04981e-06 
09/22/2020 08:35:36 - INFO - volta.utils -   [GQA]: iter 268502 Ep: 9.11 loss 0.459 score 0.934 lr 6.04944e-06 
09/22/2020 08:35:46 - INFO - volta.utils -   [GQA]: iter 268522 Ep: 9.11 loss 0.377 score 0.936 lr 6.04906e-06 
09/22/2020 08:35:56 - INFO - volta.utils -   [GQA]: iter 268542 Ep: 9.11 loss 0.453 score 0.917 lr 6.04868e-06 
09/22/2020 08:36:32 - INFO - volta.utils -   [GQA]: iter 268562 Ep: 9.11 loss 0.332 score 0.948 lr 6.0483e-06 
09/22/2020 08:36:48 - INFO - volta.utils -   [GQA]: iter 268582 Ep: 9.11 loss 0.405 score 0.933 lr 6.04793e-06 
09/22/2020 08:37:01 - INFO - volta.utils -   [GQA]: iter 268602 Ep: 9.11 loss 0.407 score 0.928 lr 6.04755e-06 
09/22/2020 08:37:09 - INFO - volta.utils -   [GQA]: iter 268622 Ep: 9.12 loss 0.384 score 0.950 lr 6.04717e-06 
09/22/2020 08:37:29 - INFO - volta.utils -   [GQA]: iter 268642 Ep: 9.12 loss 0.400 score 0.939 lr 6.0468e-06 
09/22/2020 08:37:51 - INFO - volta.utils -   [GQA]: iter 268662 Ep: 9.12 loss 0.442 score 0.931 lr 6.04642e-06 
09/22/2020 08:38:04 - INFO - volta.utils -   [GQA]: iter 268682 Ep: 9.12 loss 0.348 score 0.947 lr 6.04604e-06 
09/22/2020 08:38:17 - INFO - volta.utils -   [GQA]: iter 268702 Ep: 9.12 loss 0.375 score 0.930 lr 6.04567e-06 
09/22/2020 08:38:29 - INFO - volta.utils -   [GQA]: iter 268722 Ep: 9.12 loss 0.330 score 0.959 lr 6.04529e-06 
09/22/2020 08:38:44 - INFO - volta.utils -   [GQA]: iter 268742 Ep: 9.12 loss 0.337 score 0.948 lr 6.04491e-06 
09/22/2020 08:38:57 - INFO - volta.utils -   [GQA]: iter 268762 Ep: 9.12 loss 0.432 score 0.934 lr 6.04453e-06 
09/22/2020 08:39:12 - INFO - volta.utils -   [GQA]: iter 268782 Ep: 9.12 loss 0.338 score 0.950 lr 6.04416e-06 
09/22/2020 08:39:33 - INFO - volta.utils -   [GQA]: iter 268802 Ep: 9.12 loss 0.397 score 0.939 lr 6.04378e-06 
09/22/2020 08:39:49 - INFO - volta.utils -   [GQA]: iter 268822 Ep: 9.12 loss 0.425 score 0.939 lr 6.0434e-06 
09/22/2020 08:39:56 - INFO - volta.utils -   [GQA]: iter 268842 Ep: 9.12 loss 0.327 score 0.948 lr 6.04303e-06 
09/22/2020 08:40:05 - INFO - volta.utils -   [GQA]: iter 268862 Ep: 9.12 loss 0.393 score 0.933 lr 6.04265e-06 
09/22/2020 08:40:14 - INFO - volta.utils -   [GQA]: iter 268882 Ep: 9.12 loss 0.435 score 0.933 lr 6.04227e-06 
09/22/2020 08:40:37 - INFO - volta.utils -   [GQA]: iter 268902 Ep: 9.12 loss 0.370 score 0.945 lr 6.0419e-06 
09/22/2020 08:40:53 - INFO - volta.utils -   [GQA]: iter 268922 Ep: 9.13 loss 0.434 score 0.941 lr 6.04152e-06 
09/22/2020 08:41:08 - INFO - volta.utils -   [GQA]: iter 268942 Ep: 9.13 loss 0.421 score 0.919 lr 6.04114e-06 
09/22/2020 08:41:20 - INFO - volta.utils -   [GQA]: iter 268962 Ep: 9.13 loss 0.407 score 0.931 lr 6.04076e-06 
09/22/2020 08:41:34 - INFO - volta.utils -   [GQA]: iter 268982 Ep: 9.13 loss 0.457 score 0.922 lr 6.04039e-06 
09/22/2020 08:41:42 - INFO - volta.utils -   [GQA]: iter 269002 Ep: 9.13 loss 0.403 score 0.936 lr 6.04001e-06 
09/22/2020 08:41:51 - INFO - volta.utils -   [GQA]: iter 269022 Ep: 9.13 loss 0.412 score 0.934 lr 6.03963e-06 
09/22/2020 08:42:09 - INFO - volta.utils -   [GQA]: iter 269042 Ep: 9.13 loss 0.398 score 0.941 lr 6.03926e-06 
09/22/2020 08:42:30 - INFO - volta.utils -   [GQA]: iter 269062 Ep: 9.13 loss 0.410 score 0.928 lr 6.03888e-06 
09/22/2020 08:42:48 - INFO - volta.utils -   [GQA]: iter 269082 Ep: 9.13 loss 0.432 score 0.934 lr 6.0385e-06 
09/22/2020 08:43:03 - INFO - volta.utils -   [GQA]: iter 269102 Ep: 9.13 loss 0.390 score 0.934 lr 6.03812e-06 
09/22/2020 08:43:18 - INFO - volta.utils -   [GQA]: iter 269122 Ep: 9.13 loss 0.339 score 0.948 lr 6.03775e-06 
09/22/2020 08:43:32 - INFO - volta.utils -   [GQA]: iter 269142 Ep: 9.13 loss 0.317 score 0.948 lr 6.03737e-06 
09/22/2020 08:43:42 - INFO - volta.utils -   [GQA]: iter 269162 Ep: 9.13 loss 0.350 score 0.945 lr 6.03699e-06 
09/22/2020 08:43:55 - INFO - volta.utils -   [GQA]: iter 269182 Ep: 9.13 loss 0.406 score 0.936 lr 6.03662e-06 
09/22/2020 08:44:03 - INFO - volta.utils -   [GQA]: iter 269202 Ep: 9.14 loss 0.434 score 0.933 lr 6.03624e-06 
09/22/2020 08:44:12 - INFO - volta.utils -   [GQA]: iter 269222 Ep: 9.14 loss 0.324 score 0.958 lr 6.03586e-06 
09/22/2020 08:44:25 - INFO - volta.utils -   [GQA]: iter 269242 Ep: 9.14 loss 0.389 score 0.942 lr 6.03549e-06 
09/22/2020 08:44:47 - INFO - volta.utils -   [GQA]: iter 269262 Ep: 9.14 loss 0.441 score 0.925 lr 6.03511e-06 
09/22/2020 08:45:03 - INFO - volta.utils -   [GQA]: iter 269282 Ep: 9.14 loss 0.352 score 0.942 lr 6.03473e-06 
09/22/2020 08:45:27 - INFO - volta.utils -   [GQA]: iter 269302 Ep: 9.14 loss 0.357 score 0.948 lr 6.03435e-06 
09/22/2020 08:45:42 - INFO - volta.utils -   [GQA]: iter 269322 Ep: 9.14 loss 0.521 score 0.909 lr 6.03398e-06 
09/22/2020 08:45:53 - INFO - volta.utils -   [GQA]: iter 269342 Ep: 9.14 loss 0.435 score 0.927 lr 6.0336e-06 
09/22/2020 08:46:01 - INFO - volta.utils -   [GQA]: iter 269362 Ep: 9.14 loss 0.391 score 0.948 lr 6.03322e-06 
09/22/2020 08:46:18 - INFO - volta.utils -   [GQA]: iter 269382 Ep: 9.14 loss 0.334 score 0.956 lr 6.03285e-06 
09/22/2020 08:46:41 - INFO - volta.utils -   [GQA]: iter 269402 Ep: 9.14 loss 0.329 score 0.953 lr 6.03247e-06 
09/22/2020 08:46:59 - INFO - volta.utils -   [GQA]: iter 269422 Ep: 9.14 loss 0.403 score 0.938 lr 6.03209e-06 
09/22/2020 08:47:11 - INFO - volta.utils -   [GQA]: iter 269442 Ep: 9.14 loss 0.327 score 0.956 lr 6.03172e-06 
09/22/2020 08:47:25 - INFO - volta.utils -   [GQA]: iter 269462 Ep: 9.14 loss 0.378 score 0.938 lr 6.03134e-06 
09/22/2020 08:47:32 - INFO - volta.utils -   [GQA]: iter 269482 Ep: 9.14 loss 0.386 score 0.950 lr 6.03096e-06 
09/22/2020 08:47:56 - INFO - volta.utils -   [GQA]: iter 269502 Ep: 9.15 loss 0.374 score 0.942 lr 6.03058e-06 
09/22/2020 08:48:10 - INFO - volta.utils -   [GQA]: iter 269522 Ep: 9.15 loss 0.333 score 0.948 lr 6.03021e-06 
09/22/2020 08:48:19 - INFO - volta.utils -   [GQA]: iter 269542 Ep: 9.15 loss 0.338 score 0.947 lr 6.02983e-06 
09/22/2020 08:48:39 - INFO - volta.utils -   [GQA]: iter 269562 Ep: 9.15 loss 0.369 score 0.947 lr 6.02945e-06 
09/22/2020 08:48:54 - INFO - volta.utils -   [GQA]: iter 269582 Ep: 9.15 loss 0.379 score 0.952 lr 6.02908e-06 
09/22/2020 08:49:02 - INFO - volta.utils -   [GQA]: iter 269602 Ep: 9.15 loss 0.345 score 0.953 lr 6.0287e-06 
09/22/2020 08:49:11 - INFO - volta.utils -   [GQA]: iter 269622 Ep: 9.15 loss 0.481 score 0.925 lr 6.02832e-06 
09/22/2020 08:49:19 - INFO - volta.utils -   [GQA]: iter 269642 Ep: 9.15 loss 0.372 score 0.955 lr 6.02794e-06 
09/22/2020 08:49:34 - INFO - volta.utils -   [GQA]: iter 269662 Ep: 9.15 loss 0.375 score 0.944 lr 6.02757e-06 
09/22/2020 08:49:41 - INFO - volta.utils -   [GQA]: iter 269682 Ep: 9.15 loss 0.318 score 0.956 lr 6.02719e-06 
09/22/2020 08:49:53 - INFO - volta.utils -   [GQA]: iter 269702 Ep: 9.15 loss 0.414 score 0.936 lr 6.02681e-06 
09/22/2020 08:50:14 - INFO - volta.utils -   [GQA]: iter 269722 Ep: 9.15 loss 0.357 score 0.948 lr 6.02644e-06 
09/22/2020 08:50:29 - INFO - volta.utils -   [GQA]: iter 269742 Ep: 9.15 loss 0.384 score 0.933 lr 6.02606e-06 
09/22/2020 08:50:52 - INFO - volta.utils -   [GQA]: iter 269762 Ep: 9.15 loss 0.400 score 0.931 lr 6.02568e-06 
09/22/2020 08:51:00 - INFO - volta.utils -   [GQA]: iter 269782 Ep: 9.15 loss 0.341 score 0.948 lr 6.02531e-06 
09/22/2020 08:51:08 - INFO - volta.utils -   [GQA]: iter 269802 Ep: 9.16 loss 0.430 score 0.934 lr 6.02493e-06 
09/22/2020 08:51:16 - INFO - volta.utils -   [GQA]: iter 269822 Ep: 9.16 loss 0.384 score 0.938 lr 6.02455e-06 
09/22/2020 08:51:31 - INFO - volta.utils -   [GQA]: iter 269842 Ep: 9.16 loss 0.390 score 0.941 lr 6.02417e-06 
09/22/2020 08:51:47 - INFO - volta.utils -   [GQA]: iter 269862 Ep: 9.16 loss 0.409 score 0.941 lr 6.0238e-06 
09/22/2020 08:52:12 - INFO - volta.utils -   [GQA]: iter 269882 Ep: 9.16 loss 0.341 score 0.952 lr 6.02342e-06 
09/22/2020 08:52:24 - INFO - volta.utils -   [GQA]: iter 269902 Ep: 9.16 loss 0.379 score 0.942 lr 6.02304e-06 
09/22/2020 08:52:32 - INFO - volta.utils -   [GQA]: iter 269922 Ep: 9.16 loss 0.443 score 0.933 lr 6.02267e-06 
09/22/2020 08:52:40 - INFO - volta.utils -   [GQA]: iter 269942 Ep: 9.16 loss 0.382 score 0.945 lr 6.02229e-06 
09/22/2020 08:52:48 - INFO - volta.utils -   [GQA]: iter 269962 Ep: 9.16 loss 0.388 score 0.930 lr 6.02191e-06 
09/22/2020 08:53:06 - INFO - volta.utils -   [GQA]: iter 269982 Ep: 9.16 loss 0.367 score 0.942 lr 6.02153e-06 
09/22/2020 08:53:13 - INFO - volta.utils -   [GQA]: iter 270002 Ep: 9.16 loss 0.432 score 0.930 lr 6.02116e-06 
09/22/2020 08:53:27 - INFO - volta.utils -   [GQA]: iter 270022 Ep: 9.16 loss 0.362 score 0.939 lr 6.02078e-06 
09/22/2020 08:53:48 - INFO - volta.utils -   [GQA]: iter 270042 Ep: 9.16 loss 0.424 score 0.931 lr 6.0204e-06 
09/22/2020 08:54:07 - INFO - volta.utils -   [GQA]: iter 270062 Ep: 9.16 loss 0.392 score 0.948 lr 6.02003e-06 
09/22/2020 08:54:22 - INFO - volta.utils -   [GQA]: iter 270082 Ep: 9.16 loss 0.337 score 0.955 lr 6.01965e-06 
09/22/2020 08:54:39 - INFO - volta.utils -   [GQA]: iter 270102 Ep: 9.17 loss 0.391 score 0.930 lr 6.01927e-06 
09/22/2020 08:55:02 - INFO - volta.utils -   [GQA]: iter 270122 Ep: 9.17 loss 0.348 score 0.948 lr 6.0189e-06 
09/22/2020 08:55:18 - INFO - volta.utils -   [GQA]: iter 270142 Ep: 9.17 loss 0.410 score 0.927 lr 6.01852e-06 
09/22/2020 08:55:35 - INFO - volta.utils -   [GQA]: iter 270162 Ep: 9.17 loss 0.428 score 0.941 lr 6.01814e-06 
09/22/2020 08:55:50 - INFO - volta.utils -   [GQA]: iter 270182 Ep: 9.17 loss 0.413 score 0.944 lr 6.01776e-06 
09/22/2020 08:56:12 - INFO - volta.utils -   [GQA]: iter 270202 Ep: 9.17 loss 0.411 score 0.933 lr 6.01739e-06 
09/22/2020 08:56:19 - INFO - volta.utils -   [GQA]: iter 270222 Ep: 9.17 loss 0.414 score 0.939 lr 6.01701e-06 
09/22/2020 08:56:27 - INFO - volta.utils -   [GQA]: iter 270242 Ep: 9.17 loss 0.434 score 0.928 lr 6.01663e-06 
09/22/2020 08:56:44 - INFO - volta.utils -   [GQA]: iter 270262 Ep: 9.17 loss 0.408 score 0.938 lr 6.01626e-06 
09/22/2020 08:56:55 - INFO - volta.utils -   [GQA]: iter 270282 Ep: 9.17 loss 0.367 score 0.931 lr 6.01588e-06 
09/22/2020 08:57:07 - INFO - volta.utils -   [GQA]: iter 270302 Ep: 9.17 loss 0.467 score 0.925 lr 6.0155e-06 
09/22/2020 08:57:20 - INFO - volta.utils -   [GQA]: iter 270322 Ep: 9.17 loss 0.357 score 0.953 lr 6.01513e-06 
09/22/2020 08:57:42 - INFO - volta.utils -   [GQA]: iter 270342 Ep: 9.17 loss 0.488 score 0.911 lr 6.01475e-06 
09/22/2020 08:58:04 - INFO - volta.utils -   [GQA]: iter 270362 Ep: 9.17 loss 0.368 score 0.938 lr 6.01437e-06 
09/22/2020 08:58:16 - INFO - volta.utils -   [GQA]: iter 270382 Ep: 9.18 loss 0.349 score 0.948 lr 6.01399e-06 
09/22/2020 08:58:25 - INFO - volta.utils -   [GQA]: iter 270402 Ep: 9.18 loss 0.451 score 0.925 lr 6.01362e-06 
09/22/2020 08:58:35 - INFO - volta.utils -   [GQA]: iter 270422 Ep: 9.18 loss 0.343 score 0.931 lr 6.01324e-06 
09/22/2020 08:58:44 - INFO - volta.utils -   [GQA]: iter 270442 Ep: 9.18 loss 0.539 score 0.923 lr 6.01286e-06 
09/22/2020 08:58:58 - INFO - volta.utils -   [GQA]: iter 270462 Ep: 9.18 loss 0.390 score 0.939 lr 6.01249e-06 
09/22/2020 08:59:17 - INFO - volta.utils -   [GQA]: iter 270482 Ep: 9.18 loss 0.301 score 0.967 lr 6.01211e-06 
09/22/2020 08:59:37 - INFO - volta.utils -   [GQA]: iter 270502 Ep: 9.18 loss 0.383 score 0.945 lr 6.01173e-06 
09/22/2020 08:59:50 - INFO - volta.utils -   [GQA]: iter 270522 Ep: 9.18 loss 0.411 score 0.941 lr 6.01135e-06 
09/22/2020 09:00:00 - INFO - volta.utils -   [GQA]: iter 270542 Ep: 9.18 loss 0.410 score 0.923 lr 6.01098e-06 
09/22/2020 09:00:11 - INFO - volta.utils -   [GQA]: iter 270562 Ep: 9.18 loss 0.393 score 0.942 lr 6.0106e-06 
09/22/2020 09:00:29 - INFO - volta.utils -   [GQA]: iter 270582 Ep: 9.18 loss 0.450 score 0.919 lr 6.01022e-06 
09/22/2020 09:00:37 - INFO - volta.utils -   [GQA]: iter 270602 Ep: 9.18 loss 0.377 score 0.939 lr 6.00985e-06 
09/22/2020 09:00:48 - INFO - volta.utils -   [GQA]: iter 270622 Ep: 9.18 loss 0.433 score 0.928 lr 6.00947e-06 
09/22/2020 09:01:15 - INFO - volta.utils -   [GQA]: iter 270642 Ep: 9.18 loss 0.476 score 0.928 lr 6.00909e-06 
09/22/2020 09:01:39 - INFO - volta.utils -   [GQA]: iter 270662 Ep: 9.18 loss 0.405 score 0.939 lr 6.00872e-06 
09/22/2020 09:01:51 - INFO - volta.utils -   [GQA]: iter 270682 Ep: 9.19 loss 0.320 score 0.956 lr 6.00834e-06 
09/22/2020 09:02:02 - INFO - volta.utils -   [GQA]: iter 270702 Ep: 9.19 loss 0.329 score 0.947 lr 6.00796e-06 
09/22/2020 09:02:19 - INFO - volta.utils -   [GQA]: iter 270722 Ep: 9.19 loss 0.371 score 0.948 lr 6.00758e-06 
09/22/2020 09:02:27 - INFO - volta.utils -   [GQA]: iter 270742 Ep: 9.19 loss 0.366 score 0.948 lr 6.00721e-06 
09/22/2020 09:02:42 - INFO - volta.utils -   [GQA]: iter 270762 Ep: 9.19 loss 0.407 score 0.933 lr 6.00683e-06 
09/22/2020 09:02:59 - INFO - volta.utils -   [GQA]: iter 270782 Ep: 9.19 loss 0.457 score 0.938 lr 6.00645e-06 
09/22/2020 09:03:20 - INFO - volta.utils -   [GQA]: iter 270802 Ep: 9.19 loss 0.430 score 0.934 lr 6.00608e-06 
09/22/2020 09:03:33 - INFO - volta.utils -   [GQA]: iter 270822 Ep: 9.19 loss 0.412 score 0.938 lr 6.0057e-06 
09/22/2020 09:03:42 - INFO - volta.utils -   [GQA]: iter 270842 Ep: 9.19 loss 0.447 score 0.934 lr 6.00532e-06 
09/22/2020 09:03:51 - INFO - volta.utils -   [GQA]: iter 270862 Ep: 9.19 loss 0.338 score 0.939 lr 6.00494e-06 
09/22/2020 09:03:59 - INFO - volta.utils -   [GQA]: iter 270882 Ep: 9.19 loss 0.392 score 0.939 lr 6.00457e-06 
09/22/2020 09:04:10 - INFO - volta.utils -   [GQA]: iter 270902 Ep: 9.19 loss 0.515 score 0.914 lr 6.00419e-06 
09/22/2020 09:04:18 - INFO - volta.utils -   [GQA]: iter 270922 Ep: 9.19 loss 0.399 score 0.942 lr 6.00381e-06 
09/22/2020 09:04:27 - INFO - volta.utils -   [GQA]: iter 270942 Ep: 9.19 loss 0.467 score 0.933 lr 6.00344e-06 
09/22/2020 09:04:39 - INFO - volta.utils -   [GQA]: iter 270962 Ep: 9.19 loss 0.438 score 0.925 lr 6.00306e-06 
09/22/2020 09:04:56 - INFO - volta.utils -   [GQA]: iter 270982 Ep: 9.20 loss 0.293 score 0.952 lr 6.00268e-06 
09/22/2020 09:05:14 - INFO - volta.utils -   [GQA]: iter 271002 Ep: 9.20 loss 0.421 score 0.930 lr 6.00231e-06 
09/22/2020 09:05:29 - INFO - volta.utils -   [GQA]: iter 271022 Ep: 9.20 loss 0.356 score 0.944 lr 6.00193e-06 
09/22/2020 09:05:38 - INFO - volta.utils -   [GQA]: iter 271042 Ep: 9.20 loss 0.459 score 0.939 lr 6.00155e-06 
09/22/2020 09:05:48 - INFO - volta.utils -   [GQA]: iter 271062 Ep: 9.20 loss 0.443 score 0.938 lr 6.00117e-06 
09/22/2020 09:06:03 - INFO - volta.utils -   [GQA]: iter 271082 Ep: 9.20 loss 0.451 score 0.930 lr 6.0008e-06 
09/22/2020 09:06:11 - INFO - volta.utils -   [GQA]: iter 271102 Ep: 9.20 loss 0.409 score 0.928 lr 6.00042e-06 
09/22/2020 09:06:24 - INFO - volta.utils -   [GQA]: iter 271122 Ep: 9.20 loss 0.346 score 0.942 lr 6.00004e-06 
09/22/2020 09:06:41 - INFO - volta.utils -   [GQA]: iter 271142 Ep: 9.20 loss 0.389 score 0.936 lr 5.99967e-06 
09/22/2020 09:06:49 - INFO - volta.utils -   [GQA]: iter 271162 Ep: 9.20 loss 0.392 score 0.933 lr 5.99929e-06 
09/22/2020 09:06:59 - INFO - volta.utils -   [GQA]: iter 271182 Ep: 9.20 loss 0.337 score 0.941 lr 5.99891e-06 
09/22/2020 09:07:12 - INFO - volta.utils -   [GQA]: iter 271202 Ep: 9.20 loss 0.310 score 0.950 lr 5.99854e-06 
09/22/2020 09:07:42 - INFO - volta.utils -   [GQA]: iter 271222 Ep: 9.20 loss 0.392 score 0.944 lr 5.99816e-06 
09/22/2020 09:08:03 - INFO - volta.utils -   [GQA]: iter 271242 Ep: 9.20 loss 0.389 score 0.944 lr 5.99778e-06 
09/22/2020 09:08:15 - INFO - volta.utils -   [GQA]: iter 271262 Ep: 9.20 loss 0.368 score 0.944 lr 5.9974e-06 
09/22/2020 09:08:24 - INFO - volta.utils -   [GQA]: iter 271282 Ep: 9.21 loss 0.357 score 0.944 lr 5.99703e-06 
09/22/2020 09:08:31 - INFO - volta.utils -   [GQA]: iter 271302 Ep: 9.21 loss 0.443 score 0.919 lr 5.99665e-06 
09/22/2020 09:08:39 - INFO - volta.utils -   [GQA]: iter 271322 Ep: 9.21 loss 0.387 score 0.948 lr 5.99627e-06 
09/22/2020 09:08:52 - INFO - volta.utils -   [GQA]: iter 271342 Ep: 9.21 loss 0.360 score 0.945 lr 5.9959e-06 
09/22/2020 09:09:03 - INFO - volta.utils -   [GQA]: iter 271362 Ep: 9.21 loss 0.434 score 0.934 lr 5.99552e-06 
09/22/2020 09:09:11 - INFO - volta.utils -   [GQA]: iter 271382 Ep: 9.21 loss 0.442 score 0.931 lr 5.99514e-06 
09/22/2020 09:09:21 - INFO - volta.utils -   [GQA]: iter 271402 Ep: 9.21 loss 0.445 score 0.925 lr 5.99476e-06 
09/22/2020 09:09:43 - INFO - volta.utils -   [GQA]: iter 271422 Ep: 9.21 loss 0.377 score 0.934 lr 5.99439e-06 
09/22/2020 09:10:11 - INFO - volta.utils -   [GQA]: iter 271442 Ep: 9.21 loss 0.397 score 0.934 lr 5.99401e-06 
09/22/2020 09:10:25 - INFO - volta.utils -   [GQA]: iter 271462 Ep: 9.21 loss 0.364 score 0.947 lr 5.99363e-06 
09/22/2020 09:10:38 - INFO - volta.utils -   [GQA]: iter 271482 Ep: 9.21 loss 0.427 score 0.923 lr 5.99326e-06 
09/22/2020 09:10:53 - INFO - volta.utils -   [GQA]: iter 271502 Ep: 9.21 loss 0.365 score 0.947 lr 5.99288e-06 
09/22/2020 09:11:10 - INFO - volta.utils -   [GQA]: iter 271522 Ep: 9.21 loss 0.460 score 0.928 lr 5.9925e-06 
09/22/2020 09:11:18 - INFO - volta.utils -   [GQA]: iter 271542 Ep: 9.21 loss 0.361 score 0.945 lr 5.99213e-06 
09/22/2020 09:11:42 - INFO - volta.utils -   [GQA]: iter 271562 Ep: 9.22 loss 0.365 score 0.941 lr 5.99175e-06 
09/22/2020 09:12:06 - INFO - volta.utils -   [GQA]: iter 271582 Ep: 9.22 loss 0.359 score 0.939 lr 5.99137e-06 
09/22/2020 09:12:22 - INFO - volta.utils -   [GQA]: iter 271602 Ep: 9.22 loss 0.377 score 0.934 lr 5.99099e-06 
09/22/2020 09:12:30 - INFO - volta.utils -   [GQA]: iter 271622 Ep: 9.22 loss 0.357 score 0.941 lr 5.99062e-06 
09/22/2020 09:12:43 - INFO - volta.utils -   [GQA]: iter 271642 Ep: 9.22 loss 0.344 score 0.947 lr 5.99024e-06 
09/22/2020 09:12:56 - INFO - volta.utils -   [GQA]: iter 271662 Ep: 9.22 loss 0.450 score 0.923 lr 5.98986e-06 
09/22/2020 09:13:06 - INFO - volta.utils -   [GQA]: iter 271682 Ep: 9.22 loss 0.398 score 0.934 lr 5.98949e-06 
09/22/2020 09:13:25 - INFO - volta.utils -   [GQA]: iter 271702 Ep: 9.22 loss 0.405 score 0.931 lr 5.98911e-06 
09/22/2020 09:13:52 - INFO - volta.utils -   [GQA]: iter 271722 Ep: 9.22 loss 0.334 score 0.948 lr 5.98873e-06 
09/22/2020 09:14:09 - INFO - volta.utils -   [GQA]: iter 271742 Ep: 9.22 loss 0.397 score 0.936 lr 5.98835e-06 
09/22/2020 09:14:25 - INFO - volta.utils -   [GQA]: iter 271762 Ep: 9.22 loss 0.438 score 0.927 lr 5.98798e-06 
09/22/2020 09:14:32 - INFO - volta.utils -   [GQA]: iter 271782 Ep: 9.22 loss 0.440 score 0.934 lr 5.9876e-06 
09/22/2020 09:14:42 - INFO - volta.utils -   [GQA]: iter 271802 Ep: 9.22 loss 0.350 score 0.950 lr 5.98722e-06 
09/22/2020 09:14:53 - INFO - volta.utils -   [GQA]: iter 271822 Ep: 9.22 loss 0.482 score 0.917 lr 5.98685e-06 
09/22/2020 09:15:23 - INFO - volta.utils -   [GQA]: iter 271842 Ep: 9.22 loss 0.373 score 0.938 lr 5.98647e-06 
09/22/2020 09:15:32 - INFO - volta.utils -   [GQA]: iter 271862 Ep: 9.23 loss 0.388 score 0.938 lr 5.98609e-06 
09/22/2020 09:15:41 - INFO - volta.utils -   [GQA]: iter 271882 Ep: 9.23 loss 0.373 score 0.931 lr 5.98572e-06 
09/22/2020 09:16:08 - INFO - volta.utils -   [GQA]: iter 271902 Ep: 9.23 loss 0.432 score 0.934 lr 5.98534e-06 
09/22/2020 09:16:18 - INFO - volta.utils -   [GQA]: iter 271922 Ep: 9.23 loss 0.435 score 0.933 lr 5.98496e-06 
09/22/2020 09:16:26 - INFO - volta.utils -   [GQA]: iter 271942 Ep: 9.23 loss 0.385 score 0.944 lr 5.98458e-06 
09/22/2020 09:16:47 - INFO - volta.utils -   [GQA]: iter 271962 Ep: 9.23 loss 0.370 score 0.939 lr 5.98421e-06 
09/22/2020 09:17:05 - INFO - volta.utils -   [GQA]: iter 271982 Ep: 9.23 loss 0.451 score 0.922 lr 5.98383e-06 
09/22/2020 09:17:24 - INFO - volta.utils -   [GQA]: iter 272002 Ep: 9.23 loss 0.360 score 0.939 lr 5.98345e-06 
09/22/2020 09:17:37 - INFO - volta.utils -   [GQA]: iter 272022 Ep: 9.23 loss 0.398 score 0.945 lr 5.98308e-06 
09/22/2020 09:17:48 - INFO - volta.utils -   [GQA]: iter 272042 Ep: 9.23 loss 0.361 score 0.944 lr 5.9827e-06 
09/22/2020 09:17:55 - INFO - volta.utils -   [GQA]: iter 272062 Ep: 9.23 loss 0.435 score 0.928 lr 5.98232e-06 
09/22/2020 09:18:08 - INFO - volta.utils -   [GQA]: iter 272082 Ep: 9.23 loss 0.362 score 0.944 lr 5.98195e-06 
09/22/2020 09:18:28 - INFO - volta.utils -   [GQA]: iter 272102 Ep: 9.23 loss 0.444 score 0.948 lr 5.98157e-06 
09/22/2020 09:18:45 - INFO - volta.utils -   [GQA]: iter 272122 Ep: 9.23 loss 0.407 score 0.938 lr 5.98119e-06 
09/22/2020 09:18:58 - INFO - volta.utils -   [GQA]: iter 272142 Ep: 9.23 loss 0.411 score 0.931 lr 5.98081e-06 
09/22/2020 09:19:08 - INFO - volta.utils -   [GQA]: iter 272162 Ep: 9.24 loss 0.388 score 0.936 lr 5.98044e-06 
09/22/2020 09:19:16 - INFO - volta.utils -   [GQA]: iter 272182 Ep: 9.24 loss 0.331 score 0.952 lr 5.98006e-06 
09/22/2020 09:19:27 - INFO - volta.utils -   [GQA]: iter 272202 Ep: 9.24 loss 0.301 score 0.959 lr 5.97968e-06 
09/22/2020 09:19:40 - INFO - volta.utils -   [GQA]: iter 272222 Ep: 9.24 loss 0.530 score 0.923 lr 5.97931e-06 
09/22/2020 09:19:58 - INFO - volta.utils -   [GQA]: iter 272242 Ep: 9.24 loss 0.411 score 0.934 lr 5.97893e-06 
09/22/2020 09:20:11 - INFO - volta.utils -   [GQA]: iter 272262 Ep: 9.24 loss 0.292 score 0.959 lr 5.97855e-06 
09/22/2020 09:20:26 - INFO - volta.utils -   [GQA]: iter 272282 Ep: 9.24 loss 0.415 score 0.939 lr 5.97817e-06 
09/22/2020 09:20:45 - INFO - volta.utils -   [GQA]: iter 272302 Ep: 9.24 loss 0.453 score 0.916 lr 5.9778e-06 
09/22/2020 09:20:56 - INFO - volta.utils -   [GQA]: iter 272322 Ep: 9.24 loss 0.385 score 0.936 lr 5.97742e-06 
09/22/2020 09:21:04 - INFO - volta.utils -   [GQA]: iter 272342 Ep: 9.24 loss 0.385 score 0.947 lr 5.97704e-06 
09/22/2020 09:21:17 - INFO - volta.utils -   [GQA]: iter 272362 Ep: 9.24 loss 0.414 score 0.941 lr 5.97667e-06 
09/22/2020 09:21:36 - INFO - volta.utils -   [GQA]: iter 272382 Ep: 9.24 loss 0.413 score 0.930 lr 5.97629e-06 
09/22/2020 09:21:53 - INFO - volta.utils -   [GQA]: iter 272402 Ep: 9.24 loss 0.393 score 0.944 lr 5.97591e-06 
09/22/2020 09:22:06 - INFO - volta.utils -   [GQA]: iter 272422 Ep: 9.24 loss 0.474 score 0.927 lr 5.97554e-06 
09/22/2020 09:22:16 - INFO - volta.utils -   [GQA]: iter 272442 Ep: 9.25 loss 0.353 score 0.936 lr 5.97516e-06 
09/22/2020 09:22:31 - INFO - volta.utils -   [GQA]: iter 272462 Ep: 9.25 loss 0.343 score 0.948 lr 5.97478e-06 
09/22/2020 09:22:40 - INFO - volta.utils -   [GQA]: iter 272482 Ep: 9.25 loss 0.360 score 0.938 lr 5.9744e-06 
09/22/2020 09:22:49 - INFO - volta.utils -   [GQA]: iter 272502 Ep: 9.25 loss 0.499 score 0.923 lr 5.97403e-06 
09/22/2020 09:23:22 - INFO - volta.utils -   [GQA]: iter 272522 Ep: 9.25 loss 0.453 score 0.920 lr 5.97365e-06 
09/22/2020 09:23:30 - INFO - volta.utils -   [GQA]: iter 272542 Ep: 9.25 loss 0.438 score 0.927 lr 5.97327e-06 
09/22/2020 09:23:37 - INFO - volta.utils -   [GQA]: iter 272562 Ep: 9.25 loss 0.416 score 0.938 lr 5.9729e-06 
09/22/2020 09:23:56 - INFO - volta.utils -   [GQA]: iter 272582 Ep: 9.25 loss 0.390 score 0.931 lr 5.97252e-06 
09/22/2020 09:24:06 - INFO - volta.utils -   [GQA]: iter 272602 Ep: 9.25 loss 0.358 score 0.948 lr 5.97214e-06 
09/22/2020 09:24:15 - INFO - volta.utils -   [GQA]: iter 272622 Ep: 9.25 loss 0.439 score 0.925 lr 5.97177e-06 
09/22/2020 09:24:25 - INFO - volta.utils -   [GQA]: iter 272642 Ep: 9.25 loss 0.340 score 0.953 lr 5.97139e-06 
09/22/2020 09:24:39 - INFO - volta.utils -   [GQA]: iter 272662 Ep: 9.25 loss 0.338 score 0.945 lr 5.97101e-06 
09/22/2020 09:25:00 - INFO - volta.utils -   [GQA]: iter 272682 Ep: 9.25 loss 0.374 score 0.941 lr 5.97063e-06 
09/22/2020 09:25:22 - INFO - volta.utils -   [GQA]: iter 272702 Ep: 9.25 loss 0.385 score 0.931 lr 5.97026e-06 
09/22/2020 09:25:52 - INFO - volta.utils -   [GQA]: iter 272722 Ep: 9.25 loss 0.420 score 0.931 lr 5.96988e-06 
09/22/2020 09:26:06 - INFO - volta.utils -   [GQA]: iter 272742 Ep: 9.26 loss 0.344 score 0.944 lr 5.9695e-06 
09/22/2020 09:26:15 - INFO - volta.utils -   [GQA]: iter 272762 Ep: 9.26 loss 0.386 score 0.936 lr 5.96913e-06 
09/22/2020 09:26:23 - INFO - volta.utils -   [GQA]: iter 272782 Ep: 9.26 loss 0.399 score 0.942 lr 5.96875e-06 
09/22/2020 09:26:44 - INFO - volta.utils -   [GQA]: iter 272802 Ep: 9.26 loss 0.376 score 0.948 lr 5.96837e-06 
09/22/2020 09:27:02 - INFO - volta.utils -   [GQA]: iter 272822 Ep: 9.26 loss 0.373 score 0.947 lr 5.96799e-06 
09/22/2020 09:27:15 - INFO - volta.utils -   [GQA]: iter 272842 Ep: 9.26 loss 0.406 score 0.933 lr 5.96762e-06 
09/22/2020 09:27:31 - INFO - volta.utils -   [GQA]: iter 272862 Ep: 9.26 loss 0.375 score 0.942 lr 5.96724e-06 
09/22/2020 09:27:41 - INFO - volta.utils -   [GQA]: iter 272882 Ep: 9.26 loss 0.435 score 0.925 lr 5.96686e-06 
09/22/2020 09:27:48 - INFO - volta.utils -   [GQA]: iter 272902 Ep: 9.26 loss 0.375 score 0.947 lr 5.96649e-06 
09/22/2020 09:27:56 - INFO - volta.utils -   [GQA]: iter 272922 Ep: 9.26 loss 0.395 score 0.938 lr 5.96611e-06 
09/22/2020 09:28:06 - INFO - volta.utils -   [GQA]: iter 272942 Ep: 9.26 loss 0.421 score 0.931 lr 5.96573e-06 
09/22/2020 09:28:37 - INFO - volta.utils -   [GQA]: iter 272962 Ep: 9.26 loss 0.363 score 0.930 lr 5.96536e-06 
09/22/2020 09:28:53 - INFO - volta.utils -   [GQA]: iter 272982 Ep: 9.26 loss 0.317 score 0.947 lr 5.96498e-06 
09/22/2020 09:29:06 - INFO - volta.utils -   [GQA]: iter 273002 Ep: 9.26 loss 0.378 score 0.945 lr 5.9646e-06 
09/22/2020 09:29:14 - INFO - volta.utils -   [GQA]: iter 273022 Ep: 9.26 loss 0.401 score 0.931 lr 5.96422e-06 
09/22/2020 09:29:25 - INFO - volta.utils -   [GQA]: iter 273042 Ep: 9.27 loss 0.350 score 0.936 lr 5.96385e-06 
09/22/2020 09:29:35 - INFO - volta.utils -   [GQA]: iter 273062 Ep: 9.27 loss 0.394 score 0.936 lr 5.96347e-06 
09/22/2020 09:30:03 - INFO - volta.utils -   [GQA]: iter 273082 Ep: 9.27 loss 0.363 score 0.942 lr 5.96309e-06 
09/22/2020 09:30:16 - INFO - volta.utils -   [GQA]: iter 273102 Ep: 9.27 loss 0.460 score 0.938 lr 5.96272e-06 
09/22/2020 09:30:33 - INFO - volta.utils -   [GQA]: iter 273122 Ep: 9.27 loss 0.341 score 0.944 lr 5.96234e-06 
09/22/2020 09:30:44 - INFO - volta.utils -   [GQA]: iter 273142 Ep: 9.27 loss 0.459 score 0.931 lr 5.96196e-06 
09/22/2020 09:30:52 - INFO - volta.utils -   [GQA]: iter 273162 Ep: 9.27 loss 0.452 score 0.938 lr 5.96158e-06 
09/22/2020 09:31:01 - INFO - volta.utils -   [GQA]: iter 273182 Ep: 9.27 loss 0.375 score 0.939 lr 5.96121e-06 
09/22/2020 09:31:18 - INFO - volta.utils -   [GQA]: iter 273202 Ep: 9.27 loss 0.412 score 0.936 lr 5.96083e-06 
09/22/2020 09:31:35 - INFO - volta.utils -   [GQA]: iter 273222 Ep: 9.27 loss 0.473 score 0.923 lr 5.96045e-06 
09/22/2020 09:31:50 - INFO - volta.utils -   [GQA]: iter 273242 Ep: 9.27 loss 0.446 score 0.931 lr 5.96008e-06 
09/22/2020 09:32:05 - INFO - volta.utils -   [GQA]: iter 273262 Ep: 9.27 loss 0.418 score 0.941 lr 5.9597e-06 
09/22/2020 09:32:20 - INFO - volta.utils -   [GQA]: iter 273282 Ep: 9.27 loss 0.415 score 0.931 lr 5.95932e-06 
09/22/2020 09:32:31 - INFO - volta.utils -   [GQA]: iter 273302 Ep: 9.27 loss 0.267 score 0.972 lr 5.95895e-06 
09/22/2020 09:32:41 - INFO - volta.utils -   [GQA]: iter 273322 Ep: 9.27 loss 0.438 score 0.920 lr 5.95857e-06 
09/22/2020 09:32:59 - INFO - volta.utils -   [GQA]: iter 273342 Ep: 9.28 loss 0.381 score 0.933 lr 5.95819e-06 
09/22/2020 09:33:22 - INFO - volta.utils -   [GQA]: iter 273362 Ep: 9.28 loss 0.527 score 0.922 lr 5.95781e-06 
09/22/2020 09:33:36 - INFO - volta.utils -   [GQA]: iter 273382 Ep: 9.28 loss 0.401 score 0.933 lr 5.95744e-06 
09/22/2020 09:33:55 - INFO - volta.utils -   [GQA]: iter 273402 Ep: 9.28 loss 0.379 score 0.936 lr 5.95706e-06 
09/22/2020 09:34:06 - INFO - volta.utils -   [GQA]: iter 273422 Ep: 9.28 loss 0.329 score 0.950 lr 5.95668e-06 
09/22/2020 09:34:13 - INFO - volta.utils -   [GQA]: iter 273442 Ep: 9.28 loss 0.428 score 0.938 lr 5.95631e-06 
09/22/2020 09:34:21 - INFO - volta.utils -   [GQA]: iter 273462 Ep: 9.28 loss 0.457 score 0.928 lr 5.95593e-06 
09/22/2020 09:34:35 - INFO - volta.utils -   [GQA]: iter 273482 Ep: 9.28 loss 0.463 score 0.928 lr 5.95555e-06 
09/22/2020 09:34:59 - INFO - volta.utils -   [GQA]: iter 273502 Ep: 9.28 loss 0.392 score 0.948 lr 5.95518e-06 
09/22/2020 09:35:14 - INFO - volta.utils -   [GQA]: iter 273522 Ep: 9.28 loss 0.493 score 0.922 lr 5.9548e-06 
09/22/2020 09:35:29 - INFO - volta.utils -   [GQA]: iter 273542 Ep: 9.28 loss 0.388 score 0.939 lr 5.95442e-06 
09/22/2020 09:35:37 - INFO - volta.utils -   [GQA]: iter 273562 Ep: 9.28 loss 0.319 score 0.953 lr 5.95404e-06 
09/22/2020 09:35:45 - INFO - volta.utils -   [GQA]: iter 273582 Ep: 9.28 loss 0.449 score 0.919 lr 5.95367e-06 
09/22/2020 09:35:57 - INFO - volta.utils -   [GQA]: iter 273602 Ep: 9.28 loss 0.406 score 0.942 lr 5.95329e-06 
09/22/2020 09:36:27 - INFO - volta.utils -   [GQA]: iter 273622 Ep: 9.29 loss 0.331 score 0.953 lr 5.95291e-06 
09/22/2020 09:36:41 - INFO - volta.utils -   [GQA]: iter 273642 Ep: 9.29 loss 0.435 score 0.936 lr 5.95254e-06 
09/22/2020 09:37:01 - INFO - volta.utils -   [GQA]: iter 273662 Ep: 9.29 loss 0.410 score 0.933 lr 5.95216e-06 
09/22/2020 09:37:08 - INFO - volta.utils -   [GQA]: iter 273682 Ep: 9.29 loss 0.407 score 0.922 lr 5.95178e-06 
09/22/2020 09:37:19 - INFO - volta.utils -   [GQA]: iter 273702 Ep: 9.29 loss 0.349 score 0.952 lr 5.9514e-06 
09/22/2020 09:37:27 - INFO - volta.utils -   [GQA]: iter 273722 Ep: 9.29 loss 0.377 score 0.938 lr 5.95103e-06 
09/22/2020 09:37:42 - INFO - volta.utils -   [GQA]: iter 273742 Ep: 9.29 loss 0.370 score 0.945 lr 5.95065e-06 
09/22/2020 09:38:05 - INFO - volta.utils -   [GQA]: iter 273762 Ep: 9.29 loss 0.427 score 0.936 lr 5.95027e-06 
09/22/2020 09:38:23 - INFO - volta.utils -   [GQA]: iter 273782 Ep: 9.29 loss 0.306 score 0.955 lr 5.9499e-06 
09/22/2020 09:38:42 - INFO - volta.utils -   [GQA]: iter 273802 Ep: 9.29 loss 0.369 score 0.945 lr 5.94952e-06 
09/22/2020 09:38:50 - INFO - volta.utils -   [GQA]: iter 273822 Ep: 9.29 loss 0.374 score 0.939 lr 5.94914e-06 
09/22/2020 09:39:02 - INFO - volta.utils -   [GQA]: iter 273842 Ep: 9.29 loss 0.418 score 0.934 lr 5.94877e-06 
09/22/2020 09:39:23 - INFO - volta.utils -   [GQA]: iter 273862 Ep: 9.29 loss 0.486 score 0.922 lr 5.94839e-06 
09/22/2020 09:39:36 - INFO - volta.utils -   [GQA]: iter 273882 Ep: 9.29 loss 0.399 score 0.938 lr 5.94801e-06 
09/22/2020 09:39:51 - INFO - volta.utils -   [GQA]: iter 273902 Ep: 9.29 loss 0.489 score 0.925 lr 5.94763e-06 
09/22/2020 09:40:10 - INFO - volta.utils -   [GQA]: iter 273922 Ep: 9.30 loss 0.390 score 0.930 lr 5.94726e-06 
09/22/2020 09:40:24 - INFO - volta.utils -   [GQA]: iter 273942 Ep: 9.30 loss 0.418 score 0.927 lr 5.94688e-06 
09/22/2020 09:40:33 - INFO - volta.utils -   [GQA]: iter 273962 Ep: 9.30 loss 0.478 score 0.933 lr 5.9465e-06 
09/22/2020 09:40:51 - INFO - volta.utils -   [GQA]: iter 273982 Ep: 9.30 loss 0.341 score 0.947 lr 5.94613e-06 
09/22/2020 09:41:09 - INFO - volta.utils -   [GQA]: iter 274002 Ep: 9.30 loss 0.378 score 0.953 lr 5.94575e-06 
09/22/2020 09:41:34 - INFO - volta.utils -   [GQA]: iter 274022 Ep: 9.30 loss 0.437 score 0.931 lr 5.94537e-06 
09/22/2020 09:41:44 - INFO - volta.utils -   [GQA]: iter 274042 Ep: 9.30 loss 0.387 score 0.934 lr 5.94499e-06 
09/22/2020 09:41:55 - INFO - volta.utils -   [GQA]: iter 274062 Ep: 9.30 loss 0.324 score 0.950 lr 5.94462e-06 
09/22/2020 09:42:13 - INFO - volta.utils -   [GQA]: iter 274082 Ep: 9.30 loss 0.447 score 0.922 lr 5.94424e-06 
09/22/2020 09:42:20 - INFO - volta.utils -   [GQA]: iter 274102 Ep: 9.30 loss 0.371 score 0.945 lr 5.94386e-06 
09/22/2020 09:42:48 - INFO - volta.utils -   [GQA]: iter 274122 Ep: 9.30 loss 0.407 score 0.933 lr 5.94349e-06 
09/22/2020 09:42:59 - INFO - volta.utils -   [GQA]: iter 274142 Ep: 9.30 loss 0.341 score 0.950 lr 5.94311e-06 
09/22/2020 09:43:18 - INFO - volta.utils -   [GQA]: iter 274162 Ep: 9.30 loss 0.424 score 0.934 lr 5.94273e-06 
09/22/2020 09:43:32 - INFO - volta.utils -   [GQA]: iter 274182 Ep: 9.30 loss 0.335 score 0.953 lr 5.94236e-06 
09/22/2020 09:43:47 - INFO - volta.utils -   [GQA]: iter 274202 Ep: 9.30 loss 0.427 score 0.934 lr 5.94198e-06 
09/22/2020 09:44:12 - INFO - volta.utils -   [GQA]: iter 274222 Ep: 9.31 loss 0.377 score 0.947 lr 5.9416e-06 
09/22/2020 09:44:36 - INFO - volta.utils -   [GQA]: iter 274242 Ep: 9.31 loss 0.399 score 0.930 lr 5.94122e-06 
09/22/2020 09:44:49 - INFO - volta.utils -   [GQA]: iter 274262 Ep: 9.31 loss 0.321 score 0.964 lr 5.94085e-06 
09/22/2020 09:45:11 - INFO - volta.utils -   [GQA]: iter 274282 Ep: 9.31 loss 0.411 score 0.925 lr 5.94047e-06 
09/22/2020 09:45:18 - INFO - volta.utils -   [GQA]: iter 274302 Ep: 9.31 loss 0.397 score 0.945 lr 5.94009e-06 
09/22/2020 09:45:28 - INFO - volta.utils -   [GQA]: iter 274322 Ep: 9.31 loss 0.394 score 0.941 lr 5.93972e-06 
09/22/2020 09:45:39 - INFO - volta.utils -   [GQA]: iter 274342 Ep: 9.31 loss 0.337 score 0.947 lr 5.93934e-06 
09/22/2020 09:45:59 - INFO - volta.utils -   [GQA]: iter 274362 Ep: 9.31 loss 0.366 score 0.947 lr 5.93896e-06 
09/22/2020 09:46:17 - INFO - volta.utils -   [GQA]: iter 274382 Ep: 9.31 loss 0.391 score 0.938 lr 5.93859e-06 
09/22/2020 09:46:29 - INFO - volta.utils -   [GQA]: iter 274402 Ep: 9.31 loss 0.405 score 0.939 lr 5.93821e-06 
09/22/2020 09:46:42 - INFO - volta.utils -   [GQA]: iter 274422 Ep: 9.31 loss 0.477 score 0.936 lr 5.93783e-06 
09/22/2020 09:46:54 - INFO - volta.utils -   [GQA]: iter 274442 Ep: 9.31 loss 0.345 score 0.956 lr 5.93745e-06 
09/22/2020 09:47:12 - INFO - volta.utils -   [GQA]: iter 274462 Ep: 9.31 loss 0.413 score 0.934 lr 5.93708e-06 
09/22/2020 09:47:19 - INFO - volta.utils -   [GQA]: iter 274482 Ep: 9.31 loss 0.352 score 0.942 lr 5.9367e-06 
09/22/2020 09:47:50 - INFO - volta.utils -   [GQA]: iter 274502 Ep: 9.31 loss 0.382 score 0.934 lr 5.93632e-06 
09/22/2020 09:48:03 - INFO - volta.utils -   [GQA]: iter 274522 Ep: 9.32 loss 0.413 score 0.939 lr 5.93595e-06 
09/22/2020 09:48:20 - INFO - volta.utils -   [GQA]: iter 274542 Ep: 9.32 loss 0.408 score 0.934 lr 5.93557e-06 
09/22/2020 09:48:34 - INFO - volta.utils -   [GQA]: iter 274562 Ep: 9.32 loss 0.347 score 0.944 lr 5.93519e-06 
09/22/2020 09:48:41 - INFO - volta.utils -   [GQA]: iter 274582 Ep: 9.32 loss 0.403 score 0.941 lr 5.93481e-06 
09/22/2020 09:48:59 - INFO - volta.utils -   [GQA]: iter 274602 Ep: 9.32 loss 0.337 score 0.952 lr 5.93444e-06 
09/22/2020 09:49:16 - INFO - volta.utils -   [GQA]: iter 274622 Ep: 9.32 loss 0.442 score 0.927 lr 5.93406e-06 
09/22/2020 09:49:41 - INFO - volta.utils -   [GQA]: iter 274642 Ep: 9.32 loss 0.393 score 0.936 lr 5.93368e-06 
09/22/2020 09:49:50 - INFO - volta.utils -   [GQA]: iter 274662 Ep: 9.32 loss 0.360 score 0.950 lr 5.93331e-06 
09/22/2020 09:50:09 - INFO - volta.utils -   [GQA]: iter 274682 Ep: 9.32 loss 0.377 score 0.938 lr 5.93293e-06 
09/22/2020 09:50:18 - INFO - volta.utils -   [GQA]: iter 274702 Ep: 9.32 loss 0.340 score 0.947 lr 5.93255e-06 
09/22/2020 09:50:31 - INFO - volta.utils -   [GQA]: iter 274722 Ep: 9.32 loss 0.333 score 0.955 lr 5.93218e-06 
09/22/2020 09:50:48 - INFO - volta.utils -   [GQA]: iter 274742 Ep: 9.32 loss 0.382 score 0.934 lr 5.9318e-06 
09/22/2020 09:51:08 - INFO - volta.utils -   [GQA]: iter 274762 Ep: 9.32 loss 0.371 score 0.941 lr 5.93142e-06 
09/22/2020 09:51:22 - INFO - volta.utils -   [GQA]: iter 274782 Ep: 9.32 loss 0.447 score 0.923 lr 5.93104e-06 
09/22/2020 09:51:33 - INFO - volta.utils -   [GQA]: iter 274802 Ep: 9.33 loss 0.410 score 0.936 lr 5.93067e-06 
09/22/2020 09:51:41 - INFO - volta.utils -   [GQA]: iter 274822 Ep: 9.33 loss 0.385 score 0.938 lr 5.93029e-06 
09/22/2020 09:51:54 - INFO - volta.utils -   [GQA]: iter 274842 Ep: 9.33 loss 0.412 score 0.934 lr 5.92991e-06 
09/22/2020 09:52:16 - INFO - volta.utils -   [GQA]: iter 274862 Ep: 9.33 loss 0.412 score 0.928 lr 5.92954e-06 
09/22/2020 09:52:28 - INFO - volta.utils -   [GQA]: iter 274882 Ep: 9.33 loss 0.412 score 0.931 lr 5.92916e-06 
09/22/2020 09:52:46 - INFO - volta.utils -   [GQA]: iter 274902 Ep: 9.33 loss 0.300 score 0.952 lr 5.92878e-06 
09/22/2020 09:53:02 - INFO - volta.utils -   [GQA]: iter 274922 Ep: 9.33 loss 0.368 score 0.945 lr 5.9284e-06 
09/22/2020 09:53:12 - INFO - volta.utils -   [GQA]: iter 274942 Ep: 9.33 loss 0.450 score 0.931 lr 5.92803e-06 
09/22/2020 09:53:20 - INFO - volta.utils -   [GQA]: iter 274962 Ep: 9.33 loss 0.378 score 0.941 lr 5.92765e-06 
09/22/2020 09:53:30 - INFO - volta.utils -   [GQA]: iter 274982 Ep: 9.33 loss 0.497 score 0.914 lr 5.92727e-06 
09/22/2020 09:53:39 - INFO - volta.utils -   [GQA]: iter 275002 Ep: 9.33 loss 0.384 score 0.945 lr 5.9269e-06 
09/22/2020 09:53:53 - INFO - volta.utils -   [GQA]: iter 275022 Ep: 9.33 loss 0.429 score 0.936 lr 5.92652e-06 
09/22/2020 09:54:14 - INFO - volta.utils -   [GQA]: iter 275042 Ep: 9.33 loss 0.416 score 0.933 lr 5.92614e-06 
09/22/2020 09:54:36 - INFO - volta.utils -   [GQA]: iter 275062 Ep: 9.33 loss 0.295 score 0.961 lr 5.92577e-06 
09/22/2020 09:54:45 - INFO - volta.utils -   [GQA]: iter 275082 Ep: 9.33 loss 0.413 score 0.930 lr 5.92539e-06 
09/22/2020 09:55:01 - INFO - volta.utils -   [GQA]: iter 275102 Ep: 9.34 loss 0.347 score 0.950 lr 5.92501e-06 
09/22/2020 09:55:13 - INFO - volta.utils -   [GQA]: iter 275122 Ep: 9.34 loss 0.437 score 0.928 lr 5.92463e-06 
09/22/2020 09:55:27 - INFO - volta.utils -   [GQA]: iter 275142 Ep: 9.34 loss 0.304 score 0.959 lr 5.92426e-06 
09/22/2020 09:55:45 - INFO - volta.utils -   [GQA]: iter 275162 Ep: 9.34 loss 0.392 score 0.939 lr 5.92388e-06 
09/22/2020 09:56:00 - INFO - volta.utils -   [GQA]: iter 275182 Ep: 9.34 loss 0.407 score 0.936 lr 5.9235e-06 
09/22/2020 09:56:18 - INFO - volta.utils -   [GQA]: iter 275202 Ep: 9.34 loss 0.339 score 0.947 lr 5.92313e-06 
09/22/2020 09:56:28 - INFO - volta.utils -   [GQA]: iter 275222 Ep: 9.34 loss 0.403 score 0.927 lr 5.92275e-06 
09/22/2020 09:56:40 - INFO - volta.utils -   [GQA]: iter 275242 Ep: 9.34 loss 0.442 score 0.927 lr 5.92237e-06 
09/22/2020 09:56:51 - INFO - volta.utils -   [GQA]: iter 275262 Ep: 9.34 loss 0.322 score 0.952 lr 5.922e-06 
09/22/2020 09:57:14 - INFO - volta.utils -   [GQA]: iter 275282 Ep: 9.34 loss 0.365 score 0.939 lr 5.92162e-06 
09/22/2020 09:57:39 - INFO - volta.utils -   [GQA]: iter 275302 Ep: 9.34 loss 0.317 score 0.948 lr 5.92124e-06 
09/22/2020 09:57:53 - INFO - volta.utils -   [GQA]: iter 275322 Ep: 9.34 loss 0.389 score 0.933 lr 5.92086e-06 
09/22/2020 09:58:13 - INFO - volta.utils -   [GQA]: iter 275342 Ep: 9.34 loss 0.358 score 0.958 lr 5.92049e-06 
09/22/2020 09:58:20 - INFO - volta.utils -   [GQA]: iter 275362 Ep: 9.34 loss 0.440 score 0.931 lr 5.92011e-06 
09/22/2020 09:58:32 - INFO - volta.utils -   [GQA]: iter 275382 Ep: 9.34 loss 0.416 score 0.931 lr 5.91973e-06 
09/22/2020 09:58:54 - INFO - volta.utils -   [GQA]: iter 275402 Ep: 9.35 loss 0.473 score 0.931 lr 5.91936e-06 
09/22/2020 09:59:12 - INFO - volta.utils -   [GQA]: iter 275422 Ep: 9.35 loss 0.370 score 0.945 lr 5.91898e-06 
09/22/2020 09:59:28 - INFO - volta.utils -   [GQA]: iter 275442 Ep: 9.35 loss 0.433 score 0.936 lr 5.9186e-06 
09/22/2020 09:59:40 - INFO - volta.utils -   [GQA]: iter 275462 Ep: 9.35 loss 0.471 score 0.922 lr 5.91822e-06 
09/22/2020 09:59:48 - INFO - volta.utils -   [GQA]: iter 275482 Ep: 9.35 loss 0.332 score 0.944 lr 5.91785e-06 
09/22/2020 09:59:59 - INFO - volta.utils -   [GQA]: iter 275502 Ep: 9.35 loss 0.345 score 0.950 lr 5.91747e-06 
09/22/2020 10:00:15 - INFO - volta.utils -   [GQA]: iter 275522 Ep: 9.35 loss 0.408 score 0.930 lr 5.91709e-06 
09/22/2020 10:00:40 - INFO - volta.utils -   [GQA]: iter 275542 Ep: 9.35 loss 0.424 score 0.922 lr 5.91672e-06 
09/22/2020 10:01:01 - INFO - volta.utils -   [GQA]: iter 275562 Ep: 9.35 loss 0.450 score 0.934 lr 5.91634e-06 
09/22/2020 10:01:13 - INFO - volta.utils -   [GQA]: iter 275582 Ep: 9.35 loss 0.400 score 0.934 lr 5.91596e-06 
09/22/2020 10:01:36 - INFO - volta.utils -   [GQA]: iter 275602 Ep: 9.35 loss 0.341 score 0.950 lr 5.91559e-06 
09/22/2020 10:01:49 - INFO - volta.utils -   [GQA]: iter 275622 Ep: 9.35 loss 0.410 score 0.933 lr 5.91521e-06 
09/22/2020 10:02:01 - INFO - volta.utils -   [GQA]: iter 275642 Ep: 9.35 loss 0.367 score 0.948 lr 5.91483e-06 
09/22/2020 10:02:09 - INFO - volta.utils -   [GQA]: iter 275662 Ep: 9.35 loss 0.380 score 0.942 lr 5.91445e-06 
09/22/2020 10:02:18 - INFO - volta.utils -   [GQA]: iter 275682 Ep: 9.35 loss 0.342 score 0.945 lr 5.91408e-06 
09/22/2020 10:02:28 - INFO - volta.utils -   [GQA]: iter 275702 Ep: 9.36 loss 0.385 score 0.938 lr 5.9137e-06 
09/22/2020 10:02:51 - INFO - volta.utils -   [GQA]: iter 275722 Ep: 9.36 loss 0.355 score 0.948 lr 5.91332e-06 
09/22/2020 10:03:09 - INFO - volta.utils -   [GQA]: iter 275742 Ep: 9.36 loss 0.493 score 0.931 lr 5.91295e-06 
09/22/2020 10:03:33 - INFO - volta.utils -   [GQA]: iter 275762 Ep: 9.36 loss 0.412 score 0.941 lr 5.91257e-06 
09/22/2020 10:03:40 - INFO - volta.utils -   [GQA]: iter 275782 Ep: 9.36 loss 0.360 score 0.941 lr 5.91219e-06 
09/22/2020 10:03:51 - INFO - volta.utils -   [GQA]: iter 275802 Ep: 9.36 loss 0.341 score 0.947 lr 5.91182e-06 
09/22/2020 10:04:00 - INFO - volta.utils -   [GQA]: iter 275822 Ep: 9.36 loss 0.311 score 0.963 lr 5.91144e-06 
09/22/2020 10:04:14 - INFO - volta.utils -   [GQA]: iter 275842 Ep: 9.36 loss 0.379 score 0.941 lr 5.91106e-06 
09/22/2020 10:04:32 - INFO - volta.utils -   [GQA]: iter 275862 Ep: 9.36 loss 0.409 score 0.930 lr 5.91068e-06 
09/22/2020 10:04:56 - INFO - volta.utils -   [GQA]: iter 275882 Ep: 9.36 loss 0.338 score 0.948 lr 5.91031e-06 
09/22/2020 10:05:08 - INFO - volta.utils -   [GQA]: iter 275902 Ep: 9.36 loss 0.360 score 0.947 lr 5.90993e-06 
09/22/2020 10:05:18 - INFO - volta.utils -   [GQA]: iter 275922 Ep: 9.36 loss 0.425 score 0.927 lr 5.90955e-06 
09/22/2020 10:05:26 - INFO - volta.utils -   [GQA]: iter 275942 Ep: 9.36 loss 0.383 score 0.933 lr 5.90918e-06 
09/22/2020 10:05:40 - INFO - volta.utils -   [GQA]: iter 275962 Ep: 9.36 loss 0.358 score 0.942 lr 5.9088e-06 
09/22/2020 10:05:53 - INFO - volta.utils -   [GQA]: iter 275982 Ep: 9.37 loss 0.357 score 0.936 lr 5.90842e-06 
09/22/2020 10:06:10 - INFO - volta.utils -   [GQA]: iter 276002 Ep: 9.37 loss 0.398 score 0.936 lr 5.90804e-06 
09/22/2020 10:06:24 - INFO - volta.utils -   [GQA]: iter 276022 Ep: 9.37 loss 0.350 score 0.952 lr 5.90767e-06 
09/22/2020 10:06:35 - INFO - volta.utils -   [GQA]: iter 276042 Ep: 9.37 loss 0.439 score 0.928 lr 5.90729e-06 
09/22/2020 10:06:45 - INFO - volta.utils -   [GQA]: iter 276062 Ep: 9.37 loss 0.362 score 0.944 lr 5.90691e-06 
09/22/2020 10:06:53 - INFO - volta.utils -   [GQA]: iter 276082 Ep: 9.37 loss 0.345 score 0.944 lr 5.90654e-06 
09/22/2020 10:07:03 - INFO - volta.utils -   [GQA]: iter 276102 Ep: 9.37 loss 0.397 score 0.925 lr 5.90616e-06 
09/22/2020 10:07:14 - INFO - volta.utils -   [GQA]: iter 276122 Ep: 9.37 loss 0.332 score 0.948 lr 5.90578e-06 
09/22/2020 10:07:40 - INFO - volta.utils -   [GQA]: iter 276142 Ep: 9.37 loss 0.423 score 0.928 lr 5.90541e-06 
09/22/2020 10:08:00 - INFO - volta.utils -   [GQA]: iter 276162 Ep: 9.37 loss 0.399 score 0.933 lr 5.90503e-06 
09/22/2020 10:08:25 - INFO - volta.utils -   [GQA]: iter 276182 Ep: 9.37 loss 0.418 score 0.941 lr 5.90465e-06 
09/22/2020 10:08:32 - INFO - volta.utils -   [GQA]: iter 276202 Ep: 9.37 loss 0.351 score 0.945 lr 5.90427e-06 
09/22/2020 10:08:48 - INFO - volta.utils -   [GQA]: iter 276222 Ep: 9.37 loss 0.379 score 0.939 lr 5.9039e-06 
09/22/2020 10:08:59 - INFO - volta.utils -   [GQA]: iter 276242 Ep: 9.37 loss 0.379 score 0.938 lr 5.90352e-06 
09/22/2020 10:09:06 - INFO - volta.utils -   [GQA]: iter 276262 Ep: 9.37 loss 0.378 score 0.942 lr 5.90314e-06 
09/22/2020 10:09:13 - INFO - volta.utils -   [GQA]: iter 276282 Ep: 9.38 loss 0.358 score 0.939 lr 5.90277e-06 
09/22/2020 10:09:30 - INFO - volta.utils -   [GQA]: iter 276302 Ep: 9.38 loss 0.487 score 0.911 lr 5.90239e-06 
09/22/2020 10:09:44 - INFO - volta.utils -   [GQA]: iter 276322 Ep: 9.38 loss 0.379 score 0.950 lr 5.90201e-06 
09/22/2020 10:09:58 - INFO - volta.utils -   [GQA]: iter 276342 Ep: 9.38 loss 0.399 score 0.934 lr 5.90163e-06 
09/22/2020 10:10:06 - INFO - volta.utils -   [GQA]: iter 276362 Ep: 9.38 loss 0.478 score 0.911 lr 5.90126e-06 
09/22/2020 10:10:24 - INFO - volta.utils -   [GQA]: iter 276382 Ep: 9.38 loss 0.424 score 0.931 lr 5.90088e-06 
09/22/2020 10:10:43 - INFO - volta.utils -   [GQA]: iter 276402 Ep: 9.38 loss 0.399 score 0.928 lr 5.9005e-06 
09/22/2020 10:11:05 - INFO - volta.utils -   [GQA]: iter 276422 Ep: 9.38 loss 0.436 score 0.933 lr 5.90013e-06 
09/22/2020 10:11:20 - INFO - volta.utils -   [GQA]: iter 276442 Ep: 9.38 loss 0.383 score 0.939 lr 5.89975e-06 
09/22/2020 10:11:34 - INFO - volta.utils -   [GQA]: iter 276462 Ep: 9.38 loss 0.345 score 0.945 lr 5.89937e-06 
09/22/2020 10:11:42 - INFO - volta.utils -   [GQA]: iter 276482 Ep: 9.38 loss 0.337 score 0.964 lr 5.899e-06 
09/22/2020 10:11:52 - INFO - volta.utils -   [GQA]: iter 276502 Ep: 9.38 loss 0.364 score 0.945 lr 5.89862e-06 
09/22/2020 10:12:09 - INFO - volta.utils -   [GQA]: iter 276522 Ep: 9.38 loss 0.467 score 0.928 lr 5.89824e-06 
09/22/2020 10:12:21 - INFO - volta.utils -   [GQA]: iter 276542 Ep: 9.38 loss 0.453 score 0.914 lr 5.89786e-06 
09/22/2020 10:12:33 - INFO - volta.utils -   [GQA]: iter 276562 Ep: 9.38 loss 0.314 score 0.950 lr 5.89749e-06 
09/22/2020 10:12:40 - INFO - volta.utils -   [GQA]: iter 276582 Ep: 9.39 loss 0.422 score 0.933 lr 5.89711e-06 
09/22/2020 10:13:01 - INFO - volta.utils -   [GQA]: iter 276602 Ep: 9.39 loss 0.391 score 0.930 lr 5.89673e-06 
09/22/2020 10:13:10 - INFO - volta.utils -   [GQA]: iter 276622 Ep: 9.39 loss 0.360 score 0.941 lr 5.89636e-06 
09/22/2020 10:13:32 - INFO - volta.utils -   [GQA]: iter 276642 Ep: 9.39 loss 0.303 score 0.956 lr 5.89598e-06 
09/22/2020 10:13:47 - INFO - volta.utils -   [GQA]: iter 276662 Ep: 9.39 loss 0.333 score 0.944 lr 5.8956e-06 
09/22/2020 10:14:01 - INFO - volta.utils -   [GQA]: iter 276682 Ep: 9.39 loss 0.456 score 0.928 lr 5.89523e-06 
09/22/2020 10:14:11 - INFO - volta.utils -   [GQA]: iter 276702 Ep: 9.39 loss 0.357 score 0.938 lr 5.89485e-06 
09/22/2020 10:14:20 - INFO - volta.utils -   [GQA]: iter 276722 Ep: 9.39 loss 0.534 score 0.920 lr 5.89447e-06 
09/22/2020 10:14:33 - INFO - volta.utils -   [GQA]: iter 276742 Ep: 9.39 loss 0.467 score 0.923 lr 5.89409e-06 
09/22/2020 10:14:40 - INFO - volta.utils -   [GQA]: iter 276762 Ep: 9.39 loss 0.338 score 0.947 lr 5.89372e-06 
09/22/2020 10:14:52 - INFO - volta.utils -   [GQA]: iter 276782 Ep: 9.39 loss 0.461 score 0.916 lr 5.89334e-06 
09/22/2020 10:15:14 - INFO - volta.utils -   [GQA]: iter 276802 Ep: 9.39 loss 0.399 score 0.931 lr 5.89296e-06 
09/22/2020 10:15:29 - INFO - volta.utils -   [GQA]: iter 276822 Ep: 9.39 loss 0.325 score 0.945 lr 5.89259e-06 
09/22/2020 10:15:44 - INFO - volta.utils -   [GQA]: iter 276842 Ep: 9.39 loss 0.388 score 0.934 lr 5.89221e-06 
09/22/2020 10:15:57 - INFO - volta.utils -   [GQA]: iter 276862 Ep: 9.40 loss 0.376 score 0.931 lr 5.89183e-06 
09/22/2020 10:16:12 - INFO - volta.utils -   [GQA]: iter 276882 Ep: 9.40 loss 0.389 score 0.934 lr 5.89145e-06 
09/22/2020 10:16:20 - INFO - volta.utils -   [GQA]: iter 276902 Ep: 9.40 loss 0.408 score 0.930 lr 5.89108e-06 
09/22/2020 10:16:38 - INFO - volta.utils -   [GQA]: iter 276922 Ep: 9.40 loss 0.359 score 0.947 lr 5.8907e-06 
09/22/2020 10:16:48 - INFO - volta.utils -   [GQA]: iter 276942 Ep: 9.40 loss 0.413 score 0.934 lr 5.89032e-06 
09/22/2020 10:17:04 - INFO - volta.utils -   [GQA]: iter 276962 Ep: 9.40 loss 0.321 score 0.953 lr 5.88995e-06 
09/22/2020 10:17:14 - INFO - volta.utils -   [GQA]: iter 276982 Ep: 9.40 loss 0.516 score 0.925 lr 5.88957e-06 
09/22/2020 10:17:22 - INFO - volta.utils -   [GQA]: iter 277002 Ep: 9.40 loss 0.460 score 0.923 lr 5.88919e-06 
09/22/2020 10:17:40 - INFO - volta.utils -   [GQA]: iter 277022 Ep: 9.40 loss 0.352 score 0.934 lr 5.88882e-06 
09/22/2020 10:18:11 - INFO - volta.utils -   [GQA]: iter 277042 Ep: 9.40 loss 0.350 score 0.955 lr 5.88844e-06 
09/22/2020 10:18:25 - INFO - volta.utils -   [GQA]: iter 277062 Ep: 9.40 loss 0.361 score 0.939 lr 5.88806e-06 
09/22/2020 10:18:39 - INFO - volta.utils -   [GQA]: iter 277082 Ep: 9.40 loss 0.315 score 0.948 lr 5.88768e-06 
09/22/2020 10:18:56 - INFO - volta.utils -   [GQA]: iter 277102 Ep: 9.40 loss 0.480 score 0.920 lr 5.88731e-06 
09/22/2020 10:19:09 - INFO - volta.utils -   [GQA]: iter 277122 Ep: 9.40 loss 0.424 score 0.934 lr 5.88693e-06 
09/22/2020 10:19:24 - INFO - volta.utils -   [GQA]: iter 277142 Ep: 9.40 loss 0.465 score 0.931 lr 5.88655e-06 
09/22/2020 10:19:38 - INFO - volta.utils -   [GQA]: iter 277162 Ep: 9.41 loss 0.462 score 0.923 lr 5.88618e-06 
09/22/2020 10:19:48 - INFO - volta.utils -   [GQA]: iter 277182 Ep: 9.41 loss 0.376 score 0.939 lr 5.8858e-06 
09/22/2020 10:20:00 - INFO - volta.utils -   [GQA]: iter 277202 Ep: 9.41 loss 0.442 score 0.922 lr 5.88542e-06 
09/22/2020 10:20:08 - INFO - volta.utils -   [GQA]: iter 277222 Ep: 9.41 loss 0.391 score 0.933 lr 5.88504e-06 
09/22/2020 10:20:15 - INFO - volta.utils -   [GQA]: iter 277242 Ep: 9.41 loss 0.349 score 0.945 lr 5.88467e-06 
09/22/2020 10:20:31 - INFO - volta.utils -   [GQA]: iter 277262 Ep: 9.41 loss 0.415 score 0.923 lr 5.88429e-06 
09/22/2020 10:20:51 - INFO - volta.utils -   [GQA]: iter 277282 Ep: 9.41 loss 0.326 score 0.952 lr 5.88391e-06 
09/22/2020 10:21:03 - INFO - volta.utils -   [GQA]: iter 277302 Ep: 9.41 loss 0.463 score 0.936 lr 5.88354e-06 
09/22/2020 10:21:19 - INFO - volta.utils -   [GQA]: iter 277322 Ep: 9.41 loss 0.419 score 0.939 lr 5.88316e-06 
09/22/2020 10:21:39 - INFO - volta.utils -   [GQA]: iter 277342 Ep: 9.41 loss 0.363 score 0.939 lr 5.88278e-06 
09/22/2020 10:22:02 - INFO - volta.utils -   [GQA]: iter 277362 Ep: 9.41 loss 0.441 score 0.916 lr 5.88241e-06 
09/22/2020 10:22:16 - INFO - volta.utils -   [GQA]: iter 277382 Ep: 9.41 loss 0.482 score 0.903 lr 5.88203e-06 
09/22/2020 10:22:32 - INFO - volta.utils -   [GQA]: iter 277402 Ep: 9.41 loss 0.425 score 0.942 lr 5.88165e-06 
09/22/2020 10:22:45 - INFO - volta.utils -   [GQA]: iter 277422 Ep: 9.41 loss 0.430 score 0.941 lr 5.88127e-06 
09/22/2020 10:23:02 - INFO - volta.utils -   [GQA]: iter 277442 Ep: 9.41 loss 0.386 score 0.942 lr 5.8809e-06 
09/22/2020 10:23:23 - INFO - volta.utils -   [GQA]: iter 277462 Ep: 9.42 loss 0.372 score 0.931 lr 5.88052e-06 
09/22/2020 10:23:32 - INFO - volta.utils -   [GQA]: iter 277482 Ep: 9.42 loss 0.328 score 0.952 lr 5.88014e-06 
09/22/2020 10:23:46 - INFO - volta.utils -   [GQA]: iter 277502 Ep: 9.42 loss 0.361 score 0.945 lr 5.87977e-06 
09/22/2020 10:24:06 - INFO - volta.utils -   [GQA]: iter 277522 Ep: 9.42 loss 0.444 score 0.936 lr 5.87939e-06 
09/22/2020 10:24:14 - INFO - volta.utils -   [GQA]: iter 277542 Ep: 9.42 loss 0.486 score 0.920 lr 5.87901e-06 
09/22/2020 10:24:34 - INFO - volta.utils -   [GQA]: iter 277562 Ep: 9.42 loss 0.328 score 0.947 lr 5.87864e-06 
09/22/2020 10:24:45 - INFO - volta.utils -   [GQA]: iter 277582 Ep: 9.42 loss 0.385 score 0.945 lr 5.87826e-06 
09/22/2020 10:24:59 - INFO - volta.utils -   [GQA]: iter 277602 Ep: 9.42 loss 0.434 score 0.914 lr 5.87788e-06 
09/22/2020 10:25:17 - INFO - volta.utils -   [GQA]: iter 277622 Ep: 9.42 loss 0.429 score 0.936 lr 5.8775e-06 
09/22/2020 10:25:28 - INFO - volta.utils -   [GQA]: iter 277642 Ep: 9.42 loss 0.366 score 0.948 lr 5.87713e-06 
09/22/2020 10:25:44 - INFO - volta.utils -   [GQA]: iter 277662 Ep: 9.42 loss 0.314 score 0.947 lr 5.87675e-06 
09/22/2020 10:25:59 - INFO - volta.utils -   [GQA]: iter 277682 Ep: 9.42 loss 0.400 score 0.944 lr 5.87637e-06 
09/22/2020 10:26:13 - INFO - volta.utils -   [GQA]: iter 277702 Ep: 9.42 loss 0.370 score 0.944 lr 5.876e-06 
09/22/2020 10:26:34 - INFO - volta.utils -   [GQA]: iter 277722 Ep: 9.42 loss 0.418 score 0.939 lr 5.87562e-06 
09/22/2020 10:26:45 - INFO - volta.utils -   [GQA]: iter 277742 Ep: 9.42 loss 0.304 score 0.956 lr 5.87524e-06 
09/22/2020 10:26:52 - INFO - volta.utils -   [GQA]: iter 277762 Ep: 9.43 loss 0.365 score 0.941 lr 5.87486e-06 
09/22/2020 10:27:01 - INFO - volta.utils -   [GQA]: iter 277782 Ep: 9.43 loss 0.321 score 0.953 lr 5.87449e-06 
09/22/2020 10:27:16 - INFO - volta.utils -   [GQA]: iter 277802 Ep: 9.43 loss 0.355 score 0.942 lr 5.87411e-06 
09/22/2020 10:27:38 - INFO - volta.utils -   [GQA]: iter 277822 Ep: 9.43 loss 0.427 score 0.933 lr 5.87373e-06 
09/22/2020 10:27:46 - INFO - volta.utils -   [GQA]: iter 277842 Ep: 9.43 loss 0.462 score 0.911 lr 5.87336e-06 
09/22/2020 10:27:54 - INFO - volta.utils -   [GQA]: iter 277862 Ep: 9.43 loss 0.339 score 0.948 lr 5.87298e-06 
09/22/2020 10:28:02 - INFO - volta.utils -   [GQA]: iter 277882 Ep: 9.43 loss 0.372 score 0.941 lr 5.8726e-06 
09/22/2020 10:28:25 - INFO - volta.utils -   [GQA]: iter 277902 Ep: 9.43 loss 0.283 score 0.958 lr 5.87223e-06 
09/22/2020 10:28:52 - INFO - volta.utils -   [GQA]: iter 277922 Ep: 9.43 loss 0.363 score 0.938 lr 5.87185e-06 
09/22/2020 10:29:00 - INFO - volta.utils -   [GQA]: iter 277942 Ep: 9.43 loss 0.359 score 0.939 lr 5.87147e-06 
09/22/2020 10:29:14 - INFO - volta.utils -   [GQA]: iter 277962 Ep: 9.43 loss 0.372 score 0.939 lr 5.87109e-06 
09/22/2020 10:29:21 - INFO - volta.utils -   [GQA]: iter 277982 Ep: 9.43 loss 0.394 score 0.938 lr 5.87072e-06 
09/22/2020 10:29:29 - INFO - volta.utils -   [GQA]: iter 278002 Ep: 9.43 loss 0.356 score 0.944 lr 5.87034e-06 
09/22/2020 10:29:45 - INFO - volta.utils -   [GQA]: iter 278022 Ep: 9.43 loss 0.331 score 0.944 lr 5.86996e-06 
09/22/2020 10:29:58 - INFO - volta.utils -   [GQA]: iter 278042 Ep: 9.44 loss 0.422 score 0.934 lr 5.86959e-06 
09/22/2020 10:30:12 - INFO - volta.utils -   [GQA]: iter 278062 Ep: 9.44 loss 0.364 score 0.944 lr 5.86921e-06 
09/22/2020 10:30:20 - INFO - volta.utils -   [GQA]: iter 278082 Ep: 9.44 loss 0.392 score 0.933 lr 5.86883e-06 
09/22/2020 10:30:29 - INFO - volta.utils -   [GQA]: iter 278102 Ep: 9.44 loss 0.426 score 0.942 lr 5.86845e-06 
09/22/2020 10:31:00 - INFO - volta.utils -   [GQA]: iter 278122 Ep: 9.44 loss 0.331 score 0.947 lr 5.86808e-06 
09/22/2020 10:31:15 - INFO - volta.utils -   [GQA]: iter 278142 Ep: 9.44 loss 0.464 score 0.928 lr 5.8677e-06 
09/22/2020 10:31:28 - INFO - volta.utils -   [GQA]: iter 278162 Ep: 9.44 loss 0.417 score 0.939 lr 5.86732e-06 
09/22/2020 10:31:37 - INFO - volta.utils -   [GQA]: iter 278182 Ep: 9.44 loss 0.384 score 0.947 lr 5.86695e-06 
09/22/2020 10:31:48 - INFO - volta.utils -   [GQA]: iter 278202 Ep: 9.44 loss 0.479 score 0.914 lr 5.86657e-06 
09/22/2020 10:32:01 - INFO - volta.utils -   [GQA]: iter 278222 Ep: 9.44 loss 0.354 score 0.952 lr 5.86619e-06 
09/22/2020 10:32:13 - INFO - volta.utils -   [GQA]: iter 278242 Ep: 9.44 loss 0.470 score 0.920 lr 5.86582e-06 
09/22/2020 10:32:22 - INFO - volta.utils -   [GQA]: iter 278262 Ep: 9.44 loss 0.432 score 0.920 lr 5.86544e-06 
09/22/2020 10:32:34 - INFO - volta.utils -   [GQA]: iter 278282 Ep: 9.44 loss 0.431 score 0.934 lr 5.86506e-06 
09/22/2020 10:32:55 - INFO - volta.utils -   [GQA]: iter 278302 Ep: 9.44 loss 0.446 score 0.925 lr 5.86468e-06 
09/22/2020 10:33:17 - INFO - volta.utils -   [GQA]: iter 278322 Ep: 9.44 loss 0.428 score 0.930 lr 5.86431e-06 
09/22/2020 10:33:30 - INFO - volta.utils -   [GQA]: iter 278342 Ep: 9.45 loss 0.513 score 0.927 lr 5.86393e-06 
09/22/2020 10:33:53 - INFO - volta.utils -   [GQA]: iter 278362 Ep: 9.45 loss 0.359 score 0.947 lr 5.86355e-06 
09/22/2020 10:34:01 - INFO - volta.utils -   [GQA]: iter 278382 Ep: 9.45 loss 0.315 score 0.948 lr 5.86318e-06 
09/22/2020 10:34:11 - INFO - volta.utils -   [GQA]: iter 278402 Ep: 9.45 loss 0.361 score 0.948 lr 5.8628e-06 
09/22/2020 10:34:33 - INFO - volta.utils -   [GQA]: iter 278422 Ep: 9.45 loss 0.355 score 0.945 lr 5.86242e-06 
09/22/2020 10:34:54 - INFO - volta.utils -   [GQA]: iter 278442 Ep: 9.45 loss 0.413 score 0.931 lr 5.86205e-06 
09/22/2020 10:35:10 - INFO - volta.utils -   [GQA]: iter 278462 Ep: 9.45 loss 0.385 score 0.945 lr 5.86167e-06 
09/22/2020 10:35:23 - INFO - volta.utils -   [GQA]: iter 278482 Ep: 9.45 loss 0.442 score 0.925 lr 5.86129e-06 
09/22/2020 10:35:32 - INFO - volta.utils -   [GQA]: iter 278502 Ep: 9.45 loss 0.407 score 0.928 lr 5.86091e-06 
09/22/2020 10:35:46 - INFO - volta.utils -   [GQA]: iter 278522 Ep: 9.45 loss 0.470 score 0.920 lr 5.86054e-06 
09/22/2020 10:36:07 - INFO - volta.utils -   [GQA]: iter 278542 Ep: 9.45 loss 0.430 score 0.925 lr 5.86016e-06 
09/22/2020 10:36:16 - INFO - volta.utils -   [GQA]: iter 278562 Ep: 9.45 loss 0.431 score 0.927 lr 5.85978e-06 
09/22/2020 10:36:24 - INFO - volta.utils -   [GQA]: iter 278582 Ep: 9.45 loss 0.365 score 0.936 lr 5.85941e-06 
09/22/2020 10:36:32 - INFO - volta.utils -   [GQA]: iter 278602 Ep: 9.45 loss 0.416 score 0.934 lr 5.85903e-06 
09/22/2020 10:37:01 - INFO - volta.utils -   [GQA]: iter 278622 Ep: 9.45 loss 0.420 score 0.934 lr 5.85865e-06 
09/22/2020 10:37:27 - INFO - volta.utils -   [GQA]: iter 278642 Ep: 9.46 loss 0.318 score 0.950 lr 5.85827e-06 
09/22/2020 10:37:35 - INFO - volta.utils -   [GQA]: iter 278662 Ep: 9.46 loss 0.448 score 0.927 lr 5.8579e-06 
09/22/2020 10:37:46 - INFO - volta.utils -   [GQA]: iter 278682 Ep: 9.46 loss 0.404 score 0.939 lr 5.85752e-06 
09/22/2020 10:37:58 - INFO - volta.utils -   [GQA]: iter 278702 Ep: 9.46 loss 0.387 score 0.941 lr 5.85714e-06 
09/22/2020 10:38:07 - INFO - volta.utils -   [GQA]: iter 278722 Ep: 9.46 loss 0.403 score 0.933 lr 5.85677e-06 
09/22/2020 10:38:20 - INFO - volta.utils -   [GQA]: iter 278742 Ep: 9.46 loss 0.411 score 0.934 lr 5.85639e-06 
09/22/2020 10:38:29 - INFO - volta.utils -   [GQA]: iter 278762 Ep: 9.46 loss 0.423 score 0.941 lr 5.85601e-06 
09/22/2020 10:38:37 - INFO - volta.utils -   [GQA]: iter 278782 Ep: 9.46 loss 0.360 score 0.947 lr 5.85564e-06 
09/22/2020 10:38:49 - INFO - volta.utils -   [GQA]: iter 278802 Ep: 9.46 loss 0.380 score 0.941 lr 5.85526e-06 
09/22/2020 10:39:08 - INFO - volta.utils -   [GQA]: iter 278822 Ep: 9.46 loss 0.381 score 0.947 lr 5.85488e-06 
09/22/2020 10:39:26 - INFO - volta.utils -   [GQA]: iter 278842 Ep: 9.46 loss 0.331 score 0.945 lr 5.8545e-06 
09/22/2020 10:39:43 - INFO - volta.utils -   [GQA]: iter 278862 Ep: 9.46 loss 0.439 score 0.934 lr 5.85413e-06 
09/22/2020 10:39:56 - INFO - volta.utils -   [GQA]: iter 278882 Ep: 9.46 loss 0.321 score 0.958 lr 5.85375e-06 
09/22/2020 10:40:06 - INFO - volta.utils -   [GQA]: iter 278902 Ep: 9.46 loss 0.463 score 0.922 lr 5.85337e-06 
09/22/2020 10:40:17 - INFO - volta.utils -   [GQA]: iter 278922 Ep: 9.46 loss 0.390 score 0.945 lr 5.853e-06 
09/22/2020 10:40:25 - INFO - volta.utils -   [GQA]: iter 278942 Ep: 9.47 loss 0.354 score 0.948 lr 5.85262e-06 
09/22/2020 10:40:36 - INFO - volta.utils -   [GQA]: iter 278962 Ep: 9.47 loss 0.333 score 0.950 lr 5.85224e-06 
09/22/2020 10:41:00 - INFO - volta.utils -   [GQA]: iter 278982 Ep: 9.47 loss 0.355 score 0.947 lr 5.85187e-06 
09/22/2020 10:41:26 - INFO - volta.utils -   [GQA]: iter 279002 Ep: 9.47 loss 0.362 score 0.947 lr 5.85149e-06 
09/22/2020 10:41:35 - INFO - volta.utils -   [GQA]: iter 279022 Ep: 9.47 loss 0.420 score 0.941 lr 5.85111e-06 
09/22/2020 10:41:43 - INFO - volta.utils -   [GQA]: iter 279042 Ep: 9.47 loss 0.381 score 0.945 lr 5.85073e-06 
09/22/2020 10:41:51 - INFO - volta.utils -   [GQA]: iter 279062 Ep: 9.47 loss 0.448 score 0.934 lr 5.85036e-06 
09/22/2020 10:42:16 - INFO - volta.utils -   [GQA]: iter 279082 Ep: 9.47 loss 0.406 score 0.931 lr 5.84998e-06 
09/22/2020 10:42:35 - INFO - volta.utils -   [GQA]: iter 279102 Ep: 9.47 loss 0.427 score 0.933 lr 5.8496e-06 
09/22/2020 10:42:48 - INFO - volta.utils -   [GQA]: iter 279122 Ep: 9.47 loss 0.392 score 0.945 lr 5.84923e-06 
09/22/2020 10:42:58 - INFO - volta.utils -   [GQA]: iter 279142 Ep: 9.47 loss 0.334 score 0.944 lr 5.84885e-06 
09/22/2020 10:43:08 - INFO - volta.utils -   [GQA]: iter 279162 Ep: 9.47 loss 0.352 score 0.945 lr 5.84847e-06 
09/22/2020 10:43:29 - INFO - volta.utils -   [GQA]: iter 279182 Ep: 9.47 loss 0.457 score 0.928 lr 5.84809e-06 
09/22/2020 10:43:44 - INFO - volta.utils -   [GQA]: iter 279202 Ep: 9.47 loss 0.414 score 0.934 lr 5.84772e-06 
09/22/2020 10:44:03 - INFO - volta.utils -   [GQA]: iter 279222 Ep: 9.48 loss 0.358 score 0.942 lr 5.84734e-06 
09/22/2020 10:44:22 - INFO - volta.utils -   [GQA]: iter 279242 Ep: 9.48 loss 0.400 score 0.933 lr 5.84696e-06 
09/22/2020 10:44:29 - INFO - volta.utils -   [GQA]: iter 279262 Ep: 9.48 loss 0.381 score 0.933 lr 5.84659e-06 
09/22/2020 10:44:37 - INFO - volta.utils -   [GQA]: iter 279282 Ep: 9.48 loss 0.436 score 0.920 lr 5.84621e-06 
09/22/2020 10:44:48 - INFO - volta.utils -   [GQA]: iter 279302 Ep: 9.48 loss 0.342 score 0.939 lr 5.84583e-06 
09/22/2020 10:44:58 - INFO - volta.utils -   [GQA]: iter 279322 Ep: 9.48 loss 0.350 score 0.938 lr 5.84546e-06 
09/22/2020 10:45:09 - INFO - volta.utils -   [GQA]: iter 279342 Ep: 9.48 loss 0.327 score 0.952 lr 5.84508e-06 
09/22/2020 10:45:22 - INFO - volta.utils -   [GQA]: iter 279362 Ep: 9.48 loss 0.454 score 0.927 lr 5.8447e-06 
09/22/2020 10:45:36 - INFO - volta.utils -   [GQA]: iter 279382 Ep: 9.48 loss 0.462 score 0.930 lr 5.84432e-06 
09/22/2020 10:45:48 - INFO - volta.utils -   [GQA]: iter 279402 Ep: 9.48 loss 0.306 score 0.958 lr 5.84395e-06 
09/22/2020 10:45:56 - INFO - volta.utils -   [GQA]: iter 279422 Ep: 9.48 loss 0.367 score 0.941 lr 5.84357e-06 
09/22/2020 10:46:21 - INFO - volta.utils -   [GQA]: iter 279442 Ep: 9.48 loss 0.363 score 0.945 lr 5.84319e-06 
09/22/2020 10:46:38 - INFO - volta.utils -   [GQA]: iter 279462 Ep: 9.48 loss 0.361 score 0.936 lr 5.84282e-06 
09/22/2020 10:46:52 - INFO - volta.utils -   [GQA]: iter 279482 Ep: 9.48 loss 0.371 score 0.938 lr 5.84244e-06 
09/22/2020 10:47:01 - INFO - volta.utils -   [GQA]: iter 279502 Ep: 9.48 loss 0.432 score 0.927 lr 5.84206e-06 
09/22/2020 10:47:14 - INFO - volta.utils -   [GQA]: iter 279522 Ep: 9.49 loss 0.375 score 0.942 lr 5.84168e-06 
09/22/2020 10:47:30 - INFO - volta.utils -   [GQA]: iter 279542 Ep: 9.49 loss 0.415 score 0.941 lr 5.84131e-06 
09/22/2020 10:47:44 - INFO - volta.utils -   [GQA]: iter 279562 Ep: 9.49 loss 0.418 score 0.939 lr 5.84093e-06 
09/22/2020 10:47:56 - INFO - volta.utils -   [GQA]: iter 279582 Ep: 9.49 loss 0.303 score 0.956 lr 5.84055e-06 
09/22/2020 10:48:06 - INFO - volta.utils -   [GQA]: iter 279602 Ep: 9.49 loss 0.527 score 0.905 lr 5.84018e-06 
09/22/2020 10:48:17 - INFO - volta.utils -   [GQA]: iter 279622 Ep: 9.49 loss 0.347 score 0.953 lr 5.8398e-06 
09/22/2020 10:48:38 - INFO - volta.utils -   [GQA]: iter 279642 Ep: 9.49 loss 0.354 score 0.952 lr 5.83942e-06 
09/22/2020 10:49:03 - INFO - volta.utils -   [GQA]: iter 279662 Ep: 9.49 loss 0.307 score 0.953 lr 5.83905e-06 
09/22/2020 10:49:11 - INFO - volta.utils -   [GQA]: iter 279682 Ep: 9.49 loss 0.425 score 0.931 lr 5.83867e-06 
09/22/2020 10:49:26 - INFO - volta.utils -   [GQA]: iter 279702 Ep: 9.49 loss 0.398 score 0.944 lr 5.83829e-06 
09/22/2020 10:49:34 - INFO - volta.utils -   [GQA]: iter 279722 Ep: 9.49 loss 0.368 score 0.944 lr 5.83791e-06 
09/22/2020 10:49:42 - INFO - volta.utils -   [GQA]: iter 279742 Ep: 9.49 loss 0.331 score 0.942 lr 5.83754e-06 
09/22/2020 10:49:53 - INFO - volta.utils -   [GQA]: iter 279762 Ep: 9.49 loss 0.461 score 0.925 lr 5.83716e-06 
09/22/2020 10:50:10 - INFO - volta.utils -   [GQA]: iter 279782 Ep: 9.49 loss 0.381 score 0.945 lr 5.83678e-06 
09/22/2020 10:50:20 - INFO - volta.utils -   [GQA]: iter 279802 Ep: 9.49 loss 0.373 score 0.944 lr 5.83641e-06 
09/22/2020 10:50:31 - INFO - volta.utils -   [GQA]: iter 279822 Ep: 9.50 loss 0.367 score 0.938 lr 5.83603e-06 
09/22/2020 10:50:50 - INFO - volta.utils -   [GQA]: iter 279842 Ep: 9.50 loss 0.371 score 0.941 lr 5.83565e-06 
09/22/2020 10:51:07 - INFO - volta.utils -   [GQA]: iter 279862 Ep: 9.50 loss 0.371 score 0.941 lr 5.83528e-06 
09/22/2020 10:51:22 - INFO - volta.utils -   [GQA]: iter 279882 Ep: 9.50 loss 0.407 score 0.948 lr 5.8349e-06 
09/22/2020 10:51:35 - INFO - volta.utils -   [GQA]: iter 279902 Ep: 9.50 loss 0.425 score 0.927 lr 5.83452e-06 
09/22/2020 10:51:43 - INFO - volta.utils -   [GQA]: iter 279922 Ep: 9.50 loss 0.352 score 0.958 lr 5.83414e-06 
09/22/2020 10:51:51 - INFO - volta.utils -   [GQA]: iter 279942 Ep: 9.50 loss 0.393 score 0.930 lr 5.83377e-06 
09/22/2020 10:51:59 - INFO - volta.utils -   [GQA]: iter 279962 Ep: 9.50 loss 0.323 score 0.952 lr 5.83339e-06 
09/22/2020 10:52:29 - INFO - volta.utils -   [GQA]: iter 279982 Ep: 9.50 loss 0.411 score 0.930 lr 5.83301e-06 
09/22/2020 10:52:48 - INFO - volta.utils -   [GQA]: iter 280002 Ep: 9.50 loss 0.414 score 0.936 lr 5.83264e-06 
09/22/2020 10:53:02 - INFO - volta.utils -   [GQA]: iter 280022 Ep: 9.50 loss 0.380 score 0.942 lr 5.83226e-06 
09/22/2020 10:53:13 - INFO - volta.utils -   [GQA]: iter 280042 Ep: 9.50 loss 0.407 score 0.945 lr 5.83188e-06 
09/22/2020 10:53:24 - INFO - volta.utils -   [GQA]: iter 280062 Ep: 9.50 loss 0.394 score 0.928 lr 5.8315e-06 
09/22/2020 10:53:42 - INFO - volta.utils -   [GQA]: iter 280082 Ep: 9.50 loss 0.408 score 0.930 lr 5.83113e-06 
09/22/2020 10:53:50 - INFO - volta.utils -   [GQA]: iter 280102 Ep: 9.50 loss 0.353 score 0.948 lr 5.83075e-06 
09/22/2020 10:54:06 - INFO - volta.utils -   [GQA]: iter 280122 Ep: 9.51 loss 0.403 score 0.933 lr 5.83037e-06 
09/22/2020 10:54:33 - INFO - volta.utils -   [GQA]: iter 280142 Ep: 9.51 loss 0.337 score 0.944 lr 5.83e-06 
09/22/2020 10:54:49 - INFO - volta.utils -   [GQA]: iter 280162 Ep: 9.51 loss 0.341 score 0.945 lr 5.82962e-06 
09/22/2020 10:55:04 - INFO - volta.utils -   [GQA]: iter 280182 Ep: 9.51 loss 0.322 score 0.956 lr 5.82924e-06 
09/22/2020 10:55:14 - INFO - volta.utils -   [GQA]: iter 280202 Ep: 9.51 loss 0.335 score 0.947 lr 5.82887e-06 
09/22/2020 10:55:22 - INFO - volta.utils -   [GQA]: iter 280222 Ep: 9.51 loss 0.415 score 0.934 lr 5.82849e-06 
09/22/2020 10:55:30 - INFO - volta.utils -   [GQA]: iter 280242 Ep: 9.51 loss 0.532 score 0.898 lr 5.82811e-06 
09/22/2020 10:55:38 - INFO - volta.utils -   [GQA]: iter 280262 Ep: 9.51 loss 0.415 score 0.925 lr 5.82773e-06 
09/22/2020 10:56:03 - INFO - volta.utils -   [GQA]: iter 280282 Ep: 9.51 loss 0.371 score 0.941 lr 5.82736e-06 
09/22/2020 10:56:21 - INFO - volta.utils -   [GQA]: iter 280302 Ep: 9.51 loss 0.448 score 0.934 lr 5.82698e-06 
09/22/2020 10:56:41 - INFO - volta.utils -   [GQA]: iter 280322 Ep: 9.51 loss 0.341 score 0.948 lr 5.8266e-06 
09/22/2020 10:56:48 - INFO - volta.utils -   [GQA]: iter 280342 Ep: 9.51 loss 0.340 score 0.947 lr 5.82623e-06 
09/22/2020 10:56:58 - INFO - volta.utils -   [GQA]: iter 280362 Ep: 9.51 loss 0.425 score 0.939 lr 5.82585e-06 
09/22/2020 10:57:11 - INFO - volta.utils -   [GQA]: iter 280382 Ep: 9.51 loss 0.400 score 0.941 lr 5.82547e-06 
09/22/2020 10:57:19 - INFO - volta.utils -   [GQA]: iter 280402 Ep: 9.52 loss 0.329 score 0.952 lr 5.82509e-06 
09/22/2020 10:57:34 - INFO - volta.utils -   [GQA]: iter 280422 Ep: 9.52 loss 0.374 score 0.944 lr 5.82472e-06 
09/22/2020 10:57:51 - INFO - volta.utils -   [GQA]: iter 280442 Ep: 9.52 loss 0.400 score 0.939 lr 5.82434e-06 
09/22/2020 10:58:11 - INFO - volta.utils -   [GQA]: iter 280462 Ep: 9.52 loss 0.422 score 0.934 lr 5.82396e-06 
09/22/2020 10:58:18 - INFO - volta.utils -   [GQA]: iter 280482 Ep: 9.52 loss 0.406 score 0.931 lr 5.82359e-06 
09/22/2020 10:58:28 - INFO - volta.utils -   [GQA]: iter 280502 Ep: 9.52 loss 0.393 score 0.938 lr 5.82321e-06 
09/22/2020 10:58:48 - INFO - volta.utils -   [GQA]: iter 280522 Ep: 9.52 loss 0.402 score 0.936 lr 5.82283e-06 
09/22/2020 10:58:56 - INFO - volta.utils -   [GQA]: iter 280542 Ep: 9.52 loss 0.315 score 0.955 lr 5.82246e-06 
09/22/2020 10:59:08 - INFO - volta.utils -   [GQA]: iter 280562 Ep: 9.52 loss 0.482 score 0.934 lr 5.82208e-06 
09/22/2020 10:59:36 - INFO - volta.utils -   [GQA]: iter 280582 Ep: 9.52 loss 0.322 score 0.945 lr 5.8217e-06 
09/22/2020 10:59:49 - INFO - volta.utils -   [GQA]: iter 280602 Ep: 9.52 loss 0.359 score 0.952 lr 5.82132e-06 
09/22/2020 11:00:05 - INFO - volta.utils -   [GQA]: iter 280622 Ep: 9.52 loss 0.419 score 0.933 lr 5.82095e-06 
09/22/2020 11:00:17 - INFO - volta.utils -   [GQA]: iter 280642 Ep: 9.52 loss 0.320 score 0.952 lr 5.82057e-06 
09/22/2020 11:00:27 - INFO - volta.utils -   [GQA]: iter 280662 Ep: 9.52 loss 0.344 score 0.944 lr 5.82019e-06 
09/22/2020 11:00:44 - INFO - volta.utils -   [GQA]: iter 280682 Ep: 9.52 loss 0.431 score 0.936 lr 5.81982e-06 
09/22/2020 11:01:05 - INFO - volta.utils -   [GQA]: iter 280702 Ep: 9.53 loss 0.394 score 0.941 lr 5.81944e-06 
09/22/2020 11:01:29 - INFO - volta.utils -   [GQA]: iter 280722 Ep: 9.53 loss 0.379 score 0.938 lr 5.81906e-06 
09/22/2020 11:01:44 - INFO - volta.utils -   [GQA]: iter 280742 Ep: 9.53 loss 0.478 score 0.928 lr 5.81869e-06 
09/22/2020 11:01:53 - INFO - volta.utils -   [GQA]: iter 280762 Ep: 9.53 loss 0.456 score 0.933 lr 5.81831e-06 
09/22/2020 11:02:08 - INFO - volta.utils -   [GQA]: iter 280782 Ep: 9.53 loss 0.358 score 0.945 lr 5.81793e-06 
09/22/2020 11:02:29 - INFO - volta.utils -   [GQA]: iter 280802 Ep: 9.53 loss 0.341 score 0.948 lr 5.81755e-06 
09/22/2020 11:02:45 - INFO - volta.utils -   [GQA]: iter 280822 Ep: 9.53 loss 0.353 score 0.944 lr 5.81718e-06 
09/22/2020 11:03:01 - INFO - volta.utils -   [GQA]: iter 280842 Ep: 9.53 loss 0.351 score 0.947 lr 5.8168e-06 
09/22/2020 11:03:17 - INFO - volta.utils -   [GQA]: iter 280862 Ep: 9.53 loss 0.403 score 0.939 lr 5.81642e-06 
09/22/2020 11:03:26 - INFO - volta.utils -   [GQA]: iter 280882 Ep: 9.53 loss 0.316 score 0.950 lr 5.81605e-06 
09/22/2020 11:03:35 - INFO - volta.utils -   [GQA]: iter 280902 Ep: 9.53 loss 0.316 score 0.961 lr 5.81567e-06 
09/22/2020 11:03:43 - INFO - volta.utils -   [GQA]: iter 280922 Ep: 9.53 loss 0.395 score 0.925 lr 5.81529e-06 
09/22/2020 11:04:21 - INFO - volta.utils -   [GQA]: iter 280942 Ep: 9.53 loss 0.380 score 0.939 lr 5.81491e-06 
09/22/2020 11:04:29 - INFO - volta.utils -   [GQA]: iter 280962 Ep: 9.53 loss 0.378 score 0.945 lr 5.81454e-06 
09/22/2020 11:04:45 - INFO - volta.utils -   [GQA]: iter 280982 Ep: 9.53 loss 0.360 score 0.948 lr 5.81416e-06 
09/22/2020 11:04:55 - INFO - volta.utils -   [GQA]: iter 281002 Ep: 9.54 loss 0.428 score 0.939 lr 5.81378e-06 
09/22/2020 11:05:03 - INFO - volta.utils -   [GQA]: iter 281022 Ep: 9.54 loss 0.345 score 0.944 lr 5.81341e-06 
09/22/2020 11:05:12 - INFO - volta.utils -   [GQA]: iter 281042 Ep: 9.54 loss 0.369 score 0.950 lr 5.81303e-06 
09/22/2020 11:05:35 - INFO - volta.utils -   [GQA]: iter 281062 Ep: 9.54 loss 0.402 score 0.933 lr 5.81265e-06 
09/22/2020 11:05:50 - INFO - volta.utils -   [GQA]: iter 281082 Ep: 9.54 loss 0.420 score 0.928 lr 5.81228e-06 
09/22/2020 11:06:08 - INFO - volta.utils -   [GQA]: iter 281102 Ep: 9.54 loss 0.405 score 0.934 lr 5.8119e-06 
09/22/2020 11:06:22 - INFO - volta.utils -   [GQA]: iter 281122 Ep: 9.54 loss 0.388 score 0.933 lr 5.81152e-06 
09/22/2020 11:06:34 - INFO - volta.utils -   [GQA]: iter 281142 Ep: 9.54 loss 0.332 score 0.950 lr 5.81114e-06 
09/22/2020 11:06:42 - INFO - volta.utils -   [GQA]: iter 281162 Ep: 9.54 loss 0.396 score 0.939 lr 5.81077e-06 
09/22/2020 11:06:50 - INFO - volta.utils -   [GQA]: iter 281182 Ep: 9.54 loss 0.353 score 0.944 lr 5.81039e-06 
09/22/2020 11:07:06 - INFO - volta.utils -   [GQA]: iter 281202 Ep: 9.54 loss 0.425 score 0.933 lr 5.81001e-06 
09/22/2020 11:07:32 - INFO - volta.utils -   [GQA]: iter 281222 Ep: 9.54 loss 0.337 score 0.947 lr 5.80964e-06 
09/22/2020 11:07:43 - INFO - volta.utils -   [GQA]: iter 281242 Ep: 9.54 loss 0.370 score 0.938 lr 5.80926e-06 
09/22/2020 11:07:56 - INFO - volta.utils -   [GQA]: iter 281262 Ep: 9.54 loss 0.302 score 0.952 lr 5.80888e-06 
09/22/2020 11:08:07 - INFO - volta.utils -   [GQA]: iter 281282 Ep: 9.55 loss 0.413 score 0.936 lr 5.8085e-06 
09/22/2020 11:08:14 - INFO - volta.utils -   [GQA]: iter 281302 Ep: 9.55 loss 0.429 score 0.930 lr 5.80813e-06 
09/22/2020 11:08:22 - INFO - volta.utils -   [GQA]: iter 281322 Ep: 9.55 loss 0.400 score 0.936 lr 5.80775e-06 
09/22/2020 11:08:30 - INFO - volta.utils -   [GQA]: iter 281342 Ep: 9.55 loss 0.409 score 0.944 lr 5.80737e-06 
09/22/2020 11:08:42 - INFO - volta.utils -   [GQA]: iter 281362 Ep: 9.55 loss 0.408 score 0.938 lr 5.807e-06 
09/22/2020 11:09:09 - INFO - volta.utils -   [GQA]: iter 281382 Ep: 9.55 loss 0.340 score 0.948 lr 5.80662e-06 
09/22/2020 11:09:27 - INFO - volta.utils -   [GQA]: iter 281402 Ep: 9.55 loss 0.382 score 0.952 lr 5.80624e-06 
09/22/2020 11:09:37 - INFO - volta.utils -   [GQA]: iter 281422 Ep: 9.55 loss 0.390 score 0.945 lr 5.80587e-06 
09/22/2020 11:09:48 - INFO - volta.utils -   [GQA]: iter 281442 Ep: 9.55 loss 0.407 score 0.938 lr 5.80549e-06 
09/22/2020 11:10:01 - INFO - volta.utils -   [GQA]: iter 281462 Ep: 9.55 loss 0.383 score 0.945 lr 5.80511e-06 
09/22/2020 11:10:17 - INFO - volta.utils -   [GQA]: iter 281482 Ep: 9.55 loss 0.438 score 0.933 lr 5.80473e-06 
09/22/2020 11:10:39 - INFO - volta.utils -   [GQA]: iter 281502 Ep: 9.55 loss 0.318 score 0.948 lr 5.80436e-06 
09/22/2020 11:10:51 - INFO - volta.utils -   [GQA]: iter 281522 Ep: 9.55 loss 0.359 score 0.947 lr 5.80398e-06 
09/22/2020 11:11:01 - INFO - volta.utils -   [GQA]: iter 281542 Ep: 9.55 loss 0.267 score 0.964 lr 5.8036e-06 
09/22/2020 11:11:14 - INFO - volta.utils -   [GQA]: iter 281562 Ep: 9.55 loss 0.383 score 0.928 lr 5.80323e-06 
09/22/2020 11:11:24 - INFO - volta.utils -   [GQA]: iter 281582 Ep: 9.56 loss 0.361 score 0.945 lr 5.80285e-06 
09/22/2020 11:11:32 - INFO - volta.utils -   [GQA]: iter 281602 Ep: 9.56 loss 0.391 score 0.941 lr 5.80247e-06 
09/22/2020 11:11:40 - INFO - volta.utils -   [GQA]: iter 281622 Ep: 9.56 loss 0.363 score 0.948 lr 5.8021e-06 
09/22/2020 11:11:57 - INFO - volta.utils -   [GQA]: iter 281642 Ep: 9.56 loss 0.403 score 0.947 lr 5.80172e-06 
09/22/2020 11:12:18 - INFO - volta.utils -   [GQA]: iter 281662 Ep: 9.56 loss 0.405 score 0.923 lr 5.80134e-06 
09/22/2020 11:12:39 - INFO - volta.utils -   [GQA]: iter 281682 Ep: 9.56 loss 0.414 score 0.936 lr 5.80096e-06 
09/22/2020 11:12:50 - INFO - volta.utils -   [GQA]: iter 281702 Ep: 9.56 loss 0.390 score 0.950 lr 5.80059e-06 
09/22/2020 11:13:06 - INFO - volta.utils -   [GQA]: iter 281722 Ep: 9.56 loss 0.428 score 0.930 lr 5.80021e-06 
09/22/2020 11:13:15 - INFO - volta.utils -   [GQA]: iter 281742 Ep: 9.56 loss 0.364 score 0.939 lr 5.79983e-06 
09/22/2020 11:13:28 - INFO - volta.utils -   [GQA]: iter 281762 Ep: 9.56 loss 0.393 score 0.933 lr 5.79946e-06 
09/22/2020 11:13:48 - INFO - volta.utils -   [GQA]: iter 281782 Ep: 9.56 loss 0.462 score 0.923 lr 5.79908e-06 
09/22/2020 11:14:10 - INFO - volta.utils -   [GQA]: iter 281802 Ep: 9.56 loss 0.397 score 0.936 lr 5.7987e-06 
09/22/2020 11:14:22 - INFO - volta.utils -   [GQA]: iter 281822 Ep: 9.56 loss 0.325 score 0.958 lr 5.79832e-06 
09/22/2020 11:14:34 - INFO - volta.utils -   [GQA]: iter 281842 Ep: 9.56 loss 0.503 score 0.925 lr 5.79795e-06 
09/22/2020 11:14:50 - INFO - volta.utils -   [GQA]: iter 281862 Ep: 9.56 loss 0.435 score 0.931 lr 5.79757e-06 
09/22/2020 11:14:58 - INFO - volta.utils -   [GQA]: iter 281882 Ep: 9.57 loss 0.422 score 0.927 lr 5.79719e-06 
09/22/2020 11:15:09 - INFO - volta.utils -   [GQA]: iter 281902 Ep: 9.57 loss 0.378 score 0.930 lr 5.79682e-06 
09/22/2020 11:15:30 - INFO - volta.utils -   [GQA]: iter 281922 Ep: 9.57 loss 0.389 score 0.936 lr 5.79644e-06 
09/22/2020 11:15:48 - INFO - volta.utils -   [GQA]: iter 281942 Ep: 9.57 loss 0.376 score 0.945 lr 5.79606e-06 
09/22/2020 11:16:05 - INFO - volta.utils -   [GQA]: iter 281962 Ep: 9.57 loss 0.371 score 0.942 lr 5.79569e-06 
09/22/2020 11:16:13 - INFO - volta.utils -   [GQA]: iter 281982 Ep: 9.57 loss 0.432 score 0.934 lr 5.79531e-06 
09/22/2020 11:16:21 - INFO - volta.utils -   [GQA]: iter 282002 Ep: 9.57 loss 0.428 score 0.936 lr 5.79493e-06 
09/22/2020 11:16:32 - INFO - volta.utils -   [GQA]: iter 282022 Ep: 9.57 loss 0.369 score 0.947 lr 5.79455e-06 
09/22/2020 11:16:46 - INFO - volta.utils -   [GQA]: iter 282042 Ep: 9.57 loss 0.400 score 0.941 lr 5.79418e-06 
09/22/2020 11:17:12 - INFO - volta.utils -   [GQA]: iter 282062 Ep: 9.57 loss 0.362 score 0.939 lr 5.7938e-06 
09/22/2020 11:17:21 - INFO - volta.utils -   [GQA]: iter 282082 Ep: 9.57 loss 0.466 score 0.922 lr 5.79342e-06 
09/22/2020 11:17:40 - INFO - volta.utils -   [GQA]: iter 282102 Ep: 9.57 loss 0.281 score 0.961 lr 5.79305e-06 
09/22/2020 11:17:51 - INFO - volta.utils -   [GQA]: iter 282122 Ep: 9.57 loss 0.356 score 0.947 lr 5.79267e-06 
09/22/2020 11:18:01 - INFO - volta.utils -   [GQA]: iter 282142 Ep: 9.57 loss 0.424 score 0.928 lr 5.79229e-06 
09/22/2020 11:18:10 - INFO - volta.utils -   [GQA]: iter 282162 Ep: 9.57 loss 0.397 score 0.934 lr 5.79192e-06 
09/22/2020 11:18:45 - INFO - volta.utils -   [GQA]: iter 282182 Ep: 9.58 loss 0.371 score 0.939 lr 5.79154e-06 
09/22/2020 11:19:09 - INFO - volta.utils -   [GQA]: iter 282202 Ep: 9.58 loss 0.392 score 0.939 lr 5.79116e-06 
09/22/2020 11:19:20 - INFO - volta.utils -   [GQA]: iter 282222 Ep: 9.58 loss 0.414 score 0.928 lr 5.79078e-06 
09/22/2020 11:19:27 - INFO - volta.utils -   [GQA]: iter 282242 Ep: 9.58 loss 0.344 score 0.952 lr 5.79041e-06 
09/22/2020 11:19:43 - INFO - volta.utils -   [GQA]: iter 282262 Ep: 9.58 loss 0.459 score 0.925 lr 5.79003e-06 
09/22/2020 11:20:00 - INFO - volta.utils -   [GQA]: iter 282282 Ep: 9.58 loss 0.372 score 0.939 lr 5.78965e-06 
09/22/2020 11:20:19 - INFO - volta.utils -   [GQA]: iter 282302 Ep: 9.58 loss 0.443 score 0.925 lr 5.78928e-06 
09/22/2020 11:20:35 - INFO - volta.utils -   [GQA]: iter 282322 Ep: 9.58 loss 0.365 score 0.934 lr 5.7889e-06 
09/22/2020 11:20:48 - INFO - volta.utils -   [GQA]: iter 282342 Ep: 9.58 loss 0.383 score 0.945 lr 5.78852e-06 
09/22/2020 11:21:00 - INFO - volta.utils -   [GQA]: iter 282362 Ep: 9.58 loss 0.463 score 0.917 lr 5.78814e-06 
09/22/2020 11:21:11 - INFO - volta.utils -   [GQA]: iter 282382 Ep: 9.58 loss 0.421 score 0.944 lr 5.78777e-06 
09/22/2020 11:21:24 - INFO - volta.utils -   [GQA]: iter 282402 Ep: 9.58 loss 0.490 score 0.933 lr 5.78739e-06 
09/22/2020 11:21:39 - INFO - volta.utils -   [GQA]: iter 282422 Ep: 9.58 loss 0.383 score 0.936 lr 5.78701e-06 
09/22/2020 11:22:05 - INFO - volta.utils -   [GQA]: iter 282442 Ep: 9.58 loss 0.381 score 0.941 lr 5.78664e-06 
09/22/2020 11:22:19 - INFO - volta.utils -   [GQA]: iter 282462 Ep: 9.59 loss 0.378 score 0.938 lr 5.78626e-06 
09/22/2020 11:22:30 - INFO - volta.utils -   [GQA]: iter 282482 Ep: 9.59 loss 0.415 score 0.934 lr 5.78588e-06 
09/22/2020 11:22:41 - INFO - volta.utils -   [GQA]: iter 282502 Ep: 9.59 loss 0.379 score 0.939 lr 5.78551e-06 
09/22/2020 11:22:52 - INFO - volta.utils -   [GQA]: iter 282522 Ep: 9.59 loss 0.312 score 0.953 lr 5.78513e-06 
09/22/2020 11:22:59 - INFO - volta.utils -   [GQA]: iter 282542 Ep: 9.59 loss 0.391 score 0.939 lr 5.78475e-06 
09/22/2020 11:23:18 - INFO - volta.utils -   [GQA]: iter 282562 Ep: 9.59 loss 0.375 score 0.939 lr 5.78437e-06 
09/22/2020 11:23:40 - INFO - volta.utils -   [GQA]: iter 282582 Ep: 9.59 loss 0.462 score 0.922 lr 5.784e-06 
09/22/2020 11:24:00 - INFO - volta.utils -   [GQA]: iter 282602 Ep: 9.59 loss 0.413 score 0.928 lr 5.78362e-06 
09/22/2020 11:24:11 - INFO - volta.utils -   [GQA]: iter 282622 Ep: 9.59 loss 0.358 score 0.945 lr 5.78324e-06 
09/22/2020 11:24:19 - INFO - volta.utils -   [GQA]: iter 282642 Ep: 9.59 loss 0.373 score 0.947 lr 5.78287e-06 
09/22/2020 11:24:31 - INFO - volta.utils -   [GQA]: iter 282662 Ep: 9.59 loss 0.469 score 0.925 lr 5.78249e-06 
09/22/2020 11:24:46 - INFO - volta.utils -   [GQA]: iter 282682 Ep: 9.59 loss 0.441 score 0.947 lr 5.78211e-06 
09/22/2020 11:25:10 - INFO - volta.utils -   [GQA]: iter 282702 Ep: 9.59 loss 0.326 score 0.948 lr 5.78173e-06 
09/22/2020 11:25:27 - INFO - volta.utils -   [GQA]: iter 282722 Ep: 9.59 loss 0.323 score 0.952 lr 5.78136e-06 
09/22/2020 11:25:49 - INFO - volta.utils -   [GQA]: iter 282742 Ep: 9.59 loss 0.438 score 0.923 lr 5.78098e-06 
09/22/2020 11:26:00 - INFO - volta.utils -   [GQA]: iter 282762 Ep: 9.60 loss 0.480 score 0.927 lr 5.7806e-06 
09/22/2020 11:26:15 - INFO - volta.utils -   [GQA]: iter 282782 Ep: 9.60 loss 0.351 score 0.952 lr 5.78023e-06 
09/22/2020 11:26:39 - INFO - volta.utils -   [GQA]: iter 282802 Ep: 9.60 loss 0.363 score 0.950 lr 5.77985e-06 
09/22/2020 11:27:00 - INFO - volta.utils -   [GQA]: iter 282822 Ep: 9.60 loss 0.368 score 0.945 lr 5.77947e-06 
09/22/2020 11:27:15 - INFO - volta.utils -   [GQA]: iter 282842 Ep: 9.60 loss 0.380 score 0.938 lr 5.7791e-06 
09/22/2020 11:27:25 - INFO - volta.utils -   [GQA]: iter 282862 Ep: 9.60 loss 0.443 score 0.930 lr 5.77872e-06 
09/22/2020 11:27:37 - INFO - volta.utils -   [GQA]: iter 282882 Ep: 9.60 loss 0.338 score 0.944 lr 5.77834e-06 
09/22/2020 11:27:44 - INFO - volta.utils -   [GQA]: iter 282902 Ep: 9.60 loss 0.475 score 0.916 lr 5.77796e-06 
09/22/2020 11:27:59 - INFO - volta.utils -   [GQA]: iter 282922 Ep: 9.60 loss 0.404 score 0.941 lr 5.77759e-06 
09/22/2020 11:28:13 - INFO - volta.utils -   [GQA]: iter 282942 Ep: 9.60 loss 0.426 score 0.936 lr 5.77721e-06 
09/22/2020 11:28:26 - INFO - volta.utils -   [GQA]: iter 282962 Ep: 9.60 loss 0.456 score 0.925 lr 5.77683e-06 
09/22/2020 11:28:34 - INFO - volta.utils -   [GQA]: iter 282982 Ep: 9.60 loss 0.328 score 0.952 lr 5.77646e-06 
09/22/2020 11:28:52 - INFO - volta.utils -   [GQA]: iter 283002 Ep: 9.60 loss 0.407 score 0.930 lr 5.77608e-06 
09/22/2020 11:29:09 - INFO - volta.utils -   [GQA]: iter 283022 Ep: 9.60 loss 0.442 score 0.934 lr 5.7757e-06 
09/22/2020 11:29:28 - INFO - volta.utils -   [GQA]: iter 283042 Ep: 9.60 loss 0.440 score 0.934 lr 5.77533e-06 
09/22/2020 11:29:40 - INFO - volta.utils -   [GQA]: iter 283062 Ep: 9.61 loss 0.450 score 0.931 lr 5.77495e-06 
09/22/2020 11:29:56 - INFO - volta.utils -   [GQA]: iter 283082 Ep: 9.61 loss 0.405 score 0.931 lr 5.77457e-06 
09/22/2020 11:30:04 - INFO - volta.utils -   [GQA]: iter 283102 Ep: 9.61 loss 0.384 score 0.947 lr 5.77419e-06 
09/22/2020 11:30:12 - INFO - volta.utils -   [GQA]: iter 283122 Ep: 9.61 loss 0.385 score 0.944 lr 5.77382e-06 
09/22/2020 11:30:21 - INFO - volta.utils -   [GQA]: iter 283142 Ep: 9.61 loss 0.448 score 0.925 lr 5.77344e-06 
09/22/2020 11:30:44 - INFO - volta.utils -   [GQA]: iter 283162 Ep: 9.61 loss 0.382 score 0.948 lr 5.77306e-06 
09/22/2020 11:30:57 - INFO - volta.utils -   [GQA]: iter 283182 Ep: 9.61 loss 0.343 score 0.952 lr 5.77269e-06 
09/22/2020 11:31:19 - INFO - volta.utils -   [GQA]: iter 283202 Ep: 9.61 loss 0.403 score 0.942 lr 5.77231e-06 
09/22/2020 11:31:27 - INFO - volta.utils -   [GQA]: iter 283222 Ep: 9.61 loss 0.433 score 0.933 lr 5.77193e-06 
09/22/2020 11:31:42 - INFO - volta.utils -   [GQA]: iter 283242 Ep: 9.61 loss 0.362 score 0.948 lr 5.77155e-06 
09/22/2020 11:31:49 - INFO - volta.utils -   [GQA]: iter 283262 Ep: 9.61 loss 0.433 score 0.922 lr 5.77118e-06 
09/22/2020 11:32:02 - INFO - volta.utils -   [GQA]: iter 283282 Ep: 9.61 loss 0.361 score 0.942 lr 5.7708e-06 
09/22/2020 11:32:09 - INFO - volta.utils -   [GQA]: iter 283302 Ep: 9.61 loss 0.406 score 0.933 lr 5.77042e-06 
09/22/2020 11:32:19 - INFO - volta.utils -   [GQA]: iter 283322 Ep: 9.61 loss 0.380 score 0.945 lr 5.77005e-06 
09/22/2020 11:32:27 - INFO - volta.utils -   [GQA]: iter 283342 Ep: 9.61 loss 0.399 score 0.927 lr 5.76967e-06 
09/22/2020 11:32:51 - INFO - volta.utils -   [GQA]: iter 283362 Ep: 9.62 loss 0.350 score 0.944 lr 5.76929e-06 
09/22/2020 11:33:00 - INFO - volta.utils -   [GQA]: iter 283382 Ep: 9.62 loss 0.349 score 0.945 lr 5.76892e-06 
09/22/2020 11:33:11 - INFO - volta.utils -   [GQA]: iter 283402 Ep: 9.62 loss 0.398 score 0.928 lr 5.76854e-06 
09/22/2020 11:33:24 - INFO - volta.utils -   [GQA]: iter 283422 Ep: 9.62 loss 0.356 score 0.944 lr 5.76816e-06 
09/22/2020 11:33:38 - INFO - volta.utils -   [GQA]: iter 283442 Ep: 9.62 loss 0.320 score 0.956 lr 5.76778e-06 
09/22/2020 11:33:59 - INFO - volta.utils -   [GQA]: iter 283462 Ep: 9.62 loss 0.342 score 0.942 lr 5.76741e-06 
09/22/2020 11:34:16 - INFO - volta.utils -   [GQA]: iter 283482 Ep: 9.62 loss 0.386 score 0.944 lr 5.76703e-06 
09/22/2020 11:34:29 - INFO - volta.utils -   [GQA]: iter 283502 Ep: 9.62 loss 0.458 score 0.925 lr 5.76665e-06 
09/22/2020 11:34:38 - INFO - volta.utils -   [GQA]: iter 283522 Ep: 9.62 loss 0.407 score 0.939 lr 5.76628e-06 
09/22/2020 11:34:51 - INFO - volta.utils -   [GQA]: iter 283542 Ep: 9.62 loss 0.393 score 0.934 lr 5.7659e-06 
09/22/2020 11:35:04 - INFO - volta.utils -   [GQA]: iter 283562 Ep: 9.62 loss 0.454 score 0.927 lr 5.76552e-06 
09/22/2020 11:35:16 - INFO - volta.utils -   [GQA]: iter 283582 Ep: 9.62 loss 0.375 score 0.942 lr 5.76514e-06 
09/22/2020 11:35:35 - INFO - volta.utils -   [GQA]: iter 283602 Ep: 9.62 loss 0.514 score 0.939 lr 5.76477e-06 
09/22/2020 11:35:50 - INFO - volta.utils -   [GQA]: iter 283622 Ep: 9.62 loss 0.354 score 0.938 lr 5.76439e-06 
09/22/2020 11:36:11 - INFO - volta.utils -   [GQA]: iter 283642 Ep: 9.63 loss 0.420 score 0.933 lr 5.76401e-06 
09/22/2020 11:36:28 - INFO - volta.utils -   [GQA]: iter 283662 Ep: 9.63 loss 0.317 score 0.948 lr 5.76364e-06 
09/22/2020 11:36:41 - INFO - volta.utils -   [GQA]: iter 283682 Ep: 9.63 loss 0.409 score 0.933 lr 5.76326e-06 
09/22/2020 11:36:49 - INFO - volta.utils -   [GQA]: iter 283702 Ep: 9.63 loss 0.376 score 0.948 lr 5.76288e-06 
09/22/2020 11:36:57 - INFO - volta.utils -   [GQA]: iter 283722 Ep: 9.63 loss 0.422 score 0.930 lr 5.76251e-06 
09/22/2020 11:37:05 - INFO - volta.utils -   [GQA]: iter 283742 Ep: 9.63 loss 0.369 score 0.931 lr 5.76213e-06 
09/22/2020 11:37:17 - INFO - volta.utils -   [GQA]: iter 283762 Ep: 9.63 loss 0.413 score 0.939 lr 5.76175e-06 
09/22/2020 11:37:38 - INFO - volta.utils -   [GQA]: iter 283782 Ep: 9.63 loss 0.350 score 0.944 lr 5.76137e-06 
09/22/2020 11:37:46 - INFO - volta.utils -   [GQA]: iter 283802 Ep: 9.63 loss 0.454 score 0.916 lr 5.761e-06 
09/22/2020 11:37:55 - INFO - volta.utils -   [GQA]: iter 283822 Ep: 9.63 loss 0.432 score 0.930 lr 5.76062e-06 
09/22/2020 11:38:08 - INFO - volta.utils -   [GQA]: iter 283842 Ep: 9.63 loss 0.391 score 0.947 lr 5.76024e-06 
09/22/2020 11:38:24 - INFO - volta.utils -   [GQA]: iter 283862 Ep: 9.63 loss 0.348 score 0.936 lr 5.75987e-06 
09/22/2020 11:38:40 - INFO - volta.utils -   [GQA]: iter 283882 Ep: 9.63 loss 0.360 score 0.944 lr 5.75949e-06 
09/22/2020 11:38:58 - INFO - volta.utils -   [GQA]: iter 283902 Ep: 9.63 loss 0.323 score 0.950 lr 5.75911e-06 
09/22/2020 11:39:06 - INFO - volta.utils -   [GQA]: iter 283922 Ep: 9.63 loss 0.364 score 0.936 lr 5.75874e-06 
09/22/2020 11:39:17 - INFO - volta.utils -   [GQA]: iter 283942 Ep: 9.64 loss 0.395 score 0.953 lr 5.75836e-06 
09/22/2020 11:39:37 - INFO - volta.utils -   [GQA]: iter 283962 Ep: 9.64 loss 0.317 score 0.952 lr 5.75798e-06 
09/22/2020 11:39:54 - INFO - volta.utils -   [GQA]: iter 283982 Ep: 9.64 loss 0.407 score 0.939 lr 5.7576e-06 
09/22/2020 11:40:02 - INFO - volta.utils -   [GQA]: iter 284002 Ep: 9.64 loss 0.407 score 0.938 lr 5.75723e-06 
09/22/2020 11:40:28 - INFO - volta.utils -   [GQA]: iter 284022 Ep: 9.64 loss 0.358 score 0.950 lr 5.75685e-06 
09/22/2020 11:40:36 - INFO - volta.utils -   [GQA]: iter 284042 Ep: 9.64 loss 0.324 score 0.952 lr 5.75647e-06 
09/22/2020 11:41:10 - INFO - volta.utils -   [GQA]: iter 284062 Ep: 9.64 loss 0.469 score 0.927 lr 5.7561e-06 
09/22/2020 11:41:23 - INFO - volta.utils -   [GQA]: iter 284082 Ep: 9.64 loss 0.436 score 0.933 lr 5.75572e-06 
09/22/2020 11:41:33 - INFO - volta.utils -   [GQA]: iter 284102 Ep: 9.64 loss 0.472 score 0.916 lr 5.75534e-06 
09/22/2020 11:41:43 - INFO - volta.utils -   [GQA]: iter 284122 Ep: 9.64 loss 0.333 score 0.944 lr 5.75496e-06 
09/22/2020 11:41:53 - INFO - volta.utils -   [GQA]: iter 284142 Ep: 9.64 loss 0.408 score 0.942 lr 5.75459e-06 
09/22/2020 11:42:17 - INFO - volta.utils -   [GQA]: iter 284162 Ep: 9.64 loss 0.313 score 0.952 lr 5.75421e-06 
09/22/2020 11:42:45 - INFO - volta.utils -   [GQA]: iter 284182 Ep: 9.64 loss 0.361 score 0.939 lr 5.75383e-06 
09/22/2020 11:43:01 - INFO - volta.utils -   [GQA]: iter 284202 Ep: 9.64 loss 0.443 score 0.938 lr 5.75346e-06 
09/22/2020 11:43:10 - INFO - volta.utils -   [GQA]: iter 284222 Ep: 9.64 loss 0.396 score 0.936 lr 5.75308e-06 
09/22/2020 11:43:24 - INFO - volta.utils -   [GQA]: iter 284242 Ep: 9.65 loss 0.403 score 0.933 lr 5.7527e-06 
09/22/2020 11:43:50 - INFO - volta.utils -   [GQA]: iter 284262 Ep: 9.65 loss 0.353 score 0.945 lr 5.75233e-06 
09/22/2020 11:44:00 - INFO - volta.utils -   [GQA]: iter 284282 Ep: 9.65 loss 0.389 score 0.936 lr 5.75195e-06 
09/22/2020 11:44:16 - INFO - volta.utils -   [GQA]: iter 284302 Ep: 9.65 loss 0.422 score 0.923 lr 5.75157e-06 
09/22/2020 11:44:35 - INFO - volta.utils -   [GQA]: iter 284322 Ep: 9.65 loss 0.317 score 0.961 lr 5.75119e-06 
09/22/2020 11:44:49 - INFO - volta.utils -   [GQA]: iter 284342 Ep: 9.65 loss 0.350 score 0.942 lr 5.75082e-06 
09/22/2020 11:45:00 - INFO - volta.utils -   [GQA]: iter 284362 Ep: 9.65 loss 0.391 score 0.944 lr 5.75044e-06 
09/22/2020 11:45:16 - INFO - volta.utils -   [GQA]: iter 284382 Ep: 9.65 loss 0.520 score 0.919 lr 5.75006e-06 
09/22/2020 11:45:24 - INFO - volta.utils -   [GQA]: iter 284402 Ep: 9.65 loss 0.437 score 0.923 lr 5.74969e-06 
09/22/2020 11:45:37 - INFO - volta.utils -   [GQA]: iter 284422 Ep: 9.65 loss 0.357 score 0.950 lr 5.74931e-06 
09/22/2020 11:46:00 - INFO - volta.utils -   [GQA]: iter 284442 Ep: 9.65 loss 0.362 score 0.936 lr 5.74893e-06 
09/22/2020 11:46:17 - INFO - volta.utils -   [GQA]: iter 284462 Ep: 9.65 loss 0.386 score 0.938 lr 5.74855e-06 
09/22/2020 11:46:32 - INFO - volta.utils -   [GQA]: iter 284482 Ep: 9.65 loss 0.345 score 0.945 lr 5.74818e-06 
09/22/2020 11:46:46 - INFO - volta.utils -   [GQA]: iter 284502 Ep: 9.65 loss 0.271 score 0.961 lr 5.7478e-06 
09/22/2020 11:46:57 - INFO - volta.utils -   [GQA]: iter 284522 Ep: 9.65 loss 0.347 score 0.945 lr 5.74742e-06 
09/22/2020 11:47:07 - INFO - volta.utils -   [GQA]: iter 284542 Ep: 9.66 loss 0.372 score 0.941 lr 5.74705e-06 
09/22/2020 11:47:25 - INFO - volta.utils -   [GQA]: iter 284562 Ep: 9.66 loss 0.357 score 0.948 lr 5.74667e-06 
09/22/2020 11:47:56 - INFO - volta.utils -   [GQA]: iter 284582 Ep: 9.66 loss 0.390 score 0.933 lr 5.74629e-06 
09/22/2020 11:48:09 - INFO - volta.utils -   [GQA]: iter 284602 Ep: 9.66 loss 0.305 score 0.959 lr 5.74592e-06 
09/22/2020 11:48:17 - INFO - volta.utils -   [GQA]: iter 284622 Ep: 9.66 loss 0.391 score 0.936 lr 5.74554e-06 
09/22/2020 11:48:35 - INFO - volta.utils -   [GQA]: iter 284642 Ep: 9.66 loss 0.399 score 0.941 lr 5.74516e-06 
09/22/2020 11:48:49 - INFO - volta.utils -   [GQA]: iter 284662 Ep: 9.66 loss 0.419 score 0.936 lr 5.74478e-06 
09/22/2020 11:48:59 - INFO - volta.utils -   [GQA]: iter 284682 Ep: 9.66 loss 0.454 score 0.930 lr 5.74441e-06 
09/22/2020 11:49:06 - INFO - volta.utils -   [GQA]: iter 284702 Ep: 9.66 loss 0.378 score 0.939 lr 5.74403e-06 
09/22/2020 11:49:15 - INFO - volta.utils -   [GQA]: iter 284722 Ep: 9.66 loss 0.321 score 0.955 lr 5.74365e-06 
09/22/2020 11:49:23 - INFO - volta.utils -   [GQA]: iter 284742 Ep: 9.66 loss 0.383 score 0.933 lr 5.74328e-06 
09/22/2020 11:49:43 - INFO - volta.utils -   [GQA]: iter 284762 Ep: 9.66 loss 0.306 score 0.955 lr 5.7429e-06 
09/22/2020 11:50:06 - INFO - volta.utils -   [GQA]: iter 284782 Ep: 9.66 loss 0.512 score 0.922 lr 5.74252e-06 
09/22/2020 11:50:23 - INFO - volta.utils -   [GQA]: iter 284802 Ep: 9.66 loss 0.350 score 0.953 lr 5.74215e-06 
09/22/2020 11:50:35 - INFO - volta.utils -   [GQA]: iter 284822 Ep: 9.67 loss 0.341 score 0.956 lr 5.74177e-06 
09/22/2020 11:50:43 - INFO - volta.utils -   [GQA]: iter 284842 Ep: 9.67 loss 0.379 score 0.938 lr 5.74139e-06 
09/22/2020 11:50:51 - INFO - volta.utils -   [GQA]: iter 284862 Ep: 9.67 loss 0.400 score 0.934 lr 5.74101e-06 
09/22/2020 11:50:59 - INFO - volta.utils -   [GQA]: iter 284882 Ep: 9.67 loss 0.394 score 0.931 lr 5.74064e-06 
09/22/2020 11:51:07 - INFO - volta.utils -   [GQA]: iter 284902 Ep: 9.67 loss 0.491 score 0.922 lr 5.74026e-06 
09/22/2020 11:51:34 - INFO - volta.utils -   [GQA]: iter 284922 Ep: 9.67 loss 0.345 score 0.955 lr 5.73988e-06 
09/22/2020 11:51:41 - INFO - volta.utils -   [GQA]: iter 284942 Ep: 9.67 loss 0.399 score 0.941 lr 5.73951e-06 
09/22/2020 11:52:04 - INFO - volta.utils -   [GQA]: iter 284962 Ep: 9.67 loss 0.310 score 0.950 lr 5.73913e-06 
09/22/2020 11:52:13 - INFO - volta.utils -   [GQA]: iter 284982 Ep: 9.67 loss 0.399 score 0.941 lr 5.73875e-06 
09/22/2020 11:52:28 - INFO - volta.utils -   [GQA]: iter 285002 Ep: 9.67 loss 0.386 score 0.939 lr 5.73837e-06 
09/22/2020 11:52:38 - INFO - volta.utils -   [GQA]: iter 285022 Ep: 9.67 loss 0.462 score 0.931 lr 5.738e-06 
09/22/2020 11:52:47 - INFO - volta.utils -   [GQA]: iter 285042 Ep: 9.67 loss 0.387 score 0.939 lr 5.73762e-06 
09/22/2020 11:52:54 - INFO - volta.utils -   [GQA]: iter 285062 Ep: 9.67 loss 0.385 score 0.944 lr 5.73724e-06 
09/22/2020 11:53:06 - INFO - volta.utils -   [GQA]: iter 285082 Ep: 9.67 loss 0.330 score 0.944 lr 5.73687e-06 
09/22/2020 11:53:27 - INFO - volta.utils -   [GQA]: iter 285102 Ep: 9.67 loss 0.386 score 0.938 lr 5.73649e-06 
09/22/2020 11:53:45 - INFO - volta.utils -   [GQA]: iter 285122 Ep: 9.68 loss 0.393 score 0.939 lr 5.73611e-06 
09/22/2020 11:53:54 - INFO - volta.utils -   [GQA]: iter 285142 Ep: 9.68 loss 0.378 score 0.941 lr 5.73574e-06 
09/22/2020 11:54:03 - INFO - volta.utils -   [GQA]: iter 285162 Ep: 9.68 loss 0.392 score 0.942 lr 5.73536e-06 
09/22/2020 11:54:14 - INFO - volta.utils -   [GQA]: iter 285182 Ep: 9.68 loss 0.380 score 0.942 lr 5.73498e-06 
09/22/2020 11:54:32 - INFO - volta.utils -   [GQA]: iter 285202 Ep: 9.68 loss 0.420 score 0.942 lr 5.7346e-06 
09/22/2020 11:54:40 - INFO - volta.utils -   [GQA]: iter 285222 Ep: 9.68 loss 0.366 score 0.945 lr 5.73423e-06 
09/22/2020 11:54:48 - INFO - volta.utils -   [GQA]: iter 285242 Ep: 9.68 loss 0.463 score 0.920 lr 5.73385e-06 
09/22/2020 11:55:02 - INFO - volta.utils -   [GQA]: iter 285262 Ep: 9.68 loss 0.444 score 0.930 lr 5.73347e-06 
09/22/2020 11:55:27 - INFO - volta.utils -   [GQA]: iter 285282 Ep: 9.68 loss 0.419 score 0.934 lr 5.7331e-06 
09/22/2020 11:55:44 - INFO - volta.utils -   [GQA]: iter 285302 Ep: 9.68 loss 0.405 score 0.944 lr 5.73272e-06 
09/22/2020 11:55:57 - INFO - volta.utils -   [GQA]: iter 285322 Ep: 9.68 loss 0.389 score 0.939 lr 5.73234e-06 
09/22/2020 11:56:15 - INFO - volta.utils -   [GQA]: iter 285342 Ep: 9.68 loss 0.360 score 0.941 lr 5.73197e-06 
09/22/2020 11:56:28 - INFO - volta.utils -   [GQA]: iter 285362 Ep: 9.68 loss 0.418 score 0.930 lr 5.73159e-06 
09/22/2020 11:56:37 - INFO - volta.utils -   [GQA]: iter 285382 Ep: 9.68 loss 0.398 score 0.938 lr 5.73121e-06 
09/22/2020 11:56:54 - INFO - volta.utils -   [GQA]: iter 285402 Ep: 9.68 loss 0.318 score 0.950 lr 5.73083e-06 
09/22/2020 11:57:01 - INFO - volta.utils -   [GQA]: iter 285422 Ep: 9.69 loss 0.418 score 0.931 lr 5.73046e-06 
09/22/2020 11:57:28 - INFO - volta.utils -   [GQA]: iter 285442 Ep: 9.69 loss 0.404 score 0.925 lr 5.73008e-06 
09/22/2020 11:57:57 - INFO - volta.utils -   [GQA]: iter 285462 Ep: 9.69 loss 0.388 score 0.934 lr 5.7297e-06 
09/22/2020 11:58:12 - INFO - volta.utils -   [GQA]: iter 285482 Ep: 9.69 loss 0.330 score 0.947 lr 5.72933e-06 
09/22/2020 11:58:26 - INFO - volta.utils -   [GQA]: iter 285502 Ep: 9.69 loss 0.393 score 0.947 lr 5.72895e-06 
09/22/2020 11:58:43 - INFO - volta.utils -   [GQA]: iter 285522 Ep: 9.69 loss 0.391 score 0.938 lr 5.72857e-06 
09/22/2020 11:58:56 - INFO - volta.utils -   [GQA]: iter 285542 Ep: 9.69 loss 0.370 score 0.947 lr 5.72819e-06 
09/22/2020 11:59:15 - INFO - volta.utils -   [GQA]: iter 285562 Ep: 9.69 loss 0.379 score 0.942 lr 5.72782e-06 
09/22/2020 11:59:42 - INFO - volta.utils -   [GQA]: iter 285582 Ep: 9.69 loss 0.375 score 0.950 lr 5.72744e-06 
09/22/2020 12:00:03 - INFO - volta.utils -   [GQA]: iter 285602 Ep: 9.69 loss 0.401 score 0.933 lr 5.72706e-06 
09/22/2020 12:00:16 - INFO - volta.utils -   [GQA]: iter 285622 Ep: 9.69 loss 0.422 score 0.930 lr 5.72669e-06 
09/22/2020 12:00:32 - INFO - volta.utils -   [GQA]: iter 285642 Ep: 9.69 loss 0.391 score 0.936 lr 5.72631e-06 
09/22/2020 12:00:40 - INFO - volta.utils -   [GQA]: iter 285662 Ep: 9.69 loss 0.343 score 0.950 lr 5.72593e-06 
09/22/2020 12:01:00 - INFO - volta.utils -   [GQA]: iter 285682 Ep: 9.69 loss 0.392 score 0.936 lr 5.72556e-06 
09/22/2020 12:01:26 - INFO - volta.utils -   [GQA]: iter 285702 Ep: 9.70 loss 0.395 score 0.938 lr 5.72518e-06 
09/22/2020 12:01:34 - INFO - volta.utils -   [GQA]: iter 285722 Ep: 9.70 loss 0.390 score 0.934 lr 5.7248e-06 
09/22/2020 12:01:43 - INFO - volta.utils -   [GQA]: iter 285742 Ep: 9.70 loss 0.392 score 0.939 lr 5.72442e-06 
09/22/2020 12:02:02 - INFO - volta.utils -   [GQA]: iter 285762 Ep: 9.70 loss 0.351 score 0.938 lr 5.72405e-06 
09/22/2020 12:02:27 - INFO - volta.utils -   [GQA]: iter 285782 Ep: 9.70 loss 0.378 score 0.944 lr 5.72367e-06 
09/22/2020 12:02:52 - INFO - volta.utils -   [GQA]: iter 285802 Ep: 9.70 loss 0.363 score 0.945 lr 5.72329e-06 
09/22/2020 12:03:04 - INFO - volta.utils -   [GQA]: iter 285822 Ep: 9.70 loss 0.500 score 0.931 lr 5.72292e-06 
09/22/2020 12:03:12 - INFO - volta.utils -   [GQA]: iter 285842 Ep: 9.70 loss 0.370 score 0.936 lr 5.72254e-06 
09/22/2020 12:03:24 - INFO - volta.utils -   [GQA]: iter 285862 Ep: 9.70 loss 0.380 score 0.934 lr 5.72216e-06 
09/22/2020 12:03:33 - INFO - volta.utils -   [GQA]: iter 285882 Ep: 9.70 loss 0.335 score 0.950 lr 5.72178e-06 
09/22/2020 12:03:56 - INFO - volta.utils -   [GQA]: iter 285902 Ep: 9.70 loss 0.354 score 0.945 lr 5.72141e-06 
09/22/2020 12:04:18 - INFO - volta.utils -   [GQA]: iter 285922 Ep: 9.70 loss 0.417 score 0.936 lr 5.72103e-06 
09/22/2020 12:04:41 - INFO - volta.utils -   [GQA]: iter 285942 Ep: 9.70 loss 0.445 score 0.931 lr 5.72065e-06 
09/22/2020 12:04:52 - INFO - volta.utils -   [GQA]: iter 285962 Ep: 9.70 loss 0.405 score 0.928 lr 5.72028e-06 
09/22/2020 12:05:08 - INFO - volta.utils -   [GQA]: iter 285982 Ep: 9.70 loss 0.357 score 0.944 lr 5.7199e-06 
09/22/2020 12:05:25 - INFO - volta.utils -   [GQA]: iter 286002 Ep: 9.71 loss 0.426 score 0.934 lr 5.71952e-06 
09/22/2020 12:05:36 - INFO - volta.utils -   [GQA]: iter 286022 Ep: 9.71 loss 0.379 score 0.941 lr 5.71915e-06 
09/22/2020 12:05:46 - INFO - volta.utils -   [GQA]: iter 286042 Ep: 9.71 loss 0.444 score 0.923 lr 5.71877e-06 
09/22/2020 12:06:00 - INFO - volta.utils -   [GQA]: iter 286062 Ep: 9.71 loss 0.435 score 0.934 lr 5.71839e-06 
09/22/2020 12:06:19 - INFO - volta.utils -   [GQA]: iter 286082 Ep: 9.71 loss 0.395 score 0.936 lr 5.71801e-06 
09/22/2020 12:06:39 - INFO - volta.utils -   [GQA]: iter 286102 Ep: 9.71 loss 0.497 score 0.928 lr 5.71764e-06 
09/22/2020 12:06:56 - INFO - volta.utils -   [GQA]: iter 286122 Ep: 9.71 loss 0.349 score 0.945 lr 5.71726e-06 
09/22/2020 12:07:12 - INFO - volta.utils -   [GQA]: iter 286142 Ep: 9.71 loss 0.359 score 0.948 lr 5.71688e-06 
09/22/2020 12:07:21 - INFO - volta.utils -   [GQA]: iter 286162 Ep: 9.71 loss 0.409 score 0.938 lr 5.71651e-06 
09/22/2020 12:07:33 - INFO - volta.utils -   [GQA]: iter 286182 Ep: 9.71 loss 0.477 score 0.922 lr 5.71613e-06 
09/22/2020 12:07:50 - INFO - volta.utils -   [GQA]: iter 286202 Ep: 9.71 loss 0.411 score 0.934 lr 5.71575e-06 
09/22/2020 12:08:09 - INFO - volta.utils -   [GQA]: iter 286222 Ep: 9.71 loss 0.398 score 0.945 lr 5.71538e-06 
09/22/2020 12:08:31 - INFO - volta.utils -   [GQA]: iter 286242 Ep: 9.71 loss 0.449 score 0.917 lr 5.715e-06 
09/22/2020 12:08:51 - INFO - volta.utils -   [GQA]: iter 286262 Ep: 9.71 loss 0.379 score 0.938 lr 5.71462e-06 
09/22/2020 12:09:08 - INFO - volta.utils -   [GQA]: iter 286282 Ep: 9.71 loss 0.349 score 0.934 lr 5.71424e-06 
09/22/2020 12:09:18 - INFO - volta.utils -   [GQA]: iter 286302 Ep: 9.72 loss 0.417 score 0.928 lr 5.71387e-06 
09/22/2020 12:09:26 - INFO - volta.utils -   [GQA]: iter 286322 Ep: 9.72 loss 0.314 score 0.950 lr 5.71349e-06 
09/22/2020 12:09:42 - INFO - volta.utils -   [GQA]: iter 286342 Ep: 9.72 loss 0.374 score 0.942 lr 5.71311e-06 
09/22/2020 12:09:58 - INFO - volta.utils -   [GQA]: iter 286362 Ep: 9.72 loss 0.384 score 0.941 lr 5.71274e-06 
09/22/2020 12:10:07 - INFO - volta.utils -   [GQA]: iter 286382 Ep: 9.72 loss 0.411 score 0.933 lr 5.71236e-06 
09/22/2020 12:10:20 - INFO - volta.utils -   [GQA]: iter 286402 Ep: 9.72 loss 0.308 score 0.956 lr 5.71198e-06 
09/22/2020 12:10:39 - INFO - volta.utils -   [GQA]: iter 286422 Ep: 9.72 loss 0.492 score 0.933 lr 5.7116e-06 
09/22/2020 12:11:00 - INFO - volta.utils -   [GQA]: iter 286442 Ep: 9.72 loss 0.351 score 0.938 lr 5.71123e-06 
09/22/2020 12:11:11 - INFO - volta.utils -   [GQA]: iter 286462 Ep: 9.72 loss 0.374 score 0.941 lr 5.71085e-06 
09/22/2020 12:11:27 - INFO - volta.utils -   [GQA]: iter 286482 Ep: 9.72 loss 0.355 score 0.948 lr 5.71047e-06 
09/22/2020 12:11:48 - INFO - volta.utils -   [GQA]: iter 286502 Ep: 9.72 loss 0.333 score 0.955 lr 5.7101e-06 
09/22/2020 12:12:12 - INFO - volta.utils -   [GQA]: iter 286522 Ep: 9.72 loss 0.427 score 0.931 lr 5.70972e-06 
09/22/2020 12:12:24 - INFO - volta.utils -   [GQA]: iter 286542 Ep: 9.72 loss 0.409 score 0.928 lr 5.70934e-06 
09/22/2020 12:12:32 - INFO - volta.utils -   [GQA]: iter 286562 Ep: 9.72 loss 0.431 score 0.923 lr 5.70897e-06 
09/22/2020 12:12:41 - INFO - volta.utils -   [GQA]: iter 286582 Ep: 9.72 loss 0.406 score 0.928 lr 5.70859e-06 
09/22/2020 12:12:59 - INFO - volta.utils -   [GQA]: iter 286602 Ep: 9.73 loss 0.417 score 0.930 lr 5.70821e-06 
09/22/2020 12:13:12 - INFO - volta.utils -   [GQA]: iter 286622 Ep: 9.73 loss 0.463 score 0.922 lr 5.70783e-06 
09/22/2020 12:13:19 - INFO - volta.utils -   [GQA]: iter 286642 Ep: 9.73 loss 0.427 score 0.933 lr 5.70746e-06 
09/22/2020 12:13:35 - INFO - volta.utils -   [GQA]: iter 286662 Ep: 9.73 loss 0.478 score 0.936 lr 5.70708e-06 
09/22/2020 12:13:53 - INFO - volta.utils -   [GQA]: iter 286682 Ep: 9.73 loss 0.309 score 0.955 lr 5.7067e-06 
09/22/2020 12:14:10 - INFO - volta.utils -   [GQA]: iter 286702 Ep: 9.73 loss 0.370 score 0.942 lr 5.70633e-06 
09/22/2020 12:14:38 - INFO - volta.utils -   [GQA]: iter 286722 Ep: 9.73 loss 0.347 score 0.938 lr 5.70595e-06 
09/22/2020 12:14:45 - INFO - volta.utils -   [GQA]: iter 286742 Ep: 9.73 loss 0.386 score 0.936 lr 5.70557e-06 
09/22/2020 12:14:53 - INFO - volta.utils -   [GQA]: iter 286762 Ep: 9.73 loss 0.399 score 0.945 lr 5.70519e-06 
09/22/2020 12:15:01 - INFO - volta.utils -   [GQA]: iter 286782 Ep: 9.73 loss 0.324 score 0.948 lr 5.70482e-06 
09/22/2020 12:15:23 - INFO - volta.utils -   [GQA]: iter 286802 Ep: 9.73 loss 0.379 score 0.947 lr 5.70444e-06 
09/22/2020 12:15:49 - INFO - volta.utils -   [GQA]: iter 286822 Ep: 9.73 loss 0.360 score 0.947 lr 5.70406e-06 
09/22/2020 12:16:03 - INFO - volta.utils -   [GQA]: iter 286842 Ep: 9.73 loss 0.373 score 0.938 lr 5.70369e-06 
09/22/2020 12:16:15 - INFO - volta.utils -   [GQA]: iter 286862 Ep: 9.73 loss 0.365 score 0.952 lr 5.70331e-06 
09/22/2020 12:16:23 - INFO - volta.utils -   [GQA]: iter 286882 Ep: 9.74 loss 0.433 score 0.930 lr 5.70293e-06 
09/22/2020 12:16:32 - INFO - volta.utils -   [GQA]: iter 286902 Ep: 9.74 loss 0.364 score 0.936 lr 5.70256e-06 
09/22/2020 12:16:43 - INFO - volta.utils -   [GQA]: iter 286922 Ep: 9.74 loss 0.340 score 0.948 lr 5.70218e-06 
09/22/2020 12:17:01 - INFO - volta.utils -   [GQA]: iter 286942 Ep: 9.74 loss 0.334 score 0.947 lr 5.7018e-06 
09/22/2020 12:17:13 - INFO - volta.utils -   [GQA]: iter 286962 Ep: 9.74 loss 0.385 score 0.947 lr 5.70142e-06 
09/22/2020 12:17:21 - INFO - volta.utils -   [GQA]: iter 286982 Ep: 9.74 loss 0.427 score 0.927 lr 5.70105e-06 
09/22/2020 12:17:31 - INFO - volta.utils -   [GQA]: iter 287002 Ep: 9.74 loss 0.460 score 0.919 lr 5.70067e-06 
09/22/2020 12:17:57 - INFO - volta.utils -   [GQA]: iter 287022 Ep: 9.74 loss 0.373 score 0.942 lr 5.70029e-06 
09/22/2020 12:18:12 - INFO - volta.utils -   [GQA]: iter 287042 Ep: 9.74 loss 0.444 score 0.919 lr 5.69992e-06 
09/22/2020 12:18:27 - INFO - volta.utils -   [GQA]: iter 287062 Ep: 9.74 loss 0.370 score 0.942 lr 5.69954e-06 
09/22/2020 12:18:37 - INFO - volta.utils -   [GQA]: iter 287082 Ep: 9.74 loss 0.403 score 0.938 lr 5.69916e-06 
09/22/2020 12:18:52 - INFO - volta.utils -   [GQA]: iter 287102 Ep: 9.74 loss 0.339 score 0.942 lr 5.69879e-06 
09/22/2020 12:19:03 - INFO - volta.utils -   [GQA]: iter 287122 Ep: 9.74 loss 0.410 score 0.927 lr 5.69841e-06 
09/22/2020 12:19:12 - INFO - volta.utils -   [GQA]: iter 287142 Ep: 9.74 loss 0.395 score 0.936 lr 5.69803e-06 
09/22/2020 12:19:21 - INFO - volta.utils -   [GQA]: iter 287162 Ep: 9.74 loss 0.308 score 0.950 lr 5.69765e-06 
09/22/2020 12:19:41 - INFO - volta.utils -   [GQA]: iter 287182 Ep: 9.75 loss 0.370 score 0.942 lr 5.69728e-06 
09/22/2020 12:19:57 - INFO - volta.utils -   [GQA]: iter 287202 Ep: 9.75 loss 0.394 score 0.936 lr 5.6969e-06 
09/22/2020 12:20:07 - INFO - volta.utils -   [GQA]: iter 287222 Ep: 9.75 loss 0.386 score 0.939 lr 5.69652e-06 
09/22/2020 12:20:18 - INFO - volta.utils -   [GQA]: iter 287242 Ep: 9.75 loss 0.441 score 0.920 lr 5.69615e-06 
09/22/2020 12:20:41 - INFO - volta.utils -   [GQA]: iter 287262 Ep: 9.75 loss 0.414 score 0.925 lr 5.69577e-06 
09/22/2020 12:21:00 - INFO - volta.utils -   [GQA]: iter 287282 Ep: 9.75 loss 0.481 score 0.919 lr 5.69539e-06 
09/22/2020 12:21:11 - INFO - volta.utils -   [GQA]: iter 287302 Ep: 9.75 loss 0.360 score 0.944 lr 5.69501e-06 
09/22/2020 12:21:21 - INFO - volta.utils -   [GQA]: iter 287322 Ep: 9.75 loss 0.360 score 0.941 lr 5.69464e-06 
09/22/2020 12:21:39 - INFO - volta.utils -   [GQA]: iter 287342 Ep: 9.75 loss 0.426 score 0.922 lr 5.69426e-06 
09/22/2020 12:22:00 - INFO - volta.utils -   [GQA]: iter 287362 Ep: 9.75 loss 0.366 score 0.948 lr 5.69388e-06 
09/22/2020 12:22:08 - INFO - volta.utils -   [GQA]: iter 287382 Ep: 9.75 loss 0.386 score 0.936 lr 5.69351e-06 
09/22/2020 12:22:39 - INFO - volta.utils -   [GQA]: iter 287402 Ep: 9.75 loss 0.328 score 0.936 lr 5.69313e-06 
09/22/2020 12:23:00 - INFO - volta.utils -   [GQA]: iter 287422 Ep: 9.75 loss 0.370 score 0.950 lr 5.69275e-06 
09/22/2020 12:23:17 - INFO - volta.utils -   [GQA]: iter 287442 Ep: 9.75 loss 0.409 score 0.941 lr 5.69238e-06 
09/22/2020 12:23:31 - INFO - volta.utils -   [GQA]: iter 287462 Ep: 9.75 loss 0.356 score 0.952 lr 5.692e-06 
09/22/2020 12:23:38 - INFO - volta.utils -   [GQA]: iter 287482 Ep: 9.76 loss 0.374 score 0.941 lr 5.69162e-06 
09/22/2020 12:23:47 - INFO - volta.utils -   [GQA]: iter 287502 Ep: 9.76 loss 0.360 score 0.945 lr 5.69124e-06 
09/22/2020 12:24:05 - INFO - volta.utils -   [GQA]: iter 287522 Ep: 9.76 loss 0.403 score 0.930 lr 5.69087e-06 
09/22/2020 12:24:26 - INFO - volta.utils -   [GQA]: iter 287542 Ep: 9.76 loss 0.413 score 0.944 lr 5.69049e-06 
09/22/2020 12:24:37 - INFO - volta.utils -   [GQA]: iter 287562 Ep: 9.76 loss 0.356 score 0.941 lr 5.69011e-06 
09/22/2020 12:24:49 - INFO - volta.utils -   [GQA]: iter 287582 Ep: 9.76 loss 0.392 score 0.939 lr 5.68974e-06 
09/22/2020 12:25:10 - INFO - volta.utils -   [GQA]: iter 287602 Ep: 9.76 loss 0.323 score 0.947 lr 5.68936e-06 
09/22/2020 12:25:18 - INFO - volta.utils -   [GQA]: iter 287622 Ep: 9.76 loss 0.462 score 0.928 lr 5.68898e-06 
09/22/2020 12:25:26 - INFO - volta.utils -   [GQA]: iter 287642 Ep: 9.76 loss 0.374 score 0.936 lr 5.6886e-06 
09/22/2020 12:25:52 - INFO - volta.utils -   [GQA]: iter 287662 Ep: 9.76 loss 0.504 score 0.909 lr 5.68823e-06 
09/22/2020 12:26:13 - INFO - volta.utils -   [GQA]: iter 287682 Ep: 9.76 loss 0.393 score 0.936 lr 5.68785e-06 
09/22/2020 12:26:24 - INFO - volta.utils -   [GQA]: iter 287702 Ep: 9.76 loss 0.439 score 0.920 lr 5.68747e-06 
09/22/2020 12:26:42 - INFO - volta.utils -   [GQA]: iter 287722 Ep: 9.76 loss 0.489 score 0.919 lr 5.6871e-06 
09/22/2020 12:26:51 - INFO - volta.utils -   [GQA]: iter 287742 Ep: 9.76 loss 0.349 score 0.953 lr 5.68672e-06 
09/22/2020 12:27:05 - INFO - volta.utils -   [GQA]: iter 287762 Ep: 9.76 loss 0.357 score 0.942 lr 5.68634e-06 
09/22/2020 12:27:12 - INFO - volta.utils -   [GQA]: iter 287782 Ep: 9.77 loss 0.367 score 0.939 lr 5.68597e-06 
09/22/2020 12:27:20 - INFO - volta.utils -   [GQA]: iter 287802 Ep: 9.77 loss 0.452 score 0.923 lr 5.68559e-06 
09/22/2020 12:27:40 - INFO - volta.utils -   [GQA]: iter 287822 Ep: 9.77 loss 0.319 score 0.947 lr 5.68521e-06 
09/22/2020 12:28:11 - INFO - volta.utils -   [GQA]: iter 287842 Ep: 9.77 loss 0.328 score 0.952 lr 5.68483e-06 
09/22/2020 12:28:30 - INFO - volta.utils -   [GQA]: iter 287862 Ep: 9.77 loss 0.367 score 0.934 lr 5.68446e-06 
09/22/2020 12:28:43 - INFO - volta.utils -   [GQA]: iter 287882 Ep: 9.77 loss 0.355 score 0.934 lr 5.68408e-06 
09/22/2020 12:28:51 - INFO - volta.utils -   [GQA]: iter 287902 Ep: 9.77 loss 0.343 score 0.948 lr 5.6837e-06 
09/22/2020 12:29:09 - INFO - volta.utils -   [GQA]: iter 287922 Ep: 9.77 loss 0.354 score 0.945 lr 5.68333e-06 
09/22/2020 12:29:38 - INFO - volta.utils -   [GQA]: iter 287942 Ep: 9.77 loss 0.343 score 0.952 lr 5.68295e-06 
09/22/2020 12:29:57 - INFO - volta.utils -   [GQA]: iter 287962 Ep: 9.77 loss 0.428 score 0.925 lr 5.68257e-06 
09/22/2020 12:30:13 - INFO - volta.utils -   [GQA]: iter 287982 Ep: 9.77 loss 0.367 score 0.948 lr 5.6822e-06 
09/22/2020 12:30:21 - INFO - volta.utils -   [GQA]: iter 288002 Ep: 9.77 loss 0.385 score 0.933 lr 5.68182e-06 
09/22/2020 12:30:33 - INFO - volta.utils -   [GQA]: iter 288022 Ep: 9.77 loss 0.351 score 0.947 lr 5.68144e-06 
09/22/2020 12:30:56 - INFO - volta.utils -   [GQA]: iter 288042 Ep: 9.77 loss 0.436 score 0.922 lr 5.68106e-06 
09/22/2020 12:31:17 - INFO - volta.utils -   [GQA]: iter 288062 Ep: 9.78 loss 0.309 score 0.952 lr 5.68069e-06 
09/22/2020 12:31:34 - INFO - volta.utils -   [GQA]: iter 288082 Ep: 9.78 loss 0.429 score 0.933 lr 5.68031e-06 
09/22/2020 12:31:56 - INFO - volta.utils -   [GQA]: iter 288102 Ep: 9.78 loss 0.336 score 0.947 lr 5.67993e-06 
09/22/2020 12:32:12 - INFO - volta.utils -   [GQA]: iter 288122 Ep: 9.78 loss 0.378 score 0.928 lr 5.67956e-06 
09/22/2020 12:32:24 - INFO - volta.utils -   [GQA]: iter 288142 Ep: 9.78 loss 0.391 score 0.939 lr 5.67918e-06 
09/22/2020 12:32:35 - INFO - volta.utils -   [GQA]: iter 288162 Ep: 9.78 loss 0.417 score 0.930 lr 5.6788e-06 
09/22/2020 12:32:52 - INFO - volta.utils -   [GQA]: iter 288182 Ep: 9.78 loss 0.375 score 0.944 lr 5.67842e-06 
09/22/2020 12:33:05 - INFO - volta.utils -   [GQA]: iter 288202 Ep: 9.78 loss 0.333 score 0.948 lr 5.67805e-06 
09/22/2020 12:33:19 - INFO - volta.utils -   [GQA]: iter 288222 Ep: 9.78 loss 0.359 score 0.945 lr 5.67767e-06 
09/22/2020 12:33:38 - INFO - volta.utils -   [GQA]: iter 288242 Ep: 9.78 loss 0.380 score 0.945 lr 5.67729e-06 
09/22/2020 12:33:47 - INFO - volta.utils -   [GQA]: iter 288262 Ep: 9.78 loss 0.334 score 0.934 lr 5.67692e-06 
09/22/2020 12:34:02 - INFO - volta.utils -   [GQA]: iter 288282 Ep: 9.78 loss 0.425 score 0.933 lr 5.67654e-06 
09/22/2020 12:34:09 - INFO - volta.utils -   [GQA]: iter 288302 Ep: 9.78 loss 0.356 score 0.938 lr 5.67616e-06 
09/22/2020 12:34:32 - INFO - volta.utils -   [GQA]: iter 288322 Ep: 9.78 loss 0.397 score 0.948 lr 5.67579e-06 
09/22/2020 12:34:56 - INFO - volta.utils -   [GQA]: iter 288342 Ep: 9.78 loss 0.408 score 0.936 lr 5.67541e-06 
09/22/2020 12:35:19 - INFO - volta.utils -   [GQA]: iter 288362 Ep: 9.79 loss 0.366 score 0.939 lr 5.67503e-06 
09/22/2020 12:35:30 - INFO - volta.utils -   [GQA]: iter 288382 Ep: 9.79 loss 0.379 score 0.928 lr 5.67465e-06 
09/22/2020 12:35:42 - INFO - volta.utils -   [GQA]: iter 288402 Ep: 9.79 loss 0.385 score 0.945 lr 5.67428e-06 
09/22/2020 12:35:52 - INFO - volta.utils -   [GQA]: iter 288422 Ep: 9.79 loss 0.376 score 0.942 lr 5.6739e-06 
09/22/2020 12:36:16 - INFO - volta.utils -   [GQA]: iter 288442 Ep: 9.79 loss 0.362 score 0.948 lr 5.67352e-06 
09/22/2020 12:36:25 - INFO - volta.utils -   [GQA]: iter 288462 Ep: 9.79 loss 0.434 score 0.925 lr 5.67315e-06 
09/22/2020 12:36:42 - INFO - volta.utils -   [GQA]: iter 288482 Ep: 9.79 loss 0.347 score 0.945 lr 5.67277e-06 
09/22/2020 12:36:57 - INFO - volta.utils -   [GQA]: iter 288502 Ep: 9.79 loss 0.376 score 0.947 lr 5.67239e-06 
09/22/2020 12:37:08 - INFO - volta.utils -   [GQA]: iter 288522 Ep: 9.79 loss 0.461 score 0.920 lr 5.67202e-06 
09/22/2020 12:37:18 - INFO - volta.utils -   [GQA]: iter 288542 Ep: 9.79 loss 0.369 score 0.947 lr 5.67164e-06 
09/22/2020 12:37:34 - INFO - volta.utils -   [GQA]: iter 288562 Ep: 9.79 loss 0.332 score 0.953 lr 5.67126e-06 
09/22/2020 12:37:42 - INFO - volta.utils -   [GQA]: iter 288582 Ep: 9.79 loss 0.317 score 0.955 lr 5.67088e-06 
09/22/2020 12:37:56 - INFO - volta.utils -   [GQA]: iter 288602 Ep: 9.79 loss 0.389 score 0.939 lr 5.67051e-06 
09/22/2020 12:38:14 - INFO - volta.utils -   [GQA]: iter 288622 Ep: 9.79 loss 0.396 score 0.925 lr 5.67013e-06 
09/22/2020 12:38:37 - INFO - volta.utils -   [GQA]: iter 288642 Ep: 9.79 loss 0.349 score 0.952 lr 5.66975e-06 
09/22/2020 12:38:57 - INFO - volta.utils -   [GQA]: iter 288662 Ep: 9.80 loss 0.291 score 0.952 lr 5.66938e-06 
09/22/2020 12:39:06 - INFO - volta.utils -   [GQA]: iter 288682 Ep: 9.80 loss 0.418 score 0.933 lr 5.669e-06 
09/22/2020 12:39:17 - INFO - volta.utils -   [GQA]: iter 288702 Ep: 9.80 loss 0.359 score 0.942 lr 5.66862e-06 
09/22/2020 12:39:38 - INFO - volta.utils -   [GQA]: iter 288722 Ep: 9.80 loss 0.361 score 0.938 lr 5.66824e-06 
09/22/2020 12:39:54 - INFO - volta.utils -   [GQA]: iter 288742 Ep: 9.80 loss 0.331 score 0.947 lr 5.66787e-06 
09/22/2020 12:40:03 - INFO - volta.utils -   [GQA]: iter 288762 Ep: 9.80 loss 0.405 score 0.933 lr 5.66749e-06 
09/22/2020 12:40:20 - INFO - volta.utils -   [GQA]: iter 288782 Ep: 9.80 loss 0.384 score 0.947 lr 5.66711e-06 
09/22/2020 12:40:31 - INFO - volta.utils -   [GQA]: iter 288802 Ep: 9.80 loss 0.441 score 0.925 lr 5.66674e-06 
09/22/2020 12:40:42 - INFO - volta.utils -   [GQA]: iter 288822 Ep: 9.80 loss 0.450 score 0.917 lr 5.66636e-06 
09/22/2020 12:40:50 - INFO - volta.utils -   [GQA]: iter 288842 Ep: 9.80 loss 0.305 score 0.958 lr 5.66598e-06 
09/22/2020 12:41:12 - INFO - volta.utils -   [GQA]: iter 288862 Ep: 9.80 loss 0.371 score 0.952 lr 5.66561e-06 
09/22/2020 12:41:19 - INFO - volta.utils -   [GQA]: iter 288882 Ep: 9.80 loss 0.369 score 0.931 lr 5.66523e-06 
09/22/2020 12:41:27 - INFO - volta.utils -   [GQA]: iter 288902 Ep: 9.80 loss 0.405 score 0.928 lr 5.66485e-06 
09/22/2020 12:41:38 - INFO - volta.utils -   [GQA]: iter 288922 Ep: 9.80 loss 0.350 score 0.947 lr 5.66447e-06 
09/22/2020 12:41:56 - INFO - volta.utils -   [GQA]: iter 288942 Ep: 9.80 loss 0.398 score 0.938 lr 5.6641e-06 
09/22/2020 12:42:20 - INFO - volta.utils -   [GQA]: iter 288962 Ep: 9.81 loss 0.423 score 0.939 lr 5.66372e-06 
09/22/2020 12:42:35 - INFO - volta.utils -   [GQA]: iter 288982 Ep: 9.81 loss 0.438 score 0.931 lr 5.66334e-06 
09/22/2020 12:42:49 - INFO - volta.utils -   [GQA]: iter 289002 Ep: 9.81 loss 0.362 score 0.947 lr 5.66297e-06 
09/22/2020 12:43:00 - INFO - volta.utils -   [GQA]: iter 289022 Ep: 9.81 loss 0.314 score 0.950 lr 5.66259e-06 
09/22/2020 12:43:08 - INFO - volta.utils -   [GQA]: iter 289042 Ep: 9.81 loss 0.420 score 0.931 lr 5.66221e-06 
09/22/2020 12:43:25 - INFO - volta.utils -   [GQA]: iter 289062 Ep: 9.81 loss 0.411 score 0.934 lr 5.66183e-06 
09/22/2020 12:43:44 - INFO - volta.utils -   [GQA]: iter 289082 Ep: 9.81 loss 0.416 score 0.936 lr 5.66146e-06 
09/22/2020 12:43:54 - INFO - volta.utils -   [GQA]: iter 289102 Ep: 9.81 loss 0.427 score 0.930 lr 5.66108e-06 
09/22/2020 12:44:03 - INFO - volta.utils -   [GQA]: iter 289122 Ep: 9.81 loss 0.361 score 0.934 lr 5.6607e-06 
09/22/2020 12:44:12 - INFO - volta.utils -   [GQA]: iter 289142 Ep: 9.81 loss 0.286 score 0.958 lr 5.66033e-06 
09/22/2020 12:44:30 - INFO - volta.utils -   [GQA]: iter 289162 Ep: 9.81 loss 0.298 score 0.956 lr 5.65995e-06 
09/22/2020 12:44:51 - INFO - volta.utils -   [GQA]: iter 289182 Ep: 9.81 loss 0.611 score 0.900 lr 5.65957e-06 
09/22/2020 12:45:07 - INFO - volta.utils -   [GQA]: iter 289202 Ep: 9.81 loss 0.381 score 0.936 lr 5.6592e-06 
09/22/2020 12:45:25 - INFO - volta.utils -   [GQA]: iter 289222 Ep: 9.81 loss 0.394 score 0.927 lr 5.65882e-06 
09/22/2020 12:45:36 - INFO - volta.utils -   [GQA]: iter 289242 Ep: 9.82 loss 0.333 score 0.944 lr 5.65844e-06 
09/22/2020 12:45:49 - INFO - volta.utils -   [GQA]: iter 289262 Ep: 9.82 loss 0.350 score 0.939 lr 5.65806e-06 
09/22/2020 12:45:58 - INFO - volta.utils -   [GQA]: iter 289282 Ep: 9.82 loss 0.437 score 0.931 lr 5.65769e-06 
09/22/2020 12:46:26 - INFO - volta.utils -   [GQA]: iter 289302 Ep: 9.82 loss 0.397 score 0.948 lr 5.65731e-06 
09/22/2020 12:46:46 - INFO - volta.utils -   [GQA]: iter 289322 Ep: 9.82 loss 0.378 score 0.945 lr 5.65693e-06 
09/22/2020 12:47:00 - INFO - volta.utils -   [GQA]: iter 289342 Ep: 9.82 loss 0.379 score 0.938 lr 5.65656e-06 
09/22/2020 12:47:12 - INFO - volta.utils -   [GQA]: iter 289362 Ep: 9.82 loss 0.334 score 0.952 lr 5.65618e-06 
09/22/2020 12:47:30 - INFO - volta.utils -   [GQA]: iter 289382 Ep: 9.82 loss 0.276 score 0.959 lr 5.6558e-06 
09/22/2020 12:47:39 - INFO - volta.utils -   [GQA]: iter 289402 Ep: 9.82 loss 0.430 score 0.938 lr 5.65543e-06 
09/22/2020 12:47:46 - INFO - volta.utils -   [GQA]: iter 289422 Ep: 9.82 loss 0.448 score 0.930 lr 5.65505e-06 
09/22/2020 12:47:56 - INFO - volta.utils -   [GQA]: iter 289442 Ep: 9.82 loss 0.357 score 0.944 lr 5.65467e-06 
09/22/2020 12:48:32 - INFO - volta.utils -   [GQA]: iter 289462 Ep: 9.82 loss 0.376 score 0.938 lr 5.65429e-06 
09/22/2020 12:48:53 - INFO - volta.utils -   [GQA]: iter 289482 Ep: 9.82 loss 0.318 score 0.952 lr 5.65392e-06 
09/22/2020 12:49:02 - INFO - volta.utils -   [GQA]: iter 289502 Ep: 9.82 loss 0.348 score 0.933 lr 5.65354e-06 
09/22/2020 12:49:15 - INFO - volta.utils -   [GQA]: iter 289522 Ep: 9.82 loss 0.286 score 0.952 lr 5.65316e-06 
09/22/2020 12:49:43 - INFO - volta.utils -   [GQA]: iter 289542 Ep: 9.83 loss 0.453 score 0.917 lr 5.65279e-06 
09/22/2020 12:49:53 - INFO - volta.utils -   [GQA]: iter 289562 Ep: 9.83 loss 0.419 score 0.944 lr 5.65241e-06 
09/22/2020 12:50:10 - INFO - volta.utils -   [GQA]: iter 289582 Ep: 9.83 loss 0.377 score 0.945 lr 5.65203e-06 
09/22/2020 12:50:23 - INFO - volta.utils -   [GQA]: iter 289602 Ep: 9.83 loss 0.356 score 0.955 lr 5.65165e-06 
09/22/2020 12:50:36 - INFO - volta.utils -   [GQA]: iter 289622 Ep: 9.83 loss 0.385 score 0.942 lr 5.65128e-06 
09/22/2020 12:50:48 - INFO - volta.utils -   [GQA]: iter 289642 Ep: 9.83 loss 0.371 score 0.936 lr 5.6509e-06 
09/22/2020 12:51:02 - INFO - volta.utils -   [GQA]: iter 289662 Ep: 9.83 loss 0.351 score 0.948 lr 5.65052e-06 
09/22/2020 12:51:21 - INFO - volta.utils -   [GQA]: iter 289682 Ep: 9.83 loss 0.417 score 0.936 lr 5.65015e-06 
09/22/2020 12:51:33 - INFO - volta.utils -   [GQA]: iter 289702 Ep: 9.83 loss 0.418 score 0.930 lr 5.64977e-06 
09/22/2020 12:51:47 - INFO - volta.utils -   [GQA]: iter 289722 Ep: 9.83 loss 0.365 score 0.938 lr 5.64939e-06 
09/22/2020 12:51:56 - INFO - volta.utils -   [GQA]: iter 289742 Ep: 9.83 loss 0.353 score 0.945 lr 5.64902e-06 
09/22/2020 12:52:03 - INFO - volta.utils -   [GQA]: iter 289762 Ep: 9.83 loss 0.426 score 0.936 lr 5.64864e-06 
09/22/2020 12:52:15 - INFO - volta.utils -   [GQA]: iter 289782 Ep: 9.83 loss 0.326 score 0.947 lr 5.64826e-06 
09/22/2020 12:52:34 - INFO - volta.utils -   [GQA]: iter 289802 Ep: 9.83 loss 0.299 score 0.950 lr 5.64788e-06 
09/22/2020 12:52:50 - INFO - volta.utils -   [GQA]: iter 289822 Ep: 9.83 loss 0.395 score 0.941 lr 5.64751e-06 
09/22/2020 12:52:58 - INFO - volta.utils -   [GQA]: iter 289842 Ep: 9.84 loss 0.432 score 0.939 lr 5.64713e-06 
09/22/2020 12:53:11 - INFO - volta.utils -   [GQA]: iter 289862 Ep: 9.84 loss 0.434 score 0.925 lr 5.64675e-06 
09/22/2020 12:53:31 - INFO - volta.utils -   [GQA]: iter 289882 Ep: 9.84 loss 0.334 score 0.941 lr 5.64638e-06 
09/22/2020 12:53:59 - INFO - volta.utils -   [GQA]: iter 289902 Ep: 9.84 loss 0.420 score 0.941 lr 5.646e-06 
09/22/2020 12:54:12 - INFO - volta.utils -   [GQA]: iter 289922 Ep: 9.84 loss 0.421 score 0.927 lr 5.64562e-06 
09/22/2020 12:54:21 - INFO - volta.utils -   [GQA]: iter 289942 Ep: 9.84 loss 0.399 score 0.931 lr 5.64524e-06 
09/22/2020 12:54:32 - INFO - volta.utils -   [GQA]: iter 289962 Ep: 9.84 loss 0.328 score 0.953 lr 5.64487e-06 
09/22/2020 12:54:50 - INFO - volta.utils -   [GQA]: iter 289982 Ep: 9.84 loss 0.393 score 0.938 lr 5.64449e-06 
09/22/2020 12:55:10 - INFO - volta.utils -   [GQA]: iter 290002 Ep: 9.84 loss 0.392 score 0.942 lr 5.64411e-06 
09/22/2020 12:55:29 - INFO - volta.utils -   [GQA]: iter 290022 Ep: 9.84 loss 0.355 score 0.950 lr 5.64374e-06 
09/22/2020 12:55:46 - INFO - volta.utils -   [GQA]: iter 290042 Ep: 9.84 loss 0.381 score 0.944 lr 5.64336e-06 
09/22/2020 12:55:59 - INFO - volta.utils -   [GQA]: iter 290062 Ep: 9.84 loss 0.414 score 0.931 lr 5.64298e-06 
09/22/2020 12:56:22 - INFO - volta.utils -   [GQA]: iter 290082 Ep: 9.84 loss 0.420 score 0.936 lr 5.64261e-06 
09/22/2020 12:56:43 - INFO - volta.utils -   [GQA]: iter 290102 Ep: 9.84 loss 0.264 score 0.955 lr 5.64223e-06 
09/22/2020 12:57:17 - INFO - volta.utils -   [GQA]: iter 290122 Ep: 9.84 loss 0.387 score 0.933 lr 5.64185e-06 
09/22/2020 12:57:56 - INFO - volta.utils -   [GQA]: iter 290142 Ep: 9.85 loss 0.391 score 0.941 lr 5.64147e-06 
09/22/2020 12:58:26 - INFO - volta.utils -   [GQA]: iter 290162 Ep: 9.85 loss 0.466 score 0.931 lr 5.6411e-06 
09/22/2020 12:58:41 - INFO - volta.utils -   [GQA]: iter 290182 Ep: 9.85 loss 0.405 score 0.933 lr 5.64072e-06 
09/22/2020 12:58:59 - INFO - volta.utils -   [GQA]: iter 290202 Ep: 9.85 loss 0.296 score 0.959 lr 5.64034e-06 
09/22/2020 12:59:10 - INFO - volta.utils -   [GQA]: iter 290222 Ep: 9.85 loss 0.393 score 0.942 lr 5.63997e-06 
09/22/2020 12:59:34 - INFO - volta.utils -   [GQA]: iter 290242 Ep: 9.85 loss 0.386 score 0.944 lr 5.63959e-06 
09/22/2020 12:59:45 - INFO - volta.utils -   [GQA]: iter 290262 Ep: 9.85 loss 0.437 score 0.934 lr 5.63921e-06 
09/22/2020 13:00:00 - INFO - volta.utils -   [GQA]: iter 290282 Ep: 9.85 loss 0.365 score 0.947 lr 5.63884e-06 
09/22/2020 13:00:35 - INFO - volta.utils -   [GQA]: iter 290302 Ep: 9.85 loss 0.352 score 0.952 lr 5.63846e-06 
09/22/2020 13:00:45 - INFO - volta.utils -   [GQA]: iter 290322 Ep: 9.85 loss 0.357 score 0.952 lr 5.63808e-06 
09/22/2020 13:01:08 - INFO - volta.utils -   [GQA]: iter 290342 Ep: 9.85 loss 0.307 score 0.955 lr 5.6377e-06 
09/22/2020 13:01:32 - INFO - volta.utils -   [GQA]: iter 290362 Ep: 9.85 loss 0.433 score 0.934 lr 5.63733e-06 
09/22/2020 13:02:19 - INFO - volta.utils -   [GQA]: iter 290382 Ep: 9.85 loss 0.418 score 0.928 lr 5.63695e-06 
09/22/2020 13:02:47 - INFO - volta.utils -   [GQA]: iter 290402 Ep: 9.85 loss 0.395 score 0.942 lr 5.63657e-06 
09/22/2020 13:03:17 - INFO - volta.utils -   [GQA]: iter 290422 Ep: 9.86 loss 0.313 score 0.945 lr 5.6362e-06 
09/22/2020 13:03:34 - INFO - volta.utils -   [GQA]: iter 290442 Ep: 9.86 loss 0.361 score 0.939 lr 5.63582e-06 
09/22/2020 13:04:32 - INFO - volta.utils -   [GQA]: iter 290462 Ep: 9.86 loss 0.406 score 0.939 lr 5.63544e-06 
09/22/2020 13:04:51 - INFO - volta.utils -   [GQA]: iter 290482 Ep: 9.86 loss 0.374 score 0.944 lr 5.63506e-06 
09/22/2020 13:05:07 - INFO - volta.utils -   [GQA]: iter 290502 Ep: 9.86 loss 0.396 score 0.938 lr 5.63469e-06 
09/22/2020 13:05:25 - INFO - volta.utils -   [GQA]: iter 290522 Ep: 9.86 loss 0.294 score 0.955 lr 5.63431e-06 
09/22/2020 13:05:46 - INFO - volta.utils -   [GQA]: iter 290542 Ep: 9.86 loss 0.489 score 0.906 lr 5.63393e-06 
09/22/2020 13:06:19 - INFO - volta.utils -   [GQA]: iter 290562 Ep: 9.86 loss 0.336 score 0.939 lr 5.63356e-06 
09/22/2020 13:06:49 - INFO - volta.utils -   [GQA]: iter 290582 Ep: 9.86 loss 0.450 score 0.925 lr 5.63318e-06 
09/22/2020 13:07:16 - INFO - volta.utils -   [GQA]: iter 290602 Ep: 9.86 loss 0.409 score 0.922 lr 5.6328e-06 
09/22/2020 13:07:35 - INFO - volta.utils -   [GQA]: iter 290622 Ep: 9.86 loss 0.332 score 0.948 lr 5.63243e-06 
09/22/2020 13:07:51 - INFO - volta.utils -   [GQA]: iter 290642 Ep: 9.86 loss 0.384 score 0.936 lr 5.63205e-06 
09/22/2020 13:08:16 - INFO - volta.utils -   [GQA]: iter 290662 Ep: 9.86 loss 0.355 score 0.952 lr 5.63167e-06 
09/22/2020 13:08:52 - INFO - volta.utils -   [GQA]: iter 290682 Ep: 9.86 loss 0.361 score 0.947 lr 5.63129e-06 
09/22/2020 13:09:00 - INFO - volta.utils -   [GQA]: iter 290702 Ep: 9.86 loss 0.331 score 0.944 lr 5.63092e-06 
09/22/2020 13:09:28 - INFO - volta.utils -   [GQA]: iter 290722 Ep: 9.87 loss 0.389 score 0.942 lr 5.63054e-06 
09/22/2020 13:09:45 - INFO - volta.utils -   [GQA]: iter 290742 Ep: 9.87 loss 0.357 score 0.939 lr 5.63016e-06 
09/22/2020 13:10:05 - INFO - volta.utils -   [GQA]: iter 290762 Ep: 9.87 loss 0.406 score 0.933 lr 5.62979e-06 
09/22/2020 13:10:26 - INFO - volta.utils -   [GQA]: iter 290782 Ep: 9.87 loss 0.353 score 0.936 lr 5.62941e-06 
09/22/2020 13:10:54 - INFO - volta.utils -   [GQA]: iter 290802 Ep: 9.87 loss 0.425 score 0.923 lr 5.62903e-06 
09/22/2020 13:11:09 - INFO - volta.utils -   [GQA]: iter 290822 Ep: 9.87 loss 0.331 score 0.944 lr 5.62865e-06 
09/22/2020 13:11:20 - INFO - volta.utils -   [GQA]: iter 290842 Ep: 9.87 loss 0.314 score 0.955 lr 5.62828e-06 
09/22/2020 13:11:40 - INFO - volta.utils -   [GQA]: iter 290862 Ep: 9.87 loss 0.349 score 0.953 lr 5.6279e-06 
09/22/2020 13:11:51 - INFO - volta.utils -   [GQA]: iter 290882 Ep: 9.87 loss 0.414 score 0.938 lr 5.62752e-06 
09/22/2020 13:12:13 - INFO - volta.utils -   [GQA]: iter 290902 Ep: 9.87 loss 0.444 score 0.923 lr 5.62715e-06 
09/22/2020 13:12:21 - INFO - volta.utils -   [GQA]: iter 290922 Ep: 9.87 loss 0.370 score 0.953 lr 5.62677e-06 
09/22/2020 13:12:36 - INFO - volta.utils -   [GQA]: iter 290942 Ep: 9.87 loss 0.419 score 0.922 lr 5.62639e-06 
09/22/2020 13:12:59 - INFO - volta.utils -   [GQA]: iter 290962 Ep: 9.87 loss 0.445 score 0.933 lr 5.62602e-06 
09/22/2020 13:13:20 - INFO - volta.utils -   [GQA]: iter 290982 Ep: 9.87 loss 0.405 score 0.938 lr 5.62564e-06 
09/22/2020 13:13:37 - INFO - volta.utils -   [GQA]: iter 291002 Ep: 9.87 loss 0.426 score 0.934 lr 5.62526e-06 
09/22/2020 13:13:48 - INFO - volta.utils -   [GQA]: iter 291022 Ep: 9.88 loss 0.309 score 0.955 lr 5.62488e-06 
09/22/2020 13:14:01 - INFO - volta.utils -   [GQA]: iter 291042 Ep: 9.88 loss 0.323 score 0.955 lr 5.62451e-06 
09/22/2020 13:14:08 - INFO - volta.utils -   [GQA]: iter 291062 Ep: 9.88 loss 0.397 score 0.933 lr 5.62413e-06 
09/22/2020 13:14:23 - INFO - volta.utils -   [GQA]: iter 291082 Ep: 9.88 loss 0.431 score 0.934 lr 5.62375e-06 
09/22/2020 13:14:35 - INFO - volta.utils -   [GQA]: iter 291102 Ep: 9.88 loss 0.402 score 0.925 lr 5.62338e-06 
09/22/2020 13:14:56 - INFO - volta.utils -   [GQA]: iter 291122 Ep: 9.88 loss 0.374 score 0.941 lr 5.623e-06 
09/22/2020 13:15:04 - INFO - volta.utils -   [GQA]: iter 291142 Ep: 9.88 loss 0.478 score 0.922 lr 5.62262e-06 
09/22/2020 13:15:34 - INFO - volta.utils -   [GQA]: iter 291162 Ep: 9.88 loss 0.432 score 0.931 lr 5.62225e-06 
09/22/2020 13:15:52 - INFO - volta.utils -   [GQA]: iter 291182 Ep: 9.88 loss 0.404 score 0.930 lr 5.62187e-06 
09/22/2020 13:16:07 - INFO - volta.utils -   [GQA]: iter 291202 Ep: 9.88 loss 0.323 score 0.948 lr 5.62149e-06 
09/22/2020 13:16:19 - INFO - volta.utils -   [GQA]: iter 291222 Ep: 9.88 loss 0.347 score 0.945 lr 5.62111e-06 
09/22/2020 13:16:27 - INFO - volta.utils -   [GQA]: iter 291242 Ep: 9.88 loss 0.393 score 0.930 lr 5.62074e-06 
09/22/2020 13:16:43 - INFO - volta.utils -   [GQA]: iter 291262 Ep: 9.88 loss 0.436 score 0.936 lr 5.62036e-06 
09/22/2020 13:16:59 - INFO - volta.utils -   [GQA]: iter 291282 Ep: 9.88 loss 0.383 score 0.945 lr 5.61998e-06 
09/22/2020 13:17:23 - INFO - volta.utils -   [GQA]: iter 291302 Ep: 9.89 loss 0.350 score 0.939 lr 5.61961e-06 
09/22/2020 13:17:46 - INFO - volta.utils -   [GQA]: iter 291322 Ep: 9.89 loss 0.317 score 0.955 lr 5.61923e-06 
09/22/2020 13:18:07 - INFO - volta.utils -   [GQA]: iter 291342 Ep: 9.89 loss 0.335 score 0.945 lr 5.61885e-06 
09/22/2020 13:18:26 - INFO - volta.utils -   [GQA]: iter 291362 Ep: 9.89 loss 0.404 score 0.933 lr 5.61847e-06 
09/22/2020 13:18:53 - INFO - volta.utils -   [GQA]: iter 291382 Ep: 9.89 loss 0.434 score 0.931 lr 5.6181e-06 
09/22/2020 13:19:35 - INFO - volta.utils -   [GQA]: iter 291402 Ep: 9.89 loss 0.342 score 0.952 lr 5.61772e-06 
09/22/2020 13:19:54 - INFO - volta.utils -   [GQA]: iter 291422 Ep: 9.89 loss 0.410 score 0.923 lr 5.61734e-06 
09/22/2020 13:20:19 - INFO - volta.utils -   [GQA]: iter 291442 Ep: 9.89 loss 0.359 score 0.939 lr 5.61697e-06 
09/22/2020 13:20:34 - INFO - volta.utils -   [GQA]: iter 291462 Ep: 9.89 loss 0.341 score 0.944 lr 5.61659e-06 
09/22/2020 13:20:47 - INFO - volta.utils -   [GQA]: iter 291482 Ep: 9.89 loss 0.337 score 0.947 lr 5.61621e-06 
09/22/2020 13:21:09 - INFO - volta.utils -   [GQA]: iter 291502 Ep: 9.89 loss 0.418 score 0.945 lr 5.61584e-06 
09/22/2020 13:21:33 - INFO - volta.utils -   [GQA]: iter 291522 Ep: 9.89 loss 0.313 score 0.947 lr 5.61546e-06 
09/22/2020 13:22:03 - INFO - volta.utils -   [GQA]: iter 291542 Ep: 9.89 loss 0.312 score 0.955 lr 5.61508e-06 
09/22/2020 13:22:10 - INFO - volta.utils -   [GQA]: iter 291562 Ep: 9.89 loss 0.341 score 0.953 lr 5.6147e-06 
09/22/2020 13:22:44 - INFO - volta.utils -   [GQA]: iter 291582 Ep: 9.89 loss 0.477 score 0.927 lr 5.61433e-06 
09/22/2020 13:23:08 - INFO - volta.utils -   [GQA]: iter 291602 Ep: 9.90 loss 0.404 score 0.938 lr 5.61395e-06 
09/22/2020 13:23:25 - INFO - volta.utils -   [GQA]: iter 291622 Ep: 9.90 loss 0.329 score 0.947 lr 5.61357e-06 
09/22/2020 13:23:37 - INFO - volta.utils -   [GQA]: iter 291642 Ep: 9.90 loss 0.401 score 0.938 lr 5.6132e-06 
09/22/2020 13:23:58 - INFO - volta.utils -   [GQA]: iter 291662 Ep: 9.90 loss 0.361 score 0.947 lr 5.61282e-06 
09/22/2020 13:24:09 - INFO - volta.utils -   [GQA]: iter 291682 Ep: 9.90 loss 0.454 score 0.925 lr 5.61244e-06 
09/22/2020 13:24:28 - INFO - volta.utils -   [GQA]: iter 291702 Ep: 9.90 loss 0.319 score 0.948 lr 5.61207e-06 
09/22/2020 13:24:42 - INFO - volta.utils -   [GQA]: iter 291722 Ep: 9.90 loss 0.358 score 0.936 lr 5.61169e-06 
09/22/2020 13:25:02 - INFO - volta.utils -   [GQA]: iter 291742 Ep: 9.90 loss 0.463 score 0.928 lr 5.61131e-06 
09/22/2020 13:25:28 - INFO - volta.utils -   [GQA]: iter 291762 Ep: 9.90 loss 0.358 score 0.933 lr 5.61093e-06 
09/22/2020 13:25:47 - INFO - volta.utils -   [GQA]: iter 291782 Ep: 9.90 loss 0.359 score 0.947 lr 5.61056e-06 
09/22/2020 13:26:01 - INFO - volta.utils -   [GQA]: iter 291802 Ep: 9.90 loss 0.350 score 0.947 lr 5.61018e-06 
09/22/2020 13:26:15 - INFO - volta.utils -   [GQA]: iter 291822 Ep: 9.90 loss 0.361 score 0.941 lr 5.6098e-06 
09/22/2020 13:26:26 - INFO - volta.utils -   [GQA]: iter 291842 Ep: 9.90 loss 0.394 score 0.945 lr 5.60943e-06 
09/22/2020 13:26:39 - INFO - volta.utils -   [GQA]: iter 291862 Ep: 9.90 loss 0.397 score 0.938 lr 5.60905e-06 
09/22/2020 13:26:57 - INFO - volta.utils -   [GQA]: iter 291882 Ep: 9.90 loss 0.398 score 0.938 lr 5.60867e-06 
09/22/2020 13:27:12 - INFO - volta.utils -   [GQA]: iter 291902 Ep: 9.91 loss 0.323 score 0.950 lr 5.60829e-06 
09/22/2020 13:27:24 - INFO - volta.utils -   [GQA]: iter 291922 Ep: 9.91 loss 0.420 score 0.933 lr 5.60792e-06 
09/22/2020 13:27:54 - INFO - volta.utils -   [GQA]: iter 291942 Ep: 9.91 loss 0.396 score 0.945 lr 5.60754e-06 
09/22/2020 13:28:16 - INFO - volta.utils -   [GQA]: iter 291962 Ep: 9.91 loss 0.333 score 0.950 lr 5.60716e-06 
09/22/2020 13:28:30 - INFO - volta.utils -   [GQA]: iter 291982 Ep: 9.91 loss 0.356 score 0.950 lr 5.60679e-06 
09/22/2020 13:28:47 - INFO - volta.utils -   [GQA]: iter 292002 Ep: 9.91 loss 0.461 score 0.925 lr 5.60641e-06 
09/22/2020 13:29:07 - INFO - volta.utils -   [GQA]: iter 292022 Ep: 9.91 loss 0.377 score 0.933 lr 5.60603e-06 
09/22/2020 13:29:25 - INFO - volta.utils -   [GQA]: iter 292042 Ep: 9.91 loss 0.391 score 0.936 lr 5.60566e-06 
09/22/2020 13:29:43 - INFO - volta.utils -   [GQA]: iter 292062 Ep: 9.91 loss 0.288 score 0.953 lr 5.60528e-06 
09/22/2020 13:29:59 - INFO - volta.utils -   [GQA]: iter 292082 Ep: 9.91 loss 0.334 score 0.944 lr 5.6049e-06 
09/22/2020 13:30:09 - INFO - volta.utils -   [GQA]: iter 292102 Ep: 9.91 loss 0.385 score 0.936 lr 5.60452e-06 
09/22/2020 13:30:26 - INFO - volta.utils -   [GQA]: iter 292122 Ep: 9.91 loss 0.420 score 0.923 lr 5.60415e-06 
09/22/2020 13:30:43 - INFO - volta.utils -   [GQA]: iter 292142 Ep: 9.91 loss 0.403 score 0.939 lr 5.60377e-06 
09/22/2020 13:31:07 - INFO - volta.utils -   [GQA]: iter 292162 Ep: 9.91 loss 0.345 score 0.952 lr 5.60339e-06 
09/22/2020 13:31:39 - INFO - volta.utils -   [GQA]: iter 292182 Ep: 9.91 loss 0.466 score 0.919 lr 5.60302e-06 
09/22/2020 13:31:53 - INFO - volta.utils -   [GQA]: iter 292202 Ep: 9.92 loss 0.318 score 0.947 lr 5.60264e-06 
09/22/2020 13:32:09 - INFO - volta.utils -   [GQA]: iter 292222 Ep: 9.92 loss 0.340 score 0.952 lr 5.60226e-06 
09/22/2020 13:32:19 - INFO - volta.utils -   [GQA]: iter 292242 Ep: 9.92 loss 0.365 score 0.950 lr 5.60188e-06 
09/22/2020 13:32:43 - INFO - volta.utils -   [GQA]: iter 292262 Ep: 9.92 loss 0.385 score 0.930 lr 5.60151e-06 
09/22/2020 13:33:04 - INFO - volta.utils -   [GQA]: iter 292282 Ep: 9.92 loss 0.318 score 0.947 lr 5.60113e-06 
09/22/2020 13:33:23 - INFO - volta.utils -   [GQA]: iter 292302 Ep: 9.92 loss 0.331 score 0.948 lr 5.60075e-06 
09/22/2020 13:33:38 - INFO - volta.utils -   [GQA]: iter 292322 Ep: 9.92 loss 0.426 score 0.938 lr 5.60038e-06 
09/22/2020 13:33:47 - INFO - volta.utils -   [GQA]: iter 292342 Ep: 9.92 loss 0.395 score 0.930 lr 5.6e-06 
09/22/2020 13:34:14 - INFO - volta.utils -   [GQA]: iter 292362 Ep: 9.92 loss 0.330 score 0.941 lr 5.59962e-06 
09/22/2020 13:34:41 - INFO - volta.utils -   [GQA]: iter 292382 Ep: 9.92 loss 0.335 score 0.942 lr 5.59925e-06 
09/22/2020 13:34:58 - INFO - volta.utils -   [GQA]: iter 292402 Ep: 9.92 loss 0.421 score 0.948 lr 5.59887e-06 
09/22/2020 13:35:08 - INFO - volta.utils -   [GQA]: iter 292422 Ep: 9.92 loss 0.355 score 0.944 lr 5.59849e-06 
09/22/2020 13:35:27 - INFO - volta.utils -   [GQA]: iter 292442 Ep: 9.92 loss 0.377 score 0.936 lr 5.59811e-06 
09/22/2020 13:35:41 - INFO - volta.utils -   [GQA]: iter 292462 Ep: 9.92 loss 0.438 score 0.938 lr 5.59774e-06 
09/22/2020 13:35:55 - INFO - volta.utils -   [GQA]: iter 292482 Ep: 9.93 loss 0.350 score 0.953 lr 5.59736e-06 
09/22/2020 13:36:03 - INFO - volta.utils -   [GQA]: iter 292502 Ep: 9.93 loss 0.415 score 0.933 lr 5.59698e-06 
09/22/2020 13:36:32 - INFO - volta.utils -   [GQA]: iter 292522 Ep: 9.93 loss 0.418 score 0.944 lr 5.59661e-06 
09/22/2020 13:36:51 - INFO - volta.utils -   [GQA]: iter 292542 Ep: 9.93 loss 0.333 score 0.950 lr 5.59623e-06 
09/22/2020 13:37:12 - INFO - volta.utils -   [GQA]: iter 292562 Ep: 9.93 loss 0.441 score 0.938 lr 5.59585e-06 
09/22/2020 13:37:25 - INFO - volta.utils -   [GQA]: iter 292582 Ep: 9.93 loss 0.496 score 0.927 lr 5.59548e-06 
09/22/2020 13:37:34 - INFO - volta.utils -   [GQA]: iter 292602 Ep: 9.93 loss 0.428 score 0.938 lr 5.5951e-06 
09/22/2020 13:37:47 - INFO - volta.utils -   [GQA]: iter 292622 Ep: 9.93 loss 0.344 score 0.945 lr 5.59472e-06 
09/22/2020 13:38:15 - INFO - volta.utils -   [GQA]: iter 292642 Ep: 9.93 loss 0.382 score 0.931 lr 5.59434e-06 
09/22/2020 13:38:35 - INFO - volta.utils -   [GQA]: iter 292662 Ep: 9.93 loss 0.451 score 0.920 lr 5.59397e-06 
09/22/2020 13:38:48 - INFO - volta.utils -   [GQA]: iter 292682 Ep: 9.93 loss 0.361 score 0.945 lr 5.59359e-06 
09/22/2020 13:39:06 - INFO - volta.utils -   [GQA]: iter 292702 Ep: 9.93 loss 0.457 score 0.928 lr 5.59321e-06 
09/22/2020 13:39:30 - INFO - volta.utils -   [GQA]: iter 292722 Ep: 9.93 loss 0.384 score 0.941 lr 5.59284e-06 
09/22/2020 13:39:52 - INFO - volta.utils -   [GQA]: iter 292742 Ep: 9.93 loss 0.355 score 0.952 lr 5.59246e-06 
09/22/2020 13:40:16 - INFO - volta.utils -   [GQA]: iter 292762 Ep: 9.93 loss 0.281 score 0.955 lr 5.59208e-06 
09/22/2020 13:41:11 - INFO - volta.utils -   [GQA]: iter 292782 Ep: 9.94 loss 0.280 score 0.961 lr 5.5917e-06 
09/22/2020 13:41:32 - INFO - volta.utils -   [GQA]: iter 292802 Ep: 9.94 loss 0.400 score 0.945 lr 5.59133e-06 
09/22/2020 13:41:59 - INFO - volta.utils -   [GQA]: iter 292822 Ep: 9.94 loss 0.391 score 0.920 lr 5.59095e-06 
09/22/2020 13:42:06 - INFO - volta.utils -   [GQA]: iter 292842 Ep: 9.94 loss 0.433 score 0.922 lr 5.59057e-06 
09/22/2020 13:42:29 - INFO - volta.utils -   [GQA]: iter 292862 Ep: 9.94 loss 0.382 score 0.938 lr 5.5902e-06 
09/22/2020 13:42:56 - INFO - volta.utils -   [GQA]: iter 292882 Ep: 9.94 loss 0.391 score 0.941 lr 5.58982e-06 
09/22/2020 13:43:26 - INFO - volta.utils -   [GQA]: iter 292902 Ep: 9.94 loss 0.327 score 0.952 lr 5.58944e-06 
09/22/2020 13:43:41 - INFO - volta.utils -   [GQA]: iter 292922 Ep: 9.94 loss 0.388 score 0.933 lr 5.58907e-06 
09/22/2020 13:43:56 - INFO - volta.utils -   [GQA]: iter 292942 Ep: 9.94 loss 0.399 score 0.933 lr 5.58869e-06 
09/22/2020 13:44:26 - INFO - volta.utils -   [GQA]: iter 292962 Ep: 9.94 loss 0.365 score 0.939 lr 5.58831e-06 
09/22/2020 13:45:02 - INFO - volta.utils -   [GQA]: iter 292982 Ep: 9.94 loss 0.315 score 0.950 lr 5.58793e-06 
09/22/2020 13:45:14 - INFO - volta.utils -   [GQA]: iter 293002 Ep: 9.94 loss 0.447 score 0.933 lr 5.58756e-06 
09/22/2020 13:45:27 - INFO - volta.utils -   [GQA]: iter 293022 Ep: 9.94 loss 0.332 score 0.948 lr 5.58718e-06 
09/22/2020 13:45:42 - INFO - volta.utils -   [GQA]: iter 293042 Ep: 9.94 loss 0.414 score 0.928 lr 5.5868e-06 
09/22/2020 13:46:00 - INFO - volta.utils -   [GQA]: iter 293062 Ep: 9.94 loss 0.426 score 0.938 lr 5.58643e-06 
09/22/2020 13:46:13 - INFO - volta.utils -   [GQA]: iter 293082 Ep: 9.95 loss 0.301 score 0.953 lr 5.58605e-06 
09/22/2020 13:46:28 - INFO - volta.utils -   [GQA]: iter 293102 Ep: 9.95 loss 0.420 score 0.938 lr 5.58567e-06 
09/22/2020 13:46:46 - INFO - volta.utils -   [GQA]: iter 293122 Ep: 9.95 loss 0.435 score 0.928 lr 5.58529e-06 
09/22/2020 13:47:19 - INFO - volta.utils -   [GQA]: iter 293142 Ep: 9.95 loss 0.390 score 0.941 lr 5.58492e-06 
09/22/2020 13:47:40 - INFO - volta.utils -   [GQA]: iter 293162 Ep: 9.95 loss 0.377 score 0.934 lr 5.58454e-06 
09/22/2020 13:48:00 - INFO - volta.utils -   [GQA]: iter 293182 Ep: 9.95 loss 0.421 score 0.930 lr 5.58416e-06 
09/22/2020 13:48:19 - INFO - volta.utils -   [GQA]: iter 293202 Ep: 9.95 loss 0.375 score 0.925 lr 5.58379e-06 
09/22/2020 13:48:27 - INFO - volta.utils -   [GQA]: iter 293222 Ep: 9.95 loss 0.449 score 0.930 lr 5.58341e-06 
09/22/2020 13:48:44 - INFO - volta.utils -   [GQA]: iter 293242 Ep: 9.95 loss 0.423 score 0.928 lr 5.58303e-06 
09/22/2020 13:48:51 - INFO - volta.utils -   [GQA]: iter 293262 Ep: 9.95 loss 0.361 score 0.941 lr 5.58266e-06 
09/22/2020 13:49:07 - INFO - volta.utils -   [GQA]: iter 293282 Ep: 9.95 loss 0.416 score 0.945 lr 5.58228e-06 
09/22/2020 13:49:48 - INFO - volta.utils -   [GQA]: iter 293302 Ep: 9.95 loss 0.345 score 0.955 lr 5.5819e-06 
09/22/2020 13:50:02 - INFO - volta.utils -   [GQA]: iter 293322 Ep: 9.95 loss 0.361 score 0.950 lr 5.58152e-06 
09/22/2020 13:50:12 - INFO - volta.utils -   [GQA]: iter 293342 Ep: 9.95 loss 0.384 score 0.934 lr 5.58115e-06 
09/22/2020 13:50:27 - INFO - volta.utils -   [GQA]: iter 293362 Ep: 9.95 loss 0.430 score 0.922 lr 5.58077e-06 
09/22/2020 13:50:39 - INFO - volta.utils -   [GQA]: iter 293382 Ep: 9.96 loss 0.438 score 0.933 lr 5.58039e-06 
09/22/2020 13:51:02 - INFO - volta.utils -   [GQA]: iter 293402 Ep: 9.96 loss 0.391 score 0.930 lr 5.58002e-06 
09/22/2020 13:51:27 - INFO - volta.utils -   [GQA]: iter 293422 Ep: 9.96 loss 0.321 score 0.947 lr 5.57964e-06 
09/22/2020 13:51:52 - INFO - volta.utils -   [GQA]: iter 293442 Ep: 9.96 loss 0.376 score 0.944 lr 5.57926e-06 
09/22/2020 13:52:08 - INFO - volta.utils -   [GQA]: iter 293462 Ep: 9.96 loss 0.413 score 0.942 lr 5.57889e-06 
09/22/2020 13:52:28 - INFO - volta.utils -   [GQA]: iter 293482 Ep: 9.96 loss 0.356 score 0.938 lr 5.57851e-06 
09/22/2020 13:52:50 - INFO - volta.utils -   [GQA]: iter 293502 Ep: 9.96 loss 0.433 score 0.930 lr 5.57813e-06 
09/22/2020 13:53:32 - INFO - volta.utils -   [GQA]: iter 293522 Ep: 9.96 loss 0.426 score 0.933 lr 5.57775e-06 
09/22/2020 13:53:46 - INFO - volta.utils -   [GQA]: iter 293542 Ep: 9.96 loss 0.318 score 0.956 lr 5.57738e-06 
09/22/2020 13:53:58 - INFO - volta.utils -   [GQA]: iter 293562 Ep: 9.96 loss 0.295 score 0.950 lr 5.577e-06 
09/22/2020 13:54:09 - INFO - volta.utils -   [GQA]: iter 293582 Ep: 9.96 loss 0.356 score 0.944 lr 5.57662e-06 
09/22/2020 13:54:28 - INFO - volta.utils -   [GQA]: iter 293602 Ep: 9.96 loss 0.404 score 0.934 lr 5.57625e-06 
09/22/2020 13:54:51 - INFO - volta.utils -   [GQA]: iter 293622 Ep: 9.96 loss 0.345 score 0.948 lr 5.57587e-06 
09/22/2020 13:55:06 - INFO - volta.utils -   [GQA]: iter 293642 Ep: 9.96 loss 0.400 score 0.933 lr 5.57549e-06 
09/22/2020 13:55:25 - INFO - volta.utils -   [GQA]: iter 293662 Ep: 9.97 loss 0.364 score 0.939 lr 5.57511e-06 
09/22/2020 13:55:48 - INFO - volta.utils -   [GQA]: iter 293682 Ep: 9.97 loss 0.419 score 0.941 lr 5.57474e-06 
09/22/2020 13:56:00 - INFO - volta.utils -   [GQA]: iter 293702 Ep: 9.97 loss 0.450 score 0.927 lr 5.57436e-06 
09/22/2020 13:56:08 - INFO - volta.utils -   [GQA]: iter 293722 Ep: 9.97 loss 0.298 score 0.952 lr 5.57398e-06 
09/22/2020 13:56:20 - INFO - volta.utils -   [GQA]: iter 293742 Ep: 9.97 loss 0.368 score 0.950 lr 5.57361e-06 
09/22/2020 13:56:49 - INFO - volta.utils -   [GQA]: iter 293762 Ep: 9.97 loss 0.379 score 0.934 lr 5.57323e-06 
09/22/2020 13:57:10 - INFO - volta.utils -   [GQA]: iter 293782 Ep: 9.97 loss 0.345 score 0.934 lr 5.57285e-06 
09/22/2020 13:57:28 - INFO - volta.utils -   [GQA]: iter 293802 Ep: 9.97 loss 0.476 score 0.914 lr 5.57248e-06 
09/22/2020 13:57:42 - INFO - volta.utils -   [GQA]: iter 293822 Ep: 9.97 loss 0.313 score 0.948 lr 5.5721e-06 
09/22/2020 13:57:59 - INFO - volta.utils -   [GQA]: iter 293842 Ep: 9.97 loss 0.423 score 0.916 lr 5.57172e-06 
09/22/2020 13:58:07 - INFO - volta.utils -   [GQA]: iter 293862 Ep: 9.97 loss 0.271 score 0.966 lr 5.57134e-06 
09/22/2020 13:58:26 - INFO - volta.utils -   [GQA]: iter 293882 Ep: 9.97 loss 0.406 score 0.934 lr 5.57097e-06 
09/22/2020 13:59:10 - INFO - volta.utils -   [GQA]: iter 293902 Ep: 9.97 loss 0.446 score 0.930 lr 5.57059e-06 
09/22/2020 13:59:24 - INFO - volta.utils -   [GQA]: iter 293922 Ep: 9.97 loss 0.400 score 0.934 lr 5.57021e-06 
09/22/2020 13:59:36 - INFO - volta.utils -   [GQA]: iter 293942 Ep: 9.97 loss 0.384 score 0.928 lr 5.56984e-06 
09/22/2020 13:59:53 - INFO - volta.utils -   [GQA]: iter 293962 Ep: 9.98 loss 0.413 score 0.941 lr 5.56946e-06 
09/22/2020 14:00:08 - INFO - volta.utils -   [GQA]: iter 293982 Ep: 9.98 loss 0.324 score 0.941 lr 5.56908e-06 
09/22/2020 14:00:24 - INFO - volta.utils -   [GQA]: iter 294002 Ep: 9.98 loss 0.351 score 0.944 lr 5.5687e-06 
09/22/2020 14:01:18 - INFO - volta.utils -   [GQA]: iter 294022 Ep: 9.98 loss 0.308 score 0.956 lr 5.56833e-06 
09/22/2020 14:01:33 - INFO - volta.utils -   [GQA]: iter 294042 Ep: 9.98 loss 0.382 score 0.933 lr 5.56795e-06 
09/22/2020 14:01:56 - INFO - volta.utils -   [GQA]: iter 294062 Ep: 9.98 loss 0.408 score 0.942 lr 5.56757e-06 
09/22/2020 14:02:14 - INFO - volta.utils -   [GQA]: iter 294082 Ep: 9.98 loss 0.343 score 0.950 lr 5.5672e-06 
09/22/2020 14:02:42 - INFO - volta.utils -   [GQA]: iter 294102 Ep: 9.98 loss 0.341 score 0.934 lr 5.56682e-06 
09/22/2020 14:02:51 - INFO - volta.utils -   [GQA]: iter 294122 Ep: 9.98 loss 0.421 score 0.934 lr 5.56644e-06 
09/22/2020 14:03:01 - INFO - volta.utils -   [GQA]: iter 294142 Ep: 9.98 loss 0.393 score 0.938 lr 5.56607e-06 
09/22/2020 14:03:20 - INFO - volta.utils -   [GQA]: iter 294162 Ep: 9.98 loss 0.384 score 0.938 lr 5.56569e-06 
09/22/2020 14:03:47 - INFO - volta.utils -   [GQA]: iter 294182 Ep: 9.98 loss 0.391 score 0.941 lr 5.56531e-06 
09/22/2020 14:04:10 - INFO - volta.utils -   [GQA]: iter 294202 Ep: 9.98 loss 0.325 score 0.945 lr 5.56493e-06 
09/22/2020 14:04:20 - INFO - volta.utils -   [GQA]: iter 294222 Ep: 9.98 loss 0.414 score 0.930 lr 5.56456e-06 
09/22/2020 14:04:35 - INFO - volta.utils -   [GQA]: iter 294242 Ep: 9.98 loss 0.322 score 0.958 lr 5.56418e-06 
09/22/2020 14:04:44 - INFO - volta.utils -   [GQA]: iter 294262 Ep: 9.99 loss 0.402 score 0.923 lr 5.5638e-06 
09/22/2020 14:04:58 - INFO - volta.utils -   [GQA]: iter 294282 Ep: 9.99 loss 0.469 score 0.928 lr 5.56343e-06 
09/22/2020 14:05:34 - INFO - volta.utils -   [GQA]: iter 294302 Ep: 9.99 loss 0.333 score 0.955 lr 5.56305e-06 
09/22/2020 14:05:48 - INFO - volta.utils -   [GQA]: iter 294322 Ep: 9.99 loss 0.391 score 0.945 lr 5.56267e-06 
09/22/2020 14:06:06 - INFO - volta.utils -   [GQA]: iter 294342 Ep: 9.99 loss 0.398 score 0.931 lr 5.5623e-06 
09/22/2020 14:06:20 - INFO - volta.utils -   [GQA]: iter 294362 Ep: 9.99 loss 0.376 score 0.936 lr 5.56192e-06 
09/22/2020 14:06:28 - INFO - volta.utils -   [GQA]: iter 294382 Ep: 9.99 loss 0.385 score 0.944 lr 5.56154e-06 
09/22/2020 14:06:42 - INFO - volta.utils -   [GQA]: iter 294402 Ep: 9.99 loss 0.338 score 0.947 lr 5.56116e-06 
09/22/2020 14:07:12 - INFO - volta.utils -   [GQA]: iter 294422 Ep: 9.99 loss 0.370 score 0.944 lr 5.56079e-06 
09/22/2020 14:07:35 - INFO - volta.utils -   [GQA]: iter 294442 Ep: 9.99 loss 0.327 score 0.953 lr 5.56041e-06 
09/22/2020 14:07:50 - INFO - volta.utils -   [GQA]: iter 294462 Ep: 9.99 loss 0.461 score 0.923 lr 5.56003e-06 
09/22/2020 14:08:12 - INFO - volta.utils -   [GQA]: iter 294482 Ep: 9.99 loss 0.517 score 0.895 lr 5.55966e-06 
09/22/2020 14:08:27 - INFO - volta.utils -   [GQA]: iter 294502 Ep: 9.99 loss 0.300 score 0.958 lr 5.55928e-06 
09/22/2020 14:08:55 - INFO - volta.utils -   [GQA]: iter 294522 Ep: 9.99 loss 0.349 score 0.936 lr 5.5589e-06 
09/22/2020 14:09:10 - INFO - volta.utils -   [GQA]: iter 294542 Ep: 9.99 loss 0.442 score 0.930 lr 5.55852e-06 
09/22/2020 14:09:50 - INFO - volta.utils -   [GQA]: iter 294562 Ep: 10.00 loss 0.366 score 0.945 lr 5.55815e-06 
09/22/2020 14:10:09 - INFO - volta.utils -   [GQA]: iter 294582 Ep: 10.00 loss 0.444 score 0.938 lr 5.55777e-06 
09/22/2020 14:10:16 - INFO - volta.utils -   [GQA]: iter 294602 Ep: 10.00 loss 0.365 score 0.944 lr 5.55739e-06 
09/22/2020 14:10:35 - INFO - volta.utils -   [GQA]: iter 294622 Ep: 10.00 loss 0.337 score 0.955 lr 5.55702e-06 
09/22/2020 14:10:55 - INFO - volta.utils -   [GQA]: iter 294642 Ep: 10.00 loss 0.410 score 0.944 lr 5.55664e-06 
09/22/2020 14:11:13 - INFO - volta.utils -   [GQA]: iter 294662 Ep: 10.00 loss 0.349 score 0.941 lr 5.55626e-06 
09/22/2020 14:11:23 - INFO - volta.utils -   [GQA]: iter 294682 Ep: 10.00 loss 0.339 score 0.947 lr 5.55589e-06 
09/22/2020 14:11:26 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:   9%|         | 1/11 [6:33:59<65:39:57, 23639.78s/it]09/22/2020 14:31:22 - INFO - volta.utils -   Eval task TASK15 on iteration 294691 
09/22/2020 14:31:22 - INFO - volta.utils -   Validation [GQA]: loss 3.175 score 63.753 
09/22/2020 14:31:41 - INFO - volta.utils -   [GQA]: iter 294711 Ep: 10.00 loss 0.359 score 0.937 lr 5.55542e-06 
09/22/2020 14:31:48 - INFO - volta.utils -   [GQA]: iter 294731 Ep: 10.00 loss 0.350 score 0.953 lr 5.55496e-06 
09/22/2020 14:32:02 - INFO - volta.utils -   [GQA]: iter 294751 Ep: 10.00 loss 0.255 score 0.966 lr 5.55458e-06 
09/22/2020 14:32:15 - INFO - volta.utils -   [GQA]: iter 294771 Ep: 10.00 loss 0.311 score 0.942 lr 5.55421e-06 
09/22/2020 14:32:28 - INFO - volta.utils -   [GQA]: iter 294791 Ep: 10.00 loss 0.276 score 0.955 lr 5.55383e-06 
09/22/2020 14:32:46 - INFO - volta.utils -   [GQA]: iter 294811 Ep: 10.00 loss 0.309 score 0.955 lr 5.55345e-06 
09/22/2020 14:33:00 - INFO - volta.utils -   [GQA]: iter 294831 Ep: 10.00 loss 0.312 score 0.948 lr 5.55308e-06 
09/22/2020 14:33:07 - INFO - volta.utils -   [GQA]: iter 294851 Ep: 10.01 loss 0.292 score 0.955 lr 5.5527e-06 
09/22/2020 14:33:18 - INFO - volta.utils -   [GQA]: iter 294871 Ep: 10.01 loss 0.259 score 0.967 lr 5.55232e-06 
09/22/2020 14:33:25 - INFO - volta.utils -   [GQA]: iter 294891 Ep: 10.01 loss 0.299 score 0.963 lr 5.55195e-06 
09/22/2020 14:33:34 - INFO - volta.utils -   [GQA]: iter 294911 Ep: 10.01 loss 0.266 score 0.973 lr 5.55157e-06 
09/22/2020 14:33:50 - INFO - volta.utils -   [GQA]: iter 294931 Ep: 10.01 loss 0.310 score 0.948 lr 5.55119e-06 
09/22/2020 14:34:15 - INFO - volta.utils -   [GQA]: iter 294951 Ep: 10.01 loss 0.291 score 0.969 lr 5.55081e-06 
09/22/2020 14:34:27 - INFO - volta.utils -   [GQA]: iter 294971 Ep: 10.01 loss 0.294 score 0.963 lr 5.55044e-06 
09/22/2020 14:34:38 - INFO - volta.utils -   [GQA]: iter 294991 Ep: 10.01 loss 0.329 score 0.950 lr 5.55006e-06 
09/22/2020 14:34:49 - INFO - volta.utils -   [GQA]: iter 295011 Ep: 10.01 loss 0.243 score 0.973 lr 5.54968e-06 
09/22/2020 14:35:04 - INFO - volta.utils -   [GQA]: iter 295031 Ep: 10.01 loss 0.352 score 0.947 lr 5.54931e-06 
09/22/2020 14:35:12 - INFO - volta.utils -   [GQA]: iter 295051 Ep: 10.01 loss 0.303 score 0.953 lr 5.54893e-06 
09/22/2020 14:35:23 - INFO - volta.utils -   [GQA]: iter 295071 Ep: 10.01 loss 0.250 score 0.959 lr 5.54855e-06 
09/22/2020 14:35:43 - INFO - volta.utils -   [GQA]: iter 295091 Ep: 10.01 loss 0.257 score 0.963 lr 5.54817e-06 
09/22/2020 14:36:00 - INFO - volta.utils -   [GQA]: iter 295111 Ep: 10.01 loss 0.293 score 0.955 lr 5.5478e-06 
09/22/2020 14:36:12 - INFO - volta.utils -   [GQA]: iter 295131 Ep: 10.01 loss 0.211 score 0.978 lr 5.54742e-06 
09/22/2020 14:36:20 - INFO - volta.utils -   [GQA]: iter 295151 Ep: 10.02 loss 0.303 score 0.955 lr 5.54704e-06 
09/22/2020 14:36:38 - INFO - volta.utils -   [GQA]: iter 295171 Ep: 10.02 loss 0.297 score 0.959 lr 5.54667e-06 
09/22/2020 14:36:46 - INFO - volta.utils -   [GQA]: iter 295191 Ep: 10.02 loss 0.268 score 0.970 lr 5.54629e-06 
09/22/2020 14:36:57 - INFO - volta.utils -   [GQA]: iter 295211 Ep: 10.02 loss 0.271 score 0.964 lr 5.54591e-06 
09/22/2020 14:37:17 - INFO - volta.utils -   [GQA]: iter 295231 Ep: 10.02 loss 0.261 score 0.963 lr 5.54554e-06 
09/22/2020 14:37:34 - INFO - volta.utils -   [GQA]: iter 295251 Ep: 10.02 loss 0.313 score 0.953 lr 5.54516e-06 
09/22/2020 14:37:42 - INFO - volta.utils -   [GQA]: iter 295271 Ep: 10.02 loss 0.366 score 0.953 lr 5.54478e-06 
09/22/2020 14:37:52 - INFO - volta.utils -   [GQA]: iter 295291 Ep: 10.02 loss 0.268 score 0.966 lr 5.5444e-06 
09/22/2020 14:38:05 - INFO - volta.utils -   [GQA]: iter 295311 Ep: 10.02 loss 0.262 score 0.964 lr 5.54403e-06 
09/22/2020 14:38:17 - INFO - volta.utils -   [GQA]: iter 295331 Ep: 10.02 loss 0.320 score 0.942 lr 5.54365e-06 
09/22/2020 14:38:25 - INFO - volta.utils -   [GQA]: iter 295351 Ep: 10.02 loss 0.325 score 0.947 lr 5.54327e-06 
09/22/2020 14:38:47 - INFO - volta.utils -   [GQA]: iter 295371 Ep: 10.02 loss 0.277 score 0.955 lr 5.5429e-06 
09/22/2020 14:39:04 - INFO - volta.utils -   [GQA]: iter 295391 Ep: 10.02 loss 0.323 score 0.959 lr 5.54252e-06 
09/22/2020 14:39:14 - INFO - volta.utils -   [GQA]: iter 295411 Ep: 10.02 loss 0.292 score 0.956 lr 5.54214e-06 
09/22/2020 14:39:26 - INFO - volta.utils -   [GQA]: iter 295431 Ep: 10.03 loss 0.307 score 0.956 lr 5.54177e-06 
09/22/2020 14:39:39 - INFO - volta.utils -   [GQA]: iter 295451 Ep: 10.03 loss 0.307 score 0.963 lr 5.54139e-06 
09/22/2020 14:39:52 - INFO - volta.utils -   [GQA]: iter 295471 Ep: 10.03 loss 0.227 score 0.970 lr 5.54101e-06 
09/22/2020 14:40:03 - INFO - volta.utils -   [GQA]: iter 295491 Ep: 10.03 loss 0.229 score 0.967 lr 5.54063e-06 
09/22/2020 14:40:21 - INFO - volta.utils -   [GQA]: iter 295511 Ep: 10.03 loss 0.264 score 0.958 lr 5.54026e-06 
09/22/2020 14:40:48 - INFO - volta.utils -   [GQA]: iter 295531 Ep: 10.03 loss 0.319 score 0.955 lr 5.53988e-06 
09/22/2020 14:40:58 - INFO - volta.utils -   [GQA]: iter 295551 Ep: 10.03 loss 0.318 score 0.956 lr 5.5395e-06 
09/22/2020 14:41:09 - INFO - volta.utils -   [GQA]: iter 295571 Ep: 10.03 loss 0.295 score 0.955 lr 5.53913e-06 
09/22/2020 14:41:20 - INFO - volta.utils -   [GQA]: iter 295591 Ep: 10.03 loss 0.264 score 0.966 lr 5.53875e-06 
09/22/2020 14:41:39 - INFO - volta.utils -   [GQA]: iter 295611 Ep: 10.03 loss 0.309 score 0.958 lr 5.53837e-06 
09/22/2020 14:41:47 - INFO - volta.utils -   [GQA]: iter 295631 Ep: 10.03 loss 0.233 score 0.966 lr 5.53799e-06 
09/22/2020 14:42:00 - INFO - volta.utils -   [GQA]: iter 295651 Ep: 10.03 loss 0.300 score 0.956 lr 5.53762e-06 
09/22/2020 14:42:21 - INFO - volta.utils -   [GQA]: iter 295671 Ep: 10.03 loss 0.299 score 0.956 lr 5.53724e-06 
09/22/2020 14:42:40 - INFO - volta.utils -   [GQA]: iter 295691 Ep: 10.03 loss 0.297 score 0.948 lr 5.53686e-06 
09/22/2020 14:42:50 - INFO - volta.utils -   [GQA]: iter 295711 Ep: 10.03 loss 0.325 score 0.953 lr 5.53649e-06 
09/22/2020 14:43:01 - INFO - volta.utils -   [GQA]: iter 295731 Ep: 10.04 loss 0.261 score 0.966 lr 5.53611e-06 
09/22/2020 14:43:31 - INFO - volta.utils -   [GQA]: iter 295751 Ep: 10.04 loss 0.263 score 0.959 lr 5.53573e-06 
09/22/2020 14:43:51 - INFO - volta.utils -   [GQA]: iter 295771 Ep: 10.04 loss 0.289 score 0.964 lr 5.53536e-06 
09/22/2020 14:44:10 - INFO - volta.utils -   [GQA]: iter 295791 Ep: 10.04 loss 0.239 score 0.967 lr 5.53498e-06 
09/22/2020 14:44:22 - INFO - volta.utils -   [GQA]: iter 295811 Ep: 10.04 loss 0.272 score 0.967 lr 5.5346e-06 
09/22/2020 14:44:32 - INFO - volta.utils -   [GQA]: iter 295831 Ep: 10.04 loss 0.259 score 0.964 lr 5.53422e-06 
09/22/2020 14:44:40 - INFO - volta.utils -   [GQA]: iter 295851 Ep: 10.04 loss 0.376 score 0.936 lr 5.53385e-06 
09/22/2020 14:44:58 - INFO - volta.utils -   [GQA]: iter 295871 Ep: 10.04 loss 0.311 score 0.958 lr 5.53347e-06 
09/22/2020 14:45:16 - INFO - volta.utils -   [GQA]: iter 295891 Ep: 10.04 loss 0.299 score 0.952 lr 5.53309e-06 
09/22/2020 14:45:33 - INFO - volta.utils -   [GQA]: iter 295911 Ep: 10.04 loss 0.319 score 0.953 lr 5.53272e-06 
09/22/2020 14:45:45 - INFO - volta.utils -   [GQA]: iter 295931 Ep: 10.04 loss 0.245 score 0.964 lr 5.53234e-06 
09/22/2020 14:45:58 - INFO - volta.utils -   [GQA]: iter 295951 Ep: 10.04 loss 0.296 score 0.958 lr 5.53196e-06 
09/22/2020 14:46:12 - INFO - volta.utils -   [GQA]: iter 295971 Ep: 10.04 loss 0.329 score 0.961 lr 5.53158e-06 
09/22/2020 14:46:20 - INFO - volta.utils -   [GQA]: iter 295991 Ep: 10.04 loss 0.266 score 0.950 lr 5.53121e-06 
09/22/2020 14:46:34 - INFO - volta.utils -   [GQA]: iter 296011 Ep: 10.04 loss 0.303 score 0.950 lr 5.53083e-06 
09/22/2020 14:46:54 - INFO - volta.utils -   [GQA]: iter 296031 Ep: 10.05 loss 0.225 score 0.969 lr 5.53045e-06 
09/22/2020 14:47:15 - INFO - volta.utils -   [GQA]: iter 296051 Ep: 10.05 loss 0.236 score 0.969 lr 5.53008e-06 
09/22/2020 14:47:29 - INFO - volta.utils -   [GQA]: iter 296071 Ep: 10.05 loss 0.246 score 0.969 lr 5.5297e-06 
09/22/2020 14:47:38 - INFO - volta.utils -   [GQA]: iter 296091 Ep: 10.05 loss 0.402 score 0.939 lr 5.52932e-06 
09/22/2020 14:47:47 - INFO - volta.utils -   [GQA]: iter 296111 Ep: 10.05 loss 0.196 score 0.973 lr 5.52895e-06 
09/22/2020 14:47:59 - INFO - volta.utils -   [GQA]: iter 296131 Ep: 10.05 loss 0.240 score 0.966 lr 5.52857e-06 
09/22/2020 14:48:07 - INFO - volta.utils -   [GQA]: iter 296151 Ep: 10.05 loss 0.335 score 0.950 lr 5.52819e-06 
09/22/2020 14:48:34 - INFO - volta.utils -   [GQA]: iter 296171 Ep: 10.05 loss 0.339 score 0.948 lr 5.52781e-06 
09/22/2020 14:48:47 - INFO - volta.utils -   [GQA]: iter 296191 Ep: 10.05 loss 0.352 score 0.948 lr 5.52744e-06 
09/22/2020 14:49:03 - INFO - volta.utils -   [GQA]: iter 296211 Ep: 10.05 loss 0.288 score 0.969 lr 5.52706e-06 
09/22/2020 14:49:16 - INFO - volta.utils -   [GQA]: iter 296231 Ep: 10.05 loss 0.300 score 0.950 lr 5.52668e-06 
09/22/2020 14:49:24 - INFO - volta.utils -   [GQA]: iter 296251 Ep: 10.05 loss 0.357 score 0.944 lr 5.52631e-06 
09/22/2020 14:49:32 - INFO - volta.utils -   [GQA]: iter 296271 Ep: 10.05 loss 0.328 score 0.956 lr 5.52593e-06 
09/22/2020 14:49:40 - INFO - volta.utils -   [GQA]: iter 296291 Ep: 10.05 loss 0.290 score 0.961 lr 5.52555e-06 
09/22/2020 14:49:58 - INFO - volta.utils -   [GQA]: iter 296311 Ep: 10.06 loss 0.330 score 0.952 lr 5.52518e-06 
09/22/2020 14:50:21 - INFO - volta.utils -   [GQA]: iter 296331 Ep: 10.06 loss 0.252 score 0.963 lr 5.5248e-06 
09/22/2020 14:50:36 - INFO - volta.utils -   [GQA]: iter 296351 Ep: 10.06 loss 0.343 score 0.953 lr 5.52442e-06 
09/22/2020 14:50:49 - INFO - volta.utils -   [GQA]: iter 296371 Ep: 10.06 loss 0.199 score 0.973 lr 5.52404e-06 
09/22/2020 14:51:02 - INFO - volta.utils -   [GQA]: iter 296391 Ep: 10.06 loss 0.259 score 0.964 lr 5.52367e-06 
09/22/2020 14:51:09 - INFO - volta.utils -   [GQA]: iter 296411 Ep: 10.06 loss 0.353 score 0.944 lr 5.52329e-06 
09/22/2020 14:51:29 - INFO - volta.utils -   [GQA]: iter 296431 Ep: 10.06 loss 0.244 score 0.959 lr 5.52291e-06 
09/22/2020 14:51:48 - INFO - volta.utils -   [GQA]: iter 296451 Ep: 10.06 loss 0.311 score 0.947 lr 5.52254e-06 
09/22/2020 14:52:08 - INFO - volta.utils -   [GQA]: iter 296471 Ep: 10.06 loss 0.289 score 0.959 lr 5.52216e-06 
09/22/2020 14:52:24 - INFO - volta.utils -   [GQA]: iter 296491 Ep: 10.06 loss 0.302 score 0.952 lr 5.52178e-06 
09/22/2020 14:52:32 - INFO - volta.utils -   [GQA]: iter 296511 Ep: 10.06 loss 0.319 score 0.958 lr 5.5214e-06 
09/22/2020 14:52:43 - INFO - volta.utils -   [GQA]: iter 296531 Ep: 10.06 loss 0.297 score 0.958 lr 5.52103e-06 
09/22/2020 14:52:55 - INFO - volta.utils -   [GQA]: iter 296551 Ep: 10.06 loss 0.309 score 0.959 lr 5.52065e-06 
09/22/2020 14:53:21 - INFO - volta.utils -   [GQA]: iter 296571 Ep: 10.06 loss 0.250 score 0.961 lr 5.52027e-06 
09/22/2020 14:53:36 - INFO - volta.utils -   [GQA]: iter 296591 Ep: 10.06 loss 0.247 score 0.970 lr 5.5199e-06 
09/22/2020 14:53:54 - INFO - volta.utils -   [GQA]: iter 296611 Ep: 10.07 loss 0.239 score 0.967 lr 5.51952e-06 
09/22/2020 14:54:07 - INFO - volta.utils -   [GQA]: iter 296631 Ep: 10.07 loss 0.328 score 0.941 lr 5.51914e-06 
09/22/2020 14:54:15 - INFO - volta.utils -   [GQA]: iter 296651 Ep: 10.07 loss 0.269 score 0.963 lr 5.51877e-06 
09/22/2020 14:54:22 - INFO - volta.utils -   [GQA]: iter 296671 Ep: 10.07 loss 0.319 score 0.952 lr 5.51839e-06 
09/22/2020 14:54:38 - INFO - volta.utils -   [GQA]: iter 296691 Ep: 10.07 loss 0.252 score 0.961 lr 5.51801e-06 
09/22/2020 14:55:11 - INFO - volta.utils -   [GQA]: iter 296711 Ep: 10.07 loss 0.252 score 0.967 lr 5.51763e-06 
09/22/2020 14:55:19 - INFO - volta.utils -   [GQA]: iter 296731 Ep: 10.07 loss 0.296 score 0.955 lr 5.51726e-06 
09/22/2020 14:55:35 - INFO - volta.utils -   [GQA]: iter 296751 Ep: 10.07 loss 0.315 score 0.956 lr 5.51688e-06 
09/22/2020 14:55:45 - INFO - volta.utils -   [GQA]: iter 296771 Ep: 10.07 loss 0.322 score 0.958 lr 5.5165e-06 
09/22/2020 14:55:56 - INFO - volta.utils -   [GQA]: iter 296791 Ep: 10.07 loss 0.286 score 0.959 lr 5.51613e-06 
09/22/2020 14:56:12 - INFO - volta.utils -   [GQA]: iter 296811 Ep: 10.07 loss 0.314 score 0.944 lr 5.51575e-06 
09/22/2020 14:56:27 - INFO - volta.utils -   [GQA]: iter 296831 Ep: 10.07 loss 0.266 score 0.970 lr 5.51537e-06 
09/22/2020 14:56:39 - INFO - volta.utils -   [GQA]: iter 296851 Ep: 10.07 loss 0.308 score 0.958 lr 5.515e-06 
09/22/2020 14:56:58 - INFO - volta.utils -   [GQA]: iter 296871 Ep: 10.07 loss 0.319 score 0.952 lr 5.51462e-06 
09/22/2020 14:57:15 - INFO - volta.utils -   [GQA]: iter 296891 Ep: 10.07 loss 0.262 score 0.961 lr 5.51424e-06 
09/22/2020 14:57:25 - INFO - volta.utils -   [GQA]: iter 296911 Ep: 10.08 loss 0.299 score 0.961 lr 5.51386e-06 
09/22/2020 14:57:33 - INFO - volta.utils -   [GQA]: iter 296931 Ep: 10.08 loss 0.263 score 0.966 lr 5.51349e-06 
09/22/2020 14:57:54 - INFO - volta.utils -   [GQA]: iter 296951 Ep: 10.08 loss 0.297 score 0.959 lr 5.51311e-06 
09/22/2020 14:58:19 - INFO - volta.utils -   [GQA]: iter 296971 Ep: 10.08 loss 0.264 score 0.967 lr 5.51273e-06 
09/22/2020 14:58:37 - INFO - volta.utils -   [GQA]: iter 296991 Ep: 10.08 loss 0.294 score 0.961 lr 5.51236e-06 
09/22/2020 14:58:51 - INFO - volta.utils -   [GQA]: iter 297011 Ep: 10.08 loss 0.327 score 0.947 lr 5.51198e-06 
09/22/2020 14:59:00 - INFO - volta.utils -   [GQA]: iter 297031 Ep: 10.08 loss 0.309 score 0.952 lr 5.5116e-06 
09/22/2020 14:59:14 - INFO - volta.utils -   [GQA]: iter 297051 Ep: 10.08 loss 0.299 score 0.959 lr 5.51122e-06 
09/22/2020 14:59:32 - INFO - volta.utils -   [GQA]: iter 297071 Ep: 10.08 loss 0.259 score 0.967 lr 5.51085e-06 
09/22/2020 14:59:52 - INFO - volta.utils -   [GQA]: iter 297091 Ep: 10.08 loss 0.322 score 0.955 lr 5.51047e-06 
09/22/2020 15:00:06 - INFO - volta.utils -   [GQA]: iter 297111 Ep: 10.08 loss 0.288 score 0.964 lr 5.51009e-06 
09/22/2020 15:00:21 - INFO - volta.utils -   [GQA]: iter 297131 Ep: 10.08 loss 0.317 score 0.950 lr 5.50972e-06 
09/22/2020 15:00:32 - INFO - volta.utils -   [GQA]: iter 297151 Ep: 10.08 loss 0.279 score 0.953 lr 5.50934e-06 
09/22/2020 15:00:46 - INFO - volta.utils -   [GQA]: iter 297171 Ep: 10.08 loss 0.337 score 0.953 lr 5.50896e-06 
09/22/2020 15:01:02 - INFO - volta.utils -   [GQA]: iter 297191 Ep: 10.08 loss 0.341 score 0.955 lr 5.50859e-06 
09/22/2020 15:01:23 - INFO - volta.utils -   [GQA]: iter 297211 Ep: 10.09 loss 0.331 score 0.955 lr 5.50821e-06 
09/22/2020 15:01:38 - INFO - volta.utils -   [GQA]: iter 297231 Ep: 10.09 loss 0.326 score 0.944 lr 5.50783e-06 
09/22/2020 15:02:04 - INFO - volta.utils -   [GQA]: iter 297251 Ep: 10.09 loss 0.273 score 0.964 lr 5.50745e-06 
09/22/2020 15:02:17 - INFO - volta.utils -   [GQA]: iter 297271 Ep: 10.09 loss 0.226 score 0.973 lr 5.50708e-06 
09/22/2020 15:02:29 - INFO - volta.utils -   [GQA]: iter 297291 Ep: 10.09 loss 0.282 score 0.953 lr 5.5067e-06 
09/22/2020 15:02:48 - INFO - volta.utils -   [GQA]: iter 297311 Ep: 10.09 loss 0.286 score 0.959 lr 5.50632e-06 
09/22/2020 15:03:30 - INFO - volta.utils -   [GQA]: iter 297331 Ep: 10.09 loss 0.335 score 0.952 lr 5.50595e-06 
09/22/2020 15:03:38 - INFO - volta.utils -   [GQA]: iter 297351 Ep: 10.09 loss 0.248 score 0.966 lr 5.50557e-06 
09/22/2020 15:03:49 - INFO - volta.utils -   [GQA]: iter 297371 Ep: 10.09 loss 0.272 score 0.958 lr 5.50519e-06 
09/22/2020 15:04:01 - INFO - volta.utils -   [GQA]: iter 297391 Ep: 10.09 loss 0.256 score 0.958 lr 5.50481e-06 
09/22/2020 15:04:24 - INFO - volta.utils -   [GQA]: iter 297411 Ep: 10.09 loss 0.304 score 0.952 lr 5.50444e-06 
09/22/2020 15:04:42 - INFO - volta.utils -   [GQA]: iter 297431 Ep: 10.09 loss 0.411 score 0.938 lr 5.50406e-06 
09/22/2020 15:04:54 - INFO - volta.utils -   [GQA]: iter 297451 Ep: 10.09 loss 0.304 score 0.958 lr 5.50368e-06 
09/22/2020 15:05:05 - INFO - volta.utils -   [GQA]: iter 297471 Ep: 10.09 loss 0.320 score 0.952 lr 5.50331e-06 
09/22/2020 15:05:16 - INFO - volta.utils -   [GQA]: iter 297491 Ep: 10.10 loss 0.263 score 0.959 lr 5.50293e-06 
09/22/2020 15:05:25 - INFO - volta.utils -   [GQA]: iter 297511 Ep: 10.10 loss 0.278 score 0.952 lr 5.50255e-06 
09/22/2020 15:05:33 - INFO - volta.utils -   [GQA]: iter 297531 Ep: 10.10 loss 0.342 score 0.952 lr 5.50218e-06 
09/22/2020 15:05:52 - INFO - volta.utils -   [GQA]: iter 297551 Ep: 10.10 loss 0.258 score 0.966 lr 5.5018e-06 
09/22/2020 15:06:13 - INFO - volta.utils -   [GQA]: iter 297571 Ep: 10.10 loss 0.287 score 0.963 lr 5.50142e-06 
09/22/2020 15:06:28 - INFO - volta.utils -   [GQA]: iter 297591 Ep: 10.10 loss 0.345 score 0.945 lr 5.50104e-06 
09/22/2020 15:06:40 - INFO - volta.utils -   [GQA]: iter 297611 Ep: 10.10 loss 0.265 score 0.963 lr 5.50067e-06 
09/22/2020 15:06:50 - INFO - volta.utils -   [GQA]: iter 297631 Ep: 10.10 loss 0.301 score 0.956 lr 5.50029e-06 
09/22/2020 15:07:00 - INFO - volta.utils -   [GQA]: iter 297651 Ep: 10.10 loss 0.276 score 0.966 lr 5.49991e-06 
09/22/2020 15:07:16 - INFO - volta.utils -   [GQA]: iter 297671 Ep: 10.10 loss 0.274 score 0.952 lr 5.49954e-06 
09/22/2020 15:07:29 - INFO - volta.utils -   [GQA]: iter 297691 Ep: 10.10 loss 0.319 score 0.952 lr 5.49916e-06 
09/22/2020 15:07:56 - INFO - volta.utils -   [GQA]: iter 297711 Ep: 10.10 loss 0.342 score 0.952 lr 5.49878e-06 
09/22/2020 15:08:09 - INFO - volta.utils -   [GQA]: iter 297731 Ep: 10.10 loss 0.282 score 0.967 lr 5.49841e-06 
09/22/2020 15:08:32 - INFO - volta.utils -   [GQA]: iter 297751 Ep: 10.10 loss 0.311 score 0.953 lr 5.49803e-06 
09/22/2020 15:08:40 - INFO - volta.utils -   [GQA]: iter 297771 Ep: 10.10 loss 0.304 score 0.955 lr 5.49765e-06 
09/22/2020 15:08:48 - INFO - volta.utils -   [GQA]: iter 297791 Ep: 10.11 loss 0.255 score 0.964 lr 5.49727e-06 
09/22/2020 15:08:55 - INFO - volta.utils -   [GQA]: iter 297811 Ep: 10.11 loss 0.321 score 0.944 lr 5.4969e-06 
09/22/2020 15:09:17 - INFO - volta.utils -   [GQA]: iter 297831 Ep: 10.11 loss 0.341 score 0.947 lr 5.49652e-06 
09/22/2020 15:09:38 - INFO - volta.utils -   [GQA]: iter 297851 Ep: 10.11 loss 0.205 score 0.973 lr 5.49614e-06 
09/22/2020 15:09:50 - INFO - volta.utils -   [GQA]: iter 297871 Ep: 10.11 loss 0.309 score 0.945 lr 5.49577e-06 
09/22/2020 15:10:02 - INFO - volta.utils -   [GQA]: iter 297891 Ep: 10.11 loss 0.250 score 0.966 lr 5.49539e-06 
09/22/2020 15:10:18 - INFO - volta.utils -   [GQA]: iter 297911 Ep: 10.11 loss 0.326 score 0.953 lr 5.49501e-06 
09/22/2020 15:10:25 - INFO - volta.utils -   [GQA]: iter 297931 Ep: 10.11 loss 0.292 score 0.963 lr 5.49463e-06 
09/22/2020 15:10:46 - INFO - volta.utils -   [GQA]: iter 297951 Ep: 10.11 loss 0.285 score 0.963 lr 5.49426e-06 
09/22/2020 15:11:03 - INFO - volta.utils -   [GQA]: iter 297971 Ep: 10.11 loss 0.336 score 0.952 lr 5.49388e-06 
09/22/2020 15:11:23 - INFO - volta.utils -   [GQA]: iter 297991 Ep: 10.11 loss 0.246 score 0.964 lr 5.4935e-06 
09/22/2020 15:11:35 - INFO - volta.utils -   [GQA]: iter 298011 Ep: 10.11 loss 0.316 score 0.953 lr 5.49313e-06 
09/22/2020 15:11:46 - INFO - volta.utils -   [GQA]: iter 298031 Ep: 10.11 loss 0.225 score 0.970 lr 5.49275e-06 
09/22/2020 15:11:56 - INFO - volta.utils -   [GQA]: iter 298051 Ep: 10.11 loss 0.298 score 0.958 lr 5.49237e-06 
09/22/2020 15:12:11 - INFO - volta.utils -   [GQA]: iter 298071 Ep: 10.11 loss 0.215 score 0.970 lr 5.492e-06 
09/22/2020 15:12:49 - INFO - volta.utils -   [GQA]: iter 298091 Ep: 10.12 loss 0.264 score 0.958 lr 5.49162e-06 
09/22/2020 15:13:00 - INFO - volta.utils -   [GQA]: iter 298111 Ep: 10.12 loss 0.264 score 0.967 lr 5.49124e-06 
09/22/2020 15:13:08 - INFO - volta.utils -   [GQA]: iter 298131 Ep: 10.12 loss 0.236 score 0.977 lr 5.49086e-06 
09/22/2020 15:13:24 - INFO - volta.utils -   [GQA]: iter 298151 Ep: 10.12 loss 0.261 score 0.969 lr 5.49049e-06 
09/22/2020 15:13:42 - INFO - volta.utils -   [GQA]: iter 298171 Ep: 10.12 loss 0.348 score 0.953 lr 5.49011e-06 
09/22/2020 15:13:49 - INFO - volta.utils -   [GQA]: iter 298191 Ep: 10.12 loss 0.245 score 0.967 lr 5.48973e-06 
09/22/2020 15:14:21 - INFO - volta.utils -   [GQA]: iter 298211 Ep: 10.12 loss 0.289 score 0.963 lr 5.48936e-06 
09/22/2020 15:14:39 - INFO - volta.utils -   [GQA]: iter 298231 Ep: 10.12 loss 0.303 score 0.963 lr 5.48898e-06 
09/22/2020 15:14:49 - INFO - volta.utils -   [GQA]: iter 298251 Ep: 10.12 loss 0.376 score 0.944 lr 5.4886e-06 
09/22/2020 15:15:00 - INFO - volta.utils -   [GQA]: iter 298271 Ep: 10.12 loss 0.342 score 0.948 lr 5.48822e-06 
09/22/2020 15:15:10 - INFO - volta.utils -   [GQA]: iter 298291 Ep: 10.12 loss 0.335 score 0.958 lr 5.48785e-06 
09/22/2020 15:15:23 - INFO - volta.utils -   [GQA]: iter 298311 Ep: 10.12 loss 0.347 score 0.948 lr 5.48747e-06 
09/22/2020 15:15:48 - INFO - volta.utils -   [GQA]: iter 298331 Ep: 10.12 loss 0.318 score 0.963 lr 5.48709e-06 
09/22/2020 15:16:11 - INFO - volta.utils -   [GQA]: iter 298351 Ep: 10.12 loss 0.194 score 0.975 lr 5.48672e-06 
09/22/2020 15:16:23 - INFO - volta.utils -   [GQA]: iter 298371 Ep: 10.12 loss 0.266 score 0.959 lr 5.48634e-06 
09/22/2020 15:16:30 - INFO - volta.utils -   [GQA]: iter 298391 Ep: 10.13 loss 0.285 score 0.958 lr 5.48596e-06 
09/22/2020 15:16:43 - INFO - volta.utils -   [GQA]: iter 298411 Ep: 10.13 loss 0.283 score 0.961 lr 5.48559e-06 
09/22/2020 15:16:55 - INFO - volta.utils -   [GQA]: iter 298431 Ep: 10.13 loss 0.318 score 0.955 lr 5.48521e-06 
09/22/2020 15:17:18 - INFO - volta.utils -   [GQA]: iter 298451 Ep: 10.13 loss 0.293 score 0.959 lr 5.48483e-06 
09/22/2020 15:17:44 - INFO - volta.utils -   [GQA]: iter 298471 Ep: 10.13 loss 0.211 score 0.973 lr 5.48445e-06 
