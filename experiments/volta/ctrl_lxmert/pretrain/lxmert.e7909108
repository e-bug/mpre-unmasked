/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
09/25/2020 16:19:01 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
09/25/2020 16:19:02 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/25/2020 16:19:06 - INFO - volta.utils -   logging file at: ../../logs/volta/conceptual_captions/ctrl_lxmert
09/25/2020 16:19:07 - INFO - volta.utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/4/19ITA380/.pytorch_pretrained_bert/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/25/2020 16:19:12 - INFO - volta.utils -   
09/25/2020 16:19:12 - INFO - volta.utils -   Weights of BertForVLPreTraining not initialized from pretrained model: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.ImgLayerNorm.weight', 'bert.v_embeddings.ImgLayerNorm.bias', 'bert.v_embeddings.LocLayerNorm.weight', 'bert.v_embeddings.LocLayerNorm.bias', 'bert.encoder.layer.0.attention_self.v_query.weight', 'bert.encoder.layer.0.attention_self.v_query.bias', 'bert.encoder.layer.0.attention_self.v_key.weight', 'bert.encoder.layer.0.attention_self.v_key.bias', 'bert.encoder.layer.0.attention_self.v_value.weight', 'bert.encoder.layer.0.attention_self.v_value.bias', 'bert.encoder.layer.0.attention_output.v_dense.weight', 'bert.encoder.layer.0.attention_output.v_dense.bias', 'bert.encoder.layer.0.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.0.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.1.intermediate.v_dense.weight', 'bert.encoder.layer.1.intermediate.v_dense.bias', 'bert.encoder.layer.1.output.v_dense.weight', 'bert.encoder.layer.1.output.v_dense.bias', 'bert.encoder.layer.1.output.v_LayerNorm.weight', 'bert.encoder.layer.1.output.v_LayerNorm.bias', 'bert.encoder.layer.2.attention_self.v_query.weight', 'bert.encoder.layer.2.attention_self.v_query.bias', 'bert.encoder.layer.2.attention_self.v_key.weight', 'bert.encoder.layer.2.attention_self.v_key.bias', 'bert.encoder.layer.2.attention_self.v_value.weight', 'bert.encoder.layer.2.attention_self.v_value.bias', 'bert.encoder.layer.2.attention_output.v_dense.weight', 'bert.encoder.layer.2.attention_output.v_dense.bias', 'bert.encoder.layer.2.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.2.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.3.intermediate.v_dense.weight', 'bert.encoder.layer.3.intermediate.v_dense.bias', 'bert.encoder.layer.3.output.v_dense.weight', 'bert.encoder.layer.3.output.v_dense.bias', 'bert.encoder.layer.3.output.v_LayerNorm.weight', 'bert.encoder.layer.3.output.v_LayerNorm.bias', 'bert.encoder.layer.4.attention_self.v_query.weight', 'bert.encoder.layer.4.attention_self.v_query.bias', 'bert.encoder.layer.4.attention_self.v_key.weight', 'bert.encoder.layer.4.attention_self.v_key.bias', 'bert.encoder.layer.4.attention_self.v_value.weight', 'bert.encoder.layer.4.attention_self.v_value.bias', 'bert.encoder.layer.4.attention_output.v_dense.weight', 'bert.encoder.layer.4.attention_output.v_dense.bias', 'bert.encoder.layer.4.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.4.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.5.intermediate.v_dense.weight', 'bert.encoder.layer.5.intermediate.v_dense.bias', 'bert.encoder.layer.5.output.v_dense.weight', 'bert.encoder.layer.5.output.v_dense.bias', 'bert.encoder.layer.5.output.v_LayerNorm.weight', 'bert.encoder.layer.5.output.v_LayerNorm.bias', 'bert.encoder.layer.6.attention_self.v_query.weight', 'bert.encoder.layer.6.attention_self.v_query.bias', 'bert.encoder.layer.6.attention_self.v_key.weight', 'bert.encoder.layer.6.attention_self.v_key.bias', 'bert.encoder.layer.6.attention_self.v_value.weight', 'bert.encoder.layer.6.attention_self.v_value.bias', 'bert.encoder.layer.6.attention_output.v_dense.weight', 'bert.encoder.layer.6.attention_output.v_dense.bias', 'bert.encoder.layer.6.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.6.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.7.intermediate.v_dense.weight', 'bert.encoder.layer.7.intermediate.v_dense.bias', 'bert.encoder.layer.7.output.v_dense.weight', 'bert.encoder.layer.7.output.v_dense.bias', 'bert.encoder.layer.7.output.v_LayerNorm.weight', 'bert.encoder.layer.7.output.v_LayerNorm.bias', 'bert.encoder.layer.8.attention_self.v_query.weight', 'bert.encoder.layer.8.attention_self.v_query.bias', 'bert.encoder.layer.8.attention_self.v_key.weight', 'bert.encoder.layer.8.attention_self.v_key.bias', 'bert.encoder.layer.8.attention_self.v_value.weight', 'bert.encoder.layer.8.attention_self.v_value.bias', 'bert.encoder.layer.8.attention_output.v_dense.weight', 'bert.encoder.layer.8.attention_output.v_dense.bias', 'bert.encoder.layer.8.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.8.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.9.intermediate.v_dense.weight', 'bert.encoder.layer.9.intermediate.v_dense.bias', 'bert.encoder.layer.9.output.v_dense.weight', 'bert.encoder.layer.9.output.v_dense.bias', 'bert.encoder.layer.9.output.v_LayerNorm.weight', 'bert.encoder.layer.9.output.v_LayerNorm.bias', 'bert.encoder.layer.18.attention_self.query.weight', 'bert.encoder.layer.18.attention_self.query.bias', 'bert.encoder.layer.18.attention_self.key.weight', 'bert.encoder.layer.18.attention_self.key.bias', 'bert.encoder.layer.18.attention_self.value.weight', 'bert.encoder.layer.18.attention_self.value.bias', 'bert.encoder.layer.18.attention_self.v_query.weight', 'bert.encoder.layer.18.attention_self.v_query.bias', 'bert.encoder.layer.18.attention_self.v_key.weight', 'bert.encoder.layer.18.attention_self.v_key.bias', 'bert.encoder.layer.18.attention_self.v_value.weight', 'bert.encoder.layer.18.attention_self.v_value.bias', 'bert.encoder.layer.18.attention_output.dense.weight', 'bert.encoder.layer.18.attention_output.dense.bias', 'bert.encoder.layer.18.attention_output.LayerNorm.weight', 'bert.encoder.layer.18.attention_output.LayerNorm.bias', 'bert.encoder.layer.18.attention_output.v_dense.weight', 'bert.encoder.layer.18.attention_output.v_dense.bias', 'bert.encoder.layer.18.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.18.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.19.attention_self.v_query.weight', 'bert.encoder.layer.19.attention_self.v_query.bias', 'bert.encoder.layer.19.attention_self.v_key.weight', 'bert.encoder.layer.19.attention_self.v_key.bias', 'bert.encoder.layer.19.attention_self.v_value.weight', 'bert.encoder.layer.19.attention_self.v_value.bias', 'bert.encoder.layer.19.attention_output.v_dense.weight', 'bert.encoder.layer.19.attention_output.v_dense.bias', 'bert.encoder.layer.19.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.19.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.20.intermediate.v_dense.weight', 'bert.encoder.layer.20.intermediate.v_dense.bias', 'bert.encoder.layer.20.output.v_dense.weight', 'bert.encoder.layer.20.output.v_dense.bias', 'bert.encoder.layer.20.output.v_LayerNorm.weight', 'bert.encoder.layer.20.output.v_LayerNorm.bias', 'bert.encoder.layer.21.attention_self.query.weight', 'bert.encoder.layer.21.attention_self.query.bias', 'bert.encoder.layer.21.attention_self.key.weight', 'bert.encoder.layer.21.attention_self.key.bias', 'bert.encoder.layer.21.attention_self.value.weight', 'bert.encoder.layer.21.attention_self.value.bias', 'bert.encoder.layer.21.attention_self.v_query.weight', 'bert.encoder.layer.21.attention_self.v_query.bias', 'bert.encoder.layer.21.attention_self.v_key.weight', 'bert.encoder.layer.21.attention_self.v_key.bias', 'bert.encoder.layer.21.attention_self.v_value.weight', 'bert.encoder.layer.21.attention_self.v_value.bias', 'bert.encoder.layer.21.attention_output.dense.weight', 'bert.encoder.layer.21.attention_output.dense.bias', 'bert.encoder.layer.21.attention_output.LayerNorm.weight', 'bert.encoder.layer.21.attention_output.LayerNorm.bias', 'bert.encoder.layer.21.attention_output.v_dense.weight', 'bert.encoder.layer.21.attention_output.v_dense.bias', 'bert.encoder.layer.21.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.21.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.22.attention_self.v_query.weight', 'bert.encoder.layer.22.attention_self.v_query.bias', 'bert.encoder.layer.22.attention_self.v_key.weight', 'bert.encoder.layer.22.attention_self.v_key.bias', 'bert.encoder.layer.22.attention_self.v_value.weight', 'bert.encoder.layer.22.attention_self.v_value.bias', 'bert.encoder.layer.22.attention_output.v_dense.weight', 'bert.encoder.layer.22.attention_output.v_dense.bias', 'bert.encoder.layer.22.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.22.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.23.intermediate.v_dense.weight', 'bert.encoder.layer.23.intermediate.v_dense.bias', 'bert.encoder.layer.23.output.v_dense.weight', 'bert.encoder.layer.23.output.v_dense.bias', 'bert.encoder.layer.23.output.v_LayerNorm.weight', 'bert.encoder.layer.23.output.v_LayerNorm.bias', 'bert.encoder.layer.24.attention_self.query.weight', 'bert.encoder.layer.24.attention_self.query.bias', 'bert.encoder.layer.24.attention_self.key.weight', 'bert.encoder.layer.24.attention_self.key.bias', 'bert.encoder.layer.24.attention_self.value.weight', 'bert.encoder.layer.24.attention_self.value.bias', 'bert.encoder.layer.24.attention_self.v_query.weight', 'bert.encoder.layer.24.attention_self.v_query.bias', 'bert.encoder.layer.24.attention_self.v_key.weight', 'bert.encoder.layer.24.attention_self.v_key.bias', 'bert.encoder.layer.24.attention_self.v_value.weight', 'bert.encoder.layer.24.attention_self.v_value.bias', 'bert.encoder.layer.24.attention_output.dense.weight', 'bert.encoder.layer.24.attention_output.dense.bias', 'bert.encoder.layer.24.attention_output.LayerNorm.weight', 'bert.encoder.layer.24.attention_output.LayerNorm.bias', 'bert.encoder.layer.24.attention_output.v_dense.weight', 'bert.encoder.layer.24.attention_output.v_dense.bias', 'bert.encoder.layer.24.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.24.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.25.attention_self.v_query.weight', 'bert.encoder.layer.25.attention_self.v_query.bias', 'bert.encoder.layer.25.attention_self.v_key.weight', 'bert.encoder.layer.25.attention_self.v_key.bias', 'bert.encoder.layer.25.attention_self.v_value.weight', 'bert.encoder.layer.25.attention_self.v_value.bias', 'bert.encoder.layer.25.attention_output.v_dense.weight', 'bert.encoder.layer.25.attention_output.v_dense.bias', 'bert.encoder.layer.25.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.25.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.26.intermediate.v_dense.weight', 'bert.encoder.layer.26.intermediate.v_dense.bias', 'bert.encoder.layer.26.output.v_dense.weight', 'bert.encoder.layer.26.output.v_dense.bias', 'bert.encoder.layer.26.output.v_LayerNorm.weight', 'bert.encoder.layer.26.output.v_LayerNorm.bias', 'bert.encoder.layer.27.attention_self.query.weight', 'bert.encoder.layer.27.attention_self.query.bias', 'bert.encoder.layer.27.attention_self.key.weight', 'bert.encoder.layer.27.attention_self.key.bias', 'bert.encoder.layer.27.attention_self.value.weight', 'bert.encoder.layer.27.attention_self.value.bias', 'bert.encoder.layer.27.attention_self.v_query.weight', 'bert.encoder.layer.27.attention_self.v_query.bias', 'bert.encoder.layer.27.attention_self.v_key.weight', 'bert.encoder.layer.27.attention_self.v_key.bias', 'bert.encoder.layer.27.attention_self.v_value.weight', 'bert.encoder.layer.27.attention_self.v_value.bias', 'bert.encoder.layer.27.attention_output.dense.weight', 'bert.encoder.layer.27.attention_output.dense.bias', 'bert.encoder.layer.27.attention_output.LayerNorm.weight', 'bert.encoder.layer.27.attention_output.LayerNorm.bias', 'bert.encoder.layer.27.attention_output.v_dense.weight', 'bert.encoder.layer.27.attention_output.v_dense.bias', 'bert.encoder.layer.27.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.27.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.28.attention_self.query.weight', 'bert.encoder.layer.28.attention_self.query.bias', 'bert.encoder.layer.28.attention_self.key.weight', 'bert.encoder.layer.28.attention_self.key.bias', 'bert.encoder.layer.28.attention_self.value.weight', 'bert.encoder.layer.28.attention_self.value.bias', 'bert.encoder.layer.28.attention_self.v_query.weight', 'bert.encoder.layer.28.attention_self.v_query.bias', 'bert.encoder.layer.28.attention_self.v_key.weight', 'bert.encoder.layer.28.attention_self.v_key.bias', 'bert.encoder.layer.28.attention_self.v_value.weight', 'bert.encoder.layer.28.attention_self.v_value.bias', 'bert.encoder.layer.28.attention_output.dense.weight', 'bert.encoder.layer.28.attention_output.dense.bias', 'bert.encoder.layer.28.attention_output.LayerNorm.weight', 'bert.encoder.layer.28.attention_output.LayerNorm.bias', 'bert.encoder.layer.28.attention_output.v_dense.weight', 'bert.encoder.layer.28.attention_output.v_dense.bias', 'bert.encoder.layer.28.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.28.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.29.intermediate.dense.weight', 'bert.encoder.layer.29.intermediate.dense.bias', 'bert.encoder.layer.29.intermediate.v_dense.weight', 'bert.encoder.layer.29.intermediate.v_dense.bias', 'bert.encoder.layer.29.output.dense.weight', 'bert.encoder.layer.29.output.dense.bias', 'bert.encoder.layer.29.output.LayerNorm.weight', 'bert.encoder.layer.29.output.LayerNorm.bias', 'bert.encoder.layer.29.output.v_dense.weight', 'bert.encoder.layer.29.output.v_dense.bias', 'bert.encoder.layer.29.output.v_LayerNorm.weight', 'bert.encoder.layer.29.output.v_LayerNorm.bias', 'bert.encoder.layer.30.attention_self.query.weight', 'bert.encoder.layer.30.attention_self.query.bias', 'bert.encoder.layer.30.attention_self.key.weight', 'bert.encoder.layer.30.attention_self.key.bias', 'bert.encoder.layer.30.attention_self.value.weight', 'bert.encoder.layer.30.attention_self.value.bias', 'bert.encoder.layer.30.attention_self.v_query.weight', 'bert.encoder.layer.30.attention_self.v_query.bias', 'bert.encoder.layer.30.attention_self.v_key.weight', 'bert.encoder.layer.30.attention_self.v_key.bias', 'bert.encoder.layer.30.attention_self.v_value.weight', 'bert.encoder.layer.30.attention_self.v_value.bias', 'bert.encoder.layer.30.attention_output.dense.weight', 'bert.encoder.layer.30.attention_output.dense.bias', 'bert.encoder.layer.30.attention_output.LayerNorm.weight', 'bert.encoder.layer.30.attention_output.LayerNorm.bias', 'bert.encoder.layer.30.attention_output.v_dense.weight', 'bert.encoder.layer.30.attention_output.v_dense.bias', 'bert.encoder.layer.30.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.30.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.31.attention_self.query.weight', 'bert.encoder.layer.31.attention_self.query.bias', 'bert.encoder.layer.31.attention_self.key.weight', 'bert.encoder.layer.31.attention_self.key.bias', 'bert.encoder.layer.31.attention_self.value.weight', 'bert.encoder.layer.31.attention_self.value.bias', 'bert.encoder.layer.31.attention_self.v_query.weight', 'bert.encoder.layer.31.attention_self.v_query.bias', 'bert.encoder.layer.31.attention_self.v_key.weight', 'bert.encoder.layer.31.attention_self.v_key.bias', 'bert.encoder.layer.31.attention_self.v_value.weight', 'bert.encoder.layer.31.attention_self.v_value.bias', 'bert.encoder.layer.31.attention_output.dense.weight', 'bert.encoder.layer.31.attention_output.dense.bias', 'bert.encoder.layer.31.attention_output.LayerNorm.weight', 'bert.encoder.layer.31.attention_output.LayerNorm.bias', 'bert.encoder.layer.31.attention_output.v_dense.weight', 'bert.encoder.layer.31.attention_output.v_dense.bias', 'bert.encoder.layer.31.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.31.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.32.intermediate.dense.weight', 'bert.encoder.layer.32.intermediate.dense.bias', 'bert.encoder.layer.32.intermediate.v_dense.weight', 'bert.encoder.layer.32.intermediate.v_dense.bias', 'bert.encoder.layer.32.output.dense.weight', 'bert.encoder.layer.32.output.dense.bias', 'bert.encoder.layer.32.output.LayerNorm.weight', 'bert.encoder.layer.32.output.LayerNorm.bias', 'bert.encoder.layer.32.output.v_dense.weight', 'bert.encoder.layer.32.output.v_dense.bias', 'bert.encoder.layer.32.output.v_LayerNorm.weight', 'bert.encoder.layer.32.output.v_LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
09/25/2020 16:19:12 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLPreTraining: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
09/25/2020 16:19:16 - INFO - __main__ -   >> Trainable Parameters:
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)     |1572864     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(768, 5)        |3840        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.v_embeddings.ImgLayerNorm.weight                        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.v_embeddings.ImgLayerNorm.bias                          |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.v_embeddings.LocLayerNorm.weight                        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.v_embeddings.LocLayerNorm.bias                          |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.predictions.bias                                         |torch.float32    |(30522,)        |30522       |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.predictions.transform.dense.weight                       |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.predictions.transform.dense.bias                         |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.weight                   |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.bias                     |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.bi_seq_relationship.weight                               |torch.float32    |(2, 1024)       |2048        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.bi_seq_relationship.bias                                 |torch.float32    |(2,)            |2           |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.weight                  |torch.float32    |(768, 768)      |589824      |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.bias                    |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.weight              |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.bias                |torch.float32    |(768,)          |768         |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.weight                   |torch.float32    |(1601, 768)     |1229568     |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.bias                     |torch.float32    |(1601,)         |1601        |
09/25/2020 16:19:16 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/25/2020 16:19:16 - INFO - __main__ -   >> # TrainableParams:       	211.37	M
09/25/2020 16:19:16 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
09/25/2020 16:19:16 - INFO - __main__ -   >> # TotalParams:           	211.37	M
09/25/2020 16:19:16 - INFO - __main__ -   ***** Running training *****
09/25/2020 16:19:16 - INFO - __main__ -     Num examples = 2777649
09/25/2020 16:19:16 - INFO - __main__ -     Batch size = 256
09/25/2020 16:19:16 - INFO - __main__ -     Num steps = 108500
09/25/2020 16:19:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 21 Ep: 0.00 masked_t 8.429 masked_v 4.868 NSP 0.707 lr 1.01382e-07
09/25/2020 16:20:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 41 Ep: 0.00 masked_t 7.624 masked_v 4.348 NSP 0.703 lr 2.90323e-07
09/25/2020 16:20:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 61 Ep: 0.01 masked_t 7.054 masked_v 4.299 NSP 0.701 lr 4.74654e-07
09/25/2020 16:20:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 81 Ep: 0.01 masked_t 6.612 masked_v 4.191 NSP 0.700 lr 6.58986e-07
09/25/2020 16:21:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 101 Ep: 0.01 masked_t 6.049 masked_v 4.117 NSP 0.699 lr 8.43318e-07
09/25/2020 16:21:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 121 Ep: 0.01 masked_t 5.620 masked_v 4.057 NSP 0.701 lr 1.02765e-06
09/25/2020 16:22:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 141 Ep: 0.01 masked_t 5.308 masked_v 3.959 NSP 0.701 lr 1.21198e-06
09/25/2020 16:22:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 161 Ep: 0.01 masked_t 5.150 masked_v 3.881 NSP 0.697 lr 1.39631e-06
09/25/2020 16:22:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 181 Ep: 0.02 masked_t 4.811 masked_v 3.786 NSP 0.700 lr 1.58065e-06
09/25/2020 16:23:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 201 Ep: 0.02 masked_t 4.921 masked_v 3.717 NSP 0.699 lr 1.76498e-06
09/25/2020 16:23:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 221 Ep: 0.02 masked_t 4.670 masked_v 3.633 NSP 0.696 lr 1.94931e-06
09/25/2020 16:23:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 241 Ep: 0.02 masked_t 4.528 masked_v 3.578 NSP 0.697 lr 2.13364e-06
09/25/2020 16:24:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 261 Ep: 0.02 masked_t 4.322 masked_v 3.488 NSP 0.699 lr 2.31797e-06
09/25/2020 16:24:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 281 Ep: 0.03 masked_t 4.300 masked_v 3.425 NSP 0.697 lr 2.5023e-06
09/25/2020 16:24:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 301 Ep: 0.03 masked_t 4.213 masked_v 3.391 NSP 0.698 lr 2.68664e-06
09/25/2020 16:25:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 321 Ep: 0.03 masked_t 4.102 masked_v 3.313 NSP 0.697 lr 2.87097e-06
09/25/2020 16:25:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 341 Ep: 0.03 masked_t 4.066 masked_v 3.243 NSP 0.695 lr 3.0553e-06
09/25/2020 16:25:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 361 Ep: 0.03 masked_t 3.930 masked_v 3.231 NSP 0.693 lr 3.23963e-06
09/25/2020 16:26:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 381 Ep: 0.04 masked_t 3.872 masked_v 3.178 NSP 0.695 lr 3.42396e-06
09/25/2020 16:26:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 401 Ep: 0.04 masked_t 3.864 masked_v 3.133 NSP 0.693 lr 3.60829e-06
09/25/2020 16:27:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 421 Ep: 0.04 masked_t 3.706 masked_v 3.070 NSP 0.694 lr 3.79263e-06
09/25/2020 16:27:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 441 Ep: 0.04 masked_t 3.724 masked_v 3.033 NSP 0.690 lr 3.97696e-06
09/25/2020 16:27:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 461 Ep: 0.04 masked_t 3.692 masked_v 3.002 NSP 0.690 lr 4.16129e-06
09/25/2020 16:28:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 481 Ep: 0.04 masked_t 3.598 masked_v 2.922 NSP 0.690 lr 4.34562e-06
09/25/2020 16:28:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 501 Ep: 0.05 masked_t 3.691 masked_v 2.897 NSP 0.686 lr 4.52995e-06
09/25/2020 16:28:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 521 Ep: 0.05 masked_t 3.598 masked_v 2.860 NSP 0.686 lr 4.71429e-06
09/25/2020 16:29:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 541 Ep: 0.05 masked_t 3.471 masked_v 2.837 NSP 0.684 lr 4.89862e-06
09/25/2020 16:29:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 561 Ep: 0.05 masked_t 3.459 masked_v 2.775 NSP 0.681 lr 5.08295e-06
09/25/2020 16:30:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 581 Ep: 0.05 masked_t 3.565 masked_v 2.734 NSP 0.679 lr 5.26728e-06
09/25/2020 16:30:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 601 Ep: 0.06 masked_t 3.447 masked_v 2.710 NSP 0.672 lr 5.45161e-06
09/25/2020 16:30:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 621 Ep: 0.06 masked_t 3.361 masked_v 2.674 NSP 0.673 lr 5.63594e-06
09/25/2020 16:31:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 641 Ep: 0.06 masked_t 3.449 masked_v 2.638 NSP 0.664 lr 5.82028e-06
09/25/2020 16:31:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 661 Ep: 0.06 masked_t 3.332 masked_v 2.598 NSP 0.660 lr 6.00461e-06
09/25/2020 16:31:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 681 Ep: 0.06 masked_t 3.400 masked_v 2.573 NSP 0.659 lr 6.18894e-06
09/25/2020 16:32:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 701 Ep: 0.06 masked_t 3.305 masked_v 2.520 NSP 0.652 lr 6.37327e-06
09/25/2020 16:32:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 721 Ep: 0.07 masked_t 3.392 masked_v 2.518 NSP 0.647 lr 6.5576e-06
09/25/2020 16:32:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 741 Ep: 0.07 masked_t 3.363 masked_v 2.477 NSP 0.644 lr 6.74194e-06
09/25/2020 16:33:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 761 Ep: 0.07 masked_t 3.318 masked_v 2.442 NSP 0.632 lr 6.92627e-06
09/25/2020 16:33:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 781 Ep: 0.07 masked_t 3.393 masked_v 2.411 NSP 0.617 lr 7.1106e-06
09/25/2020 16:34:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 801 Ep: 0.07 masked_t 3.237 masked_v 2.409 NSP 0.616 lr 7.29493e-06
09/25/2020 16:34:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 821 Ep: 0.08 masked_t 3.254 masked_v 2.372 NSP 0.618 lr 7.47926e-06
09/25/2020 16:34:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 841 Ep: 0.08 masked_t 3.268 masked_v 2.350 NSP 0.606 lr 7.66359e-06
09/25/2020 16:35:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 861 Ep: 0.08 masked_t 3.152 masked_v 2.315 NSP 0.594 lr 7.84793e-06
09/25/2020 16:35:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 881 Ep: 0.08 masked_t 3.224 masked_v 2.298 NSP 0.597 lr 8.03226e-06
09/25/2020 16:35:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 901 Ep: 0.08 masked_t 3.202 masked_v 2.263 NSP 0.585 lr 8.21659e-06
09/25/2020 16:36:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 921 Ep: 0.08 masked_t 3.199 masked_v 2.249 NSP 0.574 lr 8.40092e-06
09/25/2020 16:36:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 941 Ep: 0.09 masked_t 3.143 masked_v 2.219 NSP 0.561 lr 8.58525e-06
09/25/2020 16:36:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 961 Ep: 0.09 masked_t 3.156 masked_v 2.196 NSP 0.557 lr 8.76959e-06
09/25/2020 16:37:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 981 Ep: 0.09 masked_t 3.133 masked_v 2.176 NSP 0.532 lr 8.95392e-06
09/25/2020 16:37:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 1001 Ep: 0.09 masked_t 3.138 masked_v 2.137 NSP 0.528 lr 9.13825e-06
09/25/2020 16:37:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 1021 Ep: 0.09 masked_t 3.060 masked_v 2.126 NSP 0.537 lr 9.32258e-06
09/25/2020 16:38:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 1041 Ep: 0.10 masked_t 3.054 masked_v 2.111 NSP 0.523 lr 9.50691e-06
09/25/2020 16:38:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 1061 Ep: 0.10 masked_t 3.123 masked_v 2.078 NSP 0.515 lr 9.69124e-06
09/25/2020 16:39:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 1081 Ep: 0.10 masked_t 3.194 masked_v 2.052 NSP 0.509 lr 9.87558e-06
09/25/2020 16:39:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 1101 Ep: 0.10 masked_t 3.092 masked_v 2.056 NSP 0.512 lr 1.00599e-05
09/25/2020 16:39:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 1121 Ep: 0.10 masked_t 3.185 masked_v 2.035 NSP 0.508 lr 1.02442e-05
09/25/2020 16:40:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 1141 Ep: 0.11 masked_t 3.107 masked_v 1.992 NSP 0.493 lr 1.04286e-05
09/25/2020 16:40:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 1161 Ep: 0.11 masked_t 3.117 masked_v 1.974 NSP 0.486 lr 1.06129e-05
09/25/2020 16:40:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 1181 Ep: 0.11 masked_t 3.017 masked_v 1.957 NSP 0.476 lr 1.07972e-05
09/25/2020 16:41:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 1201 Ep: 0.11 masked_t 3.097 masked_v 1.928 NSP 0.485 lr 1.09816e-05
09/25/2020 16:41:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 1221 Ep: 0.11 masked_t 3.007 masked_v 1.927 NSP 0.481 lr 1.11659e-05
09/25/2020 16:41:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 1241 Ep: 0.11 masked_t 3.010 masked_v 1.919 NSP 0.455 lr 1.13502e-05
09/25/2020 16:42:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 1261 Ep: 0.12 masked_t 3.042 masked_v 1.894 NSP 0.462 lr 1.15346e-05
09/25/2020 16:42:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 1281 Ep: 0.12 masked_t 3.065 masked_v 1.877 NSP 0.453 lr 1.17189e-05
09/25/2020 16:42:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 1301 Ep: 0.12 masked_t 2.954 masked_v 1.861 NSP 0.452 lr 1.19032e-05
09/25/2020 16:43:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 1321 Ep: 0.12 masked_t 2.851 masked_v 1.866 NSP 0.445 lr 1.20876e-05
09/25/2020 16:43:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 1341 Ep: 0.12 masked_t 2.923 masked_v 1.863 NSP 0.444 lr 1.22719e-05
09/25/2020 16:43:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 1361 Ep: 0.13 masked_t 3.024 masked_v 1.828 NSP 0.447 lr 1.24562e-05
09/25/2020 16:44:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 1381 Ep: 0.13 masked_t 2.965 masked_v 1.795 NSP 0.436 lr 1.26406e-05
09/25/2020 16:44:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 1401 Ep: 0.13 masked_t 2.948 masked_v 1.802 NSP 0.438 lr 1.28249e-05
09/25/2020 16:45:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 1421 Ep: 0.13 masked_t 2.901 masked_v 1.829 NSP 0.417 lr 1.30092e-05
09/25/2020 16:45:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 1441 Ep: 0.13 masked_t 2.904 masked_v 1.793 NSP 0.428 lr 1.31935e-05
09/25/2020 16:45:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 1461 Ep: 0.13 masked_t 3.056 masked_v 1.768 NSP 0.438 lr 1.33779e-05
09/25/2020 16:46:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 1481 Ep: 0.14 masked_t 2.935 masked_v 1.741 NSP 0.430 lr 1.35622e-05
09/25/2020 16:46:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 1501 Ep: 0.14 masked_t 2.963 masked_v 1.749 NSP 0.407 lr 1.37465e-05
09/25/2020 16:46:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 1521 Ep: 0.14 masked_t 2.903 masked_v 1.711 NSP 0.415 lr 1.39309e-05
09/25/2020 16:47:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 1541 Ep: 0.14 masked_t 2.793 masked_v 1.709 NSP 0.414 lr 1.41152e-05
09/25/2020 16:47:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 1561 Ep: 0.14 masked_t 3.016 masked_v 1.694 NSP 0.399 lr 1.42995e-05
09/25/2020 16:47:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 1581 Ep: 0.15 masked_t 2.902 masked_v 1.684 NSP 0.407 lr 1.44839e-05
09/25/2020 16:48:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 1601 Ep: 0.15 masked_t 2.929 masked_v 1.678 NSP 0.399 lr 1.46682e-05
09/25/2020 16:48:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 1621 Ep: 0.15 masked_t 2.886 masked_v 1.663 NSP 0.401 lr 1.48525e-05
09/25/2020 16:48:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 1641 Ep: 0.15 masked_t 2.974 masked_v 1.648 NSP 0.392 lr 1.50369e-05
09/25/2020 16:49:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 1661 Ep: 0.15 masked_t 2.872 masked_v 1.682 NSP 0.387 lr 1.52212e-05
09/25/2020 16:49:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 1681 Ep: 0.15 masked_t 2.926 masked_v 1.630 NSP 0.400 lr 1.54055e-05
09/25/2020 16:50:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 1701 Ep: 0.16 masked_t 2.944 masked_v 1.635 NSP 0.401 lr 1.55899e-05
09/25/2020 16:50:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 1721 Ep: 0.16 masked_t 2.884 masked_v 1.624 NSP 0.381 lr 1.57742e-05
09/25/2020 16:50:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 1741 Ep: 0.16 masked_t 2.913 masked_v 1.613 NSP 0.382 lr 1.59585e-05
09/25/2020 16:51:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 1761 Ep: 0.16 masked_t 2.883 masked_v 1.598 NSP 0.386 lr 1.61429e-05
09/25/2020 16:51:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 1781 Ep: 0.16 masked_t 2.960 masked_v 1.587 NSP 0.380 lr 1.63272e-05
09/25/2020 16:51:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 1801 Ep: 0.17 masked_t 2.788 masked_v 1.567 NSP 0.382 lr 1.65115e-05
09/25/2020 16:52:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 1821 Ep: 0.17 masked_t 2.867 masked_v 1.544 NSP 0.373 lr 1.66959e-05
09/25/2020 16:52:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 1841 Ep: 0.17 masked_t 2.888 masked_v 1.540 NSP 0.384 lr 1.68802e-05
09/25/2020 16:52:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 1861 Ep: 0.17 masked_t 2.903 masked_v 1.542 NSP 0.366 lr 1.70645e-05
09/25/2020 16:53:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 1881 Ep: 0.17 masked_t 2.809 masked_v 1.539 NSP 0.377 lr 1.72488e-05
09/25/2020 16:53:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 1901 Ep: 0.18 masked_t 2.800 masked_v 1.528 NSP 0.373 lr 1.74332e-05
09/25/2020 16:53:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 1921 Ep: 0.18 masked_t 2.891 masked_v 1.516 NSP 0.377 lr 1.76175e-05
09/25/2020 16:54:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 1941 Ep: 0.18 masked_t 2.840 masked_v 1.508 NSP 0.361 lr 1.78018e-05
09/25/2020 16:54:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 1961 Ep: 0.18 masked_t 2.780 masked_v 1.492 NSP 0.360 lr 1.79862e-05
09/25/2020 16:54:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 1981 Ep: 0.18 masked_t 2.883 masked_v 1.487 NSP 0.358 lr 1.81705e-05
09/25/2020 16:55:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 2001 Ep: 0.18 masked_t 2.826 masked_v 1.482 NSP 0.358 lr 1.83548e-05
09/25/2020 16:55:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 2021 Ep: 0.19 masked_t 2.871 masked_v 1.470 NSP 0.356 lr 1.85392e-05
09/25/2020 16:56:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 2041 Ep: 0.19 masked_t 2.815 masked_v 1.457 NSP 0.341 lr 1.87235e-05
09/25/2020 16:56:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 2061 Ep: 0.19 masked_t 2.772 masked_v 1.444 NSP 0.353 lr 1.89078e-05
09/25/2020 16:56:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 2081 Ep: 0.19 masked_t 2.797 masked_v 1.428 NSP 0.356 lr 1.90922e-05
09/25/2020 16:57:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 2101 Ep: 0.19 masked_t 2.841 masked_v 1.409 NSP 0.347 lr 1.92765e-05
09/25/2020 16:57:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 2121 Ep: 0.20 masked_t 2.777 masked_v 1.423 NSP 0.351 lr 1.94608e-05
09/25/2020 16:57:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 2141 Ep: 0.20 masked_t 2.792 masked_v 1.405 NSP 0.351 lr 1.96452e-05
09/25/2020 16:58:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 2161 Ep: 0.20 masked_t 2.776 masked_v 1.414 NSP 0.337 lr 1.98295e-05
09/25/2020 16:58:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 2181 Ep: 0.20 masked_t 2.743 masked_v 1.395 NSP 0.348 lr 2.00138e-05
09/25/2020 16:58:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 2201 Ep: 0.20 masked_t 2.788 masked_v 1.382 NSP 0.340 lr 2.01982e-05
09/25/2020 16:59:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 2221 Ep: 0.20 masked_t 2.774 masked_v 1.373 NSP 0.327 lr 2.03825e-05
09/25/2020 16:59:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 2241 Ep: 0.21 masked_t 2.845 masked_v 1.370 NSP 0.352 lr 2.05668e-05
09/25/2020 16:59:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 2261 Ep: 0.21 masked_t 2.752 masked_v 1.351 NSP 0.334 lr 2.07512e-05
09/25/2020 17:00:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 2281 Ep: 0.21 masked_t 2.682 masked_v 1.342 NSP 0.339 lr 2.09355e-05
09/25/2020 17:00:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 2301 Ep: 0.21 masked_t 2.772 masked_v 1.357 NSP 0.334 lr 2.11198e-05
09/25/2020 17:00:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 2321 Ep: 0.21 masked_t 2.801 masked_v 1.349 NSP 0.347 lr 2.13041e-05
09/25/2020 17:01:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 2341 Ep: 0.22 masked_t 2.790 masked_v 1.331 NSP 0.337 lr 2.14885e-05
09/25/2020 17:01:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 2361 Ep: 0.22 masked_t 2.639 masked_v 1.317 NSP 0.335 lr 2.16728e-05
09/25/2020 17:02:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 2381 Ep: 0.22 masked_t 2.668 masked_v 1.294 NSP 0.336 lr 2.18571e-05
09/25/2020 17:02:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 2401 Ep: 0.22 masked_t 2.697 masked_v 1.302 NSP 0.335 lr 2.20415e-05
09/25/2020 17:02:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 2421 Ep: 0.22 masked_t 2.734 masked_v 1.309 NSP 0.326 lr 2.22258e-05
09/25/2020 17:03:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 2441 Ep: 0.22 masked_t 2.672 masked_v 1.255 NSP 0.318 lr 2.24101e-05
09/25/2020 17:03:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 2461 Ep: 0.23 masked_t 2.751 masked_v 1.271 NSP 0.323 lr 2.25945e-05
09/25/2020 17:03:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 2481 Ep: 0.23 masked_t 2.745 masked_v 1.240 NSP 0.317 lr 2.27788e-05
09/25/2020 17:04:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 2501 Ep: 0.23 masked_t 2.679 masked_v 1.276 NSP 0.326 lr 2.29631e-05
09/25/2020 17:04:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 2521 Ep: 0.23 masked_t 2.672 masked_v 1.242 NSP 0.312 lr 2.31475e-05
09/25/2020 17:04:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 2541 Ep: 0.23 masked_t 2.652 masked_v 1.236 NSP 0.320 lr 2.33318e-05
09/25/2020 17:05:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 2561 Ep: 0.24 masked_t 2.726 masked_v 1.222 NSP 0.317 lr 2.35161e-05
09/25/2020 17:05:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 2581 Ep: 0.24 masked_t 2.795 masked_v 1.219 NSP 0.342 lr 2.37005e-05
09/25/2020 17:05:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 2601 Ep: 0.24 masked_t 2.811 masked_v 1.200 NSP 0.324 lr 2.38848e-05
09/25/2020 17:06:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 2621 Ep: 0.24 masked_t 2.680 masked_v 1.227 NSP 0.322 lr 2.40691e-05
09/25/2020 17:06:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 2641 Ep: 0.24 masked_t 2.630 masked_v 1.215 NSP 0.308 lr 2.42535e-05
09/25/2020 17:06:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 2661 Ep: 0.25 masked_t 2.677 masked_v 1.172 NSP 0.324 lr 2.44378e-05
09/25/2020 17:07:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 2681 Ep: 0.25 masked_t 2.695 masked_v 1.177 NSP 0.330 lr 2.46221e-05
09/25/2020 17:07:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 2701 Ep: 0.25 masked_t 2.636 masked_v 1.152 NSP 0.310 lr 2.48065e-05
09/25/2020 17:08:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 2721 Ep: 0.25 masked_t 2.698 masked_v 1.163 NSP 0.322 lr 2.49908e-05
09/25/2020 17:08:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 2741 Ep: 0.25 masked_t 2.629 masked_v 1.174 NSP 0.323 lr 2.51751e-05
09/25/2020 17:08:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 2761 Ep: 0.25 masked_t 2.726 masked_v 1.126 NSP 0.312 lr 2.53594e-05
09/25/2020 17:09:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 2781 Ep: 0.26 masked_t 2.684 masked_v 1.115 NSP 0.294 lr 2.55438e-05
09/25/2020 17:09:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 2801 Ep: 0.26 masked_t 2.672 masked_v 1.121 NSP 0.328 lr 2.57281e-05
09/25/2020 17:09:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 2821 Ep: 0.26 masked_t 2.676 masked_v 1.102 NSP 0.298 lr 2.59124e-05
09/25/2020 17:10:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 2841 Ep: 0.26 masked_t 2.622 masked_v 1.106 NSP 0.305 lr 2.60968e-05
09/25/2020 17:10:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 2861 Ep: 0.26 masked_t 2.636 masked_v 1.103 NSP 0.309 lr 2.62811e-05
09/25/2020 17:10:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 2881 Ep: 0.27 masked_t 2.625 masked_v 1.086 NSP 0.309 lr 2.64654e-05
09/25/2020 17:11:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 2901 Ep: 0.27 masked_t 2.747 masked_v 1.072 NSP 0.293 lr 2.66498e-05
09/25/2020 17:11:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 2921 Ep: 0.27 masked_t 2.699 masked_v 1.063 NSP 0.313 lr 2.68341e-05
09/25/2020 17:11:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 2941 Ep: 0.27 masked_t 2.636 masked_v 1.067 NSP 0.312 lr 2.70184e-05
09/25/2020 17:12:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 2961 Ep: 0.27 masked_t 2.727 masked_v 1.033 NSP 0.297 lr 2.72028e-05
09/25/2020 17:12:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 2981 Ep: 0.27 masked_t 2.624 masked_v 1.030 NSP 0.303 lr 2.73871e-05
09/25/2020 17:12:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 3001 Ep: 0.28 masked_t 2.662 masked_v 1.023 NSP 0.309 lr 2.75714e-05
09/25/2020 17:13:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 3021 Ep: 0.28 masked_t 2.660 masked_v 1.022 NSP 0.293 lr 2.77558e-05
09/25/2020 17:13:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 3041 Ep: 0.28 masked_t 2.678 masked_v 1.015 NSP 0.307 lr 2.79401e-05
09/25/2020 17:14:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 3061 Ep: 0.28 masked_t 2.746 masked_v 0.974 NSP 0.291 lr 2.81244e-05
09/25/2020 17:14:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 3081 Ep: 0.28 masked_t 2.534 masked_v 0.974 NSP 0.288 lr 2.83088e-05
09/25/2020 17:14:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 3101 Ep: 0.29 masked_t 2.645 masked_v 0.985 NSP 0.299 lr 2.84931e-05
09/25/2020 17:15:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 3121 Ep: 0.29 masked_t 2.609 masked_v 0.955 NSP 0.301 lr 2.86774e-05
09/25/2020 17:15:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 3141 Ep: 0.29 masked_t 2.688 masked_v 0.957 NSP 0.297 lr 2.88618e-05
09/25/2020 17:15:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 3161 Ep: 0.29 masked_t 2.586 masked_v 0.938 NSP 0.324 lr 2.90461e-05
09/25/2020 17:16:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 3181 Ep: 0.29 masked_t 2.635 masked_v 0.932 NSP 0.302 lr 2.92304e-05
09/25/2020 17:16:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 3201 Ep: 0.30 masked_t 2.644 masked_v 0.930 NSP 0.292 lr 2.94147e-05
09/25/2020 17:16:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 3221 Ep: 0.30 masked_t 2.528 masked_v 0.921 NSP 0.288 lr 2.95991e-05
09/25/2020 17:17:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 3241 Ep: 0.30 masked_t 2.621 masked_v 0.929 NSP 0.282 lr 2.97834e-05
09/25/2020 17:17:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 3261 Ep: 0.30 masked_t 2.642 masked_v 0.917 NSP 0.277 lr 2.99677e-05
09/25/2020 17:17:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 3281 Ep: 0.30 masked_t 2.670 masked_v 0.924 NSP 0.287 lr 3.01521e-05
09/25/2020 17:18:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 3301 Ep: 0.30 masked_t 2.663 masked_v 0.896 NSP 0.302 lr 3.03364e-05
09/25/2020 17:18:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 3321 Ep: 0.31 masked_t 2.653 masked_v 0.905 NSP 0.291 lr 3.05207e-05
09/25/2020 17:19:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 3341 Ep: 0.31 masked_t 2.689 masked_v 0.901 NSP 0.295 lr 3.07051e-05
09/25/2020 17:19:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 3361 Ep: 0.31 masked_t 2.545 masked_v 0.894 NSP 0.284 lr 3.08894e-05
09/25/2020 17:19:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 3381 Ep: 0.31 masked_t 2.661 masked_v 0.870 NSP 0.294 lr 3.10737e-05
09/25/2020 17:20:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 3401 Ep: 0.31 masked_t 2.548 masked_v 0.888 NSP 0.299 lr 3.12581e-05
09/25/2020 17:20:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 3421 Ep: 0.32 masked_t 2.578 masked_v 0.872 NSP 0.268 lr 3.14424e-05
09/25/2020 17:20:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 3441 Ep: 0.32 masked_t 2.572 masked_v 0.872 NSP 0.281 lr 3.16267e-05
09/25/2020 17:21:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 3461 Ep: 0.32 masked_t 2.568 masked_v 0.859 NSP 0.270 lr 3.18111e-05
09/25/2020 17:21:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 3481 Ep: 0.32 masked_t 2.640 masked_v 0.869 NSP 0.281 lr 3.19954e-05
09/25/2020 17:21:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 3501 Ep: 0.32 masked_t 2.640 masked_v 0.842 NSP 0.289 lr 3.21797e-05
09/25/2020 17:22:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 3521 Ep: 0.32 masked_t 2.578 masked_v 0.854 NSP 0.286 lr 3.23641e-05
09/25/2020 17:22:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 3541 Ep: 0.33 masked_t 2.601 masked_v 0.835 NSP 0.279 lr 3.25484e-05
09/25/2020 17:22:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 3561 Ep: 0.33 masked_t 2.550 masked_v 0.828 NSP 0.281 lr 3.27327e-05
09/25/2020 17:23:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 3581 Ep: 0.33 masked_t 2.623 masked_v 0.827 NSP 0.272 lr 3.29171e-05
09/25/2020 17:23:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 3601 Ep: 0.33 masked_t 2.640 masked_v 0.832 NSP 0.290 lr 3.31014e-05
09/25/2020 17:23:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 3621 Ep: 0.33 masked_t 2.588 masked_v 0.827 NSP 0.279 lr 3.32857e-05
09/25/2020 17:24:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 3641 Ep: 0.34 masked_t 2.554 masked_v 0.808 NSP 0.281 lr 3.347e-05
09/25/2020 17:24:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 3661 Ep: 0.34 masked_t 2.583 masked_v 0.826 NSP 0.283 lr 3.36544e-05
09/25/2020 17:25:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 3681 Ep: 0.34 masked_t 2.489 masked_v 0.817 NSP 0.272 lr 3.38387e-05
09/25/2020 17:25:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 3701 Ep: 0.34 masked_t 2.621 masked_v 0.807 NSP 0.266 lr 3.4023e-05
09/25/2020 17:25:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 3721 Ep: 0.34 masked_t 2.576 masked_v 0.804 NSP 0.257 lr 3.42074e-05
09/25/2020 17:26:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 3741 Ep: 0.34 masked_t 2.603 masked_v 0.814 NSP 0.272 lr 3.43917e-05
09/25/2020 17:26:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 3761 Ep: 0.35 masked_t 2.533 masked_v 0.800 NSP 0.275 lr 3.4576e-05
09/25/2020 17:26:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 3781 Ep: 0.35 masked_t 2.490 masked_v 0.789 NSP 0.289 lr 3.47604e-05
09/25/2020 17:27:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 3801 Ep: 0.35 masked_t 2.529 masked_v 0.784 NSP 0.268 lr 3.49447e-05
09/25/2020 17:27:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 3821 Ep: 0.35 masked_t 2.495 masked_v 0.776 NSP 0.281 lr 3.5129e-05
09/25/2020 17:27:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 3841 Ep: 0.35 masked_t 2.681 masked_v 0.810 NSP 0.272 lr 3.53134e-05
09/25/2020 17:28:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 3861 Ep: 0.36 masked_t 2.480 masked_v 0.769 NSP 0.275 lr 3.54977e-05
09/25/2020 17:28:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 3881 Ep: 0.36 masked_t 2.573 masked_v 0.773 NSP 0.278 lr 3.5682e-05
09/25/2020 17:28:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 3901 Ep: 0.36 masked_t 2.599 masked_v 0.775 NSP 0.272 lr 3.58664e-05
09/25/2020 17:29:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 3921 Ep: 0.36 masked_t 2.563 masked_v 0.766 NSP 0.272 lr 3.60507e-05
09/25/2020 17:29:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 3941 Ep: 0.36 masked_t 2.498 masked_v 0.759 NSP 0.277 lr 3.6235e-05
09/25/2020 17:30:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 3961 Ep: 0.37 masked_t 2.578 masked_v 0.769 NSP 0.265 lr 3.64194e-05
09/25/2020 17:30:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 3981 Ep: 0.37 masked_t 2.494 masked_v 0.755 NSP 0.269 lr 3.66037e-05
09/25/2020 17:30:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 4001 Ep: 0.37 masked_t 2.563 masked_v 0.753 NSP 0.275 lr 3.6788e-05
09/25/2020 17:31:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 4021 Ep: 0.37 masked_t 2.587 masked_v 0.752 NSP 0.258 lr 3.69724e-05
09/25/2020 17:31:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 4041 Ep: 0.37 masked_t 2.504 masked_v 0.739 NSP 0.274 lr 3.71567e-05
09/25/2020 17:31:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 4061 Ep: 0.37 masked_t 2.644 masked_v 0.741 NSP 0.276 lr 3.7341e-05
09/25/2020 17:32:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 4081 Ep: 0.38 masked_t 2.509 masked_v 0.745 NSP 0.280 lr 3.75253e-05
09/25/2020 17:32:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 4101 Ep: 0.38 masked_t 2.626 masked_v 0.749 NSP 0.271 lr 3.77097e-05
09/25/2020 17:32:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 4121 Ep: 0.38 masked_t 2.602 masked_v 0.735 NSP 0.257 lr 3.7894e-05
09/25/2020 17:33:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 4141 Ep: 0.38 masked_t 2.480 masked_v 0.725 NSP 0.265 lr 3.80783e-05
09/25/2020 17:33:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 4161 Ep: 0.38 masked_t 2.501 masked_v 0.728 NSP 0.274 lr 3.82627e-05
09/25/2020 17:33:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 4181 Ep: 0.39 masked_t 2.523 masked_v 0.718 NSP 0.272 lr 3.8447e-05
09/25/2020 17:34:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 4201 Ep: 0.39 masked_t 2.521 masked_v 0.729 NSP 0.262 lr 3.86313e-05
09/25/2020 17:34:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 4221 Ep: 0.39 masked_t 2.467 masked_v 0.722 NSP 0.256 lr 3.88157e-05
09/25/2020 17:34:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 4241 Ep: 0.39 masked_t 2.606 masked_v 0.719 NSP 0.256 lr 3.9e-05
09/25/2020 17:35:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 4261 Ep: 0.39 masked_t 2.484 masked_v 0.714 NSP 0.262 lr 3.91843e-05
09/25/2020 17:35:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 4281 Ep: 0.39 masked_t 2.551 masked_v 0.709 NSP 0.278 lr 3.93687e-05
09/25/2020 17:36:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 4301 Ep: 0.40 masked_t 2.565 masked_v 0.704 NSP 0.274 lr 3.9553e-05
09/25/2020 17:36:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 4321 Ep: 0.40 masked_t 2.588 masked_v 0.714 NSP 0.260 lr 3.97373e-05
09/25/2020 17:36:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 4341 Ep: 0.40 masked_t 2.515 masked_v 0.707 NSP 0.261 lr 3.99217e-05
09/25/2020 17:37:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 4361 Ep: 0.40 masked_t 2.498 masked_v 0.685 NSP 0.259 lr 4.0106e-05
09/25/2020 17:37:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 4381 Ep: 0.40 masked_t 2.476 masked_v 0.710 NSP 0.266 lr 4.02903e-05
09/25/2020 17:37:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 4401 Ep: 0.41 masked_t 2.548 masked_v 0.703 NSP 0.286 lr 4.04747e-05
09/25/2020 17:38:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 4421 Ep: 0.41 masked_t 2.532 masked_v 0.706 NSP 0.260 lr 4.0659e-05
09/25/2020 17:38:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 4441 Ep: 0.41 masked_t 2.525 masked_v 0.706 NSP 0.259 lr 4.08433e-05
09/25/2020 17:38:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 4461 Ep: 0.41 masked_t 2.590 masked_v 0.685 NSP 0.257 lr 4.10276e-05
09/25/2020 17:39:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 4481 Ep: 0.41 masked_t 2.501 masked_v 0.682 NSP 0.260 lr 4.1212e-05
09/25/2020 17:39:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 4501 Ep: 0.41 masked_t 2.459 masked_v 0.702 NSP 0.264 lr 4.13963e-05
09/25/2020 17:39:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 4521 Ep: 0.42 masked_t 2.592 masked_v 0.699 NSP 0.257 lr 4.15806e-05
09/25/2020 17:40:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 4541 Ep: 0.42 masked_t 2.612 masked_v 0.680 NSP 0.263 lr 4.1765e-05
09/25/2020 17:40:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 4561 Ep: 0.42 masked_t 2.590 masked_v 0.675 NSP 0.270 lr 4.19493e-05
09/25/2020 17:40:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 4581 Ep: 0.42 masked_t 2.430 masked_v 0.689 NSP 0.256 lr 4.21336e-05
09/25/2020 17:41:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 4601 Ep: 0.42 masked_t 2.549 masked_v 0.694 NSP 0.274 lr 4.2318e-05
09/25/2020 17:41:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 4621 Ep: 0.43 masked_t 2.496 masked_v 0.683 NSP 0.252 lr 4.25023e-05
09/25/2020 17:42:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 4641 Ep: 0.43 masked_t 2.452 masked_v 0.667 NSP 0.257 lr 4.26866e-05
09/25/2020 17:42:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 4661 Ep: 0.43 masked_t 2.611 masked_v 0.671 NSP 0.257 lr 4.2871e-05
09/25/2020 17:42:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 4681 Ep: 0.43 masked_t 2.527 masked_v 0.665 NSP 0.260 lr 4.30553e-05
09/25/2020 17:43:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 4701 Ep: 0.43 masked_t 2.417 masked_v 0.665 NSP 0.250 lr 4.32396e-05
09/25/2020 17:43:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 4721 Ep: 0.44 masked_t 2.577 masked_v 0.657 NSP 0.256 lr 4.3424e-05
09/25/2020 17:43:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 4741 Ep: 0.44 masked_t 2.506 masked_v 0.664 NSP 0.255 lr 4.36083e-05
09/25/2020 17:44:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 4761 Ep: 0.44 masked_t 2.552 masked_v 0.678 NSP 0.256 lr 4.37926e-05
09/25/2020 17:44:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 4781 Ep: 0.44 masked_t 2.562 masked_v 0.680 NSP 0.276 lr 4.3977e-05
09/25/2020 17:44:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 4801 Ep: 0.44 masked_t 2.510 masked_v 0.654 NSP 0.229 lr 4.41613e-05
09/25/2020 17:45:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 4821 Ep: 0.44 masked_t 2.525 masked_v 0.651 NSP 0.242 lr 4.43456e-05
09/25/2020 17:45:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 4841 Ep: 0.45 masked_t 2.525 masked_v 0.659 NSP 0.256 lr 4.453e-05
09/25/2020 17:46:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 4861 Ep: 0.45 masked_t 2.527 masked_v 0.663 NSP 0.245 lr 4.47143e-05
09/25/2020 17:46:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 4881 Ep: 0.45 masked_t 2.521 masked_v 0.658 NSP 0.252 lr 4.48986e-05
09/25/2020 17:46:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 4901 Ep: 0.45 masked_t 2.528 masked_v 0.649 NSP 0.257 lr 4.50829e-05
09/25/2020 17:47:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 4921 Ep: 0.45 masked_t 2.573 masked_v 0.653 NSP 0.255 lr 4.52673e-05
09/25/2020 17:47:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 4941 Ep: 0.46 masked_t 2.531 masked_v 0.649 NSP 0.260 lr 4.54516e-05
09/25/2020 17:47:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 4961 Ep: 0.46 masked_t 2.573 masked_v 0.639 NSP 0.243 lr 4.56359e-05
09/25/2020 17:48:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 4981 Ep: 0.46 masked_t 2.525 masked_v 0.641 NSP 0.248 lr 4.58203e-05
09/25/2020 17:48:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 5001 Ep: 0.46 masked_t 2.504 masked_v 0.638 NSP 0.235 lr 4.60046e-05
09/25/2020 17:48:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 5021 Ep: 0.46 masked_t 2.629 masked_v 0.650 NSP 0.260 lr 4.61889e-05
09/25/2020 17:49:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 5041 Ep: 0.46 masked_t 2.547 masked_v 0.639 NSP 0.248 lr 4.63733e-05
09/25/2020 17:49:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 5061 Ep: 0.47 masked_t 2.521 masked_v 0.637 NSP 0.244 lr 4.65576e-05
09/25/2020 17:49:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 5081 Ep: 0.47 masked_t 2.569 masked_v 0.651 NSP 0.247 lr 4.67419e-05
09/25/2020 17:50:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 5101 Ep: 0.47 masked_t 2.604 masked_v 0.633 NSP 0.235 lr 4.69263e-05
09/25/2020 17:50:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 5121 Ep: 0.47 masked_t 2.562 masked_v 0.629 NSP 0.266 lr 4.71106e-05
09/25/2020 17:50:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 5141 Ep: 0.47 masked_t 2.520 masked_v 0.639 NSP 0.258 lr 4.72949e-05
09/25/2020 17:51:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 5161 Ep: 0.48 masked_t 2.541 masked_v 0.618 NSP 0.240 lr 4.74793e-05
09/25/2020 17:51:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 5181 Ep: 0.48 masked_t 2.469 masked_v 0.600 NSP 0.252 lr 4.76636e-05
09/25/2020 17:52:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 5201 Ep: 0.48 masked_t 2.511 masked_v 0.624 NSP 0.241 lr 4.78479e-05
09/25/2020 17:52:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 5221 Ep: 0.48 masked_t 2.594 masked_v 0.647 NSP 0.255 lr 4.80323e-05
09/25/2020 17:52:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 5241 Ep: 0.48 masked_t 2.500 masked_v 0.631 NSP 0.246 lr 4.82166e-05
09/25/2020 17:53:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 5261 Ep: 0.48 masked_t 2.543 masked_v 0.628 NSP 0.254 lr 4.84009e-05
09/25/2020 17:53:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 5281 Ep: 0.49 masked_t 2.490 masked_v 0.624 NSP 0.246 lr 4.85853e-05
09/25/2020 17:53:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 5301 Ep: 0.49 masked_t 2.454 masked_v 0.614 NSP 0.231 lr 4.87696e-05
09/25/2020 17:54:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 5321 Ep: 0.49 masked_t 2.543 masked_v 0.620 NSP 0.251 lr 4.89539e-05
09/25/2020 17:54:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 5341 Ep: 0.49 masked_t 2.419 masked_v 0.606 NSP 0.251 lr 4.91382e-05
09/25/2020 17:54:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 5361 Ep: 0.49 masked_t 2.477 masked_v 0.602 NSP 0.258 lr 4.93226e-05
09/25/2020 17:55:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 5381 Ep: 0.50 masked_t 2.334 masked_v 0.613 NSP 0.243 lr 4.95069e-05
09/25/2020 17:55:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 5401 Ep: 0.50 masked_t 2.538 masked_v 0.626 NSP 0.251 lr 4.96912e-05
09/25/2020 17:55:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 5421 Ep: 0.50 masked_t 2.518 masked_v 0.625 NSP 0.251 lr 4.98756e-05
09/25/2020 17:56:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 5441 Ep: 0.50 masked_t 2.423 masked_v 0.612 NSP 0.244 lr 5.00599e-05
09/25/2020 17:56:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 5461 Ep: 0.50 masked_t 2.425 masked_v 0.602 NSP 0.251 lr 5.02442e-05
09/25/2020 17:57:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 5481 Ep: 0.51 masked_t 2.556 masked_v 0.604 NSP 0.260 lr 5.04286e-05
09/25/2020 17:57:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 5501 Ep: 0.51 masked_t 2.420 masked_v 0.610 NSP 0.229 lr 5.06129e-05
09/25/2020 17:57:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 5521 Ep: 0.51 masked_t 2.532 masked_v 0.616 NSP 0.254 lr 5.07972e-05
09/25/2020 17:58:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 5541 Ep: 0.51 masked_t 2.424 masked_v 0.612 NSP 0.255 lr 5.09816e-05
09/25/2020 17:58:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 5561 Ep: 0.51 masked_t 2.628 masked_v 0.606 NSP 0.257 lr 5.11659e-05
09/25/2020 17:58:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 5581 Ep: 0.51 masked_t 2.375 masked_v 0.587 NSP 0.239 lr 5.13502e-05
09/25/2020 17:59:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 5601 Ep: 0.52 masked_t 2.426 masked_v 0.596 NSP 0.229 lr 5.15346e-05
09/25/2020 17:59:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 5621 Ep: 0.52 masked_t 2.423 masked_v 0.594 NSP 0.243 lr 5.17189e-05
09/25/2020 17:59:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 5641 Ep: 0.52 masked_t 2.476 masked_v 0.602 NSP 0.233 lr 5.19032e-05
09/25/2020 18:00:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 5661 Ep: 0.52 masked_t 2.538 masked_v 0.600 NSP 0.247 lr 5.20876e-05
09/25/2020 18:00:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 5681 Ep: 0.52 masked_t 2.417 masked_v 0.595 NSP 0.251 lr 5.22719e-05
09/25/2020 18:00:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 5701 Ep: 0.53 masked_t 2.389 masked_v 0.599 NSP 0.237 lr 5.24562e-05
09/25/2020 18:01:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 5721 Ep: 0.53 masked_t 2.499 masked_v 0.596 NSP 0.247 lr 5.26406e-05
09/25/2020 18:01:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 5741 Ep: 0.53 masked_t 2.420 masked_v 0.592 NSP 0.263 lr 5.28249e-05
09/25/2020 18:02:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 5761 Ep: 0.53 masked_t 2.601 masked_v 0.599 NSP 0.242 lr 5.30092e-05
09/25/2020 18:02:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 5781 Ep: 0.53 masked_t 2.313 masked_v 0.594 NSP 0.230 lr 5.31935e-05
09/25/2020 18:02:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 5801 Ep: 0.53 masked_t 2.432 masked_v 0.587 NSP 0.228 lr 5.33779e-05
09/25/2020 18:03:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 5821 Ep: 0.54 masked_t 2.535 masked_v 0.602 NSP 0.232 lr 5.35622e-05
09/25/2020 18:03:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 5841 Ep: 0.54 masked_t 2.427 masked_v 0.586 NSP 0.240 lr 5.37465e-05
09/25/2020 18:03:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 5861 Ep: 0.54 masked_t 2.437 masked_v 0.600 NSP 0.249 lr 5.39309e-05
09/25/2020 18:04:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 5881 Ep: 0.54 masked_t 2.460 masked_v 0.578 NSP 0.243 lr 5.41152e-05
09/25/2020 18:04:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 5901 Ep: 0.54 masked_t 2.463 masked_v 0.594 NSP 0.241 lr 5.42995e-05
09/25/2020 18:04:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 5921 Ep: 0.55 masked_t 2.463 masked_v 0.594 NSP 0.231 lr 5.44839e-05
09/25/2020 18:05:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 5941 Ep: 0.55 masked_t 2.472 masked_v 0.579 NSP 0.233 lr 5.46682e-05
09/25/2020 18:05:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 5961 Ep: 0.55 masked_t 2.509 masked_v 0.570 NSP 0.243 lr 5.48525e-05
09/25/2020 18:05:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 5981 Ep: 0.55 masked_t 2.505 masked_v 0.586 NSP 0.237 lr 5.50369e-05
09/25/2020 18:06:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 6001 Ep: 0.55 masked_t 2.540 masked_v 0.592 NSP 0.243 lr 5.52212e-05
09/25/2020 18:06:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 6021 Ep: 0.55 masked_t 2.474 masked_v 0.582 NSP 0.224 lr 5.54055e-05
09/25/2020 18:06:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 6041 Ep: 0.56 masked_t 2.455 masked_v 0.565 NSP 0.227 lr 5.55899e-05
09/25/2020 18:07:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 6061 Ep: 0.56 masked_t 2.413 masked_v 0.580 NSP 0.226 lr 5.57742e-05
09/25/2020 18:07:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 6081 Ep: 0.56 masked_t 2.441 masked_v 0.571 NSP 0.246 lr 5.59585e-05
09/25/2020 18:08:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 6101 Ep: 0.56 masked_t 2.415 masked_v 0.589 NSP 0.240 lr 5.61429e-05
09/25/2020 18:08:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 6121 Ep: 0.56 masked_t 2.492 masked_v 0.561 NSP 0.234 lr 5.63272e-05
09/25/2020 18:08:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 6141 Ep: 0.57 masked_t 2.393 masked_v 0.579 NSP 0.231 lr 5.65115e-05
09/25/2020 18:09:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 6161 Ep: 0.57 masked_t 2.449 masked_v 0.567 NSP 0.239 lr 5.66959e-05
09/25/2020 18:09:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 6181 Ep: 0.57 masked_t 2.599 masked_v 0.562 NSP 0.240 lr 5.68802e-05
09/25/2020 18:09:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 6201 Ep: 0.57 masked_t 2.562 masked_v 0.572 NSP 0.233 lr 5.70645e-05
09/25/2020 18:10:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 6221 Ep: 0.57 masked_t 2.532 masked_v 0.579 NSP 0.241 lr 5.72488e-05
09/25/2020 18:10:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 6241 Ep: 0.58 masked_t 2.503 masked_v 0.578 NSP 0.229 lr 5.74332e-05
09/25/2020 18:10:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 6261 Ep: 0.58 masked_t 2.496 masked_v 0.559 NSP 0.229 lr 5.76175e-05
09/25/2020 18:11:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 6281 Ep: 0.58 masked_t 2.392 masked_v 0.566 NSP 0.238 lr 5.78018e-05
09/25/2020 18:11:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 6301 Ep: 0.58 masked_t 2.391 masked_v 0.559 NSP 0.235 lr 5.79862e-05
09/25/2020 18:11:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 6321 Ep: 0.58 masked_t 2.451 masked_v 0.573 NSP 0.241 lr 5.81705e-05
09/25/2020 18:12:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 6341 Ep: 0.58 masked_t 2.478 masked_v 0.572 NSP 0.227 lr 5.83548e-05
09/25/2020 18:12:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 6361 Ep: 0.59 masked_t 2.486 masked_v 0.560 NSP 0.232 lr 5.85392e-05
09/25/2020 18:13:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 6381 Ep: 0.59 masked_t 2.511 masked_v 0.565 NSP 0.253 lr 5.87235e-05
09/25/2020 18:13:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 6401 Ep: 0.59 masked_t 2.370 masked_v 0.561 NSP 0.224 lr 5.89078e-05
09/25/2020 18:14:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 6421 Ep: 0.59 masked_t 2.425 masked_v 0.561 NSP 0.228 lr 5.90922e-05
09/25/2020 18:14:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 6441 Ep: 0.59 masked_t 2.392 masked_v 0.551 NSP 0.230 lr 5.92765e-05
09/25/2020 18:14:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 6461 Ep: 0.60 masked_t 2.523 masked_v 0.560 NSP 0.244 lr 5.94608e-05
09/25/2020 18:15:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 6481 Ep: 0.60 masked_t 2.485 masked_v 0.550 NSP 0.234 lr 5.96452e-05
09/25/2020 18:15:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 6501 Ep: 0.60 masked_t 2.501 masked_v 0.549 NSP 0.224 lr 5.98295e-05
09/25/2020 18:15:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 6521 Ep: 0.60 masked_t 2.431 masked_v 0.551 NSP 0.221 lr 6.00138e-05
09/25/2020 18:16:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 6541 Ep: 0.60 masked_t 2.515 masked_v 0.565 NSP 0.233 lr 6.01982e-05
09/25/2020 18:16:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 6561 Ep: 0.60 masked_t 2.475 masked_v 0.557 NSP 0.251 lr 6.03825e-05
09/25/2020 18:16:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 6581 Ep: 0.61 masked_t 2.431 masked_v 0.548 NSP 0.227 lr 6.05668e-05
09/25/2020 18:17:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 6601 Ep: 0.61 masked_t 2.409 masked_v 0.564 NSP 0.234 lr 6.07512e-05
09/25/2020 18:17:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 6621 Ep: 0.61 masked_t 2.327 masked_v 0.552 NSP 0.224 lr 6.09355e-05
09/25/2020 18:17:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 6641 Ep: 0.61 masked_t 2.374 masked_v 0.568 NSP 0.237 lr 6.11198e-05
09/25/2020 18:18:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 6661 Ep: 0.61 masked_t 2.398 masked_v 0.541 NSP 0.240 lr 6.13041e-05
09/25/2020 18:18:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 6681 Ep: 0.62 masked_t 2.393 masked_v 0.557 NSP 0.226 lr 6.14885e-05
09/25/2020 18:19:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 6701 Ep: 0.62 masked_t 2.372 masked_v 0.558 NSP 0.236 lr 6.16728e-05
09/25/2020 18:19:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 6721 Ep: 0.62 masked_t 2.425 masked_v 0.549 NSP 0.221 lr 6.18571e-05
09/25/2020 18:19:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 6741 Ep: 0.62 masked_t 2.451 masked_v 0.552 NSP 0.235 lr 6.20415e-05
09/25/2020 18:20:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 6761 Ep: 0.62 masked_t 2.394 masked_v 0.560 NSP 0.230 lr 6.22258e-05
09/25/2020 18:20:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 6781 Ep: 0.62 masked_t 2.448 masked_v 0.558 NSP 0.227 lr 6.24101e-05
09/25/2020 18:20:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 6801 Ep: 0.63 masked_t 2.475 masked_v 0.555 NSP 0.228 lr 6.25945e-05
09/25/2020 18:21:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 6821 Ep: 0.63 masked_t 2.452 masked_v 0.551 NSP 0.229 lr 6.27788e-05
09/25/2020 18:21:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 6841 Ep: 0.63 masked_t 2.491 masked_v 0.547 NSP 0.219 lr 6.29631e-05
09/25/2020 18:22:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 6861 Ep: 0.63 masked_t 2.492 masked_v 0.521 NSP 0.222 lr 6.31475e-05
09/25/2020 18:22:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 6881 Ep: 0.63 masked_t 2.487 masked_v 0.548 NSP 0.226 lr 6.33318e-05
09/25/2020 18:22:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 6901 Ep: 0.64 masked_t 2.449 masked_v 0.539 NSP 0.231 lr 6.35161e-05
09/25/2020 18:23:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 6921 Ep: 0.64 masked_t 2.500 masked_v 0.540 NSP 0.233 lr 6.37005e-05
09/25/2020 18:23:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 6941 Ep: 0.64 masked_t 2.435 masked_v 0.545 NSP 0.222 lr 6.38848e-05
09/25/2020 18:23:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 6961 Ep: 0.64 masked_t 2.441 masked_v 0.538 NSP 0.228 lr 6.40691e-05
09/25/2020 18:24:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 6981 Ep: 0.64 masked_t 2.444 masked_v 0.551 NSP 0.221 lr 6.42535e-05
09/25/2020 18:24:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 7001 Ep: 0.65 masked_t 2.434 masked_v 0.547 NSP 0.221 lr 6.44378e-05
09/25/2020 18:24:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 7021 Ep: 0.65 masked_t 2.388 masked_v 0.541 NSP 0.228 lr 6.46221e-05
09/25/2020 18:25:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 7041 Ep: 0.65 masked_t 2.391 masked_v 0.538 NSP 0.231 lr 6.48065e-05
09/25/2020 18:25:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 7061 Ep: 0.65 masked_t 2.395 masked_v 0.552 NSP 0.219 lr 6.49908e-05
09/25/2020 18:25:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 7081 Ep: 0.65 masked_t 2.453 masked_v 0.544 NSP 0.219 lr 6.51751e-05
09/25/2020 18:26:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 7101 Ep: 0.65 masked_t 2.361 masked_v 0.539 NSP 0.233 lr 6.53594e-05
09/25/2020 18:26:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 7121 Ep: 0.66 masked_t 2.436 masked_v 0.534 NSP 0.217 lr 6.55438e-05
09/25/2020 18:27:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 7141 Ep: 0.66 masked_t 2.449 masked_v 0.518 NSP 0.223 lr 6.57281e-05
09/25/2020 18:27:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 7161 Ep: 0.66 masked_t 2.481 masked_v 0.530 NSP 0.220 lr 6.59124e-05
09/25/2020 18:27:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 7181 Ep: 0.66 masked_t 2.428 masked_v 0.536 NSP 0.230 lr 6.60968e-05
09/25/2020 18:28:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 7201 Ep: 0.66 masked_t 2.446 masked_v 0.526 NSP 0.238 lr 6.62811e-05
09/25/2020 18:28:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 7221 Ep: 0.67 masked_t 2.484 masked_v 0.529 NSP 0.234 lr 6.64654e-05
09/25/2020 18:28:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 7241 Ep: 0.67 masked_t 2.446 masked_v 0.537 NSP 0.230 lr 6.66498e-05
09/25/2020 18:29:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 7261 Ep: 0.67 masked_t 2.500 masked_v 0.535 NSP 0.220 lr 6.68341e-05
09/25/2020 18:29:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 7281 Ep: 0.67 masked_t 2.489 masked_v 0.522 NSP 0.213 lr 6.70184e-05
09/25/2020 18:29:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 7301 Ep: 0.67 masked_t 2.436 masked_v 0.536 NSP 0.218 lr 6.72028e-05
09/25/2020 18:30:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 7321 Ep: 0.67 masked_t 2.362 masked_v 0.535 NSP 0.231 lr 6.73871e-05
09/25/2020 18:30:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 7341 Ep: 0.68 masked_t 2.514 masked_v 0.536 NSP 0.223 lr 6.75714e-05
09/25/2020 18:31:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 7361 Ep: 0.68 masked_t 2.323 masked_v 0.520 NSP 0.231 lr 6.77558e-05
09/25/2020 18:31:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 7381 Ep: 0.68 masked_t 2.411 masked_v 0.523 NSP 0.208 lr 6.79401e-05
09/25/2020 18:31:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 7401 Ep: 0.68 masked_t 2.425 masked_v 0.527 NSP 0.216 lr 6.81244e-05
09/25/2020 18:32:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 7421 Ep: 0.68 masked_t 2.447 masked_v 0.529 NSP 0.221 lr 6.83088e-05
09/25/2020 18:32:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 7441 Ep: 0.69 masked_t 2.403 masked_v 0.538 NSP 0.221 lr 6.84931e-05
09/25/2020 18:32:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 7461 Ep: 0.69 masked_t 2.451 masked_v 0.530 NSP 0.223 lr 6.86774e-05
09/25/2020 18:33:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 7481 Ep: 0.69 masked_t 2.418 masked_v 0.523 NSP 0.234 lr 6.88618e-05
09/25/2020 18:33:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 7501 Ep: 0.69 masked_t 2.334 masked_v 0.521 NSP 0.220 lr 6.90461e-05
09/25/2020 18:33:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 7521 Ep: 0.69 masked_t 2.420 masked_v 0.520 NSP 0.222 lr 6.92304e-05
09/25/2020 18:34:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 7541 Ep: 0.70 masked_t 2.385 masked_v 0.532 NSP 0.226 lr 6.94147e-05
09/25/2020 18:34:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 7561 Ep: 0.70 masked_t 2.352 masked_v 0.529 NSP 0.223 lr 6.95991e-05
09/25/2020 18:34:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 7581 Ep: 0.70 masked_t 2.430 masked_v 0.523 NSP 0.223 lr 6.97834e-05
09/25/2020 18:35:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 7601 Ep: 0.70 masked_t 2.375 masked_v 0.531 NSP 0.220 lr 6.99677e-05
09/25/2020 18:35:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 7621 Ep: 0.70 masked_t 2.447 masked_v 0.526 NSP 0.222 lr 7.01521e-05
09/25/2020 18:35:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 7641 Ep: 0.70 masked_t 2.333 masked_v 0.517 NSP 0.219 lr 7.03364e-05
09/25/2020 18:36:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 7661 Ep: 0.71 masked_t 2.403 masked_v 0.530 NSP 0.221 lr 7.05207e-05
09/25/2020 18:36:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 7681 Ep: 0.71 masked_t 2.412 masked_v 0.513 NSP 0.219 lr 7.07051e-05
09/25/2020 18:37:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 7701 Ep: 0.71 masked_t 2.459 masked_v 0.519 NSP 0.230 lr 7.08894e-05
09/25/2020 18:37:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 7721 Ep: 0.71 masked_t 2.413 masked_v 0.521 NSP 0.217 lr 7.10737e-05
09/25/2020 18:37:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 7741 Ep: 0.71 masked_t 2.475 masked_v 0.515 NSP 0.227 lr 7.12581e-05
09/25/2020 18:38:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 7761 Ep: 0.72 masked_t 2.433 masked_v 0.516 NSP 0.218 lr 7.14424e-05
09/25/2020 18:38:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 7781 Ep: 0.72 masked_t 2.439 masked_v 0.506 NSP 0.212 lr 7.16267e-05
09/25/2020 18:38:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 7801 Ep: 0.72 masked_t 2.348 masked_v 0.509 NSP 0.215 lr 7.18111e-05
09/25/2020 18:39:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 7821 Ep: 0.72 masked_t 2.417 masked_v 0.515 NSP 0.230 lr 7.19954e-05
09/25/2020 18:39:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 7841 Ep: 0.72 masked_t 2.340 masked_v 0.512 NSP 0.222 lr 7.21797e-05
09/25/2020 18:39:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 7861 Ep: 0.72 masked_t 2.389 masked_v 0.506 NSP 0.205 lr 7.23641e-05
09/25/2020 18:40:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 7881 Ep: 0.73 masked_t 2.407 masked_v 0.515 NSP 0.220 lr 7.25484e-05
09/25/2020 18:40:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 7901 Ep: 0.73 masked_t 2.442 masked_v 0.524 NSP 0.206 lr 7.27327e-05
09/25/2020 18:40:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 7921 Ep: 0.73 masked_t 2.465 masked_v 0.507 NSP 0.213 lr 7.29171e-05
09/25/2020 18:41:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 7941 Ep: 0.73 masked_t 2.361 masked_v 0.502 NSP 0.209 lr 7.31014e-05
09/25/2020 18:41:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 7961 Ep: 0.73 masked_t 2.367 masked_v 0.503 NSP 0.200 lr 7.32857e-05
09/25/2020 18:42:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 7981 Ep: 0.74 masked_t 2.410 masked_v 0.508 NSP 0.207 lr 7.347e-05
09/25/2020 18:42:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 8001 Ep: 0.74 masked_t 2.372 masked_v 0.517 NSP 0.215 lr 7.36544e-05
09/25/2020 18:42:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 8021 Ep: 0.74 masked_t 2.435 masked_v 0.516 NSP 0.216 lr 7.38387e-05
09/25/2020 18:43:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 8041 Ep: 0.74 masked_t 2.436 masked_v 0.516 NSP 0.217 lr 7.4023e-05
09/25/2020 18:43:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 8061 Ep: 0.74 masked_t 2.487 masked_v 0.515 NSP 0.215 lr 7.42074e-05
09/25/2020 18:43:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 8081 Ep: 0.74 masked_t 2.410 masked_v 0.519 NSP 0.220 lr 7.43917e-05
09/25/2020 18:44:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 8101 Ep: 0.75 masked_t 2.496 masked_v 0.512 NSP 0.202 lr 7.4576e-05
09/25/2020 18:44:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 8121 Ep: 0.75 masked_t 2.328 masked_v 0.510 NSP 0.210 lr 7.47604e-05
09/25/2020 18:44:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 8141 Ep: 0.75 masked_t 2.513 masked_v 0.499 NSP 0.220 lr 7.49447e-05
09/25/2020 18:45:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 8161 Ep: 0.75 masked_t 2.442 masked_v 0.514 NSP 0.198 lr 7.5129e-05
09/25/2020 18:45:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 8181 Ep: 0.75 masked_t 2.436 masked_v 0.515 NSP 0.222 lr 7.53134e-05
09/25/2020 18:45:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 8201 Ep: 0.76 masked_t 2.429 masked_v 0.511 NSP 0.215 lr 7.54977e-05
09/25/2020 18:46:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 8221 Ep: 0.76 masked_t 2.400 masked_v 0.507 NSP 0.208 lr 7.5682e-05
09/25/2020 18:46:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 8241 Ep: 0.76 masked_t 2.358 masked_v 0.510 NSP 0.200 lr 7.58664e-05
09/25/2020 18:47:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 8261 Ep: 0.76 masked_t 2.416 masked_v 0.504 NSP 0.213 lr 7.60507e-05
09/25/2020 18:47:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 8281 Ep: 0.76 masked_t 2.413 masked_v 0.508 NSP 0.220 lr 7.6235e-05
09/25/2020 18:47:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 8301 Ep: 0.77 masked_t 2.257 masked_v 0.501 NSP 0.217 lr 7.64194e-05
09/25/2020 18:48:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 8321 Ep: 0.77 masked_t 2.448 masked_v 0.493 NSP 0.223 lr 7.66037e-05
09/25/2020 18:48:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 8341 Ep: 0.77 masked_t 2.392 masked_v 0.498 NSP 0.212 lr 7.6788e-05
09/25/2020 18:48:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 8361 Ep: 0.77 masked_t 2.374 masked_v 0.503 NSP 0.222 lr 7.69724e-05
09/25/2020 18:49:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 8381 Ep: 0.77 masked_t 2.329 masked_v 0.495 NSP 0.198 lr 7.71567e-05
09/25/2020 18:49:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 8401 Ep: 0.77 masked_t 2.393 masked_v 0.497 NSP 0.206 lr 7.7341e-05
09/25/2020 18:50:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 8421 Ep: 0.78 masked_t 2.304 masked_v 0.504 NSP 0.206 lr 7.75253e-05
09/25/2020 18:50:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 8441 Ep: 0.78 masked_t 2.348 masked_v 0.503 NSP 0.223 lr 7.77097e-05
09/25/2020 18:51:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 8461 Ep: 0.78 masked_t 2.366 masked_v 0.508 NSP 0.208 lr 7.7894e-05
09/25/2020 18:51:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 8481 Ep: 0.78 masked_t 2.447 masked_v 0.501 NSP 0.205 lr 7.80783e-05
09/25/2020 18:51:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 8501 Ep: 0.78 masked_t 2.494 masked_v 0.495 NSP 0.213 lr 7.82627e-05
09/25/2020 18:52:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 8521 Ep: 0.79 masked_t 2.378 masked_v 0.505 NSP 0.207 lr 7.8447e-05
09/25/2020 18:52:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 8541 Ep: 0.79 masked_t 2.355 masked_v 0.505 NSP 0.215 lr 7.86313e-05
09/25/2020 18:53:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 8561 Ep: 0.79 masked_t 2.344 masked_v 0.492 NSP 0.212 lr 7.88157e-05
09/25/2020 18:53:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 8581 Ep: 0.79 masked_t 2.412 masked_v 0.490 NSP 0.217 lr 7.9e-05
09/25/2020 18:54:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 8601 Ep: 0.79 masked_t 2.367 masked_v 0.507 NSP 0.211 lr 7.91843e-05
09/25/2020 18:54:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 8621 Ep: 0.79 masked_t 2.308 masked_v 0.498 NSP 0.211 lr 7.93687e-05
09/25/2020 18:54:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 8641 Ep: 0.80 masked_t 2.390 masked_v 0.502 NSP 0.208 lr 7.9553e-05
09/25/2020 18:55:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 8661 Ep: 0.80 masked_t 2.359 masked_v 0.492 NSP 0.214 lr 7.97373e-05
09/25/2020 18:55:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 8681 Ep: 0.80 masked_t 2.363 masked_v 0.503 NSP 0.194 lr 7.99217e-05
09/25/2020 18:55:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 8701 Ep: 0.80 masked_t 2.413 masked_v 0.482 NSP 0.202 lr 8.0106e-05
09/25/2020 18:56:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 8721 Ep: 0.80 masked_t 2.397 masked_v 0.493 NSP 0.206 lr 8.02903e-05
09/25/2020 18:56:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 8741 Ep: 0.81 masked_t 2.407 masked_v 0.486 NSP 0.207 lr 8.04747e-05
09/25/2020 18:56:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 8761 Ep: 0.81 masked_t 2.482 masked_v 0.489 NSP 0.206 lr 8.0659e-05
09/25/2020 18:57:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 8781 Ep: 0.81 masked_t 2.352 masked_v 0.487 NSP 0.211 lr 8.08433e-05
09/25/2020 18:57:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 8801 Ep: 0.81 masked_t 2.322 masked_v 0.493 NSP 0.202 lr 8.10276e-05
09/25/2020 18:58:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 8821 Ep: 0.81 masked_t 2.391 masked_v 0.485 NSP 0.218 lr 8.1212e-05
09/25/2020 18:58:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 8841 Ep: 0.81 masked_t 2.464 masked_v 0.483 NSP 0.210 lr 8.13963e-05
09/25/2020 18:58:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 8861 Ep: 0.82 masked_t 2.391 masked_v 0.494 NSP 0.198 lr 8.15806e-05
09/25/2020 18:59:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 8881 Ep: 0.82 masked_t 2.238 masked_v 0.486 NSP 0.214 lr 8.1765e-05
09/25/2020 18:59:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 8901 Ep: 0.82 masked_t 2.396 masked_v 0.500 NSP 0.207 lr 8.19493e-05
09/25/2020 18:59:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 8921 Ep: 0.82 masked_t 2.391 masked_v 0.488 NSP 0.211 lr 8.21336e-05
09/25/2020 19:00:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 8941 Ep: 0.82 masked_t 2.330 masked_v 0.483 NSP 0.207 lr 8.2318e-05
09/25/2020 19:00:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 8961 Ep: 0.83 masked_t 2.459 masked_v 0.484 NSP 0.205 lr 8.25023e-05
09/25/2020 19:00:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 8981 Ep: 0.83 masked_t 2.430 masked_v 0.491 NSP 0.206 lr 8.26866e-05
09/25/2020 19:01:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 9001 Ep: 0.83 masked_t 2.423 masked_v 0.486 NSP 0.204 lr 8.2871e-05
09/25/2020 19:01:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 9021 Ep: 0.83 masked_t 2.407 masked_v 0.494 NSP 0.205 lr 8.30553e-05
09/25/2020 19:02:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 9041 Ep: 0.83 masked_t 2.329 masked_v 0.488 NSP 0.218 lr 8.32396e-05
09/25/2020 19:02:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 9061 Ep: 0.84 masked_t 2.371 masked_v 0.475 NSP 0.203 lr 8.3424e-05
09/25/2020 19:02:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 9081 Ep: 0.84 masked_t 2.391 masked_v 0.491 NSP 0.209 lr 8.36083e-05
09/25/2020 19:03:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 9101 Ep: 0.84 masked_t 2.423 masked_v 0.490 NSP 0.216 lr 8.37926e-05
09/25/2020 19:03:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 9121 Ep: 0.84 masked_t 2.530 masked_v 0.498 NSP 0.198 lr 8.3977e-05
09/25/2020 19:03:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 9141 Ep: 0.84 masked_t 2.368 masked_v 0.480 NSP 0.202 lr 8.41613e-05
09/25/2020 19:04:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 9161 Ep: 0.84 masked_t 2.394 masked_v 0.496 NSP 0.196 lr 8.43456e-05
09/25/2020 19:04:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 9181 Ep: 0.85 masked_t 2.417 masked_v 0.481 NSP 0.213 lr 8.453e-05
09/25/2020 19:04:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 9201 Ep: 0.85 masked_t 2.277 masked_v 0.472 NSP 0.205 lr 8.47143e-05
09/25/2020 19:05:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 9221 Ep: 0.85 masked_t 2.432 masked_v 0.470 NSP 0.212 lr 8.48986e-05
09/25/2020 19:05:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 9241 Ep: 0.85 masked_t 2.427 masked_v 0.482 NSP 0.221 lr 8.50829e-05
09/25/2020 19:05:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 9261 Ep: 0.85 masked_t 2.382 masked_v 0.498 NSP 0.218 lr 8.52673e-05
09/25/2020 19:06:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 9281 Ep: 0.86 masked_t 2.434 masked_v 0.484 NSP 0.213 lr 8.54516e-05
09/25/2020 19:06:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 9301 Ep: 0.86 masked_t 2.319 masked_v 0.488 NSP 0.214 lr 8.56359e-05
09/25/2020 19:07:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 9321 Ep: 0.86 masked_t 2.351 masked_v 0.478 NSP 0.222 lr 8.58203e-05
09/25/2020 19:07:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 9341 Ep: 0.86 masked_t 2.430 masked_v 0.483 NSP 0.206 lr 8.60046e-05
09/25/2020 19:07:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 9361 Ep: 0.86 masked_t 2.391 masked_v 0.476 NSP 0.207 lr 8.61889e-05
09/25/2020 19:08:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 9381 Ep: 0.86 masked_t 2.346 masked_v 0.477 NSP 0.225 lr 8.63733e-05
09/25/2020 19:08:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 9401 Ep: 0.87 masked_t 2.354 masked_v 0.489 NSP 0.210 lr 8.65576e-05
09/25/2020 19:08:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 9421 Ep: 0.87 masked_t 2.435 masked_v 0.486 NSP 0.205 lr 8.67419e-05
09/25/2020 19:09:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 9441 Ep: 0.87 masked_t 2.440 masked_v 0.484 NSP 0.205 lr 8.69263e-05
09/25/2020 19:09:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 9461 Ep: 0.87 masked_t 2.400 masked_v 0.474 NSP 0.195 lr 8.71106e-05
09/25/2020 19:09:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 9481 Ep: 0.87 masked_t 2.338 masked_v 0.486 NSP 0.213 lr 8.72949e-05
09/25/2020 19:10:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 9501 Ep: 0.88 masked_t 2.318 masked_v 0.480 NSP 0.197 lr 8.74793e-05
09/25/2020 19:10:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 9521 Ep: 0.88 masked_t 2.337 masked_v 0.478 NSP 0.205 lr 8.76636e-05
09/25/2020 19:10:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 9541 Ep: 0.88 masked_t 2.357 masked_v 0.484 NSP 0.206 lr 8.78479e-05
09/25/2020 19:11:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 9561 Ep: 0.88 masked_t 2.429 masked_v 0.480 NSP 0.208 lr 8.80323e-05
09/25/2020 19:11:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 9581 Ep: 0.88 masked_t 2.477 masked_v 0.488 NSP 0.213 lr 8.82166e-05
09/25/2020 19:11:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 9601 Ep: 0.88 masked_t 2.458 masked_v 0.478 NSP 0.206 lr 8.84009e-05
09/25/2020 19:12:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 9621 Ep: 0.89 masked_t 2.398 masked_v 0.478 NSP 0.202 lr 8.85853e-05
09/25/2020 19:12:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 9641 Ep: 0.89 masked_t 2.421 masked_v 0.472 NSP 0.204 lr 8.87696e-05
09/25/2020 19:12:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 9661 Ep: 0.89 masked_t 2.294 masked_v 0.488 NSP 0.209 lr 8.89539e-05
09/25/2020 19:13:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 9681 Ep: 0.89 masked_t 2.498 masked_v 0.495 NSP 0.221 lr 8.91382e-05
09/25/2020 19:13:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 9701 Ep: 0.89 masked_t 2.408 masked_v 0.472 NSP 0.201 lr 8.93226e-05
09/25/2020 19:14:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 9721 Ep: 0.90 masked_t 2.424 masked_v 0.485 NSP 0.192 lr 8.95069e-05
09/25/2020 19:14:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 9741 Ep: 0.90 masked_t 2.336 masked_v 0.464 NSP 0.210 lr 8.96912e-05
09/25/2020 19:14:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 9761 Ep: 0.90 masked_t 2.420 masked_v 0.466 NSP 0.201 lr 8.98756e-05
09/25/2020 19:15:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 9781 Ep: 0.90 masked_t 2.421 masked_v 0.475 NSP 0.215 lr 9.00599e-05
09/25/2020 19:15:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 9801 Ep: 0.90 masked_t 2.357 masked_v 0.474 NSP 0.205 lr 9.02442e-05
09/25/2020 19:15:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 9821 Ep: 0.91 masked_t 2.353 masked_v 0.468 NSP 0.196 lr 9.04286e-05
09/25/2020 19:16:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 9841 Ep: 0.91 masked_t 2.407 masked_v 0.490 NSP 0.202 lr 9.06129e-05
09/25/2020 19:16:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 9861 Ep: 0.91 masked_t 2.389 masked_v 0.473 NSP 0.203 lr 9.07972e-05
09/25/2020 19:16:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 9881 Ep: 0.91 masked_t 2.410 masked_v 0.468 NSP 0.219 lr 9.09816e-05
09/25/2020 19:17:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 9901 Ep: 0.91 masked_t 2.345 masked_v 0.475 NSP 0.205 lr 9.11659e-05
09/25/2020 19:17:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 9921 Ep: 0.91 masked_t 2.410 masked_v 0.467 NSP 0.199 lr 9.13502e-05
09/25/2020 19:17:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 9941 Ep: 0.92 masked_t 2.331 masked_v 0.469 NSP 0.208 lr 9.15346e-05
09/25/2020 19:18:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 9961 Ep: 0.92 masked_t 2.432 masked_v 0.477 NSP 0.217 lr 9.17189e-05
09/25/2020 19:18:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 9981 Ep: 0.92 masked_t 2.411 masked_v 0.472 NSP 0.201 lr 9.19032e-05
09/25/2020 19:18:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 10001 Ep: 0.92 masked_t 2.314 masked_v 0.475 NSP 0.206 lr 9.20876e-05
09/25/2020 19:19:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 10021 Ep: 0.92 masked_t 2.368 masked_v 0.471 NSP 0.199 lr 9.22719e-05
09/25/2020 19:19:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 10041 Ep: 0.93 masked_t 2.396 masked_v 0.468 NSP 0.192 lr 9.24562e-05
09/25/2020 19:19:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 10061 Ep: 0.93 masked_t 2.434 masked_v 0.479 NSP 0.211 lr 9.26406e-05
09/25/2020 19:20:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 10081 Ep: 0.93 masked_t 2.316 masked_v 0.470 NSP 0.205 lr 9.28249e-05
09/25/2020 19:20:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 10101 Ep: 0.93 masked_t 2.405 masked_v 0.466 NSP 0.191 lr 9.30092e-05
09/25/2020 19:21:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 10121 Ep: 0.93 masked_t 2.401 masked_v 0.480 NSP 0.211 lr 9.31935e-05
09/25/2020 19:21:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 10141 Ep: 0.93 masked_t 2.229 masked_v 0.474 NSP 0.208 lr 9.33779e-05
09/25/2020 19:21:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 10161 Ep: 0.94 masked_t 2.390 masked_v 0.467 NSP 0.204 lr 9.35622e-05
09/25/2020 19:22:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 10181 Ep: 0.94 masked_t 2.352 masked_v 0.466 NSP 0.208 lr 9.37465e-05
09/25/2020 19:22:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 10201 Ep: 0.94 masked_t 2.264 masked_v 0.473 NSP 0.205 lr 9.39309e-05
09/25/2020 19:22:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 10221 Ep: 0.94 masked_t 2.469 masked_v 0.473 NSP 0.200 lr 9.41152e-05
09/25/2020 19:23:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 10241 Ep: 0.94 masked_t 2.359 masked_v 0.471 NSP 0.212 lr 9.42995e-05
09/25/2020 19:23:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 10261 Ep: 0.95 masked_t 2.448 masked_v 0.474 NSP 0.198 lr 9.44839e-05
09/25/2020 19:23:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 10281 Ep: 0.95 masked_t 2.290 masked_v 0.462 NSP 0.200 lr 9.46682e-05
09/25/2020 19:24:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 10301 Ep: 0.95 masked_t 2.385 masked_v 0.472 NSP 0.215 lr 9.48525e-05
09/25/2020 19:24:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 10321 Ep: 0.95 masked_t 2.437 masked_v 0.472 NSP 0.200 lr 9.50369e-05
09/25/2020 19:24:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 10341 Ep: 0.95 masked_t 2.344 masked_v 0.467 NSP 0.221 lr 9.52212e-05
09/25/2020 19:25:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 10361 Ep: 0.95 masked_t 2.412 masked_v 0.481 NSP 0.203 lr 9.54055e-05
09/25/2020 19:25:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 10381 Ep: 0.96 masked_t 2.337 masked_v 0.459 NSP 0.189 lr 9.55899e-05
09/25/2020 19:25:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 10401 Ep: 0.96 masked_t 2.400 masked_v 0.467 NSP 0.204 lr 9.57742e-05
09/25/2020 19:26:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 10421 Ep: 0.96 masked_t 2.303 masked_v 0.475 NSP 0.220 lr 9.59585e-05
09/25/2020 19:26:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 10441 Ep: 0.96 masked_t 2.399 masked_v 0.462 NSP 0.201 lr 9.61429e-05
09/25/2020 19:27:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 10461 Ep: 0.96 masked_t 2.443 masked_v 0.449 NSP 0.211 lr 9.63272e-05
09/25/2020 19:27:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 10481 Ep: 0.97 masked_t 2.340 masked_v 0.456 NSP 0.213 lr 9.65115e-05
09/25/2020 19:27:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 10501 Ep: 0.97 masked_t 2.318 masked_v 0.479 NSP 0.202 lr 9.66959e-05
09/25/2020 19:28:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 10521 Ep: 0.97 masked_t 2.360 masked_v 0.476 NSP 0.195 lr 9.68802e-05
09/25/2020 19:28:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 10541 Ep: 0.97 masked_t 2.384 masked_v 0.465 NSP 0.204 lr 9.70645e-05
09/25/2020 19:28:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 10561 Ep: 0.97 masked_t 2.334 masked_v 0.477 NSP 0.196 lr 9.72488e-05
09/25/2020 19:29:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 10581 Ep: 0.98 masked_t 2.367 masked_v 0.467 NSP 0.198 lr 9.74332e-05
09/25/2020 19:29:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 10601 Ep: 0.98 masked_t 2.335 masked_v 0.462 NSP 0.204 lr 9.76175e-05
09/25/2020 19:30:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 10621 Ep: 0.98 masked_t 2.487 masked_v 0.462 NSP 0.204 lr 9.78018e-05
09/25/2020 19:30:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 10641 Ep: 0.98 masked_t 2.341 masked_v 0.469 NSP 0.221 lr 9.79862e-05
09/25/2020 19:30:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 10661 Ep: 0.98 masked_t 2.364 masked_v 0.452 NSP 0.211 lr 9.81705e-05
09/25/2020 19:31:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 10681 Ep: 0.98 masked_t 2.418 masked_v 0.476 NSP 0.196 lr 9.83548e-05
09/25/2020 19:31:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 10701 Ep: 0.99 masked_t 2.425 masked_v 0.464 NSP 0.204 lr 9.85392e-05
09/25/2020 19:31:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 10721 Ep: 0.99 masked_t 2.414 masked_v 0.469 NSP 0.200 lr 9.87235e-05
09/25/2020 19:32:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 10741 Ep: 0.99 masked_t 2.352 masked_v 0.449 NSP 0.201 lr 9.89078e-05
09/25/2020 19:32:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 10761 Ep: 0.99 masked_t 2.302 masked_v 0.465 NSP 0.199 lr 9.90922e-05
09/25/2020 19:32:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 10781 Ep: 0.99 masked_t 2.485 masked_v 0.458 NSP 0.205 lr 9.92765e-05
09/25/2020 19:33:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 10801 Ep: 1.00 masked_t 2.302 masked_v 0.470 NSP 0.191 lr 9.94608e-05
09/25/2020 19:33:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 10821 Ep: 1.00 masked_t 2.414 masked_v 0.450 NSP 0.188 lr 9.96452e-05
09/25/2020 19:34:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 10841 Ep: 1.00 masked_t 2.329 masked_v 0.477 NSP 0.202 lr 9.98295e-05
09/25/2020 19:34:59 - INFO - volta.utils -   Validation [Conceptual_Caption]: masked_t 2.676 masked_v 0.453 NSP 0.226
09/25/2020 19:34:59 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 
09/25/2020 19:35:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 10871 Ep: 1.00 masked_t 2.330 masked_v 0.460 NSP 0.210 lr 9.99811e-05
09/25/2020 19:35:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 10891 Ep: 1.00 masked_t 2.423 masked_v 0.469 NSP 0.208 lr 9.99677e-05
09/25/2020 19:36:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 10911 Ep: 1.01 masked_t 2.327 masked_v 0.467 NSP 0.210 lr 9.99473e-05
09/25/2020 19:36:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 10931 Ep: 1.01 masked_t 2.503 masked_v 0.457 NSP 0.197 lr 9.99268e-05
09/25/2020 19:36:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 10951 Ep: 1.01 masked_t 2.411 masked_v 0.458 NSP 0.216 lr 9.99063e-05
09/25/2020 19:37:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 10971 Ep: 1.01 masked_t 2.342 masked_v 0.460 NSP 0.202 lr 9.98858e-05
09/25/2020 19:37:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 10991 Ep: 1.01 masked_t 2.370 masked_v 0.463 NSP 0.204 lr 9.98653e-05
09/25/2020 19:37:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 11011 Ep: 1.01 masked_t 2.356 masked_v 0.450 NSP 0.194 lr 9.98449e-05
09/25/2020 19:38:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 11031 Ep: 1.02 masked_t 2.291 masked_v 0.462 NSP 0.201 lr 9.98244e-05
09/25/2020 19:38:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 11051 Ep: 1.02 masked_t 2.387 masked_v 0.459 NSP 0.202 lr 9.98039e-05
09/25/2020 19:39:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 11071 Ep: 1.02 masked_t 2.365 masked_v 0.450 NSP 0.194 lr 9.97834e-05
09/25/2020 19:39:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 11091 Ep: 1.02 masked_t 2.432 masked_v 0.461 NSP 0.194 lr 9.97629e-05
09/25/2020 19:39:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 11111 Ep: 1.02 masked_t 2.488 masked_v 0.459 NSP 0.208 lr 9.97424e-05
09/25/2020 19:40:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 11131 Ep: 1.03 masked_t 2.400 masked_v 0.463 NSP 0.192 lr 9.9722e-05
09/25/2020 19:40:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 11151 Ep: 1.03 masked_t 2.342 masked_v 0.468 NSP 0.203 lr 9.97015e-05
09/25/2020 19:40:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 11171 Ep: 1.03 masked_t 2.325 masked_v 0.452 NSP 0.206 lr 9.9681e-05
09/25/2020 19:41:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 11191 Ep: 1.03 masked_t 2.397 masked_v 0.453 NSP 0.203 lr 9.96605e-05
09/25/2020 19:41:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 11211 Ep: 1.03 masked_t 2.263 masked_v 0.458 NSP 0.199 lr 9.964e-05
09/25/2020 19:41:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 11231 Ep: 1.04 masked_t 2.431 masked_v 0.459 NSP 0.205 lr 9.96196e-05
09/25/2020 19:42:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 11251 Ep: 1.04 masked_t 2.368 masked_v 0.449 NSP 0.201 lr 9.95991e-05
09/25/2020 19:42:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 11271 Ep: 1.04 masked_t 2.353 masked_v 0.451 NSP 0.206 lr 9.95786e-05
09/25/2020 19:42:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 11291 Ep: 1.04 masked_t 2.265 masked_v 0.454 NSP 0.200 lr 9.95581e-05
09/25/2020 19:43:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 11311 Ep: 1.04 masked_t 2.398 masked_v 0.446 NSP 0.201 lr 9.95376e-05
09/25/2020 19:43:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 11331 Ep: 1.04 masked_t 2.359 masked_v 0.448 NSP 0.198 lr 9.95172e-05
09/25/2020 19:43:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 11351 Ep: 1.05 masked_t 2.370 masked_v 0.442 NSP 0.207 lr 9.94967e-05
09/25/2020 19:44:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 11371 Ep: 1.05 masked_t 2.382 masked_v 0.450 NSP 0.195 lr 9.94762e-05
09/25/2020 19:44:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 11391 Ep: 1.05 masked_t 2.295 masked_v 0.452 NSP 0.191 lr 9.94557e-05
09/25/2020 19:45:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 11411 Ep: 1.05 masked_t 2.336 masked_v 0.445 NSP 0.199 lr 9.94352e-05
09/25/2020 19:45:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 11431 Ep: 1.05 masked_t 2.443 masked_v 0.444 NSP 0.206 lr 9.94147e-05
09/25/2020 19:45:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 11451 Ep: 1.06 masked_t 2.363 masked_v 0.447 NSP 0.191 lr 9.93943e-05
09/25/2020 19:46:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 11471 Ep: 1.06 masked_t 2.451 masked_v 0.442 NSP 0.210 lr 9.93738e-05
09/25/2020 19:46:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 11491 Ep: 1.06 masked_t 2.401 masked_v 0.454 NSP 0.191 lr 9.93533e-05
09/25/2020 19:46:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 11511 Ep: 1.06 masked_t 2.361 masked_v 0.441 NSP 0.188 lr 9.93328e-05
09/25/2020 19:47:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 11531 Ep: 1.06 masked_t 2.308 masked_v 0.450 NSP 0.200 lr 9.93123e-05
09/25/2020 19:47:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 11551 Ep: 1.06 masked_t 2.402 masked_v 0.456 NSP 0.201 lr 9.92919e-05
09/25/2020 19:47:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 11571 Ep: 1.07 masked_t 2.347 masked_v 0.456 NSP 0.196 lr 9.92714e-05
09/25/2020 19:48:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 11591 Ep: 1.07 masked_t 2.412 masked_v 0.445 NSP 0.198 lr 9.92509e-05
09/25/2020 19:48:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 11611 Ep: 1.07 masked_t 2.342 masked_v 0.447 NSP 0.201 lr 9.92304e-05
09/25/2020 19:48:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 11631 Ep: 1.07 masked_t 2.316 masked_v 0.453 NSP 0.192 lr 9.92099e-05
09/25/2020 19:49:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 11651 Ep: 1.07 masked_t 2.318 masked_v 0.440 NSP 0.205 lr 9.91895e-05
09/25/2020 19:49:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 11671 Ep: 1.08 masked_t 2.380 masked_v 0.452 NSP 0.201 lr 9.9169e-05
09/25/2020 19:50:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 11691 Ep: 1.08 masked_t 2.378 masked_v 0.443 NSP 0.216 lr 9.91485e-05
09/25/2020 19:50:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 11711 Ep: 1.08 masked_t 2.361 masked_v 0.449 NSP 0.199 lr 9.9128e-05
09/25/2020 19:50:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 11731 Ep: 1.08 masked_t 2.425 masked_v 0.446 NSP 0.200 lr 9.91075e-05
09/25/2020 19:51:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 11751 Ep: 1.08 masked_t 2.304 masked_v 0.446 NSP 0.194 lr 9.9087e-05
09/25/2020 19:51:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 11771 Ep: 1.08 masked_t 2.376 masked_v 0.441 NSP 0.202 lr 9.90666e-05
09/25/2020 19:51:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 11791 Ep: 1.09 masked_t 2.365 masked_v 0.445 NSP 0.187 lr 9.90461e-05
09/25/2020 19:52:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 11811 Ep: 1.09 masked_t 2.322 masked_v 0.433 NSP 0.193 lr 9.90256e-05
09/25/2020 19:52:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 11831 Ep: 1.09 masked_t 2.332 masked_v 0.452 NSP 0.181 lr 9.90051e-05
09/25/2020 19:52:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 11851 Ep: 1.09 masked_t 2.335 masked_v 0.441 NSP 0.205 lr 9.89846e-05
09/25/2020 19:53:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 11871 Ep: 1.09 masked_t 2.323 masked_v 0.444 NSP 0.193 lr 9.89642e-05
09/25/2020 19:53:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 11891 Ep: 1.10 masked_t 2.388 masked_v 0.451 NSP 0.192 lr 9.89437e-05
09/25/2020 19:53:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 11911 Ep: 1.10 masked_t 2.340 masked_v 0.437 NSP 0.192 lr 9.89232e-05
09/25/2020 19:54:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 11931 Ep: 1.10 masked_t 2.291 masked_v 0.439 NSP 0.202 lr 9.89027e-05
09/25/2020 19:54:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 11951 Ep: 1.10 masked_t 2.392 masked_v 0.435 NSP 0.197 lr 9.88822e-05
09/25/2020 19:55:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 11971 Ep: 1.10 masked_t 2.311 masked_v 0.440 NSP 0.199 lr 9.88618e-05
09/25/2020 19:55:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 11991 Ep: 1.11 masked_t 2.334 masked_v 0.437 NSP 0.196 lr 9.88413e-05
09/25/2020 19:55:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 12011 Ep: 1.11 masked_t 2.328 masked_v 0.433 NSP 0.200 lr 9.88208e-05
09/25/2020 19:56:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 12031 Ep: 1.11 masked_t 2.351 masked_v 0.442 NSP 0.195 lr 9.88003e-05
09/25/2020 19:56:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 12051 Ep: 1.11 masked_t 2.314 masked_v 0.445 NSP 0.177 lr 9.87798e-05
09/25/2020 19:56:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 12071 Ep: 1.11 masked_t 2.287 masked_v 0.437 NSP 0.206 lr 9.87593e-05
09/25/2020 19:57:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 12091 Ep: 1.11 masked_t 2.316 masked_v 0.437 NSP 0.205 lr 9.87389e-05
09/25/2020 19:57:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 12111 Ep: 1.12 masked_t 2.419 masked_v 0.454 NSP 0.186 lr 9.87184e-05
09/25/2020 19:57:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 12131 Ep: 1.12 masked_t 2.348 masked_v 0.442 NSP 0.201 lr 9.86979e-05
09/25/2020 19:58:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 12151 Ep: 1.12 masked_t 2.310 masked_v 0.433 NSP 0.192 lr 9.86774e-05
09/25/2020 19:58:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 12171 Ep: 1.12 masked_t 2.325 masked_v 0.427 NSP 0.190 lr 9.86569e-05
09/25/2020 19:58:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 12191 Ep: 1.12 masked_t 2.389 masked_v 0.435 NSP 0.205 lr 9.86365e-05
09/25/2020 19:59:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 12211 Ep: 1.13 masked_t 2.318 masked_v 0.445 NSP 0.190 lr 9.8616e-05
09/25/2020 19:59:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 12231 Ep: 1.13 masked_t 2.356 masked_v 0.440 NSP 0.179 lr 9.85955e-05
09/25/2020 20:00:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 12251 Ep: 1.13 masked_t 2.319 masked_v 0.427 NSP 0.190 lr 9.8575e-05
09/25/2020 20:00:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 12271 Ep: 1.13 masked_t 2.359 masked_v 0.448 NSP 0.193 lr 9.85545e-05
09/25/2020 20:00:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 12291 Ep: 1.13 masked_t 2.413 masked_v 0.441 NSP 0.199 lr 9.85341e-05
09/25/2020 20:01:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 12311 Ep: 1.13 masked_t 2.479 masked_v 0.434 NSP 0.197 lr 9.85136e-05
09/25/2020 20:01:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 12331 Ep: 1.14 masked_t 2.292 masked_v 0.431 NSP 0.195 lr 9.84931e-05
09/25/2020 20:01:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 12351 Ep: 1.14 masked_t 2.367 masked_v 0.433 NSP 0.199 lr 9.84726e-05
09/25/2020 20:02:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 12371 Ep: 1.14 masked_t 2.332 masked_v 0.436 NSP 0.178 lr 9.84521e-05
09/25/2020 20:02:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 12391 Ep: 1.14 masked_t 2.241 masked_v 0.420 NSP 0.180 lr 9.84316e-05
09/25/2020 20:02:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 12411 Ep: 1.14 masked_t 2.344 masked_v 0.431 NSP 0.190 lr 9.84112e-05
09/25/2020 20:03:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 12431 Ep: 1.15 masked_t 2.365 masked_v 0.437 NSP 0.187 lr 9.83907e-05
09/25/2020 20:03:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 12451 Ep: 1.15 masked_t 2.328 masked_v 0.441 NSP 0.195 lr 9.83702e-05
09/25/2020 20:03:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 12471 Ep: 1.15 masked_t 2.327 masked_v 0.443 NSP 0.188 lr 9.83497e-05
09/25/2020 20:04:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 12491 Ep: 1.15 masked_t 2.421 masked_v 0.422 NSP 0.192 lr 9.83292e-05
09/25/2020 20:04:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 12511 Ep: 1.15 masked_t 2.340 masked_v 0.436 NSP 0.190 lr 9.83088e-05
09/25/2020 20:04:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 12531 Ep: 1.15 masked_t 2.311 masked_v 0.429 NSP 0.191 lr 9.82883e-05
09/25/2020 20:05:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 12551 Ep: 1.16 masked_t 2.345 masked_v 0.425 NSP 0.186 lr 9.82678e-05
09/25/2020 20:05:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 12571 Ep: 1.16 masked_t 2.399 masked_v 0.438 NSP 0.186 lr 9.82473e-05
09/25/2020 20:05:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 12591 Ep: 1.16 masked_t 2.399 masked_v 0.435 NSP 0.195 lr 9.82268e-05
09/25/2020 20:06:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 12611 Ep: 1.16 masked_t 2.396 masked_v 0.429 NSP 0.185 lr 9.82063e-05
09/25/2020 20:06:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 12631 Ep: 1.16 masked_t 2.343 masked_v 0.435 NSP 0.189 lr 9.81859e-05
09/25/2020 20:07:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 12651 Ep: 1.17 masked_t 2.391 masked_v 0.438 NSP 0.199 lr 9.81654e-05
09/25/2020 20:07:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 12671 Ep: 1.17 masked_t 2.340 masked_v 0.427 NSP 0.193 lr 9.81449e-05
09/25/2020 20:07:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 12691 Ep: 1.17 masked_t 2.391 masked_v 0.420 NSP 0.175 lr 9.81244e-05
09/25/2020 20:08:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 12711 Ep: 1.17 masked_t 2.328 masked_v 0.427 NSP 0.187 lr 9.81039e-05
09/25/2020 20:08:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 12731 Ep: 1.17 masked_t 2.307 masked_v 0.427 NSP 0.183 lr 9.80835e-05
09/25/2020 20:08:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 12751 Ep: 1.18 masked_t 2.385 masked_v 0.431 NSP 0.168 lr 9.8063e-05
09/25/2020 20:09:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 12771 Ep: 1.18 masked_t 2.303 masked_v 0.428 NSP 0.184 lr 9.80425e-05
09/25/2020 20:09:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 12791 Ep: 1.18 masked_t 2.282 masked_v 0.422 NSP 0.177 lr 9.8022e-05
09/25/2020 20:09:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 12811 Ep: 1.18 masked_t 2.248 masked_v 0.430 NSP 0.176 lr 9.80015e-05
09/25/2020 20:10:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 12831 Ep: 1.18 masked_t 2.301 masked_v 0.427 NSP 0.193 lr 9.79811e-05
09/25/2020 20:10:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 12851 Ep: 1.18 masked_t 2.376 masked_v 0.425 NSP 0.198 lr 9.79606e-05
09/25/2020 20:10:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 12871 Ep: 1.19 masked_t 2.297 masked_v 0.426 NSP 0.180 lr 9.79401e-05
09/25/2020 20:11:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 12891 Ep: 1.19 masked_t 2.271 masked_v 0.436 NSP 0.197 lr 9.79196e-05
09/25/2020 20:11:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 12911 Ep: 1.19 masked_t 2.262 masked_v 0.422 NSP 0.196 lr 9.78991e-05
09/25/2020 20:12:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 12931 Ep: 1.19 masked_t 2.277 masked_v 0.430 NSP 0.178 lr 9.78786e-05
09/25/2020 20:12:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 12951 Ep: 1.19 masked_t 2.344 masked_v 0.418 NSP 0.194 lr 9.78582e-05
09/25/2020 20:12:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 12971 Ep: 1.20 masked_t 2.349 masked_v 0.427 NSP 0.189 lr 9.78377e-05
09/25/2020 20:13:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 12991 Ep: 1.20 masked_t 2.395 masked_v 0.436 NSP 0.192 lr 9.78172e-05
09/25/2020 20:13:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 13011 Ep: 1.20 masked_t 2.242 masked_v 0.421 NSP 0.178 lr 9.77967e-05
09/25/2020 20:13:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 13031 Ep: 1.20 masked_t 2.285 masked_v 0.428 NSP 0.199 lr 9.77762e-05
09/25/2020 20:14:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 13051 Ep: 1.20 masked_t 2.338 masked_v 0.423 NSP 0.187 lr 9.77558e-05
09/25/2020 20:14:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 13071 Ep: 1.20 masked_t 2.289 masked_v 0.436 NSP 0.169 lr 9.77353e-05
09/25/2020 20:14:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 13091 Ep: 1.21 masked_t 2.236 masked_v 0.425 NSP 0.175 lr 9.77148e-05
09/25/2020 20:15:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 13111 Ep: 1.21 masked_t 2.257 masked_v 0.414 NSP 0.195 lr 9.76943e-05
09/25/2020 20:15:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 13131 Ep: 1.21 masked_t 2.311 masked_v 0.411 NSP 0.191 lr 9.76738e-05
09/25/2020 20:15:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 13151 Ep: 1.21 masked_t 2.333 masked_v 0.423 NSP 0.195 lr 9.76534e-05
09/25/2020 20:16:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 13171 Ep: 1.21 masked_t 2.415 masked_v 0.424 NSP 0.193 lr 9.76329e-05
09/25/2020 20:16:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 13191 Ep: 1.22 masked_t 2.325 masked_v 0.412 NSP 0.192 lr 9.76124e-05
09/25/2020 20:17:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 13211 Ep: 1.22 masked_t 2.340 masked_v 0.427 NSP 0.214 lr 9.75919e-05
09/25/2020 20:17:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 13231 Ep: 1.22 masked_t 2.350 masked_v 0.422 NSP 0.185 lr 9.75714e-05
09/25/2020 20:17:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 13251 Ep: 1.22 masked_t 2.292 masked_v 0.427 NSP 0.189 lr 9.75509e-05
09/25/2020 20:18:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 13271 Ep: 1.22 masked_t 2.415 masked_v 0.417 NSP 0.183 lr 9.75305e-05
09/25/2020 20:18:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 13291 Ep: 1.22 masked_t 2.422 masked_v 0.415 NSP 0.190 lr 9.751e-05
09/25/2020 20:18:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 13311 Ep: 1.23 masked_t 2.328 masked_v 0.424 NSP 0.180 lr 9.74895e-05
09/25/2020 20:19:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 13331 Ep: 1.23 masked_t 2.330 masked_v 0.433 NSP 0.192 lr 9.7469e-05
09/25/2020 20:19:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 13351 Ep: 1.23 masked_t 2.318 masked_v 0.423 NSP 0.187 lr 9.74485e-05
09/25/2020 20:19:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 13371 Ep: 1.23 masked_t 2.300 masked_v 0.423 NSP 0.185 lr 9.74281e-05
09/25/2020 20:20:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 13391 Ep: 1.23 masked_t 2.300 masked_v 0.416 NSP 0.181 lr 9.74076e-05
09/25/2020 20:20:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 13411 Ep: 1.24 masked_t 2.367 masked_v 0.420 NSP 0.193 lr 9.73871e-05
09/25/2020 20:21:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 13431 Ep: 1.24 masked_t 2.245 masked_v 0.422 NSP 0.183 lr 9.73666e-05
09/25/2020 20:21:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 13451 Ep: 1.24 masked_t 2.272 masked_v 0.413 NSP 0.199 lr 9.73461e-05
09/25/2020 20:21:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 13471 Ep: 1.24 masked_t 2.370 masked_v 0.417 NSP 0.198 lr 9.73257e-05
09/25/2020 20:22:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 13491 Ep: 1.24 masked_t 2.281 masked_v 0.411 NSP 0.179 lr 9.73052e-05
09/25/2020 20:22:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 13511 Ep: 1.25 masked_t 2.319 masked_v 0.412 NSP 0.192 lr 9.72847e-05
09/25/2020 20:22:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 13531 Ep: 1.25 masked_t 2.400 masked_v 0.419 NSP 0.199 lr 9.72642e-05
09/25/2020 20:23:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 13551 Ep: 1.25 masked_t 2.279 masked_v 0.410 NSP 0.193 lr 9.72437e-05
09/25/2020 20:23:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 13571 Ep: 1.25 masked_t 2.374 masked_v 0.415 NSP 0.190 lr 9.72232e-05
09/25/2020 20:23:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 13591 Ep: 1.25 masked_t 2.288 masked_v 0.425 NSP 0.191 lr 9.72028e-05
09/25/2020 20:24:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 13611 Ep: 1.25 masked_t 2.277 masked_v 0.409 NSP 0.181 lr 9.71823e-05
09/25/2020 20:24:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 13631 Ep: 1.26 masked_t 2.299 masked_v 0.419 NSP 0.184 lr 9.71618e-05
09/25/2020 20:24:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 13651 Ep: 1.26 masked_t 2.327 masked_v 0.414 NSP 0.196 lr 9.71413e-05
09/25/2020 20:25:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 13671 Ep: 1.26 masked_t 2.254 masked_v 0.420 NSP 0.182 lr 9.71208e-05
09/25/2020 20:25:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 13691 Ep: 1.26 masked_t 2.254 masked_v 0.415 NSP 0.181 lr 9.71004e-05
09/25/2020 20:26:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 13711 Ep: 1.26 masked_t 2.307 masked_v 0.413 NSP 0.183 lr 9.70799e-05
09/25/2020 20:26:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 13731 Ep: 1.27 masked_t 2.311 masked_v 0.415 NSP 0.195 lr 9.70594e-05
09/25/2020 20:26:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 13751 Ep: 1.27 masked_t 2.305 masked_v 0.417 NSP 0.191 lr 9.70389e-05
09/25/2020 20:27:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 13771 Ep: 1.27 masked_t 2.329 masked_v 0.419 NSP 0.186 lr 9.70184e-05
09/25/2020 20:27:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 13791 Ep: 1.27 masked_t 2.269 masked_v 0.425 NSP 0.189 lr 9.6998e-05
09/25/2020 20:27:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 13811 Ep: 1.27 masked_t 2.292 masked_v 0.406 NSP 0.180 lr 9.69775e-05
09/25/2020 20:28:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 13831 Ep: 1.27 masked_t 2.285 masked_v 0.407 NSP 0.190 lr 9.6957e-05
09/25/2020 20:28:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 13851 Ep: 1.28 masked_t 2.322 masked_v 0.408 NSP 0.188 lr 9.69365e-05
09/25/2020 20:28:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 13871 Ep: 1.28 masked_t 2.363 masked_v 0.412 NSP 0.205 lr 9.6916e-05
09/25/2020 20:29:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 13891 Ep: 1.28 masked_t 2.228 masked_v 0.409 NSP 0.190 lr 9.68955e-05
09/25/2020 20:29:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 13911 Ep: 1.28 masked_t 2.332 masked_v 0.418 NSP 0.181 lr 9.68751e-05
09/25/2020 20:29:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 13931 Ep: 1.28 masked_t 2.337 masked_v 0.414 NSP 0.193 lr 9.68546e-05
09/25/2020 20:30:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 13951 Ep: 1.29 masked_t 2.272 masked_v 0.417 NSP 0.189 lr 9.68341e-05
09/25/2020 20:30:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 13971 Ep: 1.29 masked_t 2.321 masked_v 0.410 NSP 0.179 lr 9.68136e-05
09/25/2020 20:31:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 13991 Ep: 1.29 masked_t 2.333 masked_v 0.415 NSP 0.184 lr 9.67931e-05
09/25/2020 20:31:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 14011 Ep: 1.29 masked_t 2.325 masked_v 0.420 NSP 0.188 lr 9.67727e-05
09/25/2020 20:31:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 14031 Ep: 1.29 masked_t 2.390 masked_v 0.404 NSP 0.184 lr 9.67522e-05
09/25/2020 20:32:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 14051 Ep: 1.30 masked_t 2.240 masked_v 0.416 NSP 0.178 lr 9.67317e-05
09/25/2020 20:32:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 14071 Ep: 1.30 masked_t 2.249 masked_v 0.412 NSP 0.184 lr 9.67112e-05
09/25/2020 20:32:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 14091 Ep: 1.30 masked_t 2.343 masked_v 0.412 NSP 0.176 lr 9.66907e-05
09/25/2020 20:33:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 14111 Ep: 1.30 masked_t 2.380 masked_v 0.413 NSP 0.185 lr 9.66703e-05
09/25/2020 20:33:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 14131 Ep: 1.30 masked_t 2.293 masked_v 0.408 NSP 0.187 lr 9.66498e-05
09/25/2020 20:34:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 14151 Ep: 1.30 masked_t 2.325 masked_v 0.409 NSP 0.173 lr 9.66293e-05
09/25/2020 20:34:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 14171 Ep: 1.31 masked_t 2.220 masked_v 0.409 NSP 0.170 lr 9.66088e-05
09/25/2020 20:35:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 14191 Ep: 1.31 masked_t 2.261 masked_v 0.401 NSP 0.179 lr 9.65883e-05
09/25/2020 20:35:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 14211 Ep: 1.31 masked_t 2.323 masked_v 0.401 NSP 0.184 lr 9.65678e-05
09/25/2020 20:35:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 14231 Ep: 1.31 masked_t 2.326 masked_v 0.415 NSP 0.187 lr 9.65474e-05
09/25/2020 20:36:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 14251 Ep: 1.31 masked_t 2.433 masked_v 0.400 NSP 0.191 lr 9.65269e-05
09/25/2020 20:36:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 14271 Ep: 1.32 masked_t 2.314 masked_v 0.409 NSP 0.187 lr 9.65064e-05
09/25/2020 20:36:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 14291 Ep: 1.32 masked_t 2.328 masked_v 0.411 NSP 0.182 lr 9.64859e-05
09/25/2020 20:37:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 14311 Ep: 1.32 masked_t 2.275 masked_v 0.400 NSP 0.181 lr 9.64654e-05
09/25/2020 20:37:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 14331 Ep: 1.32 masked_t 2.312 masked_v 0.399 NSP 0.174 lr 9.6445e-05
09/25/2020 20:37:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 14351 Ep: 1.32 masked_t 2.269 masked_v 0.420 NSP 0.177 lr 9.64245e-05
09/25/2020 20:38:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 14371 Ep: 1.32 masked_t 2.295 masked_v 0.414 NSP 0.189 lr 9.6404e-05
09/25/2020 20:38:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 14391 Ep: 1.33 masked_t 2.376 masked_v 0.410 NSP 0.175 lr 9.63835e-05
09/25/2020 20:38:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 14411 Ep: 1.33 masked_t 2.227 masked_v 0.400 NSP 0.194 lr 9.6363e-05
09/25/2020 20:39:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 14431 Ep: 1.33 masked_t 2.383 masked_v 0.405 NSP 0.172 lr 9.63425e-05
09/25/2020 20:39:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 14451 Ep: 1.33 masked_t 2.260 masked_v 0.406 NSP 0.185 lr 9.63221e-05
09/25/2020 20:39:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 14471 Ep: 1.33 masked_t 2.383 masked_v 0.406 NSP 0.189 lr 9.63016e-05
09/25/2020 20:40:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 14491 Ep: 1.34 masked_t 2.372 masked_v 0.405 NSP 0.183 lr 9.62811e-05
09/25/2020 20:40:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 14511 Ep: 1.34 masked_t 2.272 masked_v 0.403 NSP 0.182 lr 9.62606e-05
09/25/2020 20:41:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 14531 Ep: 1.34 masked_t 2.338 masked_v 0.396 NSP 0.175 lr 9.62401e-05
09/25/2020 20:41:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 14551 Ep: 1.34 masked_t 2.283 masked_v 0.411 NSP 0.176 lr 9.62197e-05
09/25/2020 20:41:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 14571 Ep: 1.34 masked_t 2.248 masked_v 0.403 NSP 0.186 lr 9.61992e-05
09/25/2020 20:42:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 14591 Ep: 1.34 masked_t 2.281 masked_v 0.404 NSP 0.176 lr 9.61787e-05
09/25/2020 20:42:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 14611 Ep: 1.35 masked_t 2.339 masked_v 0.412 NSP 0.178 lr 9.61582e-05
09/25/2020 20:42:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 14631 Ep: 1.35 masked_t 2.345 masked_v 0.411 NSP 0.181 lr 9.61377e-05
09/25/2020 20:43:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 14651 Ep: 1.35 masked_t 2.285 masked_v 0.408 NSP 0.187 lr 9.61173e-05
09/25/2020 20:43:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 14671 Ep: 1.35 masked_t 2.330 masked_v 0.395 NSP 0.173 lr 9.60968e-05
09/25/2020 20:43:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 14691 Ep: 1.35 masked_t 2.192 masked_v 0.400 NSP 0.185 lr 9.60763e-05
09/25/2020 20:44:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 14711 Ep: 1.36 masked_t 2.286 masked_v 0.398 NSP 0.183 lr 9.60558e-05
09/25/2020 20:44:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 14731 Ep: 1.36 masked_t 2.203 masked_v 0.395 NSP 0.171 lr 9.60353e-05
09/25/2020 20:44:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 14751 Ep: 1.36 masked_t 2.336 masked_v 0.395 NSP 0.167 lr 9.60148e-05
09/25/2020 20:45:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 14771 Ep: 1.36 masked_t 2.213 masked_v 0.411 NSP 0.185 lr 9.59944e-05
09/25/2020 20:45:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 14791 Ep: 1.36 masked_t 2.197 masked_v 0.399 NSP 0.194 lr 9.59739e-05
09/25/2020 20:45:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 14811 Ep: 1.37 masked_t 2.282 masked_v 0.409 NSP 0.180 lr 9.59534e-05
09/25/2020 20:46:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 14831 Ep: 1.37 masked_t 2.213 masked_v 0.398 NSP 0.172 lr 9.59329e-05
09/25/2020 20:46:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 14851 Ep: 1.37 masked_t 2.278 masked_v 0.398 NSP 0.182 lr 9.59124e-05
09/25/2020 20:47:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 14871 Ep: 1.37 masked_t 2.294 masked_v 0.405 NSP 0.185 lr 9.5892e-05
09/25/2020 20:47:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 14891 Ep: 1.37 masked_t 2.202 masked_v 0.387 NSP 0.179 lr 9.58715e-05
09/25/2020 20:47:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 14911 Ep: 1.37 masked_t 2.304 masked_v 0.402 NSP 0.182 lr 9.5851e-05
09/25/2020 20:48:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 14931 Ep: 1.38 masked_t 2.333 masked_v 0.396 NSP 0.179 lr 9.58305e-05
09/25/2020 20:48:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 14951 Ep: 1.38 masked_t 2.289 masked_v 0.394 NSP 0.185 lr 9.581e-05
09/25/2020 20:48:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 14971 Ep: 1.38 masked_t 2.345 masked_v 0.396 NSP 0.187 lr 9.57896e-05
09/25/2020 20:49:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 14991 Ep: 1.38 masked_t 2.262 masked_v 0.394 NSP 0.182 lr 9.57691e-05
09/25/2020 20:49:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 15011 Ep: 1.38 masked_t 2.289 masked_v 0.399 NSP 0.174 lr 9.57486e-05
09/25/2020 20:49:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 15031 Ep: 1.39 masked_t 2.209 masked_v 0.393 NSP 0.186 lr 9.57281e-05
09/25/2020 20:50:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 15051 Ep: 1.39 masked_t 2.276 masked_v 0.399 NSP 0.176 lr 9.57076e-05
09/25/2020 20:50:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 15071 Ep: 1.39 masked_t 2.221 masked_v 0.396 NSP 0.169 lr 9.56871e-05
09/25/2020 20:50:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 15091 Ep: 1.39 masked_t 2.296 masked_v 0.398 NSP 0.176 lr 9.56667e-05
09/25/2020 20:51:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 15111 Ep: 1.39 masked_t 2.328 masked_v 0.395 NSP 0.190 lr 9.56462e-05
09/25/2020 20:51:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 15131 Ep: 1.39 masked_t 2.234 masked_v 0.392 NSP 0.164 lr 9.56257e-05
09/25/2020 20:51:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 15151 Ep: 1.40 masked_t 2.302 masked_v 0.400 NSP 0.183 lr 9.56052e-05
09/25/2020 20:52:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 15171 Ep: 1.40 masked_t 2.328 masked_v 0.393 NSP 0.167 lr 9.55847e-05
09/25/2020 20:52:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 15191 Ep: 1.40 masked_t 2.238 masked_v 0.403 NSP 0.176 lr 9.55643e-05
09/25/2020 20:53:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 15211 Ep: 1.40 masked_t 2.255 masked_v 0.390 NSP 0.180 lr 9.55438e-05
09/25/2020 20:53:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 15231 Ep: 1.40 masked_t 2.221 masked_v 0.391 NSP 0.170 lr 9.55233e-05
09/25/2020 20:53:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 15251 Ep: 1.41 masked_t 2.277 masked_v 0.401 NSP 0.188 lr 9.55028e-05
09/25/2020 20:54:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 15271 Ep: 1.41 masked_t 2.259 masked_v 0.411 NSP 0.180 lr 9.54823e-05
09/25/2020 20:54:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 15291 Ep: 1.41 masked_t 2.206 masked_v 0.393 NSP 0.179 lr 9.54619e-05
09/25/2020 20:54:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 15311 Ep: 1.41 masked_t 2.282 masked_v 0.395 NSP 0.165 lr 9.54414e-05
09/25/2020 20:55:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 15331 Ep: 1.41 masked_t 2.294 masked_v 0.396 NSP 0.173 lr 9.54209e-05
09/25/2020 20:55:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 15351 Ep: 1.41 masked_t 2.277 masked_v 0.398 NSP 0.174 lr 9.54004e-05
09/25/2020 20:55:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 15371 Ep: 1.42 masked_t 2.256 masked_v 0.381 NSP 0.181 lr 9.53799e-05
09/25/2020 20:56:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 15391 Ep: 1.42 masked_t 2.208 masked_v 0.395 NSP 0.168 lr 9.53594e-05
09/25/2020 20:56:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 15411 Ep: 1.42 masked_t 2.165 masked_v 0.401 NSP 0.175 lr 9.5339e-05
09/25/2020 20:56:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 15431 Ep: 1.42 masked_t 2.202 masked_v 0.396 NSP 0.160 lr 9.53185e-05
09/25/2020 20:57:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 15451 Ep: 1.42 masked_t 2.207 masked_v 0.395 NSP 0.182 lr 9.5298e-05
09/25/2020 20:57:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 15471 Ep: 1.43 masked_t 2.315 masked_v 0.399 NSP 0.172 lr 9.52775e-05
09/25/2020 20:57:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 15491 Ep: 1.43 masked_t 2.261 masked_v 0.388 NSP 0.175 lr 9.5257e-05
09/25/2020 20:58:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 15511 Ep: 1.43 masked_t 2.330 masked_v 0.393 NSP 0.167 lr 9.52366e-05
09/25/2020 20:58:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 15531 Ep: 1.43 masked_t 2.254 masked_v 0.390 NSP 0.173 lr 9.52161e-05
09/25/2020 20:59:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 15551 Ep: 1.43 masked_t 2.208 masked_v 0.392 NSP 0.170 lr 9.51956e-05
09/25/2020 20:59:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 15571 Ep: 1.44 masked_t 2.252 masked_v 0.389 NSP 0.175 lr 9.51751e-05
09/25/2020 20:59:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 15591 Ep: 1.44 masked_t 2.323 masked_v 0.386 NSP 0.183 lr 9.51546e-05
09/25/2020 21:00:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 15611 Ep: 1.44 masked_t 2.155 masked_v 0.388 NSP 0.172 lr 9.51342e-05
09/25/2020 21:00:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 15631 Ep: 1.44 masked_t 2.223 masked_v 0.391 NSP 0.168 lr 9.51137e-05
09/25/2020 21:00:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 15651 Ep: 1.44 masked_t 2.322 masked_v 0.388 NSP 0.166 lr 9.50932e-05
09/25/2020 21:01:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 15671 Ep: 1.44 masked_t 2.305 masked_v 0.382 NSP 0.186 lr 9.50727e-05
09/25/2020 21:01:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 15691 Ep: 1.45 masked_t 2.305 masked_v 0.390 NSP 0.174 lr 9.50522e-05
09/25/2020 21:01:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 15711 Ep: 1.45 masked_t 2.306 masked_v 0.390 NSP 0.174 lr 9.50317e-05
09/25/2020 21:02:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 15731 Ep: 1.45 masked_t 2.256 masked_v 0.390 NSP 0.184 lr 9.50113e-05
09/25/2020 21:02:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 15751 Ep: 1.45 masked_t 2.232 masked_v 0.388 NSP 0.171 lr 9.49908e-05
09/25/2020 21:02:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 15771 Ep: 1.45 masked_t 2.315 masked_v 0.385 NSP 0.182 lr 9.49703e-05
09/25/2020 21:03:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 15791 Ep: 1.46 masked_t 2.398 masked_v 0.386 NSP 0.172 lr 9.49498e-05
09/25/2020 21:03:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 15811 Ep: 1.46 masked_t 2.364 masked_v 0.388 NSP 0.167 lr 9.49293e-05
09/25/2020 21:04:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 15831 Ep: 1.46 masked_t 2.259 masked_v 0.390 NSP 0.175 lr 9.49089e-05
09/25/2020 21:04:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 15851 Ep: 1.46 masked_t 2.264 masked_v 0.391 NSP 0.176 lr 9.48884e-05
09/25/2020 21:04:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 15871 Ep: 1.46 masked_t 2.266 masked_v 0.405 NSP 0.183 lr 9.48679e-05
09/25/2020 21:05:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 15891 Ep: 1.46 masked_t 2.235 masked_v 0.391 NSP 0.175 lr 9.48474e-05
09/25/2020 21:05:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 15911 Ep: 1.47 masked_t 2.200 masked_v 0.383 NSP 0.169 lr 9.48269e-05
09/25/2020 21:05:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 15931 Ep: 1.47 masked_t 2.333 masked_v 0.389 NSP 0.184 lr 9.48065e-05
09/25/2020 21:06:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 15951 Ep: 1.47 masked_t 2.233 masked_v 0.385 NSP 0.182 lr 9.4786e-05
09/25/2020 21:06:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 15971 Ep: 1.47 masked_t 2.217 masked_v 0.391 NSP 0.170 lr 9.47655e-05
09/25/2020 21:06:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 15991 Ep: 1.47 masked_t 2.239 masked_v 0.395 NSP 0.171 lr 9.4745e-05
09/25/2020 21:07:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 16011 Ep: 1.48 masked_t 2.168 masked_v 0.391 NSP 0.170 lr 9.47245e-05
09/25/2020 21:07:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 16031 Ep: 1.48 masked_t 2.322 masked_v 0.383 NSP 0.169 lr 9.4704e-05
09/25/2020 21:08:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 16051 Ep: 1.48 masked_t 2.288 masked_v 0.378 NSP 0.184 lr 9.46836e-05
09/25/2020 21:08:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 16071 Ep: 1.48 masked_t 2.288 masked_v 0.389 NSP 0.175 lr 9.46631e-05
09/25/2020 21:08:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 16091 Ep: 1.48 masked_t 2.242 masked_v 0.380 NSP 0.168 lr 9.46426e-05
09/25/2020 21:09:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 16111 Ep: 1.48 masked_t 2.273 masked_v 0.383 NSP 0.179 lr 9.46221e-05
09/25/2020 21:09:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 16131 Ep: 1.49 masked_t 2.225 masked_v 0.388 NSP 0.164 lr 9.46016e-05
09/25/2020 21:09:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 16151 Ep: 1.49 masked_t 2.249 masked_v 0.399 NSP 0.181 lr 9.45812e-05
09/25/2020 21:10:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 16171 Ep: 1.49 masked_t 2.253 masked_v 0.386 NSP 0.163 lr 9.45607e-05
09/25/2020 21:10:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 16191 Ep: 1.49 masked_t 2.329 masked_v 0.383 NSP 0.159 lr 9.45402e-05
09/25/2020 21:10:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 16211 Ep: 1.49 masked_t 2.236 masked_v 0.388 NSP 0.158 lr 9.45197e-05
09/25/2020 21:11:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 16231 Ep: 1.50 masked_t 2.220 masked_v 0.384 NSP 0.171 lr 9.44992e-05
09/25/2020 21:11:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 16251 Ep: 1.50 masked_t 2.194 masked_v 0.373 NSP 0.175 lr 9.44788e-05
09/25/2020 21:11:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 16271 Ep: 1.50 masked_t 2.257 masked_v 0.382 NSP 0.184 lr 9.44583e-05
09/25/2020 21:12:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 16291 Ep: 1.50 masked_t 2.182 masked_v 0.375 NSP 0.181 lr 9.44378e-05
09/25/2020 21:12:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 16311 Ep: 1.50 masked_t 2.189 masked_v 0.394 NSP 0.187 lr 9.44173e-05
09/25/2020 21:13:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 16331 Ep: 1.51 masked_t 2.292 masked_v 0.403 NSP 0.176 lr 9.43968e-05
09/25/2020 21:13:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 16351 Ep: 1.51 masked_t 2.252 masked_v 0.381 NSP 0.165 lr 9.43763e-05
09/25/2020 21:13:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 16371 Ep: 1.51 masked_t 2.199 masked_v 0.386 NSP 0.164 lr 9.43559e-05
09/25/2020 21:14:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 16391 Ep: 1.51 masked_t 2.233 masked_v 0.392 NSP 0.165 lr 9.43354e-05
09/25/2020 21:14:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 16411 Ep: 1.51 masked_t 2.305 masked_v 0.385 NSP 0.184 lr 9.43149e-05
09/25/2020 21:14:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 16431 Ep: 1.51 masked_t 2.262 masked_v 0.378 NSP 0.175 lr 9.42944e-05
09/25/2020 21:15:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 16451 Ep: 1.52 masked_t 2.162 masked_v 0.379 NSP 0.171 lr 9.42739e-05
09/25/2020 21:15:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 16471 Ep: 1.52 masked_t 2.271 masked_v 0.375 NSP 0.180 lr 9.42535e-05
09/25/2020 21:15:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 16491 Ep: 1.52 masked_t 2.303 masked_v 0.378 NSP 0.170 lr 9.4233e-05
09/25/2020 21:16:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 16511 Ep: 1.52 masked_t 2.273 masked_v 0.383 NSP 0.159 lr 9.42125e-05
09/25/2020 21:16:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 16531 Ep: 1.52 masked_t 2.196 masked_v 0.390 NSP 0.164 lr 9.4192e-05
09/25/2020 21:16:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 16551 Ep: 1.53 masked_t 2.220 masked_v 0.381 NSP 0.163 lr 9.41715e-05
09/25/2020 21:17:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 16571 Ep: 1.53 masked_t 2.246 masked_v 0.381 NSP 0.180 lr 9.4151e-05
09/25/2020 21:17:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 16591 Ep: 1.53 masked_t 2.295 masked_v 0.392 NSP 0.183 lr 9.41306e-05
09/25/2020 21:17:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 16611 Ep: 1.53 masked_t 2.355 masked_v 0.376 NSP 0.181 lr 9.41101e-05
09/25/2020 21:18:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 16631 Ep: 1.53 masked_t 2.276 masked_v 0.383 NSP 0.178 lr 9.40896e-05
09/25/2020 21:18:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 16651 Ep: 1.53 masked_t 2.216 masked_v 0.376 NSP 0.160 lr 9.40691e-05
09/25/2020 21:19:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 16671 Ep: 1.54 masked_t 2.249 masked_v 0.388 NSP 0.187 lr 9.40486e-05
09/25/2020 21:19:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 16691 Ep: 1.54 masked_t 2.202 masked_v 0.385 NSP 0.171 lr 9.40282e-05
09/25/2020 21:19:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 16711 Ep: 1.54 masked_t 2.297 masked_v 0.381 NSP 0.184 lr 9.40077e-05
09/25/2020 21:20:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 16731 Ep: 1.54 masked_t 2.249 masked_v 0.387 NSP 0.166 lr 9.39872e-05
09/25/2020 21:20:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 16751 Ep: 1.54 masked_t 2.139 masked_v 0.380 NSP 0.169 lr 9.39667e-05
09/25/2020 21:21:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 16771 Ep: 1.55 masked_t 2.200 masked_v 0.391 NSP 0.169 lr 9.39462e-05
09/25/2020 21:21:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 16791 Ep: 1.55 masked_t 2.248 masked_v 0.388 NSP 0.169 lr 9.39258e-05
09/25/2020 21:21:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 16811 Ep: 1.55 masked_t 2.125 masked_v 0.370 NSP 0.179 lr 9.39053e-05
09/25/2020 21:22:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 16831 Ep: 1.55 masked_t 2.155 masked_v 0.380 NSP 0.158 lr 9.38848e-05
09/25/2020 21:22:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 16851 Ep: 1.55 masked_t 2.179 masked_v 0.376 NSP 0.170 lr 9.38643e-05
09/25/2020 21:22:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 16871 Ep: 1.55 masked_t 2.295 masked_v 0.387 NSP 0.168 lr 9.38438e-05
09/25/2020 21:23:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 16891 Ep: 1.56 masked_t 2.324 masked_v 0.380 NSP 0.175 lr 9.38233e-05
09/25/2020 21:23:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 16911 Ep: 1.56 masked_t 2.229 masked_v 0.387 NSP 0.167 lr 9.38029e-05
09/25/2020 21:23:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 16931 Ep: 1.56 masked_t 2.279 masked_v 0.383 NSP 0.175 lr 9.37824e-05
09/25/2020 21:24:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 16951 Ep: 1.56 masked_t 2.113 masked_v 0.381 NSP 0.184 lr 9.37619e-05
09/25/2020 21:24:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 16971 Ep: 1.56 masked_t 2.130 masked_v 0.386 NSP 0.167 lr 9.37414e-05
09/25/2020 21:25:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 16991 Ep: 1.57 masked_t 2.212 masked_v 0.384 NSP 0.181 lr 9.37209e-05
09/25/2020 21:25:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 17011 Ep: 1.57 masked_t 2.232 masked_v 0.384 NSP 0.178 lr 9.37005e-05
09/25/2020 21:25:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 17031 Ep: 1.57 masked_t 2.168 masked_v 0.379 NSP 0.173 lr 9.368e-05
09/25/2020 21:26:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 17051 Ep: 1.57 masked_t 2.278 masked_v 0.383 NSP 0.170 lr 9.36595e-05
09/25/2020 21:26:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 17071 Ep: 1.57 masked_t 2.302 masked_v 0.379 NSP 0.162 lr 9.3639e-05
09/25/2020 21:26:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 17091 Ep: 1.58 masked_t 2.264 masked_v 0.367 NSP 0.176 lr 9.36185e-05
09/25/2020 21:27:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 17111 Ep: 1.58 masked_t 2.221 masked_v 0.377 NSP 0.171 lr 9.35981e-05
09/25/2020 21:27:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 17131 Ep: 1.58 masked_t 2.276 masked_v 0.375 NSP 0.181 lr 9.35776e-05
09/25/2020 21:27:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 17151 Ep: 1.58 masked_t 2.277 masked_v 0.378 NSP 0.182 lr 9.35571e-05
09/25/2020 21:28:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 17171 Ep: 1.58 masked_t 2.169 masked_v 0.377 NSP 0.169 lr 9.35366e-05
09/25/2020 21:28:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 17191 Ep: 1.58 masked_t 2.186 masked_v 0.381 NSP 0.157 lr 9.35161e-05
09/25/2020 21:28:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 17211 Ep: 1.59 masked_t 2.202 masked_v 0.369 NSP 0.156 lr 9.34956e-05
09/25/2020 21:29:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 17231 Ep: 1.59 masked_t 2.210 masked_v 0.380 NSP 0.173 lr 9.34752e-05
09/25/2020 21:29:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 17251 Ep: 1.59 masked_t 2.195 masked_v 0.384 NSP 0.171 lr 9.34547e-05
09/25/2020 21:30:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 17271 Ep: 1.59 masked_t 2.155 masked_v 0.379 NSP 0.165 lr 9.34342e-05
09/25/2020 21:30:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 17291 Ep: 1.59 masked_t 2.222 masked_v 0.387 NSP 0.167 lr 9.34137e-05
09/25/2020 21:30:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 17311 Ep: 1.60 masked_t 2.232 masked_v 0.377 NSP 0.163 lr 9.33932e-05
09/25/2020 21:31:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 17331 Ep: 1.60 masked_t 2.218 masked_v 0.378 NSP 0.160 lr 9.33728e-05
09/25/2020 21:31:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 17351 Ep: 1.60 masked_t 2.277 masked_v 0.373 NSP 0.161 lr 9.33523e-05
09/25/2020 21:31:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 17371 Ep: 1.60 masked_t 2.214 masked_v 0.377 NSP 0.173 lr 9.33318e-05
09/25/2020 21:32:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 17391 Ep: 1.60 masked_t 2.196 masked_v 0.368 NSP 0.170 lr 9.33113e-05
09/25/2020 21:32:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 17411 Ep: 1.60 masked_t 2.268 masked_v 0.381 NSP 0.181 lr 9.32908e-05
09/25/2020 21:32:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 17431 Ep: 1.61 masked_t 2.207 masked_v 0.381 NSP 0.174 lr 9.32704e-05
09/25/2020 21:33:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 17451 Ep: 1.61 masked_t 2.250 masked_v 0.377 NSP 0.165 lr 9.32499e-05
09/25/2020 21:33:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 17471 Ep: 1.61 masked_t 2.247 masked_v 0.374 NSP 0.184 lr 9.32294e-05
09/25/2020 21:33:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 17491 Ep: 1.61 masked_t 2.242 masked_v 0.368 NSP 0.171 lr 9.32089e-05
09/25/2020 21:34:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 17511 Ep: 1.61 masked_t 2.309 masked_v 0.375 NSP 0.172 lr 9.31884e-05
09/25/2020 21:34:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 17531 Ep: 1.62 masked_t 2.205 masked_v 0.382 NSP 0.166 lr 9.31679e-05
09/25/2020 21:35:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 17551 Ep: 1.62 masked_t 2.165 masked_v 0.376 NSP 0.167 lr 9.31475e-05
09/25/2020 21:35:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 17571 Ep: 1.62 masked_t 2.276 masked_v 0.382 NSP 0.173 lr 9.3127e-05
09/25/2020 21:35:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 17591 Ep: 1.62 masked_t 2.293 masked_v 0.372 NSP 0.170 lr 9.31065e-05
09/25/2020 21:36:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 17611 Ep: 1.62 masked_t 2.199 masked_v 0.374 NSP 0.167 lr 9.3086e-05
09/25/2020 21:36:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 17631 Ep: 1.62 masked_t 2.247 masked_v 0.373 NSP 0.161 lr 9.30655e-05
09/25/2020 21:36:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 17651 Ep: 1.63 masked_t 2.202 masked_v 0.372 NSP 0.157 lr 9.30451e-05
09/25/2020 21:37:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 17671 Ep: 1.63 masked_t 2.230 masked_v 0.380 NSP 0.171 lr 9.30246e-05
09/25/2020 21:37:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 17691 Ep: 1.63 masked_t 2.260 masked_v 0.371 NSP 0.175 lr 9.30041e-05
09/25/2020 21:37:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 17711 Ep: 1.63 masked_t 2.262 masked_v 0.368 NSP 0.164 lr 9.29836e-05
09/25/2020 21:38:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 17731 Ep: 1.63 masked_t 2.335 masked_v 0.378 NSP 0.167 lr 9.29631e-05
09/25/2020 21:38:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 17751 Ep: 1.64 masked_t 2.255 masked_v 0.381 NSP 0.165 lr 9.29427e-05
09/25/2020 21:38:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 17771 Ep: 1.64 masked_t 2.185 masked_v 0.373 NSP 0.158 lr 9.29222e-05
09/25/2020 21:39:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 17791 Ep: 1.64 masked_t 2.277 masked_v 0.378 NSP 0.170 lr 9.29017e-05
09/25/2020 21:39:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 17811 Ep: 1.64 masked_t 2.081 masked_v 0.366 NSP 0.164 lr 9.28812e-05
09/25/2020 21:40:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 17831 Ep: 1.64 masked_t 2.196 masked_v 0.367 NSP 0.170 lr 9.28607e-05
09/25/2020 21:40:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 17851 Ep: 1.65 masked_t 2.170 masked_v 0.366 NSP 0.174 lr 9.28402e-05
09/25/2020 21:40:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 17871 Ep: 1.65 masked_t 2.312 masked_v 0.369 NSP 0.170 lr 9.28198e-05
09/25/2020 21:41:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 17891 Ep: 1.65 masked_t 2.128 masked_v 0.374 NSP 0.164 lr 9.27993e-05
09/25/2020 21:41:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 17911 Ep: 1.65 masked_t 2.243 masked_v 0.375 NSP 0.150 lr 9.27788e-05
09/25/2020 21:41:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 17931 Ep: 1.65 masked_t 2.311 masked_v 0.390 NSP 0.179 lr 9.27583e-05
09/25/2020 21:42:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 17951 Ep: 1.65 masked_t 2.131 masked_v 0.364 NSP 0.174 lr 9.27378e-05
09/25/2020 21:42:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 17971 Ep: 1.66 masked_t 2.193 masked_v 0.367 NSP 0.159 lr 9.27174e-05
09/25/2020 21:42:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 17991 Ep: 1.66 masked_t 2.222 masked_v 0.373 NSP 0.170 lr 9.26969e-05
09/25/2020 21:43:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 18011 Ep: 1.66 masked_t 2.235 masked_v 0.372 NSP 0.178 lr 9.26764e-05
09/25/2020 21:43:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 18031 Ep: 1.66 masked_t 2.139 masked_v 0.363 NSP 0.155 lr 9.26559e-05
09/25/2020 21:43:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 18051 Ep: 1.66 masked_t 2.293 masked_v 0.367 NSP 0.166 lr 9.26354e-05
09/25/2020 21:44:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 18071 Ep: 1.67 masked_t 2.198 masked_v 0.373 NSP 0.171 lr 9.2615e-05
09/25/2020 21:44:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 18091 Ep: 1.67 masked_t 2.181 masked_v 0.376 NSP 0.168 lr 9.25945e-05
09/25/2020 21:45:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 18111 Ep: 1.67 masked_t 2.237 masked_v 0.379 NSP 0.175 lr 9.2574e-05
09/25/2020 21:45:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 18131 Ep: 1.67 masked_t 2.233 masked_v 0.363 NSP 0.164 lr 9.25535e-05
09/25/2020 21:45:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 18151 Ep: 1.67 masked_t 2.227 masked_v 0.376 NSP 0.180 lr 9.2533e-05
09/25/2020 21:46:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 18171 Ep: 1.67 masked_t 2.207 masked_v 0.380 NSP 0.162 lr 9.25125e-05
09/25/2020 21:46:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 18191 Ep: 1.68 masked_t 2.200 masked_v 0.384 NSP 0.168 lr 9.24921e-05
09/25/2020 21:46:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 18211 Ep: 1.68 masked_t 2.207 masked_v 0.378 NSP 0.160 lr 9.24716e-05
09/25/2020 21:47:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 18231 Ep: 1.68 masked_t 2.099 masked_v 0.376 NSP 0.176 lr 9.24511e-05
09/25/2020 21:47:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 18251 Ep: 1.68 masked_t 2.213 masked_v 0.364 NSP 0.164 lr 9.24306e-05
09/25/2020 21:47:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 18271 Ep: 1.68 masked_t 2.237 masked_v 0.374 NSP 0.188 lr 9.24101e-05
09/25/2020 21:48:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 18291 Ep: 1.69 masked_t 2.158 masked_v 0.373 NSP 0.156 lr 9.23897e-05
09/25/2020 21:48:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 18311 Ep: 1.69 masked_t 2.225 masked_v 0.363 NSP 0.161 lr 9.23692e-05
09/25/2020 21:48:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 18331 Ep: 1.69 masked_t 2.239 masked_v 0.364 NSP 0.173 lr 9.23487e-05
09/25/2020 21:49:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 18351 Ep: 1.69 masked_t 2.253 masked_v 0.362 NSP 0.165 lr 9.23282e-05
09/25/2020 21:49:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 18371 Ep: 1.69 masked_t 2.215 masked_v 0.375 NSP 0.177 lr 9.23077e-05
09/25/2020 21:49:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 18391 Ep: 1.69 masked_t 2.154 masked_v 0.363 NSP 0.171 lr 9.22873e-05
09/25/2020 21:50:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 18411 Ep: 1.70 masked_t 2.242 masked_v 0.370 NSP 0.183 lr 9.22668e-05
09/25/2020 21:50:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 18431 Ep: 1.70 masked_t 2.212 masked_v 0.371 NSP 0.164 lr 9.22463e-05
09/25/2020 21:51:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 18451 Ep: 1.70 masked_t 2.144 masked_v 0.369 NSP 0.152 lr 9.22258e-05
09/25/2020 21:51:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 18471 Ep: 1.70 masked_t 2.155 masked_v 0.371 NSP 0.159 lr 9.22053e-05
09/25/2020 21:51:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 18491 Ep: 1.70 masked_t 2.202 masked_v 0.371 NSP 0.160 lr 9.21848e-05
09/25/2020 21:52:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 18511 Ep: 1.71 masked_t 2.197 masked_v 0.359 NSP 0.183 lr 9.21644e-05
09/25/2020 21:52:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 18531 Ep: 1.71 masked_t 2.176 masked_v 0.366 NSP 0.154 lr 9.21439e-05
09/25/2020 21:52:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 18551 Ep: 1.71 masked_t 2.181 masked_v 0.365 NSP 0.152 lr 9.21234e-05
09/25/2020 21:53:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 18571 Ep: 1.71 masked_t 2.223 masked_v 0.372 NSP 0.173 lr 9.21029e-05
09/25/2020 21:53:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 18591 Ep: 1.71 masked_t 2.187 masked_v 0.374 NSP 0.157 lr 9.20824e-05
09/25/2020 21:54:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 18611 Ep: 1.72 masked_t 2.109 masked_v 0.369 NSP 0.164 lr 9.2062e-05
09/25/2020 21:54:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 18631 Ep: 1.72 masked_t 2.232 masked_v 0.361 NSP 0.164 lr 9.20415e-05
09/25/2020 21:54:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 18651 Ep: 1.72 masked_t 2.262 masked_v 0.372 NSP 0.186 lr 9.2021e-05
09/25/2020 21:55:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 18671 Ep: 1.72 masked_t 2.191 masked_v 0.364 NSP 0.164 lr 9.20005e-05
09/25/2020 21:55:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 18691 Ep: 1.72 masked_t 2.139 masked_v 0.363 NSP 0.171 lr 9.198e-05
09/25/2020 21:55:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 18711 Ep: 1.72 masked_t 2.213 masked_v 0.367 NSP 0.160 lr 9.19595e-05
09/25/2020 21:56:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 18731 Ep: 1.73 masked_t 2.208 masked_v 0.364 NSP 0.176 lr 9.19391e-05
09/25/2020 21:56:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 18751 Ep: 1.73 masked_t 2.135 masked_v 0.376 NSP 0.157 lr 9.19186e-05
09/25/2020 21:56:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 18771 Ep: 1.73 masked_t 2.259 masked_v 0.371 NSP 0.155 lr 9.18981e-05
09/25/2020 21:57:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 18791 Ep: 1.73 masked_t 2.270 masked_v 0.374 NSP 0.163 lr 9.18776e-05
09/25/2020 21:57:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 18811 Ep: 1.73 masked_t 2.208 masked_v 0.370 NSP 0.150 lr 9.18571e-05
09/25/2020 21:58:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 18831 Ep: 1.74 masked_t 2.246 masked_v 0.375 NSP 0.158 lr 9.18367e-05
09/25/2020 21:58:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 18851 Ep: 1.74 masked_t 2.258 masked_v 0.365 NSP 0.164 lr 9.18162e-05
09/25/2020 21:58:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 18871 Ep: 1.74 masked_t 2.147 masked_v 0.362 NSP 0.173 lr 9.17957e-05
09/25/2020 21:59:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 18891 Ep: 1.74 masked_t 2.119 masked_v 0.353 NSP 0.166 lr 9.17752e-05
09/25/2020 21:59:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 18911 Ep: 1.74 masked_t 2.149 masked_v 0.365 NSP 0.163 lr 9.17547e-05
09/25/2020 21:59:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 18931 Ep: 1.74 masked_t 2.275 masked_v 0.371 NSP 0.168 lr 9.17343e-05
09/25/2020 22:00:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 18951 Ep: 1.75 masked_t 2.190 masked_v 0.361 NSP 0.165 lr 9.17138e-05
09/25/2020 22:00:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 18971 Ep: 1.75 masked_t 2.110 masked_v 0.373 NSP 0.172 lr 9.16933e-05
09/25/2020 22:00:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 18991 Ep: 1.75 masked_t 2.245 masked_v 0.359 NSP 0.161 lr 9.16728e-05
09/25/2020 22:01:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 19011 Ep: 1.75 masked_t 2.241 masked_v 0.365 NSP 0.166 lr 9.16523e-05
09/25/2020 22:01:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 19031 Ep: 1.75 masked_t 2.159 masked_v 0.366 NSP 0.164 lr 9.16318e-05
09/25/2020 22:01:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 19051 Ep: 1.76 masked_t 2.171 masked_v 0.358 NSP 0.170 lr 9.16114e-05
09/25/2020 22:02:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 19071 Ep: 1.76 masked_t 2.213 masked_v 0.368 NSP 0.162 lr 9.15909e-05
09/25/2020 22:02:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 19091 Ep: 1.76 masked_t 2.180 masked_v 0.365 NSP 0.157 lr 9.15704e-05
09/25/2020 22:03:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 19111 Ep: 1.76 masked_t 2.226 masked_v 0.363 NSP 0.157 lr 9.15499e-05
09/25/2020 22:03:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 19131 Ep: 1.76 masked_t 2.227 masked_v 0.372 NSP 0.163 lr 9.15294e-05
09/25/2020 22:03:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 19151 Ep: 1.77 masked_t 2.126 masked_v 0.360 NSP 0.166 lr 9.1509e-05
09/25/2020 22:04:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 19171 Ep: 1.77 masked_t 2.193 masked_v 0.363 NSP 0.165 lr 9.14885e-05
09/25/2020 22:04:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 19191 Ep: 1.77 masked_t 2.226 masked_v 0.370 NSP 0.158 lr 9.1468e-05
09/25/2020 22:04:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 19211 Ep: 1.77 masked_t 2.160 masked_v 0.363 NSP 0.156 lr 9.14475e-05
09/25/2020 22:05:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 19231 Ep: 1.77 masked_t 2.134 masked_v 0.357 NSP 0.154 lr 9.1427e-05
09/25/2020 22:05:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 19251 Ep: 1.77 masked_t 2.135 masked_v 0.354 NSP 0.159 lr 9.14066e-05
09/25/2020 22:05:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 19271 Ep: 1.78 masked_t 2.127 masked_v 0.358 NSP 0.156 lr 9.13861e-05
09/25/2020 22:06:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 19291 Ep: 1.78 masked_t 2.275 masked_v 0.371 NSP 0.164 lr 9.13656e-05
09/25/2020 22:06:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 19311 Ep: 1.78 masked_t 2.226 masked_v 0.370 NSP 0.176 lr 9.13451e-05
09/25/2020 22:07:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 19331 Ep: 1.78 masked_t 2.220 masked_v 0.361 NSP 0.155 lr 9.13246e-05
09/25/2020 22:07:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 19351 Ep: 1.78 masked_t 2.217 masked_v 0.361 NSP 0.164 lr 9.13041e-05
09/25/2020 22:07:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 19371 Ep: 1.79 masked_t 2.194 masked_v 0.361 NSP 0.159 lr 9.12837e-05
09/25/2020 22:08:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 19391 Ep: 1.79 masked_t 2.210 masked_v 0.361 NSP 0.165 lr 9.12632e-05
09/25/2020 22:08:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 19411 Ep: 1.79 masked_t 2.169 masked_v 0.364 NSP 0.164 lr 9.12427e-05
09/25/2020 22:08:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 19431 Ep: 1.79 masked_t 2.158 masked_v 0.361 NSP 0.165 lr 9.12222e-05
09/25/2020 22:09:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 19451 Ep: 1.79 masked_t 2.172 masked_v 0.364 NSP 0.159 lr 9.12017e-05
09/25/2020 22:09:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 19471 Ep: 1.79 masked_t 2.154 masked_v 0.361 NSP 0.154 lr 9.11813e-05
09/25/2020 22:09:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 19491 Ep: 1.80 masked_t 2.278 masked_v 0.369 NSP 0.149 lr 9.11608e-05
09/25/2020 22:10:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 19511 Ep: 1.80 masked_t 2.126 masked_v 0.357 NSP 0.167 lr 9.11403e-05
09/25/2020 22:10:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 19531 Ep: 1.80 masked_t 2.155 masked_v 0.362 NSP 0.163 lr 9.11198e-05
09/25/2020 22:11:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 19551 Ep: 1.80 masked_t 2.177 masked_v 0.361 NSP 0.150 lr 9.10993e-05
09/25/2020 22:11:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 19571 Ep: 1.80 masked_t 2.134 masked_v 0.370 NSP 0.167 lr 9.10789e-05
09/25/2020 22:11:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 19591 Ep: 1.81 masked_t 2.156 masked_v 0.359 NSP 0.159 lr 9.10584e-05
09/25/2020 22:12:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 19611 Ep: 1.81 masked_t 2.143 masked_v 0.357 NSP 0.157 lr 9.10379e-05
09/25/2020 22:12:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 19631 Ep: 1.81 masked_t 2.087 masked_v 0.362 NSP 0.149 lr 9.10174e-05
09/25/2020 22:12:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 19651 Ep: 1.81 masked_t 2.136 masked_v 0.354 NSP 0.158 lr 9.09969e-05
09/25/2020 22:13:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 19671 Ep: 1.81 masked_t 2.216 masked_v 0.355 NSP 0.153 lr 9.09764e-05
09/25/2020 22:13:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 19691 Ep: 1.81 masked_t 2.173 masked_v 0.359 NSP 0.168 lr 9.0956e-05
09/25/2020 22:13:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 19711 Ep: 1.82 masked_t 2.229 masked_v 0.356 NSP 0.158 lr 9.09355e-05
09/25/2020 22:14:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 19731 Ep: 1.82 masked_t 2.206 masked_v 0.365 NSP 0.169 lr 9.0915e-05
09/25/2020 22:14:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 19751 Ep: 1.82 masked_t 2.153 masked_v 0.364 NSP 0.171 lr 9.08945e-05
09/25/2020 22:15:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 19771 Ep: 1.82 masked_t 2.229 masked_v 0.364 NSP 0.154 lr 9.0874e-05
09/25/2020 22:15:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 19791 Ep: 1.82 masked_t 2.108 masked_v 0.356 NSP 0.174 lr 9.08536e-05
09/25/2020 22:15:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 19811 Ep: 1.83 masked_t 2.148 masked_v 0.353 NSP 0.157 lr 9.08331e-05
09/25/2020 22:16:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 19831 Ep: 1.83 masked_t 2.191 masked_v 0.361 NSP 0.163 lr 9.08126e-05
09/25/2020 22:16:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 19851 Ep: 1.83 masked_t 2.207 masked_v 0.363 NSP 0.156 lr 9.07921e-05
09/25/2020 22:16:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 19871 Ep: 1.83 masked_t 2.196 masked_v 0.366 NSP 0.170 lr 9.07716e-05
09/25/2020 22:17:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 19891 Ep: 1.83 masked_t 2.148 masked_v 0.359 NSP 0.158 lr 9.07512e-05
09/25/2020 22:17:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 19911 Ep: 1.84 masked_t 2.113 masked_v 0.360 NSP 0.163 lr 9.07307e-05
