/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
08/25/2020 06:40:10 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
08/25/2020 06:40:11 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
08/25/2020 06:40:11 - INFO - volta.task_utils -   Loading refcoco Dataset with batch size 256
08/25/2020 06:41:03 - INFO - volta.utils -   logging file at: ../../logs/volta/refcoco_unc/refcoco_vilbert_base
08/25/2020 06:41:03 - INFO - volta.utils -   loading weights file /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/volta/vilbert/vilbert_base/pytorch_model_9.bin
08/25/2020 06:41:10 - INFO - volta.utils -   
08/25/2020 06:41:10 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK9.weight', 'clfs_dict.TASK9.bias']
08/25/2020 06:41:14 - INFO - __main__ -   >> Trainable Parameters:
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(1024, 2048)    |2097152     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(1024, 5)       |5120        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.weight                           |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.bias                             |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                   |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.predictions.bias                                         |torch.float32    |(30522,)        |30522       |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.predictions.transform.dense.weight                       |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.predictions.transform.dense.bias                         |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.weight                   |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.bias                     |torch.float32    |(768,)          |768         |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.bi_seq_relationship.weight                               |torch.float32    |(2, 1024)       |2048        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.bi_seq_relationship.bias                                 |torch.float32    |(2,)            |2           |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.weight                   |torch.float32    |(1601, 1024)    |1639424     |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.bias                     |torch.float32    |(1601,)         |1601        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.clfs_dict.TASK9.weight                                       |torch.float32    |(1, 1024)       |1024        |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   |module.clfs_dict.TASK9.bias                                         |torch.float32    |(1,)            |1           |
08/25/2020 06:41:14 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:41:14 - INFO - __main__ -   >> # TrainableParams:       	239.02	M
08/25/2020 06:41:14 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
08/25/2020 06:41:14 - INFO - __main__ -   >> # TotalParams:           	239.02	M

Epoch:   0%|          | 0/20 [00:00<?, ?it/s]08/25/2020 06:41:51 - INFO - volta.utils -   [refcoco]: iter 21 Ep: 0.04 loss 4.922 score 0.215 lr 2.33051e-07 
08/25/2020 06:42:04 - INFO - volta.utils -   [refcoco]: iter 41 Ep: 0.09 loss 3.568 score 0.260 lr 6.67373e-07 
08/25/2020 06:42:17 - INFO - volta.utils -   [refcoco]: iter 61 Ep: 0.13 loss 3.288 score 0.322 lr 1.0911e-06 
08/25/2020 06:42:28 - INFO - volta.utils -   [refcoco]: iter 81 Ep: 0.17 loss 3.163 score 0.345 lr 1.51483e-06 
08/25/2020 06:42:40 - INFO - volta.utils -   [refcoco]: iter 101 Ep: 0.21 loss 3.084 score 0.387 lr 1.93856e-06 
08/25/2020 06:42:52 - INFO - volta.utils -   [refcoco]: iter 121 Ep: 0.26 loss 3.017 score 0.412 lr 2.36229e-06 
08/25/2020 06:43:05 - INFO - volta.utils -   [refcoco]: iter 141 Ep: 0.30 loss 2.943 score 0.445 lr 2.78602e-06 
08/25/2020 06:43:17 - INFO - volta.utils -   [refcoco]: iter 161 Ep: 0.34 loss 2.921 score 0.485 lr 3.20975e-06 
08/25/2020 06:43:29 - INFO - volta.utils -   [refcoco]: iter 181 Ep: 0.38 loss 2.873 score 0.497 lr 3.63347e-06 
08/25/2020 06:43:41 - INFO - volta.utils -   [refcoco]: iter 201 Ep: 0.43 loss 2.834 score 0.520 lr 4.0572e-06 
08/25/2020 06:43:52 - INFO - volta.utils -   [refcoco]: iter 221 Ep: 0.47 loss 2.790 score 0.544 lr 4.48093e-06 
08/25/2020 06:44:06 - INFO - volta.utils -   [refcoco]: iter 241 Ep: 0.51 loss 2.729 score 0.571 lr 4.90466e-06 
08/25/2020 06:44:18 - INFO - volta.utils -   [refcoco]: iter 261 Ep: 0.55 loss 2.647 score 0.615 lr 5.32839e-06 
08/25/2020 06:44:29 - INFO - volta.utils -   [refcoco]: iter 281 Ep: 0.60 loss 2.565 score 0.653 lr 5.75212e-06 
08/25/2020 06:44:41 - INFO - volta.utils -   [refcoco]: iter 301 Ep: 0.64 loss 2.503 score 0.672 lr 6.17585e-06 
08/25/2020 06:44:55 - INFO - volta.utils -   [refcoco]: iter 321 Ep: 0.68 loss 2.459 score 0.681 lr 6.59958e-06 
08/25/2020 06:45:07 - INFO - volta.utils -   [refcoco]: iter 341 Ep: 0.72 loss 2.433 score 0.690 lr 7.02331e-06 
08/25/2020 06:45:18 - INFO - volta.utils -   [refcoco]: iter 361 Ep: 0.76 loss 2.397 score 0.697 lr 7.44703e-06 
08/25/2020 06:45:30 - INFO - volta.utils -   [refcoco]: iter 381 Ep: 0.81 loss 2.352 score 0.721 lr 7.87076e-06 
08/25/2020 06:45:43 - INFO - volta.utils -   [refcoco]: iter 401 Ep: 0.85 loss 2.366 score 0.721 lr 8.29449e-06 
08/25/2020 06:45:55 - INFO - volta.utils -   [refcoco]: iter 421 Ep: 0.89 loss 2.363 score 0.708 lr 8.71822e-06 
08/25/2020 06:46:06 - INFO - volta.utils -   [refcoco]: iter 441 Ep: 0.93 loss 2.318 score 0.727 lr 9.14195e-06 
08/25/2020 06:46:18 - INFO - volta.utils -   [refcoco]: iter 461 Ep: 0.98 loss 2.316 score 0.726 lr 9.56568e-06 
08/25/2020 06:46:24 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:   5%|▌         | 1/20 [05:14<1:39:38, 314.67s/it]08/25/2020 06:46:44 - INFO - volta.utils -   Eval task TASK9 on iteration 473 
08/25/2020 06:46:44 - INFO - volta.utils -   Validation [refcoco]: loss 2.221 score 73.842 
08/25/2020 06:46:56 - INFO - volta.utils -   [refcoco]: iter 493 Ep: 1.04 loss 2.266 score 0.741 lr 1.01165e-05 
08/25/2020 06:47:08 - INFO - volta.utils -   [refcoco]: iter 513 Ep: 1.09 loss 2.251 score 0.756 lr 1.06674e-05 
08/25/2020 06:47:20 - INFO - volta.utils -   [refcoco]: iter 533 Ep: 1.13 loss 2.251 score 0.761 lr 1.10911e-05 
08/25/2020 06:47:33 - INFO - volta.utils -   [refcoco]: iter 553 Ep: 1.17 loss 2.217 score 0.754 lr 1.15148e-05 
08/25/2020 06:47:45 - INFO - volta.utils -   [refcoco]: iter 573 Ep: 1.21 loss 2.204 score 0.758 lr 1.19386e-05 
08/25/2020 06:47:57 - INFO - volta.utils -   [refcoco]: iter 593 Ep: 1.26 loss 2.218 score 0.754 lr 1.23623e-05 
08/25/2020 06:48:09 - INFO - volta.utils -   [refcoco]: iter 613 Ep: 1.30 loss 2.206 score 0.762 lr 1.2786e-05 
08/25/2020 06:48:22 - INFO - volta.utils -   [refcoco]: iter 633 Ep: 1.34 loss 2.185 score 0.776 lr 1.32097e-05 
08/25/2020 06:48:34 - INFO - volta.utils -   [refcoco]: iter 653 Ep: 1.38 loss 2.199 score 0.760 lr 1.36335e-05 
08/25/2020 06:48:46 - INFO - volta.utils -   [refcoco]: iter 673 Ep: 1.43 loss 2.191 score 0.771 lr 1.40572e-05 
08/25/2020 06:48:57 - INFO - volta.utils -   [refcoco]: iter 693 Ep: 1.47 loss 2.146 score 0.787 lr 1.44809e-05 
08/25/2020 06:49:10 - INFO - volta.utils -   [refcoco]: iter 713 Ep: 1.51 loss 2.150 score 0.784 lr 1.49047e-05 
08/25/2020 06:49:22 - INFO - volta.utils -   [refcoco]: iter 733 Ep: 1.55 loss 2.166 score 0.780 lr 1.53284e-05 
08/25/2020 06:49:34 - INFO - volta.utils -   [refcoco]: iter 753 Ep: 1.60 loss 2.158 score 0.790 lr 1.57521e-05 
08/25/2020 06:49:46 - INFO - volta.utils -   [refcoco]: iter 773 Ep: 1.64 loss 2.140 score 0.786 lr 1.61758e-05 
08/25/2020 06:49:58 - INFO - volta.utils -   [refcoco]: iter 793 Ep: 1.68 loss 2.141 score 0.771 lr 1.65996e-05 
08/25/2020 06:50:11 - INFO - volta.utils -   [refcoco]: iter 813 Ep: 1.72 loss 2.119 score 0.787 lr 1.70233e-05 
08/25/2020 06:50:23 - INFO - volta.utils -   [refcoco]: iter 833 Ep: 1.76 loss 2.118 score 0.789 lr 1.7447e-05 
08/25/2020 06:50:34 - INFO - volta.utils -   [refcoco]: iter 853 Ep: 1.81 loss 2.104 score 0.795 lr 1.78708e-05 
08/25/2020 06:50:46 - INFO - volta.utils -   [refcoco]: iter 873 Ep: 1.85 loss 2.131 score 0.786 lr 1.82945e-05 
08/25/2020 06:50:59 - INFO - volta.utils -   [refcoco]: iter 893 Ep: 1.89 loss 2.097 score 0.784 lr 1.87182e-05 
08/25/2020 06:51:11 - INFO - volta.utils -   [refcoco]: iter 913 Ep: 1.93 loss 2.100 score 0.794 lr 1.91419e-05 
08/25/2020 06:51:22 - INFO - volta.utils -   [refcoco]: iter 933 Ep: 1.98 loss 2.118 score 0.794 lr 1.95657e-05 
08/25/2020 06:51:28 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  10%|█         | 2/20 [10:19<1:33:28, 311.61s/it]08/25/2020 06:51:54 - INFO - volta.utils -   Eval task TASK9 on iteration 945 
08/25/2020 06:51:54 - INFO - volta.utils -   Validation [refcoco]: loss 2.099 score 77.598 
08/25/2020 06:52:06 - INFO - volta.utils -   [refcoco]: iter 965 Ep: 2.04 loss 2.049 score 0.813 lr 1.99466e-05 
08/25/2020 06:52:18 - INFO - volta.utils -   [refcoco]: iter 985 Ep: 2.09 loss 2.042 score 0.816 lr 1.99258e-05 
08/25/2020 06:52:29 - INFO - volta.utils -   [refcoco]: iter 1005 Ep: 2.13 loss 2.004 score 0.816 lr 1.98788e-05 
08/25/2020 06:52:42 - INFO - volta.utils -   [refcoco]: iter 1025 Ep: 2.17 loss 2.053 score 0.816 lr 1.98317e-05 
08/25/2020 06:52:53 - INFO - volta.utils -   [refcoco]: iter 1045 Ep: 2.21 loss 2.029 score 0.822 lr 1.97846e-05 
08/25/2020 06:53:05 - INFO - volta.utils -   [refcoco]: iter 1065 Ep: 2.26 loss 2.026 score 0.816 lr 1.97375e-05 
08/25/2020 06:53:17 - INFO - volta.utils -   [refcoco]: iter 1085 Ep: 2.30 loss 2.019 score 0.823 lr 1.96904e-05 
08/25/2020 06:53:30 - INFO - volta.utils -   [refcoco]: iter 1105 Ep: 2.34 loss 2.003 score 0.825 lr 1.96434e-05 
08/25/2020 06:53:41 - INFO - volta.utils -   [refcoco]: iter 1125 Ep: 2.38 loss 2.012 score 0.813 lr 1.95963e-05 
08/25/2020 06:53:53 - INFO - volta.utils -   [refcoco]: iter 1145 Ep: 2.43 loss 2.028 score 0.817 lr 1.95492e-05 
08/25/2020 06:54:05 - INFO - volta.utils -   [refcoco]: iter 1165 Ep: 2.47 loss 2.031 score 0.824 lr 1.95021e-05 
08/25/2020 06:54:17 - INFO - volta.utils -   [refcoco]: iter 1185 Ep: 2.51 loss 2.031 score 0.820 lr 1.9455e-05 
08/25/2020 06:54:30 - INFO - volta.utils -   [refcoco]: iter 1205 Ep: 2.55 loss 1.990 score 0.816 lr 1.9408e-05 
08/25/2020 06:54:42 - INFO - volta.utils -   [refcoco]: iter 1225 Ep: 2.60 loss 2.013 score 0.831 lr 1.93609e-05 
08/25/2020 06:54:53 - INFO - volta.utils -   [refcoco]: iter 1245 Ep: 2.64 loss 1.999 score 0.820 lr 1.93138e-05 
08/25/2020 06:55:05 - INFO - volta.utils -   [refcoco]: iter 1265 Ep: 2.68 loss 2.012 score 0.829 lr 1.92667e-05 
08/25/2020 06:55:18 - INFO - volta.utils -   [refcoco]: iter 1285 Ep: 2.72 loss 1.991 score 0.820 lr 1.92196e-05 
08/25/2020 06:55:30 - INFO - volta.utils -   [refcoco]: iter 1305 Ep: 2.76 loss 1.976 score 0.829 lr 1.91726e-05 
08/25/2020 06:55:41 - INFO - volta.utils -   [refcoco]: iter 1325 Ep: 2.81 loss 2.009 score 0.823 lr 1.91255e-05 
08/25/2020 06:55:53 - INFO - volta.utils -   [refcoco]: iter 1345 Ep: 2.85 loss 2.000 score 0.835 lr 1.90784e-05 
08/25/2020 06:56:06 - INFO - volta.utils -   [refcoco]: iter 1365 Ep: 2.89 loss 2.005 score 0.831 lr 1.90313e-05 
08/25/2020 06:56:17 - INFO - volta.utils -   [refcoco]: iter 1385 Ep: 2.93 loss 2.013 score 0.823 lr 1.89842e-05 
08/25/2020 06:56:29 - INFO - volta.utils -   [refcoco]: iter 1405 Ep: 2.98 loss 1.975 score 0.831 lr 1.89371e-05 
08/25/2020 06:56:35 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  15%|█▌        | 3/20 [15:25<1:27:49, 309.94s/it]08/25/2020 06:56:54 - INFO - volta.utils -   Eval task TASK9 on iteration 1417 
08/25/2020 06:56:54 - INFO - volta.utils -   Validation [refcoco]: loss 2.071 score 77.977 
08/25/2020 06:57:06 - INFO - volta.utils -   [refcoco]: iter 1437 Ep: 3.04 loss 1.957 score 0.842 lr 1.88759e-05 
08/25/2020 06:57:18 - INFO - volta.utils -   [refcoco]: iter 1457 Ep: 3.09 loss 1.900 score 0.855 lr 1.88147e-05 
08/25/2020 06:57:29 - INFO - volta.utils -   [refcoco]: iter 1477 Ep: 3.13 loss 1.951 score 0.846 lr 1.87677e-05 
08/25/2020 06:57:41 - INFO - volta.utils -   [refcoco]: iter 1497 Ep: 3.17 loss 1.932 score 0.849 lr 1.87206e-05 
08/25/2020 06:57:54 - INFO - volta.utils -   [refcoco]: iter 1517 Ep: 3.21 loss 1.904 score 0.856 lr 1.86735e-05 
08/25/2020 06:58:06 - INFO - volta.utils -   [refcoco]: iter 1537 Ep: 3.26 loss 1.925 score 0.850 lr 1.86264e-05 
08/25/2020 06:58:17 - INFO - volta.utils -   [refcoco]: iter 1557 Ep: 3.30 loss 1.918 score 0.847 lr 1.85793e-05 
08/25/2020 06:58:29 - INFO - volta.utils -   [refcoco]: iter 1577 Ep: 3.34 loss 1.932 score 0.852 lr 1.85323e-05 
08/25/2020 06:58:42 - INFO - volta.utils -   [refcoco]: iter 1597 Ep: 3.38 loss 1.917 score 0.844 lr 1.84852e-05 
08/25/2020 06:58:54 - INFO - volta.utils -   [refcoco]: iter 1617 Ep: 3.43 loss 1.939 score 0.846 lr 1.84381e-05 
08/25/2020 06:59:05 - INFO - volta.utils -   [refcoco]: iter 1637 Ep: 3.47 loss 1.927 score 0.840 lr 1.8391e-05 
08/25/2020 06:59:17 - INFO - volta.utils -   [refcoco]: iter 1657 Ep: 3.51 loss 1.907 score 0.851 lr 1.83439e-05 
08/25/2020 06:59:30 - INFO - volta.utils -   [refcoco]: iter 1677 Ep: 3.55 loss 1.915 score 0.857 lr 1.82968e-05 
08/25/2020 06:59:42 - INFO - volta.utils -   [refcoco]: iter 1697 Ep: 3.60 loss 1.895 score 0.846 lr 1.82498e-05 
08/25/2020 06:59:54 - INFO - volta.utils -   [refcoco]: iter 1717 Ep: 3.64 loss 1.936 score 0.843 lr 1.82027e-05 
08/25/2020 07:00:06 - INFO - volta.utils -   [refcoco]: iter 1737 Ep: 3.68 loss 1.923 score 0.854 lr 1.81556e-05 
08/25/2020 07:00:18 - INFO - volta.utils -   [refcoco]: iter 1757 Ep: 3.72 loss 1.918 score 0.853 lr 1.81085e-05 
08/25/2020 07:00:32 - INFO - volta.utils -   [refcoco]: iter 1777 Ep: 3.76 loss 1.927 score 0.845 lr 1.80614e-05 
08/25/2020 07:00:44 - INFO - volta.utils -   [refcoco]: iter 1797 Ep: 3.81 loss 1.916 score 0.851 lr 1.80144e-05 
08/25/2020 07:00:55 - INFO - volta.utils -   [refcoco]: iter 1817 Ep: 3.85 loss 1.905 score 0.853 lr 1.79673e-05 
08/25/2020 07:01:07 - INFO - volta.utils -   [refcoco]: iter 1837 Ep: 3.89 loss 1.937 score 0.843 lr 1.79202e-05 
08/25/2020 07:01:20 - INFO - volta.utils -   [refcoco]: iter 1857 Ep: 3.93 loss 1.894 score 0.856 lr 1.78731e-05 
08/25/2020 07:01:31 - INFO - volta.utils -   [refcoco]: iter 1877 Ep: 3.98 loss 1.922 score 0.862 lr 1.7826e-05 
08/25/2020 07:01:37 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  20%|██        | 4/20 [20:28<1:22:05, 307.82s/it]08/25/2020 07:02:01 - INFO - volta.utils -   Eval task TASK9 on iteration 1889 
08/25/2020 07:02:01 - INFO - volta.utils -   Validation [refcoco]: loss 2.053 score 78.927 
08/25/2020 07:02:14 - INFO - volta.utils -   [refcoco]: iter 1909 Ep: 4.04 loss 1.889 score 0.859 lr 1.77648e-05 
08/25/2020 07:02:26 - INFO - volta.utils -   [refcoco]: iter 1929 Ep: 4.09 loss 1.831 score 0.870 lr 1.77036e-05 
08/25/2020 07:02:38 - INFO - volta.utils -   [refcoco]: iter 1949 Ep: 4.13 loss 1.862 score 0.868 lr 1.76565e-05 
08/25/2020 07:02:50 - INFO - volta.utils -   [refcoco]: iter 1969 Ep: 4.17 loss 1.862 score 0.866 lr 1.76095e-05 
08/25/2020 07:03:03 - INFO - volta.utils -   [refcoco]: iter 1989 Ep: 4.21 loss 1.845 score 0.869 lr 1.75624e-05 
08/25/2020 07:03:15 - INFO - volta.utils -   [refcoco]: iter 2009 Ep: 4.26 loss 1.860 score 0.874 lr 1.75153e-05 
08/25/2020 07:03:26 - INFO - volta.utils -   [refcoco]: iter 2029 Ep: 4.30 loss 1.858 score 0.863 lr 1.74682e-05 
08/25/2020 07:03:38 - INFO - volta.utils -   [refcoco]: iter 2049 Ep: 4.34 loss 1.847 score 0.865 lr 1.74211e-05 
08/25/2020 07:03:50 - INFO - volta.utils -   [refcoco]: iter 2069 Ep: 4.38 loss 1.872 score 0.865 lr 1.73741e-05 
08/25/2020 07:04:03 - INFO - volta.utils -   [refcoco]: iter 2089 Ep: 4.43 loss 1.873 score 0.871 lr 1.7327e-05 
08/25/2020 07:04:15 - INFO - volta.utils -   [refcoco]: iter 2109 Ep: 4.47 loss 1.888 score 0.867 lr 1.72799e-05 
08/25/2020 07:04:26 - INFO - volta.utils -   [refcoco]: iter 2129 Ep: 4.51 loss 1.883 score 0.858 lr 1.72328e-05 
08/25/2020 07:04:38 - INFO - volta.utils -   [refcoco]: iter 2149 Ep: 4.55 loss 1.866 score 0.868 lr 1.71857e-05 
08/25/2020 07:04:51 - INFO - volta.utils -   [refcoco]: iter 2169 Ep: 4.60 loss 1.870 score 0.870 lr 1.71387e-05 
08/25/2020 07:05:03 - INFO - volta.utils -   [refcoco]: iter 2189 Ep: 4.64 loss 1.831 score 0.867 lr 1.70916e-05 
08/25/2020 07:05:15 - INFO - volta.utils -   [refcoco]: iter 2209 Ep: 4.68 loss 1.860 score 0.866 lr 1.70445e-05 
08/25/2020 07:05:27 - INFO - volta.utils -   [refcoco]: iter 2229 Ep: 4.72 loss 1.864 score 0.877 lr 1.69974e-05 
08/25/2020 07:05:39 - INFO - volta.utils -   [refcoco]: iter 2249 Ep: 4.76 loss 1.860 score 0.870 lr 1.69503e-05 
08/25/2020 07:05:51 - INFO - volta.utils -   [refcoco]: iter 2269 Ep: 4.81 loss 1.864 score 0.872 lr 1.69032e-05 
08/25/2020 07:06:03 - INFO - volta.utils -   [refcoco]: iter 2289 Ep: 4.85 loss 1.860 score 0.871 lr 1.68562e-05 
08/25/2020 07:06:15 - INFO - volta.utils -   [refcoco]: iter 2309 Ep: 4.89 loss 1.851 score 0.864 lr 1.68091e-05 
08/25/2020 07:06:27 - INFO - volta.utils -   [refcoco]: iter 2329 Ep: 4.93 loss 1.862 score 0.861 lr 1.6762e-05 
08/25/2020 07:06:40 - INFO - volta.utils -   [refcoco]: iter 2349 Ep: 4.98 loss 1.845 score 0.864 lr 1.67149e-05 
08/25/2020 07:06:46 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  25%|██▌       | 5/20 [25:36<1:17:01, 308.08s/it]08/25/2020 07:07:04 - INFO - volta.utils -   Eval task TASK9 on iteration 2361 
08/25/2020 07:07:04 - INFO - volta.utils -   Validation [refcoco]: loss 2.076 score 78.881 
08/25/2020 07:07:16 - INFO - volta.utils -   [refcoco]: iter 2381 Ep: 5.04 loss 1.838 score 0.873 lr 1.66537e-05 
08/25/2020 07:07:29 - INFO - volta.utils -   [refcoco]: iter 2401 Ep: 5.09 loss 1.836 score 0.881 lr 1.65925e-05 
08/25/2020 07:07:41 - INFO - volta.utils -   [refcoco]: iter 2421 Ep: 5.13 loss 1.827 score 0.880 lr 1.65454e-05 
08/25/2020 07:07:53 - INFO - volta.utils -   [refcoco]: iter 2441 Ep: 5.17 loss 1.803 score 0.884 lr 1.64984e-05 
08/25/2020 07:08:04 - INFO - volta.utils -   [refcoco]: iter 2461 Ep: 5.21 loss 1.802 score 0.875 lr 1.64513e-05 
08/25/2020 07:08:16 - INFO - volta.utils -   [refcoco]: iter 2481 Ep: 5.26 loss 1.844 score 0.877 lr 1.64042e-05 
08/25/2020 07:08:29 - INFO - volta.utils -   [refcoco]: iter 2501 Ep: 5.30 loss 1.819 score 0.873 lr 1.63571e-05 
08/25/2020 07:08:41 - INFO - volta.utils -   [refcoco]: iter 2521 Ep: 5.34 loss 1.839 score 0.876 lr 1.631e-05 
08/25/2020 07:08:52 - INFO - volta.utils -   [refcoco]: iter 2541 Ep: 5.38 loss 1.814 score 0.875 lr 1.62629e-05 
08/25/2020 07:09:04 - INFO - volta.utils -   [refcoco]: iter 2561 Ep: 5.43 loss 1.822 score 0.884 lr 1.62159e-05 
08/25/2020 07:09:17 - INFO - volta.utils -   [refcoco]: iter 2581 Ep: 5.47 loss 1.809 score 0.874 lr 1.61688e-05 
08/25/2020 07:09:29 - INFO - volta.utils -   [refcoco]: iter 2601 Ep: 5.51 loss 1.819 score 0.882 lr 1.61217e-05 
08/25/2020 07:09:41 - INFO - volta.utils -   [refcoco]: iter 2621 Ep: 5.55 loss 1.820 score 0.877 lr 1.60746e-05 
08/25/2020 07:09:53 - INFO - volta.utils -   [refcoco]: iter 2641 Ep: 5.60 loss 1.819 score 0.873 lr 1.60275e-05 
08/25/2020 07:10:05 - INFO - volta.utils -   [refcoco]: iter 2661 Ep: 5.64 loss 1.819 score 0.877 lr 1.59805e-05 
08/25/2020 07:10:18 - INFO - volta.utils -   [refcoco]: iter 2681 Ep: 5.68 loss 1.820 score 0.870 lr 1.59334e-05 
08/25/2020 07:10:30 - INFO - volta.utils -   [refcoco]: iter 2701 Ep: 5.72 loss 1.809 score 0.887 lr 1.58863e-05 
08/25/2020 07:10:42 - INFO - volta.utils -   [refcoco]: iter 2721 Ep: 5.76 loss 1.824 score 0.878 lr 1.58392e-05 
08/25/2020 07:10:54 - INFO - volta.utils -   [refcoco]: iter 2741 Ep: 5.81 loss 1.818 score 0.875 lr 1.57921e-05 
08/25/2020 07:11:06 - INFO - volta.utils -   [refcoco]: iter 2761 Ep: 5.85 loss 1.810 score 0.878 lr 1.57451e-05 
08/25/2020 07:11:19 - INFO - volta.utils -   [refcoco]: iter 2781 Ep: 5.89 loss 1.808 score 0.884 lr 1.5698e-05 
08/25/2020 07:11:31 - INFO - volta.utils -   [refcoco]: iter 2801 Ep: 5.93 loss 1.842 score 0.880 lr 1.56509e-05 
08/25/2020 07:11:43 - INFO - volta.utils -   [refcoco]: iter 2821 Ep: 5.98 loss 1.826 score 0.884 lr 1.56038e-05 
08/25/2020 07:11:49 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  30%|███       | 6/20 [30:39<1:11:30, 306.44s/it]08/25/2020 07:12:11 - INFO - volta.utils -   Eval task TASK9 on iteration 2833 
08/25/2020 07:12:11 - INFO - volta.utils -   Validation [refcoco]: loss 2.060 score 79.029 
08/25/2020 07:12:23 - INFO - volta.utils -   [refcoco]: iter 2853 Ep: 6.04 loss 1.804 score 0.886 lr 1.55426e-05 
08/25/2020 07:12:35 - INFO - volta.utils -   [refcoco]: iter 2873 Ep: 6.09 loss 1.786 score 0.890 lr 1.54814e-05 
08/25/2020 07:12:46 - INFO - volta.utils -   [refcoco]: iter 2893 Ep: 6.13 loss 1.781 score 0.896 lr 1.54343e-05 
08/25/2020 07:12:59 - INFO - volta.utils -   [refcoco]: iter 2913 Ep: 6.17 loss 1.781 score 0.888 lr 1.53872e-05 
08/25/2020 07:13:12 - INFO - volta.utils -   [refcoco]: iter 2933 Ep: 6.21 loss 1.786 score 0.883 lr 1.53402e-05 
08/25/2020 07:13:25 - INFO - volta.utils -   [refcoco]: iter 2953 Ep: 6.26 loss 1.814 score 0.889 lr 1.52931e-05 
08/25/2020 07:13:37 - INFO - volta.utils -   [refcoco]: iter 2973 Ep: 6.30 loss 1.776 score 0.894 lr 1.5246e-05 
08/25/2020 07:13:49 - INFO - volta.utils -   [refcoco]: iter 2993 Ep: 6.34 loss 1.785 score 0.888 lr 1.51989e-05 
08/25/2020 07:14:01 - INFO - volta.utils -   [refcoco]: iter 3013 Ep: 6.38 loss 1.786 score 0.886 lr 1.51518e-05 
08/25/2020 07:14:14 - INFO - volta.utils -   [refcoco]: iter 3033 Ep: 6.43 loss 1.790 score 0.895 lr 1.51048e-05 
08/25/2020 07:14:26 - INFO - volta.utils -   [refcoco]: iter 3053 Ep: 6.47 loss 1.777 score 0.889 lr 1.50577e-05 
08/25/2020 07:14:37 - INFO - volta.utils -   [refcoco]: iter 3073 Ep: 6.51 loss 1.803 score 0.879 lr 1.50106e-05 
08/25/2020 07:14:49 - INFO - volta.utils -   [refcoco]: iter 3093 Ep: 6.55 loss 1.789 score 0.879 lr 1.49635e-05 
08/25/2020 07:15:01 - INFO - volta.utils -   [refcoco]: iter 3113 Ep: 6.60 loss 1.806 score 0.882 lr 1.49164e-05 
08/25/2020 07:15:14 - INFO - volta.utils -   [refcoco]: iter 3133 Ep: 6.64 loss 1.789 score 0.886 lr 1.48694e-05 
08/25/2020 07:15:26 - INFO - volta.utils -   [refcoco]: iter 3153 Ep: 6.68 loss 1.771 score 0.892 lr 1.48223e-05 
08/25/2020 07:15:37 - INFO - volta.utils -   [refcoco]: iter 3173 Ep: 6.72 loss 1.780 score 0.887 lr 1.47752e-05 
08/25/2020 07:15:49 - INFO - volta.utils -   [refcoco]: iter 3193 Ep: 6.76 loss 1.791 score 0.887 lr 1.47281e-05 
08/25/2020 07:16:02 - INFO - volta.utils -   [refcoco]: iter 3213 Ep: 6.81 loss 1.795 score 0.888 lr 1.4681e-05 
08/25/2020 07:16:14 - INFO - volta.utils -   [refcoco]: iter 3233 Ep: 6.85 loss 1.778 score 0.880 lr 1.46339e-05 
08/25/2020 07:16:25 - INFO - volta.utils -   [refcoco]: iter 3253 Ep: 6.89 loss 1.807 score 0.875 lr 1.45869e-05 
08/25/2020 07:16:37 - INFO - volta.utils -   [refcoco]: iter 3273 Ep: 6.93 loss 1.793 score 0.890 lr 1.45398e-05 
08/25/2020 07:16:48 - INFO - volta.utils -   [refcoco]: iter 3293 Ep: 6.98 loss 1.792 score 0.889 lr 1.44927e-05 
08/25/2020 07:16:54 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  35%|███▌      | 7/20 [35:45<1:06:20, 306.20s/it]08/25/2020 07:17:16 - INFO - volta.utils -   Eval task TASK9 on iteration 3305 
08/25/2020 07:17:16 - INFO - volta.utils -   Validation [refcoco]: loss 2.078 score 79.389 
08/25/2020 07:17:28 - INFO - volta.utils -   [refcoco]: iter 3325 Ep: 7.04 loss 1.778 score 0.889 lr 1.44315e-05 
08/25/2020 07:17:39 - INFO - volta.utils -   [refcoco]: iter 3345 Ep: 7.09 loss 1.762 score 0.891 lr 1.43703e-05 
08/25/2020 07:17:51 - INFO - volta.utils -   [refcoco]: iter 3365 Ep: 7.13 loss 1.783 score 0.892 lr 1.43232e-05 
08/25/2020 07:18:04 - INFO - volta.utils -   [refcoco]: iter 3385 Ep: 7.17 loss 1.766 score 0.898 lr 1.42761e-05 
08/25/2020 07:18:16 - INFO - volta.utils -   [refcoco]: iter 3405 Ep: 7.21 loss 1.763 score 0.897 lr 1.4229e-05 
08/25/2020 07:18:28 - INFO - volta.utils -   [refcoco]: iter 3425 Ep: 7.26 loss 1.756 score 0.895 lr 1.4182e-05 
08/25/2020 07:18:40 - INFO - volta.utils -   [refcoco]: iter 3445 Ep: 7.30 loss 1.783 score 0.887 lr 1.41349e-05 
08/25/2020 07:18:51 - INFO - volta.utils -   [refcoco]: iter 3465 Ep: 7.34 loss 1.756 score 0.886 lr 1.40878e-05 
08/25/2020 07:19:05 - INFO - volta.utils -   [refcoco]: iter 3485 Ep: 7.38 loss 1.747 score 0.894 lr 1.40407e-05 
08/25/2020 07:19:16 - INFO - volta.utils -   [refcoco]: iter 3505 Ep: 7.43 loss 1.751 score 0.895 lr 1.39936e-05 
08/25/2020 07:19:28 - INFO - volta.utils -   [refcoco]: iter 3525 Ep: 7.47 loss 1.769 score 0.891 lr 1.39466e-05 
08/25/2020 07:19:40 - INFO - volta.utils -   [refcoco]: iter 3545 Ep: 7.51 loss 1.762 score 0.895 lr 1.38995e-05 
08/25/2020 07:19:52 - INFO - volta.utils -   [refcoco]: iter 3565 Ep: 7.55 loss 1.768 score 0.892 lr 1.38524e-05 
08/25/2020 07:20:05 - INFO - volta.utils -   [refcoco]: iter 3585 Ep: 7.60 loss 1.776 score 0.898 lr 1.38053e-05 
08/25/2020 07:20:16 - INFO - volta.utils -   [refcoco]: iter 3605 Ep: 7.64 loss 1.778 score 0.892 lr 1.37582e-05 
08/25/2020 07:20:28 - INFO - volta.utils -   [refcoco]: iter 3625 Ep: 7.68 loss 1.790 score 0.889 lr 1.37112e-05 
08/25/2020 07:20:40 - INFO - volta.utils -   [refcoco]: iter 3645 Ep: 7.72 loss 1.773 score 0.890 lr 1.36641e-05 
08/25/2020 07:20:52 - INFO - volta.utils -   [refcoco]: iter 3665 Ep: 7.76 loss 1.756 score 0.897 lr 1.3617e-05 
08/25/2020 07:21:04 - INFO - volta.utils -   [refcoco]: iter 3685 Ep: 7.81 loss 1.760 score 0.894 lr 1.35699e-05 
08/25/2020 07:21:17 - INFO - volta.utils -   [refcoco]: iter 3705 Ep: 7.85 loss 1.751 score 0.895 lr 1.35228e-05 
08/25/2020 07:21:29 - INFO - volta.utils -   [refcoco]: iter 3725 Ep: 7.89 loss 1.752 score 0.893 lr 1.34758e-05 
08/25/2020 07:21:41 - INFO - volta.utils -   [refcoco]: iter 3745 Ep: 7.93 loss 1.790 score 0.883 lr 1.34287e-05 
08/25/2020 07:21:52 - INFO - volta.utils -   [refcoco]: iter 3765 Ep: 7.98 loss 1.748 score 0.894 lr 1.33816e-05 
08/25/2020 07:21:58 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  40%|████      | 8/20 [40:49<1:01:09, 305.77s/it]08/25/2020 07:22:26 - INFO - volta.utils -   Eval task TASK9 on iteration 3777 
08/25/2020 07:22:26 - INFO - volta.utils -   Validation [refcoco]: loss 2.083 score 79.334 
08/25/2020 07:22:37 - INFO - volta.utils -   [refcoco]: iter 3797 Ep: 8.04 loss 1.750 score 0.898 lr 1.33204e-05 
08/25/2020 07:22:49 - INFO - volta.utils -   [refcoco]: iter 3817 Ep: 8.09 loss 1.745 score 0.897 lr 1.32592e-05 
08/25/2020 07:23:01 - INFO - volta.utils -   [refcoco]: iter 3837 Ep: 8.13 loss 1.744 score 0.897 lr 1.32121e-05 
08/25/2020 07:23:14 - INFO - volta.utils -   [refcoco]: iter 3857 Ep: 8.17 loss 1.751 score 0.902 lr 1.3165e-05 
08/25/2020 07:23:25 - INFO - volta.utils -   [refcoco]: iter 3877 Ep: 8.21 loss 1.753 score 0.895 lr 1.31179e-05 
08/25/2020 07:23:37 - INFO - volta.utils -   [refcoco]: iter 3897 Ep: 8.26 loss 1.746 score 0.899 lr 1.30709e-05 
08/25/2020 07:23:48 - INFO - volta.utils -   [refcoco]: iter 3917 Ep: 8.30 loss 1.763 score 0.898 lr 1.30238e-05 
08/25/2020 07:24:01 - INFO - volta.utils -   [refcoco]: iter 3937 Ep: 8.34 loss 1.747 score 0.899 lr 1.29767e-05 
08/25/2020 07:24:13 - INFO - volta.utils -   [refcoco]: iter 3957 Ep: 8.38 loss 1.755 score 0.897 lr 1.29296e-05 
08/25/2020 07:24:25 - INFO - volta.utils -   [refcoco]: iter 3977 Ep: 8.43 loss 1.761 score 0.903 lr 1.28825e-05 
08/25/2020 07:24:36 - INFO - volta.utils -   [refcoco]: iter 3997 Ep: 8.47 loss 1.754 score 0.901 lr 1.28355e-05 
08/25/2020 07:24:48 - INFO - volta.utils -   [refcoco]: iter 4017 Ep: 8.51 loss 1.739 score 0.893 lr 1.27884e-05 
08/25/2020 07:25:01 - INFO - volta.utils -   [refcoco]: iter 4037 Ep: 8.55 loss 1.743 score 0.900 lr 1.27413e-05 
08/25/2020 07:25:13 - INFO - volta.utils -   [refcoco]: iter 4057 Ep: 8.60 loss 1.743 score 0.895 lr 1.26942e-05 
08/25/2020 07:25:24 - INFO - volta.utils -   [refcoco]: iter 4077 Ep: 8.64 loss 1.751 score 0.892 lr 1.26471e-05 
08/25/2020 07:25:36 - INFO - volta.utils -   [refcoco]: iter 4097 Ep: 8.68 loss 1.730 score 0.896 lr 1.26e-05 
08/25/2020 07:25:49 - INFO - volta.utils -   [refcoco]: iter 4117 Ep: 8.72 loss 1.743 score 0.899 lr 1.2553e-05 
08/25/2020 07:26:01 - INFO - volta.utils -   [refcoco]: iter 4137 Ep: 8.76 loss 1.764 score 0.888 lr 1.25059e-05 
08/25/2020 07:26:12 - INFO - volta.utils -   [refcoco]: iter 4157 Ep: 8.81 loss 1.744 score 0.905 lr 1.24588e-05 
08/25/2020 07:26:24 - INFO - volta.utils -   [refcoco]: iter 4177 Ep: 8.85 loss 1.748 score 0.894 lr 1.24117e-05 
08/25/2020 07:26:37 - INFO - volta.utils -   [refcoco]: iter 4197 Ep: 8.89 loss 1.732 score 0.896 lr 1.23646e-05 
08/25/2020 07:26:49 - INFO - volta.utils -   [refcoco]: iter 4217 Ep: 8.93 loss 1.730 score 0.897 lr 1.23176e-05 
08/25/2020 07:27:00 - INFO - volta.utils -   [refcoco]: iter 4237 Ep: 8.98 loss 1.746 score 0.896 lr 1.22705e-05 
08/25/2020 07:27:06 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  45%|████▌     | 9/20 [45:56<56:06, 306.01s/it]  08/25/2020 07:27:26 - INFO - volta.utils -   Eval task TASK9 on iteration 4249 
08/25/2020 07:27:26 - INFO - volta.utils -   Validation [refcoco]: loss 2.076 score 79.315 
08/25/2020 07:27:37 - INFO - volta.utils -   [refcoco]: iter 4269 Ep: 9.04 loss 1.725 score 0.895 lr 1.22093e-05 
08/25/2020 07:27:49 - INFO - volta.utils -   [refcoco]: iter 4289 Ep: 9.09 loss 1.734 score 0.902 lr 1.21481e-05 
08/25/2020 07:28:00 - INFO - volta.utils -   [refcoco]: iter 4309 Ep: 9.13 loss 1.745 score 0.898 lr 1.2101e-05 
08/25/2020 07:28:12 - INFO - volta.utils -   [refcoco]: iter 4329 Ep: 9.17 loss 1.743 score 0.898 lr 1.20539e-05 
08/25/2020 07:28:25 - INFO - volta.utils -   [refcoco]: iter 4349 Ep: 9.21 loss 1.735 score 0.906 lr 1.20068e-05 
08/25/2020 07:28:37 - INFO - volta.utils -   [refcoco]: iter 4369 Ep: 9.26 loss 1.726 score 0.906 lr 1.19597e-05 
08/25/2020 07:28:48 - INFO - volta.utils -   [refcoco]: iter 4389 Ep: 9.30 loss 1.732 score 0.900 lr 1.19127e-05 
08/25/2020 07:29:00 - INFO - volta.utils -   [refcoco]: iter 4409 Ep: 9.34 loss 1.723 score 0.901 lr 1.18656e-05 
08/25/2020 07:29:12 - INFO - volta.utils -   [refcoco]: iter 4429 Ep: 9.38 loss 1.725 score 0.903 lr 1.18185e-05 
08/25/2020 07:29:25 - INFO - volta.utils -   [refcoco]: iter 4449 Ep: 9.43 loss 1.723 score 0.906 lr 1.17714e-05 
08/25/2020 07:29:36 - INFO - volta.utils -   [refcoco]: iter 4469 Ep: 9.47 loss 1.726 score 0.900 lr 1.17243e-05 
08/25/2020 07:29:48 - INFO - volta.utils -   [refcoco]: iter 4489 Ep: 9.51 loss 1.724 score 0.900 lr 1.16773e-05 
08/25/2020 07:29:59 - INFO - volta.utils -   [refcoco]: iter 4509 Ep: 9.55 loss 1.737 score 0.899 lr 1.16302e-05 
08/25/2020 07:30:12 - INFO - volta.utils -   [refcoco]: iter 4529 Ep: 9.60 loss 1.733 score 0.893 lr 1.15831e-05 
08/25/2020 07:30:24 - INFO - volta.utils -   [refcoco]: iter 4549 Ep: 9.64 loss 1.731 score 0.902 lr 1.1536e-05 
08/25/2020 07:30:35 - INFO - volta.utils -   [refcoco]: iter 4569 Ep: 9.68 loss 1.720 score 0.901 lr 1.14889e-05 
08/25/2020 07:30:47 - INFO - volta.utils -   [refcoco]: iter 4589 Ep: 9.72 loss 1.729 score 0.895 lr 1.14419e-05 
08/25/2020 07:30:59 - INFO - volta.utils -   [refcoco]: iter 4609 Ep: 9.76 loss 1.739 score 0.897 lr 1.13948e-05 
08/25/2020 07:31:12 - INFO - volta.utils -   [refcoco]: iter 4629 Ep: 9.81 loss 1.730 score 0.899 lr 1.13477e-05 
08/25/2020 07:31:24 - INFO - volta.utils -   [refcoco]: iter 4649 Ep: 9.85 loss 1.736 score 0.899 lr 1.13006e-05 
08/25/2020 07:31:36 - INFO - volta.utils -   [refcoco]: iter 4669 Ep: 9.89 loss 1.728 score 0.904 lr 1.12535e-05 
08/25/2020 07:31:47 - INFO - volta.utils -   [refcoco]: iter 4689 Ep: 9.93 loss 1.737 score 0.905 lr 1.12065e-05 
08/25/2020 07:31:59 - INFO - volta.utils -   [refcoco]: iter 4709 Ep: 9.98 loss 1.733 score 0.906 lr 1.11594e-05 
08/25/2020 07:32:05 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  50%|█████     | 10/20 [50:56<50:43, 304.35s/it]08/25/2020 07:32:24 - INFO - volta.utils -   Eval task TASK9 on iteration 4721 
08/25/2020 07:32:24 - INFO - volta.utils -   Validation [refcoco]: loss 2.088 score 79.047 
08/25/2020 07:32:36 - INFO - volta.utils -   [refcoco]: iter 4741 Ep: 10.04 loss 1.735 score 0.897 lr 1.10982e-05 
08/25/2020 07:32:48 - INFO - volta.utils -   [refcoco]: iter 4761 Ep: 10.09 loss 1.714 score 0.908 lr 1.1037e-05 
08/25/2020 07:33:01 - INFO - volta.utils -   [refcoco]: iter 4781 Ep: 10.13 loss 1.720 score 0.898 lr 1.09899e-05 
08/25/2020 07:33:13 - INFO - volta.utils -   [refcoco]: iter 4801 Ep: 10.17 loss 1.712 score 0.906 lr 1.09428e-05 
08/25/2020 07:33:25 - INFO - volta.utils -   [refcoco]: iter 4821 Ep: 10.21 loss 1.723 score 0.902 lr 1.08957e-05 
08/25/2020 07:33:37 - INFO - volta.utils -   [refcoco]: iter 4841 Ep: 10.26 loss 1.718 score 0.903 lr 1.08486e-05 
08/25/2020 07:33:51 - INFO - volta.utils -   [refcoco]: iter 4861 Ep: 10.30 loss 1.716 score 0.901 lr 1.08016e-05 
08/25/2020 07:34:03 - INFO - volta.utils -   [refcoco]: iter 4881 Ep: 10.34 loss 1.702 score 0.906 lr 1.07545e-05 
08/25/2020 07:34:16 - INFO - volta.utils -   [refcoco]: iter 4901 Ep: 10.38 loss 1.712 score 0.900 lr 1.07074e-05 
08/25/2020 07:34:28 - INFO - volta.utils -   [refcoco]: iter 4921 Ep: 10.43 loss 1.707 score 0.912 lr 1.06603e-05 
08/25/2020 07:34:39 - INFO - volta.utils -   [refcoco]: iter 4941 Ep: 10.47 loss 1.717 score 0.901 lr 1.06132e-05 
08/25/2020 07:34:52 - INFO - volta.utils -   [refcoco]: iter 4961 Ep: 10.51 loss 1.726 score 0.905 lr 1.05661e-05 
08/25/2020 07:35:04 - INFO - volta.utils -   [refcoco]: iter 4981 Ep: 10.55 loss 1.706 score 0.911 lr 1.05191e-05 
08/25/2020 07:35:16 - INFO - volta.utils -   [refcoco]: iter 5001 Ep: 10.60 loss 1.737 score 0.902 lr 1.0472e-05 
08/25/2020 07:35:28 - INFO - volta.utils -   [refcoco]: iter 5021 Ep: 10.64 loss 1.720 score 0.906 lr 1.04249e-05 
08/25/2020 07:35:41 - INFO - volta.utils -   [refcoco]: iter 5041 Ep: 10.68 loss 1.725 score 0.896 lr 1.03778e-05 
08/25/2020 07:35:52 - INFO - volta.utils -   [refcoco]: iter 5061 Ep: 10.72 loss 1.724 score 0.904 lr 1.03307e-05 
08/25/2020 07:36:04 - INFO - volta.utils -   [refcoco]: iter 5081 Ep: 10.76 loss 1.714 score 0.899 lr 1.02837e-05 
08/25/2020 07:36:16 - INFO - volta.utils -   [refcoco]: iter 5101 Ep: 10.81 loss 1.730 score 0.901 lr 1.02366e-05 
08/25/2020 07:36:29 - INFO - volta.utils -   [refcoco]: iter 5121 Ep: 10.85 loss 1.723 score 0.906 lr 1.01895e-05 
08/25/2020 07:36:41 - INFO - volta.utils -   [refcoco]: iter 5141 Ep: 10.89 loss 1.723 score 0.905 lr 1.01424e-05 
08/25/2020 07:36:52 - INFO - volta.utils -   [refcoco]: iter 5161 Ep: 10.93 loss 1.721 score 0.901 lr 1.00953e-05 
08/25/2020 07:37:04 - INFO - volta.utils -   [refcoco]: iter 5181 Ep: 10.98 loss 1.702 score 0.900 lr 1.00483e-05 
08/25/2020 07:37:10 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  55%|█████▌    | 11/20 [56:00<45:37, 304.17s/it]08/25/2020 07:37:34 - INFO - volta.utils -   Eval task TASK9 on iteration 5193 
08/25/2020 07:37:34 - INFO - volta.utils -   Validation [refcoco]: loss 2.082 score 79.371 
08/25/2020 07:37:46 - INFO - volta.utils -   [refcoco]: iter 5213 Ep: 11.04 loss 1.715 score 0.903 lr 9.98705e-06 
08/25/2020 07:37:58 - INFO - volta.utils -   [refcoco]: iter 5233 Ep: 11.09 loss 1.717 score 0.904 lr 9.92585e-06 
08/25/2020 07:38:10 - INFO - volta.utils -   [refcoco]: iter 5253 Ep: 11.13 loss 1.716 score 0.903 lr 9.87877e-06 
08/25/2020 07:38:23 - INFO - volta.utils -   [refcoco]: iter 5273 Ep: 11.17 loss 1.695 score 0.912 lr 9.83169e-06 
08/25/2020 07:38:35 - INFO - volta.utils -   [refcoco]: iter 5293 Ep: 11.21 loss 1.706 score 0.907 lr 9.7846e-06 
08/25/2020 07:38:47 - INFO - volta.utils -   [refcoco]: iter 5313 Ep: 11.26 loss 1.712 score 0.905 lr 9.73752e-06 
08/25/2020 07:38:59 - INFO - volta.utils -   [refcoco]: iter 5333 Ep: 11.30 loss 1.728 score 0.906 lr 9.69044e-06 
08/25/2020 07:39:13 - INFO - volta.utils -   [refcoco]: iter 5353 Ep: 11.34 loss 1.715 score 0.904 lr 9.64336e-06 
08/25/2020 07:39:25 - INFO - volta.utils -   [refcoco]: iter 5373 Ep: 11.38 loss 1.701 score 0.904 lr 9.59628e-06 
08/25/2020 07:39:37 - INFO - volta.utils -   [refcoco]: iter 5393 Ep: 11.43 loss 1.711 score 0.906 lr 9.5492e-06 
08/25/2020 07:39:49 - INFO - volta.utils -   [refcoco]: iter 5413 Ep: 11.47 loss 1.706 score 0.910 lr 9.50212e-06 
08/25/2020 07:40:02 - INFO - volta.utils -   [refcoco]: iter 5433 Ep: 11.51 loss 1.727 score 0.912 lr 9.45504e-06 
08/25/2020 07:40:14 - INFO - volta.utils -   [refcoco]: iter 5453 Ep: 11.55 loss 1.701 score 0.905 lr 9.40796e-06 
08/25/2020 07:40:26 - INFO - volta.utils -   [refcoco]: iter 5473 Ep: 11.60 loss 1.710 score 0.905 lr 9.36088e-06 
08/25/2020 07:40:38 - INFO - volta.utils -   [refcoco]: iter 5493 Ep: 11.64 loss 1.714 score 0.903 lr 9.31379e-06 
08/25/2020 07:40:50 - INFO - volta.utils -   [refcoco]: iter 5513 Ep: 11.68 loss 1.690 score 0.913 lr 9.26671e-06 
08/25/2020 07:41:03 - INFO - volta.utils -   [refcoco]: iter 5533 Ep: 11.72 loss 1.724 score 0.910 lr 9.21963e-06 
08/25/2020 07:41:15 - INFO - volta.utils -   [refcoco]: iter 5553 Ep: 11.76 loss 1.699 score 0.901 lr 9.17255e-06 
08/25/2020 07:41:27 - INFO - volta.utils -   [refcoco]: iter 5573 Ep: 11.81 loss 1.693 score 0.899 lr 9.12547e-06 
08/25/2020 07:41:39 - INFO - volta.utils -   [refcoco]: iter 5593 Ep: 11.85 loss 1.727 score 0.900 lr 9.07839e-06 
08/25/2020 07:41:52 - INFO - volta.utils -   [refcoco]: iter 5613 Ep: 11.89 loss 1.697 score 0.907 lr 9.03131e-06 
08/25/2020 07:42:04 - INFO - volta.utils -   [refcoco]: iter 5633 Ep: 11.93 loss 1.711 score 0.906 lr 8.98423e-06 
08/25/2020 07:42:15 - INFO - volta.utils -   [refcoco]: iter 5653 Ep: 11.98 loss 1.703 score 0.906 lr 8.93715e-06 
08/25/2020 07:42:21 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  60%|██████    | 12/20 [1:01:11<40:49, 306.19s/it]08/25/2020 07:42:41 - INFO - volta.utils -   Eval task TASK9 on iteration 5665 
08/25/2020 07:42:41 - INFO - volta.utils -   Validation [refcoco]: loss 2.098 score 79.454 
08/25/2020 07:42:53 - INFO - volta.utils -   [refcoco]: iter 5685 Ep: 12.04 loss 1.702 score 0.905 lr 8.87594e-06 
08/25/2020 07:43:04 - INFO - volta.utils -   [refcoco]: iter 5705 Ep: 12.09 loss 1.697 score 0.910 lr 8.81474e-06 
08/25/2020 07:43:16 - INFO - volta.utils -   [refcoco]: iter 5725 Ep: 12.13 loss 1.710 score 0.906 lr 8.76766e-06 
08/25/2020 07:43:28 - INFO - volta.utils -   [refcoco]: iter 5745 Ep: 12.17 loss 1.693 score 0.910 lr 8.72057e-06 
08/25/2020 07:43:41 - INFO - volta.utils -   [refcoco]: iter 5765 Ep: 12.21 loss 1.684 score 0.910 lr 8.67349e-06 
08/25/2020 07:43:52 - INFO - volta.utils -   [refcoco]: iter 5785 Ep: 12.26 loss 1.678 score 0.903 lr 8.62641e-06 
08/25/2020 07:44:04 - INFO - volta.utils -   [refcoco]: iter 5805 Ep: 12.30 loss 1.714 score 0.908 lr 8.57933e-06 
08/25/2020 07:44:16 - INFO - volta.utils -   [refcoco]: iter 5825 Ep: 12.34 loss 1.700 score 0.908 lr 8.53225e-06 
08/25/2020 07:44:28 - INFO - volta.utils -   [refcoco]: iter 5845 Ep: 12.38 loss 1.704 score 0.908 lr 8.48517e-06 
08/25/2020 07:44:40 - INFO - volta.utils -   [refcoco]: iter 5865 Ep: 12.43 loss 1.720 score 0.909 lr 8.43809e-06 
08/25/2020 07:44:52 - INFO - volta.utils -   [refcoco]: iter 5885 Ep: 12.47 loss 1.688 score 0.911 lr 8.39101e-06 
08/25/2020 07:45:04 - INFO - volta.utils -   [refcoco]: iter 5905 Ep: 12.51 loss 1.700 score 0.905 lr 8.34393e-06 
08/25/2020 07:45:15 - INFO - volta.utils -   [refcoco]: iter 5925 Ep: 12.55 loss 1.711 score 0.900 lr 8.29685e-06 
08/25/2020 07:45:28 - INFO - volta.utils -   [refcoco]: iter 5945 Ep: 12.60 loss 1.697 score 0.908 lr 8.24976e-06 
08/25/2020 07:45:40 - INFO - volta.utils -   [refcoco]: iter 5965 Ep: 12.64 loss 1.710 score 0.910 lr 8.20268e-06 
08/25/2020 07:45:52 - INFO - volta.utils -   [refcoco]: iter 5985 Ep: 12.68 loss 1.712 score 0.897 lr 8.1556e-06 
08/25/2020 07:46:03 - INFO - volta.utils -   [refcoco]: iter 6005 Ep: 12.72 loss 1.706 score 0.914 lr 8.10852e-06 
08/25/2020 07:46:15 - INFO - volta.utils -   [refcoco]: iter 6025 Ep: 12.76 loss 1.700 score 0.905 lr 8.06144e-06 
08/25/2020 07:46:28 - INFO - volta.utils -   [refcoco]: iter 6045 Ep: 12.81 loss 1.693 score 0.912 lr 8.01436e-06 
08/25/2020 07:46:40 - INFO - volta.utils -   [refcoco]: iter 6065 Ep: 12.85 loss 1.679 score 0.911 lr 7.96728e-06 
08/25/2020 07:46:52 - INFO - volta.utils -   [refcoco]: iter 6085 Ep: 12.89 loss 1.704 score 0.906 lr 7.9202e-06 
08/25/2020 07:47:04 - INFO - volta.utils -   [refcoco]: iter 6105 Ep: 12.93 loss 1.693 score 0.907 lr 7.87312e-06 
08/25/2020 07:47:15 - INFO - volta.utils -   [refcoco]: iter 6125 Ep: 12.98 loss 1.711 score 0.907 lr 7.82604e-06 
08/25/2020 07:47:22 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  65%|██████▌   | 13/20 [1:06:13<35:35, 305.05s/it]08/25/2020 07:47:47 - INFO - volta.utils -   Eval task TASK9 on iteration 6137 
08/25/2020 07:47:47 - INFO - volta.utils -   Validation [refcoco]: loss 2.105 score 79.352 
08/25/2020 07:47:59 - INFO - volta.utils -   [refcoco]: iter 6157 Ep: 13.04 loss 1.698 score 0.906 lr 7.76483e-06 
08/25/2020 07:48:11 - INFO - volta.utils -   [refcoco]: iter 6177 Ep: 13.09 loss 1.696 score 0.906 lr 7.70363e-06 
08/25/2020 07:48:24 - INFO - volta.utils -   [refcoco]: iter 6197 Ep: 13.13 loss 1.690 score 0.913 lr 7.65654e-06 
08/25/2020 07:48:36 - INFO - volta.utils -   [refcoco]: iter 6217 Ep: 13.17 loss 1.687 score 0.915 lr 7.60946e-06 
08/25/2020 07:48:48 - INFO - volta.utils -   [refcoco]: iter 6237 Ep: 13.21 loss 1.708 score 0.905 lr 7.56238e-06 
08/25/2020 07:49:00 - INFO - volta.utils -   [refcoco]: iter 6257 Ep: 13.26 loss 1.673 score 0.913 lr 7.5153e-06 
08/25/2020 07:49:12 - INFO - volta.utils -   [refcoco]: iter 6277 Ep: 13.30 loss 1.696 score 0.913 lr 7.46822e-06 
08/25/2020 07:49:23 - INFO - volta.utils -   [refcoco]: iter 6297 Ep: 13.34 loss 1.687 score 0.909 lr 7.42114e-06 
08/25/2020 07:49:37 - INFO - volta.utils -   [refcoco]: iter 6317 Ep: 13.38 loss 1.681 score 0.908 lr 7.37406e-06 
08/25/2020 07:49:48 - INFO - volta.utils -   [refcoco]: iter 6337 Ep: 13.43 loss 1.695 score 0.906 lr 7.32698e-06 
08/25/2020 07:50:00 - INFO - volta.utils -   [refcoco]: iter 6357 Ep: 13.47 loss 1.688 score 0.908 lr 7.2799e-06 
08/25/2020 07:50:12 - INFO - volta.utils -   [refcoco]: iter 6377 Ep: 13.51 loss 1.696 score 0.910 lr 7.23282e-06 
08/25/2020 07:50:24 - INFO - volta.utils -   [refcoco]: iter 6397 Ep: 13.55 loss 1.707 score 0.912 lr 7.18573e-06 
08/25/2020 07:50:36 - INFO - volta.utils -   [refcoco]: iter 6417 Ep: 13.60 loss 1.697 score 0.911 lr 7.13865e-06 
08/25/2020 07:50:48 - INFO - volta.utils -   [refcoco]: iter 6437 Ep: 13.64 loss 1.689 score 0.910 lr 7.09157e-06 
08/25/2020 07:51:00 - INFO - volta.utils -   [refcoco]: iter 6457 Ep: 13.68 loss 1.683 score 0.912 lr 7.04449e-06 
08/25/2020 07:51:11 - INFO - volta.utils -   [refcoco]: iter 6477 Ep: 13.72 loss 1.703 score 0.905 lr 6.99741e-06 
08/25/2020 07:51:23 - INFO - volta.utils -   [refcoco]: iter 6497 Ep: 13.76 loss 1.690 score 0.908 lr 6.95033e-06 
08/25/2020 07:51:36 - INFO - volta.utils -   [refcoco]: iter 6517 Ep: 13.81 loss 1.683 score 0.913 lr 6.90325e-06 
08/25/2020 07:51:48 - INFO - volta.utils -   [refcoco]: iter 6537 Ep: 13.85 loss 1.691 score 0.917 lr 6.85617e-06 
08/25/2020 07:52:01 - INFO - volta.utils -   [refcoco]: iter 6557 Ep: 13.89 loss 1.678 score 0.909 lr 6.80909e-06 
08/25/2020 07:52:13 - INFO - volta.utils -   [refcoco]: iter 6577 Ep: 13.93 loss 1.707 score 0.905 lr 6.76201e-06 
08/25/2020 07:52:24 - INFO - volta.utils -   [refcoco]: iter 6597 Ep: 13.98 loss 1.688 score 0.901 lr 6.71492e-06 
08/25/2020 07:52:31 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  70%|███████   | 14/20 [1:11:21<30:34, 305.74s/it]08/25/2020 07:52:50 - INFO - volta.utils -   Eval task TASK9 on iteration 6609 
08/25/2020 07:52:50 - INFO - volta.utils -   Validation [refcoco]: loss 2.116 score 79.223 
08/25/2020 07:53:02 - INFO - volta.utils -   [refcoco]: iter 6629 Ep: 14.04 loss 1.701 score 0.906 lr 6.65372e-06 
08/25/2020 07:53:14 - INFO - volta.utils -   [refcoco]: iter 6649 Ep: 14.09 loss 1.689 score 0.909 lr 6.59251e-06 
08/25/2020 07:53:26 - INFO - volta.utils -   [refcoco]: iter 6669 Ep: 14.13 loss 1.700 score 0.909 lr 6.54543e-06 
08/25/2020 07:53:39 - INFO - volta.utils -   [refcoco]: iter 6689 Ep: 14.17 loss 1.699 score 0.913 lr 6.49835e-06 
08/25/2020 07:53:51 - INFO - volta.utils -   [refcoco]: iter 6709 Ep: 14.21 loss 1.697 score 0.911 lr 6.45127e-06 
08/25/2020 07:54:03 - INFO - volta.utils -   [refcoco]: iter 6729 Ep: 14.26 loss 1.683 score 0.915 lr 6.40419e-06 
08/25/2020 07:54:15 - INFO - volta.utils -   [refcoco]: iter 6749 Ep: 14.30 loss 1.686 score 0.909 lr 6.35711e-06 
08/25/2020 07:54:28 - INFO - volta.utils -   [refcoco]: iter 6769 Ep: 14.34 loss 1.678 score 0.905 lr 6.31003e-06 
08/25/2020 07:54:40 - INFO - volta.utils -   [refcoco]: iter 6789 Ep: 14.38 loss 1.698 score 0.910 lr 6.26295e-06 
08/25/2020 07:54:53 - INFO - volta.utils -   [refcoco]: iter 6809 Ep: 14.43 loss 1.677 score 0.910 lr 6.21587e-06 
08/25/2020 07:55:05 - INFO - volta.utils -   [refcoco]: iter 6829 Ep: 14.47 loss 1.675 score 0.918 lr 6.16879e-06 
08/25/2020 07:55:16 - INFO - volta.utils -   [refcoco]: iter 6849 Ep: 14.51 loss 1.686 score 0.905 lr 6.1217e-06 
08/25/2020 07:55:28 - INFO - volta.utils -   [refcoco]: iter 6869 Ep: 14.55 loss 1.700 score 0.910 lr 6.07462e-06 
08/25/2020 07:55:40 - INFO - volta.utils -   [refcoco]: iter 6889 Ep: 14.60 loss 1.683 score 0.912 lr 6.02754e-06 
08/25/2020 07:55:53 - INFO - volta.utils -   [refcoco]: iter 6909 Ep: 14.64 loss 1.686 score 0.911 lr 5.98046e-06 
08/25/2020 07:56:05 - INFO - volta.utils -   [refcoco]: iter 6929 Ep: 14.68 loss 1.685 score 0.917 lr 5.93338e-06 
08/25/2020 07:56:17 - INFO - volta.utils -   [refcoco]: iter 6949 Ep: 14.72 loss 1.698 score 0.910 lr 5.8863e-06 
08/25/2020 07:56:29 - INFO - volta.utils -   [refcoco]: iter 6969 Ep: 14.76 loss 1.680 score 0.907 lr 5.83922e-06 
08/25/2020 07:56:40 - INFO - volta.utils -   [refcoco]: iter 6989 Ep: 14.81 loss 1.682 score 0.907 lr 5.79214e-06 
08/25/2020 07:56:53 - INFO - volta.utils -   [refcoco]: iter 7009 Ep: 14.85 loss 1.680 score 0.908 lr 5.74506e-06 
08/25/2020 07:57:05 - INFO - volta.utils -   [refcoco]: iter 7029 Ep: 14.89 loss 1.666 score 0.911 lr 5.69798e-06 
08/25/2020 07:57:17 - INFO - volta.utils -   [refcoco]: iter 7049 Ep: 14.93 loss 1.681 score 0.915 lr 5.65089e-06 
08/25/2020 07:57:29 - INFO - volta.utils -   [refcoco]: iter 7069 Ep: 14.98 loss 1.685 score 0.910 lr 5.60381e-06 
08/25/2020 07:57:35 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  75%|███████▌  | 15/20 [1:16:26<25:28, 305.73s/it]08/25/2020 07:58:02 - INFO - volta.utils -   Eval task TASK9 on iteration 7081 
08/25/2020 07:58:02 - INFO - volta.utils -   Validation [refcoco]: loss 2.101 score 79.426 
08/25/2020 07:58:14 - INFO - volta.utils -   [refcoco]: iter 7101 Ep: 15.04 loss 1.689 score 0.908 lr 5.54261e-06 
08/25/2020 07:58:26 - INFO - volta.utils -   [refcoco]: iter 7121 Ep: 15.09 loss 1.683 score 0.914 lr 5.4814e-06 
08/25/2020 07:58:37 - INFO - volta.utils -   [refcoco]: iter 7141 Ep: 15.13 loss 1.673 score 0.912 lr 5.43432e-06 
08/25/2020 07:58:49 - INFO - volta.utils -   [refcoco]: iter 7161 Ep: 15.17 loss 1.684 score 0.910 lr 5.38724e-06 
08/25/2020 07:59:01 - INFO - volta.utils -   [refcoco]: iter 7181 Ep: 15.21 loss 1.688 score 0.913 lr 5.34016e-06 
08/25/2020 07:59:13 - INFO - volta.utils -   [refcoco]: iter 7201 Ep: 15.26 loss 1.680 score 0.911 lr 5.29308e-06 
08/25/2020 07:59:25 - INFO - volta.utils -   [refcoco]: iter 7221 Ep: 15.30 loss 1.683 score 0.906 lr 5.246e-06 
08/25/2020 07:59:36 - INFO - volta.utils -   [refcoco]: iter 7241 Ep: 15.34 loss 1.674 score 0.915 lr 5.19892e-06 
08/25/2020 07:59:48 - INFO - volta.utils -   [refcoco]: iter 7261 Ep: 15.38 loss 1.678 score 0.910 lr 5.15184e-06 
08/25/2020 07:59:59 - INFO - volta.utils -   [refcoco]: iter 7281 Ep: 15.43 loss 1.682 score 0.908 lr 5.10476e-06 
08/25/2020 08:00:12 - INFO - volta.utils -   [refcoco]: iter 7301 Ep: 15.47 loss 1.681 score 0.913 lr 5.05767e-06 
08/25/2020 08:00:23 - INFO - volta.utils -   [refcoco]: iter 7321 Ep: 15.51 loss 1.687 score 0.914 lr 5.01059e-06 
08/25/2020 08:00:35 - INFO - volta.utils -   [refcoco]: iter 7341 Ep: 15.55 loss 1.678 score 0.906 lr 4.96351e-06 
08/25/2020 08:00:46 - INFO - volta.utils -   [refcoco]: iter 7361 Ep: 15.60 loss 1.691 score 0.909 lr 4.91643e-06 
08/25/2020 08:00:58 - INFO - volta.utils -   [refcoco]: iter 7381 Ep: 15.64 loss 1.684 score 0.912 lr 4.86935e-06 
08/25/2020 08:01:11 - INFO - volta.utils -   [refcoco]: iter 7401 Ep: 15.68 loss 1.676 score 0.916 lr 4.82227e-06 
08/25/2020 08:01:22 - INFO - volta.utils -   [refcoco]: iter 7421 Ep: 15.72 loss 1.689 score 0.911 lr 4.77519e-06 
08/25/2020 08:01:33 - INFO - volta.utils -   [refcoco]: iter 7441 Ep: 15.76 loss 1.686 score 0.907 lr 4.72811e-06 
08/25/2020 08:01:45 - INFO - volta.utils -   [refcoco]: iter 7461 Ep: 15.81 loss 1.690 score 0.913 lr 4.68103e-06 
08/25/2020 08:01:56 - INFO - volta.utils -   [refcoco]: iter 7481 Ep: 15.85 loss 1.682 score 0.912 lr 4.63395e-06 
08/25/2020 08:02:09 - INFO - volta.utils -   [refcoco]: iter 7501 Ep: 15.89 loss 1.648 score 0.916 lr 4.58686e-06 
08/25/2020 08:02:20 - INFO - volta.utils -   [refcoco]: iter 7521 Ep: 15.93 loss 1.680 score 0.914 lr 4.53978e-06 
08/25/2020 08:02:32 - INFO - volta.utils -   [refcoco]: iter 7541 Ep: 15.98 loss 1.690 score 0.911 lr 4.4927e-06 
08/25/2020 08:02:38 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  80%|████████  | 16/20 [1:21:29<20:19, 304.76s/it]08/25/2020 08:02:57 - INFO - volta.utils -   Eval task TASK9 on iteration 7553 
08/25/2020 08:02:57 - INFO - volta.utils -   Validation [refcoco]: loss 2.117 score 79.490 
08/25/2020 08:03:10 - INFO - volta.utils -   [refcoco]: iter 7573 Ep: 16.04 loss 1.664 score 0.914 lr 4.4315e-06 
08/25/2020 08:03:22 - INFO - volta.utils -   [refcoco]: iter 7593 Ep: 16.09 loss 1.668 score 0.916 lr 4.37029e-06 
08/25/2020 08:03:33 - INFO - volta.utils -   [refcoco]: iter 7613 Ep: 16.13 loss 1.703 score 0.907 lr 4.32321e-06 
08/25/2020 08:03:45 - INFO - volta.utils -   [refcoco]: iter 7633 Ep: 16.17 loss 1.693 score 0.917 lr 4.27613e-06 
08/25/2020 08:03:56 - INFO - volta.utils -   [refcoco]: iter 7653 Ep: 16.21 loss 1.672 score 0.912 lr 4.22905e-06 
08/25/2020 08:04:09 - INFO - volta.utils -   [refcoco]: iter 7673 Ep: 16.26 loss 1.695 score 0.915 lr 4.18197e-06 
08/25/2020 08:04:21 - INFO - volta.utils -   [refcoco]: iter 7693 Ep: 16.30 loss 1.686 score 0.908 lr 4.13489e-06 
08/25/2020 08:04:32 - INFO - volta.utils -   [refcoco]: iter 7713 Ep: 16.34 loss 1.679 score 0.918 lr 4.08781e-06 
08/25/2020 08:04:44 - INFO - volta.utils -   [refcoco]: iter 7733 Ep: 16.38 loss 1.681 score 0.906 lr 4.04073e-06 
08/25/2020 08:04:55 - INFO - volta.utils -   [refcoco]: iter 7753 Ep: 16.43 loss 1.695 score 0.912 lr 3.99364e-06 
08/25/2020 08:05:07 - INFO - volta.utils -   [refcoco]: iter 7773 Ep: 16.47 loss 1.671 score 0.908 lr 3.94656e-06 
08/25/2020 08:05:19 - INFO - volta.utils -   [refcoco]: iter 7793 Ep: 16.51 loss 1.661 score 0.908 lr 3.89948e-06 
08/25/2020 08:05:31 - INFO - volta.utils -   [refcoco]: iter 7813 Ep: 16.55 loss 1.668 score 0.915 lr 3.8524e-06 
08/25/2020 08:05:43 - INFO - volta.utils -   [refcoco]: iter 7833 Ep: 16.60 loss 1.677 score 0.907 lr 3.80532e-06 
08/25/2020 08:05:55 - INFO - volta.utils -   [refcoco]: iter 7853 Ep: 16.64 loss 1.676 score 0.911 lr 3.75824e-06 
08/25/2020 08:06:07 - INFO - volta.utils -   [refcoco]: iter 7873 Ep: 16.68 loss 1.666 score 0.910 lr 3.71116e-06 
08/25/2020 08:06:20 - INFO - volta.utils -   [refcoco]: iter 7893 Ep: 16.72 loss 1.669 score 0.916 lr 3.66408e-06 
08/25/2020 08:06:32 - INFO - volta.utils -   [refcoco]: iter 7913 Ep: 16.76 loss 1.701 score 0.915 lr 3.617e-06 
08/25/2020 08:06:43 - INFO - volta.utils -   [refcoco]: iter 7933 Ep: 16.81 loss 1.669 score 0.912 lr 3.56992e-06 
08/25/2020 08:06:55 - INFO - volta.utils -   [refcoco]: iter 7953 Ep: 16.85 loss 1.681 score 0.915 lr 3.52283e-06 
08/25/2020 08:07:06 - INFO - volta.utils -   [refcoco]: iter 7973 Ep: 16.89 loss 1.671 score 0.906 lr 3.47575e-06 
08/25/2020 08:07:19 - INFO - volta.utils -   [refcoco]: iter 7993 Ep: 16.93 loss 1.663 score 0.912 lr 3.42867e-06 
08/25/2020 08:07:31 - INFO - volta.utils -   [refcoco]: iter 8013 Ep: 16.98 loss 1.675 score 0.909 lr 3.38159e-06 
08/25/2020 08:07:37 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  85%|████████▌ | 17/20 [1:26:27<15:08, 302.76s/it]