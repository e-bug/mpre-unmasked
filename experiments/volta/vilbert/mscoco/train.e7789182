/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
08/28/2020 04:42:12 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
08/28/2020 04:42:13 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
08/28/2020 04:42:14 - INFO - volta.task_utils -   Loading RetrievalCOCO Dataset with batch size 64
08/28/2020 04:44:06 - INFO - volta.utils -   logging file at: ../../logs/volta/mscoco/RetrievalCOCO_vilbert_base
08/28/2020 04:44:06 - INFO - volta.utils -   loading weights file /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/volta/vilbert/vilbert_base/pytorch_model_9.bin
08/28/2020 04:44:14 - INFO - volta.utils -   
08/28/2020 04:44:14 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK7.weight', 'clfs_dict.TASK7.bias']
08/28/2020 04:44:27 - INFO - __main__ -   >> Trainable Parameters:
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(1024, 2048)    |2097152     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(1024, 5)       |5120        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.weight                           |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.bias                             |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                   |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.predictions.bias                                         |torch.float32    |(30522,)        |30522       |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.predictions.transform.dense.weight                       |torch.float32    |(768, 768)      |589824      |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.predictions.transform.dense.bias                         |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.weight                   |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.bias                     |torch.float32    |(768,)          |768         |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.bi_seq_relationship.weight                               |torch.float32    |(2, 1024)       |2048        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.bi_seq_relationship.bias                                 |torch.float32    |(2,)            |2           |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.bias                    |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.weight                   |torch.float32    |(1601, 1024)    |1639424     |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.bias                     |torch.float32    |(1601,)         |1601        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.clfs_dict.TASK7.weight                                       |torch.float32    |(1, 1024)       |1024        |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   |module.clfs_dict.TASK7.bias                                         |torch.float32    |(1,)            |1           |
08/28/2020 04:44:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/28/2020 04:44:27 - INFO - __main__ -   >> # TrainableParams:       	239.02	M
08/28/2020 04:44:27 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
08/28/2020 04:44:27 - INFO - __main__ -   >> # TotalParams:           	239.02	M

Epoch:   0%|          | 0/6 [00:00<?, ?it/s]08/28/2020 04:51:17 - INFO - volta.utils -   Eval task TASK7 on iteration 123985 
08/28/2020 04:51:17 - INFO - volta.utils -   Validation [RetrievalCOCO]: loss 0.020 score 99.376 
08/28/2020 04:52:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 124005 Ep: 14.00 loss 0.081 score 0.966 lr 6.66623e-06 
08/28/2020 04:52:25 - INFO - volta.utils -   [RetrievalCOCO]: iter 124025 Ep: 14.00 loss 0.064 score 0.973 lr 6.66271e-06 
08/28/2020 04:52:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 124045 Ep: 14.01 loss 0.066 score 0.967 lr 6.66021e-06 
08/28/2020 04:53:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 124065 Ep: 14.01 loss 0.071 score 0.969 lr 6.6577e-06 
08/28/2020 04:53:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 124085 Ep: 14.01 loss 0.057 score 0.977 lr 6.65519e-06 
08/28/2020 04:54:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 124105 Ep: 14.01 loss 0.055 score 0.977 lr 6.65268e-06 
08/28/2020 04:54:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 124125 Ep: 14.02 loss 0.051 score 0.979 lr 6.65017e-06 
08/28/2020 04:54:58 - INFO - volta.utils -   [RetrievalCOCO]: iter 124145 Ep: 14.02 loss 0.052 score 0.979 lr 6.64766e-06 
08/28/2020 04:55:23 - INFO - volta.utils -   [RetrievalCOCO]: iter 124165 Ep: 14.02 loss 0.052 score 0.981 lr 6.64515e-06 
08/28/2020 04:55:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 124185 Ep: 14.02 loss 0.045 score 0.982 lr 6.64264e-06 
08/28/2020 04:55:58 - INFO - volta.utils -   [RetrievalCOCO]: iter 124205 Ep: 14.02 loss 0.056 score 0.977 lr 6.64013e-06 
08/28/2020 04:56:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 124225 Ep: 14.03 loss 0.057 score 0.977 lr 6.63762e-06 
08/28/2020 04:56:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 124245 Ep: 14.03 loss 0.039 score 0.984 lr 6.63511e-06 
08/28/2020 04:56:43 - INFO - volta.utils -   [RetrievalCOCO]: iter 124265 Ep: 14.03 loss 0.060 score 0.973 lr 6.6326e-06 
08/28/2020 04:56:57 - INFO - volta.utils -   [RetrievalCOCO]: iter 124285 Ep: 14.03 loss 0.053 score 0.980 lr 6.63009e-06 
08/28/2020 04:57:11 - INFO - volta.utils -   [RetrievalCOCO]: iter 124305 Ep: 14.04 loss 0.059 score 0.978 lr 6.62758e-06 
08/28/2020 04:57:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 124325 Ep: 14.04 loss 0.054 score 0.976 lr 6.62508e-06 
08/28/2020 04:57:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 124345 Ep: 14.04 loss 0.053 score 0.974 lr 6.62257e-06 
08/28/2020 04:58:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 124365 Ep: 14.04 loss 0.050 score 0.980 lr 6.62006e-06 
08/28/2020 04:58:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 124385 Ep: 14.05 loss 0.047 score 0.980 lr 6.61755e-06 
08/28/2020 04:58:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 124405 Ep: 14.05 loss 0.046 score 0.986 lr 6.61504e-06 
08/28/2020 04:58:50 - INFO - volta.utils -   [RetrievalCOCO]: iter 124425 Ep: 14.05 loss 0.059 score 0.980 lr 6.61253e-06 
08/28/2020 04:59:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 124445 Ep: 14.05 loss 0.048 score 0.977 lr 6.61002e-06 
08/28/2020 04:59:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 124465 Ep: 14.05 loss 0.075 score 0.965 lr 6.60751e-06 
08/28/2020 04:59:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 124485 Ep: 14.06 loss 0.047 score 0.978 lr 6.605e-06 
08/28/2020 04:59:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 124505 Ep: 14.06 loss 0.040 score 0.988 lr 6.60249e-06 
08/28/2020 05:00:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 124525 Ep: 14.06 loss 0.046 score 0.980 lr 6.59998e-06 
08/28/2020 05:00:19 - INFO - volta.utils -   [RetrievalCOCO]: iter 124545 Ep: 14.06 loss 0.047 score 0.984 lr 6.59747e-06 
08/28/2020 05:00:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 124565 Ep: 14.07 loss 0.047 score 0.979 lr 6.59496e-06 
08/28/2020 05:00:47 - INFO - volta.utils -   [RetrievalCOCO]: iter 124585 Ep: 14.07 loss 0.053 score 0.977 lr 6.59245e-06 
08/28/2020 05:01:01 - INFO - volta.utils -   [RetrievalCOCO]: iter 124605 Ep: 14.07 loss 0.053 score 0.976 lr 6.58995e-06 
08/28/2020 05:01:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 124625 Ep: 14.07 loss 0.048 score 0.980 lr 6.58744e-06 
08/28/2020 05:01:29 - INFO - volta.utils -   [RetrievalCOCO]: iter 124645 Ep: 14.07 loss 0.045 score 0.981 lr 6.58493e-06 
08/28/2020 05:01:45 - INFO - volta.utils -   [RetrievalCOCO]: iter 124665 Ep: 14.08 loss 0.044 score 0.985 lr 6.58242e-06 
08/28/2020 05:01:59 - INFO - volta.utils -   [RetrievalCOCO]: iter 124685 Ep: 14.08 loss 0.045 score 0.980 lr 6.57991e-06 
08/28/2020 05:02:13 - INFO - volta.utils -   [RetrievalCOCO]: iter 124705 Ep: 14.08 loss 0.063 score 0.975 lr 6.5774e-06 
08/28/2020 05:02:27 - INFO - volta.utils -   [RetrievalCOCO]: iter 124725 Ep: 14.08 loss 0.052 score 0.979 lr 6.57489e-06 
08/28/2020 05:02:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 124745 Ep: 14.09 loss 0.056 score 0.977 lr 6.57238e-06 
08/28/2020 05:02:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 124765 Ep: 14.09 loss 0.051 score 0.975 lr 6.56987e-06 
08/28/2020 05:03:12 - INFO - volta.utils -   [RetrievalCOCO]: iter 124785 Ep: 14.09 loss 0.050 score 0.981 lr 6.56736e-06 
08/28/2020 05:03:26 - INFO - volta.utils -   [RetrievalCOCO]: iter 124805 Ep: 14.09 loss 0.060 score 0.976 lr 6.56485e-06 
08/28/2020 05:03:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 124825 Ep: 14.09 loss 0.071 score 0.973 lr 6.56234e-06 
08/28/2020 05:03:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 124845 Ep: 14.10 loss 0.043 score 0.984 lr 6.55983e-06 
08/28/2020 05:04:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 124865 Ep: 14.10 loss 0.055 score 0.977 lr 6.55732e-06 
08/28/2020 05:04:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 124885 Ep: 14.10 loss 0.052 score 0.975 lr 6.55482e-06 
08/28/2020 05:04:39 - INFO - volta.utils -   [RetrievalCOCO]: iter 124905 Ep: 14.10 loss 0.050 score 0.981 lr 6.55231e-06 
08/28/2020 05:04:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 124925 Ep: 14.11 loss 0.045 score 0.980 lr 6.5498e-06 
08/28/2020 05:05:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 124945 Ep: 14.11 loss 0.058 score 0.977 lr 6.54729e-06 
08/28/2020 05:05:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 124965 Ep: 14.11 loss 0.048 score 0.982 lr 6.54478e-06 
08/28/2020 05:05:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 124985 Ep: 14.11 loss 0.053 score 0.980 lr 6.54227e-06 
08/28/2020 05:05:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 125005 Ep: 14.12 loss 0.048 score 0.980 lr 6.53976e-06 
08/28/2020 05:06:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 125025 Ep: 14.12 loss 0.047 score 0.978 lr 6.53725e-06 
08/28/2020 05:06:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 125045 Ep: 14.12 loss 0.050 score 0.978 lr 6.53474e-06 
08/28/2020 05:06:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 125065 Ep: 14.12 loss 0.056 score 0.978 lr 6.53223e-06 
08/28/2020 05:06:50 - INFO - volta.utils -   [RetrievalCOCO]: iter 125085 Ep: 14.12 loss 0.062 score 0.979 lr 6.52972e-06 
08/28/2020 05:07:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 125105 Ep: 14.13 loss 0.042 score 0.982 lr 6.52721e-06 
08/28/2020 05:07:20 - INFO - volta.utils -   [RetrievalCOCO]: iter 125125 Ep: 14.13 loss 0.045 score 0.980 lr 6.5247e-06 
08/28/2020 05:07:39 - INFO - volta.utils -   [RetrievalCOCO]: iter 125145 Ep: 14.13 loss 0.063 score 0.971 lr 6.52219e-06 
08/28/2020 05:07:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 125165 Ep: 14.13 loss 0.044 score 0.980 lr 6.51969e-06 
08/28/2020 05:08:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 125185 Ep: 14.14 loss 0.044 score 0.984 lr 6.51718e-06 
08/28/2020 05:08:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 125205 Ep: 14.14 loss 0.040 score 0.985 lr 6.51467e-06 
08/28/2020 05:08:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 125225 Ep: 14.14 loss 0.038 score 0.987 lr 6.51216e-06 
08/28/2020 05:08:57 - INFO - volta.utils -   [RetrievalCOCO]: iter 125245 Ep: 14.14 loss 0.053 score 0.977 lr 6.50965e-06 
08/28/2020 05:09:11 - INFO - volta.utils -   [RetrievalCOCO]: iter 125265 Ep: 14.14 loss 0.051 score 0.980 lr 6.50714e-06 
08/28/2020 05:09:30 - INFO - volta.utils -   [RetrievalCOCO]: iter 125285 Ep: 14.15 loss 0.054 score 0.979 lr 6.50463e-06 
08/28/2020 05:09:44 - INFO - volta.utils -   [RetrievalCOCO]: iter 125305 Ep: 14.15 loss 0.058 score 0.975 lr 6.50212e-06 
08/28/2020 05:10:02 - INFO - volta.utils -   [RetrievalCOCO]: iter 125325 Ep: 14.15 loss 0.051 score 0.979 lr 6.49961e-06 
08/28/2020 05:10:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 125345 Ep: 14.15 loss 0.059 score 0.980 lr 6.4971e-06 
08/28/2020 05:10:39 - INFO - volta.utils -   [RetrievalCOCO]: iter 125365 Ep: 14.16 loss 0.054 score 0.977 lr 6.49459e-06 
08/28/2020 05:10:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 125385 Ep: 14.16 loss 0.041 score 0.984 lr 6.49208e-06 
08/28/2020 05:11:13 - INFO - volta.utils -   [RetrievalCOCO]: iter 125405 Ep: 14.16 loss 0.063 score 0.967 lr 6.48957e-06 
08/28/2020 05:11:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 125425 Ep: 14.16 loss 0.049 score 0.979 lr 6.48706e-06 
08/28/2020 05:11:46 - INFO - volta.utils -   [RetrievalCOCO]: iter 125445 Ep: 14.16 loss 0.049 score 0.982 lr 6.48456e-06 
08/28/2020 05:12:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 125465 Ep: 14.17 loss 0.056 score 0.977 lr 6.48205e-06 
08/28/2020 05:12:18 - INFO - volta.utils -   [RetrievalCOCO]: iter 125485 Ep: 14.17 loss 0.054 score 0.975 lr 6.47954e-06 
08/28/2020 05:12:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 125505 Ep: 14.17 loss 0.061 score 0.973 lr 6.47703e-06 
08/28/2020 05:12:46 - INFO - volta.utils -   [RetrievalCOCO]: iter 125525 Ep: 14.17 loss 0.035 score 0.986 lr 6.47452e-06 
08/28/2020 05:13:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 125545 Ep: 14.18 loss 0.045 score 0.984 lr 6.47201e-06 
08/28/2020 05:13:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 125565 Ep: 14.18 loss 0.042 score 0.984 lr 6.4695e-06 
08/28/2020 05:13:30 - INFO - volta.utils -   [RetrievalCOCO]: iter 125585 Ep: 14.18 loss 0.058 score 0.979 lr 6.46699e-06 
08/28/2020 05:13:45 - INFO - volta.utils -   [RetrievalCOCO]: iter 125605 Ep: 14.18 loss 0.040 score 0.984 lr 6.46448e-06 
08/28/2020 05:14:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 125625 Ep: 14.19 loss 0.043 score 0.985 lr 6.46197e-06 
08/28/2020 05:14:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 125645 Ep: 14.19 loss 0.056 score 0.976 lr 6.45946e-06 
08/28/2020 05:14:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 125665 Ep: 14.19 loss 0.043 score 0.982 lr 6.45695e-06 
08/28/2020 05:14:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 125685 Ep: 14.19 loss 0.048 score 0.980 lr 6.45444e-06 
08/28/2020 05:14:58 - INFO - volta.utils -   [RetrievalCOCO]: iter 125705 Ep: 14.19 loss 0.064 score 0.972 lr 6.45193e-06 
08/28/2020 05:15:13 - INFO - volta.utils -   [RetrievalCOCO]: iter 125725 Ep: 14.20 loss 0.049 score 0.979 lr 6.44943e-06 
08/28/2020 05:15:27 - INFO - volta.utils -   [RetrievalCOCO]: iter 125745 Ep: 14.20 loss 0.062 score 0.975 lr 6.44692e-06 
08/28/2020 05:15:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 125765 Ep: 14.20 loss 0.046 score 0.979 lr 6.44441e-06 
08/28/2020 05:15:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 125785 Ep: 14.20 loss 0.041 score 0.980 lr 6.4419e-06 
08/28/2020 05:16:10 - INFO - volta.utils -   [RetrievalCOCO]: iter 125805 Ep: 14.21 loss 0.060 score 0.976 lr 6.43939e-06 
08/28/2020 05:16:26 - INFO - volta.utils -   [RetrievalCOCO]: iter 125825 Ep: 14.21 loss 0.066 score 0.973 lr 6.43688e-06 
08/28/2020 05:16:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 125845 Ep: 14.21 loss 0.048 score 0.980 lr 6.43437e-06 
08/28/2020 05:16:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 125865 Ep: 14.21 loss 0.044 score 0.985 lr 6.43186e-06 
08/28/2020 05:17:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 125885 Ep: 14.21 loss 0.056 score 0.977 lr 6.42935e-06 
08/28/2020 05:17:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 125905 Ep: 14.22 loss 0.062 score 0.973 lr 6.42684e-06 
08/28/2020 05:17:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 125925 Ep: 14.22 loss 0.061 score 0.975 lr 6.42433e-06 
08/28/2020 05:17:52 - INFO - volta.utils -   [RetrievalCOCO]: iter 125945 Ep: 14.22 loss 0.052 score 0.977 lr 6.42182e-06 
08/28/2020 05:18:06 - INFO - volta.utils -   [RetrievalCOCO]: iter 125965 Ep: 14.22 loss 0.054 score 0.971 lr 6.41931e-06 
08/28/2020 05:18:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 125985 Ep: 14.23 loss 0.035 score 0.987 lr 6.4168e-06 
08/28/2020 05:18:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 126005 Ep: 14.23 loss 0.042 score 0.982 lr 6.4143e-06 
08/28/2020 05:18:48 - INFO - volta.utils -   [RetrievalCOCO]: iter 126025 Ep: 14.23 loss 0.054 score 0.980 lr 6.41179e-06 
08/28/2020 05:19:05 - INFO - volta.utils -   [RetrievalCOCO]: iter 126045 Ep: 14.23 loss 0.037 score 0.988 lr 6.40928e-06 
08/28/2020 05:19:19 - INFO - volta.utils -   [RetrievalCOCO]: iter 126065 Ep: 14.23 loss 0.036 score 0.986 lr 6.40677e-06 
08/28/2020 05:19:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 126085 Ep: 14.24 loss 0.050 score 0.982 lr 6.40426e-06 
08/28/2020 05:19:56 - INFO - volta.utils -   [RetrievalCOCO]: iter 126105 Ep: 14.24 loss 0.034 score 0.985 lr 6.40175e-06 
08/28/2020 05:20:10 - INFO - volta.utils -   [RetrievalCOCO]: iter 126125 Ep: 14.24 loss 0.058 score 0.975 lr 6.39924e-06 
08/28/2020 05:20:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 126145 Ep: 14.24 loss 0.056 score 0.974 lr 6.39673e-06 
08/28/2020 05:20:47 - INFO - volta.utils -   [RetrievalCOCO]: iter 126165 Ep: 14.25 loss 0.058 score 0.977 lr 6.39422e-06 
08/28/2020 05:21:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 126185 Ep: 14.25 loss 0.049 score 0.975 lr 6.39171e-06 
08/28/2020 05:21:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 126205 Ep: 14.25 loss 0.070 score 0.970 lr 6.3892e-06 
08/28/2020 05:21:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 126225 Ep: 14.25 loss 0.050 score 0.978 lr 6.38669e-06 
08/28/2020 05:22:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 126245 Ep: 14.26 loss 0.057 score 0.977 lr 6.38418e-06 
08/28/2020 05:22:23 - INFO - volta.utils -   [RetrievalCOCO]: iter 126265 Ep: 14.26 loss 0.074 score 0.970 lr 6.38167e-06 
08/28/2020 05:22:48 - INFO - volta.utils -   [RetrievalCOCO]: iter 126285 Ep: 14.26 loss 0.054 score 0.973 lr 6.37917e-06 
08/28/2020 05:23:09 - INFO - volta.utils -   [RetrievalCOCO]: iter 126305 Ep: 14.26 loss 0.049 score 0.980 lr 6.37666e-06 
08/28/2020 05:23:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 126325 Ep: 14.26 loss 0.033 score 0.988 lr 6.37415e-06 
08/28/2020 05:23:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 126345 Ep: 14.27 loss 0.063 score 0.979 lr 6.37164e-06 
08/28/2020 05:24:10 - INFO - volta.utils -   [RetrievalCOCO]: iter 126365 Ep: 14.27 loss 0.050 score 0.977 lr 6.36913e-06 
08/28/2020 05:24:27 - INFO - volta.utils -   [RetrievalCOCO]: iter 126385 Ep: 14.27 loss 0.053 score 0.977 lr 6.36662e-06 
08/28/2020 05:24:48 - INFO - volta.utils -   [RetrievalCOCO]: iter 126405 Ep: 14.27 loss 0.045 score 0.982 lr 6.36411e-06 
08/28/2020 05:25:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 126425 Ep: 14.28 loss 0.040 score 0.981 lr 6.3616e-06 
08/28/2020 05:25:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 126445 Ep: 14.28 loss 0.041 score 0.982 lr 6.35909e-06 
08/28/2020 05:25:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 126465 Ep: 14.28 loss 0.048 score 0.982 lr 6.35658e-06 
08/28/2020 05:25:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 126485 Ep: 14.28 loss 0.043 score 0.983 lr 6.35407e-06 
08/28/2020 05:26:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 126505 Ep: 14.28 loss 0.060 score 0.972 lr 6.35156e-06 
08/28/2020 05:26:30 - INFO - volta.utils -   [RetrievalCOCO]: iter 126525 Ep: 14.29 loss 0.049 score 0.979 lr 6.34905e-06 
08/28/2020 05:26:45 - INFO - volta.utils -   [RetrievalCOCO]: iter 126545 Ep: 14.29 loss 0.053 score 0.974 lr 6.34654e-06 
08/28/2020 05:27:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 126565 Ep: 14.29 loss 0.056 score 0.976 lr 6.34404e-06 
08/28/2020 05:27:18 - INFO - volta.utils -   [RetrievalCOCO]: iter 126585 Ep: 14.29 loss 0.056 score 0.976 lr 6.34153e-06 
08/28/2020 05:27:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 126605 Ep: 14.30 loss 0.042 score 0.982 lr 6.33902e-06 
08/28/2020 05:27:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 126625 Ep: 14.30 loss 0.053 score 0.973 lr 6.33651e-06 
08/28/2020 05:28:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 126645 Ep: 14.30 loss 0.043 score 0.982 lr 6.334e-06 
08/28/2020 05:28:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 126665 Ep: 14.30 loss 0.040 score 0.981 lr 6.33149e-06 
08/28/2020 05:28:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 126685 Ep: 14.30 loss 0.056 score 0.977 lr 6.32898e-06 
08/28/2020 05:29:02 - INFO - volta.utils -   [RetrievalCOCO]: iter 126705 Ep: 14.31 loss 0.045 score 0.979 lr 6.32647e-06 
08/28/2020 05:29:16 - INFO - volta.utils -   [RetrievalCOCO]: iter 126725 Ep: 14.31 loss 0.052 score 0.980 lr 6.32396e-06 
08/28/2020 05:29:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 126745 Ep: 14.31 loss 0.058 score 0.974 lr 6.32145e-06 
08/28/2020 05:29:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 126765 Ep: 14.31 loss 0.040 score 0.981 lr 6.31894e-06 
08/28/2020 05:30:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 126785 Ep: 14.32 loss 0.047 score 0.978 lr 6.31643e-06 
08/28/2020 05:30:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 126805 Ep: 14.32 loss 0.038 score 0.988 lr 6.31392e-06 
08/28/2020 05:30:47 - INFO - volta.utils -   [RetrievalCOCO]: iter 126825 Ep: 14.32 loss 0.050 score 0.978 lr 6.31141e-06 
08/28/2020 05:31:06 - INFO - volta.utils -   [RetrievalCOCO]: iter 126845 Ep: 14.32 loss 0.047 score 0.982 lr 6.30891e-06 
08/28/2020 05:31:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 126865 Ep: 14.33 loss 0.043 score 0.981 lr 6.3064e-06 
08/28/2020 05:31:39 - INFO - volta.utils -   [RetrievalCOCO]: iter 126885 Ep: 14.33 loss 0.064 score 0.977 lr 6.30389e-06 
08/28/2020 05:31:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 126905 Ep: 14.33 loss 0.051 score 0.976 lr 6.30138e-06 
08/28/2020 05:32:09 - INFO - volta.utils -   [RetrievalCOCO]: iter 126925 Ep: 14.33 loss 0.042 score 0.979 lr 6.29887e-06 
08/28/2020 05:32:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 126945 Ep: 14.33 loss 0.060 score 0.975 lr 6.29636e-06 
08/28/2020 05:32:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 126965 Ep: 14.34 loss 0.043 score 0.984 lr 6.29385e-06 
08/28/2020 05:33:06 - INFO - volta.utils -   [RetrievalCOCO]: iter 126985 Ep: 14.34 loss 0.056 score 0.977 lr 6.29134e-06 
08/28/2020 05:33:19 - INFO - volta.utils -   [RetrievalCOCO]: iter 127005 Ep: 14.34 loss 0.049 score 0.980 lr 6.28883e-06 
08/28/2020 05:33:38 - INFO - volta.utils -   [RetrievalCOCO]: iter 127025 Ep: 14.34 loss 0.044 score 0.981 lr 6.28632e-06 
08/28/2020 05:33:58 - INFO - volta.utils -   [RetrievalCOCO]: iter 127045 Ep: 14.35 loss 0.055 score 0.978 lr 6.28381e-06 
08/28/2020 05:34:12 - INFO - volta.utils -   [RetrievalCOCO]: iter 127065 Ep: 14.35 loss 0.050 score 0.979 lr 6.2813e-06 
08/28/2020 05:34:29 - INFO - volta.utils -   [RetrievalCOCO]: iter 127085 Ep: 14.35 loss 0.036 score 0.985 lr 6.27879e-06 
08/28/2020 05:34:43 - INFO - volta.utils -   [RetrievalCOCO]: iter 127105 Ep: 14.35 loss 0.053 score 0.982 lr 6.27628e-06 
08/28/2020 05:34:57 - INFO - volta.utils -   [RetrievalCOCO]: iter 127125 Ep: 14.35 loss 0.036 score 0.987 lr 6.27378e-06 
08/28/2020 05:35:11 - INFO - volta.utils -   [RetrievalCOCO]: iter 127145 Ep: 14.36 loss 0.059 score 0.974 lr 6.27127e-06 
08/28/2020 05:35:25 - INFO - volta.utils -   [RetrievalCOCO]: iter 127165 Ep: 14.36 loss 0.046 score 0.984 lr 6.26876e-06 
08/28/2020 05:35:39 - INFO - volta.utils -   [RetrievalCOCO]: iter 127185 Ep: 14.36 loss 0.048 score 0.978 lr 6.26625e-06 
08/28/2020 05:36:02 - INFO - volta.utils -   [RetrievalCOCO]: iter 127205 Ep: 14.36 loss 0.053 score 0.978 lr 6.26374e-06 
08/28/2020 05:36:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 127225 Ep: 14.37 loss 0.060 score 0.973 lr 6.26123e-06 
08/28/2020 05:36:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 127245 Ep: 14.37 loss 0.039 score 0.987 lr 6.25872e-06 
08/28/2020 05:36:57 - INFO - volta.utils -   [RetrievalCOCO]: iter 127265 Ep: 14.37 loss 0.045 score 0.984 lr 6.25621e-06 
08/28/2020 05:37:17 - INFO - volta.utils -   [RetrievalCOCO]: iter 127285 Ep: 14.37 loss 0.053 score 0.977 lr 6.2537e-06 
08/28/2020 05:37:31 - INFO - volta.utils -   [RetrievalCOCO]: iter 127305 Ep: 14.38 loss 0.036 score 0.986 lr 6.25119e-06 
08/28/2020 05:37:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 127325 Ep: 14.38 loss 0.044 score 0.984 lr 6.24868e-06 
08/28/2020 05:38:09 - INFO - volta.utils -   [RetrievalCOCO]: iter 127345 Ep: 14.38 loss 0.061 score 0.977 lr 6.24617e-06 
08/28/2020 05:38:25 - INFO - volta.utils -   [RetrievalCOCO]: iter 127365 Ep: 14.38 loss 0.046 score 0.983 lr 6.24366e-06 
08/28/2020 05:38:39 - INFO - volta.utils -   [RetrievalCOCO]: iter 127385 Ep: 14.38 loss 0.054 score 0.973 lr 6.24115e-06 
08/28/2020 05:38:57 - INFO - volta.utils -   [RetrievalCOCO]: iter 127405 Ep: 14.39 loss 0.054 score 0.980 lr 6.23865e-06 
08/28/2020 05:39:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 127425 Ep: 14.39 loss 0.052 score 0.977 lr 6.23614e-06 
08/28/2020 05:39:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 127445 Ep: 14.39 loss 0.050 score 0.977 lr 6.23363e-06 
08/28/2020 05:39:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 127465 Ep: 14.39 loss 0.044 score 0.980 lr 6.23112e-06 
08/28/2020 05:40:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 127485 Ep: 14.40 loss 0.049 score 0.980 lr 6.22861e-06 
08/28/2020 05:40:29 - INFO - volta.utils -   [RetrievalCOCO]: iter 127505 Ep: 14.40 loss 0.042 score 0.982 lr 6.2261e-06 
08/28/2020 05:40:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 127525 Ep: 14.40 loss 0.044 score 0.986 lr 6.22359e-06 
08/28/2020 05:41:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 127545 Ep: 14.40 loss 0.048 score 0.978 lr 6.22108e-06 
08/28/2020 05:41:17 - INFO - volta.utils -   [RetrievalCOCO]: iter 127565 Ep: 14.40 loss 0.043 score 0.979 lr 6.21857e-06 
08/28/2020 05:41:30 - INFO - volta.utils -   [RetrievalCOCO]: iter 127585 Ep: 14.41 loss 0.050 score 0.981 lr 6.21606e-06 
08/28/2020 05:41:50 - INFO - volta.utils -   [RetrievalCOCO]: iter 127605 Ep: 14.41 loss 0.046 score 0.976 lr 6.21355e-06 
08/28/2020 05:42:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 127625 Ep: 14.41 loss 0.046 score 0.979 lr 6.21104e-06 
08/28/2020 05:42:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 127645 Ep: 14.41 loss 0.046 score 0.982 lr 6.20853e-06 
08/28/2020 05:42:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 127665 Ep: 14.42 loss 0.042 score 0.986 lr 6.20602e-06 
08/28/2020 05:42:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 127685 Ep: 14.42 loss 0.055 score 0.976 lr 6.20352e-06 
08/28/2020 05:43:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 127705 Ep: 14.42 loss 0.069 score 0.970 lr 6.20101e-06 
08/28/2020 05:43:23 - INFO - volta.utils -   [RetrievalCOCO]: iter 127725 Ep: 14.42 loss 0.058 score 0.974 lr 6.1985e-06 
08/28/2020 05:43:37 - INFO - volta.utils -   [RetrievalCOCO]: iter 127745 Ep: 14.42 loss 0.034 score 0.984 lr 6.19599e-06 
08/28/2020 05:43:50 - INFO - volta.utils -   [RetrievalCOCO]: iter 127765 Ep: 14.43 loss 0.063 score 0.974 lr 6.19348e-06 
08/28/2020 05:44:10 - INFO - volta.utils -   [RetrievalCOCO]: iter 127785 Ep: 14.43 loss 0.036 score 0.988 lr 6.19097e-06 
08/28/2020 05:44:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 127805 Ep: 14.43 loss 0.037 score 0.985 lr 6.18846e-06 
08/28/2020 05:44:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 127825 Ep: 14.43 loss 0.051 score 0.977 lr 6.18595e-06 
08/28/2020 05:44:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 127845 Ep: 14.44 loss 0.045 score 0.981 lr 6.18344e-06 
08/28/2020 05:45:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 127865 Ep: 14.44 loss 0.065 score 0.973 lr 6.18093e-06 
08/28/2020 05:45:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 127885 Ep: 14.44 loss 0.044 score 0.984 lr 6.17842e-06 
08/28/2020 05:45:45 - INFO - volta.utils -   [RetrievalCOCO]: iter 127905 Ep: 14.44 loss 0.058 score 0.980 lr 6.17591e-06 
08/28/2020 05:45:59 - INFO - volta.utils -   [RetrievalCOCO]: iter 127925 Ep: 14.45 loss 0.042 score 0.981 lr 6.1734e-06 
08/28/2020 05:46:18 - INFO - volta.utils -   [RetrievalCOCO]: iter 127945 Ep: 14.45 loss 0.064 score 0.972 lr 6.17089e-06 
08/28/2020 05:46:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 127965 Ep: 14.45 loss 0.043 score 0.979 lr 6.16839e-06 
08/28/2020 05:46:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 127985 Ep: 14.45 loss 0.053 score 0.983 lr 6.16588e-06 
08/28/2020 05:47:10 - INFO - volta.utils -   [RetrievalCOCO]: iter 128005 Ep: 14.45 loss 0.047 score 0.981 lr 6.16337e-06 
08/28/2020 05:47:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 128025 Ep: 14.46 loss 0.064 score 0.970 lr 6.16086e-06 
08/28/2020 05:47:46 - INFO - volta.utils -   [RetrievalCOCO]: iter 128045 Ep: 14.46 loss 0.043 score 0.978 lr 6.15835e-06 
08/28/2020 05:48:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 128065 Ep: 14.46 loss 0.049 score 0.979 lr 6.15584e-06 
08/28/2020 05:48:17 - INFO - volta.utils -   [RetrievalCOCO]: iter 128085 Ep: 14.46 loss 0.052 score 0.983 lr 6.15333e-06 
08/28/2020 05:48:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 128105 Ep: 14.47 loss 0.052 score 0.977 lr 6.15082e-06 
08/28/2020 05:48:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 128125 Ep: 14.47 loss 0.046 score 0.982 lr 6.14831e-06 
08/28/2020 05:49:12 - INFO - volta.utils -   [RetrievalCOCO]: iter 128145 Ep: 14.47 loss 0.050 score 0.978 lr 6.1458e-06 
08/28/2020 05:49:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 128165 Ep: 14.47 loss 0.054 score 0.975 lr 6.14329e-06 
08/28/2020 05:49:47 - INFO - volta.utils -   [RetrievalCOCO]: iter 128185 Ep: 14.47 loss 0.052 score 0.977 lr 6.14078e-06 
08/28/2020 05:50:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 128205 Ep: 14.48 loss 0.062 score 0.980 lr 6.13827e-06 
08/28/2020 05:50:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 128225 Ep: 14.48 loss 0.052 score 0.978 lr 6.13576e-06 
08/28/2020 05:50:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 128245 Ep: 14.48 loss 0.040 score 0.988 lr 6.13326e-06 
08/28/2020 05:50:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 128265 Ep: 14.48 loss 0.044 score 0.982 lr 6.13075e-06 
08/28/2020 05:51:11 - INFO - volta.utils -   [RetrievalCOCO]: iter 128285 Ep: 14.49 loss 0.040 score 0.981 lr 6.12824e-06 
08/28/2020 05:51:26 - INFO - volta.utils -   [RetrievalCOCO]: iter 128305 Ep: 14.49 loss 0.045 score 0.983 lr 6.12573e-06 
08/28/2020 05:51:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 128325 Ep: 14.49 loss 0.049 score 0.981 lr 6.12322e-06 
08/28/2020 05:51:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 128345 Ep: 14.49 loss 0.049 score 0.977 lr 6.12071e-06 
08/28/2020 05:52:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 128365 Ep: 14.49 loss 0.048 score 0.980 lr 6.1182e-06 
08/28/2020 05:52:27 - INFO - volta.utils -   [RetrievalCOCO]: iter 128385 Ep: 14.50 loss 0.045 score 0.984 lr 6.11569e-06 
08/28/2020 05:52:43 - INFO - volta.utils -   [RetrievalCOCO]: iter 128405 Ep: 14.50 loss 0.052 score 0.981 lr 6.11318e-06 
08/28/2020 05:52:58 - INFO - volta.utils -   [RetrievalCOCO]: iter 128425 Ep: 14.50 loss 0.038 score 0.986 lr 6.11067e-06 
08/28/2020 05:53:11 - INFO - volta.utils -   [RetrievalCOCO]: iter 128445 Ep: 14.50 loss 0.054 score 0.981 lr 6.10816e-06 
08/28/2020 05:53:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 128465 Ep: 14.51 loss 0.065 score 0.973 lr 6.10565e-06 
08/28/2020 05:53:44 - INFO - volta.utils -   [RetrievalCOCO]: iter 128485 Ep: 14.51 loss 0.035 score 0.988 lr 6.10314e-06 
08/28/2020 05:54:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 128505 Ep: 14.51 loss 0.039 score 0.987 lr 6.10063e-06 
08/28/2020 05:54:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 128525 Ep: 14.51 loss 0.033 score 0.990 lr 6.09813e-06 
08/28/2020 05:54:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 128545 Ep: 14.52 loss 0.040 score 0.984 lr 6.09562e-06 
08/28/2020 05:54:43 - INFO - volta.utils -   [RetrievalCOCO]: iter 128565 Ep: 14.52 loss 0.046 score 0.983 lr 6.09311e-06 
08/28/2020 05:55:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 128585 Ep: 14.52 loss 0.046 score 0.983 lr 6.0906e-06 
08/28/2020 05:55:17 - INFO - volta.utils -   [RetrievalCOCO]: iter 128605 Ep: 14.52 loss 0.054 score 0.982 lr 6.08809e-06 
08/28/2020 05:55:31 - INFO - volta.utils -   [RetrievalCOCO]: iter 128625 Ep: 14.52 loss 0.036 score 0.984 lr 6.08558e-06 
08/28/2020 05:55:48 - INFO - volta.utils -   [RetrievalCOCO]: iter 128645 Ep: 14.53 loss 0.044 score 0.982 lr 6.08307e-06 
08/28/2020 05:56:02 - INFO - volta.utils -   [RetrievalCOCO]: iter 128665 Ep: 14.53 loss 0.037 score 0.984 lr 6.08056e-06 
08/28/2020 05:56:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 128685 Ep: 14.53 loss 0.047 score 0.981 lr 6.07805e-06 
08/28/2020 05:56:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 128705 Ep: 14.53 loss 0.047 score 0.980 lr 6.07554e-06 
08/28/2020 05:56:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 128725 Ep: 14.54 loss 0.055 score 0.981 lr 6.07303e-06 
08/28/2020 05:57:02 - INFO - volta.utils -   [RetrievalCOCO]: iter 128745 Ep: 14.54 loss 0.056 score 0.973 lr 6.07052e-06 
08/28/2020 05:57:20 - INFO - volta.utils -   [RetrievalCOCO]: iter 128765 Ep: 14.54 loss 0.043 score 0.981 lr 6.06801e-06 
08/28/2020 05:57:37 - INFO - volta.utils -   [RetrievalCOCO]: iter 128785 Ep: 14.54 loss 0.044 score 0.981 lr 6.0655e-06 
08/28/2020 05:57:51 - INFO - volta.utils -   [RetrievalCOCO]: iter 128805 Ep: 14.54 loss 0.045 score 0.981 lr 6.063e-06 
08/28/2020 05:58:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 128825 Ep: 14.55 loss 0.050 score 0.982 lr 6.06049e-06 
08/28/2020 05:58:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 128845 Ep: 14.55 loss 0.047 score 0.979 lr 6.05798e-06 
08/28/2020 05:58:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 128865 Ep: 14.55 loss 0.045 score 0.983 lr 6.05547e-06 
08/28/2020 05:58:59 - INFO - volta.utils -   [RetrievalCOCO]: iter 128885 Ep: 14.55 loss 0.046 score 0.980 lr 6.05296e-06 
08/28/2020 05:59:18 - INFO - volta.utils -   [RetrievalCOCO]: iter 128905 Ep: 14.56 loss 0.050 score 0.975 lr 6.05045e-06 
08/28/2020 05:59:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 128925 Ep: 14.56 loss 0.046 score 0.977 lr 6.04794e-06 
08/28/2020 05:59:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 128945 Ep: 14.56 loss 0.042 score 0.980 lr 6.04543e-06 
08/28/2020 06:00:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 128965 Ep: 14.56 loss 0.045 score 0.980 lr 6.04292e-06 
08/28/2020 06:00:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 128985 Ep: 14.56 loss 0.044 score 0.984 lr 6.04041e-06 
08/28/2020 06:01:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 129005 Ep: 14.57 loss 0.039 score 0.986 lr 6.0379e-06 
08/28/2020 06:01:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 129025 Ep: 14.57 loss 0.050 score 0.984 lr 6.03539e-06 
08/28/2020 06:01:45 - INFO - volta.utils -   [RetrievalCOCO]: iter 129045 Ep: 14.57 loss 0.038 score 0.984 lr 6.03288e-06 
08/28/2020 06:02:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 129065 Ep: 14.57 loss 0.042 score 0.984 lr 6.03037e-06 
08/28/2020 06:02:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 129085 Ep: 14.58 loss 0.040 score 0.981 lr 6.02787e-06 
08/28/2020 06:02:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 129105 Ep: 14.58 loss 0.051 score 0.979 lr 6.02536e-06 
08/28/2020 06:02:56 - INFO - volta.utils -   [RetrievalCOCO]: iter 129125 Ep: 14.58 loss 0.056 score 0.975 lr 6.02285e-06 
08/28/2020 06:03:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 129145 Ep: 14.58 loss 0.040 score 0.984 lr 6.02034e-06 
08/28/2020 06:03:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 129165 Ep: 14.59 loss 0.042 score 0.980 lr 6.01783e-06 
08/28/2020 06:03:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 129185 Ep: 14.59 loss 0.043 score 0.980 lr 6.01532e-06 
08/28/2020 06:04:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 129205 Ep: 14.59 loss 0.051 score 0.977 lr 6.01281e-06 
08/28/2020 06:04:34 - INFO - volta.utils -   [RetrievalCOCO]: iter 129225 Ep: 14.59 loss 0.043 score 0.981 lr 6.0103e-06 
08/28/2020 06:05:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 129245 Ep: 14.59 loss 0.057 score 0.973 lr 6.00779e-06 
08/28/2020 06:05:30 - INFO - volta.utils -   [RetrievalCOCO]: iter 129265 Ep: 14.60 loss 0.050 score 0.977 lr 6.00528e-06 
08/28/2020 06:05:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 129285 Ep: 14.60 loss 0.050 score 0.984 lr 6.00277e-06 
08/28/2020 06:06:10 - INFO - volta.utils -   [RetrievalCOCO]: iter 129305 Ep: 14.60 loss 0.049 score 0.978 lr 6.00026e-06 
08/28/2020 06:06:27 - INFO - volta.utils -   [RetrievalCOCO]: iter 129325 Ep: 14.60 loss 0.040 score 0.984 lr 5.99775e-06 
08/28/2020 06:06:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 129345 Ep: 14.61 loss 0.046 score 0.980 lr 5.99524e-06 
08/28/2020 06:06:58 - INFO - volta.utils -   [RetrievalCOCO]: iter 129365 Ep: 14.61 loss 0.048 score 0.980 lr 5.99274e-06 
08/28/2020 06:07:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 129385 Ep: 14.61 loss 0.041 score 0.981 lr 5.99023e-06 
08/28/2020 06:07:34 - INFO - volta.utils -   [RetrievalCOCO]: iter 129405 Ep: 14.61 loss 0.027 score 0.987 lr 5.98772e-06 
08/28/2020 06:07:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 129425 Ep: 14.61 loss 0.045 score 0.978 lr 5.98521e-06 
08/28/2020 06:08:05 - INFO - volta.utils -   [RetrievalCOCO]: iter 129445 Ep: 14.62 loss 0.068 score 0.971 lr 5.9827e-06 
08/28/2020 06:08:20 - INFO - volta.utils -   [RetrievalCOCO]: iter 129465 Ep: 14.62 loss 0.037 score 0.986 lr 5.98019e-06 
08/28/2020 06:08:37 - INFO - volta.utils -   [RetrievalCOCO]: iter 129485 Ep: 14.62 loss 0.054 score 0.979 lr 5.97768e-06 
08/28/2020 06:08:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 129505 Ep: 14.62 loss 0.047 score 0.977 lr 5.97517e-06 
08/28/2020 06:09:10 - INFO - volta.utils -   [RetrievalCOCO]: iter 129525 Ep: 14.63 loss 0.044 score 0.977 lr 5.97266e-06 
08/28/2020 06:09:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 129545 Ep: 14.63 loss 0.028 score 0.988 lr 5.97015e-06 
08/28/2020 06:09:38 - INFO - volta.utils -   [RetrievalCOCO]: iter 129565 Ep: 14.63 loss 0.041 score 0.980 lr 5.96764e-06 
08/28/2020 06:09:52 - INFO - volta.utils -   [RetrievalCOCO]: iter 129585 Ep: 14.63 loss 0.043 score 0.984 lr 5.96513e-06 
08/28/2020 06:10:06 - INFO - volta.utils -   [RetrievalCOCO]: iter 129605 Ep: 14.63 loss 0.046 score 0.977 lr 5.96262e-06 
08/28/2020 06:10:23 - INFO - volta.utils -   [RetrievalCOCO]: iter 129625 Ep: 14.64 loss 0.054 score 0.977 lr 5.96011e-06 
08/28/2020 06:10:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 129645 Ep: 14.64 loss 0.062 score 0.977 lr 5.95761e-06 
08/28/2020 06:10:50 - INFO - volta.utils -   [RetrievalCOCO]: iter 129665 Ep: 14.64 loss 0.041 score 0.980 lr 5.9551e-06 
08/28/2020 06:11:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 129685 Ep: 14.64 loss 0.045 score 0.980 lr 5.95259e-06 
08/28/2020 06:11:18 - INFO - volta.utils -   [RetrievalCOCO]: iter 129705 Ep: 14.65 loss 0.039 score 0.985 lr 5.95008e-06 
08/28/2020 06:11:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 129725 Ep: 14.65 loss 0.042 score 0.984 lr 5.94757e-06 
08/28/2020 06:11:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 129745 Ep: 14.65 loss 0.055 score 0.974 lr 5.94506e-06 
08/28/2020 06:12:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 129765 Ep: 14.65 loss 0.045 score 0.980 lr 5.94255e-06 
08/28/2020 06:12:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 129785 Ep: 14.66 loss 0.043 score 0.984 lr 5.94004e-06 
08/28/2020 06:12:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 129805 Ep: 14.66 loss 0.040 score 0.988 lr 5.93753e-06 
08/28/2020 06:12:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 129825 Ep: 14.66 loss 0.044 score 0.983 lr 5.93502e-06 
08/28/2020 06:13:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 129845 Ep: 14.66 loss 0.037 score 0.981 lr 5.93251e-06 
08/28/2020 06:13:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 129865 Ep: 14.66 loss 0.038 score 0.984 lr 5.93e-06 
08/28/2020 06:13:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 129885 Ep: 14.67 loss 0.043 score 0.983 lr 5.92749e-06 
08/28/2020 06:13:48 - INFO - volta.utils -   [RetrievalCOCO]: iter 129905 Ep: 14.67 loss 0.052 score 0.977 lr 5.92498e-06 
08/28/2020 06:14:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 129925 Ep: 14.67 loss 0.053 score 0.974 lr 5.92248e-06 
08/28/2020 06:14:17 - INFO - volta.utils -   [RetrievalCOCO]: iter 129945 Ep: 14.67 loss 0.048 score 0.981 lr 5.91997e-06 
08/28/2020 06:14:37 - INFO - volta.utils -   [RetrievalCOCO]: iter 129965 Ep: 14.68 loss 0.043 score 0.980 lr 5.91746e-06 
08/28/2020 06:14:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 129985 Ep: 14.68 loss 0.043 score 0.982 lr 5.91495e-06 
08/28/2020 06:15:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 130005 Ep: 14.68 loss 0.033 score 0.987 lr 5.91244e-06 
08/28/2020 06:15:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 130025 Ep: 14.68 loss 0.043 score 0.977 lr 5.90993e-06 
08/28/2020 06:15:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 130045 Ep: 14.68 loss 0.075 score 0.968 lr 5.90742e-06 
08/28/2020 06:15:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 130065 Ep: 14.69 loss 0.037 score 0.991 lr 5.90491e-06 
08/28/2020 06:16:05 - INFO - volta.utils -   [RetrievalCOCO]: iter 130085 Ep: 14.69 loss 0.042 score 0.982 lr 5.9024e-06 
08/28/2020 06:16:19 - INFO - volta.utils -   [RetrievalCOCO]: iter 130105 Ep: 14.69 loss 0.037 score 0.983 lr 5.89989e-06 
08/28/2020 06:16:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 130125 Ep: 14.69 loss 0.047 score 0.981 lr 5.89738e-06 
08/28/2020 06:16:47 - INFO - volta.utils -   [RetrievalCOCO]: iter 130145 Ep: 14.70 loss 0.035 score 0.989 lr 5.89487e-06 
08/28/2020 06:17:01 - INFO - volta.utils -   [RetrievalCOCO]: iter 130165 Ep: 14.70 loss 0.044 score 0.980 lr 5.89236e-06 
08/28/2020 06:17:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 130185 Ep: 14.70 loss 0.034 score 0.992 lr 5.88985e-06 
08/28/2020 06:17:31 - INFO - volta.utils -   [RetrievalCOCO]: iter 130205 Ep: 14.70 loss 0.033 score 0.987 lr 5.88735e-06 
08/28/2020 06:17:51 - INFO - volta.utils -   [RetrievalCOCO]: iter 130225 Ep: 14.70 loss 0.042 score 0.982 lr 5.88484e-06 
08/28/2020 06:18:05 - INFO - volta.utils -   [RetrievalCOCO]: iter 130245 Ep: 14.71 loss 0.041 score 0.981 lr 5.88233e-06 
08/28/2020 06:18:19 - INFO - volta.utils -   [RetrievalCOCO]: iter 130265 Ep: 14.71 loss 0.045 score 0.982 lr 5.87982e-06 
08/28/2020 06:18:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 130285 Ep: 14.71 loss 0.048 score 0.978 lr 5.87731e-06 
08/28/2020 06:18:47 - INFO - volta.utils -   [RetrievalCOCO]: iter 130305 Ep: 14.71 loss 0.044 score 0.980 lr 5.8748e-06 
08/28/2020 06:19:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 130325 Ep: 14.72 loss 0.034 score 0.984 lr 5.87229e-06 
08/28/2020 06:19:18 - INFO - volta.utils -   [RetrievalCOCO]: iter 130345 Ep: 14.72 loss 0.044 score 0.984 lr 5.86978e-06 
08/28/2020 06:19:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 130365 Ep: 14.72 loss 0.031 score 0.987 lr 5.86727e-06 
08/28/2020 06:19:46 - INFO - volta.utils -   [RetrievalCOCO]: iter 130385 Ep: 14.72 loss 0.035 score 0.987 lr 5.86476e-06 
08/28/2020 06:20:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 130405 Ep: 14.73 loss 0.056 score 0.979 lr 5.86225e-06 
08/28/2020 06:20:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 130425 Ep: 14.73 loss 0.037 score 0.984 lr 5.85974e-06 
08/28/2020 06:20:31 - INFO - volta.utils -   [RetrievalCOCO]: iter 130445 Ep: 14.73 loss 0.046 score 0.980 lr 5.85723e-06 
08/28/2020 06:20:45 - INFO - volta.utils -   [RetrievalCOCO]: iter 130465 Ep: 14.73 loss 0.050 score 0.977 lr 5.85472e-06 
08/28/2020 06:20:59 - INFO - volta.utils -   [RetrievalCOCO]: iter 130485 Ep: 14.73 loss 0.032 score 0.987 lr 5.85222e-06 
08/28/2020 06:21:13 - INFO - volta.utils -   [RetrievalCOCO]: iter 130505 Ep: 14.74 loss 0.034 score 0.986 lr 5.84971e-06 
08/28/2020 06:21:27 - INFO - volta.utils -   [RetrievalCOCO]: iter 130525 Ep: 14.74 loss 0.047 score 0.979 lr 5.8472e-06 
08/28/2020 06:21:46 - INFO - volta.utils -   [RetrievalCOCO]: iter 130545 Ep: 14.74 loss 0.048 score 0.984 lr 5.84469e-06 
08/28/2020 06:22:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 130565 Ep: 14.74 loss 0.039 score 0.984 lr 5.84218e-06 
08/28/2020 06:22:17 - INFO - volta.utils -   [RetrievalCOCO]: iter 130585 Ep: 14.75 loss 0.038 score 0.982 lr 5.83967e-06 
08/28/2020 06:22:31 - INFO - volta.utils -   [RetrievalCOCO]: iter 130605 Ep: 14.75 loss 0.051 score 0.978 lr 5.83716e-06 
08/28/2020 06:22:50 - INFO - volta.utils -   [RetrievalCOCO]: iter 130625 Ep: 14.75 loss 0.037 score 0.983 lr 5.83465e-06 
08/28/2020 06:23:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 130645 Ep: 14.75 loss 0.036 score 0.987 lr 5.83214e-06 
08/28/2020 06:23:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 130665 Ep: 14.75 loss 0.035 score 0.987 lr 5.82963e-06 
08/28/2020 06:23:47 - INFO - volta.utils -   [RetrievalCOCO]: iter 130685 Ep: 14.76 loss 0.028 score 0.986 lr 5.82712e-06 
08/28/2020 06:24:01 - INFO - volta.utils -   [RetrievalCOCO]: iter 130705 Ep: 14.76 loss 0.041 score 0.983 lr 5.82461e-06 
08/28/2020 06:24:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 130725 Ep: 14.76 loss 0.051 score 0.982 lr 5.8221e-06 
08/28/2020 06:24:29 - INFO - volta.utils -   [RetrievalCOCO]: iter 130745 Ep: 14.76 loss 0.070 score 0.971 lr 5.8196e-06 
08/28/2020 06:24:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 130765 Ep: 14.77 loss 0.046 score 0.983 lr 5.81709e-06 
08/28/2020 06:25:06 - INFO - volta.utils -   [RetrievalCOCO]: iter 130785 Ep: 14.77 loss 0.044 score 0.984 lr 5.81458e-06 
08/28/2020 06:25:20 - INFO - volta.utils -   [RetrievalCOCO]: iter 130805 Ep: 14.77 loss 0.053 score 0.976 lr 5.81207e-06 
08/28/2020 06:25:43 - INFO - volta.utils -   [RetrievalCOCO]: iter 130825 Ep: 14.77 loss 0.037 score 0.986 lr 5.80956e-06 
08/28/2020 06:26:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 130845 Ep: 14.77 loss 0.040 score 0.982 lr 5.80705e-06 
08/28/2020 06:26:17 - INFO - volta.utils -   [RetrievalCOCO]: iter 130865 Ep: 14.78 loss 0.040 score 0.985 lr 5.80454e-06 
08/28/2020 06:26:39 - INFO - volta.utils -   [RetrievalCOCO]: iter 130885 Ep: 14.78 loss 0.040 score 0.980 lr 5.80203e-06 
08/28/2020 06:27:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 130905 Ep: 14.78 loss 0.036 score 0.990 lr 5.79952e-06 
08/28/2020 06:27:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 130925 Ep: 14.78 loss 0.039 score 0.983 lr 5.79701e-06 
08/28/2020 06:27:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 130945 Ep: 14.79 loss 0.038 score 0.983 lr 5.7945e-06 
08/28/2020 06:28:45 - INFO - volta.utils -   [RetrievalCOCO]: iter 130965 Ep: 14.79 loss 0.036 score 0.991 lr 5.79199e-06 
08/28/2020 06:29:20 - INFO - volta.utils -   [RetrievalCOCO]: iter 130985 Ep: 14.79 loss 0.047 score 0.977 lr 5.78948e-06 
08/28/2020 06:29:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 131005 Ep: 14.79 loss 0.038 score 0.984 lr 5.78697e-06 
08/28/2020 06:30:26 - INFO - volta.utils -   [RetrievalCOCO]: iter 131025 Ep: 14.80 loss 0.045 score 0.982 lr 5.78447e-06 
08/28/2020 06:30:56 - INFO - volta.utils -   [RetrievalCOCO]: iter 131045 Ep: 14.80 loss 0.046 score 0.982 lr 5.78196e-06 
08/28/2020 06:31:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 131065 Ep: 14.80 loss 0.034 score 0.984 lr 5.77945e-06 
08/28/2020 06:31:48 - INFO - volta.utils -   [RetrievalCOCO]: iter 131085 Ep: 14.80 loss 0.056 score 0.977 lr 5.77694e-06 
08/28/2020 06:32:13 - INFO - volta.utils -   [RetrievalCOCO]: iter 131105 Ep: 14.80 loss 0.042 score 0.984 lr 5.77443e-06 
08/28/2020 06:32:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 131125 Ep: 14.81 loss 0.033 score 0.984 lr 5.77192e-06 
08/28/2020 06:32:50 - INFO - volta.utils -   [RetrievalCOCO]: iter 131145 Ep: 14.81 loss 0.039 score 0.984 lr 5.76941e-06 
08/28/2020 06:33:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 131165 Ep: 14.81 loss 0.045 score 0.982 lr 5.7669e-06 
08/28/2020 06:33:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 131185 Ep: 14.81 loss 0.056 score 0.978 lr 5.76439e-06 
08/28/2020 06:33:37 - INFO - volta.utils -   [RetrievalCOCO]: iter 131205 Ep: 14.82 loss 0.035 score 0.986 lr 5.76188e-06 
08/28/2020 06:33:52 - INFO - volta.utils -   [RetrievalCOCO]: iter 131225 Ep: 14.82 loss 0.049 score 0.979 lr 5.75937e-06 
08/28/2020 06:34:09 - INFO - volta.utils -   [RetrievalCOCO]: iter 131245 Ep: 14.82 loss 0.045 score 0.980 lr 5.75686e-06 
08/28/2020 06:34:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 131265 Ep: 14.82 loss 0.040 score 0.986 lr 5.75435e-06 
08/28/2020 06:34:38 - INFO - volta.utils -   [RetrievalCOCO]: iter 131285 Ep: 14.82 loss 0.056 score 0.980 lr 5.75184e-06 
08/28/2020 06:34:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 131305 Ep: 14.83 loss 0.045 score 0.979 lr 5.74934e-06 
08/28/2020 06:35:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 131325 Ep: 14.83 loss 0.041 score 0.980 lr 5.74683e-06 
08/28/2020 06:35:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 131345 Ep: 14.83 loss 0.034 score 0.987 lr 5.74432e-06 
08/28/2020 06:35:39 - INFO - volta.utils -   [RetrievalCOCO]: iter 131365 Ep: 14.83 loss 0.038 score 0.985 lr 5.74181e-06 
08/28/2020 06:35:52 - INFO - volta.utils -   [RetrievalCOCO]: iter 131385 Ep: 14.84 loss 0.043 score 0.981 lr 5.7393e-06 
08/28/2020 06:36:06 - INFO - volta.utils -   [RetrievalCOCO]: iter 131405 Ep: 14.84 loss 0.045 score 0.982 lr 5.73679e-06 
08/28/2020 06:36:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 131425 Ep: 14.84 loss 0.037 score 0.984 lr 5.73428e-06 
08/28/2020 06:36:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 131445 Ep: 14.84 loss 0.049 score 0.981 lr 5.73177e-06 
08/28/2020 06:36:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 131465 Ep: 14.84 loss 0.047 score 0.984 lr 5.72926e-06 
08/28/2020 06:37:06 - INFO - volta.utils -   [RetrievalCOCO]: iter 131485 Ep: 14.85 loss 0.042 score 0.984 lr 5.72675e-06 
08/28/2020 06:37:20 - INFO - volta.utils -   [RetrievalCOCO]: iter 131505 Ep: 14.85 loss 0.034 score 0.984 lr 5.72424e-06 
08/28/2020 06:37:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 131525 Ep: 14.85 loss 0.053 score 0.973 lr 5.72173e-06 
08/28/2020 06:37:47 - INFO - volta.utils -   [RetrievalCOCO]: iter 131545 Ep: 14.85 loss 0.048 score 0.979 lr 5.71922e-06 
08/28/2020 06:38:01 - INFO - volta.utils -   [RetrievalCOCO]: iter 131565 Ep: 14.86 loss 0.048 score 0.977 lr 5.71671e-06 
08/28/2020 06:38:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 131585 Ep: 14.86 loss 0.042 score 0.980 lr 5.71421e-06 
08/28/2020 06:38:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 131605 Ep: 14.86 loss 0.042 score 0.981 lr 5.7117e-06 
08/28/2020 06:38:46 - INFO - volta.utils -   [RetrievalCOCO]: iter 131625 Ep: 14.86 loss 0.049 score 0.979 lr 5.70919e-06 
08/28/2020 06:39:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 131645 Ep: 14.87 loss 0.036 score 0.987 lr 5.70668e-06 
08/28/2020 06:39:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 131665 Ep: 14.87 loss 0.036 score 0.988 lr 5.70417e-06 
08/28/2020 06:39:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 131685 Ep: 14.87 loss 0.035 score 0.984 lr 5.70166e-06 
08/28/2020 06:39:45 - INFO - volta.utils -   [RetrievalCOCO]: iter 131705 Ep: 14.87 loss 0.024 score 0.991 lr 5.69915e-06 
08/28/2020 06:39:59 - INFO - volta.utils -   [RetrievalCOCO]: iter 131725 Ep: 14.87 loss 0.033 score 0.987 lr 5.69664e-06 
08/28/2020 06:40:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 131745 Ep: 14.88 loss 0.050 score 0.975 lr 5.69413e-06 
08/28/2020 06:40:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 131765 Ep: 14.88 loss 0.039 score 0.986 lr 5.69162e-06 
08/28/2020 06:40:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 131785 Ep: 14.88 loss 0.052 score 0.978 lr 5.68911e-06 
08/28/2020 06:40:56 - INFO - volta.utils -   [RetrievalCOCO]: iter 131805 Ep: 14.88 loss 0.046 score 0.981 lr 5.6866e-06 
08/28/2020 06:41:13 - INFO - volta.utils -   [RetrievalCOCO]: iter 131825 Ep: 14.89 loss 0.042 score 0.981 lr 5.68409e-06 
08/28/2020 06:41:27 - INFO - volta.utils -   [RetrievalCOCO]: iter 131845 Ep: 14.89 loss 0.044 score 0.982 lr 5.68158e-06 
08/28/2020 06:41:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 131865 Ep: 14.89 loss 0.042 score 0.984 lr 5.67908e-06 
08/28/2020 06:41:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 131885 Ep: 14.89 loss 0.042 score 0.981 lr 5.67657e-06 
08/28/2020 06:42:09 - INFO - volta.utils -   [RetrievalCOCO]: iter 131905 Ep: 14.89 loss 0.034 score 0.984 lr 5.67406e-06 
08/28/2020 06:42:23 - INFO - volta.utils -   [RetrievalCOCO]: iter 131925 Ep: 14.90 loss 0.040 score 0.981 lr 5.67155e-06 
08/28/2020 06:42:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 131945 Ep: 14.90 loss 0.049 score 0.980 lr 5.66904e-06 
08/28/2020 06:42:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 131965 Ep: 14.90 loss 0.045 score 0.980 lr 5.66653e-06 
08/28/2020 06:43:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 131985 Ep: 14.90 loss 0.035 score 0.984 lr 5.66402e-06 
08/28/2020 06:43:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 132005 Ep: 14.91 loss 0.044 score 0.983 lr 5.66151e-06 
08/28/2020 06:43:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 132025 Ep: 14.91 loss 0.062 score 0.976 lr 5.659e-06 
08/28/2020 06:43:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 132045 Ep: 14.91 loss 0.041 score 0.984 lr 5.65649e-06 
08/28/2020 06:44:06 - INFO - volta.utils -   [RetrievalCOCO]: iter 132065 Ep: 14.91 loss 0.045 score 0.978 lr 5.65398e-06 
08/28/2020 06:44:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 132085 Ep: 14.91 loss 0.050 score 0.977 lr 5.65147e-06 
08/28/2020 06:44:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 132105 Ep: 14.92 loss 0.043 score 0.980 lr 5.64896e-06 
08/28/2020 06:44:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 132125 Ep: 14.92 loss 0.032 score 0.985 lr 5.64645e-06 
08/28/2020 06:45:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 132145 Ep: 14.92 loss 0.037 score 0.985 lr 5.64395e-06 
08/28/2020 06:45:20 - INFO - volta.utils -   [RetrievalCOCO]: iter 132165 Ep: 14.92 loss 0.035 score 0.984 lr 5.64144e-06 
08/28/2020 06:45:34 - INFO - volta.utils -   [RetrievalCOCO]: iter 132185 Ep: 14.93 loss 0.041 score 0.982 lr 5.63893e-06 
08/28/2020 06:45:48 - INFO - volta.utils -   [RetrievalCOCO]: iter 132205 Ep: 14.93 loss 0.038 score 0.987 lr 5.63642e-06 
08/28/2020 06:46:02 - INFO - volta.utils -   [RetrievalCOCO]: iter 132225 Ep: 14.93 loss 0.051 score 0.980 lr 5.63391e-06 
08/28/2020 06:46:16 - INFO - volta.utils -   [RetrievalCOCO]: iter 132245 Ep: 14.93 loss 0.045 score 0.986 lr 5.6314e-06 
08/28/2020 06:46:29 - INFO - volta.utils -   [RetrievalCOCO]: iter 132265 Ep: 14.94 loss 0.044 score 0.980 lr 5.62889e-06 
08/28/2020 06:46:46 - INFO - volta.utils -   [RetrievalCOCO]: iter 132285 Ep: 14.94 loss 0.044 score 0.984 lr 5.62638e-06 
08/28/2020 06:47:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 132305 Ep: 14.94 loss 0.039 score 0.984 lr 5.62387e-06 
08/28/2020 06:47:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 132325 Ep: 14.94 loss 0.039 score 0.982 lr 5.62136e-06 
08/28/2020 06:47:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 132345 Ep: 14.94 loss 0.046 score 0.984 lr 5.61885e-06 
08/28/2020 06:47:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 132365 Ep: 14.95 loss 0.042 score 0.984 lr 5.61634e-06 
08/28/2020 06:47:56 - INFO - volta.utils -   [RetrievalCOCO]: iter 132385 Ep: 14.95 loss 0.042 score 0.985 lr 5.61383e-06 
08/28/2020 06:48:12 - INFO - volta.utils -   [RetrievalCOCO]: iter 132405 Ep: 14.95 loss 0.044 score 0.977 lr 5.61132e-06 
08/28/2020 06:48:26 - INFO - volta.utils -   [RetrievalCOCO]: iter 132425 Ep: 14.95 loss 0.036 score 0.986 lr 5.60882e-06 
08/28/2020 06:48:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 132445 Ep: 14.96 loss 0.042 score 0.980 lr 5.60631e-06 
08/28/2020 06:49:01 - INFO - volta.utils -   [RetrievalCOCO]: iter 132465 Ep: 14.96 loss 0.033 score 0.987 lr 5.6038e-06 
08/28/2020 06:49:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 132485 Ep: 14.96 loss 0.043 score 0.984 lr 5.60129e-06 
08/28/2020 06:49:29 - INFO - volta.utils -   [RetrievalCOCO]: iter 132505 Ep: 14.96 loss 0.030 score 0.986 lr 5.59878e-06 
08/28/2020 06:49:47 - INFO - volta.utils -   [RetrievalCOCO]: iter 132525 Ep: 14.96 loss 0.049 score 0.981 lr 5.59627e-06 
08/28/2020 06:50:01 - INFO - volta.utils -   [RetrievalCOCO]: iter 132545 Ep: 14.97 loss 0.035 score 0.987 lr 5.59376e-06 
08/28/2020 06:50:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 132565 Ep: 14.97 loss 0.036 score 0.984 lr 5.59125e-06 
08/28/2020 06:50:29 - INFO - volta.utils -   [RetrievalCOCO]: iter 132585 Ep: 14.97 loss 0.031 score 0.987 lr 5.58874e-06 
08/28/2020 06:50:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 132605 Ep: 14.97 loss 0.025 score 0.991 lr 5.58623e-06 
08/28/2020 06:50:56 - INFO - volta.utils -   [RetrievalCOCO]: iter 132625 Ep: 14.98 loss 0.026 score 0.989 lr 5.58372e-06 
08/28/2020 06:51:13 - INFO - volta.utils -   [RetrievalCOCO]: iter 132645 Ep: 14.98 loss 0.043 score 0.980 lr 5.58121e-06 
08/28/2020 06:51:26 - INFO - volta.utils -   [RetrievalCOCO]: iter 132665 Ep: 14.98 loss 0.044 score 0.981 lr 5.5787e-06 
08/28/2020 06:51:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 132685 Ep: 14.98 loss 0.037 score 0.982 lr 5.57619e-06 
08/28/2020 06:51:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 132705 Ep: 14.98 loss 0.049 score 0.973 lr 5.57369e-06 
08/28/2020 06:52:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 132725 Ep: 14.99 loss 0.037 score 0.984 lr 5.57118e-06 
08/28/2020 06:52:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 132745 Ep: 14.99 loss 0.038 score 0.984 lr 5.56867e-06 
08/28/2020 06:52:38 - INFO - volta.utils -   [RetrievalCOCO]: iter 132765 Ep: 14.99 loss 0.048 score 0.982 lr 5.56616e-06 
08/28/2020 06:52:52 - INFO - volta.utils -   [RetrievalCOCO]: iter 132785 Ep: 14.99 loss 0.035 score 0.983 lr 5.56365e-06 
08/28/2020 06:53:05 - INFO - volta.utils -   [RetrievalCOCO]: iter 132805 Ep: 15.00 loss 0.042 score 0.988 lr 5.56114e-06 
08/28/2020 06:53:20 - INFO - volta.utils -   [RetrievalCOCO]: iter 132825 Ep: 15.00 loss 0.062 score 0.974 lr 5.55863e-06 
08/28/2020 06:53:36 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  17%|        | 1/6 [2:09:20<10:46:42, 7760.43s/it]08/28/2020 06:57:09 - INFO - volta.utils -   Eval task TASK7 on iteration 132841 
08/28/2020 06:57:09 - INFO - volta.utils -   Validation [RetrievalCOCO]: loss 0.029 score 99.316 
08/28/2020 06:57:23 - INFO - volta.utils -   [RetrievalCOCO]: iter 132861 Ep: 15.00 loss 0.048 score 0.981 lr 5.55512e-06 
08/28/2020 06:57:37 - INFO - volta.utils -   [RetrievalCOCO]: iter 132881 Ep: 15.00 loss 0.051 score 0.978 lr 5.5516e-06 
08/28/2020 06:57:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 132901 Ep: 15.01 loss 0.061 score 0.979 lr 5.54909e-06 
08/28/2020 06:58:38 - INFO - volta.utils -   [RetrievalCOCO]: iter 132921 Ep: 15.01 loss 0.053 score 0.970 lr 5.54658e-06 
08/28/2020 06:59:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 132941 Ep: 15.01 loss 0.037 score 0.987 lr 5.54408e-06 
08/28/2020 07:00:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 132961 Ep: 15.01 loss 0.038 score 0.984 lr 5.54157e-06 
08/28/2020 07:00:52 - INFO - volta.utils -   [RetrievalCOCO]: iter 132981 Ep: 15.02 loss 0.031 score 0.988 lr 5.53906e-06 
08/28/2020 07:01:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 133001 Ep: 15.02 loss 0.048 score 0.979 lr 5.53655e-06 
08/28/2020 07:02:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 133021 Ep: 15.02 loss 0.050 score 0.979 lr 5.53404e-06 
08/28/2020 07:02:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 133041 Ep: 15.02 loss 0.036 score 0.984 lr 5.53153e-06 
08/28/2020 07:03:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 133061 Ep: 15.02 loss 0.041 score 0.981 lr 5.52902e-06 
08/28/2020 07:03:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 133081 Ep: 15.03 loss 0.033 score 0.987 lr 5.52651e-06 
08/28/2020 07:04:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 133101 Ep: 15.03 loss 0.042 score 0.987 lr 5.524e-06 
08/28/2020 07:04:35 - INFO - volta.utils -   [RetrievalCOCO]: iter 133121 Ep: 15.03 loss 0.034 score 0.984 lr 5.52149e-06 
08/28/2020 07:04:59 - INFO - volta.utils -   [RetrievalCOCO]: iter 133141 Ep: 15.03 loss 0.044 score 0.983 lr 5.51898e-06 
08/28/2020 07:05:18 - INFO - volta.utils -   [RetrievalCOCO]: iter 133161 Ep: 15.04 loss 0.041 score 0.978 lr 5.51647e-06 
08/28/2020 07:05:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 133181 Ep: 15.04 loss 0.038 score 0.983 lr 5.51396e-06 
08/28/2020 07:05:56 - INFO - volta.utils -   [RetrievalCOCO]: iter 133201 Ep: 15.04 loss 0.047 score 0.978 lr 5.51145e-06 
08/28/2020 07:06:10 - INFO - volta.utils -   [RetrievalCOCO]: iter 133221 Ep: 15.04 loss 0.042 score 0.984 lr 5.50895e-06 
08/28/2020 07:06:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 133241 Ep: 15.05 loss 0.054 score 0.973 lr 5.50644e-06 
08/28/2020 07:06:38 - INFO - volta.utils -   [RetrievalCOCO]: iter 133261 Ep: 15.05 loss 0.045 score 0.983 lr 5.50393e-06 
08/28/2020 07:06:57 - INFO - volta.utils -   [RetrievalCOCO]: iter 133281 Ep: 15.05 loss 0.051 score 0.981 lr 5.50142e-06 
08/28/2020 07:07:11 - INFO - volta.utils -   [RetrievalCOCO]: iter 133301 Ep: 15.05 loss 0.051 score 0.975 lr 5.49891e-06 
08/28/2020 07:07:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 133321 Ep: 15.05 loss 0.037 score 0.987 lr 5.4964e-06 
08/28/2020 07:07:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 133341 Ep: 15.06 loss 0.037 score 0.986 lr 5.49389e-06 
08/28/2020 07:07:56 - INFO - volta.utils -   [RetrievalCOCO]: iter 133361 Ep: 15.06 loss 0.048 score 0.982 lr 5.49138e-06 
08/28/2020 07:08:10 - INFO - volta.utils -   [RetrievalCOCO]: iter 133381 Ep: 15.06 loss 0.041 score 0.984 lr 5.48887e-06 
08/28/2020 07:08:34 - INFO - volta.utils -   [RetrievalCOCO]: iter 133401 Ep: 15.06 loss 0.048 score 0.980 lr 5.48636e-06 
08/28/2020 07:08:47 - INFO - volta.utils -   [RetrievalCOCO]: iter 133421 Ep: 15.07 loss 0.044 score 0.980 lr 5.48385e-06 
08/28/2020 07:09:01 - INFO - volta.utils -   [RetrievalCOCO]: iter 133441 Ep: 15.07 loss 0.055 score 0.976 lr 5.48134e-06 
08/28/2020 07:09:18 - INFO - volta.utils -   [RetrievalCOCO]: iter 133461 Ep: 15.07 loss 0.061 score 0.977 lr 5.47883e-06 
08/28/2020 07:09:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 133481 Ep: 15.07 loss 0.031 score 0.988 lr 5.47632e-06 
08/28/2020 07:09:46 - INFO - volta.utils -   [RetrievalCOCO]: iter 133501 Ep: 15.07 loss 0.044 score 0.981 lr 5.47382e-06 
08/28/2020 07:10:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 133521 Ep: 15.08 loss 0.037 score 0.985 lr 5.47131e-06 
08/28/2020 07:10:14 - INFO - volta.utils -   [RetrievalCOCO]: iter 133541 Ep: 15.08 loss 0.039 score 0.983 lr 5.4688e-06 
08/28/2020 07:10:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 133561 Ep: 15.08 loss 0.033 score 0.985 lr 5.46629e-06 
08/28/2020 07:10:42 - INFO - volta.utils -   [RetrievalCOCO]: iter 133581 Ep: 15.08 loss 0.050 score 0.979 lr 5.46378e-06 
08/28/2020 07:10:59 - INFO - volta.utils -   [RetrievalCOCO]: iter 133601 Ep: 15.09 loss 0.039 score 0.980 lr 5.46127e-06 
08/28/2020 07:11:13 - INFO - volta.utils -   [RetrievalCOCO]: iter 133621 Ep: 15.09 loss 0.053 score 0.980 lr 5.45876e-06 
08/28/2020 07:11:27 - INFO - volta.utils -   [RetrievalCOCO]: iter 133641 Ep: 15.09 loss 0.057 score 0.976 lr 5.45625e-06 
08/28/2020 07:11:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 133661 Ep: 15.09 loss 0.044 score 0.980 lr 5.45374e-06 
08/28/2020 07:11:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 133681 Ep: 15.09 loss 0.044 score 0.982 lr 5.45123e-06 
08/28/2020 07:12:08 - INFO - volta.utils -   [RetrievalCOCO]: iter 133701 Ep: 15.10 loss 0.039 score 0.983 lr 5.44872e-06 
08/28/2020 07:12:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 133721 Ep: 15.10 loss 0.047 score 0.980 lr 5.44621e-06 
08/28/2020 07:12:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 133741 Ep: 15.10 loss 0.029 score 0.989 lr 5.4437e-06 
08/28/2020 07:12:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 133761 Ep: 15.10 loss 0.043 score 0.984 lr 5.44119e-06 
08/28/2020 07:13:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 133781 Ep: 15.11 loss 0.048 score 0.981 lr 5.43869e-06 
08/28/2020 07:13:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 133801 Ep: 15.11 loss 0.041 score 0.984 lr 5.43618e-06 
08/28/2020 07:13:34 - INFO - volta.utils -   [RetrievalCOCO]: iter 133821 Ep: 15.11 loss 0.052 score 0.977 lr 5.43367e-06 
08/28/2020 07:13:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 133841 Ep: 15.11 loss 0.039 score 0.989 lr 5.43116e-06 
08/28/2020 07:14:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 133861 Ep: 15.12 loss 0.046 score 0.984 lr 5.42865e-06 
08/28/2020 07:14:17 - INFO - volta.utils -   [RetrievalCOCO]: iter 133881 Ep: 15.12 loss 0.040 score 0.984 lr 5.42614e-06 
08/28/2020 07:14:34 - INFO - volta.utils -   [RetrievalCOCO]: iter 133901 Ep: 15.12 loss 0.029 score 0.988 lr 5.42363e-06 
08/28/2020 07:14:48 - INFO - volta.utils -   [RetrievalCOCO]: iter 133921 Ep: 15.12 loss 0.034 score 0.985 lr 5.42112e-06 
08/28/2020 07:15:02 - INFO - volta.utils -   [RetrievalCOCO]: iter 133941 Ep: 15.12 loss 0.038 score 0.980 lr 5.41861e-06 
08/28/2020 07:15:16 - INFO - volta.utils -   [RetrievalCOCO]: iter 133961 Ep: 15.13 loss 0.040 score 0.980 lr 5.4161e-06 
08/28/2020 07:15:30 - INFO - volta.utils -   [RetrievalCOCO]: iter 133981 Ep: 15.13 loss 0.025 score 0.991 lr 5.41359e-06 
08/28/2020 07:15:44 - INFO - volta.utils -   [RetrievalCOCO]: iter 134001 Ep: 15.13 loss 0.040 score 0.987 lr 5.41108e-06 
08/28/2020 07:15:58 - INFO - volta.utils -   [RetrievalCOCO]: iter 134021 Ep: 15.13 loss 0.039 score 0.985 lr 5.40857e-06 
08/28/2020 07:16:15 - INFO - volta.utils -   [RetrievalCOCO]: iter 134041 Ep: 15.14 loss 0.055 score 0.983 lr 5.40606e-06 
08/28/2020 07:16:29 - INFO - volta.utils -   [RetrievalCOCO]: iter 134061 Ep: 15.14 loss 0.031 score 0.987 lr 5.40356e-06 
08/28/2020 07:16:43 - INFO - volta.utils -   [RetrievalCOCO]: iter 134081 Ep: 15.14 loss 0.028 score 0.989 lr 5.40105e-06 
08/28/2020 07:16:58 - INFO - volta.utils -   [RetrievalCOCO]: iter 134101 Ep: 15.14 loss 0.034 score 0.986 lr 5.39854e-06 
08/28/2020 07:17:12 - INFO - volta.utils -   [RetrievalCOCO]: iter 134121 Ep: 15.14 loss 0.052 score 0.977 lr 5.39603e-06 
08/28/2020 07:17:26 - INFO - volta.utils -   [RetrievalCOCO]: iter 134141 Ep: 15.15 loss 0.043 score 0.979 lr 5.39352e-06 
08/28/2020 07:17:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 134161 Ep: 15.15 loss 0.037 score 0.984 lr 5.39101e-06 
08/28/2020 07:17:57 - INFO - volta.utils -   [RetrievalCOCO]: iter 134181 Ep: 15.15 loss 0.053 score 0.978 lr 5.3885e-06 
08/28/2020 07:18:11 - INFO - volta.utils -   [RetrievalCOCO]: iter 134201 Ep: 15.15 loss 0.042 score 0.984 lr 5.38599e-06 
08/28/2020 07:18:25 - INFO - volta.utils -   [RetrievalCOCO]: iter 134221 Ep: 15.16 loss 0.049 score 0.982 lr 5.38348e-06 
08/28/2020 07:18:39 - INFO - volta.utils -   [RetrievalCOCO]: iter 134241 Ep: 15.16 loss 0.034 score 0.987 lr 5.38097e-06 
08/28/2020 07:18:52 - INFO - volta.utils -   [RetrievalCOCO]: iter 134261 Ep: 15.16 loss 0.053 score 0.979 lr 5.37846e-06 
08/28/2020 07:19:06 - INFO - volta.utils -   [RetrievalCOCO]: iter 134281 Ep: 15.16 loss 0.045 score 0.980 lr 5.37595e-06 
08/28/2020 07:19:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 134301 Ep: 15.16 loss 0.052 score 0.976 lr 5.37344e-06 
08/28/2020 07:19:37 - INFO - volta.utils -   [RetrievalCOCO]: iter 134321 Ep: 15.17 loss 0.038 score 0.987 lr 5.37093e-06 
08/28/2020 07:19:59 - INFO - volta.utils -   [RetrievalCOCO]: iter 134341 Ep: 15.17 loss 0.039 score 0.984 lr 5.36843e-06 
08/28/2020 07:20:22 - INFO - volta.utils -   [RetrievalCOCO]: iter 134361 Ep: 15.17 loss 0.050 score 0.981 lr 5.36592e-06 
08/28/2020 07:20:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 134381 Ep: 15.17 loss 0.028 score 0.991 lr 5.36341e-06 
08/28/2020 07:20:50 - INFO - volta.utils -   [RetrievalCOCO]: iter 134401 Ep: 15.18 loss 0.040 score 0.985 lr 5.3609e-06 
08/28/2020 07:21:04 - INFO - volta.utils -   [RetrievalCOCO]: iter 134421 Ep: 15.18 loss 0.036 score 0.990 lr 5.35839e-06 
08/28/2020 07:21:18 - INFO - volta.utils -   [RetrievalCOCO]: iter 134441 Ep: 15.18 loss 0.038 score 0.984 lr 5.35588e-06 
08/28/2020 07:21:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 134461 Ep: 15.18 loss 0.054 score 0.977 lr 5.35337e-06 
08/28/2020 07:21:50 - INFO - volta.utils -   [RetrievalCOCO]: iter 134481 Ep: 15.19 loss 0.047 score 0.979 lr 5.35086e-06 
08/28/2020 07:22:12 - INFO - volta.utils -   [RetrievalCOCO]: iter 134501 Ep: 15.19 loss 0.050 score 0.984 lr 5.34835e-06 
08/28/2020 07:22:26 - INFO - volta.utils -   [RetrievalCOCO]: iter 134521 Ep: 15.19 loss 0.043 score 0.981 lr 5.34584e-06 
08/28/2020 07:22:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 134541 Ep: 15.19 loss 0.043 score 0.983 lr 5.34333e-06 
08/28/2020 07:22:54 - INFO - volta.utils -   [RetrievalCOCO]: iter 134561 Ep: 15.19 loss 0.048 score 0.980 lr 5.34082e-06 
08/28/2020 07:23:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 134581 Ep: 15.20 loss 0.040 score 0.984 lr 5.33831e-06 
08/28/2020 07:23:28 - INFO - volta.utils -   [RetrievalCOCO]: iter 134601 Ep: 15.20 loss 0.045 score 0.977 lr 5.3358e-06 
08/28/2020 07:23:52 - INFO - volta.utils -   [RetrievalCOCO]: iter 134621 Ep: 15.20 loss 0.044 score 0.980 lr 5.3333e-06 
08/28/2020 07:24:16 - INFO - volta.utils -   [RetrievalCOCO]: iter 134641 Ep: 15.20 loss 0.034 score 0.987 lr 5.33079e-06 
08/28/2020 07:24:30 - INFO - volta.utils -   [RetrievalCOCO]: iter 134661 Ep: 15.21 loss 0.043 score 0.986 lr 5.32828e-06 
08/28/2020 07:24:45 - INFO - volta.utils -   [RetrievalCOCO]: iter 134681 Ep: 15.21 loss 0.051 score 0.979 lr 5.32577e-06 
08/28/2020 07:24:59 - INFO - volta.utils -   [RetrievalCOCO]: iter 134701 Ep: 15.21 loss 0.040 score 0.984 lr 5.32326e-06 
08/28/2020 07:25:13 - INFO - volta.utils -   [RetrievalCOCO]: iter 134721 Ep: 15.21 loss 0.044 score 0.979 lr 5.32075e-06 
08/28/2020 07:25:34 - INFO - volta.utils -   [RetrievalCOCO]: iter 134741 Ep: 15.21 loss 0.045 score 0.983 lr 5.31824e-06 
08/28/2020 07:25:57 - INFO - volta.utils -   [RetrievalCOCO]: iter 134761 Ep: 15.22 loss 0.032 score 0.989 lr 5.31573e-06 
08/28/2020 07:26:12 - INFO - volta.utils -   [RetrievalCOCO]: iter 134781 Ep: 15.22 loss 0.057 score 0.977 lr 5.31322e-06 
08/28/2020 07:26:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 134801 Ep: 15.22 loss 0.045 score 0.988 lr 5.31071e-06 
08/28/2020 07:26:57 - INFO - volta.utils -   [RetrievalCOCO]: iter 134821 Ep: 15.22 loss 0.036 score 0.986 lr 5.3082e-06 
08/28/2020 07:27:12 - INFO - volta.utils -   [RetrievalCOCO]: iter 134841 Ep: 15.23 loss 0.035 score 0.985 lr 5.30569e-06 
08/28/2020 07:27:34 - INFO - volta.utils -   [RetrievalCOCO]: iter 134861 Ep: 15.23 loss 0.031 score 0.991 lr 5.30318e-06 
08/28/2020 07:27:57 - INFO - volta.utils -   [RetrievalCOCO]: iter 134881 Ep: 15.23 loss 0.036 score 0.984 lr 5.30067e-06 
08/28/2020 07:28:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 134901 Ep: 15.23 loss 0.057 score 0.978 lr 5.29817e-06 
08/28/2020 07:28:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 134921 Ep: 15.23 loss 0.046 score 0.982 lr 5.29566e-06 
08/28/2020 07:28:56 - INFO - volta.utils -   [RetrievalCOCO]: iter 134941 Ep: 15.24 loss 0.037 score 0.984 lr 5.29315e-06 
08/28/2020 07:29:11 - INFO - volta.utils -   [RetrievalCOCO]: iter 134961 Ep: 15.24 loss 0.036 score 0.984 lr 5.29064e-06 
08/28/2020 07:29:32 - INFO - volta.utils -   [RetrievalCOCO]: iter 134981 Ep: 15.24 loss 0.051 score 0.977 lr 5.28813e-06 
08/28/2020 07:29:46 - INFO - volta.utils -   [RetrievalCOCO]: iter 135001 Ep: 15.24 loss 0.042 score 0.985 lr 5.28562e-06 
08/28/2020 07:30:00 - INFO - volta.utils -   [RetrievalCOCO]: iter 135021 Ep: 15.25 loss 0.051 score 0.980 lr 5.28311e-06 
08/28/2020 07:30:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 135041 Ep: 15.25 loss 0.054 score 0.979 lr 5.2806e-06 
08/28/2020 07:30:36 - INFO - volta.utils -   [RetrievalCOCO]: iter 135061 Ep: 15.25 loss 0.038 score 0.985 lr 5.27809e-06 
08/28/2020 07:30:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 135081 Ep: 15.25 loss 0.047 score 0.984 lr 5.27558e-06 
08/28/2020 07:31:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 135101 Ep: 15.26 loss 0.043 score 0.980 lr 5.27307e-06 
08/28/2020 07:31:21 - INFO - volta.utils -   [RetrievalCOCO]: iter 135121 Ep: 15.26 loss 0.042 score 0.980 lr 5.27056e-06 
08/28/2020 07:31:39 - INFO - volta.utils -   [RetrievalCOCO]: iter 135141 Ep: 15.26 loss 0.036 score 0.983 lr 5.26805e-06 
08/28/2020 07:31:53 - INFO - volta.utils -   [RetrievalCOCO]: iter 135161 Ep: 15.26 loss 0.047 score 0.980 lr 5.26555e-06 
08/28/2020 07:32:07 - INFO - volta.utils -   [RetrievalCOCO]: iter 135181 Ep: 15.26 loss 0.054 score 0.977 lr 5.26304e-06 
08/28/2020 07:32:26 - INFO - volta.utils -   [RetrievalCOCO]: iter 135201 Ep: 15.27 loss 0.057 score 0.975 lr 5.26053e-06 
08/28/2020 07:32:41 - INFO - volta.utils -   [RetrievalCOCO]: iter 135221 Ep: 15.27 loss 0.038 score 0.981 lr 5.25802e-06 
08/28/2020 07:33:03 - INFO - volta.utils -   [RetrievalCOCO]: iter 135241 Ep: 15.27 loss 0.038 score 0.983 lr 5.25551e-06 
08/28/2020 07:33:33 - INFO - volta.utils -   [RetrievalCOCO]: iter 135261 Ep: 15.27 loss 0.049 score 0.977 lr 5.253e-06 
08/28/2020 07:34:02 - INFO - volta.utils -   [RetrievalCOCO]: iter 135281 Ep: 15.28 loss 0.051 score 0.980 lr 5.25049e-06 
08/28/2020 07:34:26 - INFO - volta.utils -   [RetrievalCOCO]: iter 135301 Ep: 15.28 loss 0.036 score 0.988 lr 5.24798e-06 
08/28/2020 07:34:50 - INFO - volta.utils -   [RetrievalCOCO]: iter 135321 Ep: 15.28 loss 0.031 score 0.988 lr 5.24547e-06 
08/28/2020 07:35:16 - INFO - volta.utils -   [RetrievalCOCO]: iter 135341 Ep: 15.28 loss 0.045 score 0.985 lr 5.24296e-06 
08/28/2020 07:35:37 - INFO - volta.utils -   [RetrievalCOCO]: iter 135361 Ep: 15.28 loss 0.043 score 0.982 lr 5.24045e-06 
08/28/2020 07:36:01 - INFO - volta.utils -   [RetrievalCOCO]: iter 135381 Ep: 15.29 loss 0.049 score 0.980 lr 5.23794e-06 
08/28/2020 07:36:24 - INFO - volta.utils -   [RetrievalCOCO]: iter 135401 Ep: 15.29 loss 0.042 score 0.985 lr 5.23543e-06 
08/28/2020 07:36:49 - INFO - volta.utils -   [RetrievalCOCO]: iter 135421 Ep: 15.29 loss 0.033 score 0.988 lr 5.23292e-06 
08/28/2020 07:37:23 - INFO - volta.utils -   [RetrievalCOCO]: iter 135441 Ep: 15.29 loss 0.038 score 0.988 lr 5.23042e-06 
08/28/2020 07:38:02 - INFO - volta.utils -   [RetrievalCOCO]: iter 135461 Ep: 15.30 loss 0.041 score 0.984 lr 5.22791e-06 
08/28/2020 07:38:30 - INFO - volta.utils -   [RetrievalCOCO]: iter 135481 Ep: 15.30 loss 0.040 score 0.983 lr 5.2254e-06 
08/28/2020 07:38:55 - INFO - volta.utils -   [RetrievalCOCO]: iter 135501 Ep: 15.30 loss 0.052 score 0.980 lr 5.22289e-06 
08/28/2020 07:39:17 - INFO - volta.utils -   [RetrievalCOCO]: iter 135521 Ep: 15.30 loss 0.032 score 0.986 lr 5.22038e-06 
08/28/2020 07:39:40 - INFO - volta.utils -   [RetrievalCOCO]: iter 135541 Ep: 15.30 loss 0.036 score 0.987 lr 5.21787e-06 
