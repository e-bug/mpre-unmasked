/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
09/16/2020 05:37:54 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
09/16/2020 05:37:55 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16/2020 05:37:56 - INFO - volta.task_utils -   Loading GQA Dataset with batch size 256
09/16/2020 05:37:56 - INFO - volta.datasets.gqa_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/gqa/cache/GQA_train_26.pkl
09/16/2020 05:42:46 - INFO - volta.datasets.gqa_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/gqa/cache/GQA_val_26.pkl
09/16/2020 05:43:30 - INFO - volta.utils -   logging file at: ../../logs/volta/gqa/GQA_vilbert_base
09/16/2020 05:43:30 - INFO - volta.utils -   loading weights file /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/volta/vilbert/vilbert_base/pytorch_model_9.bin
09/16/2020 05:43:37 - INFO - volta.utils -   
09/16/2020 05:43:37 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK15.logit_fc.0.weight', 'clfs_dict.TASK15.logit_fc.0.bias', 'clfs_dict.TASK15.logit_fc.2.weight', 'clfs_dict.TASK15.logit_fc.2.bias', 'clfs_dict.TASK15.logit_fc.3.weight', 'clfs_dict.TASK15.logit_fc.3.bias']
09/16/2020 05:43:37 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
09/16/2020 05:43:46 - INFO - __main__ -   >> Trainable Parameters:
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(1024, 2048)    |2097152     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(1024, 5)       |5120        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.weight                           |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.bias                             |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                   |torch.float32    |(1024, 1024)    |1048576     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.0.weight                           |torch.float32    |(1536, 1024)    |1572864     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.0.bias                             |torch.float32    |(1536,)         |1536        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.2.weight                           |torch.float32    |(1536,)         |1536        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.2.bias                             |torch.float32    |(1536,)         |1536        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.3.weight                           |torch.float32    |(1842, 1536)    |2829312     |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.3.bias                             |torch.float32    |(1842,)         |1842        |
09/16/2020 05:43:46 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/16/2020 05:43:46 - INFO - __main__ -   >> # TrainableParams:       	240.11	M
09/16/2020 05:43:46 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
09/16/2020 05:43:46 - INFO - __main__ -   >> # TotalParams:           	240.11	M

Epoch:   0%|          | 0/8 [00:00<?, ?it/s]09/16/2020 06:05:05 - INFO - volta.utils -   Eval task TASK15 on iteration 44209 
09/16/2020 06:05:05 - INFO - volta.utils -   Validation [GQA]: loss 3.173 score 64.232 
09/16/2020 06:05:18 - INFO - volta.utils -   [GQA]: iter 44229 Ep: 12.01 loss 0.171 score 0.976 lr 1.7772e-05 
09/16/2020 06:06:38 - INFO - volta.utils -   [GQA]: iter 44249 Ep: 12.01 loss 0.159 score 0.975 lr 1.77588e-05 
09/16/2020 06:07:44 - INFO - volta.utils -   [GQA]: iter 44269 Ep: 12.02 loss 0.154 score 0.978 lr 1.77467e-05 
09/16/2020 06:09:09 - INFO - volta.utils -   [GQA]: iter 44289 Ep: 12.02 loss 0.149 score 0.981 lr 1.77346e-05 
09/16/2020 06:11:04 - INFO - volta.utils -   [GQA]: iter 44309 Ep: 12.03 loss 0.157 score 0.978 lr 1.77226e-05 
09/16/2020 06:12:24 - INFO - volta.utils -   [GQA]: iter 44329 Ep: 12.03 loss 0.141 score 0.981 lr 1.77105e-05 
09/16/2020 06:13:34 - INFO - volta.utils -   [GQA]: iter 44349 Ep: 12.04 loss 0.148 score 0.980 lr 1.76985e-05 
09/16/2020 06:14:31 - INFO - volta.utils -   [GQA]: iter 44369 Ep: 12.04 loss 0.157 score 0.978 lr 1.76864e-05 
09/16/2020 06:17:23 - INFO - volta.utils -   [GQA]: iter 44389 Ep: 12.05 loss 0.152 score 0.978 lr 1.76743e-05 
09/16/2020 06:19:01 - INFO - volta.utils -   [GQA]: iter 44409 Ep: 12.05 loss 0.151 score 0.977 lr 1.76623e-05 
09/16/2020 06:20:05 - INFO - volta.utils -   [GQA]: iter 44429 Ep: 12.06 loss 0.146 score 0.982 lr 1.76502e-05 
09/16/2020 06:21:41 - INFO - volta.utils -   [GQA]: iter 44449 Ep: 12.07 loss 0.154 score 0.979 lr 1.76381e-05 
09/16/2020 06:24:17 - INFO - volta.utils -   [GQA]: iter 44469 Ep: 12.07 loss 0.147 score 0.979 lr 1.76261e-05 
09/16/2020 06:25:41 - INFO - volta.utils -   [GQA]: iter 44489 Ep: 12.08 loss 0.136 score 0.982 lr 1.7614e-05 
09/16/2020 06:27:13 - INFO - volta.utils -   [GQA]: iter 44509 Ep: 12.08 loss 0.156 score 0.976 lr 1.76019e-05 
09/16/2020 06:28:33 - INFO - volta.utils -   [GQA]: iter 44529 Ep: 12.09 loss 0.150 score 0.979 lr 1.75899e-05 
09/16/2020 06:30:48 - INFO - volta.utils -   [GQA]: iter 44549 Ep: 12.09 loss 0.138 score 0.979 lr 1.75778e-05 
09/16/2020 06:32:31 - INFO - volta.utils -   [GQA]: iter 44569 Ep: 12.10 loss 0.140 score 0.981 lr 1.75657e-05 
09/16/2020 06:34:12 - INFO - volta.utils -   [GQA]: iter 44589 Ep: 12.10 loss 0.139 score 0.981 lr 1.75537e-05 
09/16/2020 06:35:37 - INFO - volta.utils -   [GQA]: iter 44609 Ep: 12.11 loss 0.133 score 0.982 lr 1.75416e-05 
09/16/2020 06:38:25 - INFO - volta.utils -   [GQA]: iter 44629 Ep: 12.11 loss 0.135 score 0.981 lr 1.75296e-05 
09/16/2020 06:39:45 - INFO - volta.utils -   [GQA]: iter 44649 Ep: 12.12 loss 0.145 score 0.982 lr 1.75175e-05 
09/16/2020 06:40:51 - INFO - volta.utils -   [GQA]: iter 44669 Ep: 12.13 loss 0.154 score 0.977 lr 1.75054e-05 
09/16/2020 06:42:55 - INFO - volta.utils -   [GQA]: iter 44689 Ep: 12.13 loss 0.151 score 0.977 lr 1.74934e-05 
09/16/2020 06:44:26 - INFO - volta.utils -   [GQA]: iter 44709 Ep: 12.14 loss 0.141 score 0.980 lr 1.74813e-05 
09/16/2020 06:45:41 - INFO - volta.utils -   [GQA]: iter 44729 Ep: 12.14 loss 0.155 score 0.978 lr 1.74692e-05 
09/16/2020 06:47:22 - INFO - volta.utils -   [GQA]: iter 44749 Ep: 12.15 loss 0.138 score 0.980 lr 1.74572e-05 
09/16/2020 06:48:46 - INFO - volta.utils -   [GQA]: iter 44769 Ep: 12.15 loss 0.162 score 0.978 lr 1.74451e-05 
09/16/2020 06:50:59 - INFO - volta.utils -   [GQA]: iter 44789 Ep: 12.16 loss 0.142 score 0.980 lr 1.7433e-05 
09/16/2020 06:52:38 - INFO - volta.utils -   [GQA]: iter 44809 Ep: 12.16 loss 0.134 score 0.981 lr 1.7421e-05 
09/16/2020 06:54:22 - INFO - volta.utils -   [GQA]: iter 44829 Ep: 12.17 loss 0.154 score 0.978 lr 1.74089e-05 
09/16/2020 06:55:58 - INFO - volta.utils -   [GQA]: iter 44849 Ep: 12.17 loss 0.135 score 0.979 lr 1.73969e-05 
09/16/2020 06:57:58 - INFO - volta.utils -   [GQA]: iter 44869 Ep: 12.18 loss 0.128 score 0.986 lr 1.73848e-05 
09/16/2020 06:59:39 - INFO - volta.utils -   [GQA]: iter 44889 Ep: 12.18 loss 0.151 score 0.978 lr 1.73727e-05 
09/16/2020 07:01:17 - INFO - volta.utils -   [GQA]: iter 44909 Ep: 12.19 loss 0.135 score 0.982 lr 1.73607e-05 
09/16/2020 07:02:46 - INFO - volta.utils -   [GQA]: iter 44929 Ep: 12.20 loss 0.148 score 0.979 lr 1.73486e-05 
09/16/2020 07:04:40 - INFO - volta.utils -   [GQA]: iter 44949 Ep: 12.20 loss 0.139 score 0.980 lr 1.73365e-05 
09/16/2020 07:06:23 - INFO - volta.utils -   [GQA]: iter 44969 Ep: 12.21 loss 0.147 score 0.978 lr 1.73245e-05 
09/16/2020 07:08:06 - INFO - volta.utils -   [GQA]: iter 44989 Ep: 12.21 loss 0.150 score 0.979 lr 1.73124e-05 
09/16/2020 07:09:47 - INFO - volta.utils -   [GQA]: iter 45009 Ep: 12.22 loss 0.152 score 0.977 lr 1.73003e-05 
09/16/2020 07:10:59 - INFO - volta.utils -   [GQA]: iter 45029 Ep: 12.22 loss 0.139 score 0.981 lr 1.72883e-05 
09/16/2020 07:13:13 - INFO - volta.utils -   [GQA]: iter 45049 Ep: 12.23 loss 0.151 score 0.979 lr 1.72762e-05 
09/16/2020 07:14:53 - INFO - volta.utils -   [GQA]: iter 45069 Ep: 12.23 loss 0.143 score 0.980 lr 1.72641e-05 
09/16/2020 07:16:19 - INFO - volta.utils -   [GQA]: iter 45089 Ep: 12.24 loss 0.129 score 0.982 lr 1.72521e-05 
09/16/2020 07:18:05 - INFO - volta.utils -   [GQA]: iter 45109 Ep: 12.24 loss 0.150 score 0.978 lr 1.724e-05 
09/16/2020 07:20:23 - INFO - volta.utils -   [GQA]: iter 45129 Ep: 12.25 loss 0.148 score 0.979 lr 1.7228e-05 
09/16/2020 07:22:02 - INFO - volta.utils -   [GQA]: iter 45149 Ep: 12.26 loss 0.154 score 0.978 lr 1.72159e-05 
09/16/2020 07:23:02 - INFO - volta.utils -   [GQA]: iter 45169 Ep: 12.26 loss 0.144 score 0.981 lr 1.72038e-05 
09/16/2020 07:24:42 - INFO - volta.utils -   [GQA]: iter 45189 Ep: 12.27 loss 0.160 score 0.973 lr 1.71918e-05 
09/16/2020 07:27:17 - INFO - volta.utils -   [GQA]: iter 45209 Ep: 12.27 loss 0.144 score 0.978 lr 1.71797e-05 
09/16/2020 07:28:24 - INFO - volta.utils -   [GQA]: iter 45229 Ep: 12.28 loss 0.147 score 0.978 lr 1.71676e-05 
09/16/2020 07:29:41 - INFO - volta.utils -   [GQA]: iter 45249 Ep: 12.28 loss 0.141 score 0.978 lr 1.71556e-05 
09/16/2020 07:31:20 - INFO - volta.utils -   [GQA]: iter 45269 Ep: 12.29 loss 0.148 score 0.979 lr 1.71435e-05 
09/16/2020 07:33:54 - INFO - volta.utils -   [GQA]: iter 45289 Ep: 12.29 loss 0.152 score 0.976 lr 1.71314e-05 
09/16/2020 07:35:15 - INFO - volta.utils -   [GQA]: iter 45309 Ep: 12.30 loss 0.166 score 0.978 lr 1.71194e-05 
09/16/2020 07:36:30 - INFO - volta.utils -   [GQA]: iter 45329 Ep: 12.30 loss 0.152 score 0.979 lr 1.71073e-05 
09/16/2020 07:37:58 - INFO - volta.utils -   [GQA]: iter 45349 Ep: 12.31 loss 0.155 score 0.978 lr 1.70952e-05 
09/16/2020 07:40:04 - INFO - volta.utils -   [GQA]: iter 45369 Ep: 12.32 loss 0.138 score 0.980 lr 1.70832e-05 
09/16/2020 07:41:25 - INFO - volta.utils -   [GQA]: iter 45389 Ep: 12.32 loss 0.165 score 0.975 lr 1.70711e-05 
09/16/2020 07:43:00 - INFO - volta.utils -   [GQA]: iter 45409 Ep: 12.33 loss 0.142 score 0.979 lr 1.70591e-05 
09/16/2020 07:44:27 - INFO - volta.utils -   [GQA]: iter 45429 Ep: 12.33 loss 0.143 score 0.980 lr 1.7047e-05 
09/16/2020 07:46:43 - INFO - volta.utils -   [GQA]: iter 45449 Ep: 12.34 loss 0.144 score 0.978 lr 1.70349e-05 
09/16/2020 07:48:07 - INFO - volta.utils -   [GQA]: iter 45469 Ep: 12.34 loss 0.150 score 0.977 lr 1.70229e-05 
09/16/2020 07:49:35 - INFO - volta.utils -   [GQA]: iter 45489 Ep: 12.35 loss 0.141 score 0.979 lr 1.70108e-05 
09/16/2020 07:51:10 - INFO - volta.utils -   [GQA]: iter 45509 Ep: 12.35 loss 0.143 score 0.978 lr 1.69987e-05 
09/16/2020 07:53:10 - INFO - volta.utils -   [GQA]: iter 45529 Ep: 12.36 loss 0.164 score 0.977 lr 1.69867e-05 
09/16/2020 07:54:40 - INFO - volta.utils -   [GQA]: iter 45549 Ep: 12.36 loss 0.156 score 0.976 lr 1.69746e-05 
09/16/2020 07:56:19 - INFO - volta.utils -   [GQA]: iter 45569 Ep: 12.37 loss 0.136 score 0.982 lr 1.69625e-05 
09/16/2020 07:57:58 - INFO - volta.utils -   [GQA]: iter 45589 Ep: 12.37 loss 0.147 score 0.980 lr 1.69505e-05 
09/16/2020 08:00:01 - INFO - volta.utils -   [GQA]: iter 45609 Ep: 12.38 loss 0.153 score 0.977 lr 1.69384e-05 
09/16/2020 08:02:02 - INFO - volta.utils -   [GQA]: iter 45629 Ep: 12.39 loss 0.150 score 0.977 lr 1.69263e-05 
09/16/2020 08:03:20 - INFO - volta.utils -   [GQA]: iter 45649 Ep: 12.39 loss 0.144 score 0.979 lr 1.69143e-05 
09/16/2020 08:04:58 - INFO - volta.utils -   [GQA]: iter 45669 Ep: 12.40 loss 0.160 score 0.974 lr 1.69022e-05 
09/16/2020 08:06:42 - INFO - volta.utils -   [GQA]: iter 45689 Ep: 12.40 loss 0.159 score 0.978 lr 1.68902e-05 
09/16/2020 08:09:10 - INFO - volta.utils -   [GQA]: iter 45709 Ep: 12.41 loss 0.146 score 0.979 lr 1.68781e-05 
09/16/2020 08:10:45 - INFO - volta.utils -   [GQA]: iter 45729 Ep: 12.41 loss 0.143 score 0.980 lr 1.6866e-05 
09/16/2020 08:11:56 - INFO - volta.utils -   [GQA]: iter 45749 Ep: 12.42 loss 0.157 score 0.977 lr 1.6854e-05 
09/16/2020 08:13:57 - INFO - volta.utils -   [GQA]: iter 45769 Ep: 12.42 loss 0.137 score 0.981 lr 1.68419e-05 
09/16/2020 08:15:53 - INFO - volta.utils -   [GQA]: iter 45789 Ep: 12.43 loss 0.152 score 0.979 lr 1.68298e-05 
09/16/2020 08:17:33 - INFO - volta.utils -   [GQA]: iter 45809 Ep: 12.43 loss 0.163 score 0.975 lr 1.68178e-05 
09/16/2020 08:18:54 - INFO - volta.utils -   [GQA]: iter 45829 Ep: 12.44 loss 0.144 score 0.979 lr 1.68057e-05 
09/16/2020 08:20:48 - INFO - volta.utils -   [GQA]: iter 45849 Ep: 12.45 loss 0.155 score 0.978 lr 1.67936e-05 
09/16/2020 08:22:53 - INFO - volta.utils -   [GQA]: iter 45869 Ep: 12.45 loss 0.148 score 0.979 lr 1.67816e-05 
09/16/2020 08:24:30 - INFO - volta.utils -   [GQA]: iter 45889 Ep: 12.46 loss 0.152 score 0.979 lr 1.67695e-05 
09/16/2020 08:25:57 - INFO - volta.utils -   [GQA]: iter 45909 Ep: 12.46 loss 0.156 score 0.976 lr 1.67574e-05 
09/16/2020 08:28:02 - INFO - volta.utils -   [GQA]: iter 45929 Ep: 12.47 loss 0.169 score 0.975 lr 1.67454e-05 
09/16/2020 08:29:14 - INFO - volta.utils -   [GQA]: iter 45949 Ep: 12.47 loss 0.146 score 0.979 lr 1.67333e-05 
09/16/2020 08:31:02 - INFO - volta.utils -   [GQA]: iter 45969 Ep: 12.48 loss 0.143 score 0.979 lr 1.67213e-05 
09/16/2020 08:31:52 - INFO - volta.utils -   [GQA]: iter 45989 Ep: 12.48 loss 0.157 score 0.977 lr 1.67092e-05 
09/16/2020 08:34:00 - INFO - volta.utils -   [GQA]: iter 46009 Ep: 12.49 loss 0.159 score 0.973 lr 1.66971e-05 
09/16/2020 08:35:29 - INFO - volta.utils -   [GQA]: iter 46029 Ep: 12.49 loss 0.147 score 0.980 lr 1.66851e-05 
09/16/2020 08:36:59 - INFO - volta.utils -   [GQA]: iter 46049 Ep: 12.50 loss 0.159 score 0.977 lr 1.6673e-05 
09/16/2020 08:38:34 - INFO - volta.utils -   [GQA]: iter 46069 Ep: 12.51 loss 0.158 score 0.975 lr 1.66609e-05 
09/16/2020 08:40:35 - INFO - volta.utils -   [GQA]: iter 46089 Ep: 12.51 loss 0.145 score 0.978 lr 1.66489e-05 
09/16/2020 08:41:54 - INFO - volta.utils -   [GQA]: iter 46109 Ep: 12.52 loss 0.164 score 0.976 lr 1.66368e-05 
09/16/2020 08:43:37 - INFO - volta.utils -   [GQA]: iter 46129 Ep: 12.52 loss 0.141 score 0.982 lr 1.66247e-05 
09/16/2020 08:45:12 - INFO - volta.utils -   [GQA]: iter 46149 Ep: 12.53 loss 0.152 score 0.977 lr 1.66127e-05 
09/16/2020 08:47:12 - INFO - volta.utils -   [GQA]: iter 46169 Ep: 12.53 loss 0.151 score 0.976 lr 1.66006e-05 
09/16/2020 08:48:46 - INFO - volta.utils -   [GQA]: iter 46189 Ep: 12.54 loss 0.143 score 0.980 lr 1.65886e-05 
09/16/2020 08:51:03 - INFO - volta.utils -   [GQA]: iter 46209 Ep: 12.54 loss 0.151 score 0.978 lr 1.65765e-05 
09/16/2020 08:52:33 - INFO - volta.utils -   [GQA]: iter 46229 Ep: 12.55 loss 0.159 score 0.975 lr 1.65644e-05 
09/16/2020 08:54:07 - INFO - volta.utils -   [GQA]: iter 46249 Ep: 12.55 loss 0.161 score 0.975 lr 1.65524e-05 
09/16/2020 08:55:41 - INFO - volta.utils -   [GQA]: iter 46269 Ep: 12.56 loss 0.146 score 0.978 lr 1.65403e-05 
09/16/2020 08:58:16 - INFO - volta.utils -   [GQA]: iter 46289 Ep: 12.56 loss 0.135 score 0.980 lr 1.65282e-05 
09/16/2020 08:59:15 - INFO - volta.utils -   [GQA]: iter 46309 Ep: 12.57 loss 0.145 score 0.980 lr 1.65162e-05 
09/16/2020 09:01:10 - INFO - volta.utils -   [GQA]: iter 46329 Ep: 12.58 loss 0.163 score 0.976 lr 1.65041e-05 
09/16/2020 09:02:32 - INFO - volta.utils -   [GQA]: iter 46349 Ep: 12.58 loss 0.158 score 0.976 lr 1.6492e-05 
09/16/2020 09:04:26 - INFO - volta.utils -   [GQA]: iter 46369 Ep: 12.59 loss 0.139 score 0.980 lr 1.648e-05 
09/16/2020 09:06:21 - INFO - volta.utils -   [GQA]: iter 46389 Ep: 12.59 loss 0.151 score 0.975 lr 1.64679e-05 
09/16/2020 09:07:43 - INFO - volta.utils -   [GQA]: iter 46409 Ep: 12.60 loss 0.166 score 0.976 lr 1.64558e-05 
09/16/2020 09:09:14 - INFO - volta.utils -   [GQA]: iter 46429 Ep: 12.60 loss 0.157 score 0.977 lr 1.64438e-05 
09/16/2020 09:11:11 - INFO - volta.utils -   [GQA]: iter 46449 Ep: 12.61 loss 0.169 score 0.973 lr 1.64317e-05 
09/16/2020 09:12:47 - INFO - volta.utils -   [GQA]: iter 46469 Ep: 12.61 loss 0.151 score 0.977 lr 1.64197e-05 
09/16/2020 09:14:10 - INFO - volta.utils -   [GQA]: iter 46489 Ep: 12.62 loss 0.158 score 0.976 lr 1.64076e-05 
09/16/2020 09:15:44 - INFO - volta.utils -   [GQA]: iter 46509 Ep: 12.62 loss 0.168 score 0.974 lr 1.63955e-05 
09/16/2020 09:17:54 - INFO - volta.utils -   [GQA]: iter 46529 Ep: 12.63 loss 0.181 score 0.971 lr 1.63835e-05 
09/16/2020 09:19:31 - INFO - volta.utils -   [GQA]: iter 46549 Ep: 12.64 loss 0.157 score 0.978 lr 1.63714e-05 
09/16/2020 09:20:59 - INFO - volta.utils -   [GQA]: iter 46569 Ep: 12.64 loss 0.154 score 0.976 lr 1.63593e-05 
09/16/2020 09:22:42 - INFO - volta.utils -   [GQA]: iter 46589 Ep: 12.65 loss 0.145 score 0.978 lr 1.63473e-05 
09/16/2020 09:24:44 - INFO - volta.utils -   [GQA]: iter 46609 Ep: 12.65 loss 0.151 score 0.976 lr 1.63352e-05 
09/16/2020 09:26:12 - INFO - volta.utils -   [GQA]: iter 46629 Ep: 12.66 loss 0.156 score 0.976 lr 1.63231e-05 
09/16/2020 09:26:58 - INFO - volta.utils -   [GQA]: iter 46649 Ep: 12.66 loss 0.149 score 0.977 lr 1.63111e-05 
09/16/2020 09:28:30 - INFO - volta.utils -   [GQA]: iter 46669 Ep: 12.67 loss 0.155 score 0.976 lr 1.6299e-05 
09/16/2020 09:31:46 - INFO - volta.utils -   [GQA]: iter 46689 Ep: 12.67 loss 0.150 score 0.979 lr 1.62869e-05 
09/16/2020 09:33:11 - INFO - volta.utils -   [GQA]: iter 46709 Ep: 12.68 loss 0.165 score 0.976 lr 1.62749e-05 
09/16/2020 09:34:30 - INFO - volta.utils -   [GQA]: iter 46729 Ep: 12.68 loss 0.161 score 0.976 lr 1.62628e-05 
09/16/2020 09:35:46 - INFO - volta.utils -   [GQA]: iter 46749 Ep: 12.69 loss 0.159 score 0.977 lr 1.62508e-05 
09/16/2020 09:38:08 - INFO - volta.utils -   [GQA]: iter 46769 Ep: 12.70 loss 0.166 score 0.975 lr 1.62387e-05 
09/16/2020 09:39:45 - INFO - volta.utils -   [GQA]: iter 46789 Ep: 12.70 loss 0.142 score 0.980 lr 1.62266e-05 
09/16/2020 09:41:20 - INFO - volta.utils -   [GQA]: iter 46809 Ep: 12.71 loss 0.157 score 0.976 lr 1.62146e-05 
09/16/2020 09:42:53 - INFO - volta.utils -   [GQA]: iter 46829 Ep: 12.71 loss 0.140 score 0.979 lr 1.62025e-05 
09/16/2020 09:44:20 - INFO - volta.utils -   [GQA]: iter 46849 Ep: 12.72 loss 0.154 score 0.977 lr 1.61904e-05 
09/16/2020 09:46:59 - INFO - volta.utils -   [GQA]: iter 46869 Ep: 12.72 loss 0.148 score 0.980 lr 1.61784e-05 
09/16/2020 09:48:31 - INFO - volta.utils -   [GQA]: iter 46889 Ep: 12.73 loss 0.141 score 0.980 lr 1.61663e-05 
09/16/2020 09:50:22 - INFO - volta.utils -   [GQA]: iter 46909 Ep: 12.73 loss 0.159 score 0.977 lr 1.61542e-05 
09/16/2020 09:51:21 - INFO - volta.utils -   [GQA]: iter 46929 Ep: 12.74 loss 0.155 score 0.977 lr 1.61422e-05 
09/16/2020 09:53:53 - INFO - volta.utils -   [GQA]: iter 46949 Ep: 12.74 loss 0.147 score 0.978 lr 1.61301e-05 
09/16/2020 09:55:09 - INFO - volta.utils -   [GQA]: iter 46969 Ep: 12.75 loss 0.156 score 0.977 lr 1.6118e-05 
09/16/2020 09:56:01 - INFO - volta.utils -   [GQA]: iter 46989 Ep: 12.75 loss 0.141 score 0.980 lr 1.6106e-05 
09/16/2020 09:57:39 - INFO - volta.utils -   [GQA]: iter 47009 Ep: 12.76 loss 0.163 score 0.973 lr 1.60939e-05 
09/16/2020 09:59:53 - INFO - volta.utils -   [GQA]: iter 47029 Ep: 12.77 loss 0.153 score 0.975 lr 1.60819e-05 
09/16/2020 10:01:36 - INFO - volta.utils -   [GQA]: iter 47049 Ep: 12.77 loss 0.163 score 0.974 lr 1.60698e-05 
09/16/2020 10:03:10 - INFO - volta.utils -   [GQA]: iter 47069 Ep: 12.78 loss 0.157 score 0.976 lr 1.60577e-05 
09/16/2020 10:04:30 - INFO - volta.utils -   [GQA]: iter 47089 Ep: 12.78 loss 0.156 score 0.977 lr 1.60457e-05 
09/16/2020 10:06:51 - INFO - volta.utils -   [GQA]: iter 47109 Ep: 12.79 loss 0.171 score 0.973 lr 1.60336e-05 
09/16/2020 10:07:57 - INFO - volta.utils -   [GQA]: iter 47129 Ep: 12.79 loss 0.138 score 0.979 lr 1.60215e-05 
09/16/2020 10:09:28 - INFO - volta.utils -   [GQA]: iter 47149 Ep: 12.80 loss 0.168 score 0.972 lr 1.60095e-05 
09/16/2020 10:10:56 - INFO - volta.utils -   [GQA]: iter 47169 Ep: 12.80 loss 0.163 score 0.975 lr 1.59974e-05 
09/16/2020 10:13:04 - INFO - volta.utils -   [GQA]: iter 47189 Ep: 12.81 loss 0.164 score 0.974 lr 1.59853e-05 
09/16/2020 10:14:37 - INFO - volta.utils -   [GQA]: iter 47209 Ep: 12.81 loss 0.149 score 0.978 lr 1.59733e-05 
09/16/2020 10:16:15 - INFO - volta.utils -   [GQA]: iter 47229 Ep: 12.82 loss 0.148 score 0.977 lr 1.59612e-05 
09/16/2020 10:17:24 - INFO - volta.utils -   [GQA]: iter 47249 Ep: 12.83 loss 0.160 score 0.973 lr 1.59491e-05 
09/16/2020 10:20:00 - INFO - volta.utils -   [GQA]: iter 47269 Ep: 12.83 loss 0.148 score 0.976 lr 1.59371e-05 
09/16/2020 10:21:30 - INFO - volta.utils -   [GQA]: iter 47289 Ep: 12.84 loss 0.137 score 0.979 lr 1.5925e-05 
09/16/2020 10:22:41 - INFO - volta.utils -   [GQA]: iter 47309 Ep: 12.84 loss 0.155 score 0.977 lr 1.5913e-05 
09/16/2020 10:24:24 - INFO - volta.utils -   [GQA]: iter 47329 Ep: 12.85 loss 0.140 score 0.979 lr 1.59009e-05 
09/16/2020 10:26:33 - INFO - volta.utils -   [GQA]: iter 47349 Ep: 12.85 loss 0.152 score 0.975 lr 1.58888e-05 
09/16/2020 10:28:21 - INFO - volta.utils -   [GQA]: iter 47369 Ep: 12.86 loss 0.150 score 0.979 lr 1.58768e-05 
09/16/2020 10:29:52 - INFO - volta.utils -   [GQA]: iter 47389 Ep: 12.86 loss 0.167 score 0.976 lr 1.58647e-05 
09/16/2020 10:31:49 - INFO - volta.utils -   [GQA]: iter 47409 Ep: 12.87 loss 0.163 score 0.977 lr 1.58526e-05 
09/16/2020 10:33:36 - INFO - volta.utils -   [GQA]: iter 47429 Ep: 12.87 loss 0.149 score 0.979 lr 1.58406e-05 
09/16/2020 10:35:15 - INFO - volta.utils -   [GQA]: iter 47449 Ep: 12.88 loss 0.187 score 0.971 lr 1.58285e-05 
09/16/2020 10:36:50 - INFO - volta.utils -   [GQA]: iter 47469 Ep: 12.89 loss 0.169 score 0.976 lr 1.58164e-05 
09/16/2020 10:38:40 - INFO - volta.utils -   [GQA]: iter 47489 Ep: 12.89 loss 0.152 score 0.977 lr 1.58044e-05 
09/16/2020 10:40:35 - INFO - volta.utils -   [GQA]: iter 47509 Ep: 12.90 loss 0.162 score 0.974 lr 1.57923e-05 
09/16/2020 10:41:45 - INFO - volta.utils -   [GQA]: iter 47529 Ep: 12.90 loss 0.163 score 0.975 lr 1.57803e-05 
09/16/2020 10:43:22 - INFO - volta.utils -   [GQA]: iter 47549 Ep: 12.91 loss 0.150 score 0.977 lr 1.57682e-05 
09/16/2020 10:45:34 - INFO - volta.utils -   [GQA]: iter 47569 Ep: 12.91 loss 0.174 score 0.974 lr 1.57561e-05 
09/16/2020 10:47:33 - INFO - volta.utils -   [GQA]: iter 47589 Ep: 12.92 loss 0.152 score 0.977 lr 1.57441e-05 
09/16/2020 10:49:14 - INFO - volta.utils -   [GQA]: iter 47609 Ep: 12.92 loss 0.167 score 0.974 lr 1.5732e-05 
09/16/2020 10:50:47 - INFO - volta.utils -   [GQA]: iter 47629 Ep: 12.93 loss 0.163 score 0.975 lr 1.57199e-05 
09/16/2020 10:53:10 - INFO - volta.utils -   [GQA]: iter 47649 Ep: 12.93 loss 0.158 score 0.977 lr 1.57079e-05 
09/16/2020 10:54:43 - INFO - volta.utils -   [GQA]: iter 47669 Ep: 12.94 loss 0.155 score 0.975 lr 1.56958e-05 
09/16/2020 10:56:06 - INFO - volta.utils -   [GQA]: iter 47689 Ep: 12.94 loss 0.152 score 0.978 lr 1.56837e-05 
09/16/2020 10:57:20 - INFO - volta.utils -   [GQA]: iter 47709 Ep: 12.95 loss 0.149 score 0.976 lr 1.56717e-05 
09/16/2020 10:59:14 - INFO - volta.utils -   [GQA]: iter 47729 Ep: 12.96 loss 0.146 score 0.980 lr 1.56596e-05 
09/16/2020 11:00:31 - INFO - volta.utils -   [GQA]: iter 47749 Ep: 12.96 loss 0.164 score 0.977 lr 1.56475e-05 
09/16/2020 11:01:44 - INFO - volta.utils -   [GQA]: iter 47769 Ep: 12.97 loss 0.156 score 0.975 lr 1.56355e-05 
09/16/2020 11:03:46 - INFO - volta.utils -   [GQA]: iter 47789 Ep: 12.97 loss 0.154 score 0.976 lr 1.56234e-05 
09/16/2020 11:05:12 - INFO - volta.utils -   [GQA]: iter 47809 Ep: 12.98 loss 0.162 score 0.974 lr 1.56114e-05 
09/16/2020 11:07:43 - INFO - volta.utils -   [GQA]: iter 47829 Ep: 12.98 loss 0.145 score 0.978 lr 1.55993e-05 
09/16/2020 11:09:15 - INFO - volta.utils -   [GQA]: iter 47849 Ep: 12.99 loss 0.142 score 0.977 lr 1.55872e-05 
09/16/2020 11:10:39 - INFO - volta.utils -   [GQA]: iter 47869 Ep: 12.99 loss 0.149 score 0.978 lr 1.55752e-05 
09/16/2020 11:11:50 - INFO - volta.utils -   [GQA]: iter 47889 Ep: 13.00 loss 0.149 score 0.978 lr 1.55631e-05 
09/16/2020 11:12:00 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  12%|█▎        | 1/8 [5:28:22<38:18:34, 19702.03s/it]09/16/2020 11:31:46 - INFO - volta.utils -   Eval task TASK15 on iteration 47893 
09/16/2020 11:31:46 - INFO - volta.utils -   Validation [GQA]: loss 3.485 score 64.349 
09/16/2020 11:32:00 - INFO - volta.utils -   [GQA]: iter 47913 Ep: 13.01 loss 0.129 score 0.983 lr 1.55498e-05 
09/16/2020 11:33:08 - INFO - volta.utils -   [GQA]: iter 47933 Ep: 13.01 loss 0.104 score 0.987 lr 1.55366e-05 
09/16/2020 11:34:42 - INFO - volta.utils -   [GQA]: iter 47953 Ep: 13.02 loss 0.115 score 0.984 lr 1.55245e-05 
09/16/2020 11:36:09 - INFO - volta.utils -   [GQA]: iter 47973 Ep: 13.02 loss 0.121 score 0.984 lr 1.55124e-05 
09/16/2020 11:37:48 - INFO - volta.utils -   [GQA]: iter 47993 Ep: 13.03 loss 0.111 score 0.987 lr 1.55004e-05 
09/16/2020 11:39:13 - INFO - volta.utils -   [GQA]: iter 48013 Ep: 13.03 loss 0.104 score 0.986 lr 1.54883e-05 
09/16/2020 11:40:38 - INFO - volta.utils -   [GQA]: iter 48033 Ep: 13.04 loss 0.105 score 0.987 lr 1.54762e-05 
09/16/2020 11:41:53 - INFO - volta.utils -   [GQA]: iter 48053 Ep: 13.04 loss 0.098 score 0.989 lr 1.54642e-05 
09/16/2020 11:44:09 - INFO - volta.utils -   [GQA]: iter 48073 Ep: 13.05 loss 0.095 score 0.988 lr 1.54521e-05 
09/16/2020 11:46:03 - INFO - volta.utils -   [GQA]: iter 48093 Ep: 13.05 loss 0.103 score 0.986 lr 1.544e-05 
09/16/2020 11:47:11 - INFO - volta.utils -   [GQA]: iter 48113 Ep: 13.06 loss 0.101 score 0.988 lr 1.5428e-05 
09/16/2020 11:48:38 - INFO - volta.utils -   [GQA]: iter 48133 Ep: 13.07 loss 0.101 score 0.988 lr 1.54159e-05 
09/16/2020 11:50:44 - INFO - volta.utils -   [GQA]: iter 48153 Ep: 13.07 loss 0.108 score 0.986 lr 1.54038e-05 
09/16/2020 11:52:22 - INFO - volta.utils -   [GQA]: iter 48173 Ep: 13.08 loss 0.103 score 0.988 lr 1.53918e-05 
09/16/2020 11:53:51 - INFO - volta.utils -   [GQA]: iter 48193 Ep: 13.08 loss 0.101 score 0.989 lr 1.53797e-05 
09/16/2020 11:55:18 - INFO - volta.utils -   [GQA]: iter 48213 Ep: 13.09 loss 0.111 score 0.987 lr 1.53677e-05 
09/16/2020 11:57:28 - INFO - volta.utils -   [GQA]: iter 48233 Ep: 13.09 loss 0.115 score 0.983 lr 1.53556e-05 
09/16/2020 11:59:12 - INFO - volta.utils -   [GQA]: iter 48253 Ep: 13.10 loss 0.098 score 0.987 lr 1.53435e-05 
09/16/2020 12:00:32 - INFO - volta.utils -   [GQA]: iter 48273 Ep: 13.10 loss 0.099 score 0.987 lr 1.53315e-05 
09/16/2020 12:01:55 - INFO - volta.utils -   [GQA]: iter 48293 Ep: 13.11 loss 0.104 score 0.988 lr 1.53194e-05 
09/16/2020 12:03:40 - INFO - volta.utils -   [GQA]: iter 48313 Ep: 13.11 loss 0.092 score 0.988 lr 1.53073e-05 
09/16/2020 12:05:44 - INFO - volta.utils -   [GQA]: iter 48333 Ep: 13.12 loss 0.097 score 0.987 lr 1.52953e-05 
09/16/2020 12:07:10 - INFO - volta.utils -   [GQA]: iter 48353 Ep: 13.13 loss 0.092 score 0.988 lr 1.52832e-05 
09/16/2020 12:08:41 - INFO - volta.utils -   [GQA]: iter 48373 Ep: 13.13 loss 0.116 score 0.984 lr 1.52711e-05 
09/16/2020 12:10:29 - INFO - volta.utils -   [GQA]: iter 48393 Ep: 13.14 loss 0.108 score 0.986 lr 1.52591e-05 
09/16/2020 12:12:26 - INFO - volta.utils -   [GQA]: iter 48413 Ep: 13.14 loss 0.109 score 0.987 lr 1.5247e-05 
09/16/2020 12:14:27 - INFO - volta.utils -   [GQA]: iter 48433 Ep: 13.15 loss 0.113 score 0.985 lr 1.52349e-05 
09/16/2020 12:16:05 - INFO - volta.utils -   [GQA]: iter 48453 Ep: 13.15 loss 0.110 score 0.986 lr 1.52229e-05 
09/16/2020 12:17:39 - INFO - volta.utils -   [GQA]: iter 48473 Ep: 13.16 loss 0.119 score 0.985 lr 1.52108e-05 
09/16/2020 12:20:24 - INFO - volta.utils -   [GQA]: iter 48493 Ep: 13.16 loss 0.112 score 0.984 lr 1.51988e-05 
09/16/2020 12:21:47 - INFO - volta.utils -   [GQA]: iter 48513 Ep: 13.17 loss 0.100 score 0.987 lr 1.51867e-05 
09/16/2020 12:22:53 - INFO - volta.utils -   [GQA]: iter 48533 Ep: 13.17 loss 0.114 score 0.984 lr 1.51746e-05 
09/16/2020 12:24:09 - INFO - volta.utils -   [GQA]: iter 48553 Ep: 13.18 loss 0.118 score 0.983 lr 1.51626e-05 
09/16/2020 12:26:58 - INFO - volta.utils -   [GQA]: iter 48573 Ep: 13.18 loss 0.109 score 0.987 lr 1.51505e-05 
09/16/2020 12:28:30 - INFO - volta.utils -   [GQA]: iter 48593 Ep: 13.19 loss 0.107 score 0.985 lr 1.51384e-05 
09/16/2020 12:29:51 - INFO - volta.utils -   [GQA]: iter 48613 Ep: 13.20 loss 0.100 score 0.987 lr 1.51264e-05 
09/16/2020 12:31:01 - INFO - volta.utils -   [GQA]: iter 48633 Ep: 13.20 loss 0.110 score 0.985 lr 1.51143e-05 
09/16/2020 12:33:20 - INFO - volta.utils -   [GQA]: iter 48653 Ep: 13.21 loss 0.116 score 0.984 lr 1.51022e-05 
09/16/2020 12:34:05 - INFO - volta.utils -   [GQA]: iter 48673 Ep: 13.21 loss 0.108 score 0.986 lr 1.50902e-05 
09/16/2020 12:35:32 - INFO - volta.utils -   [GQA]: iter 48693 Ep: 13.22 loss 0.114 score 0.986 lr 1.50781e-05 
09/16/2020 12:36:44 - INFO - volta.utils -   [GQA]: iter 48713 Ep: 13.22 loss 0.108 score 0.987 lr 1.50661e-05 
09/16/2020 12:39:09 - INFO - volta.utils -   [GQA]: iter 48733 Ep: 13.23 loss 0.119 score 0.983 lr 1.5054e-05 
09/16/2020 12:40:26 - INFO - volta.utils -   [GQA]: iter 48753 Ep: 13.23 loss 0.106 score 0.987 lr 1.50419e-05 
09/16/2020 12:41:51 - INFO - volta.utils -   [GQA]: iter 48773 Ep: 13.24 loss 0.114 score 0.984 lr 1.50299e-05 
09/16/2020 12:43:18 - INFO - volta.utils -   [GQA]: iter 48793 Ep: 13.24 loss 0.118 score 0.984 lr 1.50178e-05 
09/16/2020 12:45:33 - INFO - volta.utils -   [GQA]: iter 48813 Ep: 13.25 loss 0.113 score 0.983 lr 1.50057e-05 
09/16/2020 12:47:11 - INFO - volta.utils -   [GQA]: iter 48833 Ep: 13.26 loss 0.115 score 0.985 lr 1.49937e-05 
09/16/2020 12:48:42 - INFO - volta.utils -   [GQA]: iter 48853 Ep: 13.26 loss 0.108 score 0.985 lr 1.49816e-05 
09/16/2020 12:50:17 - INFO - volta.utils -   [GQA]: iter 48873 Ep: 13.27 loss 0.112 score 0.985 lr 1.49695e-05 
09/16/2020 12:53:21 - INFO - volta.utils -   [GQA]: iter 48893 Ep: 13.27 loss 0.105 score 0.985 lr 1.49575e-05 
09/16/2020 12:54:54 - INFO - volta.utils -   [GQA]: iter 48913 Ep: 13.28 loss 0.113 score 0.985 lr 1.49454e-05 
09/16/2020 12:56:04 - INFO - volta.utils -   [GQA]: iter 48933 Ep: 13.28 loss 0.101 score 0.987 lr 1.49333e-05 
09/16/2020 12:57:28 - INFO - volta.utils -   [GQA]: iter 48953 Ep: 13.29 loss 0.110 score 0.985 lr 1.49213e-05 
09/16/2020 12:59:56 - INFO - volta.utils -   [GQA]: iter 48973 Ep: 13.29 loss 0.112 score 0.985 lr 1.49092e-05 
09/16/2020 13:01:10 - INFO - volta.utils -   [GQA]: iter 48993 Ep: 13.30 loss 0.100 score 0.987 lr 1.48972e-05 
09/16/2020 13:02:45 - INFO - volta.utils -   [GQA]: iter 49013 Ep: 13.30 loss 0.120 score 0.983 lr 1.48851e-05 
09/16/2020 13:04:31 - INFO - volta.utils -   [GQA]: iter 49033 Ep: 13.31 loss 0.109 score 0.984 lr 1.4873e-05 
09/16/2020 13:07:10 - INFO - volta.utils -   [GQA]: iter 49053 Ep: 13.32 loss 0.101 score 0.987 lr 1.4861e-05 
09/16/2020 13:08:29 - INFO - volta.utils -   [GQA]: iter 49073 Ep: 13.32 loss 0.115 score 0.982 lr 1.48489e-05 
09/16/2020 13:09:56 - INFO - volta.utils -   [GQA]: iter 49093 Ep: 13.33 loss 0.122 score 0.984 lr 1.48368e-05 
09/16/2020 13:11:21 - INFO - volta.utils -   [GQA]: iter 49113 Ep: 13.33 loss 0.123 score 0.984 lr 1.48248e-05 
09/16/2020 13:14:15 - INFO - volta.utils -   [GQA]: iter 49133 Ep: 13.34 loss 0.104 score 0.986 lr 1.48127e-05 
09/16/2020 13:15:27 - INFO - volta.utils -   [GQA]: iter 49153 Ep: 13.34 loss 0.099 score 0.988 lr 1.48006e-05 
09/16/2020 13:16:43 - INFO - volta.utils -   [GQA]: iter 49173 Ep: 13.35 loss 0.123 score 0.983 lr 1.47886e-05 
09/16/2020 13:18:11 - INFO - volta.utils -   [GQA]: iter 49193 Ep: 13.35 loss 0.125 score 0.982 lr 1.47765e-05 
09/16/2020 13:20:51 - INFO - volta.utils -   [GQA]: iter 49213 Ep: 13.36 loss 0.108 score 0.985 lr 1.47644e-05 
09/16/2020 13:22:19 - INFO - volta.utils -   [GQA]: iter 49233 Ep: 13.36 loss 0.122 score 0.983 lr 1.47524e-05 
09/16/2020 13:23:40 - INFO - volta.utils -   [GQA]: iter 49253 Ep: 13.37 loss 0.120 score 0.983 lr 1.47403e-05 
09/16/2020 13:24:59 - INFO - volta.utils -   [GQA]: iter 49273 Ep: 13.37 loss 0.113 score 0.985 lr 1.47283e-05 
09/16/2020 13:27:38 - INFO - volta.utils -   [GQA]: iter 49293 Ep: 13.38 loss 0.110 score 0.987 lr 1.47162e-05 
09/16/2020 13:28:22 - INFO - volta.utils -   [GQA]: iter 49313 Ep: 13.39 loss 0.111 score 0.984 lr 1.47041e-05 
09/16/2020 13:29:46 - INFO - volta.utils -   [GQA]: iter 49333 Ep: 13.39 loss 0.101 score 0.986 lr 1.46921e-05 
09/16/2020 13:30:29 - INFO - volta.utils -   [GQA]: iter 49353 Ep: 13.40 loss 0.120 score 0.985 lr 1.468e-05 
09/16/2020 13:32:51 - INFO - volta.utils -   [GQA]: iter 49373 Ep: 13.40 loss 0.102 score 0.987 lr 1.46679e-05 
09/16/2020 13:34:16 - INFO - volta.utils -   [GQA]: iter 49393 Ep: 13.41 loss 0.103 score 0.987 lr 1.46559e-05 
09/16/2020 13:35:45 - INFO - volta.utils -   [GQA]: iter 49413 Ep: 13.41 loss 0.097 score 0.989 lr 1.46438e-05 
09/16/2020 13:37:22 - INFO - volta.utils -   [GQA]: iter 49433 Ep: 13.42 loss 0.118 score 0.982 lr 1.46317e-05 
09/16/2020 13:39:07 - INFO - volta.utils -   [GQA]: iter 49453 Ep: 13.42 loss 0.123 score 0.983 lr 1.46197e-05 
09/16/2020 13:40:37 - INFO - volta.utils -   [GQA]: iter 49473 Ep: 13.43 loss 0.123 score 0.985 lr 1.46076e-05 
09/16/2020 13:43:08 - INFO - volta.utils -   [GQA]: iter 49493 Ep: 13.43 loss 0.106 score 0.987 lr 1.45955e-05 
09/16/2020 13:44:26 - INFO - volta.utils -   [GQA]: iter 49513 Ep: 13.44 loss 0.114 score 0.984 lr 1.45835e-05 
09/16/2020 13:46:03 - INFO - volta.utils -   [GQA]: iter 49533 Ep: 13.45 loss 0.104 score 0.986 lr 1.45714e-05 
09/16/2020 13:47:49 - INFO - volta.utils -   [GQA]: iter 49553 Ep: 13.45 loss 0.124 score 0.982 lr 1.45594e-05 
09/16/2020 13:50:36 - INFO - volta.utils -   [GQA]: iter 49573 Ep: 13.46 loss 0.115 score 0.984 lr 1.45473e-05 
09/16/2020 13:52:14 - INFO - volta.utils -   [GQA]: iter 49593 Ep: 13.46 loss 0.103 score 0.988 lr 1.45352e-05 
09/16/2020 13:53:16 - INFO - volta.utils -   [GQA]: iter 49613 Ep: 13.47 loss 0.100 score 0.987 lr 1.45232e-05 
09/16/2020 13:55:16 - INFO - volta.utils -   [GQA]: iter 49633 Ep: 13.47 loss 0.098 score 0.987 lr 1.45111e-05 
09/16/2020 13:57:21 - INFO - volta.utils -   [GQA]: iter 49653 Ep: 13.48 loss 0.114 score 0.984 lr 1.4499e-05 
09/16/2020 13:59:08 - INFO - volta.utils -   [GQA]: iter 49673 Ep: 13.48 loss 0.119 score 0.983 lr 1.4487e-05 
09/16/2020 14:00:23 - INFO - volta.utils -   [GQA]: iter 49693 Ep: 13.49 loss 0.119 score 0.985 lr 1.44749e-05 
09/16/2020 14:01:22 - INFO - volta.utils -   [GQA]: iter 49713 Ep: 13.49 loss 0.117 score 0.982 lr 1.44628e-05 
09/16/2020 14:03:41 - INFO - volta.utils -   [GQA]: iter 49733 Ep: 13.50 loss 0.122 score 0.982 lr 1.44508e-05 
09/16/2020 14:05:28 - INFO - volta.utils -   [GQA]: iter 49753 Ep: 13.51 loss 0.113 score 0.985 lr 1.44387e-05 
09/16/2020 14:07:02 - INFO - volta.utils -   [GQA]: iter 49773 Ep: 13.51 loss 0.114 score 0.986 lr 1.44266e-05 
09/16/2020 14:08:08 - INFO - volta.utils -   [GQA]: iter 49793 Ep: 13.52 loss 0.113 score 0.983 lr 1.44146e-05 
09/16/2020 14:11:01 - INFO - volta.utils -   [GQA]: iter 49813 Ep: 13.52 loss 0.118 score 0.984 lr 1.44025e-05 
09/16/2020 14:12:35 - INFO - volta.utils -   [GQA]: iter 49833 Ep: 13.53 loss 0.123 score 0.983 lr 1.43905e-05 
09/16/2020 14:14:21 - INFO - volta.utils -   [GQA]: iter 49853 Ep: 13.53 loss 0.136 score 0.982 lr 1.43784e-05 
09/16/2020 14:16:12 - INFO - volta.utils -   [GQA]: iter 49873 Ep: 13.54 loss 0.122 score 0.986 lr 1.43663e-05 
09/16/2020 14:18:45 - INFO - volta.utils -   [GQA]: iter 49893 Ep: 13.54 loss 0.118 score 0.984 lr 1.43543e-05 
09/16/2020 14:20:21 - INFO - volta.utils -   [GQA]: iter 49913 Ep: 13.55 loss 0.115 score 0.983 lr 1.43422e-05 
09/16/2020 14:21:43 - INFO - volta.utils -   [GQA]: iter 49933 Ep: 13.55 loss 0.105 score 0.985 lr 1.43301e-05 
09/16/2020 14:22:59 - INFO - volta.utils -   [GQA]: iter 49953 Ep: 13.56 loss 0.125 score 0.983 lr 1.43181e-05 
09/16/2020 14:25:32 - INFO - volta.utils -   [GQA]: iter 49973 Ep: 13.56 loss 0.125 score 0.982 lr 1.4306e-05 
09/16/2020 14:27:15 - INFO - volta.utils -   [GQA]: iter 49993 Ep: 13.57 loss 0.114 score 0.984 lr 1.42939e-05 
09/16/2020 14:28:04 - INFO - volta.utils -   [GQA]: iter 50013 Ep: 13.58 loss 0.114 score 0.984 lr 1.42819e-05 
09/16/2020 14:29:27 - INFO - volta.utils -   [GQA]: iter 50033 Ep: 13.58 loss 0.115 score 0.984 lr 1.42698e-05 
09/16/2020 14:31:30 - INFO - volta.utils -   [GQA]: iter 50053 Ep: 13.59 loss 0.104 score 0.985 lr 1.42578e-05 
09/16/2020 14:33:04 - INFO - volta.utils -   [GQA]: iter 50073 Ep: 13.59 loss 0.117 score 0.985 lr 1.42457e-05 
09/16/2020 14:34:48 - INFO - volta.utils -   [GQA]: iter 50093 Ep: 13.60 loss 0.115 score 0.983 lr 1.42336e-05 
09/16/2020 14:36:23 - INFO - volta.utils -   [GQA]: iter 50113 Ep: 13.60 loss 0.118 score 0.983 lr 1.42216e-05 
09/16/2020 14:38:28 - INFO - volta.utils -   [GQA]: iter 50133 Ep: 13.61 loss 0.118 score 0.984 lr 1.42095e-05 
09/16/2020 14:40:41 - INFO - volta.utils -   [GQA]: iter 50153 Ep: 13.61 loss 0.110 score 0.985 lr 1.41974e-05 
09/16/2020 14:42:25 - INFO - volta.utils -   [GQA]: iter 50173 Ep: 13.62 loss 0.115 score 0.982 lr 1.41854e-05 
09/16/2020 14:43:40 - INFO - volta.utils -   [GQA]: iter 50193 Ep: 13.62 loss 0.129 score 0.982 lr 1.41733e-05 
09/16/2020 14:44:47 - INFO - volta.utils -   [GQA]: iter 50213 Ep: 13.63 loss 0.114 score 0.984 lr 1.41612e-05 
09/16/2020 14:47:22 - INFO - volta.utils -   [GQA]: iter 50233 Ep: 13.64 loss 0.122 score 0.982 lr 1.41492e-05 
09/16/2020 14:49:38 - INFO - volta.utils -   [GQA]: iter 50253 Ep: 13.64 loss 0.117 score 0.982 lr 1.41371e-05 
09/16/2020 14:51:13 - INFO - volta.utils -   [GQA]: iter 50273 Ep: 13.65 loss 0.102 score 0.987 lr 1.4125e-05 
09/16/2020 14:52:23 - INFO - volta.utils -   [GQA]: iter 50293 Ep: 13.65 loss 0.109 score 0.986 lr 1.4113e-05 
09/16/2020 14:53:46 - INFO - volta.utils -   [GQA]: iter 50313 Ep: 13.66 loss 0.109 score 0.984 lr 1.41009e-05 
09/16/2020 14:56:18 - INFO - volta.utils -   [GQA]: iter 50333 Ep: 13.66 loss 0.119 score 0.984 lr 1.40889e-05 
09/16/2020 14:57:51 - INFO - volta.utils -   [GQA]: iter 50353 Ep: 13.67 loss 0.116 score 0.982 lr 1.40768e-05 
09/16/2020 14:59:17 - INFO - volta.utils -   [GQA]: iter 50373 Ep: 13.67 loss 0.120 score 0.981 lr 1.40647e-05 
09/16/2020 15:00:49 - INFO - volta.utils -   [GQA]: iter 50393 Ep: 13.68 loss 0.123 score 0.982 lr 1.40527e-05 
09/16/2020 15:03:15 - INFO - volta.utils -   [GQA]: iter 50413 Ep: 13.68 loss 0.122 score 0.983 lr 1.40406e-05 
09/16/2020 15:04:42 - INFO - volta.utils -   [GQA]: iter 50433 Ep: 13.69 loss 0.118 score 0.984 lr 1.40285e-05 
09/16/2020 15:06:06 - INFO - volta.utils -   [GQA]: iter 50453 Ep: 13.70 loss 0.121 score 0.983 lr 1.40165e-05 
09/16/2020 15:07:58 - INFO - volta.utils -   [GQA]: iter 50473 Ep: 13.70 loss 0.127 score 0.981 lr 1.40044e-05 
09/16/2020 15:09:47 - INFO - volta.utils -   [GQA]: iter 50493 Ep: 13.71 loss 0.113 score 0.982 lr 1.39923e-05 
09/16/2020 15:11:20 - INFO - volta.utils -   [GQA]: iter 50513 Ep: 13.71 loss 0.110 score 0.985 lr 1.39803e-05 
09/16/2020 15:12:43 - INFO - volta.utils -   [GQA]: iter 50533 Ep: 13.72 loss 0.124 score 0.982 lr 1.39682e-05 
09/16/2020 15:14:29 - INFO - volta.utils -   [GQA]: iter 50553 Ep: 13.72 loss 0.108 score 0.985 lr 1.39561e-05 
09/16/2020 15:16:20 - INFO - volta.utils -   [GQA]: iter 50573 Ep: 13.73 loss 0.116 score 0.984 lr 1.39441e-05 
09/16/2020 15:17:30 - INFO - volta.utils -   [GQA]: iter 50593 Ep: 13.73 loss 0.117 score 0.983 lr 1.3932e-05 
09/16/2020 15:19:26 - INFO - volta.utils -   [GQA]: iter 50613 Ep: 13.74 loss 0.113 score 0.983 lr 1.392e-05 
09/16/2020 15:21:21 - INFO - volta.utils -   [GQA]: iter 50633 Ep: 13.74 loss 0.116 score 0.984 lr 1.39079e-05 
09/16/2020 15:22:53 - INFO - volta.utils -   [GQA]: iter 50653 Ep: 13.75 loss 0.127 score 0.981 lr 1.38958e-05 
09/16/2020 15:24:51 - INFO - volta.utils -   [GQA]: iter 50673 Ep: 13.75 loss 0.128 score 0.985 lr 1.38838e-05 
09/16/2020 15:25:40 - INFO - volta.utils -   [GQA]: iter 50693 Ep: 13.76 loss 0.113 score 0.985 lr 1.38717e-05 
09/16/2020 15:28:08 - INFO - volta.utils -   [GQA]: iter 50713 Ep: 13.77 loss 0.106 score 0.984 lr 1.38596e-05 
09/16/2020 15:29:12 - INFO - volta.utils -   [GQA]: iter 50733 Ep: 13.77 loss 0.108 score 0.985 lr 1.38476e-05 
09/16/2020 15:30:53 - INFO - volta.utils -   [GQA]: iter 50753 Ep: 13.78 loss 0.116 score 0.984 lr 1.38355e-05 
09/16/2020 15:33:02 - INFO - volta.utils -   [GQA]: iter 50773 Ep: 13.78 loss 0.128 score 0.981 lr 1.38234e-05 
09/16/2020 15:35:25 - INFO - volta.utils -   [GQA]: iter 50793 Ep: 13.79 loss 0.109 score 0.984 lr 1.38114e-05 
09/16/2020 15:36:57 - INFO - volta.utils -   [GQA]: iter 50813 Ep: 13.79 loss 0.124 score 0.982 lr 1.37993e-05 
09/16/2020 15:38:42 - INFO - volta.utils -   [GQA]: iter 50833 Ep: 13.80 loss 0.104 score 0.987 lr 1.37872e-05 
09/16/2020 15:40:23 - INFO - volta.utils -   [GQA]: iter 50853 Ep: 13.80 loss 0.112 score 0.985 lr 1.37752e-05 
09/16/2020 15:42:32 - INFO - volta.utils -   [GQA]: iter 50873 Ep: 13.81 loss 0.106 score 0.986 lr 1.37631e-05 
09/16/2020 15:44:02 - INFO - volta.utils -   [GQA]: iter 50893 Ep: 13.81 loss 0.120 score 0.981 lr 1.37511e-05 
09/16/2020 15:45:31 - INFO - volta.utils -   [GQA]: iter 50913 Ep: 13.82 loss 0.109 score 0.987 lr 1.3739e-05 
09/16/2020 15:47:13 - INFO - volta.utils -   [GQA]: iter 50933 Ep: 13.83 loss 0.113 score 0.982 lr 1.37269e-05 
09/16/2020 15:49:58 - INFO - volta.utils -   [GQA]: iter 50953 Ep: 13.83 loss 0.113 score 0.986 lr 1.37149e-05 
09/16/2020 15:51:09 - INFO - volta.utils -   [GQA]: iter 50973 Ep: 13.84 loss 0.109 score 0.985 lr 1.37028e-05 
09/16/2020 15:52:30 - INFO - volta.utils -   [GQA]: iter 50993 Ep: 13.84 loss 0.108 score 0.984 lr 1.36907e-05 
09/16/2020 15:54:06 - INFO - volta.utils -   [GQA]: iter 51013 Ep: 13.85 loss 0.109 score 0.985 lr 1.36787e-05 
09/16/2020 15:56:18 - INFO - volta.utils -   [GQA]: iter 51033 Ep: 13.85 loss 0.113 score 0.983 lr 1.36666e-05 
09/16/2020 15:57:44 - INFO - volta.utils -   [GQA]: iter 51053 Ep: 13.86 loss 0.110 score 0.983 lr 1.36545e-05 
09/16/2020 15:59:09 - INFO - volta.utils -   [GQA]: iter 51073 Ep: 13.86 loss 0.114 score 0.984 lr 1.36425e-05 
09/16/2020 16:00:09 - INFO - volta.utils -   [GQA]: iter 51093 Ep: 13.87 loss 0.122 score 0.983 lr 1.36304e-05 
09/16/2020 16:02:55 - INFO - volta.utils -   [GQA]: iter 51113 Ep: 13.87 loss 0.122 score 0.981 lr 1.36183e-05 
09/16/2020 16:04:32 - INFO - volta.utils -   [GQA]: iter 51133 Ep: 13.88 loss 0.119 score 0.983 lr 1.36063e-05 
09/16/2020 16:06:11 - INFO - volta.utils -   [GQA]: iter 51153 Ep: 13.89 loss 0.109 score 0.987 lr 1.35942e-05 
09/16/2020 16:07:57 - INFO - volta.utils -   [GQA]: iter 51173 Ep: 13.89 loss 0.095 score 0.987 lr 1.35822e-05 
09/16/2020 16:10:11 - INFO - volta.utils -   [GQA]: iter 51193 Ep: 13.90 loss 0.112 score 0.984 lr 1.35701e-05 
09/16/2020 16:11:44 - INFO - volta.utils -   [GQA]: iter 51213 Ep: 13.90 loss 0.121 score 0.981 lr 1.3558e-05 
09/16/2020 16:13:11 - INFO - volta.utils -   [GQA]: iter 51233 Ep: 13.91 loss 0.119 score 0.983 lr 1.3546e-05 
09/16/2020 16:14:06 - INFO - volta.utils -   [GQA]: iter 51253 Ep: 13.91 loss 0.108 score 0.986 lr 1.35339e-05 
09/16/2020 16:16:45 - INFO - volta.utils -   [GQA]: iter 51273 Ep: 13.92 loss 0.101 score 0.985 lr 1.35218e-05 
09/16/2020 16:18:26 - INFO - volta.utils -   [GQA]: iter 51293 Ep: 13.92 loss 0.097 score 0.987 lr 1.35098e-05 
09/16/2020 16:20:06 - INFO - volta.utils -   [GQA]: iter 51313 Ep: 13.93 loss 0.112 score 0.984 lr 1.34977e-05 
09/16/2020 16:21:48 - INFO - volta.utils -   [GQA]: iter 51333 Ep: 13.93 loss 0.119 score 0.983 lr 1.34856e-05 
09/16/2020 16:24:15 - INFO - volta.utils -   [GQA]: iter 51353 Ep: 13.94 loss 0.115 score 0.985 lr 1.34736e-05 
09/16/2020 16:25:24 - INFO - volta.utils -   [GQA]: iter 51373 Ep: 13.94 loss 0.128 score 0.980 lr 1.34615e-05 
09/16/2020 16:26:56 - INFO - volta.utils -   [GQA]: iter 51393 Ep: 13.95 loss 0.123 score 0.979 lr 1.34495e-05 
09/16/2020 16:28:00 - INFO - volta.utils -   [GQA]: iter 51413 Ep: 13.96 loss 0.104 score 0.986 lr 1.34374e-05 
09/16/2020 16:30:01 - INFO - volta.utils -   [GQA]: iter 51433 Ep: 13.96 loss 0.113 score 0.986 lr 1.34253e-05 
09/16/2020 16:31:34 - INFO - volta.utils -   [GQA]: iter 51453 Ep: 13.97 loss 0.112 score 0.984 lr 1.34133e-05 
09/16/2020 16:33:27 - INFO - volta.utils -   [GQA]: iter 51473 Ep: 13.97 loss 0.127 score 0.984 lr 1.34012e-05 
09/16/2020 16:34:59 - INFO - volta.utils -   [GQA]: iter 51493 Ep: 13.98 loss 0.107 score 0.986 lr 1.33891e-05 
09/16/2020 16:36:16 - INFO - volta.utils -   [GQA]: iter 51513 Ep: 13.98 loss 0.112 score 0.985 lr 1.33771e-05 
09/16/2020 16:37:32 - INFO - volta.utils -   [GQA]: iter 51533 Ep: 13.99 loss 0.134 score 0.978 lr 1.3365e-05 
09/16/2020 16:39:02 - INFO - volta.utils -   [GQA]: iter 51553 Ep: 13.99 loss 0.109 score 0.985 lr 1.33529e-05 
09/16/2020 16:40:45 - INFO - volta.utils -   [GQA]: iter 51573 Ep: 14.00 loss 0.113 score 0.986 lr 1.33409e-05 
09/16/2020 16:40:53 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  25%|██▌       | 2/8 [10:57:18<32:51:13, 19712.32s/it]09/16/2020 17:01:19 - INFO - volta.utils -   Eval task TASK15 on iteration 51577 
09/16/2020 17:01:19 - INFO - volta.utils -   Validation [GQA]: loss 3.781 score 64.364 
09/16/2020 17:01:31 - INFO - volta.utils -   [GQA]: iter 51597 Ep: 14.01 loss 0.093 score 0.989 lr 1.33276e-05 
09/16/2020 17:02:48 - INFO - volta.utils -   [GQA]: iter 51617 Ep: 14.01 loss 0.080 score 0.990 lr 1.33143e-05 
09/16/2020 17:04:00 - INFO - volta.utils -   [GQA]: iter 51637 Ep: 14.02 loss 0.089 score 0.988 lr 1.33023e-05 
09/16/2020 17:04:59 - INFO - volta.utils -   [GQA]: iter 51657 Ep: 14.02 loss 0.080 score 0.990 lr 1.32902e-05 
09/16/2020 17:06:35 - INFO - volta.utils -   [GQA]: iter 51677 Ep: 14.03 loss 0.069 score 0.993 lr 1.32781e-05 
09/16/2020 17:07:58 - INFO - volta.utils -   [GQA]: iter 51697 Ep: 14.03 loss 0.074 score 0.990 lr 1.32661e-05 
09/16/2020 17:09:29 - INFO - volta.utils -   [GQA]: iter 51717 Ep: 14.04 loss 0.072 score 0.992 lr 1.3254e-05 
09/16/2020 17:10:54 - INFO - volta.utils -   [GQA]: iter 51737 Ep: 14.04 loss 0.080 score 0.990 lr 1.32419e-05 
09/16/2020 17:13:05 - INFO - volta.utils -   [GQA]: iter 51757 Ep: 14.05 loss 0.090 score 0.988 lr 1.32299e-05 
09/16/2020 17:14:23 - INFO - volta.utils -   [GQA]: iter 51777 Ep: 14.05 loss 0.087 score 0.990 lr 1.32178e-05 
09/16/2020 17:15:37 - INFO - volta.utils -   [GQA]: iter 51797 Ep: 14.06 loss 0.086 score 0.989 lr 1.32058e-05 
09/16/2020 17:17:31 - INFO - volta.utils -   [GQA]: iter 51817 Ep: 14.07 loss 0.090 score 0.989 lr 1.31937e-05 
09/16/2020 17:20:15 - INFO - volta.utils -   [GQA]: iter 51837 Ep: 14.07 loss 0.078 score 0.991 lr 1.31816e-05 
09/16/2020 17:21:43 - INFO - volta.utils -   [GQA]: iter 51857 Ep: 14.08 loss 0.081 score 0.992 lr 1.31696e-05 
09/16/2020 17:22:55 - INFO - volta.utils -   [GQA]: iter 51877 Ep: 14.08 loss 0.070 score 0.992 lr 1.31575e-05 
09/16/2020 17:24:12 - INFO - volta.utils -   [GQA]: iter 51897 Ep: 14.09 loss 0.086 score 0.988 lr 1.31454e-05 
09/16/2020 17:27:01 - INFO - volta.utils -   [GQA]: iter 51917 Ep: 14.09 loss 0.084 score 0.991 lr 1.31334e-05 
09/16/2020 17:28:10 - INFO - volta.utils -   [GQA]: iter 51937 Ep: 14.10 loss 0.079 score 0.991 lr 1.31213e-05 
09/16/2020 17:29:43 - INFO - volta.utils -   [GQA]: iter 51957 Ep: 14.10 loss 0.086 score 0.990 lr 1.31092e-05 
09/16/2020 17:31:21 - INFO - volta.utils -   [GQA]: iter 51977 Ep: 14.11 loss 0.083 score 0.990 lr 1.30972e-05 
09/16/2020 17:34:27 - INFO - volta.utils -   [GQA]: iter 51997 Ep: 14.11 loss 0.083 score 0.989 lr 1.30851e-05 
09/16/2020 17:36:16 - INFO - volta.utils -   [GQA]: iter 52017 Ep: 14.12 loss 0.083 score 0.991 lr 1.3073e-05 
09/16/2020 17:38:05 - INFO - volta.utils -   [GQA]: iter 52037 Ep: 14.13 loss 0.084 score 0.991 lr 1.3061e-05 
09/16/2020 17:39:45 - INFO - volta.utils -   [GQA]: iter 52057 Ep: 14.13 loss 0.081 score 0.990 lr 1.30489e-05 
09/16/2020 17:42:50 - INFO - volta.utils -   [GQA]: iter 52077 Ep: 14.14 loss 0.084 score 0.990 lr 1.30369e-05 
09/16/2020 17:44:22 - INFO - volta.utils -   [GQA]: iter 52097 Ep: 14.14 loss 0.087 score 0.988 lr 1.30248e-05 
09/16/2020 17:45:34 - INFO - volta.utils -   [GQA]: iter 52117 Ep: 14.15 loss 0.087 score 0.989 lr 1.30127e-05 
09/16/2020 17:46:42 - INFO - volta.utils -   [GQA]: iter 52137 Ep: 14.15 loss 0.076 score 0.993 lr 1.30007e-05 
09/16/2020 17:50:17 - INFO - volta.utils -   [GQA]: iter 52157 Ep: 14.16 loss 0.081 score 0.990 lr 1.29886e-05 
09/16/2020 17:51:54 - INFO - volta.utils -   [GQA]: iter 52177 Ep: 14.16 loss 0.089 score 0.989 lr 1.29765e-05 
09/16/2020 17:53:40 - INFO - volta.utils -   [GQA]: iter 52197 Ep: 14.17 loss 0.083 score 0.988 lr 1.29645e-05 
09/16/2020 17:55:22 - INFO - volta.utils -   [GQA]: iter 52217 Ep: 14.17 loss 0.080 score 0.991 lr 1.29524e-05 
09/16/2020 17:57:48 - INFO - volta.utils -   [GQA]: iter 52237 Ep: 14.18 loss 0.078 score 0.990 lr 1.29403e-05 
09/16/2020 17:59:06 - INFO - volta.utils -   [GQA]: iter 52257 Ep: 14.18 loss 0.072 score 0.990 lr 1.29283e-05 
09/16/2020 18:00:39 - INFO - volta.utils -   [GQA]: iter 52277 Ep: 14.19 loss 0.090 score 0.989 lr 1.29162e-05 
09/16/2020 18:02:01 - INFO - volta.utils -   [GQA]: iter 52297 Ep: 14.20 loss 0.085 score 0.990 lr 1.29042e-05 
09/16/2020 18:04:16 - INFO - volta.utils -   [GQA]: iter 52317 Ep: 14.20 loss 0.081 score 0.990 lr 1.28921e-05 
09/16/2020 18:05:39 - INFO - volta.utils -   [GQA]: iter 52337 Ep: 14.21 loss 0.077 score 0.993 lr 1.288e-05 
09/16/2020 18:07:11 - INFO - volta.utils -   [GQA]: iter 52357 Ep: 14.21 loss 0.081 score 0.990 lr 1.2868e-05 
09/16/2020 18:08:17 - INFO - volta.utils -   [GQA]: iter 52377 Ep: 14.22 loss 0.082 score 0.991 lr 1.28559e-05 
09/16/2020 18:10:55 - INFO - volta.utils -   [GQA]: iter 52397 Ep: 14.22 loss 0.091 score 0.988 lr 1.28438e-05 
09/16/2020 18:12:26 - INFO - volta.utils -   [GQA]: iter 52417 Ep: 14.23 loss 0.086 score 0.990 lr 1.28318e-05 
09/16/2020 18:13:54 - INFO - volta.utils -   [GQA]: iter 52437 Ep: 14.23 loss 0.091 score 0.989 lr 1.28197e-05 
09/16/2020 18:15:29 - INFO - volta.utils -   [GQA]: iter 52457 Ep: 14.24 loss 0.082 score 0.989 lr 1.28076e-05 
09/16/2020 18:18:53 - INFO - volta.utils -   [GQA]: iter 52477 Ep: 14.24 loss 0.075 score 0.991 lr 1.27956e-05 
09/16/2020 18:19:51 - INFO - volta.utils -   [GQA]: iter 52497 Ep: 14.25 loss 0.082 score 0.989 lr 1.27835e-05 
09/16/2020 18:21:08 - INFO - volta.utils -   [GQA]: iter 52517 Ep: 14.26 loss 0.071 score 0.991 lr 1.27714e-05 
09/16/2020 18:22:40 - INFO - volta.utils -   [GQA]: iter 52537 Ep: 14.26 loss 0.081 score 0.991 lr 1.27594e-05 
09/16/2020 18:25:23 - INFO - volta.utils -   [GQA]: iter 52557 Ep: 14.27 loss 0.081 score 0.989 lr 1.27473e-05 
09/16/2020 18:27:04 - INFO - volta.utils -   [GQA]: iter 52577 Ep: 14.27 loss 0.074 score 0.991 lr 1.27353e-05 
09/16/2020 18:28:26 - INFO - volta.utils -   [GQA]: iter 52597 Ep: 14.28 loss 0.080 score 0.989 lr 1.27232e-05 
09/16/2020 18:30:39 - INFO - volta.utils -   [GQA]: iter 52617 Ep: 14.28 loss 0.074 score 0.992 lr 1.27111e-05 
09/16/2020 18:32:45 - INFO - volta.utils -   [GQA]: iter 52637 Ep: 14.29 loss 0.081 score 0.990 lr 1.26991e-05 
09/16/2020 18:34:08 - INFO - volta.utils -   [GQA]: iter 52657 Ep: 14.29 loss 0.073 score 0.991 lr 1.2687e-05 
09/16/2020 18:35:41 - INFO - volta.utils -   [GQA]: iter 52677 Ep: 14.30 loss 0.078 score 0.991 lr 1.26749e-05 
09/16/2020 18:37:15 - INFO - volta.utils -   [GQA]: iter 52697 Ep: 14.30 loss 0.069 score 0.992 lr 1.26629e-05 
09/16/2020 18:39:35 - INFO - volta.utils -   [GQA]: iter 52717 Ep: 14.31 loss 0.084 score 0.989 lr 1.26508e-05 
09/16/2020 18:41:09 - INFO - volta.utils -   [GQA]: iter 52737 Ep: 14.32 loss 0.090 score 0.988 lr 1.26387e-05 
09/16/2020 18:42:34 - INFO - volta.utils -   [GQA]: iter 52757 Ep: 14.32 loss 0.080 score 0.989 lr 1.26267e-05 
09/16/2020 18:44:10 - INFO - volta.utils -   [GQA]: iter 52777 Ep: 14.33 loss 0.092 score 0.986 lr 1.26146e-05 
09/16/2020 18:46:26 - INFO - volta.utils -   [GQA]: iter 52797 Ep: 14.33 loss 0.092 score 0.987 lr 1.26025e-05 
09/16/2020 18:48:01 - INFO - volta.utils -   [GQA]: iter 52817 Ep: 14.34 loss 0.072 score 0.991 lr 1.25905e-05 
09/16/2020 18:49:39 - INFO - volta.utils -   [GQA]: iter 52837 Ep: 14.34 loss 0.073 score 0.991 lr 1.25784e-05 
09/16/2020 18:50:59 - INFO - volta.utils -   [GQA]: iter 52857 Ep: 14.35 loss 0.072 score 0.992 lr 1.25664e-05 
09/16/2020 18:53:35 - INFO - volta.utils -   [GQA]: iter 52877 Ep: 14.35 loss 0.076 score 0.990 lr 1.25543e-05 
09/16/2020 18:54:30 - INFO - volta.utils -   [GQA]: iter 52897 Ep: 14.36 loss 0.074 score 0.990 lr 1.25422e-05 
09/16/2020 18:56:08 - INFO - volta.utils -   [GQA]: iter 52917 Ep: 14.36 loss 0.079 score 0.990 lr 1.25302e-05 
09/16/2020 18:57:39 - INFO - volta.utils -   [GQA]: iter 52937 Ep: 14.37 loss 0.078 score 0.992 lr 1.25181e-05 
09/16/2020 19:00:25 - INFO - volta.utils -   [GQA]: iter 52957 Ep: 14.37 loss 0.078 score 0.989 lr 1.2506e-05 
09/16/2020 19:01:30 - INFO - volta.utils -   [GQA]: iter 52977 Ep: 14.38 loss 0.075 score 0.991 lr 1.2494e-05 
09/16/2020 19:03:08 - INFO - volta.utils -   [GQA]: iter 52997 Ep: 14.39 loss 0.087 score 0.990 lr 1.24819e-05 
09/16/2020 19:04:48 - INFO - volta.utils -   [GQA]: iter 53017 Ep: 14.39 loss 0.078 score 0.991 lr 1.24698e-05 
09/16/2020 19:06:45 - INFO - volta.utils -   [GQA]: iter 53037 Ep: 14.40 loss 0.093 score 0.988 lr 1.24578e-05 
09/16/2020 19:07:52 - INFO - volta.utils -   [GQA]: iter 53057 Ep: 14.40 loss 0.090 score 0.989 lr 1.24457e-05 
09/16/2020 19:09:36 - INFO - volta.utils -   [GQA]: iter 53077 Ep: 14.41 loss 0.089 score 0.988 lr 1.24336e-05 
09/16/2020 19:11:41 - INFO - volta.utils -   [GQA]: iter 53097 Ep: 14.41 loss 0.076 score 0.990 lr 1.24216e-05 
09/16/2020 19:13:22 - INFO - volta.utils -   [GQA]: iter 53117 Ep: 14.42 loss 0.071 score 0.993 lr 1.24095e-05 
09/16/2020 19:14:34 - INFO - volta.utils -   [GQA]: iter 53137 Ep: 14.42 loss 0.077 score 0.989 lr 1.23975e-05 
09/16/2020 19:16:12 - INFO - volta.utils -   [GQA]: iter 53157 Ep: 14.43 loss 0.078 score 0.989 lr 1.23854e-05 
09/16/2020 19:17:51 - INFO - volta.utils -   [GQA]: iter 53177 Ep: 14.43 loss 0.076 score 0.990 lr 1.23733e-05 
09/16/2020 19:19:22 - INFO - volta.utils -   [GQA]: iter 53197 Ep: 14.44 loss 0.088 score 0.987 lr 1.23613e-05 
09/16/2020 19:21:09 - INFO - volta.utils -   [GQA]: iter 53217 Ep: 14.45 loss 0.082 score 0.988 lr 1.23492e-05 
09/16/2020 19:23:00 - INFO - volta.utils -   [GQA]: iter 53237 Ep: 14.45 loss 0.080 score 0.990 lr 1.23371e-05 
09/16/2020 19:25:47 - INFO - volta.utils -   [GQA]: iter 53257 Ep: 14.46 loss 0.075 score 0.990 lr 1.23251e-05 
09/16/2020 19:27:21 - INFO - volta.utils -   [GQA]: iter 53277 Ep: 14.46 loss 0.070 score 0.992 lr 1.2313e-05 
09/16/2020 19:28:40 - INFO - volta.utils -   [GQA]: iter 53297 Ep: 14.47 loss 0.087 score 0.989 lr 1.23009e-05 
09/16/2020 19:30:34 - INFO - volta.utils -   [GQA]: iter 53317 Ep: 14.47 loss 0.076 score 0.990 lr 1.22889e-05 
09/16/2020 19:32:49 - INFO - volta.utils -   [GQA]: iter 53337 Ep: 14.48 loss 0.084 score 0.990 lr 1.22768e-05 
09/16/2020 19:34:21 - INFO - volta.utils -   [GQA]: iter 53357 Ep: 14.48 loss 0.080 score 0.990 lr 1.22647e-05 
09/16/2020 19:35:48 - INFO - volta.utils -   [GQA]: iter 53377 Ep: 14.49 loss 0.082 score 0.989 lr 1.22527e-05 
09/16/2020 19:37:28 - INFO - volta.utils -   [GQA]: iter 53397 Ep: 14.49 loss 0.079 score 0.990 lr 1.22406e-05 
09/16/2020 19:39:24 - INFO - volta.utils -   [GQA]: iter 53417 Ep: 14.50 loss 0.087 score 0.987 lr 1.22286e-05 
09/16/2020 19:40:47 - INFO - volta.utils -   [GQA]: iter 53437 Ep: 14.51 loss 0.086 score 0.988 lr 1.22165e-05 
09/16/2020 19:42:19 - INFO - volta.utils -   [GQA]: iter 53457 Ep: 14.51 loss 0.089 score 0.988 lr 1.22044e-05 
09/16/2020 19:44:10 - INFO - volta.utils -   [GQA]: iter 53477 Ep: 14.52 loss 0.077 score 0.992 lr 1.21924e-05 
09/16/2020 19:45:50 - INFO - volta.utils -   [GQA]: iter 53497 Ep: 14.52 loss 0.087 score 0.988 lr 1.21803e-05 
09/16/2020 19:47:15 - INFO - volta.utils -   [GQA]: iter 53517 Ep: 14.53 loss 0.090 score 0.989 lr 1.21682e-05 
09/16/2020 19:48:20 - INFO - volta.utils -   [GQA]: iter 53537 Ep: 14.53 loss 0.071 score 0.991 lr 1.21562e-05 
09/16/2020 19:50:38 - INFO - volta.utils -   [GQA]: iter 53557 Ep: 14.54 loss 0.072 score 0.992 lr 1.21441e-05 
09/16/2020 19:52:36 - INFO - volta.utils -   [GQA]: iter 53577 Ep: 14.54 loss 0.076 score 0.990 lr 1.2132e-05 
09/16/2020 19:53:44 - INFO - volta.utils -   [GQA]: iter 53597 Ep: 14.55 loss 0.079 score 0.991 lr 1.212e-05 
09/16/2020 19:54:43 - INFO - volta.utils -   [GQA]: iter 53617 Ep: 14.55 loss 0.081 score 0.989 lr 1.21079e-05 
09/16/2020 19:56:26 - INFO - volta.utils -   [GQA]: iter 53637 Ep: 14.56 loss 0.092 score 0.988 lr 1.20958e-05 
09/16/2020 19:58:21 - INFO - volta.utils -   [GQA]: iter 53657 Ep: 14.56 loss 0.079 score 0.991 lr 1.20838e-05 
09/16/2020 19:59:47 - INFO - volta.utils -   [GQA]: iter 53677 Ep: 14.57 loss 0.086 score 0.989 lr 1.20717e-05 
09/16/2020 20:01:32 - INFO - volta.utils -   [GQA]: iter 53697 Ep: 14.58 loss 0.091 score 0.989 lr 1.20597e-05 
09/16/2020 20:03:09 - INFO - volta.utils -   [GQA]: iter 53717 Ep: 14.58 loss 0.083 score 0.988 lr 1.20476e-05 
09/16/2020 20:05:11 - INFO - volta.utils -   [GQA]: iter 53737 Ep: 14.59 loss 0.071 score 0.992 lr 1.20355e-05 
09/16/2020 20:06:58 - INFO - volta.utils -   [GQA]: iter 53757 Ep: 14.59 loss 0.075 score 0.990 lr 1.20235e-05 
09/16/2020 20:08:20 - INFO - volta.utils -   [GQA]: iter 53777 Ep: 14.60 loss 0.084 score 0.990 lr 1.20114e-05 
09/16/2020 20:09:56 - INFO - volta.utils -   [GQA]: iter 53797 Ep: 14.60 loss 0.078 score 0.991 lr 1.19993e-05 
09/16/2020 20:11:43 - INFO - volta.utils -   [GQA]: iter 53817 Ep: 14.61 loss 0.083 score 0.990 lr 1.19873e-05 
09/16/2020 20:13:11 - INFO - volta.utils -   [GQA]: iter 53837 Ep: 14.61 loss 0.087 score 0.990 lr 1.19752e-05 
09/16/2020 20:14:52 - INFO - volta.utils -   [GQA]: iter 53857 Ep: 14.62 loss 0.084 score 0.989 lr 1.19631e-05 
09/16/2020 20:16:12 - INFO - volta.utils -   [GQA]: iter 53877 Ep: 14.62 loss 0.080 score 0.990 lr 1.19511e-05 
09/16/2020 20:18:13 - INFO - volta.utils -   [GQA]: iter 53897 Ep: 14.63 loss 0.095 score 0.986 lr 1.1939e-05 
09/16/2020 20:19:53 - INFO - volta.utils -   [GQA]: iter 53917 Ep: 14.64 loss 0.082 score 0.990 lr 1.1927e-05 
09/16/2020 20:21:30 - INFO - volta.utils -   [GQA]: iter 53937 Ep: 14.64 loss 0.088 score 0.988 lr 1.19149e-05 
09/16/2020 20:22:54 - INFO - volta.utils -   [GQA]: iter 53957 Ep: 14.65 loss 0.082 score 0.991 lr 1.19028e-05 
09/16/2020 20:25:10 - INFO - volta.utils -   [GQA]: iter 53977 Ep: 14.65 loss 0.086 score 0.988 lr 1.18908e-05 
09/16/2020 20:26:48 - INFO - volta.utils -   [GQA]: iter 53997 Ep: 14.66 loss 0.090 score 0.987 lr 1.18787e-05 
09/16/2020 20:28:19 - INFO - volta.utils -   [GQA]: iter 54017 Ep: 14.66 loss 0.095 score 0.988 lr 1.18666e-05 
09/16/2020 20:29:20 - INFO - volta.utils -   [GQA]: iter 54037 Ep: 14.67 loss 0.082 score 0.990 lr 1.18546e-05 
09/16/2020 20:31:32 - INFO - volta.utils -   [GQA]: iter 54057 Ep: 14.67 loss 0.093 score 0.987 lr 1.18425e-05 
09/16/2020 20:32:37 - INFO - volta.utils -   [GQA]: iter 54077 Ep: 14.68 loss 0.091 score 0.988 lr 1.18304e-05 
09/16/2020 20:34:46 - INFO - volta.utils -   [GQA]: iter 54097 Ep: 14.68 loss 0.080 score 0.989 lr 1.18184e-05 
09/16/2020 20:36:00 - INFO - volta.utils -   [GQA]: iter 54117 Ep: 14.69 loss 0.081 score 0.990 lr 1.18063e-05 
09/16/2020 20:38:04 - INFO - volta.utils -   [GQA]: iter 54137 Ep: 14.70 loss 0.084 score 0.989 lr 1.17942e-05 
09/16/2020 20:39:29 - INFO - volta.utils -   [GQA]: iter 54157 Ep: 14.70 loss 0.085 score 0.988 lr 1.17822e-05 
09/16/2020 20:41:02 - INFO - volta.utils -   [GQA]: iter 54177 Ep: 14.71 loss 0.079 score 0.989 lr 1.17701e-05 
09/16/2020 20:42:29 - INFO - volta.utils -   [GQA]: iter 54197 Ep: 14.71 loss 0.092 score 0.988 lr 1.17581e-05 
09/16/2020 20:44:30 - INFO - volta.utils -   [GQA]: iter 54217 Ep: 14.72 loss 0.073 score 0.992 lr 1.1746e-05 
09/16/2020 20:45:54 - INFO - volta.utils -   [GQA]: iter 54237 Ep: 14.72 loss 0.074 score 0.991 lr 1.17339e-05 
09/16/2020 20:48:42 - INFO - volta.utils -   [GQA]: iter 54257 Ep: 14.73 loss 0.077 score 0.990 lr 1.17219e-05 
09/16/2020 20:50:06 - INFO - volta.utils -   [GQA]: iter 54277 Ep: 14.73 loss 0.080 score 0.990 lr 1.17098e-05 
09/16/2020 20:51:08 - INFO - volta.utils -   [GQA]: iter 54297 Ep: 14.74 loss 0.079 score 0.990 lr 1.16977e-05 
09/16/2020 20:52:31 - INFO - volta.utils -   [GQA]: iter 54317 Ep: 14.74 loss 0.073 score 0.992 lr 1.16857e-05 
09/16/2020 20:54:26 - INFO - volta.utils -   [GQA]: iter 54337 Ep: 14.75 loss 0.090 score 0.989 lr 1.16736e-05 
09/16/2020 20:56:11 - INFO - volta.utils -   [GQA]: iter 54357 Ep: 14.75 loss 0.093 score 0.988 lr 1.16615e-05 
09/16/2020 20:57:47 - INFO - volta.utils -   [GQA]: iter 54377 Ep: 14.76 loss 0.082 score 0.990 lr 1.16495e-05 
09/16/2020 20:59:29 - INFO - volta.utils -   [GQA]: iter 54397 Ep: 14.77 loss 0.086 score 0.989 lr 1.16374e-05 
09/16/2020 21:01:55 - INFO - volta.utils -   [GQA]: iter 54417 Ep: 14.77 loss 0.086 score 0.991 lr 1.16253e-05 
09/16/2020 21:03:36 - INFO - volta.utils -   [GQA]: iter 54437 Ep: 14.78 loss 0.084 score 0.990 lr 1.16133e-05 
09/16/2020 21:04:51 - INFO - volta.utils -   [GQA]: iter 54457 Ep: 14.78 loss 0.089 score 0.988 lr 1.16012e-05 
09/16/2020 21:06:47 - INFO - volta.utils -   [GQA]: iter 54477 Ep: 14.79 loss 0.097 score 0.987 lr 1.15892e-05 
09/16/2020 21:09:08 - INFO - volta.utils -   [GQA]: iter 54497 Ep: 14.79 loss 0.078 score 0.988 lr 1.15771e-05 
09/16/2020 21:10:14 - INFO - volta.utils -   [GQA]: iter 54517 Ep: 14.80 loss 0.087 score 0.988 lr 1.1565e-05 
09/16/2020 21:11:23 - INFO - volta.utils -   [GQA]: iter 54537 Ep: 14.80 loss 0.095 score 0.988 lr 1.1553e-05 
09/16/2020 21:13:40 - INFO - volta.utils -   [GQA]: iter 54557 Ep: 14.81 loss 0.087 score 0.988 lr 1.15409e-05 
09/16/2020 21:15:05 - INFO - volta.utils -   [GQA]: iter 54577 Ep: 14.81 loss 0.083 score 0.989 lr 1.15288e-05 
09/16/2020 21:16:40 - INFO - volta.utils -   [GQA]: iter 54597 Ep: 14.82 loss 0.082 score 0.988 lr 1.15168e-05 
09/16/2020 21:18:16 - INFO - volta.utils -   [GQA]: iter 54617 Ep: 14.83 loss 0.085 score 0.990 lr 1.15047e-05 
09/16/2020 21:20:46 - INFO - volta.utils -   [GQA]: iter 54637 Ep: 14.83 loss 0.089 score 0.989 lr 1.14926e-05 
09/16/2020 21:22:09 - INFO - volta.utils -   [GQA]: iter 54657 Ep: 14.84 loss 0.092 score 0.985 lr 1.14806e-05 
09/16/2020 21:23:38 - INFO - volta.utils -   [GQA]: iter 54677 Ep: 14.84 loss 0.084 score 0.988 lr 1.14685e-05 
09/16/2020 21:24:52 - INFO - volta.utils -   [GQA]: iter 54697 Ep: 14.85 loss 0.083 score 0.990 lr 1.14564e-05 
09/16/2020 21:26:44 - INFO - volta.utils -   [GQA]: iter 54717 Ep: 14.85 loss 0.089 score 0.987 lr 1.14444e-05 
09/16/2020 21:28:22 - INFO - volta.utils -   [GQA]: iter 54737 Ep: 14.86 loss 0.076 score 0.991 lr 1.14323e-05 
09/16/2020 21:30:06 - INFO - volta.utils -   [GQA]: iter 54757 Ep: 14.86 loss 0.090 score 0.990 lr 1.14203e-05 
09/16/2020 21:31:49 - INFO - volta.utils -   [GQA]: iter 54777 Ep: 14.87 loss 0.074 score 0.992 lr 1.14082e-05 
09/16/2020 21:34:44 - INFO - volta.utils -   [GQA]: iter 54797 Ep: 14.87 loss 0.086 score 0.989 lr 1.13961e-05 
09/16/2020 21:36:06 - INFO - volta.utils -   [GQA]: iter 54817 Ep: 14.88 loss 0.084 score 0.990 lr 1.13841e-05 
09/16/2020 21:37:16 - INFO - volta.utils -   [GQA]: iter 54837 Ep: 14.89 loss 0.079 score 0.988 lr 1.1372e-05 
09/16/2020 21:38:45 - INFO - volta.utils -   [GQA]: iter 54857 Ep: 14.89 loss 0.080 score 0.989 lr 1.13599e-05 
09/16/2020 21:41:31 - INFO - volta.utils -   [GQA]: iter 54877 Ep: 14.90 loss 0.079 score 0.991 lr 1.13479e-05 
09/16/2020 21:42:15 - INFO - volta.utils -   [GQA]: iter 54897 Ep: 14.90 loss 0.083 score 0.989 lr 1.13358e-05 
09/16/2020 21:43:49 - INFO - volta.utils -   [GQA]: iter 54917 Ep: 14.91 loss 0.085 score 0.989 lr 1.13237e-05 
09/16/2020 21:45:50 - INFO - volta.utils -   [GQA]: iter 54937 Ep: 14.91 loss 0.091 score 0.988 lr 1.13117e-05 
09/16/2020 21:48:17 - INFO - volta.utils -   [GQA]: iter 54957 Ep: 14.92 loss 0.077 score 0.990 lr 1.12996e-05 
09/16/2020 21:49:54 - INFO - volta.utils -   [GQA]: iter 54977 Ep: 14.92 loss 0.085 score 0.987 lr 1.12875e-05 
09/16/2020 21:50:53 - INFO - volta.utils -   [GQA]: iter 54997 Ep: 14.93 loss 0.091 score 0.989 lr 1.12755e-05 
09/16/2020 21:52:25 - INFO - volta.utils -   [GQA]: iter 55017 Ep: 14.93 loss 0.085 score 0.989 lr 1.12634e-05 
09/16/2020 21:54:21 - INFO - volta.utils -   [GQA]: iter 55037 Ep: 14.94 loss 0.085 score 0.989 lr 1.12514e-05 
09/16/2020 21:56:08 - INFO - volta.utils -   [GQA]: iter 55057 Ep: 14.94 loss 0.081 score 0.990 lr 1.12393e-05 
09/16/2020 21:57:37 - INFO - volta.utils -   [GQA]: iter 55077 Ep: 14.95 loss 0.074 score 0.991 lr 1.12272e-05 
09/16/2020 21:59:09 - INFO - volta.utils -   [GQA]: iter 55097 Ep: 14.96 loss 0.100 score 0.984 lr 1.12152e-05 
09/16/2020 22:00:14 - INFO - volta.utils -   [GQA]: iter 55117 Ep: 14.96 loss 0.086 score 0.987 lr 1.12031e-05 
09/16/2020 22:02:15 - INFO - volta.utils -   [GQA]: iter 55137 Ep: 14.97 loss 0.084 score 0.990 lr 1.1191e-05 
09/16/2020 22:03:58 - INFO - volta.utils -   [GQA]: iter 55157 Ep: 14.97 loss 0.085 score 0.989 lr 1.1179e-05 
09/16/2020 22:05:37 - INFO - volta.utils -   [GQA]: iter 55177 Ep: 14.98 loss 0.089 score 0.991 lr 1.11669e-05 
09/16/2020 22:06:44 - INFO - volta.utils -   [GQA]: iter 55197 Ep: 14.98 loss 0.079 score 0.990 lr 1.11548e-05 
09/16/2020 22:09:08 - INFO - volta.utils -   [GQA]: iter 55217 Ep: 14.99 loss 0.085 score 0.989 lr 1.11428e-05 
09/16/2020 22:11:00 - INFO - volta.utils -   [GQA]: iter 55237 Ep: 14.99 loss 0.082 score 0.990 lr 1.11307e-05 
09/16/2020 22:11:56 - INFO - volta.utils -   [GQA]: iter 55257 Ep: 15.00 loss 0.090 score 0.989 lr 1.11187e-05 
09/16/2020 22:11:58 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  38%|███▊      | 3/8 [16:28:22<27:26:28, 19757.72s/it]09/16/2020 22:31:40 - INFO - volta.utils -   Eval task TASK15 on iteration 55261 
09/16/2020 22:31:40 - INFO - volta.utils -   Validation [GQA]: loss 3.935 score 64.476 
09/16/2020 22:31:52 - INFO - volta.utils -   [GQA]: iter 55281 Ep: 15.01 loss 0.067 score 0.993 lr 1.11054e-05 
09/16/2020 22:33:12 - INFO - volta.utils -   [GQA]: iter 55301 Ep: 15.01 loss 0.062 score 0.993 lr 1.10921e-05 
09/16/2020 22:34:43 - INFO - volta.utils -   [GQA]: iter 55321 Ep: 15.02 loss 0.061 score 0.994 lr 1.108e-05 
09/16/2020 22:35:39 - INFO - volta.utils -   [GQA]: iter 55341 Ep: 15.02 loss 0.061 score 0.993 lr 1.1068e-05 
09/16/2020 22:37:21 - INFO - volta.utils -   [GQA]: iter 55361 Ep: 15.03 loss 0.072 score 0.991 lr 1.10559e-05 
09/16/2020 22:38:33 - INFO - volta.utils -   [GQA]: iter 55381 Ep: 15.03 loss 0.066 score 0.993 lr 1.10439e-05 
09/16/2020 22:40:25 - INFO - volta.utils -   [GQA]: iter 55401 Ep: 15.04 loss 0.057 score 0.994 lr 1.10318e-05 
09/16/2020 22:41:43 - INFO - volta.utils -   [GQA]: iter 55421 Ep: 15.04 loss 0.064 score 0.992 lr 1.10197e-05 
09/16/2020 22:43:18 - INFO - volta.utils -   [GQA]: iter 55441 Ep: 15.05 loss 0.063 score 0.994 lr 1.10077e-05 
09/16/2020 22:45:12 - INFO - volta.utils -   [GQA]: iter 55461 Ep: 15.05 loss 0.062 score 0.992 lr 1.09956e-05 
09/16/2020 22:46:50 - INFO - volta.utils -   [GQA]: iter 55481 Ep: 15.06 loss 0.075 score 0.990 lr 1.09835e-05 
09/16/2020 22:48:12 - INFO - volta.utils -   [GQA]: iter 55501 Ep: 15.07 loss 0.058 score 0.995 lr 1.09715e-05 
09/16/2020 22:50:53 - INFO - volta.utils -   [GQA]: iter 55521 Ep: 15.07 loss 0.061 score 0.993 lr 1.09594e-05 
09/16/2020 22:52:48 - INFO - volta.utils -   [GQA]: iter 55541 Ep: 15.08 loss 0.066 score 0.991 lr 1.09473e-05 
09/16/2020 22:54:19 - INFO - volta.utils -   [GQA]: iter 55561 Ep: 15.08 loss 0.052 score 0.994 lr 1.09353e-05 
09/16/2020 22:55:53 - INFO - volta.utils -   [GQA]: iter 55581 Ep: 15.09 loss 0.060 score 0.993 lr 1.09232e-05 
09/16/2020 22:57:59 - INFO - volta.utils -   [GQA]: iter 55601 Ep: 15.09 loss 0.057 score 0.994 lr 1.09111e-05 
09/16/2020 22:59:44 - INFO - volta.utils -   [GQA]: iter 55621 Ep: 15.10 loss 0.064 score 0.993 lr 1.08991e-05 
09/16/2020 23:01:23 - INFO - volta.utils -   [GQA]: iter 55641 Ep: 15.10 loss 0.065 score 0.993 lr 1.0887e-05 
09/16/2020 23:02:56 - INFO - volta.utils -   [GQA]: iter 55661 Ep: 15.11 loss 0.064 score 0.993 lr 1.0875e-05 
09/16/2020 23:05:26 - INFO - volta.utils -   [GQA]: iter 55681 Ep: 15.11 loss 0.067 score 0.992 lr 1.08629e-05 
09/16/2020 23:06:33 - INFO - volta.utils -   [GQA]: iter 55701 Ep: 15.12 loss 0.058 score 0.995 lr 1.08508e-05 
09/16/2020 23:07:50 - INFO - volta.utils -   [GQA]: iter 55721 Ep: 15.13 loss 0.063 score 0.992 lr 1.08388e-05 
09/16/2020 23:09:20 - INFO - volta.utils -   [GQA]: iter 55741 Ep: 15.13 loss 0.055 score 0.994 lr 1.08267e-05 
09/16/2020 23:11:29 - INFO - volta.utils -   [GQA]: iter 55761 Ep: 15.14 loss 0.055 score 0.994 lr 1.08146e-05 
09/16/2020 23:12:53 - INFO - volta.utils -   [GQA]: iter 55781 Ep: 15.14 loss 0.056 score 0.995 lr 1.08026e-05 
09/16/2020 23:14:42 - INFO - volta.utils -   [GQA]: iter 55801 Ep: 15.15 loss 0.052 score 0.995 lr 1.07905e-05 
09/16/2020 23:16:38 - INFO - volta.utils -   [GQA]: iter 55821 Ep: 15.15 loss 0.058 score 0.994 lr 1.07784e-05 
09/16/2020 23:18:50 - INFO - volta.utils -   [GQA]: iter 55841 Ep: 15.16 loss 0.060 score 0.994 lr 1.07664e-05 
09/16/2020 23:20:11 - INFO - volta.utils -   [GQA]: iter 55861 Ep: 15.16 loss 0.059 score 0.994 lr 1.07543e-05 
09/16/2020 23:21:54 - INFO - volta.utils -   [GQA]: iter 55881 Ep: 15.17 loss 0.060 score 0.994 lr 1.07422e-05 
09/16/2020 23:23:18 - INFO - volta.utils -   [GQA]: iter 55901 Ep: 15.17 loss 0.052 score 0.994 lr 1.07302e-05 
09/16/2020 23:25:40 - INFO - volta.utils -   [GQA]: iter 55921 Ep: 15.18 loss 0.064 score 0.993 lr 1.07181e-05 
09/16/2020 23:27:06 - INFO - volta.utils -   [GQA]: iter 55941 Ep: 15.18 loss 0.062 score 0.992 lr 1.07061e-05 
09/16/2020 23:28:51 - INFO - volta.utils -   [GQA]: iter 55961 Ep: 15.19 loss 0.060 score 0.994 lr 1.0694e-05 
09/16/2020 23:30:14 - INFO - volta.utils -   [GQA]: iter 55981 Ep: 15.20 loss 0.064 score 0.992 lr 1.06819e-05 
09/16/2020 23:33:01 - INFO - volta.utils -   [GQA]: iter 56001 Ep: 15.20 loss 0.062 score 0.994 lr 1.06699e-05 
09/16/2020 23:34:29 - INFO - volta.utils -   [GQA]: iter 56021 Ep: 15.21 loss 0.052 score 0.995 lr 1.06578e-05 
09/16/2020 23:36:06 - INFO - volta.utils -   [GQA]: iter 56041 Ep: 15.21 loss 0.066 score 0.993 lr 1.06457e-05 
09/16/2020 23:37:33 - INFO - volta.utils -   [GQA]: iter 56061 Ep: 15.22 loss 0.064 score 0.993 lr 1.06337e-05 
09/16/2020 23:39:48 - INFO - volta.utils -   [GQA]: iter 56081 Ep: 15.22 loss 0.059 score 0.994 lr 1.06216e-05 
09/16/2020 23:40:58 - INFO - volta.utils -   [GQA]: iter 56101 Ep: 15.23 loss 0.057 score 0.995 lr 1.06095e-05 
09/16/2020 23:42:41 - INFO - volta.utils -   [GQA]: iter 56121 Ep: 15.23 loss 0.058 score 0.995 lr 1.05975e-05 
09/16/2020 23:44:00 - INFO - volta.utils -   [GQA]: iter 56141 Ep: 15.24 loss 0.053 score 0.995 lr 1.05854e-05 
09/16/2020 23:46:07 - INFO - volta.utils -   [GQA]: iter 56161 Ep: 15.24 loss 0.059 score 0.993 lr 1.05734e-05 
09/16/2020 23:47:41 - INFO - volta.utils -   [GQA]: iter 56181 Ep: 15.25 loss 0.056 score 0.994 lr 1.05613e-05 
09/16/2020 23:49:34 - INFO - volta.utils -   [GQA]: iter 56201 Ep: 15.26 loss 0.054 score 0.995 lr 1.05492e-05 
09/16/2020 23:51:18 - INFO - volta.utils -   [GQA]: iter 56221 Ep: 15.26 loss 0.058 score 0.993 lr 1.05372e-05 
09/16/2020 23:53:53 - INFO - volta.utils -   [GQA]: iter 56241 Ep: 15.27 loss 0.053 score 0.994 lr 1.05251e-05 
09/16/2020 23:55:28 - INFO - volta.utils -   [GQA]: iter 56261 Ep: 15.27 loss 0.054 score 0.994 lr 1.0513e-05 
09/16/2020 23:57:16 - INFO - volta.utils -   [GQA]: iter 56281 Ep: 15.28 loss 0.054 score 0.994 lr 1.0501e-05 
09/16/2020 23:58:26 - INFO - volta.utils -   [GQA]: iter 56301 Ep: 15.28 loss 0.063 score 0.993 lr 1.04889e-05 
09/17/2020 00:01:25 - INFO - volta.utils -   [GQA]: iter 56321 Ep: 15.29 loss 0.052 score 0.995 lr 1.04768e-05 
09/17/2020 00:02:45 - INFO - volta.utils -   [GQA]: iter 56341 Ep: 15.29 loss 0.062 score 0.994 lr 1.04648e-05 
09/17/2020 00:04:08 - INFO - volta.utils -   [GQA]: iter 56361 Ep: 15.30 loss 0.050 score 0.995 lr 1.04527e-05 
09/17/2020 00:05:16 - INFO - volta.utils -   [GQA]: iter 56381 Ep: 15.30 loss 0.057 score 0.994 lr 1.04406e-05 
09/17/2020 00:07:43 - INFO - volta.utils -   [GQA]: iter 56401 Ep: 15.31 loss 0.056 score 0.994 lr 1.04286e-05 
09/17/2020 00:09:13 - INFO - volta.utils -   [GQA]: iter 56421 Ep: 15.32 loss 0.061 score 0.993 lr 1.04165e-05 
09/17/2020 00:10:51 - INFO - volta.utils -   [GQA]: iter 56441 Ep: 15.32 loss 0.067 score 0.991 lr 1.04045e-05 
09/17/2020 00:12:15 - INFO - volta.utils -   [GQA]: iter 56461 Ep: 15.33 loss 0.059 score 0.994 lr 1.03924e-05 
09/17/2020 00:15:26 - INFO - volta.utils -   [GQA]: iter 56481 Ep: 15.33 loss 0.062 score 0.992 lr 1.03803e-05 
09/17/2020 00:16:38 - INFO - volta.utils -   [GQA]: iter 56501 Ep: 15.34 loss 0.060 score 0.992 lr 1.03683e-05 
09/17/2020 00:18:08 - INFO - volta.utils -   [GQA]: iter 56521 Ep: 15.34 loss 0.055 score 0.994 lr 1.03562e-05 
09/17/2020 00:19:42 - INFO - volta.utils -   [GQA]: iter 56541 Ep: 15.35 loss 0.055 score 0.994 lr 1.03441e-05 
09/17/2020 00:22:30 - INFO - volta.utils -   [GQA]: iter 56561 Ep: 15.35 loss 0.059 score 0.992 lr 1.03321e-05 
09/17/2020 00:24:02 - INFO - volta.utils -   [GQA]: iter 56581 Ep: 15.36 loss 0.077 score 0.990 lr 1.032e-05 
09/17/2020 00:25:34 - INFO - volta.utils -   [GQA]: iter 56601 Ep: 15.36 loss 0.065 score 0.992 lr 1.03079e-05 
09/17/2020 00:27:13 - INFO - volta.utils -   [GQA]: iter 56621 Ep: 15.37 loss 0.057 score 0.995 lr 1.02959e-05 
09/17/2020 00:29:49 - INFO - volta.utils -   [GQA]: iter 56641 Ep: 15.37 loss 0.056 score 0.993 lr 1.02838e-05 
09/17/2020 00:31:13 - INFO - volta.utils -   [GQA]: iter 56661 Ep: 15.38 loss 0.054 score 0.995 lr 1.02717e-05 
09/17/2020 00:33:12 - INFO - volta.utils -   [GQA]: iter 56681 Ep: 15.39 loss 0.050 score 0.996 lr 1.02597e-05 
09/17/2020 00:34:34 - INFO - volta.utils -   [GQA]: iter 56701 Ep: 15.39 loss 0.057 score 0.994 lr 1.02476e-05 
09/17/2020 00:36:43 - INFO - volta.utils -   [GQA]: iter 56721 Ep: 15.40 loss 0.060 score 0.993 lr 1.02356e-05 
09/17/2020 00:38:14 - INFO - volta.utils -   [GQA]: iter 56741 Ep: 15.40 loss 0.054 score 0.995 lr 1.02235e-05 
09/17/2020 00:39:35 - INFO - volta.utils -   [GQA]: iter 56761 Ep: 15.41 loss 0.071 score 0.991 lr 1.02114e-05 
09/17/2020 00:41:06 - INFO - volta.utils -   [GQA]: iter 56781 Ep: 15.41 loss 0.053 score 0.994 lr 1.01994e-05 
09/17/2020 00:43:56 - INFO - volta.utils -   [GQA]: iter 56801 Ep: 15.42 loss 0.061 score 0.993 lr 1.01873e-05 
09/17/2020 00:45:34 - INFO - volta.utils -   [GQA]: iter 56821 Ep: 15.42 loss 0.071 score 0.990 lr 1.01752e-05 
09/17/2020 00:47:25 - INFO - volta.utils -   [GQA]: iter 56841 Ep: 15.43 loss 0.072 score 0.992 lr 1.01632e-05 
09/17/2020 00:48:45 - INFO - volta.utils -   [GQA]: iter 56861 Ep: 15.43 loss 0.057 score 0.995 lr 1.01511e-05 
09/17/2020 00:51:07 - INFO - volta.utils -   [GQA]: iter 56881 Ep: 15.44 loss 0.054 score 0.994 lr 1.0139e-05 
09/17/2020 00:52:47 - INFO - volta.utils -   [GQA]: iter 56901 Ep: 15.45 loss 0.053 score 0.993 lr 1.0127e-05 
09/17/2020 00:54:25 - INFO - volta.utils -   [GQA]: iter 56921 Ep: 15.45 loss 0.057 score 0.994 lr 1.01149e-05 
09/17/2020 00:55:46 - INFO - volta.utils -   [GQA]: iter 56941 Ep: 15.46 loss 0.065 score 0.992 lr 1.01028e-05 
09/17/2020 00:57:47 - INFO - volta.utils -   [GQA]: iter 56961 Ep: 15.46 loss 0.053 score 0.995 lr 1.00908e-05 
09/17/2020 00:59:19 - INFO - volta.utils -   [GQA]: iter 56981 Ep: 15.47 loss 0.067 score 0.992 lr 1.00787e-05 
09/17/2020 01:00:56 - INFO - volta.utils -   [GQA]: iter 57001 Ep: 15.47 loss 0.062 score 0.994 lr 1.00667e-05 
09/17/2020 01:02:18 - INFO - volta.utils -   [GQA]: iter 57021 Ep: 15.48 loss 0.063 score 0.993 lr 1.00546e-05 
09/17/2020 01:04:14 - INFO - volta.utils -   [GQA]: iter 57041 Ep: 15.48 loss 0.064 score 0.992 lr 1.00425e-05 
09/17/2020 01:05:39 - INFO - volta.utils -   [GQA]: iter 57061 Ep: 15.49 loss 0.059 score 0.993 lr 1.00305e-05 
09/17/2020 01:07:40 - INFO - volta.utils -   [GQA]: iter 57081 Ep: 15.49 loss 0.061 score 0.992 lr 1.00184e-05 
09/17/2020 01:08:44 - INFO - volta.utils -   [GQA]: iter 57101 Ep: 15.50 loss 0.056 score 0.994 lr 1.00063e-05 
09/17/2020 01:10:53 - INFO - volta.utils -   [GQA]: iter 57121 Ep: 15.51 loss 0.060 score 0.993 lr 9.99427e-06 
09/17/2020 01:12:12 - INFO - volta.utils -   [GQA]: iter 57141 Ep: 15.51 loss 0.065 score 0.992 lr 9.98221e-06 
09/17/2020 01:14:26 - INFO - volta.utils -   [GQA]: iter 57161 Ep: 15.52 loss 0.063 score 0.993 lr 9.97014e-06 
09/17/2020 01:16:00 - INFO - volta.utils -   [GQA]: iter 57181 Ep: 15.52 loss 0.064 score 0.994 lr 9.95808e-06 
09/17/2020 01:17:31 - INFO - volta.utils -   [GQA]: iter 57201 Ep: 15.53 loss 0.065 score 0.992 lr 9.94601e-06 
09/17/2020 01:19:02 - INFO - volta.utils -   [GQA]: iter 57221 Ep: 15.53 loss 0.063 score 0.992 lr 9.93395e-06 
09/17/2020 01:20:58 - INFO - volta.utils -   [GQA]: iter 57241 Ep: 15.54 loss 0.063 score 0.993 lr 9.92188e-06 
09/17/2020 01:22:37 - INFO - volta.utils -   [GQA]: iter 57261 Ep: 15.54 loss 0.071 score 0.992 lr 9.90982e-06 
09/17/2020 01:24:15 - INFO - volta.utils -   [GQA]: iter 57281 Ep: 15.55 loss 0.067 score 0.992 lr 9.89776e-06 
09/17/2020 01:26:08 - INFO - volta.utils -   [GQA]: iter 57301 Ep: 15.55 loss 0.061 score 0.993 lr 9.88569e-06 
09/17/2020 01:28:00 - INFO - volta.utils -   [GQA]: iter 57321 Ep: 15.56 loss 0.068 score 0.991 lr 9.87363e-06 
09/17/2020 01:29:34 - INFO - volta.utils -   [GQA]: iter 57341 Ep: 15.56 loss 0.057 score 0.994 lr 9.86156e-06 
09/17/2020 01:31:12 - INFO - volta.utils -   [GQA]: iter 57361 Ep: 15.57 loss 0.059 score 0.992 lr 9.8495e-06 
09/17/2020 01:33:05 - INFO - volta.utils -   [GQA]: iter 57381 Ep: 15.58 loss 0.071 score 0.992 lr 9.83744e-06 
09/17/2020 01:34:50 - INFO - volta.utils -   [GQA]: iter 57401 Ep: 15.58 loss 0.072 score 0.990 lr 9.82537e-06 
09/17/2020 01:35:57 - INFO - volta.utils -   [GQA]: iter 57421 Ep: 15.59 loss 0.055 score 0.994 lr 9.81331e-06 
09/17/2020 01:37:00 - INFO - volta.utils -   [GQA]: iter 57441 Ep: 15.59 loss 0.074 score 0.991 lr 9.80124e-06 
09/17/2020 01:38:30 - INFO - volta.utils -   [GQA]: iter 57461 Ep: 15.60 loss 0.058 score 0.993 lr 9.78918e-06 
09/17/2020 01:41:21 - INFO - volta.utils -   [GQA]: iter 57481 Ep: 15.60 loss 0.054 score 0.995 lr 9.77711e-06 
09/17/2020 01:43:02 - INFO - volta.utils -   [GQA]: iter 57501 Ep: 15.61 loss 0.061 score 0.992 lr 9.76505e-06 
09/17/2020 01:44:32 - INFO - volta.utils -   [GQA]: iter 57521 Ep: 15.61 loss 0.065 score 0.993 lr 9.75299e-06 
09/17/2020 01:45:54 - INFO - volta.utils -   [GQA]: iter 57541 Ep: 15.62 loss 0.061 score 0.993 lr 9.74092e-06 
09/17/2020 01:48:28 - INFO - volta.utils -   [GQA]: iter 57561 Ep: 15.62 loss 0.070 score 0.990 lr 9.72886e-06 
09/17/2020 01:49:59 - INFO - volta.utils -   [GQA]: iter 57581 Ep: 15.63 loss 0.062 score 0.993 lr 9.71679e-06 
09/17/2020 01:51:12 - INFO - volta.utils -   [GQA]: iter 57601 Ep: 15.64 loss 0.056 score 0.992 lr 9.70473e-06 
09/17/2020 01:53:15 - INFO - volta.utils -   [GQA]: iter 57621 Ep: 15.64 loss 0.066 score 0.993 lr 9.69266e-06 
09/17/2020 01:56:01 - INFO - volta.utils -   [GQA]: iter 57641 Ep: 15.65 loss 0.053 score 0.994 lr 9.6806e-06 
09/17/2020 01:57:23 - INFO - volta.utils -   [GQA]: iter 57661 Ep: 15.65 loss 0.056 score 0.995 lr 9.66854e-06 
09/17/2020 01:58:32 - INFO - volta.utils -   [GQA]: iter 57681 Ep: 15.66 loss 0.056 score 0.993 lr 9.65647e-06 
09/17/2020 02:00:50 - INFO - volta.utils -   [GQA]: iter 57701 Ep: 15.66 loss 0.053 score 0.995 lr 9.64441e-06 
09/17/2020 02:02:52 - INFO - volta.utils -   [GQA]: iter 57721 Ep: 15.67 loss 0.059 score 0.992 lr 9.63234e-06 
09/17/2020 02:04:33 - INFO - volta.utils -   [GQA]: iter 57741 Ep: 15.67 loss 0.053 score 0.996 lr 9.62028e-06 
09/17/2020 02:06:19 - INFO - volta.utils -   [GQA]: iter 57761 Ep: 15.68 loss 0.066 score 0.992 lr 9.60822e-06 
09/17/2020 02:07:51 - INFO - volta.utils -   [GQA]: iter 57781 Ep: 15.68 loss 0.059 score 0.993 lr 9.59615e-06 
09/17/2020 02:09:57 - INFO - volta.utils -   [GQA]: iter 57801 Ep: 15.69 loss 0.063 score 0.992 lr 9.58409e-06 
09/17/2020 02:11:30 - INFO - volta.utils -   [GQA]: iter 57821 Ep: 15.70 loss 0.065 score 0.993 lr 9.57202e-06 
09/17/2020 02:12:59 - INFO - volta.utils -   [GQA]: iter 57841 Ep: 15.70 loss 0.053 score 0.994 lr 9.55996e-06 
09/17/2020 02:14:28 - INFO - volta.utils -   [GQA]: iter 57861 Ep: 15.71 loss 0.056 score 0.994 lr 9.54789e-06 
09/17/2020 02:16:38 - INFO - volta.utils -   [GQA]: iter 57881 Ep: 15.71 loss 0.058 score 0.994 lr 9.53583e-06 
09/17/2020 02:18:22 - INFO - volta.utils -   [GQA]: iter 57901 Ep: 15.72 loss 0.070 score 0.991 lr 9.52377e-06 
09/17/2020 02:21:21 - INFO - volta.utils -   [GQA]: iter 57921 Ep: 15.72 loss 0.060 score 0.994 lr 9.5117e-06 
09/17/2020 02:22:52 - INFO - volta.utils -   [GQA]: iter 57941 Ep: 15.73 loss 0.064 score 0.991 lr 9.49964e-06 
09/17/2020 02:24:21 - INFO - volta.utils -   [GQA]: iter 57961 Ep: 15.73 loss 0.062 score 0.993 lr 9.48757e-06 
09/17/2020 02:25:37 - INFO - volta.utils -   [GQA]: iter 57981 Ep: 15.74 loss 0.066 score 0.991 lr 9.47551e-06 
09/17/2020 02:28:33 - INFO - volta.utils -   [GQA]: iter 58001 Ep: 15.74 loss 0.065 score 0.992 lr 9.46345e-06 
09/17/2020 02:29:59 - INFO - volta.utils -   [GQA]: iter 58021 Ep: 15.75 loss 0.062 score 0.993 lr 9.45138e-06 
09/17/2020 02:30:49 - INFO - volta.utils -   [GQA]: iter 58041 Ep: 15.75 loss 0.055 score 0.994 lr 9.43932e-06 
09/17/2020 02:32:20 - INFO - volta.utils -   [GQA]: iter 58061 Ep: 15.76 loss 0.061 score 0.992 lr 9.42725e-06 
09/17/2020 02:35:13 - INFO - volta.utils -   [GQA]: iter 58081 Ep: 15.77 loss 0.063 score 0.993 lr 9.41519e-06 
09/17/2020 02:36:31 - INFO - volta.utils -   [GQA]: iter 58101 Ep: 15.77 loss 0.054 score 0.994 lr 9.40312e-06 
09/17/2020 02:37:38 - INFO - volta.utils -   [GQA]: iter 58121 Ep: 15.78 loss 0.069 score 0.991 lr 9.39106e-06 
09/17/2020 02:38:53 - INFO - volta.utils -   [GQA]: iter 58141 Ep: 15.78 loss 0.066 score 0.992 lr 9.379e-06 
09/17/2020 02:41:16 - INFO - volta.utils -   [GQA]: iter 58161 Ep: 15.79 loss 0.069 score 0.991 lr 9.36693e-06 
09/17/2020 02:42:38 - INFO - volta.utils -   [GQA]: iter 58181 Ep: 15.79 loss 0.067 score 0.991 lr 9.35487e-06 
09/17/2020 02:44:09 - INFO - volta.utils -   [GQA]: iter 58201 Ep: 15.80 loss 0.060 score 0.992 lr 9.3428e-06 
09/17/2020 02:45:41 - INFO - volta.utils -   [GQA]: iter 58221 Ep: 15.80 loss 0.062 score 0.993 lr 9.33074e-06 
09/17/2020 02:47:22 - INFO - volta.utils -   [GQA]: iter 58241 Ep: 15.81 loss 0.067 score 0.992 lr 9.31868e-06 
09/17/2020 02:48:46 - INFO - volta.utils -   [GQA]: iter 58261 Ep: 15.81 loss 0.060 score 0.993 lr 9.30661e-06 
09/17/2020 02:50:43 - INFO - volta.utils -   [GQA]: iter 58281 Ep: 15.82 loss 0.055 score 0.993 lr 9.29455e-06 
09/17/2020 02:52:05 - INFO - volta.utils -   [GQA]: iter 58301 Ep: 15.83 loss 0.064 score 0.992 lr 9.28248e-06 
09/17/2020 02:53:24 - INFO - volta.utils -   [GQA]: iter 58321 Ep: 15.83 loss 0.056 score 0.994 lr 9.27042e-06 
09/17/2020 02:55:35 - INFO - volta.utils -   [GQA]: iter 58341 Ep: 15.84 loss 0.064 score 0.991 lr 9.25835e-06 
09/17/2020 02:57:06 - INFO - volta.utils -   [GQA]: iter 58361 Ep: 15.84 loss 0.056 score 0.994 lr 9.24629e-06 
09/17/2020 02:58:39 - INFO - volta.utils -   [GQA]: iter 58381 Ep: 15.85 loss 0.063 score 0.993 lr 9.23423e-06 
09/17/2020 02:59:40 - INFO - volta.utils -   [GQA]: iter 58401 Ep: 15.85 loss 0.062 score 0.993 lr 9.22216e-06 
09/17/2020 03:02:41 - INFO - volta.utils -   [GQA]: iter 58421 Ep: 15.86 loss 0.075 score 0.992 lr 9.2101e-06 
09/17/2020 03:03:53 - INFO - volta.utils -   [GQA]: iter 58441 Ep: 15.86 loss 0.063 score 0.992 lr 9.19803e-06 
09/17/2020 03:05:25 - INFO - volta.utils -   [GQA]: iter 58461 Ep: 15.87 loss 0.069 score 0.991 lr 9.18597e-06 
09/17/2020 03:07:09 - INFO - volta.utils -   [GQA]: iter 58481 Ep: 15.87 loss 0.065 score 0.993 lr 9.17391e-06 
09/17/2020 03:09:32 - INFO - volta.utils -   [GQA]: iter 58501 Ep: 15.88 loss 0.058 score 0.994 lr 9.16184e-06 
09/17/2020 03:11:12 - INFO - volta.utils -   [GQA]: iter 58521 Ep: 15.89 loss 0.061 score 0.993 lr 9.14978e-06 
09/17/2020 03:12:34 - INFO - volta.utils -   [GQA]: iter 58541 Ep: 15.89 loss 0.065 score 0.991 lr 9.13771e-06 
09/17/2020 03:13:12 - INFO - volta.utils -   [GQA]: iter 58561 Ep: 15.90 loss 0.062 score 0.992 lr 9.12565e-06 
09/17/2020 03:14:42 - INFO - volta.utils -   [GQA]: iter 58581 Ep: 15.90 loss 0.071 score 0.992 lr 9.11358e-06 
09/17/2020 03:17:23 - INFO - volta.utils -   [GQA]: iter 58601 Ep: 15.91 loss 0.058 score 0.992 lr 9.10152e-06 
09/17/2020 03:18:55 - INFO - volta.utils -   [GQA]: iter 58621 Ep: 15.91 loss 0.052 score 0.993 lr 9.08946e-06 
09/17/2020 03:20:46 - INFO - volta.utils -   [GQA]: iter 58641 Ep: 15.92 loss 0.064 score 0.993 lr 9.07739e-06 
09/17/2020 03:22:27 - INFO - volta.utils -   [GQA]: iter 58661 Ep: 15.92 loss 0.062 score 0.993 lr 9.06533e-06 
09/17/2020 03:24:47 - INFO - volta.utils -   [GQA]: iter 58681 Ep: 15.93 loss 0.066 score 0.992 lr 9.05326e-06 
09/17/2020 03:26:20 - INFO - volta.utils -   [GQA]: iter 58701 Ep: 15.93 loss 0.062 score 0.994 lr 9.0412e-06 
09/17/2020 03:27:51 - INFO - volta.utils -   [GQA]: iter 58721 Ep: 15.94 loss 0.067 score 0.992 lr 9.02913e-06 
09/17/2020 03:29:01 - INFO - volta.utils -   [GQA]: iter 58741 Ep: 15.94 loss 0.062 score 0.992 lr 9.01707e-06 
09/17/2020 03:31:50 - INFO - volta.utils -   [GQA]: iter 58761 Ep: 15.95 loss 0.067 score 0.992 lr 9.00501e-06 
09/17/2020 03:33:14 - INFO - volta.utils -   [GQA]: iter 58781 Ep: 15.96 loss 0.057 score 0.993 lr 8.99294e-06 
09/17/2020 03:34:29 - INFO - volta.utils -   [GQA]: iter 58801 Ep: 15.96 loss 0.066 score 0.992 lr 8.98088e-06 
09/17/2020 03:35:43 - INFO - volta.utils -   [GQA]: iter 58821 Ep: 15.97 loss 0.067 score 0.992 lr 8.96881e-06 
09/17/2020 03:38:12 - INFO - volta.utils -   [GQA]: iter 58841 Ep: 15.97 loss 0.067 score 0.991 lr 8.95675e-06 
09/17/2020 03:39:28 - INFO - volta.utils -   [GQA]: iter 58861 Ep: 15.98 loss 0.069 score 0.993 lr 8.94469e-06 
09/17/2020 03:41:06 - INFO - volta.utils -   [GQA]: iter 58881 Ep: 15.98 loss 0.064 score 0.993 lr 8.93262e-06 
09/17/2020 03:42:11 - INFO - volta.utils -   [GQA]: iter 58901 Ep: 15.99 loss 0.066 score 0.992 lr 8.92056e-06 
09/17/2020 03:44:50 - INFO - volta.utils -   [GQA]: iter 58921 Ep: 15.99 loss 0.071 score 0.991 lr 8.90849e-06 
09/17/2020 03:46:37 - INFO - volta.utils -   [GQA]: iter 58941 Ep: 16.00 loss 0.059 score 0.993 lr 8.89643e-06 
09/17/2020 03:46:39 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  50%|█████     | 4/8 [22:03:05<22:03:42, 19855.56s/it]09/17/2020 04:05:30 - INFO - volta.utils -   Eval task TASK15 on iteration 58945 
09/17/2020 04:05:30 - INFO - volta.utils -   Validation [GQA]: loss 4.102 score 64.443 
09/17/2020 04:05:56 - INFO - volta.utils -   [GQA]: iter 58965 Ep: 16.01 loss 0.174 score 0.974 lr 8.88316e-06 
09/17/2020 04:06:42 - INFO - volta.utils -   [GQA]: iter 58985 Ep: 16.01 loss 0.212 score 0.966 lr 8.86989e-06 
09/17/2020 04:07:52 - INFO - volta.utils -   [GQA]: iter 59005 Ep: 16.02 loss 0.199 score 0.971 lr 8.85782e-06 
09/17/2020 04:08:51 - INFO - volta.utils -   [GQA]: iter 59025 Ep: 16.02 loss 0.195 score 0.970 lr 8.84576e-06 
09/17/2020 04:10:17 - INFO - volta.utils -   [GQA]: iter 59045 Ep: 16.03 loss 0.211 score 0.963 lr 8.8337e-06 
09/17/2020 04:11:54 - INFO - volta.utils -   [GQA]: iter 59065 Ep: 16.03 loss 0.201 score 0.970 lr 8.82163e-06 
09/17/2020 04:12:54 - INFO - volta.utils -   [GQA]: iter 59085 Ep: 16.04 loss 0.232 score 0.963 lr 8.80957e-06 
09/17/2020 04:14:16 - INFO - volta.utils -   [GQA]: iter 59105 Ep: 16.04 loss 0.197 score 0.969 lr 8.7975e-06 
09/17/2020 04:16:02 - INFO - volta.utils -   [GQA]: iter 59125 Ep: 16.05 loss 0.207 score 0.966 lr 8.78544e-06 
09/17/2020 04:17:43 - INFO - volta.utils -   [GQA]: iter 59145 Ep: 16.05 loss 0.225 score 0.963 lr 8.77337e-06 
09/17/2020 04:19:15 - INFO - volta.utils -   [GQA]: iter 59165 Ep: 16.06 loss 0.196 score 0.970 lr 8.76131e-06 
09/17/2020 04:19:51 - INFO - volta.utils -   [GQA]: iter 59185 Ep: 16.07 loss 0.217 score 0.963 lr 8.74925e-06 
09/17/2020 04:22:01 - INFO - volta.utils -   [GQA]: iter 59205 Ep: 16.07 loss 0.223 score 0.969 lr 8.73718e-06 
09/17/2020 04:23:52 - INFO - volta.utils -   [GQA]: iter 59225 Ep: 16.08 loss 0.193 score 0.971 lr 8.72512e-06 
09/17/2020 04:24:51 - INFO - volta.utils -   [GQA]: iter 59245 Ep: 16.08 loss 0.195 score 0.969 lr 8.71305e-06 
09/17/2020 04:26:17 - INFO - volta.utils -   [GQA]: iter 59265 Ep: 16.09 loss 0.209 score 0.967 lr 8.70099e-06 
09/17/2020 04:28:03 - INFO - volta.utils -   [GQA]: iter 59285 Ep: 16.09 loss 0.203 score 0.970 lr 8.68893e-06 
09/17/2020 04:29:27 - INFO - volta.utils -   [GQA]: iter 59305 Ep: 16.10 loss 0.209 score 0.967 lr 8.67686e-06 
09/17/2020 04:30:33 - INFO - volta.utils -   [GQA]: iter 59325 Ep: 16.10 loss 0.216 score 0.964 lr 8.6648e-06 
09/17/2020 04:31:46 - INFO - volta.utils -   [GQA]: iter 59345 Ep: 16.11 loss 0.202 score 0.970 lr 8.65273e-06 
09/17/2020 04:33:51 - INFO - volta.utils -   [GQA]: iter 59365 Ep: 16.11 loss 0.224 score 0.964 lr 8.64067e-06 
09/17/2020 04:34:54 - INFO - volta.utils -   [GQA]: iter 59385 Ep: 16.12 loss 0.209 score 0.965 lr 8.6286e-06 
09/17/2020 04:36:46 - INFO - volta.utils -   [GQA]: iter 59405 Ep: 16.13 loss 0.201 score 0.965 lr 8.61654e-06 
09/17/2020 04:38:18 - INFO - volta.utils -   [GQA]: iter 59425 Ep: 16.13 loss 0.197 score 0.971 lr 8.60448e-06 
09/17/2020 04:40:16 - INFO - volta.utils -   [GQA]: iter 59445 Ep: 16.14 loss 0.218 score 0.962 lr 8.59241e-06 
09/17/2020 04:41:30 - INFO - volta.utils -   [GQA]: iter 59465 Ep: 16.14 loss 0.206 score 0.968 lr 8.58035e-06 
09/17/2020 04:43:08 - INFO - volta.utils -   [GQA]: iter 59485 Ep: 16.15 loss 0.212 score 0.967 lr 8.56828e-06 
09/17/2020 04:44:58 - INFO - volta.utils -   [GQA]: iter 59505 Ep: 16.15 loss 0.205 score 0.971 lr 8.55622e-06 
09/17/2020 04:46:38 - INFO - volta.utils -   [GQA]: iter 59525 Ep: 16.16 loss 0.207 score 0.968 lr 8.54415e-06 
09/17/2020 04:48:03 - INFO - volta.utils -   [GQA]: iter 59545 Ep: 16.16 loss 0.211 score 0.967 lr 8.53209e-06 
09/17/2020 04:50:14 - INFO - volta.utils -   [GQA]: iter 59565 Ep: 16.17 loss 0.175 score 0.972 lr 8.52003e-06 
09/17/2020 04:52:17 - INFO - volta.utils -   [GQA]: iter 59585 Ep: 16.17 loss 0.175 score 0.972 lr 8.50796e-06 
09/17/2020 04:54:04 - INFO - volta.utils -   [GQA]: iter 59605 Ep: 16.18 loss 0.185 score 0.972 lr 8.4959e-06 
09/17/2020 04:55:37 - INFO - volta.utils -   [GQA]: iter 59625 Ep: 16.18 loss 0.215 score 0.966 lr 8.48383e-06 
09/17/2020 04:57:42 - INFO - volta.utils -   [GQA]: iter 59645 Ep: 16.19 loss 0.202 score 0.968 lr 8.47177e-06 
09/17/2020 04:59:24 - INFO - volta.utils -   [GQA]: iter 59665 Ep: 16.20 loss 0.204 score 0.968 lr 8.45971e-06 
09/17/2020 05:00:41 - INFO - volta.utils -   [GQA]: iter 59685 Ep: 16.20 loss 0.223 score 0.962 lr 8.44764e-06 
09/17/2020 05:02:04 - INFO - volta.utils -   [GQA]: iter 59705 Ep: 16.21 loss 0.207 score 0.968 lr 8.43558e-06 
09/17/2020 05:03:27 - INFO - volta.utils -   [GQA]: iter 59725 Ep: 16.21 loss 0.210 score 0.967 lr 8.42351e-06 
09/17/2020 05:05:50 - INFO - volta.utils -   [GQA]: iter 59745 Ep: 16.22 loss 0.198 score 0.970 lr 8.41145e-06 
09/17/2020 05:06:23 - INFO - volta.utils -   [GQA]: iter 59765 Ep: 16.22 loss 0.195 score 0.967 lr 8.39938e-06 
09/17/2020 05:07:56 - INFO - volta.utils -   [GQA]: iter 59785 Ep: 16.23 loss 0.232 score 0.961 lr 8.38732e-06 
09/17/2020 05:09:22 - INFO - volta.utils -   [GQA]: iter 59805 Ep: 16.23 loss 0.214 score 0.967 lr 8.37526e-06 
09/17/2020 05:12:04 - INFO - volta.utils -   [GQA]: iter 59825 Ep: 16.24 loss 0.203 score 0.968 lr 8.36319e-06 
09/17/2020 05:13:12 - INFO - volta.utils -   [GQA]: iter 59845 Ep: 16.24 loss 0.199 score 0.967 lr 8.35113e-06 
09/17/2020 05:14:41 - INFO - volta.utils -   [GQA]: iter 59865 Ep: 16.25 loss 0.207 score 0.967 lr 8.33906e-06 
09/17/2020 05:16:22 - INFO - volta.utils -   [GQA]: iter 59885 Ep: 16.26 loss 0.193 score 0.972 lr 8.327e-06 
09/17/2020 05:18:45 - INFO - volta.utils -   [GQA]: iter 59905 Ep: 16.26 loss 0.205 score 0.969 lr 8.31494e-06 
09/17/2020 05:19:52 - INFO - volta.utils -   [GQA]: iter 59925 Ep: 16.27 loss 0.199 score 0.965 lr 8.30287e-06 
09/17/2020 05:21:18 - INFO - volta.utils -   [GQA]: iter 59945 Ep: 16.27 loss 0.220 score 0.965 lr 8.29081e-06 
09/17/2020 05:22:44 - INFO - volta.utils -   [GQA]: iter 59965 Ep: 16.28 loss 0.192 score 0.970 lr 8.27874e-06 
09/17/2020 05:25:38 - INFO - volta.utils -   [GQA]: iter 59985 Ep: 16.28 loss 0.221 score 0.963 lr 8.26668e-06 
09/17/2020 05:27:05 - INFO - volta.utils -   [GQA]: iter 60005 Ep: 16.29 loss 0.211 score 0.965 lr 8.25461e-06 
09/17/2020 05:28:34 - INFO - volta.utils -   [GQA]: iter 60025 Ep: 16.29 loss 0.233 score 0.964 lr 8.24255e-06 
09/17/2020 05:29:55 - INFO - volta.utils -   [GQA]: iter 60045 Ep: 16.30 loss 0.190 score 0.973 lr 8.23049e-06 
09/17/2020 05:32:05 - INFO - volta.utils -   [GQA]: iter 60065 Ep: 16.30 loss 0.196 score 0.969 lr 8.21842e-06 
09/17/2020 05:33:01 - INFO - volta.utils -   [GQA]: iter 60085 Ep: 16.31 loss 0.184 score 0.974 lr 8.20636e-06 
