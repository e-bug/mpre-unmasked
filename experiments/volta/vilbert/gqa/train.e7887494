/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
09/17/2020 05:39:30 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
09/17/2020 05:39:31 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17/2020 05:39:31 - INFO - volta.task_utils -   Loading GQA Dataset with batch size 256
09/17/2020 05:39:31 - INFO - volta.datasets.gqa_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/gqa/cache/GQA_train_26.pkl
09/17/2020 05:44:27 - INFO - volta.datasets.gqa_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/gqa/cache/GQA_val_26.pkl
09/17/2020 05:45:13 - INFO - volta.utils -   logging file at: ../../logs/volta/gqa/GQA_vilbert_base
09/17/2020 05:45:13 - INFO - volta.utils -   loading weights file /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/volta/vilbert/vilbert_base/pytorch_model_9.bin
09/17/2020 05:45:19 - INFO - volta.utils -   
09/17/2020 05:45:20 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK15.logit_fc.0.weight', 'clfs_dict.TASK15.logit_fc.0.bias', 'clfs_dict.TASK15.logit_fc.2.weight', 'clfs_dict.TASK15.logit_fc.2.bias', 'clfs_dict.TASK15.logit_fc.3.weight', 'clfs_dict.TASK15.logit_fc.3.bias']
09/17/2020 05:45:20 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
09/17/2020 05:45:29 - INFO - __main__ -   >> Trainable Parameters:
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(1024, 2048)    |2097152     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(1024, 5)       |5120        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.weight                           |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.bias                             |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                   |torch.float32    |(1024, 1024)    |1048576     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.0.weight                           |torch.float32    |(1536, 1024)    |1572864     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.0.bias                             |torch.float32    |(1536,)         |1536        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.2.weight                           |torch.float32    |(1536,)         |1536        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.2.bias                             |torch.float32    |(1536,)         |1536        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.3.weight                           |torch.float32    |(1842, 1536)    |2829312     |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.3.bias                             |torch.float32    |(1842,)         |1842        |
09/17/2020 05:45:29 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/17/2020 05:45:29 - INFO - __main__ -   >> # TrainableParams:       	240.11	M
09/17/2020 05:45:29 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
09/17/2020 05:45:29 - INFO - __main__ -   >> # TotalParams:           	240.11	M

Epoch:   0%|          | 0/4 [00:00<?, ?it/s]09/17/2020 06:06:45 - INFO - volta.utils -   Eval task TASK15 on iteration 58945 
09/17/2020 06:06:45 - INFO - volta.utils -   Validation [GQA]: loss 4.101 score 64.442 
09/17/2020 06:06:57 - INFO - volta.utils -   [GQA]: iter 58965 Ep: 16.01 loss 0.047 score 0.995 lr 8.88316e-06 
09/17/2020 06:08:19 - INFO - volta.utils -   [GQA]: iter 58985 Ep: 16.01 loss 0.038 score 0.996 lr 8.86989e-06 
09/17/2020 06:09:27 - INFO - volta.utils -   [GQA]: iter 59005 Ep: 16.02 loss 0.046 score 0.996 lr 8.85782e-06 
09/17/2020 06:10:41 - INFO - volta.utils -   [GQA]: iter 59025 Ep: 16.02 loss 0.043 score 0.996 lr 8.84576e-06 
09/17/2020 06:12:26 - INFO - volta.utils -   [GQA]: iter 59045 Ep: 16.03 loss 0.042 score 0.996 lr 8.8337e-06 
09/17/2020 06:13:47 - INFO - volta.utils -   [GQA]: iter 59065 Ep: 16.03 loss 0.049 score 0.995 lr 8.82163e-06 
09/17/2020 06:14:32 - INFO - volta.utils -   [GQA]: iter 59085 Ep: 16.04 loss 0.043 score 0.996 lr 8.80957e-06 
09/17/2020 06:15:46 - INFO - volta.utils -   [GQA]: iter 59105 Ep: 16.04 loss 0.036 score 0.997 lr 8.7975e-06 
09/17/2020 06:17:52 - INFO - volta.utils -   [GQA]: iter 59125 Ep: 16.05 loss 0.044 score 0.996 lr 8.78544e-06 
09/17/2020 06:19:15 - INFO - volta.utils -   [GQA]: iter 59145 Ep: 16.05 loss 0.040 score 0.996 lr 8.77337e-06 
09/17/2020 06:20:27 - INFO - volta.utils -   [GQA]: iter 59165 Ep: 16.06 loss 0.045 score 0.996 lr 8.76131e-06 
09/17/2020 06:21:52 - INFO - volta.utils -   [GQA]: iter 59185 Ep: 16.07 loss 0.039 score 0.997 lr 8.74925e-06 
09/17/2020 06:24:25 - INFO - volta.utils -   [GQA]: iter 59205 Ep: 16.07 loss 0.035 score 0.997 lr 8.73718e-06 
09/17/2020 06:26:02 - INFO - volta.utils -   [GQA]: iter 59225 Ep: 16.08 loss 0.039 score 0.997 lr 8.72512e-06 
09/17/2020 06:27:43 - INFO - volta.utils -   [GQA]: iter 59245 Ep: 16.08 loss 0.042 score 0.996 lr 8.71305e-06 
09/17/2020 06:28:58 - INFO - volta.utils -   [GQA]: iter 59265 Ep: 16.09 loss 0.031 score 0.998 lr 8.70099e-06 
09/17/2020 06:31:52 - INFO - volta.utils -   [GQA]: iter 59285 Ep: 16.09 loss 0.034 score 0.997 lr 8.68893e-06 
09/17/2020 06:33:11 - INFO - volta.utils -   [GQA]: iter 59305 Ep: 16.10 loss 0.044 score 0.996 lr 8.67686e-06 
09/17/2020 06:34:49 - INFO - volta.utils -   [GQA]: iter 59325 Ep: 16.10 loss 0.040 score 0.996 lr 8.6648e-06 
09/17/2020 06:36:23 - INFO - volta.utils -   [GQA]: iter 59345 Ep: 16.11 loss 0.040 score 0.996 lr 8.65273e-06 
09/17/2020 06:38:37 - INFO - volta.utils -   [GQA]: iter 59365 Ep: 16.11 loss 0.031 score 0.998 lr 8.64067e-06 
09/17/2020 06:39:42 - INFO - volta.utils -   [GQA]: iter 59385 Ep: 16.12 loss 0.042 score 0.996 lr 8.6286e-06 
09/17/2020 06:41:12 - INFO - volta.utils -   [GQA]: iter 59405 Ep: 16.13 loss 0.036 score 0.996 lr 8.61654e-06 
09/17/2020 06:42:52 - INFO - volta.utils -   [GQA]: iter 59425 Ep: 16.13 loss 0.041 score 0.996 lr 8.60448e-06 
09/17/2020 06:45:09 - INFO - volta.utils -   [GQA]: iter 59445 Ep: 16.14 loss 0.037 score 0.997 lr 8.59241e-06 
09/17/2020 06:46:53 - INFO - volta.utils -   [GQA]: iter 59465 Ep: 16.14 loss 0.043 score 0.995 lr 8.58035e-06 
09/17/2020 06:48:31 - INFO - volta.utils -   [GQA]: iter 59485 Ep: 16.15 loss 0.032 score 0.997 lr 8.56828e-06 
09/17/2020 06:50:10 - INFO - volta.utils -   [GQA]: iter 59505 Ep: 16.15 loss 0.037 score 0.997 lr 8.55622e-06 
09/17/2020 06:52:20 - INFO - volta.utils -   [GQA]: iter 59525 Ep: 16.16 loss 0.039 score 0.996 lr 8.54415e-06 
09/17/2020 06:54:00 - INFO - volta.utils -   [GQA]: iter 59545 Ep: 16.16 loss 0.035 score 0.997 lr 8.53209e-06 
09/17/2020 06:56:13 - INFO - volta.utils -   [GQA]: iter 59565 Ep: 16.17 loss 0.039 score 0.996 lr 8.52003e-06 
09/17/2020 06:57:11 - INFO - volta.utils -   [GQA]: iter 59585 Ep: 16.17 loss 0.035 score 0.997 lr 8.50796e-06 
09/17/2020 06:59:42 - INFO - volta.utils -   [GQA]: iter 59605 Ep: 16.18 loss 0.035 score 0.997 lr 8.4959e-06 
09/17/2020 07:01:35 - INFO - volta.utils -   [GQA]: iter 59625 Ep: 16.18 loss 0.032 score 0.998 lr 8.48383e-06 
09/17/2020 07:02:22 - INFO - volta.utils -   [GQA]: iter 59645 Ep: 16.19 loss 0.029 score 0.998 lr 8.47177e-06 
09/17/2020 07:03:46 - INFO - volta.utils -   [GQA]: iter 59665 Ep: 16.20 loss 0.030 score 0.998 lr 8.45971e-06 
09/17/2020 07:06:12 - INFO - volta.utils -   [GQA]: iter 59685 Ep: 16.20 loss 0.025 score 0.999 lr 8.44764e-06 
09/17/2020 07:07:59 - INFO - volta.utils -   [GQA]: iter 59705 Ep: 16.21 loss 0.035 score 0.996 lr 8.43558e-06 
09/17/2020 07:09:29 - INFO - volta.utils -   [GQA]: iter 59725 Ep: 16.21 loss 0.032 score 0.997 lr 8.42351e-06 
09/17/2020 07:11:05 - INFO - volta.utils -   [GQA]: iter 59745 Ep: 16.22 loss 0.029 score 0.998 lr 8.41145e-06 
09/17/2020 07:12:47 - INFO - volta.utils -   [GQA]: iter 59765 Ep: 16.22 loss 0.039 score 0.996 lr 8.39938e-06 
09/17/2020 07:14:56 - INFO - volta.utils -   [GQA]: iter 59785 Ep: 16.23 loss 0.041 score 0.997 lr 8.38732e-06 
09/17/2020 07:16:27 - INFO - volta.utils -   [GQA]: iter 59805 Ep: 16.23 loss 0.037 score 0.996 lr 8.37526e-06 
09/17/2020 07:17:57 - INFO - volta.utils -   [GQA]: iter 59825 Ep: 16.24 loss 0.043 score 0.995 lr 8.36319e-06 
09/17/2020 07:19:28 - INFO - volta.utils -   [GQA]: iter 59845 Ep: 16.24 loss 0.035 score 0.997 lr 8.35113e-06 
09/17/2020 07:22:23 - INFO - volta.utils -   [GQA]: iter 59865 Ep: 16.25 loss 0.038 score 0.997 lr 8.33906e-06 
09/17/2020 07:23:52 - INFO - volta.utils -   [GQA]: iter 59885 Ep: 16.26 loss 0.040 score 0.996 lr 8.327e-06 
09/17/2020 07:25:23 - INFO - volta.utils -   [GQA]: iter 59905 Ep: 16.26 loss 0.037 score 0.997 lr 8.31494e-06 
09/17/2020 07:26:48 - INFO - volta.utils -   [GQA]: iter 59925 Ep: 16.27 loss 0.037 score 0.997 lr 8.30287e-06 
09/17/2020 07:29:30 - INFO - volta.utils -   [GQA]: iter 59945 Ep: 16.27 loss 0.037 score 0.996 lr 8.29081e-06 
09/17/2020 07:30:47 - INFO - volta.utils -   [GQA]: iter 59965 Ep: 16.28 loss 0.036 score 0.996 lr 8.27874e-06 
09/17/2020 07:32:08 - INFO - volta.utils -   [GQA]: iter 59985 Ep: 16.28 loss 0.032 score 0.997 lr 8.26668e-06 
09/17/2020 07:33:36 - INFO - volta.utils -   [GQA]: iter 60005 Ep: 16.29 loss 0.030 score 0.997 lr 8.25461e-06 
09/17/2020 07:35:35 - INFO - volta.utils -   [GQA]: iter 60025 Ep: 16.29 loss 0.039 score 0.997 lr 8.24255e-06 
09/17/2020 07:37:10 - INFO - volta.utils -   [GQA]: iter 60045 Ep: 16.30 loss 0.040 score 0.996 lr 8.23049e-06 
09/17/2020 07:38:42 - INFO - volta.utils -   [GQA]: iter 60065 Ep: 16.30 loss 0.036 score 0.996 lr 8.21842e-06 
09/17/2020 07:39:48 - INFO - volta.utils -   [GQA]: iter 60085 Ep: 16.31 loss 0.035 score 0.996 lr 8.20636e-06 
09/17/2020 07:42:24 - INFO - volta.utils -   [GQA]: iter 60105 Ep: 16.32 loss 0.032 score 0.998 lr 8.19429e-06 
09/17/2020 07:43:50 - INFO - volta.utils -   [GQA]: iter 60125 Ep: 16.32 loss 0.040 score 0.995 lr 8.18223e-06 
09/17/2020 07:45:24 - INFO - volta.utils -   [GQA]: iter 60145 Ep: 16.33 loss 0.034 score 0.997 lr 8.17017e-06 
09/17/2020 07:46:47 - INFO - volta.utils -   [GQA]: iter 60165 Ep: 16.33 loss 0.042 score 0.996 lr 8.1581e-06 
09/17/2020 07:49:03 - INFO - volta.utils -   [GQA]: iter 60185 Ep: 16.34 loss 0.033 score 0.998 lr 8.14604e-06 
09/17/2020 07:50:17 - INFO - volta.utils -   [GQA]: iter 60205 Ep: 16.34 loss 0.038 score 0.996 lr 8.13397e-06 
09/17/2020 07:51:37 - INFO - volta.utils -   [GQA]: iter 60225 Ep: 16.35 loss 0.038 score 0.997 lr 8.12191e-06 
09/17/2020 07:53:03 - INFO - volta.utils -   [GQA]: iter 60245 Ep: 16.35 loss 0.037 score 0.996 lr 8.10984e-06 
09/17/2020 07:55:23 - INFO - volta.utils -   [GQA]: iter 60265 Ep: 16.36 loss 0.036 score 0.996 lr 8.09778e-06 
09/17/2020 07:56:37 - INFO - volta.utils -   [GQA]: iter 60285 Ep: 16.36 loss 0.039 score 0.997 lr 8.08572e-06 
09/17/2020 07:57:58 - INFO - volta.utils -   [GQA]: iter 60305 Ep: 16.37 loss 0.029 score 0.998 lr 8.07365e-06 
09/17/2020 07:59:12 - INFO - volta.utils -   [GQA]: iter 60325 Ep: 16.37 loss 0.042 score 0.996 lr 8.06159e-06 
09/17/2020 08:01:48 - INFO - volta.utils -   [GQA]: iter 60345 Ep: 16.38 loss 0.039 score 0.995 lr 8.04952e-06 
09/17/2020 08:03:11 - INFO - volta.utils -   [GQA]: iter 60365 Ep: 16.39 loss 0.042 score 0.996 lr 8.03746e-06 
09/17/2020 08:04:42 - INFO - volta.utils -   [GQA]: iter 60385 Ep: 16.39 loss 0.033 score 0.997 lr 8.0254e-06 
09/17/2020 08:05:47 - INFO - volta.utils -   [GQA]: iter 60405 Ep: 16.40 loss 0.039 score 0.996 lr 8.01333e-06 
09/17/2020 08:08:45 - INFO - volta.utils -   [GQA]: iter 60425 Ep: 16.40 loss 0.038 score 0.996 lr 8.00127e-06 
09/17/2020 08:10:02 - INFO - volta.utils -   [GQA]: iter 60445 Ep: 16.41 loss 0.041 score 0.996 lr 7.9892e-06 
09/17/2020 08:11:20 - INFO - volta.utils -   [GQA]: iter 60465 Ep: 16.41 loss 0.037 score 0.996 lr 7.97714e-06 
09/17/2020 08:12:29 - INFO - volta.utils -   [GQA]: iter 60485 Ep: 16.42 loss 0.036 score 0.995 lr 7.96507e-06 
09/17/2020 08:14:50 - INFO - volta.utils -   [GQA]: iter 60505 Ep: 16.42 loss 0.035 score 0.996 lr 7.95301e-06 
09/17/2020 08:16:37 - INFO - volta.utils -   [GQA]: iter 60525 Ep: 16.43 loss 0.039 score 0.996 lr 7.94095e-06 
09/17/2020 08:18:13 - INFO - volta.utils -   [GQA]: iter 60545 Ep: 16.43 loss 0.037 score 0.997 lr 7.92888e-06 
09/17/2020 08:19:55 - INFO - volta.utils -   [GQA]: iter 60565 Ep: 16.44 loss 0.043 score 0.995 lr 7.91682e-06 
09/17/2020 08:22:19 - INFO - volta.utils -   [GQA]: iter 60585 Ep: 16.45 loss 0.042 score 0.996 lr 7.90475e-06 
09/17/2020 08:23:34 - INFO - volta.utils -   [GQA]: iter 60605 Ep: 16.45 loss 0.037 score 0.996 lr 7.89269e-06 
09/17/2020 08:25:05 - INFO - volta.utils -   [GQA]: iter 60625 Ep: 16.46 loss 0.040 score 0.996 lr 7.88062e-06 
09/17/2020 08:26:34 - INFO - volta.utils -   [GQA]: iter 60645 Ep: 16.46 loss 0.041 score 0.996 lr 7.86856e-06 
09/17/2020 08:29:31 - INFO - volta.utils -   [GQA]: iter 60665 Ep: 16.47 loss 0.034 score 0.997 lr 7.8565e-06 
09/17/2020 08:31:00 - INFO - volta.utils -   [GQA]: iter 60685 Ep: 16.47 loss 0.034 score 0.997 lr 7.84443e-06 
09/17/2020 08:32:26 - INFO - volta.utils -   [GQA]: iter 60705 Ep: 16.48 loss 0.035 score 0.997 lr 7.83237e-06 
09/17/2020 08:33:22 - INFO - volta.utils -   [GQA]: iter 60725 Ep: 16.48 loss 0.045 score 0.995 lr 7.8203e-06 
09/17/2020 08:35:52 - INFO - volta.utils -   [GQA]: iter 60745 Ep: 16.49 loss 0.045 score 0.995 lr 7.80824e-06 
09/17/2020 08:37:26 - INFO - volta.utils -   [GQA]: iter 60765 Ep: 16.49 loss 0.038 score 0.996 lr 7.79618e-06 
09/17/2020 08:38:42 - INFO - volta.utils -   [GQA]: iter 60785 Ep: 16.50 loss 0.040 score 0.996 lr 7.78411e-06 
09/17/2020 08:39:58 - INFO - volta.utils -   [GQA]: iter 60805 Ep: 16.51 loss 0.041 score 0.995 lr 7.77205e-06 
09/17/2020 08:42:44 - INFO - volta.utils -   [GQA]: iter 60825 Ep: 16.51 loss 0.038 score 0.996 lr 7.75998e-06 
09/17/2020 08:44:31 - INFO - volta.utils -   [GQA]: iter 60845 Ep: 16.52 loss 0.040 score 0.997 lr 7.74792e-06 
09/17/2020 08:46:04 - INFO - volta.utils -   [GQA]: iter 60865 Ep: 16.52 loss 0.041 score 0.996 lr 7.73585e-06 
09/17/2020 08:47:46 - INFO - volta.utils -   [GQA]: iter 60885 Ep: 16.53 loss 0.034 score 0.996 lr 7.72379e-06 
09/17/2020 08:50:40 - INFO - volta.utils -   [GQA]: iter 60905 Ep: 16.53 loss 0.037 score 0.996 lr 7.71173e-06 
09/17/2020 08:52:03 - INFO - volta.utils -   [GQA]: iter 60925 Ep: 16.54 loss 0.033 score 0.997 lr 7.69966e-06 
09/17/2020 08:53:05 - INFO - volta.utils -   [GQA]: iter 60945 Ep: 16.54 loss 0.032 score 0.998 lr 7.6876e-06 
09/17/2020 08:54:38 - INFO - volta.utils -   [GQA]: iter 60965 Ep: 16.55 loss 0.033 score 0.997 lr 7.67553e-06 
09/17/2020 08:57:11 - INFO - volta.utils -   [GQA]: iter 60985 Ep: 16.55 loss 0.030 score 0.998 lr 7.66347e-06 
09/17/2020 08:58:21 - INFO - volta.utils -   [GQA]: iter 61005 Ep: 16.56 loss 0.032 score 0.997 lr 7.65141e-06 
09/17/2020 08:59:26 - INFO - volta.utils -   [GQA]: iter 61025 Ep: 16.56 loss 0.035 score 0.996 lr 7.63934e-06 
09/17/2020 09:01:02 - INFO - volta.utils -   [GQA]: iter 61045 Ep: 16.57 loss 0.031 score 0.997 lr 7.62728e-06 
09/17/2020 09:04:00 - INFO - volta.utils -   [GQA]: iter 61065 Ep: 16.58 loss 0.034 score 0.997 lr 7.61521e-06 
09/17/2020 09:05:14 - INFO - volta.utils -   [GQA]: iter 61085 Ep: 16.58 loss 0.037 score 0.996 lr 7.60315e-06 
09/17/2020 09:06:32 - INFO - volta.utils -   [GQA]: iter 61105 Ep: 16.59 loss 0.033 score 0.997 lr 7.59108e-06 
09/17/2020 09:07:43 - INFO - volta.utils -   [GQA]: iter 61125 Ep: 16.59 loss 0.039 score 0.996 lr 7.57902e-06 
09/17/2020 09:09:36 - INFO - volta.utils -   [GQA]: iter 61145 Ep: 16.60 loss 0.037 score 0.996 lr 7.56696e-06 
09/17/2020 09:10:47 - INFO - volta.utils -   [GQA]: iter 61165 Ep: 16.60 loss 0.037 score 0.996 lr 7.55489e-06 
09/17/2020 09:12:29 - INFO - volta.utils -   [GQA]: iter 61185 Ep: 16.61 loss 0.037 score 0.996 lr 7.54283e-06 
09/17/2020 09:14:01 - INFO - volta.utils -   [GQA]: iter 61205 Ep: 16.61 loss 0.035 score 0.996 lr 7.53076e-06 
09/17/2020 09:15:48 - INFO - volta.utils -   [GQA]: iter 61225 Ep: 16.62 loss 0.039 score 0.996 lr 7.5187e-06 
09/17/2020 09:17:23 - INFO - volta.utils -   [GQA]: iter 61245 Ep: 16.62 loss 0.034 score 0.997 lr 7.50664e-06 
09/17/2020 09:19:31 - INFO - volta.utils -   [GQA]: iter 61265 Ep: 16.63 loss 0.036 score 0.997 lr 7.49457e-06 
09/17/2020 09:20:52 - INFO - volta.utils -   [GQA]: iter 61285 Ep: 16.64 loss 0.036 score 0.996 lr 7.48251e-06 
09/17/2020 09:22:31 - INFO - volta.utils -   [GQA]: iter 61305 Ep: 16.64 loss 0.028 score 0.999 lr 7.47044e-06 
09/17/2020 09:24:02 - INFO - volta.utils -   [GQA]: iter 61325 Ep: 16.65 loss 0.042 score 0.995 lr 7.45838e-06 
09/17/2020 09:25:57 - INFO - volta.utils -   [GQA]: iter 61345 Ep: 16.65 loss 0.031 score 0.997 lr 7.44631e-06 
09/17/2020 09:27:40 - INFO - volta.utils -   [GQA]: iter 61365 Ep: 16.66 loss 0.043 score 0.995 lr 7.43425e-06 
09/17/2020 09:29:16 - INFO - volta.utils -   [GQA]: iter 61385 Ep: 16.66 loss 0.034 score 0.997 lr 7.42219e-06 
09/17/2020 09:30:50 - INFO - volta.utils -   [GQA]: iter 61405 Ep: 16.67 loss 0.034 score 0.997 lr 7.41012e-06 
09/17/2020 09:33:32 - INFO - volta.utils -   [GQA]: iter 61425 Ep: 16.67 loss 0.034 score 0.997 lr 7.39806e-06 
09/17/2020 09:34:56 - INFO - volta.utils -   [GQA]: iter 61445 Ep: 16.68 loss 0.034 score 0.997 lr 7.38599e-06 
09/17/2020 09:36:25 - INFO - volta.utils -   [GQA]: iter 61465 Ep: 16.68 loss 0.042 score 0.995 lr 7.37393e-06 
09/17/2020 09:38:13 - INFO - volta.utils -   [GQA]: iter 61485 Ep: 16.69 loss 0.034 score 0.997 lr 7.36187e-06 
09/17/2020 09:40:16 - INFO - volta.utils -   [GQA]: iter 61505 Ep: 16.70 loss 0.033 score 0.997 lr 7.3498e-06 
09/17/2020 09:42:05 - INFO - volta.utils -   [GQA]: iter 61525 Ep: 16.70 loss 0.031 score 0.998 lr 7.33774e-06 
09/17/2020 09:43:48 - INFO - volta.utils -   [GQA]: iter 61545 Ep: 16.71 loss 0.039 score 0.996 lr 7.32567e-06 
09/17/2020 09:45:05 - INFO - volta.utils -   [GQA]: iter 61565 Ep: 16.71 loss 0.033 score 0.997 lr 7.31361e-06 
09/17/2020 09:47:03 - INFO - volta.utils -   [GQA]: iter 61585 Ep: 16.72 loss 0.034 score 0.997 lr 7.30154e-06 
09/17/2020 09:49:01 - INFO - volta.utils -   [GQA]: iter 61605 Ep: 16.72 loss 0.031 score 0.997 lr 7.28948e-06 
09/17/2020 09:50:20 - INFO - volta.utils -   [GQA]: iter 61625 Ep: 16.73 loss 0.033 score 0.997 lr 7.27742e-06 
09/17/2020 09:51:49 - INFO - volta.utils -   [GQA]: iter 61645 Ep: 16.73 loss 0.039 score 0.996 lr 7.26535e-06 
09/17/2020 09:53:53 - INFO - volta.utils -   [GQA]: iter 61665 Ep: 16.74 loss 0.037 score 0.996 lr 7.25329e-06 
09/17/2020 09:55:35 - INFO - volta.utils -   [GQA]: iter 61685 Ep: 16.74 loss 0.036 score 0.996 lr 7.24122e-06 
09/17/2020 09:56:50 - INFO - volta.utils -   [GQA]: iter 61705 Ep: 16.75 loss 0.038 score 0.997 lr 7.22916e-06 
09/17/2020 09:58:35 - INFO - volta.utils -   [GQA]: iter 61725 Ep: 16.75 loss 0.028 score 0.998 lr 7.21709e-06 
09/17/2020 10:00:55 - INFO - volta.utils -   [GQA]: iter 61745 Ep: 16.76 loss 0.033 score 0.997 lr 7.20503e-06 
09/17/2020 10:02:26 - INFO - volta.utils -   [GQA]: iter 61765 Ep: 16.77 loss 0.038 score 0.996 lr 7.19297e-06 
09/17/2020 10:03:55 - INFO - volta.utils -   [GQA]: iter 61785 Ep: 16.77 loss 0.033 score 0.997 lr 7.1809e-06 
09/17/2020 10:05:41 - INFO - volta.utils -   [GQA]: iter 61805 Ep: 16.78 loss 0.037 score 0.997 lr 7.16884e-06 
09/17/2020 10:08:04 - INFO - volta.utils -   [GQA]: iter 61825 Ep: 16.78 loss 0.035 score 0.996 lr 7.15677e-06 
09/17/2020 10:09:10 - INFO - volta.utils -   [GQA]: iter 61845 Ep: 16.79 loss 0.032 score 0.997 lr 7.14471e-06 
09/17/2020 10:10:34 - INFO - volta.utils -   [GQA]: iter 61865 Ep: 16.79 loss 0.025 score 0.998 lr 7.13265e-06 
09/17/2020 10:12:01 - INFO - volta.utils -   [GQA]: iter 61885 Ep: 16.80 loss 0.033 score 0.998 lr 7.12058e-06 
09/17/2020 10:14:44 - INFO - volta.utils -   [GQA]: iter 61905 Ep: 16.80 loss 0.033 score 0.997 lr 7.10852e-06 
09/17/2020 10:15:54 - INFO - volta.utils -   [GQA]: iter 61925 Ep: 16.81 loss 0.034 score 0.996 lr 7.09645e-06 
09/17/2020 10:17:04 - INFO - volta.utils -   [GQA]: iter 61945 Ep: 16.81 loss 0.035 score 0.997 lr 7.08439e-06 
09/17/2020 10:18:54 - INFO - volta.utils -   [GQA]: iter 61965 Ep: 16.82 loss 0.040 score 0.996 lr 7.07232e-06 
09/17/2020 10:21:06 - INFO - volta.utils -   [GQA]: iter 61985 Ep: 16.83 loss 0.039 score 0.995 lr 7.06026e-06 
09/17/2020 10:22:33 - INFO - volta.utils -   [GQA]: iter 62005 Ep: 16.83 loss 0.036 score 0.996 lr 7.0482e-06 
09/17/2020 10:23:57 - INFO - volta.utils -   [GQA]: iter 62025 Ep: 16.84 loss 0.040 score 0.995 lr 7.03613e-06 
09/17/2020 10:25:35 - INFO - volta.utils -   [GQA]: iter 62045 Ep: 16.84 loss 0.032 score 0.996 lr 7.02407e-06 
09/17/2020 10:27:35 - INFO - volta.utils -   [GQA]: iter 62065 Ep: 16.85 loss 0.035 score 0.997 lr 7.012e-06 
09/17/2020 10:29:03 - INFO - volta.utils -   [GQA]: iter 62085 Ep: 16.85 loss 0.032 score 0.997 lr 6.99994e-06 
09/17/2020 10:30:37 - INFO - volta.utils -   [GQA]: iter 62105 Ep: 16.86 loss 0.045 score 0.995 lr 6.98788e-06 
09/17/2020 10:32:04 - INFO - volta.utils -   [GQA]: iter 62125 Ep: 16.86 loss 0.037 score 0.997 lr 6.97581e-06 
09/17/2020 10:34:06 - INFO - volta.utils -   [GQA]: iter 62145 Ep: 16.87 loss 0.045 score 0.995 lr 6.96375e-06 
09/17/2020 10:35:28 - INFO - volta.utils -   [GQA]: iter 62165 Ep: 16.87 loss 0.032 score 0.997 lr 6.95168e-06 
09/17/2020 10:36:36 - INFO - volta.utils -   [GQA]: iter 62185 Ep: 16.88 loss 0.040 score 0.996 lr 6.93962e-06 
09/17/2020 10:39:13 - INFO - volta.utils -   [GQA]: iter 62205 Ep: 16.89 loss 0.038 score 0.997 lr 6.92755e-06 
09/17/2020 10:40:48 - INFO - volta.utils -   [GQA]: iter 62225 Ep: 16.89 loss 0.032 score 0.997 lr 6.91549e-06 
09/17/2020 10:42:04 - INFO - volta.utils -   [GQA]: iter 62245 Ep: 16.90 loss 0.041 score 0.996 lr 6.90343e-06 
09/17/2020 10:43:38 - INFO - volta.utils -   [GQA]: iter 62265 Ep: 16.90 loss 0.032 score 0.997 lr 6.89136e-06 
09/17/2020 10:45:23 - INFO - volta.utils -   [GQA]: iter 62285 Ep: 16.91 loss 0.030 score 0.998 lr 6.8793e-06 
09/17/2020 10:48:03 - INFO - volta.utils -   [GQA]: iter 62305 Ep: 16.91 loss 0.040 score 0.995 lr 6.86723e-06 
09/17/2020 10:49:19 - INFO - volta.utils -   [GQA]: iter 62325 Ep: 16.92 loss 0.033 score 0.998 lr 6.85517e-06 
09/17/2020 10:50:45 - INFO - volta.utils -   [GQA]: iter 62345 Ep: 16.92 loss 0.040 score 0.996 lr 6.84311e-06 
09/17/2020 10:52:56 - INFO - volta.utils -   [GQA]: iter 62365 Ep: 16.93 loss 0.039 score 0.996 lr 6.83104e-06 
09/17/2020 10:54:37 - INFO - volta.utils -   [GQA]: iter 62385 Ep: 16.93 loss 0.038 score 0.996 lr 6.81898e-06 
09/17/2020 10:56:02 - INFO - volta.utils -   [GQA]: iter 62405 Ep: 16.94 loss 0.034 score 0.996 lr 6.80691e-06 
09/17/2020 10:57:06 - INFO - volta.utils -   [GQA]: iter 62425 Ep: 16.94 loss 0.031 score 0.997 lr 6.79485e-06 
09/17/2020 10:59:54 - INFO - volta.utils -   [GQA]: iter 62445 Ep: 16.95 loss 0.025 score 0.999 lr 6.78278e-06 
09/17/2020 11:01:31 - INFO - volta.utils -   [GQA]: iter 62465 Ep: 16.96 loss 0.033 score 0.997 lr 6.77072e-06 
09/17/2020 11:03:05 - INFO - volta.utils -   [GQA]: iter 62485 Ep: 16.96 loss 0.035 score 0.996 lr 6.75866e-06 
09/17/2020 11:04:21 - INFO - volta.utils -   [GQA]: iter 62505 Ep: 16.97 loss 0.037 score 0.997 lr 6.74659e-06 
09/17/2020 11:06:40 - INFO - volta.utils -   [GQA]: iter 62525 Ep: 16.97 loss 0.029 score 0.997 lr 6.73453e-06 
09/17/2020 11:07:15 - INFO - volta.utils -   [GQA]: iter 62545 Ep: 16.98 loss 0.032 score 0.997 lr 6.72246e-06 
09/17/2020 11:08:44 - INFO - volta.utils -   [GQA]: iter 62565 Ep: 16.98 loss 0.032 score 0.997 lr 6.7104e-06 
09/17/2020 11:10:24 - INFO - volta.utils -   [GQA]: iter 62585 Ep: 16.99 loss 0.032 score 0.997 lr 6.69834e-06 
09/17/2020 11:12:44 - INFO - volta.utils -   [GQA]: iter 62605 Ep: 16.99 loss 0.041 score 0.997 lr 6.68627e-06 
09/17/2020 11:14:00 - INFO - volta.utils -   [GQA]: iter 62625 Ep: 17.00 loss 0.034 score 0.996 lr 6.67421e-06 
09/17/2020 11:14:02 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  25%|██▌       | 1/4 [5:28:40<16:26:00, 19720.17s/it]09/17/2020 11:33:39 - INFO - volta.utils -   Eval task TASK15 on iteration 62629 
09/17/2020 11:33:39 - INFO - volta.utils -   Validation [GQA]: loss 4.359 score 64.583 
09/17/2020 11:33:52 - INFO - volta.utils -   [GQA]: iter 62649 Ep: 17.01 loss 0.026 score 0.998 lr 6.66094e-06 
09/17/2020 11:35:16 - INFO - volta.utils -   [GQA]: iter 62669 Ep: 17.01 loss 0.029 score 0.997 lr 6.64767e-06 
09/17/2020 11:36:23 - INFO - volta.utils -   [GQA]: iter 62689 Ep: 17.02 loss 0.036 score 0.997 lr 6.6356e-06 
09/17/2020 11:37:33 - INFO - volta.utils -   [GQA]: iter 62709 Ep: 17.02 loss 0.033 score 0.997 lr 6.62354e-06 
09/17/2020 11:39:51 - INFO - volta.utils -   [GQA]: iter 62729 Ep: 17.03 loss 0.028 score 0.997 lr 6.61147e-06 
09/17/2020 11:41:16 - INFO - volta.utils -   [GQA]: iter 62749 Ep: 17.03 loss 0.032 score 0.998 lr 6.59941e-06 
09/17/2020 11:42:42 - INFO - volta.utils -   [GQA]: iter 62769 Ep: 17.04 loss 0.026 score 0.998 lr 6.58734e-06 
09/17/2020 11:44:02 - INFO - volta.utils -   [GQA]: iter 62789 Ep: 17.04 loss 0.027 score 0.998 lr 6.57528e-06 
09/17/2020 11:46:22 - INFO - volta.utils -   [GQA]: iter 62809 Ep: 17.05 loss 0.027 score 0.997 lr 6.56322e-06 
09/17/2020 11:47:30 - INFO - volta.utils -   [GQA]: iter 62829 Ep: 17.05 loss 0.027 score 0.997 lr 6.55115e-06 
09/17/2020 11:49:03 - INFO - volta.utils -   [GQA]: iter 62849 Ep: 17.06 loss 0.027 score 0.998 lr 6.53909e-06 
09/17/2020 11:50:30 - INFO - volta.utils -   [GQA]: iter 62869 Ep: 17.07 loss 0.030 score 0.997 lr 6.52702e-06 
09/17/2020 11:53:04 - INFO - volta.utils -   [GQA]: iter 62889 Ep: 17.07 loss 0.029 score 0.997 lr 6.51496e-06 
09/17/2020 11:54:42 - INFO - volta.utils -   [GQA]: iter 62909 Ep: 17.08 loss 0.033 score 0.997 lr 6.5029e-06 
09/17/2020 11:56:17 - INFO - volta.utils -   [GQA]: iter 62929 Ep: 17.08 loss 0.026 score 0.998 lr 6.49083e-06 
09/17/2020 11:57:39 - INFO - volta.utils -   [GQA]: iter 62949 Ep: 17.09 loss 0.028 score 0.998 lr 6.47877e-06 
09/17/2020 12:00:17 - INFO - volta.utils -   [GQA]: iter 62969 Ep: 17.09 loss 0.026 score 0.997 lr 6.4667e-06 
09/17/2020 12:01:40 - INFO - volta.utils -   [GQA]: iter 62989 Ep: 17.10 loss 0.025 score 0.999 lr 6.45464e-06 
09/17/2020 12:03:09 - INFO - volta.utils -   [GQA]: iter 63009 Ep: 17.10 loss 0.031 score 0.997 lr 6.44257e-06 
09/17/2020 12:04:37 - INFO - volta.utils -   [GQA]: iter 63029 Ep: 17.11 loss 0.028 score 0.997 lr 6.43051e-06 
09/17/2020 12:06:48 - INFO - volta.utils -   [GQA]: iter 63049 Ep: 17.11 loss 0.027 score 0.997 lr 6.41845e-06 
09/17/2020 12:08:16 - INFO - volta.utils -   [GQA]: iter 63069 Ep: 17.12 loss 0.023 score 0.998 lr 6.40638e-06 
09/17/2020 12:09:44 - INFO - volta.utils -   [GQA]: iter 63089 Ep: 17.13 loss 0.031 score 0.996 lr 6.39432e-06 
09/17/2020 12:11:21 - INFO - volta.utils -   [GQA]: iter 63109 Ep: 17.13 loss 0.033 score 0.997 lr 6.38225e-06 
09/17/2020 12:14:00 - INFO - volta.utils -   [GQA]: iter 63129 Ep: 17.14 loss 0.033 score 0.996 lr 6.37019e-06 
09/17/2020 12:15:45 - INFO - volta.utils -   [GQA]: iter 63149 Ep: 17.14 loss 0.029 score 0.997 lr 6.35813e-06 
09/17/2020 12:16:44 - INFO - volta.utils -   [GQA]: iter 63169 Ep: 17.15 loss 0.029 score 0.997 lr 6.34606e-06 
09/17/2020 12:18:01 - INFO - volta.utils -   [GQA]: iter 63189 Ep: 17.15 loss 0.031 score 0.997 lr 6.334e-06 
09/17/2020 12:20:44 - INFO - volta.utils -   [GQA]: iter 63209 Ep: 17.16 loss 0.032 score 0.997 lr 6.32193e-06 
09/17/2020 12:22:12 - INFO - volta.utils -   [GQA]: iter 63229 Ep: 17.16 loss 0.028 score 0.998 lr 6.30987e-06 
09/17/2020 12:24:03 - INFO - volta.utils -   [GQA]: iter 63249 Ep: 17.17 loss 0.027 score 0.998 lr 6.2978e-06 
09/17/2020 12:25:20 - INFO - volta.utils -   [GQA]: iter 63269 Ep: 17.17 loss 0.022 score 0.999 lr 6.28574e-06 
09/17/2020 12:27:30 - INFO - volta.utils -   [GQA]: iter 63289 Ep: 17.18 loss 0.034 score 0.997 lr 6.27368e-06 
09/17/2020 12:29:03 - INFO - volta.utils -   [GQA]: iter 63309 Ep: 17.18 loss 0.030 score 0.998 lr 6.26161e-06 
09/17/2020 12:30:43 - INFO - volta.utils -   [GQA]: iter 63329 Ep: 17.19 loss 0.026 score 0.998 lr 6.24955e-06 
09/17/2020 12:32:10 - INFO - volta.utils -   [GQA]: iter 63349 Ep: 17.20 loss 0.025 score 0.999 lr 6.23748e-06 
09/17/2020 12:34:32 - INFO - volta.utils -   [GQA]: iter 63369 Ep: 17.20 loss 0.026 score 0.998 lr 6.22542e-06 
09/17/2020 12:36:27 - INFO - volta.utils -   [GQA]: iter 63389 Ep: 17.21 loss 0.028 score 0.997 lr 6.21336e-06 
09/17/2020 12:37:49 - INFO - volta.utils -   [GQA]: iter 63409 Ep: 17.21 loss 0.026 score 0.998 lr 6.20129e-06 
09/17/2020 12:39:00 - INFO - volta.utils -   [GQA]: iter 63429 Ep: 17.22 loss 0.024 score 0.998 lr 6.18923e-06 
09/17/2020 12:41:42 - INFO - volta.utils -   [GQA]: iter 63449 Ep: 17.22 loss 0.026 score 0.998 lr 6.17716e-06 
09/17/2020 12:43:04 - INFO - volta.utils -   [GQA]: iter 63469 Ep: 17.23 loss 0.027 score 0.997 lr 6.1651e-06 
09/17/2020 12:44:44 - INFO - volta.utils -   [GQA]: iter 63489 Ep: 17.23 loss 0.025 score 0.999 lr 6.15303e-06 
09/17/2020 12:46:52 - INFO - volta.utils -   [GQA]: iter 63509 Ep: 17.24 loss 0.029 score 0.996 lr 6.14097e-06 
09/17/2020 12:49:53 - INFO - volta.utils -   [GQA]: iter 63529 Ep: 17.24 loss 0.027 score 0.998 lr 6.12891e-06 
09/17/2020 12:51:25 - INFO - volta.utils -   [GQA]: iter 63549 Ep: 17.25 loss 0.022 score 0.998 lr 6.11684e-06 
09/17/2020 12:52:51 - INFO - volta.utils -   [GQA]: iter 63569 Ep: 17.26 loss 0.027 score 0.997 lr 6.10478e-06 
09/17/2020 12:54:19 - INFO - volta.utils -   [GQA]: iter 63589 Ep: 17.26 loss 0.025 score 0.998 lr 6.09271e-06 
09/17/2020 12:56:43 - INFO - volta.utils -   [GQA]: iter 63609 Ep: 17.27 loss 0.024 score 0.998 lr 6.08065e-06 
09/17/2020 12:58:01 - INFO - volta.utils -   [GQA]: iter 63629 Ep: 17.27 loss 0.026 score 0.997 lr 6.06858e-06 
09/17/2020 12:59:26 - INFO - volta.utils -   [GQA]: iter 63649 Ep: 17.28 loss 0.026 score 0.997 lr 6.05652e-06 
09/17/2020 13:00:44 - INFO - volta.utils -   [GQA]: iter 63669 Ep: 17.28 loss 0.026 score 0.998 lr 6.04446e-06 
09/17/2020 13:03:07 - INFO - volta.utils -   [GQA]: iter 63689 Ep: 17.29 loss 0.021 score 0.999 lr 6.03239e-06 
09/17/2020 13:04:34 - INFO - volta.utils -   [GQA]: iter 63709 Ep: 17.29 loss 0.028 score 0.997 lr 6.02033e-06 
09/17/2020 13:05:51 - INFO - volta.utils -   [GQA]: iter 63729 Ep: 17.30 loss 0.025 score 0.998 lr 6.00826e-06 
09/17/2020 13:07:16 - INFO - volta.utils -   [GQA]: iter 63749 Ep: 17.30 loss 0.026 score 0.999 lr 5.9962e-06 
09/17/2020 13:09:28 - INFO - volta.utils -   [GQA]: iter 63769 Ep: 17.31 loss 0.027 score 0.998 lr 5.98414e-06 
09/17/2020 13:10:50 - INFO - volta.utils -   [GQA]: iter 63789 Ep: 17.32 loss 0.031 score 0.997 lr 5.97207e-06 
09/17/2020 13:12:21 - INFO - volta.utils -   [GQA]: iter 63809 Ep: 17.32 loss 0.023 score 0.998 lr 5.96001e-06 
09/17/2020 13:13:50 - INFO - volta.utils -   [GQA]: iter 63829 Ep: 17.33 loss 0.028 score 0.997 lr 5.94794e-06 
09/17/2020 13:15:46 - INFO - volta.utils -   [GQA]: iter 63849 Ep: 17.33 loss 0.026 score 0.998 lr 5.93588e-06 
09/17/2020 13:17:46 - INFO - volta.utils -   [GQA]: iter 63869 Ep: 17.34 loss 0.033 score 0.997 lr 5.92381e-06 
09/17/2020 13:19:08 - INFO - volta.utils -   [GQA]: iter 63889 Ep: 17.34 loss 0.023 score 0.998 lr 5.91175e-06 
09/17/2020 13:20:27 - INFO - volta.utils -   [GQA]: iter 63909 Ep: 17.35 loss 0.024 score 0.998 lr 5.89969e-06 
09/17/2020 13:22:43 - INFO - volta.utils -   [GQA]: iter 63929 Ep: 17.35 loss 0.027 score 0.998 lr 5.88762e-06 
09/17/2020 13:24:20 - INFO - volta.utils -   [GQA]: iter 63949 Ep: 17.36 loss 0.025 score 0.999 lr 5.87556e-06 
09/17/2020 13:25:48 - INFO - volta.utils -   [GQA]: iter 63969 Ep: 17.36 loss 0.025 score 0.998 lr 5.86349e-06 
09/17/2020 13:27:24 - INFO - volta.utils -   [GQA]: iter 63989 Ep: 17.37 loss 0.030 score 0.997 lr 5.85143e-06 
09/17/2020 13:30:02 - INFO - volta.utils -   [GQA]: iter 64009 Ep: 17.37 loss 0.024 score 0.998 lr 5.83937e-06 
09/17/2020 13:31:05 - INFO - volta.utils -   [GQA]: iter 64029 Ep: 17.38 loss 0.024 score 0.998 lr 5.8273e-06 
09/17/2020 13:32:45 - INFO - volta.utils -   [GQA]: iter 64049 Ep: 17.39 loss 0.024 score 0.998 lr 5.81524e-06 
09/17/2020 13:33:49 - INFO - volta.utils -   [GQA]: iter 64069 Ep: 17.39 loss 0.022 score 0.999 lr 5.80317e-06 
09/17/2020 13:36:25 - INFO - volta.utils -   [GQA]: iter 64089 Ep: 17.40 loss 0.026 score 0.998 lr 5.79111e-06 
09/17/2020 13:37:40 - INFO - volta.utils -   [GQA]: iter 64109 Ep: 17.40 loss 0.025 score 0.997 lr 5.77904e-06 
09/17/2020 13:39:18 - INFO - volta.utils -   [GQA]: iter 64129 Ep: 17.41 loss 0.023 score 0.998 lr 5.76698e-06 
09/17/2020 13:40:30 - INFO - volta.utils -   [GQA]: iter 64149 Ep: 17.41 loss 0.025 score 0.998 lr 5.75492e-06 
09/17/2020 13:42:35 - INFO - volta.utils -   [GQA]: iter 64169 Ep: 17.42 loss 0.027 score 0.997 lr 5.74285e-06 
09/17/2020 13:43:56 - INFO - volta.utils -   [GQA]: iter 64189 Ep: 17.42 loss 0.021 score 0.999 lr 5.73079e-06 
09/17/2020 13:46:15 - INFO - volta.utils -   [GQA]: iter 64209 Ep: 17.43 loss 0.030 score 0.998 lr 5.71872e-06 
09/17/2020 13:47:34 - INFO - volta.utils -   [GQA]: iter 64229 Ep: 17.43 loss 0.024 score 0.998 lr 5.70666e-06 
09/17/2020 13:48:59 - INFO - volta.utils -   [GQA]: iter 64249 Ep: 17.44 loss 0.029 score 0.998 lr 5.6946e-06 
09/17/2020 13:50:34 - INFO - volta.utils -   [GQA]: iter 64269 Ep: 17.45 loss 0.028 score 0.997 lr 5.68253e-06 
09/17/2020 13:52:07 - INFO - volta.utils -   [GQA]: iter 64289 Ep: 17.45 loss 0.026 score 0.998 lr 5.67047e-06 
09/17/2020 13:53:37 - INFO - volta.utils -   [GQA]: iter 64309 Ep: 17.46 loss 0.028 score 0.997 lr 5.6584e-06 
09/17/2020 13:56:14 - INFO - volta.utils -   [GQA]: iter 64329 Ep: 17.46 loss 0.029 score 0.997 lr 5.64634e-06 
09/17/2020 13:57:46 - INFO - volta.utils -   [GQA]: iter 64349 Ep: 17.47 loss 0.029 score 0.997 lr 5.63427e-06 
09/17/2020 13:59:05 - INFO - volta.utils -   [GQA]: iter 64369 Ep: 17.47 loss 0.023 score 0.998 lr 5.62221e-06 
09/17/2020 14:01:00 - INFO - volta.utils -   [GQA]: iter 64389 Ep: 17.48 loss 0.030 score 0.997 lr 5.61015e-06 
09/17/2020 14:03:29 - INFO - volta.utils -   [GQA]: iter 64409 Ep: 17.48 loss 0.030 score 0.997 lr 5.59808e-06 
09/17/2020 14:04:54 - INFO - volta.utils -   [GQA]: iter 64429 Ep: 17.49 loss 0.031 score 0.997 lr 5.58602e-06 
09/17/2020 14:06:08 - INFO - volta.utils -   [GQA]: iter 64449 Ep: 17.49 loss 0.029 score 0.997 lr 5.57395e-06 
09/17/2020 14:07:21 - INFO - volta.utils -   [GQA]: iter 64469 Ep: 17.50 loss 0.025 score 0.998 lr 5.56189e-06 
09/17/2020 14:09:59 - INFO - volta.utils -   [GQA]: iter 64489 Ep: 17.51 loss 0.029 score 0.998 lr 5.54983e-06 
09/17/2020 14:11:33 - INFO - volta.utils -   [GQA]: iter 64509 Ep: 17.51 loss 0.021 score 0.998 lr 5.53776e-06 
09/17/2020 14:13:09 - INFO - volta.utils -   [GQA]: iter 64529 Ep: 17.52 loss 0.021 score 0.999 lr 5.5257e-06 
09/17/2020 14:14:42 - INFO - volta.utils -   [GQA]: iter 64549 Ep: 17.52 loss 0.027 score 0.997 lr 5.51363e-06 
09/17/2020 14:16:35 - INFO - volta.utils -   [GQA]: iter 64569 Ep: 17.53 loss 0.021 score 0.999 lr 5.50157e-06 
09/17/2020 14:18:09 - INFO - volta.utils -   [GQA]: iter 64589 Ep: 17.53 loss 0.024 score 0.997 lr 5.4895e-06 
09/17/2020 14:19:43 - INFO - volta.utils -   [GQA]: iter 64609 Ep: 17.54 loss 0.024 score 0.999 lr 5.47744e-06 
09/17/2020 14:21:37 - INFO - volta.utils -   [GQA]: iter 64629 Ep: 17.54 loss 0.025 score 0.998 lr 5.46538e-06 
09/17/2020 14:23:09 - INFO - volta.utils -   [GQA]: iter 64649 Ep: 17.55 loss 0.031 score 0.997 lr 5.45331e-06 
09/17/2020 14:24:40 - INFO - volta.utils -   [GQA]: iter 64669 Ep: 17.55 loss 0.028 score 0.997 lr 5.44125e-06 
09/17/2020 14:26:35 - INFO - volta.utils -   [GQA]: iter 64689 Ep: 17.56 loss 0.023 score 0.999 lr 5.42918e-06 
09/17/2020 14:28:11 - INFO - volta.utils -   [GQA]: iter 64709 Ep: 17.56 loss 0.024 score 0.998 lr 5.41712e-06 
09/17/2020 14:29:44 - INFO - volta.utils -   [GQA]: iter 64729 Ep: 17.57 loss 0.024 score 0.998 lr 5.40505e-06 
09/17/2020 14:31:26 - INFO - volta.utils -   [GQA]: iter 64749 Ep: 17.58 loss 0.024 score 0.998 lr 5.39299e-06 
09/17/2020 14:33:01 - INFO - volta.utils -   [GQA]: iter 64769 Ep: 17.58 loss 0.026 score 0.999 lr 5.38093e-06 
09/17/2020 14:34:56 - INFO - volta.utils -   [GQA]: iter 64789 Ep: 17.59 loss 0.022 score 0.999 lr 5.36886e-06 
09/17/2020 14:36:49 - INFO - volta.utils -   [GQA]: iter 64809 Ep: 17.59 loss 0.027 score 0.997 lr 5.3568e-06 
09/17/2020 14:38:38 - INFO - volta.utils -   [GQA]: iter 64829 Ep: 17.60 loss 0.024 score 0.998 lr 5.34473e-06 
09/17/2020 14:40:02 - INFO - volta.utils -   [GQA]: iter 64849 Ep: 17.60 loss 0.032 score 0.996 lr 5.33267e-06 
09/17/2020 14:41:48 - INFO - volta.utils -   [GQA]: iter 64869 Ep: 17.61 loss 0.031 score 0.996 lr 5.32061e-06 
09/17/2020 14:43:44 - INFO - volta.utils -   [GQA]: iter 64889 Ep: 17.61 loss 0.024 score 0.998 lr 5.30854e-06 
09/17/2020 14:45:45 - INFO - volta.utils -   [GQA]: iter 64909 Ep: 17.62 loss 0.022 score 0.999 lr 5.29648e-06 
09/17/2020 14:47:27 - INFO - volta.utils -   [GQA]: iter 64929 Ep: 17.62 loss 0.029 score 0.997 lr 5.28441e-06 
09/17/2020 14:49:02 - INFO - volta.utils -   [GQA]: iter 64949 Ep: 17.63 loss 0.024 score 0.998 lr 5.27235e-06 
09/17/2020 14:50:35 - INFO - volta.utils -   [GQA]: iter 64969 Ep: 17.64 loss 0.032 score 0.997 lr 5.26028e-06 
09/17/2020 14:52:44 - INFO - volta.utils -   [GQA]: iter 64989 Ep: 17.64 loss 0.026 score 0.998 lr 5.24822e-06 
09/17/2020 14:54:19 - INFO - volta.utils -   [GQA]: iter 65009 Ep: 17.65 loss 0.031 score 0.997 lr 5.23616e-06 
09/17/2020 14:56:58 - INFO - volta.utils -   [GQA]: iter 65029 Ep: 17.65 loss 0.024 score 0.998 lr 5.22409e-06 
09/17/2020 14:58:35 - INFO - volta.utils -   [GQA]: iter 65049 Ep: 17.66 loss 0.017 score 0.999 lr 5.21203e-06 
09/17/2020 15:00:18 - INFO - volta.utils -   [GQA]: iter 65069 Ep: 17.66 loss 0.023 score 0.998 lr 5.19996e-06 
09/17/2020 15:01:50 - INFO - volta.utils -   [GQA]: iter 65089 Ep: 17.67 loss 0.023 score 0.998 lr 5.1879e-06 
09/17/2020 15:03:57 - INFO - volta.utils -   [GQA]: iter 65109 Ep: 17.67 loss 0.024 score 0.998 lr 5.17584e-06 
09/17/2020 15:05:43 - INFO - volta.utils -   [GQA]: iter 65129 Ep: 17.68 loss 0.033 score 0.997 lr 5.16377e-06 
09/17/2020 15:07:01 - INFO - volta.utils -   [GQA]: iter 65149 Ep: 17.68 loss 0.024 score 0.998 lr 5.15171e-06 
09/17/2020 15:08:26 - INFO - volta.utils -   [GQA]: iter 65169 Ep: 17.69 loss 0.025 score 0.998 lr 5.13964e-06 
09/17/2020 15:11:19 - INFO - volta.utils -   [GQA]: iter 65189 Ep: 17.70 loss 0.025 score 0.998 lr 5.12758e-06 
09/17/2020 15:12:49 - INFO - volta.utils -   [GQA]: iter 65209 Ep: 17.70 loss 0.023 score 0.997 lr 5.11551e-06 
09/17/2020 15:14:08 - INFO - volta.utils -   [GQA]: iter 65229 Ep: 17.71 loss 0.025 score 0.998 lr 5.10345e-06 
09/17/2020 15:15:50 - INFO - volta.utils -   [GQA]: iter 65249 Ep: 17.71 loss 0.028 score 0.997 lr 5.09139e-06 
09/17/2020 15:17:46 - INFO - volta.utils -   [GQA]: iter 65269 Ep: 17.72 loss 0.027 score 0.998 lr 5.07932e-06 
09/17/2020 15:19:33 - INFO - volta.utils -   [GQA]: iter 65289 Ep: 17.72 loss 0.024 score 0.998 lr 5.06726e-06 
09/17/2020 15:21:07 - INFO - volta.utils -   [GQA]: iter 65309 Ep: 17.73 loss 0.025 score 0.998 lr 5.05519e-06 
09/17/2020 15:22:58 - INFO - volta.utils -   [GQA]: iter 65329 Ep: 17.73 loss 0.020 score 0.999 lr 5.04313e-06 
09/17/2020 15:24:24 - INFO - volta.utils -   [GQA]: iter 65349 Ep: 17.74 loss 0.029 score 0.998 lr 5.03107e-06 
09/17/2020 15:26:08 - INFO - volta.utils -   [GQA]: iter 65369 Ep: 17.74 loss 0.027 score 0.997 lr 5.019e-06 
09/17/2020 15:27:32 - INFO - volta.utils -   [GQA]: iter 65389 Ep: 17.75 loss 0.024 score 0.998 lr 5.00694e-06 
09/17/2020 15:30:11 - INFO - volta.utils -   [GQA]: iter 65409 Ep: 17.75 loss 0.022 score 0.999 lr 4.99487e-06 
09/17/2020 15:31:18 - INFO - volta.utils -   [GQA]: iter 65429 Ep: 17.76 loss 0.026 score 0.998 lr 4.98281e-06 
09/17/2020 15:32:55 - INFO - volta.utils -   [GQA]: iter 65449 Ep: 17.77 loss 0.027 score 0.997 lr 4.97074e-06 
09/17/2020 15:35:08 - INFO - volta.utils -   [GQA]: iter 65469 Ep: 17.77 loss 0.030 score 0.996 lr 4.95868e-06 
09/17/2020 15:37:56 - INFO - volta.utils -   [GQA]: iter 65489 Ep: 17.78 loss 0.027 score 0.998 lr 4.94662e-06 
09/17/2020 15:39:41 - INFO - volta.utils -   [GQA]: iter 65509 Ep: 17.78 loss 0.029 score 0.998 lr 4.93455e-06 
09/17/2020 15:41:20 - INFO - volta.utils -   [GQA]: iter 65529 Ep: 17.79 loss 0.026 score 0.998 lr 4.92249e-06 
09/17/2020 15:43:02 - INFO - volta.utils -   [GQA]: iter 65549 Ep: 17.79 loss 0.022 score 0.998 lr 4.91042e-06 
09/17/2020 15:45:57 - INFO - volta.utils -   [GQA]: iter 65569 Ep: 17.80 loss 0.020 score 0.999 lr 4.89836e-06 
09/17/2020 15:46:57 - INFO - volta.utils -   [GQA]: iter 65589 Ep: 17.80 loss 0.024 score 0.999 lr 4.8863e-06 
09/17/2020 15:48:16 - INFO - volta.utils -   [GQA]: iter 65609 Ep: 17.81 loss 0.024 score 0.998 lr 4.87423e-06 
09/17/2020 15:49:39 - INFO - volta.utils -   [GQA]: iter 65629 Ep: 17.81 loss 0.021 score 0.998 lr 4.86217e-06 
09/17/2020 15:52:22 - INFO - volta.utils -   [GQA]: iter 65649 Ep: 17.82 loss 0.023 score 0.998 lr 4.8501e-06 
09/17/2020 15:53:34 - INFO - volta.utils -   [GQA]: iter 65669 Ep: 17.83 loss 0.024 score 0.998 lr 4.83804e-06 
09/17/2020 15:54:34 - INFO - volta.utils -   [GQA]: iter 65689 Ep: 17.83 loss 0.022 score 0.998 lr 4.82597e-06 
09/17/2020 15:56:00 - INFO - volta.utils -   [GQA]: iter 65709 Ep: 17.84 loss 0.027 score 0.997 lr 4.81391e-06 
09/17/2020 15:58:35 - INFO - volta.utils -   [GQA]: iter 65729 Ep: 17.84 loss 0.023 score 0.998 lr 4.80185e-06 
09/17/2020 15:59:52 - INFO - volta.utils -   [GQA]: iter 65749 Ep: 17.85 loss 0.023 score 0.999 lr 4.78978e-06 
09/17/2020 16:01:22 - INFO - volta.utils -   [GQA]: iter 65769 Ep: 17.85 loss 0.027 score 0.996 lr 4.77772e-06 
09/17/2020 16:02:51 - INFO - volta.utils -   [GQA]: iter 65789 Ep: 17.86 loss 0.025 score 0.997 lr 4.76565e-06 
09/17/2020 16:05:03 - INFO - volta.utils -   [GQA]: iter 65809 Ep: 17.86 loss 0.023 score 0.998 lr 4.75359e-06 
09/17/2020 16:06:26 - INFO - volta.utils -   [GQA]: iter 65829 Ep: 17.87 loss 0.020 score 0.999 lr 4.74152e-06 
09/17/2020 16:07:57 - INFO - volta.utils -   [GQA]: iter 65849 Ep: 17.87 loss 0.025 score 0.997 lr 4.72946e-06 
09/17/2020 16:09:35 - INFO - volta.utils -   [GQA]: iter 65869 Ep: 17.88 loss 0.020 score 0.998 lr 4.7174e-06 
09/17/2020 16:11:43 - INFO - volta.utils -   [GQA]: iter 65889 Ep: 17.89 loss 0.029 score 0.997 lr 4.70533e-06 
09/17/2020 16:13:14 - INFO - volta.utils -   [GQA]: iter 65909 Ep: 17.89 loss 0.020 score 0.999 lr 4.69327e-06 
09/17/2020 16:14:43 - INFO - volta.utils -   [GQA]: iter 65929 Ep: 17.90 loss 0.026 score 0.998 lr 4.6812e-06 
09/17/2020 16:16:03 - INFO - volta.utils -   [GQA]: iter 65949 Ep: 17.90 loss 0.024 score 0.998 lr 4.66914e-06 
09/17/2020 16:18:50 - INFO - volta.utils -   [GQA]: iter 65969 Ep: 17.91 loss 0.021 score 0.999 lr 4.65708e-06 
09/17/2020 16:20:20 - INFO - volta.utils -   [GQA]: iter 65989 Ep: 17.91 loss 0.024 score 0.998 lr 4.64501e-06 
09/17/2020 16:21:38 - INFO - volta.utils -   [GQA]: iter 66009 Ep: 17.92 loss 0.026 score 0.998 lr 4.63295e-06 
09/17/2020 16:22:53 - INFO - volta.utils -   [GQA]: iter 66029 Ep: 17.92 loss 0.023 score 0.998 lr 4.62088e-06 
09/17/2020 16:24:54 - INFO - volta.utils -   [GQA]: iter 66049 Ep: 17.93 loss 0.023 score 0.999 lr 4.60882e-06 
09/17/2020 16:26:10 - INFO - volta.utils -   [GQA]: iter 66069 Ep: 17.93 loss 0.021 score 0.998 lr 4.59675e-06 
09/17/2020 16:27:31 - INFO - volta.utils -   [GQA]: iter 66089 Ep: 17.94 loss 0.027 score 0.998 lr 4.58469e-06 
09/17/2020 16:28:57 - INFO - volta.utils -   [GQA]: iter 66109 Ep: 17.94 loss 0.025 score 0.998 lr 4.57263e-06 
09/17/2020 16:31:53 - INFO - volta.utils -   [GQA]: iter 66129 Ep: 17.95 loss 0.029 score 0.997 lr 4.56056e-06 
09/17/2020 16:33:41 - INFO - volta.utils -   [GQA]: iter 66149 Ep: 17.96 loss 0.020 score 0.998 lr 4.5485e-06 
09/17/2020 16:35:18 - INFO - volta.utils -   [GQA]: iter 66169 Ep: 17.96 loss 0.021 score 0.998 lr 4.53643e-06 
09/17/2020 16:36:47 - INFO - volta.utils -   [GQA]: iter 66189 Ep: 17.97 loss 0.021 score 0.998 lr 4.52437e-06 
09/17/2020 16:38:46 - INFO - volta.utils -   [GQA]: iter 66209 Ep: 17.97 loss 0.028 score 0.998 lr 4.51231e-06 
09/17/2020 16:39:59 - INFO - volta.utils -   [GQA]: iter 66229 Ep: 17.98 loss 0.028 score 0.998 lr 4.50024e-06 
09/17/2020 16:41:29 - INFO - volta.utils -   [GQA]: iter 66249 Ep: 17.98 loss 0.020 score 0.999 lr 4.48818e-06 
09/17/2020 16:43:12 - INFO - volta.utils -   [GQA]: iter 66269 Ep: 17.99 loss 0.025 score 0.998 lr 4.47611e-06 
09/17/2020 16:45:22 - INFO - volta.utils -   [GQA]: iter 66289 Ep: 17.99 loss 0.025 score 0.997 lr 4.46405e-06 
09/17/2020 16:46:31 - INFO - volta.utils -   [GQA]: iter 66309 Ep: 18.00 loss 0.024 score 0.999 lr 4.45198e-06 
09/17/2020 16:46:33 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  50%|█████     | 2/4 [11:01:12<10:59:39, 19789.83s/it]09/17/2020 17:05:52 - INFO - volta.utils -   Eval task TASK15 on iteration 66313 
09/17/2020 17:05:52 - INFO - volta.utils -   Validation [GQA]: loss 4.536 score 64.587 
09/17/2020 17:06:05 - INFO - volta.utils -   [GQA]: iter 66333 Ep: 18.01 loss 0.027 score 0.997 lr 4.43871e-06 
09/17/2020 17:07:29 - INFO - volta.utils -   [GQA]: iter 66353 Ep: 18.01 loss 0.021 score 0.999 lr 4.42544e-06 
09/17/2020 17:08:42 - INFO - volta.utils -   [GQA]: iter 66373 Ep: 18.02 loss 0.019 score 0.999 lr 4.41338e-06 
09/17/2020 17:10:04 - INFO - volta.utils -   [GQA]: iter 66393 Ep: 18.02 loss 0.020 score 0.999 lr 4.40131e-06 
09/17/2020 17:12:20 - INFO - volta.utils -   [GQA]: iter 66413 Ep: 18.03 loss 0.019 score 0.999 lr 4.38925e-06 
09/17/2020 17:13:01 - INFO - volta.utils -   [GQA]: iter 66433 Ep: 18.03 loss 0.020 score 0.998 lr 4.37719e-06 
09/17/2020 17:14:18 - INFO - volta.utils -   [GQA]: iter 66453 Ep: 18.04 loss 0.019 score 0.998 lr 4.36512e-06 
09/17/2020 17:15:01 - INFO - volta.utils -   [GQA]: iter 66473 Ep: 18.04 loss 0.026 score 0.999 lr 4.35306e-06 
09/17/2020 17:17:04 - INFO - volta.utils -   [GQA]: iter 66493 Ep: 18.05 loss 0.020 score 0.999 lr 4.34099e-06 
09/17/2020 17:18:09 - INFO - volta.utils -   [GQA]: iter 66513 Ep: 18.05 loss 0.020 score 0.999 lr 4.32893e-06 
09/17/2020 17:19:26 - INFO - volta.utils -   [GQA]: iter 66533 Ep: 18.06 loss 0.021 score 0.999 lr 4.31687e-06 
09/17/2020 17:20:57 - INFO - volta.utils -   [GQA]: iter 66553 Ep: 18.07 loss 0.021 score 0.999 lr 4.3048e-06 
09/17/2020 17:22:59 - INFO - volta.utils -   [GQA]: iter 66573 Ep: 18.07 loss 0.022 score 0.999 lr 4.29274e-06 
09/17/2020 17:24:40 - INFO - volta.utils -   [GQA]: iter 66593 Ep: 18.08 loss 0.022 score 0.999 lr 4.28067e-06 
09/17/2020 17:26:11 - INFO - volta.utils -   [GQA]: iter 66613 Ep: 18.08 loss 0.021 score 0.998 lr 4.26861e-06 
09/17/2020 17:27:40 - INFO - volta.utils -   [GQA]: iter 66633 Ep: 18.09 loss 0.015 score 0.999 lr 4.25654e-06 
09/17/2020 17:29:57 - INFO - volta.utils -   [GQA]: iter 66653 Ep: 18.09 loss 0.017 score 0.999 lr 4.24448e-06 
09/17/2020 17:31:31 - INFO - volta.utils -   [GQA]: iter 66673 Ep: 18.10 loss 0.021 score 0.998 lr 4.23242e-06 
09/17/2020 17:33:55 - INFO - volta.utils -   [GQA]: iter 66693 Ep: 18.10 loss 0.018 score 0.999 lr 4.22035e-06 
09/17/2020 17:35:16 - INFO - volta.utils -   [GQA]: iter 66713 Ep: 18.11 loss 0.022 score 0.999 lr 4.20829e-06 
09/17/2020 17:37:06 - INFO - volta.utils -   [GQA]: iter 66733 Ep: 18.11 loss 0.015 score 1.000 lr 4.19622e-06 
09/17/2020 17:38:43 - INFO - volta.utils -   [GQA]: iter 66753 Ep: 18.12 loss 0.021 score 0.998 lr 4.18416e-06 
09/17/2020 17:39:59 - INFO - volta.utils -   [GQA]: iter 66773 Ep: 18.13 loss 0.022 score 0.999 lr 4.1721e-06 
09/17/2020 17:40:58 - INFO - volta.utils -   [GQA]: iter 66793 Ep: 18.13 loss 0.021 score 0.998 lr 4.16003e-06 
09/17/2020 17:43:33 - INFO - volta.utils -   [GQA]: iter 66813 Ep: 18.14 loss 0.023 score 0.998 lr 4.14797e-06 
09/17/2020 17:45:05 - INFO - volta.utils -   [GQA]: iter 66833 Ep: 18.14 loss 0.023 score 0.997 lr 4.1359e-06 
09/17/2020 17:46:50 - INFO - volta.utils -   [GQA]: iter 66853 Ep: 18.15 loss 0.018 score 0.999 lr 4.12384e-06 
09/17/2020 17:48:33 - INFO - volta.utils -   [GQA]: iter 66873 Ep: 18.15 loss 0.022 score 0.998 lr 4.11177e-06 
09/17/2020 17:50:53 - INFO - volta.utils -   [GQA]: iter 66893 Ep: 18.16 loss 0.018 score 0.999 lr 4.09971e-06 
09/17/2020 17:52:07 - INFO - volta.utils -   [GQA]: iter 66913 Ep: 18.16 loss 0.019 score 0.999 lr 4.08765e-06 
09/17/2020 17:53:45 - INFO - volta.utils -   [GQA]: iter 66933 Ep: 18.17 loss 0.015 score 0.998 lr 4.07558e-06 
09/17/2020 17:55:22 - INFO - volta.utils -   [GQA]: iter 66953 Ep: 18.17 loss 0.017 score 0.999 lr 4.06352e-06 
09/17/2020 17:58:02 - INFO - volta.utils -   [GQA]: iter 66973 Ep: 18.18 loss 0.018 score 0.999 lr 4.05145e-06 
09/17/2020 17:59:05 - INFO - volta.utils -   [GQA]: iter 66993 Ep: 18.18 loss 0.020 score 0.999 lr 4.03939e-06 
09/17/2020 18:00:59 - INFO - volta.utils -   [GQA]: iter 67013 Ep: 18.19 loss 0.021 score 0.998 lr 4.02733e-06 
09/17/2020 18:02:35 - INFO - volta.utils -   [GQA]: iter 67033 Ep: 18.20 loss 0.016 score 0.998 lr 4.01526e-06 
09/17/2020 18:05:15 - INFO - volta.utils -   [GQA]: iter 67053 Ep: 18.20 loss 0.018 score 0.999 lr 4.0032e-06 
09/17/2020 18:06:30 - INFO - volta.utils -   [GQA]: iter 67073 Ep: 18.21 loss 0.017 score 0.998 lr 3.99113e-06 
09/17/2020 18:07:48 - INFO - volta.utils -   [GQA]: iter 67093 Ep: 18.21 loss 0.018 score 0.999 lr 3.97907e-06 
09/17/2020 18:09:25 - INFO - volta.utils -   [GQA]: iter 67113 Ep: 18.22 loss 0.019 score 0.999 lr 3.967e-06 
09/17/2020 18:11:48 - INFO - volta.utils -   [GQA]: iter 67133 Ep: 18.22 loss 0.019 score 0.999 lr 3.95494e-06 
09/17/2020 18:12:49 - INFO - volta.utils -   [GQA]: iter 67153 Ep: 18.23 loss 0.018 score 0.999 lr 3.94288e-06 
09/17/2020 18:14:25 - INFO - volta.utils -   [GQA]: iter 67173 Ep: 18.23 loss 0.018 score 0.999 lr 3.93081e-06 
09/17/2020 18:16:02 - INFO - volta.utils -   [GQA]: iter 67193 Ep: 18.24 loss 0.016 score 0.999 lr 3.91875e-06 
09/17/2020 18:18:02 - INFO - volta.utils -   [GQA]: iter 67213 Ep: 18.24 loss 0.014 score 0.999 lr 3.90668e-06 
09/17/2020 18:19:06 - INFO - volta.utils -   [GQA]: iter 67233 Ep: 18.25 loss 0.017 score 0.999 lr 3.89462e-06 
09/17/2020 18:20:22 - INFO - volta.utils -   [GQA]: iter 67253 Ep: 18.26 loss 0.016 score 0.999 lr 3.88256e-06 
09/17/2020 18:22:07 - INFO - volta.utils -   [GQA]: iter 67273 Ep: 18.26 loss 0.018 score 0.999 lr 3.87049e-06 
09/17/2020 18:23:55 - INFO - volta.utils -   [GQA]: iter 67293 Ep: 18.27 loss 0.023 score 0.998 lr 3.85843e-06 
09/17/2020 18:25:15 - INFO - volta.utils -   [GQA]: iter 67313 Ep: 18.27 loss 0.015 score 0.999 lr 3.84636e-06 
09/17/2020 18:27:03 - INFO - volta.utils -   [GQA]: iter 67333 Ep: 18.28 loss 0.021 score 0.998 lr 3.8343e-06 
09/17/2020 18:28:48 - INFO - volta.utils -   [GQA]: iter 67353 Ep: 18.28 loss 0.016 score 0.999 lr 3.82223e-06 
09/17/2020 18:31:08 - INFO - volta.utils -   [GQA]: iter 67373 Ep: 18.29 loss 0.020 score 0.998 lr 3.81017e-06 
09/17/2020 18:32:28 - INFO - volta.utils -   [GQA]: iter 67393 Ep: 18.29 loss 0.019 score 0.999 lr 3.79811e-06 
09/17/2020 18:33:57 - INFO - volta.utils -   [GQA]: iter 67413 Ep: 18.30 loss 0.020 score 0.999 lr 3.78604e-06 
09/17/2020 18:35:32 - INFO - volta.utils -   [GQA]: iter 67433 Ep: 18.30 loss 0.020 score 0.998 lr 3.77398e-06 
09/17/2020 18:37:19 - INFO - volta.utils -   [GQA]: iter 67453 Ep: 18.31 loss 0.015 score 0.999 lr 3.76191e-06 
09/17/2020 18:39:15 - INFO - volta.utils -   [GQA]: iter 67473 Ep: 18.32 loss 0.017 score 0.999 lr 3.74985e-06 
09/17/2020 18:40:50 - INFO - volta.utils -   [GQA]: iter 67493 Ep: 18.32 loss 0.019 score 0.999 lr 3.73779e-06 
09/17/2020 18:42:01 - INFO - volta.utils -   [GQA]: iter 67513 Ep: 18.33 loss 0.020 score 0.999 lr 3.72572e-06 
09/17/2020 18:44:27 - INFO - volta.utils -   [GQA]: iter 67533 Ep: 18.33 loss 0.020 score 0.999 lr 3.71366e-06 
09/17/2020 18:46:04 - INFO - volta.utils -   [GQA]: iter 67553 Ep: 18.34 loss 0.017 score 0.998 lr 3.70159e-06 
09/17/2020 18:47:44 - INFO - volta.utils -   [GQA]: iter 67573 Ep: 18.34 loss 0.022 score 0.998 lr 3.68953e-06 
09/17/2020 18:49:22 - INFO - volta.utils -   [GQA]: iter 67593 Ep: 18.35 loss 0.016 score 0.999 lr 3.67746e-06 
09/17/2020 18:51:41 - INFO - volta.utils -   [GQA]: iter 67613 Ep: 18.35 loss 0.018 score 0.998 lr 3.6654e-06 
09/17/2020 18:54:12 - INFO - volta.utils -   [GQA]: iter 67633 Ep: 18.36 loss 0.016 score 0.999 lr 3.65334e-06 
09/17/2020 18:55:46 - INFO - volta.utils -   [GQA]: iter 67653 Ep: 18.36 loss 0.014 score 0.999 lr 3.64127e-06 
09/17/2020 18:57:59 - INFO - volta.utils -   [GQA]: iter 67673 Ep: 18.37 loss 0.018 score 0.999 lr 3.62921e-06 
09/17/2020 18:59:48 - INFO - volta.utils -   [GQA]: iter 67693 Ep: 18.37 loss 0.020 score 0.998 lr 3.61714e-06 
09/17/2020 19:01:30 - INFO - volta.utils -   [GQA]: iter 67713 Ep: 18.38 loss 0.017 score 0.999 lr 3.60508e-06 
09/17/2020 19:02:50 - INFO - volta.utils -   [GQA]: iter 67733 Ep: 18.39 loss 0.015 score 0.999 lr 3.59301e-06 
09/17/2020 19:04:40 - INFO - volta.utils -   [GQA]: iter 67753 Ep: 18.39 loss 0.019 score 0.998 lr 3.58095e-06 
09/17/2020 19:06:30 - INFO - volta.utils -   [GQA]: iter 67773 Ep: 18.40 loss 0.016 score 1.000 lr 3.56889e-06 
09/17/2020 19:08:08 - INFO - volta.utils -   [GQA]: iter 67793 Ep: 18.40 loss 0.018 score 0.999 lr 3.55682e-06 
09/17/2020 19:09:32 - INFO - volta.utils -   [GQA]: iter 67813 Ep: 18.41 loss 0.016 score 0.999 lr 3.54476e-06 
09/17/2020 19:11:39 - INFO - volta.utils -   [GQA]: iter 67833 Ep: 18.41 loss 0.015 score 1.000 lr 3.53269e-06 
09/17/2020 19:13:16 - INFO - volta.utils -   [GQA]: iter 67853 Ep: 18.42 loss 0.016 score 0.999 lr 3.52063e-06 
09/17/2020 19:14:43 - INFO - volta.utils -   [GQA]: iter 67873 Ep: 18.42 loss 0.018 score 0.999 lr 3.50857e-06 
09/17/2020 19:17:22 - INFO - volta.utils -   [GQA]: iter 67893 Ep: 18.43 loss 0.017 score 0.999 lr 3.4965e-06 
09/17/2020 19:18:57 - INFO - volta.utils -   [GQA]: iter 67913 Ep: 18.43 loss 0.019 score 0.998 lr 3.48444e-06 
09/17/2020 19:20:46 - INFO - volta.utils -   [GQA]: iter 67933 Ep: 18.44 loss 0.016 score 0.998 lr 3.47237e-06 
09/17/2020 19:22:27 - INFO - volta.utils -   [GQA]: iter 67953 Ep: 18.45 loss 0.018 score 0.999 lr 3.46031e-06 
09/17/2020 19:24:22 - INFO - volta.utils -   [GQA]: iter 67973 Ep: 18.45 loss 0.016 score 0.999 lr 3.44824e-06 
09/17/2020 19:26:15 - INFO - volta.utils -   [GQA]: iter 67993 Ep: 18.46 loss 0.013 score 0.999 lr 3.43618e-06 
09/17/2020 19:27:43 - INFO - volta.utils -   [GQA]: iter 68013 Ep: 18.46 loss 0.018 score 0.998 lr 3.42412e-06 
09/17/2020 19:29:29 - INFO - volta.utils -   [GQA]: iter 68033 Ep: 18.47 loss 0.016 score 0.999 lr 3.41205e-06 
09/17/2020 19:31:19 - INFO - volta.utils -   [GQA]: iter 68053 Ep: 18.47 loss 0.015 score 0.999 lr 3.39999e-06 
09/17/2020 19:32:56 - INFO - volta.utils -   [GQA]: iter 68073 Ep: 18.48 loss 0.016 score 0.999 lr 3.38792e-06 
09/17/2020 19:34:37 - INFO - volta.utils -   [GQA]: iter 68093 Ep: 18.48 loss 0.019 score 0.999 lr 3.37586e-06 
09/17/2020 19:36:33 - INFO - volta.utils -   [GQA]: iter 68113 Ep: 18.49 loss 0.013 score 1.000 lr 3.3638e-06 
09/17/2020 19:37:51 - INFO - volta.utils -   [GQA]: iter 68133 Ep: 18.49 loss 0.015 score 0.999 lr 3.35173e-06 
09/17/2020 19:40:46 - INFO - volta.utils -   [GQA]: iter 68153 Ep: 18.50 loss 0.027 score 0.998 lr 3.33967e-06 
09/17/2020 19:42:20 - INFO - volta.utils -   [GQA]: iter 68173 Ep: 18.51 loss 0.016 score 0.999 lr 3.3276e-06 
09/17/2020 19:43:55 - INFO - volta.utils -   [GQA]: iter 68193 Ep: 18.51 loss 0.017 score 0.999 lr 3.31554e-06 
09/17/2020 19:45:08 - INFO - volta.utils -   [GQA]: iter 68213 Ep: 18.52 loss 0.014 score 0.999 lr 3.30347e-06 
09/17/2020 19:47:44 - INFO - volta.utils -   [GQA]: iter 68233 Ep: 18.52 loss 0.014 score 0.999 lr 3.29141e-06 
09/17/2020 19:49:00 - INFO - volta.utils -   [GQA]: iter 68253 Ep: 18.53 loss 0.013 score 1.000 lr 3.27935e-06 
09/17/2020 19:50:59 - INFO - volta.utils -   [GQA]: iter 68273 Ep: 18.53 loss 0.014 score 0.999 lr 3.26728e-06 
09/17/2020 19:52:45 - INFO - volta.utils -   [GQA]: iter 68293 Ep: 18.54 loss 0.015 score 0.999 lr 3.25522e-06 
09/17/2020 19:54:35 - INFO - volta.utils -   [GQA]: iter 68313 Ep: 18.54 loss 0.013 score 0.999 lr 3.24315e-06 
09/17/2020 19:56:16 - INFO - volta.utils -   [GQA]: iter 68333 Ep: 18.55 loss 0.017 score 0.999 lr 3.23109e-06 
09/17/2020 19:57:49 - INFO - volta.utils -   [GQA]: iter 68353 Ep: 18.55 loss 0.015 score 0.999 lr 3.21903e-06 
09/17/2020 19:59:11 - INFO - volta.utils -   [GQA]: iter 68373 Ep: 18.56 loss 0.014 score 1.000 lr 3.20696e-06 
09/17/2020 20:01:30 - INFO - volta.utils -   [GQA]: iter 68393 Ep: 18.56 loss 0.012 score 1.000 lr 3.1949e-06 
09/17/2020 20:03:18 - INFO - volta.utils -   [GQA]: iter 68413 Ep: 18.57 loss 0.014 score 0.999 lr 3.18283e-06 
09/17/2020 20:04:38 - INFO - volta.utils -   [GQA]: iter 68433 Ep: 18.58 loss 0.018 score 0.999 lr 3.17077e-06 
09/17/2020 20:06:03 - INFO - volta.utils -   [GQA]: iter 68453 Ep: 18.58 loss 0.018 score 0.999 lr 3.1587e-06 
09/17/2020 20:08:49 - INFO - volta.utils -   [GQA]: iter 68473 Ep: 18.59 loss 0.014 score 0.999 lr 3.14664e-06 
09/17/2020 20:10:26 - INFO - volta.utils -   [GQA]: iter 68493 Ep: 18.59 loss 0.014 score 1.000 lr 3.13458e-06 
09/17/2020 20:12:11 - INFO - volta.utils -   [GQA]: iter 68513 Ep: 18.60 loss 0.018 score 0.998 lr 3.12251e-06 
09/17/2020 20:13:36 - INFO - volta.utils -   [GQA]: iter 68533 Ep: 18.60 loss 0.016 score 0.999 lr 3.11045e-06 
09/17/2020 20:16:46 - INFO - volta.utils -   [GQA]: iter 68553 Ep: 18.61 loss 0.021 score 0.998 lr 3.09838e-06 
09/17/2020 20:18:13 - INFO - volta.utils -   [GQA]: iter 68573 Ep: 18.61 loss 0.014 score 1.000 lr 3.08632e-06 
09/17/2020 20:19:36 - INFO - volta.utils -   [GQA]: iter 68593 Ep: 18.62 loss 0.018 score 0.998 lr 3.07426e-06 
09/17/2020 20:20:58 - INFO - volta.utils -   [GQA]: iter 68613 Ep: 18.62 loss 0.020 score 0.998 lr 3.06219e-06 
09/17/2020 20:23:18 - INFO - volta.utils -   [GQA]: iter 68633 Ep: 18.63 loss 0.012 score 1.000 lr 3.05013e-06 
09/17/2020 20:24:59 - INFO - volta.utils -   [GQA]: iter 68653 Ep: 18.64 loss 0.016 score 0.999 lr 3.03806e-06 
09/17/2020 20:26:30 - INFO - volta.utils -   [GQA]: iter 68673 Ep: 18.64 loss 0.015 score 0.999 lr 3.026e-06 
09/17/2020 20:27:35 - INFO - volta.utils -   [GQA]: iter 68693 Ep: 18.65 loss 0.018 score 0.999 lr 3.01393e-06 
09/17/2020 20:29:36 - INFO - volta.utils -   [GQA]: iter 68713 Ep: 18.65 loss 0.017 score 0.999 lr 3.00187e-06 
09/17/2020 20:31:27 - INFO - volta.utils -   [GQA]: iter 68733 Ep: 18.66 loss 0.020 score 0.999 lr 2.98981e-06 
09/17/2020 20:32:49 - INFO - volta.utils -   [GQA]: iter 68753 Ep: 18.66 loss 0.019 score 0.998 lr 2.97774e-06 
09/17/2020 20:34:24 - INFO - volta.utils -   [GQA]: iter 68773 Ep: 18.67 loss 0.020 score 0.998 lr 2.96568e-06 
09/17/2020 20:37:12 - INFO - volta.utils -   [GQA]: iter 68793 Ep: 18.67 loss 0.020 score 0.998 lr 2.95361e-06 
09/17/2020 20:39:11 - INFO - volta.utils -   [GQA]: iter 68813 Ep: 18.68 loss 0.023 score 0.998 lr 2.94155e-06 
09/17/2020 20:40:38 - INFO - volta.utils -   [GQA]: iter 68833 Ep: 18.68 loss 0.016 score 0.999 lr 2.92948e-06 
09/17/2020 20:42:11 - INFO - volta.utils -   [GQA]: iter 68853 Ep: 18.69 loss 0.015 score 0.999 lr 2.91742e-06 
09/17/2020 20:45:06 - INFO - volta.utils -   [GQA]: iter 68873 Ep: 18.70 loss 0.016 score 0.999 lr 2.90536e-06 
09/17/2020 20:46:34 - INFO - volta.utils -   [GQA]: iter 68893 Ep: 18.70 loss 0.019 score 0.999 lr 2.89329e-06 
09/17/2020 20:47:52 - INFO - volta.utils -   [GQA]: iter 68913 Ep: 18.71 loss 0.015 score 0.999 lr 2.88123e-06 
09/17/2020 20:49:22 - INFO - volta.utils -   [GQA]: iter 68933 Ep: 18.71 loss 0.018 score 0.999 lr 2.86916e-06 
09/17/2020 20:51:44 - INFO - volta.utils -   [GQA]: iter 68953 Ep: 18.72 loss 0.015 score 0.999 lr 2.8571e-06 
09/17/2020 20:53:10 - INFO - volta.utils -   [GQA]: iter 68973 Ep: 18.72 loss 0.015 score 0.999 lr 2.84504e-06 
09/17/2020 20:54:47 - INFO - volta.utils -   [GQA]: iter 68993 Ep: 18.73 loss 0.014 score 1.000 lr 2.83297e-06 
09/17/2020 20:56:47 - INFO - volta.utils -   [GQA]: iter 69013 Ep: 18.73 loss 0.017 score 0.999 lr 2.82091e-06 
09/17/2020 20:58:46 - INFO - volta.utils -   [GQA]: iter 69033 Ep: 18.74 loss 0.018 score 0.999 lr 2.80884e-06 
09/17/2020 21:00:14 - INFO - volta.utils -   [GQA]: iter 69053 Ep: 18.74 loss 0.015 score 0.999 lr 2.79678e-06 
09/17/2020 21:01:44 - INFO - volta.utils -   [GQA]: iter 69073 Ep: 18.75 loss 0.021 score 0.999 lr 2.78471e-06 
09/17/2020 21:03:21 - INFO - volta.utils -   [GQA]: iter 69093 Ep: 18.75 loss 0.015 score 0.999 lr 2.77265e-06 
09/17/2020 21:05:10 - INFO - volta.utils -   [GQA]: iter 69113 Ep: 18.76 loss 0.017 score 0.999 lr 2.76059e-06 
09/17/2020 21:06:23 - INFO - volta.utils -   [GQA]: iter 69133 Ep: 18.77 loss 0.014 score 1.000 lr 2.74852e-06 
09/17/2020 21:08:01 - INFO - volta.utils -   [GQA]: iter 69153 Ep: 18.77 loss 0.017 score 0.999 lr 2.73646e-06 
09/17/2020 21:09:15 - INFO - volta.utils -   [GQA]: iter 69173 Ep: 18.78 loss 0.020 score 0.998 lr 2.72439e-06 
09/17/2020 21:12:06 - INFO - volta.utils -   [GQA]: iter 69193 Ep: 18.78 loss 0.015 score 0.999 lr 2.71233e-06 
09/17/2020 21:13:44 - INFO - volta.utils -   [GQA]: iter 69213 Ep: 18.79 loss 0.016 score 0.999 lr 2.70027e-06 
09/17/2020 21:15:33 - INFO - volta.utils -   [GQA]: iter 69233 Ep: 18.79 loss 0.019 score 0.998 lr 2.6882e-06 
09/17/2020 21:16:50 - INFO - volta.utils -   [GQA]: iter 69253 Ep: 18.80 loss 0.016 score 0.999 lr 2.67614e-06 
09/17/2020 21:19:23 - INFO - volta.utils -   [GQA]: iter 69273 Ep: 18.80 loss 0.016 score 0.999 lr 2.66407e-06 
09/17/2020 21:20:37 - INFO - volta.utils -   [GQA]: iter 69293 Ep: 18.81 loss 0.015 score 0.999 lr 2.65201e-06 
09/17/2020 21:21:37 - INFO - volta.utils -   [GQA]: iter 69313 Ep: 18.81 loss 0.016 score 0.999 lr 2.63994e-06 
09/17/2020 21:23:10 - INFO - volta.utils -   [GQA]: iter 69333 Ep: 18.82 loss 0.016 score 0.999 lr 2.62788e-06 
09/17/2020 21:25:09 - INFO - volta.utils -   [GQA]: iter 69353 Ep: 18.83 loss 0.016 score 0.999 lr 2.61582e-06 
09/17/2020 21:26:33 - INFO - volta.utils -   [GQA]: iter 69373 Ep: 18.83 loss 0.016 score 0.999 lr 2.60375e-06 
09/17/2020 21:27:58 - INFO - volta.utils -   [GQA]: iter 69393 Ep: 18.84 loss 0.014 score 0.999 lr 2.59169e-06 
09/17/2020 21:29:32 - INFO - volta.utils -   [GQA]: iter 69413 Ep: 18.84 loss 0.014 score 0.999 lr 2.57962e-06 
09/17/2020 21:32:51 - INFO - volta.utils -   [GQA]: iter 69433 Ep: 18.85 loss 0.018 score 0.998 lr 2.56756e-06 
09/17/2020 21:34:20 - INFO - volta.utils -   [GQA]: iter 69453 Ep: 18.85 loss 0.017 score 0.999 lr 2.5555e-06 
09/17/2020 21:35:12 - INFO - volta.utils -   [GQA]: iter 69473 Ep: 18.86 loss 0.016 score 0.999 lr 2.54343e-06 
09/17/2020 21:36:51 - INFO - volta.utils -   [GQA]: iter 69493 Ep: 18.86 loss 0.016 score 0.999 lr 2.53137e-06 
09/17/2020 21:38:44 - INFO - volta.utils -   [GQA]: iter 69513 Ep: 18.87 loss 0.017 score 0.999 lr 2.5193e-06 
09/17/2020 21:40:26 - INFO - volta.utils -   [GQA]: iter 69533 Ep: 18.87 loss 0.013 score 1.000 lr 2.50724e-06 
09/17/2020 21:41:54 - INFO - volta.utils -   [GQA]: iter 69553 Ep: 18.88 loss 0.015 score 0.999 lr 2.49517e-06 
09/17/2020 21:43:25 - INFO - volta.utils -   [GQA]: iter 69573 Ep: 18.89 loss 0.020 score 0.999 lr 2.48311e-06 
09/17/2020 21:45:40 - INFO - volta.utils -   [GQA]: iter 69593 Ep: 18.89 loss 0.015 score 0.999 lr 2.47105e-06 
09/17/2020 21:47:13 - INFO - volta.utils -   [GQA]: iter 69613 Ep: 18.90 loss 0.017 score 0.999 lr 2.45898e-06 
09/17/2020 21:48:57 - INFO - volta.utils -   [GQA]: iter 69633 Ep: 18.90 loss 0.014 score 1.000 lr 2.44692e-06 
09/17/2020 21:50:18 - INFO - volta.utils -   [GQA]: iter 69653 Ep: 18.91 loss 0.013 score 1.000 lr 2.43485e-06 
09/17/2020 21:52:26 - INFO - volta.utils -   [GQA]: iter 69673 Ep: 18.91 loss 0.021 score 0.998 lr 2.42279e-06 
09/17/2020 21:53:40 - INFO - volta.utils -   [GQA]: iter 69693 Ep: 18.92 loss 0.012 score 1.000 lr 2.41073e-06 
09/17/2020 21:54:58 - INFO - volta.utils -   [GQA]: iter 69713 Ep: 18.92 loss 0.015 score 0.999 lr 2.39866e-06 
09/17/2020 21:56:02 - INFO - volta.utils -   [GQA]: iter 69733 Ep: 18.93 loss 0.018 score 0.999 lr 2.3866e-06 
09/17/2020 21:58:33 - INFO - volta.utils -   [GQA]: iter 69753 Ep: 18.93 loss 0.013 score 0.999 lr 2.37453e-06 
09/17/2020 21:59:50 - INFO - volta.utils -   [GQA]: iter 69773 Ep: 18.94 loss 0.018 score 0.999 lr 2.36247e-06 
09/17/2020 22:01:37 - INFO - volta.utils -   [GQA]: iter 69793 Ep: 18.94 loss 0.014 score 0.999 lr 2.3504e-06 
09/17/2020 22:02:39 - INFO - volta.utils -   [GQA]: iter 69813 Ep: 18.95 loss 0.013 score 0.999 lr 2.33834e-06 
09/17/2020 22:05:22 - INFO - volta.utils -   [GQA]: iter 69833 Ep: 18.96 loss 0.016 score 0.999 lr 2.32628e-06 
09/17/2020 22:06:48 - INFO - volta.utils -   [GQA]: iter 69853 Ep: 18.96 loss 0.015 score 0.999 lr 2.31421e-06 
09/17/2020 22:08:06 - INFO - volta.utils -   [GQA]: iter 69873 Ep: 18.97 loss 0.014 score 0.999 lr 2.30215e-06 
09/17/2020 22:09:27 - INFO - volta.utils -   [GQA]: iter 69893 Ep: 18.97 loss 0.017 score 0.998 lr 2.29008e-06 
09/17/2020 22:11:35 - INFO - volta.utils -   [GQA]: iter 69913 Ep: 18.98 loss 0.021 score 0.998 lr 2.27802e-06 
09/17/2020 22:12:53 - INFO - volta.utils -   [GQA]: iter 69933 Ep: 18.98 loss 0.018 score 0.999 lr 2.26595e-06 
09/17/2020 22:13:56 - INFO - volta.utils -   [GQA]: iter 69953 Ep: 18.99 loss 0.017 score 0.999 lr 2.25389e-06 
09/17/2020 22:15:24 - INFO - volta.utils -   [GQA]: iter 69973 Ep: 18.99 loss 0.012 score 0.999 lr 2.24183e-06 
09/17/2020 22:16:56 - INFO - volta.utils -   [GQA]: iter 69993 Ep: 19.00 loss 0.019 score 0.999 lr 2.22976e-06 
09/17/2020 22:16:59 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  75%|███████▌  | 3/4 [16:31:41<5:30:01, 19801.49s/it] 09/17/2020 22:37:38 - INFO - volta.utils -   Eval task TASK15 on iteration 69997 
09/17/2020 22:37:38 - INFO - volta.utils -   Validation [GQA]: loss 4.709 score 64.658 
09/17/2020 22:37:50 - INFO - volta.utils -   [GQA]: iter 70017 Ep: 19.01 loss 0.013 score 1.000 lr 2.21649e-06 
09/17/2020 22:39:01 - INFO - volta.utils -   [GQA]: iter 70037 Ep: 19.01 loss 0.017 score 0.999 lr 2.20322e-06 
09/17/2020 22:40:02 - INFO - volta.utils -   [GQA]: iter 70057 Ep: 19.02 loss 0.016 score 0.999 lr 2.19116e-06 
09/17/2020 22:41:23 - INFO - volta.utils -   [GQA]: iter 70077 Ep: 19.02 loss 0.019 score 0.999 lr 2.17909e-06 
09/17/2020 22:43:07 - INFO - volta.utils -   [GQA]: iter 70097 Ep: 19.03 loss 0.017 score 0.999 lr 2.16703e-06 
09/17/2020 22:44:09 - INFO - volta.utils -   [GQA]: iter 70117 Ep: 19.03 loss 0.014 score 1.000 lr 2.15496e-06 
09/17/2020 22:45:01 - INFO - volta.utils -   [GQA]: iter 70137 Ep: 19.04 loss 0.015 score 0.999 lr 2.1429e-06 
09/17/2020 22:46:30 - INFO - volta.utils -   [GQA]: iter 70157 Ep: 19.04 loss 0.014 score 1.000 lr 2.13084e-06 
09/17/2020 22:49:13 - INFO - volta.utils -   [GQA]: iter 70177 Ep: 19.05 loss 0.014 score 0.999 lr 2.11877e-06 
09/17/2020 22:50:19 - INFO - volta.utils -   [GQA]: iter 70197 Ep: 19.05 loss 0.014 score 0.999 lr 2.10671e-06 
09/17/2020 22:51:36 - INFO - volta.utils -   [GQA]: iter 70217 Ep: 19.06 loss 0.019 score 0.999 lr 2.09464e-06 
09/17/2020 22:53:22 - INFO - volta.utils -   [GQA]: iter 70237 Ep: 19.07 loss 0.013 score 0.999 lr 2.08258e-06 
09/17/2020 22:56:06 - INFO - volta.utils -   [GQA]: iter 70257 Ep: 19.07 loss 0.018 score 0.998 lr 2.07052e-06 
09/17/2020 22:57:47 - INFO - volta.utils -   [GQA]: iter 70277 Ep: 19.08 loss 0.017 score 0.999 lr 2.05845e-06 
09/17/2020 22:59:09 - INFO - volta.utils -   [GQA]: iter 70297 Ep: 19.08 loss 0.011 score 1.000 lr 2.04639e-06 
09/17/2020 23:00:52 - INFO - volta.utils -   [GQA]: iter 70317 Ep: 19.09 loss 0.017 score 0.999 lr 2.03432e-06 
09/17/2020 23:03:57 - INFO - volta.utils -   [GQA]: iter 70337 Ep: 19.09 loss 0.016 score 0.999 lr 2.02226e-06 
09/17/2020 23:05:07 - INFO - volta.utils -   [GQA]: iter 70357 Ep: 19.10 loss 0.012 score 1.000 lr 2.01019e-06 
09/17/2020 23:06:33 - INFO - volta.utils -   [GQA]: iter 70377 Ep: 19.10 loss 0.014 score 0.999 lr 1.99813e-06 
09/17/2020 23:08:25 - INFO - volta.utils -   [GQA]: iter 70397 Ep: 19.11 loss 0.013 score 1.000 lr 1.98607e-06 
09/17/2020 23:10:37 - INFO - volta.utils -   [GQA]: iter 70417 Ep: 19.11 loss 0.016 score 0.999 lr 1.974e-06 
09/17/2020 23:12:11 - INFO - volta.utils -   [GQA]: iter 70437 Ep: 19.12 loss 0.016 score 0.999 lr 1.96194e-06 
09/17/2020 23:13:55 - INFO - volta.utils -   [GQA]: iter 70457 Ep: 19.13 loss 0.015 score 0.999 lr 1.94987e-06 
09/17/2020 23:15:42 - INFO - volta.utils -   [GQA]: iter 70477 Ep: 19.13 loss 0.020 score 0.998 lr 1.93781e-06 
09/17/2020 23:17:16 - INFO - volta.utils -   [GQA]: iter 70497 Ep: 19.14 loss 0.019 score 0.998 lr 1.92574e-06 
09/17/2020 23:18:51 - INFO - volta.utils -   [GQA]: iter 70517 Ep: 19.14 loss 0.014 score 0.999 lr 1.91368e-06 
09/17/2020 23:21:14 - INFO - volta.utils -   [GQA]: iter 70537 Ep: 19.15 loss 0.013 score 0.999 lr 1.90162e-06 
09/17/2020 23:23:05 - INFO - volta.utils -   [GQA]: iter 70557 Ep: 19.15 loss 0.013 score 0.999 lr 1.88955e-06 
09/17/2020 23:24:58 - INFO - volta.utils -   [GQA]: iter 70577 Ep: 19.16 loss 0.014 score 0.999 lr 1.87749e-06 
09/17/2020 23:26:37 - INFO - volta.utils -   [GQA]: iter 70597 Ep: 19.16 loss 0.011 score 0.999 lr 1.86542e-06 
09/17/2020 23:28:39 - INFO - volta.utils -   [GQA]: iter 70617 Ep: 19.17 loss 0.013 score 0.999 lr 1.85336e-06 
09/17/2020 23:30:57 - INFO - volta.utils -   [GQA]: iter 70637 Ep: 19.17 loss 0.014 score 0.999 lr 1.8413e-06 
09/17/2020 23:32:25 - INFO - volta.utils -   [GQA]: iter 70657 Ep: 19.18 loss 0.013 score 0.999 lr 1.82923e-06 
09/17/2020 23:33:27 - INFO - volta.utils -   [GQA]: iter 70677 Ep: 19.18 loss 0.016 score 0.998 lr 1.81717e-06 
09/17/2020 23:35:30 - INFO - volta.utils -   [GQA]: iter 70697 Ep: 19.19 loss 0.012 score 1.000 lr 1.8051e-06 
09/17/2020 23:36:45 - INFO - volta.utils -   [GQA]: iter 70717 Ep: 19.20 loss 0.017 score 0.998 lr 1.79304e-06 
09/17/2020 23:38:58 - INFO - volta.utils -   [GQA]: iter 70737 Ep: 19.20 loss 0.014 score 0.999 lr 1.78097e-06 
09/17/2020 23:40:12 - INFO - volta.utils -   [GQA]: iter 70757 Ep: 19.21 loss 0.013 score 1.000 lr 1.76891e-06 
09/17/2020 23:42:26 - INFO - volta.utils -   [GQA]: iter 70777 Ep: 19.21 loss 0.013 score 1.000 lr 1.75685e-06 
09/17/2020 23:43:53 - INFO - volta.utils -   [GQA]: iter 70797 Ep: 19.22 loss 0.013 score 0.999 lr 1.74478e-06 
09/17/2020 23:45:19 - INFO - volta.utils -   [GQA]: iter 70817 Ep: 19.22 loss 0.011 score 1.000 lr 1.73272e-06 
09/17/2020 23:46:52 - INFO - volta.utils -   [GQA]: iter 70837 Ep: 19.23 loss 0.015 score 0.999 lr 1.72065e-06 
09/17/2020 23:49:20 - INFO - volta.utils -   [GQA]: iter 70857 Ep: 19.23 loss 0.012 score 1.000 lr 1.70859e-06 
09/17/2020 23:50:34 - INFO - volta.utils -   [GQA]: iter 70877 Ep: 19.24 loss 0.017 score 0.999 lr 1.69653e-06 
09/17/2020 23:52:04 - INFO - volta.utils -   [GQA]: iter 70897 Ep: 19.24 loss 0.012 score 0.999 lr 1.68446e-06 
09/17/2020 23:53:35 - INFO - volta.utils -   [GQA]: iter 70917 Ep: 19.25 loss 0.011 score 1.000 lr 1.6724e-06 
09/17/2020 23:56:34 - INFO - volta.utils -   [GQA]: iter 70937 Ep: 19.26 loss 0.014 score 0.999 lr 1.66033e-06 
09/17/2020 23:58:14 - INFO - volta.utils -   [GQA]: iter 70957 Ep: 19.26 loss 0.012 score 1.000 lr 1.64827e-06 
09/17/2020 23:59:26 - INFO - volta.utils -   [GQA]: iter 70977 Ep: 19.27 loss 0.016 score 0.999 lr 1.6362e-06 
09/18/2020 00:00:51 - INFO - volta.utils -   [GQA]: iter 70997 Ep: 19.27 loss 0.013 score 0.999 lr 1.62414e-06 
09/18/2020 00:03:13 - INFO - volta.utils -   [GQA]: iter 71017 Ep: 19.28 loss 0.011 score 0.999 lr 1.61208e-06 
09/18/2020 00:04:40 - INFO - volta.utils -   [GQA]: iter 71037 Ep: 19.28 loss 0.012 score 1.000 lr 1.60001e-06 
09/18/2020 00:06:04 - INFO - volta.utils -   [GQA]: iter 71057 Ep: 19.29 loss 0.013 score 0.999 lr 1.58795e-06 
09/18/2020 00:07:31 - INFO - volta.utils -   [GQA]: iter 71077 Ep: 19.29 loss 0.013 score 0.999 lr 1.57588e-06 
09/18/2020 00:10:28 - INFO - volta.utils -   [GQA]: iter 71097 Ep: 19.30 loss 0.013 score 0.999 lr 1.56382e-06 
09/18/2020 00:12:20 - INFO - volta.utils -   [GQA]: iter 71117 Ep: 19.30 loss 0.012 score 0.999 lr 1.55176e-06 
09/18/2020 00:13:45 - INFO - volta.utils -   [GQA]: iter 71137 Ep: 19.31 loss 0.013 score 0.999 lr 1.53969e-06 
09/18/2020 00:15:10 - INFO - volta.utils -   [GQA]: iter 71157 Ep: 19.32 loss 0.013 score 0.999 lr 1.52763e-06 
09/18/2020 00:17:35 - INFO - volta.utils -   [GQA]: iter 71177 Ep: 19.32 loss 0.016 score 0.999 lr 1.51556e-06 
09/18/2020 00:19:05 - INFO - volta.utils -   [GQA]: iter 71197 Ep: 19.33 loss 0.012 score 0.999 lr 1.5035e-06 
09/18/2020 00:20:30 - INFO - volta.utils -   [GQA]: iter 71217 Ep: 19.33 loss 0.011 score 1.000 lr 1.49143e-06 
09/18/2020 00:22:09 - INFO - volta.utils -   [GQA]: iter 71237 Ep: 19.34 loss 0.012 score 0.999 lr 1.47937e-06 
09/18/2020 00:24:48 - INFO - volta.utils -   [GQA]: iter 71257 Ep: 19.34 loss 0.010 score 1.000 lr 1.46731e-06 
09/18/2020 00:26:03 - INFO - volta.utils -   [GQA]: iter 71277 Ep: 19.35 loss 0.009 score 1.000 lr 1.45524e-06 
09/18/2020 00:27:21 - INFO - volta.utils -   [GQA]: iter 71297 Ep: 19.35 loss 0.011 score 1.000 lr 1.44318e-06 
09/18/2020 00:28:37 - INFO - volta.utils -   [GQA]: iter 71317 Ep: 19.36 loss 0.016 score 0.999 lr 1.43111e-06 
09/18/2020 00:30:50 - INFO - volta.utils -   [GQA]: iter 71337 Ep: 19.36 loss 0.012 score 0.999 lr 1.41905e-06 
09/18/2020 00:32:22 - INFO - volta.utils -   [GQA]: iter 71357 Ep: 19.37 loss 0.010 score 1.000 lr 1.40699e-06 
09/18/2020 00:34:21 - INFO - volta.utils -   [GQA]: iter 71377 Ep: 19.37 loss 0.012 score 0.999 lr 1.39492e-06 
09/18/2020 00:35:37 - INFO - volta.utils -   [GQA]: iter 71397 Ep: 19.38 loss 0.013 score 1.000 lr 1.38286e-06 
09/18/2020 00:38:07 - INFO - volta.utils -   [GQA]: iter 71417 Ep: 19.39 loss 0.012 score 0.999 lr 1.37079e-06 
09/18/2020 00:39:01 - INFO - volta.utils -   [GQA]: iter 71437 Ep: 19.39 loss 0.012 score 0.999 lr 1.35873e-06 
09/18/2020 00:40:31 - INFO - volta.utils -   [GQA]: iter 71457 Ep: 19.40 loss 0.015 score 0.999 lr 1.34666e-06 
09/18/2020 00:42:06 - INFO - volta.utils -   [GQA]: iter 71477 Ep: 19.40 loss 0.012 score 1.000 lr 1.3346e-06 
09/18/2020 00:43:59 - INFO - volta.utils -   [GQA]: iter 71497 Ep: 19.41 loss 0.015 score 0.999 lr 1.32254e-06 
09/18/2020 00:45:27 - INFO - volta.utils -   [GQA]: iter 71517 Ep: 19.41 loss 0.014 score 1.000 lr 1.31047e-06 
09/18/2020 00:47:09 - INFO - volta.utils -   [GQA]: iter 71537 Ep: 19.42 loss 0.011 score 0.999 lr 1.29841e-06 
09/18/2020 00:49:42 - INFO - volta.utils -   [GQA]: iter 71557 Ep: 19.42 loss 0.015 score 1.000 lr 1.28634e-06 
09/18/2020 00:51:22 - INFO - volta.utils -   [GQA]: iter 71577 Ep: 19.43 loss 0.013 score 1.000 lr 1.27428e-06 
09/18/2020 00:52:25 - INFO - volta.utils -   [GQA]: iter 71597 Ep: 19.43 loss 0.010 score 1.000 lr 1.26221e-06 
09/18/2020 00:54:41 - INFO - volta.utils -   [GQA]: iter 71617 Ep: 19.44 loss 0.015 score 0.999 lr 1.25015e-06 
09/18/2020 00:56:27 - INFO - volta.utils -   [GQA]: iter 71637 Ep: 19.45 loss 0.012 score 0.999 lr 1.23809e-06 
09/18/2020 00:58:31 - INFO - volta.utils -   [GQA]: iter 71657 Ep: 19.45 loss 0.011 score 0.999 lr 1.22602e-06 
09/18/2020 01:00:03 - INFO - volta.utils -   [GQA]: iter 71677 Ep: 19.46 loss 0.013 score 0.999 lr 1.21396e-06 
09/18/2020 01:01:33 - INFO - volta.utils -   [GQA]: iter 71697 Ep: 19.46 loss 0.011 score 1.000 lr 1.20189e-06 
09/18/2020 01:03:20 - INFO - volta.utils -   [GQA]: iter 71717 Ep: 19.47 loss 0.011 score 0.999 lr 1.18983e-06 
09/18/2020 01:05:32 - INFO - volta.utils -   [GQA]: iter 71737 Ep: 19.47 loss 0.011 score 1.000 lr 1.17777e-06 
09/18/2020 01:06:54 - INFO - volta.utils -   [GQA]: iter 71757 Ep: 19.48 loss 0.014 score 0.999 lr 1.1657e-06 
09/18/2020 01:08:19 - INFO - volta.utils -   [GQA]: iter 71777 Ep: 19.48 loss 0.009 score 1.000 lr 1.15364e-06 
09/18/2020 01:10:05 - INFO - volta.utils -   [GQA]: iter 71797 Ep: 19.49 loss 0.012 score 0.999 lr 1.14157e-06 
09/18/2020 01:11:50 - INFO - volta.utils -   [GQA]: iter 71817 Ep: 19.49 loss 0.012 score 0.999 lr 1.12951e-06 
09/18/2020 01:13:31 - INFO - volta.utils -   [GQA]: iter 71837 Ep: 19.50 loss 0.014 score 1.000 lr 1.11744e-06 
09/18/2020 01:14:59 - INFO - volta.utils -   [GQA]: iter 71857 Ep: 19.51 loss 0.013 score 0.999 lr 1.10538e-06 
09/18/2020 01:17:40 - INFO - volta.utils -   [GQA]: iter 71877 Ep: 19.51 loss 0.012 score 0.999 lr 1.09332e-06 
09/18/2020 01:19:21 - INFO - volta.utils -   [GQA]: iter 71897 Ep: 19.52 loss 0.013 score 0.999 lr 1.08125e-06 
09/18/2020 01:20:46 - INFO - volta.utils -   [GQA]: iter 71917 Ep: 19.52 loss 0.013 score 0.999 lr 1.06919e-06 
09/18/2020 01:22:09 - INFO - volta.utils -   [GQA]: iter 71937 Ep: 19.53 loss 0.013 score 1.000 lr 1.05712e-06 
09/18/2020 01:24:20 - INFO - volta.utils -   [GQA]: iter 71957 Ep: 19.53 loss 0.013 score 0.999 lr 1.04506e-06 
09/18/2020 01:25:43 - INFO - volta.utils -   [GQA]: iter 71977 Ep: 19.54 loss 0.015 score 0.999 lr 1.033e-06 
09/18/2020 01:26:57 - INFO - volta.utils -   [GQA]: iter 71997 Ep: 19.54 loss 0.011 score 0.999 lr 1.02093e-06 
09/18/2020 01:28:22 - INFO - volta.utils -   [GQA]: iter 72017 Ep: 19.55 loss 0.009 score 1.000 lr 1.00887e-06 
09/18/2020 01:30:00 - INFO - volta.utils -   [GQA]: iter 72037 Ep: 19.55 loss 0.010 score 1.000 lr 9.96803e-07 
09/18/2020 01:32:37 - INFO - volta.utils -   [GQA]: iter 72057 Ep: 19.56 loss 0.012 score 0.999 lr 9.84739e-07 
09/18/2020 01:33:46 - INFO - volta.utils -   [GQA]: iter 72077 Ep: 19.56 loss 0.013 score 1.000 lr 9.72675e-07 
09/18/2020 01:35:22 - INFO - volta.utils -   [GQA]: iter 72097 Ep: 19.57 loss 0.013 score 1.000 lr 9.6061e-07 
09/18/2020 01:36:43 - INFO - volta.utils -   [GQA]: iter 72117 Ep: 19.58 loss 0.011 score 1.000 lr 9.48546e-07 
09/18/2020 01:38:32 - INFO - volta.utils -   [GQA]: iter 72137 Ep: 19.58 loss 0.012 score 1.000 lr 9.36482e-07 
09/18/2020 01:40:05 - INFO - volta.utils -   [GQA]: iter 72157 Ep: 19.59 loss 0.011 score 0.999 lr 9.24418e-07 
09/18/2020 01:41:46 - INFO - volta.utils -   [GQA]: iter 72177 Ep: 19.59 loss 0.015 score 0.999 lr 9.12354e-07 
09/18/2020 01:43:19 - INFO - volta.utils -   [GQA]: iter 72197 Ep: 19.60 loss 0.009 score 1.000 lr 9.0029e-07 
09/18/2020 01:45:08 - INFO - volta.utils -   [GQA]: iter 72217 Ep: 19.60 loss 0.010 score 1.000 lr 8.88225e-07 
09/18/2020 01:46:27 - INFO - volta.utils -   [GQA]: iter 72237 Ep: 19.61 loss 0.011 score 1.000 lr 8.76161e-07 
09/18/2020 01:48:26 - INFO - volta.utils -   [GQA]: iter 72257 Ep: 19.61 loss 0.014 score 0.999 lr 8.64097e-07 
09/18/2020 01:50:04 - INFO - volta.utils -   [GQA]: iter 72277 Ep: 19.62 loss 0.008 score 1.000 lr 8.52033e-07 
09/18/2020 01:52:46 - INFO - volta.utils -   [GQA]: iter 72297 Ep: 19.62 loss 0.015 score 0.999 lr 8.39969e-07 
09/18/2020 01:54:19 - INFO - volta.utils -   [GQA]: iter 72317 Ep: 19.63 loss 0.016 score 0.999 lr 8.27904e-07 
09/18/2020 01:56:29 - INFO - volta.utils -   [GQA]: iter 72337 Ep: 19.64 loss 0.010 score 1.000 lr 8.1584e-07 
09/18/2020 01:57:38 - INFO - volta.utils -   [GQA]: iter 72357 Ep: 19.64 loss 0.010 score 1.000 lr 8.03776e-07 
09/18/2020 02:00:09 - INFO - volta.utils -   [GQA]: iter 72377 Ep: 19.65 loss 0.012 score 0.999 lr 7.91712e-07 
09/18/2020 02:01:20 - INFO - volta.utils -   [GQA]: iter 72397 Ep: 19.65 loss 0.014 score 0.999 lr 7.79648e-07 
09/18/2020 02:03:24 - INFO - volta.utils -   [GQA]: iter 72417 Ep: 19.66 loss 0.009 score 1.000 lr 7.67584e-07 
09/18/2020 02:04:40 - INFO - volta.utils -   [GQA]: iter 72437 Ep: 19.66 loss 0.011 score 1.000 lr 7.55519e-07 
09/18/2020 02:06:05 - INFO - volta.utils -   [GQA]: iter 72457 Ep: 19.67 loss 0.015 score 0.999 lr 7.43455e-07 
09/18/2020 02:07:24 - INFO - volta.utils -   [GQA]: iter 72477 Ep: 19.67 loss 0.011 score 1.000 lr 7.31391e-07 
09/18/2020 02:09:52 - INFO - volta.utils -   [GQA]: iter 72497 Ep: 19.68 loss 0.014 score 0.999 lr 7.19327e-07 
09/18/2020 02:11:15 - INFO - volta.utils -   [GQA]: iter 72517 Ep: 19.68 loss 0.012 score 1.000 lr 7.07263e-07 
09/18/2020 02:12:28 - INFO - volta.utils -   [GQA]: iter 72537 Ep: 19.69 loss 0.015 score 0.999 lr 6.95198e-07 
09/18/2020 02:13:53 - INFO - volta.utils -   [GQA]: iter 72557 Ep: 19.70 loss 0.012 score 0.999 lr 6.83134e-07 
09/18/2020 02:16:10 - INFO - volta.utils -   [GQA]: iter 72577 Ep: 19.70 loss 0.009 score 1.000 lr 6.7107e-07 
09/18/2020 02:17:39 - INFO - volta.utils -   [GQA]: iter 72597 Ep: 19.71 loss 0.013 score 0.999 lr 6.59006e-07 
09/18/2020 02:19:05 - INFO - volta.utils -   [GQA]: iter 72617 Ep: 19.71 loss 0.010 score 1.000 lr 6.46942e-07 
09/18/2020 02:20:45 - INFO - volta.utils -   [GQA]: iter 72637 Ep: 19.72 loss 0.014 score 0.999 lr 6.34878e-07 
09/18/2020 02:23:42 - INFO - volta.utils -   [GQA]: iter 72657 Ep: 19.72 loss 0.012 score 0.999 lr 6.22813e-07 
09/18/2020 02:25:19 - INFO - volta.utils -   [GQA]: iter 72677 Ep: 19.73 loss 0.011 score 1.000 lr 6.10749e-07 
09/18/2020 02:26:39 - INFO - volta.utils -   [GQA]: iter 72697 Ep: 19.73 loss 0.015 score 0.999 lr 5.98685e-07 
09/18/2020 02:27:59 - INFO - volta.utils -   [GQA]: iter 72717 Ep: 19.74 loss 0.013 score 0.999 lr 5.86621e-07 
09/18/2020 02:30:36 - INFO - volta.utils -   [GQA]: iter 72737 Ep: 19.74 loss 0.012 score 1.000 lr 5.74557e-07 
09/18/2020 02:32:21 - INFO - volta.utils -   [GQA]: iter 72757 Ep: 19.75 loss 0.011 score 0.999 lr 5.62492e-07 
09/18/2020 02:33:54 - INFO - volta.utils -   [GQA]: iter 72777 Ep: 19.75 loss 0.012 score 0.999 lr 5.50428e-07 
09/18/2020 02:35:14 - INFO - volta.utils -   [GQA]: iter 72797 Ep: 19.76 loss 0.011 score 0.999 lr 5.38364e-07 
09/18/2020 02:37:24 - INFO - volta.utils -   [GQA]: iter 72817 Ep: 19.77 loss 0.017 score 0.998 lr 5.263e-07 
09/18/2020 02:38:49 - INFO - volta.utils -   [GQA]: iter 72837 Ep: 19.77 loss 0.012 score 1.000 lr 5.14236e-07 
09/18/2020 02:40:36 - INFO - volta.utils -   [GQA]: iter 72857 Ep: 19.78 loss 0.011 score 1.000 lr 5.02172e-07 
09/18/2020 02:41:57 - INFO - volta.utils -   [GQA]: iter 72877 Ep: 19.78 loss 0.011 score 0.999 lr 4.90107e-07 
09/18/2020 02:44:05 - INFO - volta.utils -   [GQA]: iter 72897 Ep: 19.79 loss 0.013 score 1.000 lr 4.78043e-07 
09/18/2020 02:45:15 - INFO - volta.utils -   [GQA]: iter 72917 Ep: 19.79 loss 0.013 score 0.999 lr 4.65979e-07 
09/18/2020 02:46:49 - INFO - volta.utils -   [GQA]: iter 72937 Ep: 19.80 loss 0.014 score 0.999 lr 4.53915e-07 
09/18/2020 02:48:00 - INFO - volta.utils -   [GQA]: iter 72957 Ep: 19.80 loss 0.010 score 1.000 lr 4.41851e-07 
09/18/2020 02:50:41 - INFO - volta.utils -   [GQA]: iter 72977 Ep: 19.81 loss 0.011 score 1.000 lr 4.29786e-07 
09/18/2020 02:52:03 - INFO - volta.utils -   [GQA]: iter 72997 Ep: 19.81 loss 0.013 score 0.999 lr 4.17722e-07 
09/18/2020 02:52:57 - INFO - volta.utils -   [GQA]: iter 73017 Ep: 19.82 loss 0.009 score 1.000 lr 4.05658e-07 
09/18/2020 02:54:36 - INFO - volta.utils -   [GQA]: iter 73037 Ep: 19.83 loss 0.010 score 1.000 lr 3.93594e-07 
09/18/2020 02:57:00 - INFO - volta.utils -   [GQA]: iter 73057 Ep: 19.83 loss 0.009 score 1.000 lr 3.8153e-07 
09/18/2020 02:58:19 - INFO - volta.utils -   [GQA]: iter 73077 Ep: 19.84 loss 0.010 score 1.000 lr 3.69466e-07 
09/18/2020 02:59:29 - INFO - volta.utils -   [GQA]: iter 73097 Ep: 19.84 loss 0.012 score 0.999 lr 3.57401e-07 
09/18/2020 03:01:03 - INFO - volta.utils -   [GQA]: iter 73117 Ep: 19.85 loss 0.012 score 0.999 lr 3.45337e-07 
09/18/2020 03:03:36 - INFO - volta.utils -   [GQA]: iter 73137 Ep: 19.85 loss 0.010 score 1.000 lr 3.33273e-07 
09/18/2020 03:04:59 - INFO - volta.utils -   [GQA]: iter 73157 Ep: 19.86 loss 0.013 score 0.999 lr 3.21209e-07 
09/18/2020 03:06:32 - INFO - volta.utils -   [GQA]: iter 73177 Ep: 19.86 loss 0.011 score 1.000 lr 3.09145e-07 
09/18/2020 03:07:50 - INFO - volta.utils -   [GQA]: iter 73197 Ep: 19.87 loss 0.010 score 1.000 lr 2.9708e-07 
09/18/2020 03:09:56 - INFO - volta.utils -   [GQA]: iter 73217 Ep: 19.87 loss 0.009 score 1.000 lr 2.85016e-07 
09/18/2020 03:11:16 - INFO - volta.utils -   [GQA]: iter 73237 Ep: 19.88 loss 0.010 score 1.000 lr 2.72952e-07 
09/18/2020 03:12:48 - INFO - volta.utils -   [GQA]: iter 73257 Ep: 19.89 loss 0.010 score 1.000 lr 2.60888e-07 
09/18/2020 03:14:28 - INFO - volta.utils -   [GQA]: iter 73277 Ep: 19.89 loss 0.013 score 1.000 lr 2.48824e-07 
09/18/2020 03:16:20 - INFO - volta.utils -   [GQA]: iter 73297 Ep: 19.90 loss 0.013 score 1.000 lr 2.3676e-07 
09/18/2020 03:17:49 - INFO - volta.utils -   [GQA]: iter 73317 Ep: 19.90 loss 0.013 score 0.999 lr 2.24695e-07 
09/18/2020 03:19:29 - INFO - volta.utils -   [GQA]: iter 73337 Ep: 19.91 loss 0.013 score 0.999 lr 2.12631e-07 
09/18/2020 03:21:14 - INFO - volta.utils -   [GQA]: iter 73357 Ep: 19.91 loss 0.009 score 1.000 lr 2.00567e-07 
09/18/2020 03:23:23 - INFO - volta.utils -   [GQA]: iter 73377 Ep: 19.92 loss 0.012 score 0.999 lr 1.88503e-07 
09/18/2020 03:24:48 - INFO - volta.utils -   [GQA]: iter 73397 Ep: 19.92 loss 0.010 score 0.999 lr 1.76439e-07 
09/18/2020 03:27:07 - INFO - volta.utils -   [GQA]: iter 73417 Ep: 19.93 loss 0.010 score 1.000 lr 1.64374e-07 
09/18/2020 03:28:04 - INFO - volta.utils -   [GQA]: iter 73437 Ep: 19.93 loss 0.013 score 0.999 lr 1.5231e-07 
09/18/2020 03:30:47 - INFO - volta.utils -   [GQA]: iter 73457 Ep: 19.94 loss 0.011 score 1.000 lr 1.40246e-07 
09/18/2020 03:32:30 - INFO - volta.utils -   [GQA]: iter 73477 Ep: 19.94 loss 0.010 score 1.000 lr 1.28182e-07 
09/18/2020 03:34:12 - INFO - volta.utils -   [GQA]: iter 73497 Ep: 19.95 loss 0.011 score 0.999 lr 1.16118e-07 
09/18/2020 03:35:42 - INFO - volta.utils -   [GQA]: iter 73517 Ep: 19.96 loss 0.012 score 0.999 lr 1.04054e-07 
09/18/2020 03:38:38 - INFO - volta.utils -   [GQA]: iter 73537 Ep: 19.96 loss 0.010 score 1.000 lr 9.19894e-08 
09/18/2020 03:40:21 - INFO - volta.utils -   [GQA]: iter 73557 Ep: 19.97 loss 0.013 score 1.000 lr 7.99252e-08 
09/18/2020 03:41:44 - INFO - volta.utils -   [GQA]: iter 73577 Ep: 19.97 loss 0.012 score 0.999 lr 6.7861e-08 
09/18/2020 03:42:53 - INFO - volta.utils -   [GQA]: iter 73597 Ep: 19.98 loss 0.010 score 0.999 lr 5.57968e-08 
09/18/2020 03:44:52 - INFO - volta.utils -   [GQA]: iter 73617 Ep: 19.98 loss 0.010 score 1.000 lr 4.37327e-08 
09/18/2020 03:46:17 - INFO - volta.utils -   [GQA]: iter 73637 Ep: 19.99 loss 0.013 score 0.999 lr 3.16685e-08 
09/18/2020 03:48:44 - INFO - volta.utils -   [GQA]: iter 73657 Ep: 19.99 loss 0.012 score 0.999 lr 1.96043e-08 
09/18/2020 03:49:50 - INFO - volta.utils -   [GQA]: iter 73677 Ep: 20.00 loss 0.011 score 1.000 lr 7.54011e-09 
09/18/2020 04:06:44 - INFO - volta.utils -   Eval task TASK15 on iteration 73680 
09/18/2020 04:06:44 - INFO - volta.utils -   Validation [GQA]: loss 4.766 score 64.726 
09/18/2020 04:06:44 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch: 100%|██████████| 4/4 [22:21:24<00:00, 20156.09s/it]  
