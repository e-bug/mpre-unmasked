/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
09/15/2020 01:14:05 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
09/15/2020 01:14:06 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/15/2020 01:14:07 - INFO - volta.task_utils -   Loading GQA Dataset with batch size 256
09/15/2020 01:14:07 - INFO - volta.datasets.gqa_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/gqa/cache/GQA_train_26.pkl
09/15/2020 01:18:57 - INFO - volta.datasets.gqa_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/gqa/cache/GQA_val_26.pkl
09/15/2020 01:19:40 - INFO - volta.utils -   logging file at: ../../logs/volta/gqa/GQA_vilbert_base
09/15/2020 01:19:40 - INFO - volta.utils -   loading weights file /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/volta/vilbert/vilbert_base/pytorch_model_9.bin
09/15/2020 01:19:47 - INFO - volta.utils -   
09/15/2020 01:19:47 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK15.logit_fc.0.weight', 'clfs_dict.TASK15.logit_fc.0.bias', 'clfs_dict.TASK15.logit_fc.2.weight', 'clfs_dict.TASK15.logit_fc.2.bias', 'clfs_dict.TASK15.logit_fc.3.weight', 'clfs_dict.TASK15.logit_fc.3.bias']
09/15/2020 01:19:47 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
09/15/2020 01:19:57 - INFO - __main__ -   >> Trainable Parameters:
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(1024, 2048)    |2097152     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(1024, 5)       |5120        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.weight                           |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.bias                             |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                   |torch.float32    |(1024, 1024)    |1048576     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.0.weight                           |torch.float32    |(1536, 1024)    |1572864     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.0.bias                             |torch.float32    |(1536,)         |1536        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.2.weight                           |torch.float32    |(1536,)         |1536        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.2.bias                             |torch.float32    |(1536,)         |1536        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.3.weight                           |torch.float32    |(1842, 1536)    |2829312     |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.3.bias                             |torch.float32    |(1842,)         |1842        |
09/15/2020 01:19:57 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/15/2020 01:19:57 - INFO - __main__ -   >> # TrainableParams:       	240.11	M
09/15/2020 01:19:57 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
09/15/2020 01:19:57 - INFO - __main__ -   >> # TotalParams:           	240.11	M

Epoch:   0%|          | 0/12 [00:00<?, ?it/s]09/15/2020 01:41:09 - INFO - volta.utils -   Eval task TASK15 on iteration 29473 
09/15/2020 01:41:09 - INFO - volta.utils -   Validation [GQA]: loss 2.159 score 64.770 
09/15/2020 01:41:22 - INFO - volta.utils -   [GQA]: iter 29493 Ep: 8.01 loss 0.579 score 0.897 lr 2.66609e-05 
09/15/2020 01:42:35 - INFO - volta.utils -   [GQA]: iter 29513 Ep: 8.01 loss 0.527 score 0.907 lr 2.66477e-05 
09/15/2020 01:43:29 - INFO - volta.utils -   [GQA]: iter 29533 Ep: 8.02 loss 0.533 score 0.903 lr 2.66356e-05 
09/15/2020 01:44:54 - INFO - volta.utils -   [GQA]: iter 29553 Ep: 8.02 loss 0.542 score 0.901 lr 2.66235e-05 
09/15/2020 01:46:37 - INFO - volta.utils -   [GQA]: iter 29573 Ep: 8.03 loss 0.536 score 0.897 lr 2.66115e-05 
09/15/2020 01:47:20 - INFO - volta.utils -   [GQA]: iter 29593 Ep: 8.03 loss 0.510 score 0.912 lr 2.65994e-05 
09/15/2020 01:48:34 - INFO - volta.utils -   [GQA]: iter 29613 Ep: 8.04 loss 0.531 score 0.904 lr 2.65873e-05 
09/15/2020 01:50:12 - INFO - volta.utils -   [GQA]: iter 29633 Ep: 8.04 loss 0.511 score 0.912 lr 2.65753e-05 
09/15/2020 01:51:47 - INFO - volta.utils -   [GQA]: iter 29653 Ep: 8.05 loss 0.523 score 0.903 lr 2.65632e-05 
09/15/2020 01:53:17 - INFO - volta.utils -   [GQA]: iter 29673 Ep: 8.05 loss 0.506 score 0.913 lr 2.65512e-05 
09/15/2020 01:54:13 - INFO - volta.utils -   [GQA]: iter 29693 Ep: 8.06 loss 0.522 score 0.906 lr 2.65391e-05 
09/15/2020 01:55:32 - INFO - volta.utils -   [GQA]: iter 29713 Ep: 8.07 loss 0.558 score 0.898 lr 2.6527e-05 
09/15/2020 01:57:16 - INFO - volta.utils -   [GQA]: iter 29733 Ep: 8.07 loss 0.515 score 0.913 lr 2.6515e-05 
09/15/2020 01:58:38 - INFO - volta.utils -   [GQA]: iter 29753 Ep: 8.08 loss 0.507 score 0.908 lr 2.65029e-05 
09/15/2020 02:00:04 - INFO - volta.utils -   [GQA]: iter 29773 Ep: 8.08 loss 0.535 score 0.902 lr 2.64908e-05 
09/15/2020 02:01:49 - INFO - volta.utils -   [GQA]: iter 29793 Ep: 8.09 loss 0.522 score 0.905 lr 2.64788e-05 
09/15/2020 02:03:43 - INFO - volta.utils -   [GQA]: iter 29813 Ep: 8.09 loss 0.510 score 0.911 lr 2.64667e-05 
09/15/2020 02:05:18 - INFO - volta.utils -   [GQA]: iter 29833 Ep: 8.10 loss 0.531 score 0.904 lr 2.64546e-05 
09/15/2020 02:06:40 - INFO - volta.utils -   [GQA]: iter 29853 Ep: 8.10 loss 0.519 score 0.907 lr 2.64426e-05 
09/15/2020 02:08:17 - INFO - volta.utils -   [GQA]: iter 29873 Ep: 8.11 loss 0.495 score 0.910 lr 2.64305e-05 
09/15/2020 02:09:59 - INFO - volta.utils -   [GQA]: iter 29893 Ep: 8.11 loss 0.529 score 0.907 lr 2.64184e-05 
09/15/2020 02:11:29 - INFO - volta.utils -   [GQA]: iter 29913 Ep: 8.12 loss 0.543 score 0.898 lr 2.64064e-05 
09/15/2020 02:12:37 - INFO - volta.utils -   [GQA]: iter 29933 Ep: 8.13 loss 0.521 score 0.905 lr 2.63943e-05 
09/15/2020 02:14:16 - INFO - volta.utils -   [GQA]: iter 29953 Ep: 8.13 loss 0.536 score 0.904 lr 2.63823e-05 
09/15/2020 02:16:12 - INFO - volta.utils -   [GQA]: iter 29973 Ep: 8.14 loss 0.514 score 0.908 lr 2.63702e-05 
09/15/2020 02:18:28 - INFO - volta.utils -   [GQA]: iter 29993 Ep: 8.14 loss 0.550 score 0.905 lr 2.63581e-05 
09/15/2020 02:19:50 - INFO - volta.utils -   [GQA]: iter 30013 Ep: 8.15 loss 0.508 score 0.906 lr 2.63461e-05 
09/15/2020 02:22:17 - INFO - volta.utils -   [GQA]: iter 30033 Ep: 8.15 loss 0.526 score 0.905 lr 2.6334e-05 
09/15/2020 02:23:23 - INFO - volta.utils -   [GQA]: iter 30053 Ep: 8.16 loss 0.513 score 0.906 lr 2.63219e-05 
09/15/2020 02:24:58 - INFO - volta.utils -   [GQA]: iter 30073 Ep: 8.16 loss 0.530 score 0.906 lr 2.63099e-05 
09/15/2020 02:26:25 - INFO - volta.utils -   [GQA]: iter 30093 Ep: 8.17 loss 0.544 score 0.903 lr 2.62978e-05 
09/15/2020 02:28:51 - INFO - volta.utils -   [GQA]: iter 30113 Ep: 8.17 loss 0.531 score 0.904 lr 2.62857e-05 
09/15/2020 02:29:51 - INFO - volta.utils -   [GQA]: iter 30133 Ep: 8.18 loss 0.528 score 0.903 lr 2.62737e-05 
09/15/2020 02:32:19 - INFO - volta.utils -   [GQA]: iter 30153 Ep: 8.18 loss 0.556 score 0.892 lr 2.62616e-05 
09/15/2020 02:33:43 - INFO - volta.utils -   [GQA]: iter 30173 Ep: 8.19 loss 0.519 score 0.909 lr 2.62495e-05 
09/15/2020 02:35:42 - INFO - volta.utils -   [GQA]: iter 30193 Ep: 8.20 loss 0.529 score 0.904 lr 2.62375e-05 
09/15/2020 02:37:17 - INFO - volta.utils -   [GQA]: iter 30213 Ep: 8.20 loss 0.528 score 0.902 lr 2.62254e-05 
09/15/2020 02:39:13 - INFO - volta.utils -   [GQA]: iter 30233 Ep: 8.21 loss 0.532 score 0.904 lr 2.62134e-05 
09/15/2020 02:40:27 - INFO - volta.utils -   [GQA]: iter 30253 Ep: 8.21 loss 0.519 score 0.903 lr 2.62013e-05 
09/15/2020 02:41:36 - INFO - volta.utils -   [GQA]: iter 30273 Ep: 8.22 loss 0.518 score 0.904 lr 2.61892e-05 
09/15/2020 02:42:55 - INFO - volta.utils -   [GQA]: iter 30293 Ep: 8.22 loss 0.529 score 0.907 lr 2.61772e-05 
09/15/2020 02:44:32 - INFO - volta.utils -   [GQA]: iter 30313 Ep: 8.23 loss 0.553 score 0.900 lr 2.61651e-05 
09/15/2020 02:46:07 - INFO - volta.utils -   [GQA]: iter 30333 Ep: 8.23 loss 0.541 score 0.902 lr 2.6153e-05 
09/15/2020 02:48:17 - INFO - volta.utils -   [GQA]: iter 30353 Ep: 8.24 loss 0.533 score 0.904 lr 2.6141e-05 
09/15/2020 02:49:40 - INFO - volta.utils -   [GQA]: iter 30373 Ep: 8.24 loss 0.535 score 0.902 lr 2.61289e-05 
09/15/2020 02:51:03 - INFO - volta.utils -   [GQA]: iter 30393 Ep: 8.25 loss 0.544 score 0.898 lr 2.61168e-05 
09/15/2020 02:52:35 - INFO - volta.utils -   [GQA]: iter 30413 Ep: 8.26 loss 0.517 score 0.907 lr 2.61048e-05 
09/15/2020 02:54:35 - INFO - volta.utils -   [GQA]: iter 30433 Ep: 8.26 loss 0.545 score 0.902 lr 2.60927e-05 
09/15/2020 02:56:01 - INFO - volta.utils -   [GQA]: iter 30453 Ep: 8.27 loss 0.548 score 0.900 lr 2.60806e-05 
09/15/2020 02:58:15 - INFO - volta.utils -   [GQA]: iter 30473 Ep: 8.27 loss 0.521 score 0.903 lr 2.60686e-05 
09/15/2020 03:00:07 - INFO - volta.utils -   [GQA]: iter 30493 Ep: 8.28 loss 0.528 score 0.900 lr 2.60565e-05 
09/15/2020 03:01:38 - INFO - volta.utils -   [GQA]: iter 30513 Ep: 8.28 loss 0.554 score 0.892 lr 2.60445e-05 
09/15/2020 03:02:46 - INFO - volta.utils -   [GQA]: iter 30533 Ep: 8.29 loss 0.527 score 0.900 lr 2.60324e-05 
09/15/2020 03:05:03 - INFO - volta.utils -   [GQA]: iter 30553 Ep: 8.29 loss 0.548 score 0.898 lr 2.60203e-05 
09/15/2020 03:07:08 - INFO - volta.utils -   [GQA]: iter 30573 Ep: 8.30 loss 0.540 score 0.904 lr 2.60083e-05 
09/15/2020 03:08:39 - INFO - volta.utils -   [GQA]: iter 30593 Ep: 8.30 loss 0.530 score 0.904 lr 2.59962e-05 
09/15/2020 03:10:15 - INFO - volta.utils -   [GQA]: iter 30613 Ep: 8.31 loss 0.557 score 0.899 lr 2.59841e-05 
09/15/2020 03:12:03 - INFO - volta.utils -   [GQA]: iter 30633 Ep: 8.32 loss 0.525 score 0.906 lr 2.59721e-05 
09/15/2020 03:13:54 - INFO - volta.utils -   [GQA]: iter 30653 Ep: 8.32 loss 0.524 score 0.908 lr 2.596e-05 
09/15/2020 03:15:10 - INFO - volta.utils -   [GQA]: iter 30673 Ep: 8.33 loss 0.510 score 0.907 lr 2.59479e-05 
09/15/2020 03:16:59 - INFO - volta.utils -   [GQA]: iter 30693 Ep: 8.33 loss 0.552 score 0.899 lr 2.59359e-05 
09/15/2020 03:18:39 - INFO - volta.utils -   [GQA]: iter 30713 Ep: 8.34 loss 0.538 score 0.904 lr 2.59238e-05 
09/15/2020 03:20:19 - INFO - volta.utils -   [GQA]: iter 30733 Ep: 8.34 loss 0.542 score 0.901 lr 2.59118e-05 
09/15/2020 03:21:37 - INFO - volta.utils -   [GQA]: iter 30753 Ep: 8.35 loss 0.536 score 0.903 lr 2.58997e-05 
09/15/2020 03:22:53 - INFO - volta.utils -   [GQA]: iter 30773 Ep: 8.35 loss 0.534 score 0.905 lr 2.58876e-05 
09/15/2020 03:24:54 - INFO - volta.utils -   [GQA]: iter 30793 Ep: 8.36 loss 0.549 score 0.902 lr 2.58756e-05 
09/15/2020 03:26:34 - INFO - volta.utils -   [GQA]: iter 30813 Ep: 8.36 loss 0.550 score 0.901 lr 2.58635e-05 
09/15/2020 03:27:55 - INFO - volta.utils -   [GQA]: iter 30833 Ep: 8.37 loss 0.519 score 0.908 lr 2.58514e-05 
09/15/2020 03:29:09 - INFO - volta.utils -   [GQA]: iter 30853 Ep: 8.37 loss 0.524 score 0.903 lr 2.58394e-05 
09/15/2020 03:32:14 - INFO - volta.utils -   [GQA]: iter 30873 Ep: 8.38 loss 0.524 score 0.904 lr 2.58273e-05 
09/15/2020 03:33:44 - INFO - volta.utils -   [GQA]: iter 30893 Ep: 8.39 loss 0.543 score 0.897 lr 2.58152e-05 
09/15/2020 03:35:09 - INFO - volta.utils -   [GQA]: iter 30913 Ep: 8.39 loss 0.536 score 0.903 lr 2.58032e-05 
09/15/2020 03:36:40 - INFO - volta.utils -   [GQA]: iter 30933 Ep: 8.40 loss 0.564 score 0.893 lr 2.57911e-05 
09/15/2020 03:38:49 - INFO - volta.utils -   [GQA]: iter 30953 Ep: 8.40 loss 0.547 score 0.899 lr 2.5779e-05 
09/15/2020 03:40:30 - INFO - volta.utils -   [GQA]: iter 30973 Ep: 8.41 loss 0.547 score 0.900 lr 2.5767e-05 
09/15/2020 03:42:00 - INFO - volta.utils -   [GQA]: iter 30993 Ep: 8.41 loss 0.520 score 0.905 lr 2.57549e-05 
09/15/2020 03:43:39 - INFO - volta.utils -   [GQA]: iter 31013 Ep: 8.42 loss 0.527 score 0.905 lr 2.57429e-05 
09/15/2020 03:46:12 - INFO - volta.utils -   [GQA]: iter 31033 Ep: 8.42 loss 0.520 score 0.904 lr 2.57308e-05 
09/15/2020 03:47:33 - INFO - volta.utils -   [GQA]: iter 31053 Ep: 8.43 loss 0.570 score 0.893 lr 2.57187e-05 
09/15/2020 03:48:56 - INFO - volta.utils -   [GQA]: iter 31073 Ep: 8.43 loss 0.537 score 0.904 lr 2.57067e-05 
09/15/2020 03:50:13 - INFO - volta.utils -   [GQA]: iter 31093 Ep: 8.44 loss 0.518 score 0.907 lr 2.56946e-05 
09/15/2020 03:52:39 - INFO - volta.utils -   [GQA]: iter 31113 Ep: 8.45 loss 0.540 score 0.897 lr 2.56825e-05 
09/15/2020 03:54:28 - INFO - volta.utils -   [GQA]: iter 31133 Ep: 8.45 loss 0.544 score 0.899 lr 2.56705e-05 
09/15/2020 03:55:52 - INFO - volta.utils -   [GQA]: iter 31153 Ep: 8.46 loss 0.558 score 0.896 lr 2.56584e-05 
09/15/2020 03:57:21 - INFO - volta.utils -   [GQA]: iter 31173 Ep: 8.46 loss 0.566 score 0.896 lr 2.56463e-05 
09/15/2020 03:59:24 - INFO - volta.utils -   [GQA]: iter 31193 Ep: 8.47 loss 0.559 score 0.900 lr 2.56343e-05 
09/15/2020 04:01:01 - INFO - volta.utils -   [GQA]: iter 31213 Ep: 8.47 loss 0.536 score 0.903 lr 2.56222e-05 
09/15/2020 04:02:28 - INFO - volta.utils -   [GQA]: iter 31233 Ep: 8.48 loss 0.544 score 0.904 lr 2.56101e-05 
09/15/2020 04:04:04 - INFO - volta.utils -   [GQA]: iter 31253 Ep: 8.48 loss 0.568 score 0.897 lr 2.55981e-05 
09/15/2020 04:06:46 - INFO - volta.utils -   [GQA]: iter 31273 Ep: 8.49 loss 0.550 score 0.896 lr 2.5586e-05 
09/15/2020 04:08:21 - INFO - volta.utils -   [GQA]: iter 31293 Ep: 8.49 loss 0.553 score 0.897 lr 2.5574e-05 
09/15/2020 04:09:15 - INFO - volta.utils -   [GQA]: iter 31313 Ep: 8.50 loss 0.545 score 0.898 lr 2.55619e-05 
09/15/2020 04:10:37 - INFO - volta.utils -   [GQA]: iter 31333 Ep: 8.51 loss 0.559 score 0.897 lr 2.55498e-05 
09/15/2020 04:12:39 - INFO - volta.utils -   [GQA]: iter 31353 Ep: 8.51 loss 0.558 score 0.899 lr 2.55378e-05 
09/15/2020 04:13:57 - INFO - volta.utils -   [GQA]: iter 31373 Ep: 8.52 loss 0.571 score 0.895 lr 2.55257e-05 
09/15/2020 04:15:35 - INFO - volta.utils -   [GQA]: iter 31393 Ep: 8.52 loss 0.529 score 0.905 lr 2.55136e-05 
09/15/2020 04:16:48 - INFO - volta.utils -   [GQA]: iter 31413 Ep: 8.53 loss 0.543 score 0.902 lr 2.55016e-05 
09/15/2020 04:19:05 - INFO - volta.utils -   [GQA]: iter 31433 Ep: 8.53 loss 0.564 score 0.896 lr 2.54895e-05 
09/15/2020 04:20:03 - INFO - volta.utils -   [GQA]: iter 31453 Ep: 8.54 loss 0.531 score 0.903 lr 2.54774e-05 
09/15/2020 04:21:32 - INFO - volta.utils -   [GQA]: iter 31473 Ep: 8.54 loss 0.552 score 0.903 lr 2.54654e-05 
09/15/2020 04:22:53 - INFO - volta.utils -   [GQA]: iter 31493 Ep: 8.55 loss 0.532 score 0.897 lr 2.54533e-05 
09/15/2020 04:24:29 - INFO - volta.utils -   [GQA]: iter 31513 Ep: 8.55 loss 0.554 score 0.900 lr 2.54412e-05 
09/15/2020 04:26:39 - INFO - volta.utils -   [GQA]: iter 31533 Ep: 8.56 loss 0.545 score 0.896 lr 2.54292e-05 
09/15/2020 04:28:11 - INFO - volta.utils -   [GQA]: iter 31553 Ep: 8.56 loss 0.503 score 0.909 lr 2.54171e-05 
09/15/2020 04:29:42 - INFO - volta.utils -   [GQA]: iter 31573 Ep: 8.57 loss 0.540 score 0.901 lr 2.54051e-05 
09/15/2020 04:31:40 - INFO - volta.utils -   [GQA]: iter 31593 Ep: 8.58 loss 0.557 score 0.896 lr 2.5393e-05 
09/15/2020 04:34:15 - INFO - volta.utils -   [GQA]: iter 31613 Ep: 8.58 loss 0.547 score 0.900 lr 2.53809e-05 
09/15/2020 04:36:01 - INFO - volta.utils -   [GQA]: iter 31633 Ep: 8.59 loss 0.526 score 0.907 lr 2.53689e-05 
09/15/2020 04:37:35 - INFO - volta.utils -   [GQA]: iter 31653 Ep: 8.59 loss 0.535 score 0.903 lr 2.53568e-05 
09/15/2020 04:38:57 - INFO - volta.utils -   [GQA]: iter 31673 Ep: 8.60 loss 0.549 score 0.900 lr 2.53447e-05 
09/15/2020 04:40:41 - INFO - volta.utils -   [GQA]: iter 31693 Ep: 8.60 loss 0.545 score 0.898 lr 2.53327e-05 
09/15/2020 04:42:59 - INFO - volta.utils -   [GQA]: iter 31713 Ep: 8.61 loss 0.551 score 0.900 lr 2.53206e-05 
09/15/2020 04:44:24 - INFO - volta.utils -   [GQA]: iter 31733 Ep: 8.61 loss 0.551 score 0.898 lr 2.53085e-05 
09/15/2020 04:45:58 - INFO - volta.utils -   [GQA]: iter 31753 Ep: 8.62 loss 0.532 score 0.900 lr 2.52965e-05 
09/15/2020 04:47:44 - INFO - volta.utils -   [GQA]: iter 31773 Ep: 8.62 loss 0.543 score 0.896 lr 2.52844e-05 
09/15/2020 04:50:06 - INFO - volta.utils -   [GQA]: iter 31793 Ep: 8.63 loss 0.590 score 0.889 lr 2.52723e-05 
09/15/2020 04:51:13 - INFO - volta.utils -   [GQA]: iter 31813 Ep: 8.64 loss 0.539 score 0.898 lr 2.52603e-05 
09/15/2020 04:52:41 - INFO - volta.utils -   [GQA]: iter 31833 Ep: 8.64 loss 0.541 score 0.899 lr 2.52482e-05 
09/15/2020 04:54:21 - INFO - volta.utils -   [GQA]: iter 31853 Ep: 8.65 loss 0.528 score 0.907 lr 2.52362e-05 
09/15/2020 04:56:00 - INFO - volta.utils -   [GQA]: iter 31873 Ep: 8.65 loss 0.569 score 0.897 lr 2.52241e-05 
09/15/2020 04:57:21 - INFO - volta.utils -   [GQA]: iter 31893 Ep: 8.66 loss 0.558 score 0.900 lr 2.5212e-05 
09/15/2020 04:58:30 - INFO - volta.utils -   [GQA]: iter 31913 Ep: 8.66 loss 0.549 score 0.899 lr 2.52e-05 
09/15/2020 05:00:37 - INFO - volta.utils -   [GQA]: iter 31933 Ep: 8.67 loss 0.551 score 0.899 lr 2.51879e-05 
09/15/2020 05:02:21 - INFO - volta.utils -   [GQA]: iter 31953 Ep: 8.67 loss 0.549 score 0.898 lr 2.51758e-05 
09/15/2020 05:03:37 - INFO - volta.utils -   [GQA]: iter 31973 Ep: 8.68 loss 0.556 score 0.898 lr 2.51638e-05 
09/15/2020 05:04:41 - INFO - volta.utils -   [GQA]: iter 31993 Ep: 8.68 loss 0.557 score 0.900 lr 2.51517e-05 
09/15/2020 05:06:35 - INFO - volta.utils -   [GQA]: iter 32013 Ep: 8.69 loss 0.561 score 0.897 lr 2.51396e-05 
09/15/2020 05:08:08 - INFO - volta.utils -   [GQA]: iter 32033 Ep: 8.70 loss 0.564 score 0.898 lr 2.51276e-05 
09/15/2020 05:09:41 - INFO - volta.utils -   [GQA]: iter 32053 Ep: 8.70 loss 0.525 score 0.902 lr 2.51155e-05 
09/15/2020 05:11:14 - INFO - volta.utils -   [GQA]: iter 32073 Ep: 8.71 loss 0.547 score 0.898 lr 2.51035e-05 
09/15/2020 05:13:10 - INFO - volta.utils -   [GQA]: iter 32093 Ep: 8.71 loss 0.515 score 0.905 lr 2.50914e-05 
09/15/2020 05:14:51 - INFO - volta.utils -   [GQA]: iter 32113 Ep: 8.72 loss 0.565 score 0.896 lr 2.50793e-05 
09/15/2020 05:16:15 - INFO - volta.utils -   [GQA]: iter 32133 Ep: 8.72 loss 0.565 score 0.895 lr 2.50673e-05 
09/15/2020 05:18:00 - INFO - volta.utils -   [GQA]: iter 32153 Ep: 8.73 loss 0.511 score 0.907 lr 2.50552e-05 
09/15/2020 05:19:57 - INFO - volta.utils -   [GQA]: iter 32173 Ep: 8.73 loss 0.541 score 0.902 lr 2.50431e-05 
09/15/2020 05:21:31 - INFO - volta.utils -   [GQA]: iter 32193 Ep: 8.74 loss 0.530 score 0.907 lr 2.50311e-05 
09/15/2020 05:23:08 - INFO - volta.utils -   [GQA]: iter 32213 Ep: 8.74 loss 0.540 score 0.900 lr 2.5019e-05 
09/15/2020 05:25:50 - INFO - volta.utils -   [GQA]: iter 32233 Ep: 8.75 loss 0.541 score 0.895 lr 2.50069e-05 
09/15/2020 05:27:01 - INFO - volta.utils -   [GQA]: iter 32253 Ep: 8.75 loss 0.541 score 0.903 lr 2.49949e-05 
09/15/2020 05:28:17 - INFO - volta.utils -   [GQA]: iter 32273 Ep: 8.76 loss 0.558 score 0.896 lr 2.49828e-05 
09/15/2020 05:29:55 - INFO - volta.utils -   [GQA]: iter 32293 Ep: 8.77 loss 0.542 score 0.899 lr 2.49707e-05 
09/15/2020 05:31:41 - INFO - volta.utils -   [GQA]: iter 32313 Ep: 8.77 loss 0.553 score 0.896 lr 2.49587e-05 
09/15/2020 05:33:10 - INFO - volta.utils -   [GQA]: iter 32333 Ep: 8.78 loss 0.552 score 0.896 lr 2.49466e-05 
09/15/2020 05:34:26 - INFO - volta.utils -   [GQA]: iter 32353 Ep: 8.78 loss 0.544 score 0.896 lr 2.49346e-05 
09/15/2020 05:36:22 - INFO - volta.utils -   [GQA]: iter 32373 Ep: 8.79 loss 0.548 score 0.898 lr 2.49225e-05 
09/15/2020 05:38:03 - INFO - volta.utils -   [GQA]: iter 32393 Ep: 8.79 loss 0.515 score 0.910 lr 2.49104e-05 
09/15/2020 05:39:42 - INFO - volta.utils -   [GQA]: iter 32413 Ep: 8.80 loss 0.568 score 0.896 lr 2.48984e-05 
09/15/2020 05:41:13 - INFO - volta.utils -   [GQA]: iter 32433 Ep: 8.80 loss 0.556 score 0.892 lr 2.48863e-05 
09/15/2020 05:43:29 - INFO - volta.utils -   [GQA]: iter 32453 Ep: 8.81 loss 0.545 score 0.897 lr 2.48742e-05 
09/15/2020 05:44:50 - INFO - volta.utils -   [GQA]: iter 32473 Ep: 8.81 loss 0.534 score 0.899 lr 2.48622e-05 
09/15/2020 05:46:48 - INFO - volta.utils -   [GQA]: iter 32493 Ep: 8.82 loss 0.538 score 0.899 lr 2.48501e-05 
09/15/2020 05:48:20 - INFO - volta.utils -   [GQA]: iter 32513 Ep: 8.83 loss 0.536 score 0.903 lr 2.4838e-05 
09/15/2020 05:50:10 - INFO - volta.utils -   [GQA]: iter 32533 Ep: 8.83 loss 0.537 score 0.901 lr 2.4826e-05 
09/15/2020 05:51:58 - INFO - volta.utils -   [GQA]: iter 32553 Ep: 8.84 loss 0.530 score 0.900 lr 2.48139e-05 
09/15/2020 05:53:51 - INFO - volta.utils -   [GQA]: iter 32573 Ep: 8.84 loss 0.518 score 0.907 lr 2.48018e-05 
09/15/2020 05:55:06 - INFO - volta.utils -   [GQA]: iter 32593 Ep: 8.85 loss 0.556 score 0.898 lr 2.47898e-05 
09/15/2020 05:56:34 - INFO - volta.utils -   [GQA]: iter 32613 Ep: 8.85 loss 0.575 score 0.894 lr 2.47777e-05 
09/15/2020 05:57:31 - INFO - volta.utils -   [GQA]: iter 32633 Ep: 8.86 loss 0.546 score 0.897 lr 2.47657e-05 
09/15/2020 05:59:44 - INFO - volta.utils -   [GQA]: iter 32653 Ep: 8.86 loss 0.575 score 0.892 lr 2.47536e-05 
09/15/2020 06:01:23 - INFO - volta.utils -   [GQA]: iter 32673 Ep: 8.87 loss 0.555 score 0.895 lr 2.47415e-05 
09/15/2020 06:03:21 - INFO - volta.utils -   [GQA]: iter 32693 Ep: 8.87 loss 0.560 score 0.894 lr 2.47295e-05 
09/15/2020 06:04:41 - INFO - volta.utils -   [GQA]: iter 32713 Ep: 8.88 loss 0.582 score 0.895 lr 2.47174e-05 
09/15/2020 06:07:04 - INFO - volta.utils -   [GQA]: iter 32733 Ep: 8.89 loss 0.574 score 0.893 lr 2.47053e-05 
09/15/2020 06:08:48 - INFO - volta.utils -   [GQA]: iter 32753 Ep: 8.89 loss 0.535 score 0.898 lr 2.46933e-05 
09/15/2020 06:10:21 - INFO - volta.utils -   [GQA]: iter 32773 Ep: 8.90 loss 0.542 score 0.901 lr 2.46812e-05 
09/15/2020 06:11:57 - INFO - volta.utils -   [GQA]: iter 32793 Ep: 8.90 loss 0.573 score 0.891 lr 2.46691e-05 
09/15/2020 06:13:55 - INFO - volta.utils -   [GQA]: iter 32813 Ep: 8.91 loss 0.525 score 0.902 lr 2.46571e-05 
09/15/2020 06:15:33 - INFO - volta.utils -   [GQA]: iter 32833 Ep: 8.91 loss 0.562 score 0.901 lr 2.4645e-05 
09/15/2020 06:17:03 - INFO - volta.utils -   [GQA]: iter 32853 Ep: 8.92 loss 0.530 score 0.904 lr 2.46329e-05 
09/15/2020 06:18:52 - INFO - volta.utils -   [GQA]: iter 32873 Ep: 8.92 loss 0.543 score 0.903 lr 2.46209e-05 
09/15/2020 06:21:24 - INFO - volta.utils -   [GQA]: iter 32893 Ep: 8.93 loss 0.562 score 0.896 lr 2.46088e-05 
09/15/2020 06:23:03 - INFO - volta.utils -   [GQA]: iter 32913 Ep: 8.93 loss 0.540 score 0.900 lr 2.45968e-05 
09/15/2020 06:24:10 - INFO - volta.utils -   [GQA]: iter 32933 Ep: 8.94 loss 0.543 score 0.904 lr 2.45847e-05 
09/15/2020 06:25:30 - INFO - volta.utils -   [GQA]: iter 32953 Ep: 8.94 loss 0.546 score 0.897 lr 2.45726e-05 
09/15/2020 06:27:36 - INFO - volta.utils -   [GQA]: iter 32973 Ep: 8.95 loss 0.545 score 0.899 lr 2.45606e-05 
09/15/2020 06:29:04 - INFO - volta.utils -   [GQA]: iter 32993 Ep: 8.96 loss 0.516 score 0.908 lr 2.45485e-05 
09/15/2020 06:30:31 - INFO - volta.utils -   [GQA]: iter 33013 Ep: 8.96 loss 0.567 score 0.892 lr 2.45364e-05 
09/15/2020 06:31:57 - INFO - volta.utils -   [GQA]: iter 33033 Ep: 8.97 loss 0.550 score 0.898 lr 2.45244e-05 
09/15/2020 06:34:17 - INFO - volta.utils -   [GQA]: iter 33053 Ep: 8.97 loss 0.546 score 0.903 lr 2.45123e-05 
09/15/2020 06:35:52 - INFO - volta.utils -   [GQA]: iter 33073 Ep: 8.98 loss 0.560 score 0.900 lr 2.45002e-05 
09/15/2020 06:37:33 - INFO - volta.utils -   [GQA]: iter 33093 Ep: 8.98 loss 0.547 score 0.891 lr 2.44882e-05 
09/15/2020 06:39:05 - INFO - volta.utils -   [GQA]: iter 33113 Ep: 8.99 loss 0.517 score 0.903 lr 2.44761e-05 
09/15/2020 06:40:51 - INFO - volta.utils -   [GQA]: iter 33133 Ep: 8.99 loss 0.526 score 0.906 lr 2.4464e-05 
09/15/2020 06:42:08 - INFO - volta.utils -   [GQA]: iter 33153 Ep: 9.00 loss 0.520 score 0.907 lr 2.4452e-05 
09/15/2020 06:42:10 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:   8%|         | 1/12 [5:22:24<59:06:26, 19344.27s/it]09/15/2020 07:01:49 - INFO - volta.utils -   Eval task TASK15 on iteration 33157 
09/15/2020 07:01:49 - INFO - volta.utils -   Validation [GQA]: loss 2.542 score 64.711 
09/15/2020 07:02:01 - INFO - volta.utils -   [GQA]: iter 33177 Ep: 9.01 loss 0.412 score 0.927 lr 2.44387e-05 
09/15/2020 07:03:30 - INFO - volta.utils -   [GQA]: iter 33197 Ep: 9.01 loss 0.384 score 0.937 lr 2.44254e-05 
09/15/2020 07:04:44 - INFO - volta.utils -   [GQA]: iter 33217 Ep: 9.02 loss 0.408 score 0.934 lr 2.44134e-05 
09/15/2020 07:06:02 - INFO - volta.utils -   [GQA]: iter 33237 Ep: 9.02 loss 0.391 score 0.931 lr 2.44013e-05 
09/15/2020 07:07:51 - INFO - volta.utils -   [GQA]: iter 33257 Ep: 9.03 loss 0.391 score 0.931 lr 2.43893e-05 
09/15/2020 07:08:38 - INFO - volta.utils -   [GQA]: iter 33277 Ep: 9.03 loss 0.383 score 0.936 lr 2.43772e-05 
09/15/2020 07:10:02 - INFO - volta.utils -   [GQA]: iter 33297 Ep: 9.04 loss 0.384 score 0.933 lr 2.43651e-05 
09/15/2020 07:11:19 - INFO - volta.utils -   [GQA]: iter 33317 Ep: 9.04 loss 0.380 score 0.938 lr 2.43531e-05 
09/15/2020 07:12:54 - INFO - volta.utils -   [GQA]: iter 33337 Ep: 9.05 loss 0.380 score 0.932 lr 2.4341e-05 
09/15/2020 07:14:23 - INFO - volta.utils -   [GQA]: iter 33357 Ep: 9.05 loss 0.388 score 0.933 lr 2.43289e-05 
09/15/2020 07:16:08 - INFO - volta.utils -   [GQA]: iter 33377 Ep: 9.06 loss 0.394 score 0.934 lr 2.43169e-05 
09/15/2020 07:17:43 - INFO - volta.utils -   [GQA]: iter 33397 Ep: 9.07 loss 0.407 score 0.931 lr 2.43048e-05 
09/15/2020 07:19:36 - INFO - volta.utils -   [GQA]: iter 33417 Ep: 9.07 loss 0.383 score 0.935 lr 2.42927e-05 
09/15/2020 07:21:00 - INFO - volta.utils -   [GQA]: iter 33437 Ep: 9.08 loss 0.427 score 0.925 lr 2.42807e-05 
09/15/2020 07:23:03 - INFO - volta.utils -   [GQA]: iter 33457 Ep: 9.08 loss 0.398 score 0.932 lr 2.42686e-05 
09/15/2020 07:24:44 - INFO - volta.utils -   [GQA]: iter 33477 Ep: 9.09 loss 0.411 score 0.928 lr 2.42565e-05 
09/15/2020 07:26:12 - INFO - volta.utils -   [GQA]: iter 33497 Ep: 9.09 loss 0.404 score 0.932 lr 2.42445e-05 
09/15/2020 07:28:09 - INFO - volta.utils -   [GQA]: iter 33517 Ep: 9.10 loss 0.376 score 0.938 lr 2.42324e-05 
09/15/2020 07:30:22 - INFO - volta.utils -   [GQA]: iter 33537 Ep: 9.10 loss 0.401 score 0.934 lr 2.42204e-05 
09/15/2020 07:31:25 - INFO - volta.utils -   [GQA]: iter 33557 Ep: 9.11 loss 0.403 score 0.929 lr 2.42083e-05 
09/15/2020 07:33:08 - INFO - volta.utils -   [GQA]: iter 33577 Ep: 9.11 loss 0.382 score 0.936 lr 2.41962e-05 
09/15/2020 07:34:19 - INFO - volta.utils -   [GQA]: iter 33597 Ep: 9.12 loss 0.385 score 0.931 lr 2.41842e-05 
09/15/2020 07:36:41 - INFO - volta.utils -   [GQA]: iter 33617 Ep: 9.13 loss 0.392 score 0.934 lr 2.41721e-05 
09/15/2020 07:38:31 - INFO - volta.utils -   [GQA]: iter 33637 Ep: 9.13 loss 0.419 score 0.931 lr 2.416e-05 
09/15/2020 07:40:06 - INFO - volta.utils -   [GQA]: iter 33657 Ep: 9.14 loss 0.418 score 0.926 lr 2.4148e-05 
09/15/2020 07:42:07 - INFO - volta.utils -   [GQA]: iter 33677 Ep: 9.14 loss 0.385 score 0.932 lr 2.41359e-05 
09/15/2020 07:44:45 - INFO - volta.utils -   [GQA]: iter 33697 Ep: 9.15 loss 0.416 score 0.926 lr 2.41238e-05 
09/15/2020 07:46:18 - INFO - volta.utils -   [GQA]: iter 33717 Ep: 9.15 loss 0.426 score 0.925 lr 2.41118e-05 
09/15/2020 07:47:50 - INFO - volta.utils -   [GQA]: iter 33737 Ep: 9.16 loss 0.402 score 0.929 lr 2.40997e-05 
09/15/2020 07:49:26 - INFO - volta.utils -   [GQA]: iter 33757 Ep: 9.16 loss 0.401 score 0.931 lr 2.40876e-05 
09/15/2020 07:52:18 - INFO - volta.utils -   [GQA]: iter 33777 Ep: 9.17 loss 0.401 score 0.931 lr 2.40756e-05 
09/15/2020 07:53:29 - INFO - volta.utils -   [GQA]: iter 33797 Ep: 9.17 loss 0.396 score 0.932 lr 2.40635e-05 
09/15/2020 07:54:42 - INFO - volta.utils -   [GQA]: iter 33817 Ep: 9.18 loss 0.427 score 0.929 lr 2.40515e-05 
09/15/2020 07:56:15 - INFO - volta.utils -   [GQA]: iter 33837 Ep: 9.18 loss 0.395 score 0.932 lr 2.40394e-05 
09/15/2020 07:59:09 - INFO - volta.utils -   [GQA]: iter 33857 Ep: 9.19 loss 0.395 score 0.935 lr 2.40273e-05 
09/15/2020 08:00:35 - INFO - volta.utils -   [GQA]: iter 33877 Ep: 9.20 loss 0.403 score 0.932 lr 2.40153e-05 
09/15/2020 08:02:03 - INFO - volta.utils -   [GQA]: iter 33897 Ep: 9.20 loss 0.416 score 0.928 lr 2.40032e-05 
09/15/2020 08:03:10 - INFO - volta.utils -   [GQA]: iter 33917 Ep: 9.21 loss 0.390 score 0.932 lr 2.39911e-05 
09/15/2020 08:06:09 - INFO - volta.utils -   [GQA]: iter 33937 Ep: 9.21 loss 0.397 score 0.933 lr 2.39791e-05 
09/15/2020 08:08:02 - INFO - volta.utils -   [GQA]: iter 33957 Ep: 9.22 loss 0.399 score 0.926 lr 2.3967e-05 
09/15/2020 08:09:26 - INFO - volta.utils -   [GQA]: iter 33977 Ep: 9.22 loss 0.390 score 0.933 lr 2.39549e-05 
09/15/2020 08:10:38 - INFO - volta.utils -   [GQA]: iter 33997 Ep: 9.23 loss 0.413 score 0.930 lr 2.39429e-05 
09/15/2020 08:13:07 - INFO - volta.utils -   [GQA]: iter 34017 Ep: 9.23 loss 0.398 score 0.931 lr 2.39308e-05 
09/15/2020 08:13:55 - INFO - volta.utils -   [GQA]: iter 34037 Ep: 9.24 loss 0.410 score 0.931 lr 2.39187e-05 
09/15/2020 08:15:43 - INFO - volta.utils -   [GQA]: iter 34057 Ep: 9.24 loss 0.439 score 0.921 lr 2.39067e-05 
09/15/2020 08:17:08 - INFO - volta.utils -   [GQA]: iter 34077 Ep: 9.25 loss 0.390 score 0.929 lr 2.38946e-05 
09/15/2020 08:19:42 - INFO - volta.utils -   [GQA]: iter 34097 Ep: 9.26 loss 0.428 score 0.925 lr 2.38826e-05 
09/15/2020 08:21:17 - INFO - volta.utils -   [GQA]: iter 34117 Ep: 9.26 loss 0.414 score 0.928 lr 2.38705e-05 
09/15/2020 08:23:01 - INFO - volta.utils -   [GQA]: iter 34137 Ep: 9.27 loss 0.413 score 0.929 lr 2.38584e-05 
09/15/2020 08:24:33 - INFO - volta.utils -   [GQA]: iter 34157 Ep: 9.27 loss 0.426 score 0.924 lr 2.38464e-05 
09/15/2020 08:26:50 - INFO - volta.utils -   [GQA]: iter 34177 Ep: 9.28 loss 0.396 score 0.933 lr 2.38343e-05 
09/15/2020 08:28:19 - INFO - volta.utils -   [GQA]: iter 34197 Ep: 9.28 loss 0.397 score 0.928 lr 2.38222e-05 
09/15/2020 08:29:27 - INFO - volta.utils -   [GQA]: iter 34217 Ep: 9.29 loss 0.398 score 0.931 lr 2.38102e-05 
09/15/2020 08:31:05 - INFO - volta.utils -   [GQA]: iter 34237 Ep: 9.29 loss 0.409 score 0.929 lr 2.37981e-05 
09/15/2020 08:33:06 - INFO - volta.utils -   [GQA]: iter 34257 Ep: 9.30 loss 0.406 score 0.929 lr 2.3786e-05 
09/15/2020 08:35:02 - INFO - volta.utils -   [GQA]: iter 34277 Ep: 9.30 loss 0.444 score 0.924 lr 2.3774e-05 
09/15/2020 08:36:30 - INFO - volta.utils -   [GQA]: iter 34297 Ep: 9.31 loss 0.408 score 0.930 lr 2.37619e-05 
09/15/2020 08:38:02 - INFO - volta.utils -   [GQA]: iter 34317 Ep: 9.32 loss 0.403 score 0.929 lr 2.37498e-05 
09/15/2020 08:39:23 - INFO - volta.utils -   [GQA]: iter 34337 Ep: 9.32 loss 0.416 score 0.923 lr 2.37378e-05 
09/15/2020 08:41:11 - INFO - volta.utils -   [GQA]: iter 34357 Ep: 9.33 loss 0.419 score 0.924 lr 2.37257e-05 
09/15/2020 08:42:16 - INFO - volta.utils -   [GQA]: iter 34377 Ep: 9.33 loss 0.439 score 0.920 lr 2.37137e-05 
09/15/2020 08:44:27 - INFO - volta.utils -   [GQA]: iter 34397 Ep: 9.34 loss 0.370 score 0.936 lr 2.37016e-05 
09/15/2020 08:46:17 - INFO - volta.utils -   [GQA]: iter 34417 Ep: 9.34 loss 0.387 score 0.933 lr 2.36895e-05 
09/15/2020 08:47:39 - INFO - volta.utils -   [GQA]: iter 34437 Ep: 9.35 loss 0.408 score 0.926 lr 2.36775e-05 
09/15/2020 08:49:25 - INFO - volta.utils -   [GQA]: iter 34457 Ep: 9.35 loss 0.418 score 0.926 lr 2.36654e-05 
09/15/2020 08:51:42 - INFO - volta.utils -   [GQA]: iter 34477 Ep: 9.36 loss 0.420 score 0.924 lr 2.36533e-05 
09/15/2020 08:53:07 - INFO - volta.utils -   [GQA]: iter 34497 Ep: 9.36 loss 0.413 score 0.924 lr 2.36413e-05 
09/15/2020 08:54:41 - INFO - volta.utils -   [GQA]: iter 34517 Ep: 9.37 loss 0.403 score 0.930 lr 2.36292e-05 
09/15/2020 08:56:07 - INFO - volta.utils -   [GQA]: iter 34537 Ep: 9.37 loss 0.407 score 0.931 lr 2.36171e-05 
09/15/2020 08:58:13 - INFO - volta.utils -   [GQA]: iter 34557 Ep: 9.38 loss 0.417 score 0.927 lr 2.36051e-05 
09/15/2020 08:59:43 - INFO - volta.utils -   [GQA]: iter 34577 Ep: 9.39 loss 0.388 score 0.934 lr 2.3593e-05 
09/15/2020 09:01:54 - INFO - volta.utils -   [GQA]: iter 34597 Ep: 9.39 loss 0.403 score 0.927 lr 2.3581e-05 
09/15/2020 09:03:22 - INFO - volta.utils -   [GQA]: iter 34617 Ep: 9.40 loss 0.426 score 0.920 lr 2.35689e-05 
09/15/2020 09:06:09 - INFO - volta.utils -   [GQA]: iter 34637 Ep: 9.40 loss 0.408 score 0.930 lr 2.35568e-05 
09/15/2020 09:07:45 - INFO - volta.utils -   [GQA]: iter 34657 Ep: 9.41 loss 0.392 score 0.933 lr 2.35448e-05 
09/15/2020 09:09:21 - INFO - volta.utils -   [GQA]: iter 34677 Ep: 9.41 loss 0.375 score 0.938 lr 2.35327e-05 
09/15/2020 09:10:29 - INFO - volta.utils -   [GQA]: iter 34697 Ep: 9.42 loss 0.419 score 0.929 lr 2.35206e-05 
09/15/2020 09:12:43 - INFO - volta.utils -   [GQA]: iter 34717 Ep: 9.42 loss 0.416 score 0.929 lr 2.35086e-05 
09/15/2020 09:14:17 - INFO - volta.utils -   [GQA]: iter 34737 Ep: 9.43 loss 0.432 score 0.921 lr 2.34965e-05 
09/15/2020 09:15:43 - INFO - volta.utils -   [GQA]: iter 34757 Ep: 9.43 loss 0.420 score 0.924 lr 2.34844e-05 
09/15/2020 09:16:57 - INFO - volta.utils -   [GQA]: iter 34777 Ep: 9.44 loss 0.418 score 0.925 lr 2.34724e-05 
09/15/2020 09:19:08 - INFO - volta.utils -   [GQA]: iter 34797 Ep: 9.45 loss 0.425 score 0.927 lr 2.34603e-05 
09/15/2020 09:20:24 - INFO - volta.utils -   [GQA]: iter 34817 Ep: 9.45 loss 0.449 score 0.918 lr 2.34482e-05 
09/15/2020 09:22:06 - INFO - volta.utils -   [GQA]: iter 34837 Ep: 9.46 loss 0.445 score 0.922 lr 2.34362e-05 
09/15/2020 09:23:13 - INFO - volta.utils -   [GQA]: iter 34857 Ep: 9.46 loss 0.407 score 0.931 lr 2.34241e-05 
09/15/2020 09:25:02 - INFO - volta.utils -   [GQA]: iter 34877 Ep: 9.47 loss 0.423 score 0.921 lr 2.34121e-05 
09/15/2020 09:27:17 - INFO - volta.utils -   [GQA]: iter 34897 Ep: 9.47 loss 0.389 score 0.931 lr 2.34e-05 
09/15/2020 09:29:25 - INFO - volta.utils -   [GQA]: iter 34917 Ep: 9.48 loss 0.412 score 0.927 lr 2.33879e-05 
09/15/2020 09:31:06 - INFO - volta.utils -   [GQA]: iter 34937 Ep: 9.48 loss 0.452 score 0.919 lr 2.33759e-05 
09/15/2020 09:32:44 - INFO - volta.utils -   [GQA]: iter 34957 Ep: 9.49 loss 0.444 score 0.920 lr 2.33638e-05 
09/15/2020 09:34:35 - INFO - volta.utils -   [GQA]: iter 34977 Ep: 9.49 loss 0.437 score 0.922 lr 2.33517e-05 
09/15/2020 09:37:04 - INFO - volta.utils -   [GQA]: iter 34997 Ep: 9.50 loss 0.416 score 0.926 lr 2.33397e-05 
09/15/2020 09:37:59 - INFO - volta.utils -   [GQA]: iter 35017 Ep: 9.51 loss 0.438 score 0.925 lr 2.33276e-05 
09/15/2020 09:39:40 - INFO - volta.utils -   [GQA]: iter 35037 Ep: 9.51 loss 0.419 score 0.925 lr 2.33155e-05 
09/15/2020 09:41:06 - INFO - volta.utils -   [GQA]: iter 35057 Ep: 9.52 loss 0.427 score 0.925 lr 2.33035e-05 
09/15/2020 09:43:05 - INFO - volta.utils -   [GQA]: iter 35077 Ep: 9.52 loss 0.426 score 0.924 lr 2.32914e-05 
09/15/2020 09:44:31 - INFO - volta.utils -   [GQA]: iter 35097 Ep: 9.53 loss 0.433 score 0.924 lr 2.32793e-05 
09/15/2020 09:46:05 - INFO - volta.utils -   [GQA]: iter 35117 Ep: 9.53 loss 0.458 score 0.917 lr 2.32673e-05 
09/15/2020 09:47:40 - INFO - volta.utils -   [GQA]: iter 35137 Ep: 9.54 loss 0.442 score 0.919 lr 2.32552e-05 
09/15/2020 09:50:47 - INFO - volta.utils -   [GQA]: iter 35157 Ep: 9.54 loss 0.401 score 0.933 lr 2.32432e-05 
09/15/2020 09:52:06 - INFO - volta.utils -   [GQA]: iter 35177 Ep: 9.55 loss 0.409 score 0.929 lr 2.32311e-05 
09/15/2020 09:53:10 - INFO - volta.utils -   [GQA]: iter 35197 Ep: 9.55 loss 0.409 score 0.924 lr 2.3219e-05 
09/15/2020 09:54:47 - INFO - volta.utils -   [GQA]: iter 35217 Ep: 9.56 loss 0.412 score 0.926 lr 2.3207e-05 
09/15/2020 09:57:26 - INFO - volta.utils -   [GQA]: iter 35237 Ep: 9.56 loss 0.432 score 0.923 lr 2.31949e-05 
09/15/2020 09:58:40 - INFO - volta.utils -   [GQA]: iter 35257 Ep: 9.57 loss 0.413 score 0.929 lr 2.31828e-05 
09/15/2020 10:00:08 - INFO - volta.utils -   [GQA]: iter 35277 Ep: 9.58 loss 0.443 score 0.922 lr 2.31708e-05 
09/15/2020 10:01:50 - INFO - volta.utils -   [GQA]: iter 35297 Ep: 9.58 loss 0.428 score 0.923 lr 2.31587e-05 
09/15/2020 10:04:07 - INFO - volta.utils -   [GQA]: iter 35317 Ep: 9.59 loss 0.403 score 0.929 lr 2.31466e-05 
09/15/2020 10:05:48 - INFO - volta.utils -   [GQA]: iter 35337 Ep: 9.59 loss 0.418 score 0.924 lr 2.31346e-05 
09/15/2020 10:07:05 - INFO - volta.utils -   [GQA]: iter 35357 Ep: 9.60 loss 0.409 score 0.924 lr 2.31225e-05 
09/15/2020 10:08:35 - INFO - volta.utils -   [GQA]: iter 35377 Ep: 9.60 loss 0.445 score 0.923 lr 2.31104e-05 
09/15/2020 10:10:26 - INFO - volta.utils -   [GQA]: iter 35397 Ep: 9.61 loss 0.407 score 0.927 lr 2.30984e-05 
09/15/2020 10:12:26 - INFO - volta.utils -   [GQA]: iter 35417 Ep: 9.61 loss 0.430 score 0.919 lr 2.30863e-05 
09/15/2020 10:13:55 - INFO - volta.utils -   [GQA]: iter 35437 Ep: 9.62 loss 0.399 score 0.928 lr 2.30743e-05 
09/15/2020 10:15:28 - INFO - volta.utils -   [GQA]: iter 35457 Ep: 9.62 loss 0.434 score 0.921 lr 2.30622e-05 
09/15/2020 10:16:48 - INFO - volta.utils -   [GQA]: iter 35477 Ep: 9.63 loss 0.438 score 0.922 lr 2.30501e-05 
09/15/2020 10:19:13 - INFO - volta.utils -   [GQA]: iter 35497 Ep: 9.64 loss 0.420 score 0.925 lr 2.30381e-05 
09/15/2020 10:20:32 - INFO - volta.utils -   [GQA]: iter 35517 Ep: 9.64 loss 0.416 score 0.926 lr 2.3026e-05 
09/15/2020 10:22:07 - INFO - volta.utils -   [GQA]: iter 35537 Ep: 9.65 loss 0.437 score 0.918 lr 2.30139e-05 
09/15/2020 10:23:54 - INFO - volta.utils -   [GQA]: iter 35557 Ep: 9.65 loss 0.428 score 0.924 lr 2.30019e-05 
09/15/2020 10:25:56 - INFO - volta.utils -   [GQA]: iter 35577 Ep: 9.66 loss 0.419 score 0.922 lr 2.29898e-05 
09/15/2020 10:27:39 - INFO - volta.utils -   [GQA]: iter 35597 Ep: 9.66 loss 0.461 score 0.915 lr 2.29777e-05 
09/15/2020 10:29:16 - INFO - volta.utils -   [GQA]: iter 35617 Ep: 9.67 loss 0.434 score 0.923 lr 2.29657e-05 
09/15/2020 10:31:47 - INFO - volta.utils -   [GQA]: iter 35637 Ep: 9.67 loss 0.413 score 0.925 lr 2.29536e-05 
09/15/2020 10:33:00 - INFO - volta.utils -   [GQA]: iter 35657 Ep: 9.68 loss 0.435 score 0.923 lr 2.29415e-05 
09/15/2020 10:34:24 - INFO - volta.utils -   [GQA]: iter 35677 Ep: 9.68 loss 0.428 score 0.924 lr 2.29295e-05 
09/15/2020 10:36:05 - INFO - volta.utils -   [GQA]: iter 35697 Ep: 9.69 loss 0.441 score 0.919 lr 2.29174e-05 
09/15/2020 10:38:28 - INFO - volta.utils -   [GQA]: iter 35717 Ep: 9.70 loss 0.423 score 0.924 lr 2.29054e-05 
09/15/2020 10:39:54 - INFO - volta.utils -   [GQA]: iter 35737 Ep: 9.70 loss 0.452 score 0.920 lr 2.28933e-05 
09/15/2020 10:41:14 - INFO - volta.utils -   [GQA]: iter 35757 Ep: 9.71 loss 0.445 score 0.921 lr 2.28812e-05 
09/15/2020 10:42:53 - INFO - volta.utils -   [GQA]: iter 35777 Ep: 9.71 loss 0.428 score 0.926 lr 2.28692e-05 
09/15/2020 10:44:22 - INFO - volta.utils -   [GQA]: iter 35797 Ep: 9.72 loss 0.422 score 0.924 lr 2.28571e-05 
09/15/2020 10:46:32 - INFO - volta.utils -   [GQA]: iter 35817 Ep: 9.72 loss 0.416 score 0.926 lr 2.2845e-05 
09/15/2020 10:47:47 - INFO - volta.utils -   [GQA]: iter 35837 Ep: 9.73 loss 0.415 score 0.923 lr 2.2833e-05 
09/15/2020 10:49:50 - INFO - volta.utils -   [GQA]: iter 35857 Ep: 9.73 loss 0.419 score 0.923 lr 2.28209e-05 
09/15/2020 10:51:36 - INFO - volta.utils -   [GQA]: iter 35877 Ep: 9.74 loss 0.408 score 0.928 lr 2.28088e-05 
09/15/2020 10:53:44 - INFO - volta.utils -   [GQA]: iter 35897 Ep: 9.74 loss 0.396 score 0.931 lr 2.27968e-05 
09/15/2020 10:54:53 - INFO - volta.utils -   [GQA]: iter 35917 Ep: 9.75 loss 0.414 score 0.926 lr 2.27847e-05 
09/15/2020 10:56:29 - INFO - volta.utils -   [GQA]: iter 35937 Ep: 9.75 loss 0.421 score 0.927 lr 2.27727e-05 
09/15/2020 10:58:41 - INFO - volta.utils -   [GQA]: iter 35957 Ep: 9.76 loss 0.422 score 0.925 lr 2.27606e-05 
09/15/2020 10:59:59 - INFO - volta.utils -   [GQA]: iter 35977 Ep: 9.77 loss 0.429 score 0.922 lr 2.27485e-05 
09/15/2020 11:01:36 - INFO - volta.utils -   [GQA]: iter 35997 Ep: 9.77 loss 0.411 score 0.927 lr 2.27365e-05 
09/15/2020 11:03:06 - INFO - volta.utils -   [GQA]: iter 36017 Ep: 9.78 loss 0.430 score 0.926 lr 2.27244e-05 
09/15/2020 11:05:37 - INFO - volta.utils -   [GQA]: iter 36037 Ep: 9.78 loss 0.450 score 0.921 lr 2.27123e-05 
09/15/2020 11:06:56 - INFO - volta.utils -   [GQA]: iter 36057 Ep: 9.79 loss 0.424 score 0.925 lr 2.27003e-05 
09/15/2020 11:08:32 - INFO - volta.utils -   [GQA]: iter 36077 Ep: 9.79 loss 0.439 score 0.922 lr 2.26882e-05 
09/15/2020 11:10:01 - INFO - volta.utils -   [GQA]: iter 36097 Ep: 9.80 loss 0.400 score 0.930 lr 2.26761e-05 
09/15/2020 11:11:50 - INFO - volta.utils -   [GQA]: iter 36117 Ep: 9.80 loss 0.427 score 0.924 lr 2.26641e-05 
09/15/2020 11:13:23 - INFO - volta.utils -   [GQA]: iter 36137 Ep: 9.81 loss 0.418 score 0.924 lr 2.2652e-05 
09/15/2020 11:14:05 - INFO - volta.utils -   [GQA]: iter 36157 Ep: 9.81 loss 0.403 score 0.926 lr 2.26399e-05 
09/15/2020 11:15:30 - INFO - volta.utils -   [GQA]: iter 36177 Ep: 9.82 loss 0.432 score 0.917 lr 2.26279e-05 
09/15/2020 11:17:27 - INFO - volta.utils -   [GQA]: iter 36197 Ep: 9.83 loss 0.433 score 0.918 lr 2.26158e-05 
09/15/2020 11:18:57 - INFO - volta.utils -   [GQA]: iter 36217 Ep: 9.83 loss 0.414 score 0.927 lr 2.26038e-05 
09/15/2020 11:20:28 - INFO - volta.utils -   [GQA]: iter 36237 Ep: 9.84 loss 0.408 score 0.927 lr 2.25917e-05 
09/15/2020 11:22:04 - INFO - volta.utils -   [GQA]: iter 36257 Ep: 9.84 loss 0.428 score 0.921 lr 2.25796e-05 
09/15/2020 11:23:24 - INFO - volta.utils -   [GQA]: iter 36277 Ep: 9.85 loss 0.391 score 0.934 lr 2.25676e-05 
09/15/2020 11:25:13 - INFO - volta.utils -   [GQA]: iter 36297 Ep: 9.85 loss 0.452 score 0.915 lr 2.25555e-05 
09/15/2020 11:26:42 - INFO - volta.utils -   [GQA]: iter 36317 Ep: 9.86 loss 0.433 score 0.923 lr 2.25434e-05 
09/15/2020 11:27:45 - INFO - volta.utils -   [GQA]: iter 36337 Ep: 9.86 loss 0.423 score 0.926 lr 2.25314e-05 
09/15/2020 11:29:31 - INFO - volta.utils -   [GQA]: iter 36357 Ep: 9.87 loss 0.417 score 0.926 lr 2.25193e-05 
09/15/2020 11:31:33 - INFO - volta.utils -   [GQA]: iter 36377 Ep: 9.87 loss 0.425 score 0.925 lr 2.25072e-05 
09/15/2020 11:33:34 - INFO - volta.utils -   [GQA]: iter 36397 Ep: 9.88 loss 0.426 score 0.927 lr 2.24952e-05 
09/15/2020 11:34:34 - INFO - volta.utils -   [GQA]: iter 36417 Ep: 9.89 loss 0.420 score 0.922 lr 2.24831e-05 
09/15/2020 11:35:50 - INFO - volta.utils -   [GQA]: iter 36437 Ep: 9.89 loss 0.397 score 0.932 lr 2.2471e-05 
09/15/2020 11:37:33 - INFO - volta.utils -   [GQA]: iter 36457 Ep: 9.90 loss 0.421 score 0.924 lr 2.2459e-05 
09/15/2020 11:38:55 - INFO - volta.utils -   [GQA]: iter 36477 Ep: 9.90 loss 0.443 score 0.922 lr 2.24469e-05 
09/15/2020 11:40:38 - INFO - volta.utils -   [GQA]: iter 36497 Ep: 9.91 loss 0.441 score 0.919 lr 2.24349e-05 
09/15/2020 11:42:16 - INFO - volta.utils -   [GQA]: iter 36517 Ep: 9.91 loss 0.400 score 0.930 lr 2.24228e-05 
09/15/2020 11:44:42 - INFO - volta.utils -   [GQA]: iter 36537 Ep: 9.92 loss 0.411 score 0.928 lr 2.24107e-05 
09/15/2020 11:45:41 - INFO - volta.utils -   [GQA]: iter 36557 Ep: 9.92 loss 0.416 score 0.924 lr 2.23987e-05 
09/15/2020 11:47:12 - INFO - volta.utils -   [GQA]: iter 36577 Ep: 9.93 loss 0.419 score 0.926 lr 2.23866e-05 
09/15/2020 11:49:09 - INFO - volta.utils -   [GQA]: iter 36597 Ep: 9.93 loss 0.425 score 0.923 lr 2.23745e-05 
09/15/2020 11:51:51 - INFO - volta.utils -   [GQA]: iter 36617 Ep: 9.94 loss 0.450 score 0.920 lr 2.23625e-05 
09/15/2020 11:53:19 - INFO - volta.utils -   [GQA]: iter 36637 Ep: 9.94 loss 0.414 score 0.925 lr 2.23504e-05 
09/15/2020 11:55:01 - INFO - volta.utils -   [GQA]: iter 36657 Ep: 9.95 loss 0.459 score 0.917 lr 2.23383e-05 
09/15/2020 11:56:02 - INFO - volta.utils -   [GQA]: iter 36677 Ep: 9.96 loss 0.423 score 0.926 lr 2.23263e-05 
09/15/2020 11:58:17 - INFO - volta.utils -   [GQA]: iter 36697 Ep: 9.96 loss 0.446 score 0.918 lr 2.23142e-05 
09/15/2020 11:59:10 - INFO - volta.utils -   [GQA]: iter 36717 Ep: 9.97 loss 0.427 score 0.926 lr 2.23021e-05 
09/15/2020 12:01:07 - INFO - volta.utils -   [GQA]: iter 36737 Ep: 9.97 loss 0.452 score 0.920 lr 2.22901e-05 
09/15/2020 12:03:20 - INFO - volta.utils -   [GQA]: iter 36757 Ep: 9.98 loss 0.407 score 0.926 lr 2.2278e-05 
09/15/2020 12:04:24 - INFO - volta.utils -   [GQA]: iter 36777 Ep: 9.98 loss 0.433 score 0.926 lr 2.2266e-05 
09/15/2020 12:05:54 - INFO - volta.utils -   [GQA]: iter 36797 Ep: 9.99 loss 0.440 score 0.922 lr 2.22539e-05 
09/15/2020 12:07:39 - INFO - volta.utils -   [GQA]: iter 36817 Ep: 9.99 loss 0.404 score 0.927 lr 2.22418e-05 
09/15/2020 12:09:11 - INFO - volta.utils -   [GQA]: iter 36837 Ep: 10.00 loss 0.430 score 0.926 lr 2.22298e-05 
09/15/2020 12:09:12 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  17%|        | 2/12 [10:49:26<53:57:57, 19427.71s/it]09/15/2020 12:28:30 - INFO - volta.utils -   Eval task TASK15 on iteration 36841 
09/15/2020 12:28:30 - INFO - volta.utils -   Validation [GQA]: loss 2.713 score 64.296 
09/15/2020 12:28:57 - INFO - volta.utils -   [GQA]: iter 36861 Ep: 10.01 loss 0.331 score 0.948 lr 2.22165e-05 
09/15/2020 12:30:05 - INFO - volta.utils -   [GQA]: iter 36881 Ep: 10.01 loss 0.304 score 0.953 lr 2.22032e-05 
09/15/2020 12:31:28 - INFO - volta.utils -   [GQA]: iter 36901 Ep: 10.02 loss 0.313 score 0.948 lr 2.21912e-05 
09/15/2020 12:32:31 - INFO - volta.utils -   [GQA]: iter 36921 Ep: 10.02 loss 0.285 score 0.953 lr 2.21791e-05 
09/15/2020 12:34:12 - INFO - volta.utils -   [GQA]: iter 36941 Ep: 10.03 loss 0.294 score 0.953 lr 2.2167e-05 
09/15/2020 12:35:14 - INFO - volta.utils -   [GQA]: iter 36961 Ep: 10.03 loss 0.290 score 0.952 lr 2.2155e-05 
09/15/2020 12:36:32 - INFO - volta.utils -   [GQA]: iter 36981 Ep: 10.04 loss 0.289 score 0.952 lr 2.21429e-05 
09/15/2020 12:37:58 - INFO - volta.utils -   [GQA]: iter 37001 Ep: 10.04 loss 0.310 score 0.949 lr 2.21308e-05 
09/15/2020 12:39:52 - INFO - volta.utils -   [GQA]: iter 37021 Ep: 10.05 loss 0.287 score 0.954 lr 2.21188e-05 
09/15/2020 12:41:27 - INFO - volta.utils -   [GQA]: iter 37041 Ep: 10.05 loss 0.306 score 0.950 lr 2.21067e-05 
09/15/2020 12:43:13 - INFO - volta.utils -   [GQA]: iter 37061 Ep: 10.06 loss 0.282 score 0.953 lr 2.20946e-05 
09/15/2020 12:44:45 - INFO - volta.utils -   [GQA]: iter 37081 Ep: 10.07 loss 0.293 score 0.952 lr 2.20826e-05 
09/15/2020 12:46:57 - INFO - volta.utils -   [GQA]: iter 37101 Ep: 10.07 loss 0.300 score 0.949 lr 2.20705e-05 
09/15/2020 12:48:47 - INFO - volta.utils -   [GQA]: iter 37121 Ep: 10.08 loss 0.301 score 0.948 lr 2.20585e-05 
09/15/2020 12:49:51 - INFO - volta.utils -   [GQA]: iter 37141 Ep: 10.08 loss 0.289 score 0.955 lr 2.20464e-05 
09/15/2020 12:51:15 - INFO - volta.utils -   [GQA]: iter 37161 Ep: 10.09 loss 0.306 score 0.947 lr 2.20343e-05 
09/15/2020 12:52:56 - INFO - volta.utils -   [GQA]: iter 37181 Ep: 10.09 loss 0.299 score 0.949 lr 2.20223e-05 
09/15/2020 12:54:42 - INFO - volta.utils -   [GQA]: iter 37201 Ep: 10.10 loss 0.314 score 0.950 lr 2.20102e-05 
09/15/2020 12:56:02 - INFO - volta.utils -   [GQA]: iter 37221 Ep: 10.10 loss 0.318 score 0.942 lr 2.19981e-05 
09/15/2020 12:57:34 - INFO - volta.utils -   [GQA]: iter 37241 Ep: 10.11 loss 0.304 score 0.952 lr 2.19861e-05 
09/15/2020 12:59:00 - INFO - volta.utils -   [GQA]: iter 37261 Ep: 10.11 loss 0.309 score 0.946 lr 2.1974e-05 
09/15/2020 13:01:05 - INFO - volta.utils -   [GQA]: iter 37281 Ep: 10.12 loss 0.305 score 0.952 lr 2.19619e-05 
09/15/2020 13:03:26 - INFO - volta.utils -   [GQA]: iter 37301 Ep: 10.13 loss 0.309 score 0.950 lr 2.19499e-05 
09/15/2020 13:04:59 - INFO - volta.utils -   [GQA]: iter 37321 Ep: 10.13 loss 0.294 score 0.950 lr 2.19378e-05 
09/15/2020 13:05:59 - INFO - volta.utils -   [GQA]: iter 37341 Ep: 10.14 loss 0.282 score 0.955 lr 2.19257e-05 
09/15/2020 13:07:34 - INFO - volta.utils -   [GQA]: iter 37361 Ep: 10.14 loss 0.312 score 0.948 lr 2.19137e-05 
09/15/2020 13:10:02 - INFO - volta.utils -   [GQA]: iter 37381 Ep: 10.15 loss 0.316 score 0.950 lr 2.19016e-05 
09/15/2020 13:11:34 - INFO - volta.utils -   [GQA]: iter 37401 Ep: 10.15 loss 0.301 score 0.951 lr 2.18896e-05 
09/15/2020 13:13:14 - INFO - volta.utils -   [GQA]: iter 37421 Ep: 10.16 loss 0.297 score 0.952 lr 2.18775e-05 
09/15/2020 13:14:27 - INFO - volta.utils -   [GQA]: iter 37441 Ep: 10.16 loss 0.318 score 0.945 lr 2.18654e-05 
09/15/2020 13:16:37 - INFO - volta.utils -   [GQA]: iter 37461 Ep: 10.17 loss 0.300 score 0.950 lr 2.18534e-05 
09/15/2020 13:17:37 - INFO - volta.utils -   [GQA]: iter 37481 Ep: 10.17 loss 0.310 score 0.947 lr 2.18413e-05 
09/15/2020 13:18:54 - INFO - volta.utils -   [GQA]: iter 37501 Ep: 10.18 loss 0.293 score 0.950 lr 2.18292e-05 
09/15/2020 13:21:07 - INFO - volta.utils -   [GQA]: iter 37521 Ep: 10.18 loss 0.311 score 0.943 lr 2.18172e-05 
09/15/2020 13:23:24 - INFO - volta.utils -   [GQA]: iter 37541 Ep: 10.19 loss 0.312 score 0.946 lr 2.18051e-05 
09/15/2020 13:24:48 - INFO - volta.utils -   [GQA]: iter 37561 Ep: 10.20 loss 0.299 score 0.951 lr 2.1793e-05 
09/15/2020 13:25:37 - INFO - volta.utils -   [GQA]: iter 37581 Ep: 10.20 loss 0.302 score 0.951 lr 2.1781e-05 
09/15/2020 13:27:15 - INFO - volta.utils -   [GQA]: iter 37601 Ep: 10.21 loss 0.301 score 0.950 lr 2.17689e-05 
09/15/2020 13:30:16 - INFO - volta.utils -   [GQA]: iter 37621 Ep: 10.21 loss 0.308 score 0.946 lr 2.17568e-05 
09/15/2020 13:31:44 - INFO - volta.utils -   [GQA]: iter 37641 Ep: 10.22 loss 0.312 score 0.950 lr 2.17448e-05 
09/15/2020 13:32:52 - INFO - volta.utils -   [GQA]: iter 37661 Ep: 10.22 loss 0.307 score 0.947 lr 2.17327e-05 
09/15/2020 13:33:59 - INFO - volta.utils -   [GQA]: iter 37681 Ep: 10.23 loss 0.312 score 0.947 lr 2.17207e-05 
09/15/2020 13:36:42 - INFO - volta.utils -   [GQA]: iter 37701 Ep: 10.23 loss 0.322 score 0.947 lr 2.17086e-05 
09/15/2020 13:38:11 - INFO - volta.utils -   [GQA]: iter 37721 Ep: 10.24 loss 0.316 score 0.949 lr 2.16965e-05 
09/15/2020 13:39:29 - INFO - volta.utils -   [GQA]: iter 37741 Ep: 10.24 loss 0.293 score 0.953 lr 2.16845e-05 
09/15/2020 13:40:53 - INFO - volta.utils -   [GQA]: iter 37761 Ep: 10.25 loss 0.298 score 0.952 lr 2.16724e-05 
09/15/2020 13:42:56 - INFO - volta.utils -   [GQA]: iter 37781 Ep: 10.26 loss 0.296 score 0.951 lr 2.16603e-05 
09/15/2020 13:43:51 - INFO - volta.utils -   [GQA]: iter 37801 Ep: 10.26 loss 0.301 score 0.948 lr 2.16483e-05 
09/15/2020 13:46:10 - INFO - volta.utils -   [GQA]: iter 37821 Ep: 10.27 loss 0.322 score 0.947 lr 2.16362e-05 
09/15/2020 13:47:42 - INFO - volta.utils -   [GQA]: iter 37841 Ep: 10.27 loss 0.284 score 0.954 lr 2.16241e-05 
09/15/2020 13:49:15 - INFO - volta.utils -   [GQA]: iter 37861 Ep: 10.28 loss 0.308 score 0.950 lr 2.16121e-05 
09/15/2020 13:51:17 - INFO - volta.utils -   [GQA]: iter 37881 Ep: 10.28 loss 0.308 score 0.949 lr 2.16e-05 
09/15/2020 13:53:12 - INFO - volta.utils -   [GQA]: iter 37901 Ep: 10.29 loss 0.304 score 0.949 lr 2.15879e-05 
09/15/2020 13:54:40 - INFO - volta.utils -   [GQA]: iter 37921 Ep: 10.29 loss 0.298 score 0.951 lr 2.15759e-05 
09/15/2020 13:56:07 - INFO - volta.utils -   [GQA]: iter 37941 Ep: 10.30 loss 0.318 score 0.945 lr 2.15638e-05 
09/15/2020 13:57:53 - INFO - volta.utils -   [GQA]: iter 37961 Ep: 10.30 loss 0.323 score 0.943 lr 2.15518e-05 
09/15/2020 13:59:52 - INFO - volta.utils -   [GQA]: iter 37981 Ep: 10.31 loss 0.318 score 0.946 lr 2.15397e-05 
09/15/2020 14:01:29 - INFO - volta.utils -   [GQA]: iter 38001 Ep: 10.32 loss 0.325 score 0.945 lr 2.15276e-05 
09/15/2020 14:03:28 - INFO - volta.utils -   [GQA]: iter 38021 Ep: 10.32 loss 0.298 score 0.950 lr 2.15156e-05 
09/15/2020 14:05:02 - INFO - volta.utils -   [GQA]: iter 38041 Ep: 10.33 loss 0.326 score 0.946 lr 2.15035e-05 
09/15/2020 14:07:03 - INFO - volta.utils -   [GQA]: iter 38061 Ep: 10.33 loss 0.319 score 0.948 lr 2.14914e-05 
09/15/2020 14:08:17 - INFO - volta.utils -   [GQA]: iter 38081 Ep: 10.34 loss 0.294 score 0.952 lr 2.14794e-05 
09/15/2020 14:10:23 - INFO - volta.utils -   [GQA]: iter 38101 Ep: 10.34 loss 0.306 score 0.952 lr 2.14673e-05 
09/15/2020 14:11:31 - INFO - volta.utils -   [GQA]: iter 38121 Ep: 10.35 loss 0.290 score 0.953 lr 2.14552e-05 
09/15/2020 14:13:39 - INFO - volta.utils -   [GQA]: iter 38141 Ep: 10.35 loss 0.306 score 0.946 lr 2.14432e-05 
09/15/2020 14:14:50 - INFO - volta.utils -   [GQA]: iter 38161 Ep: 10.36 loss 0.316 score 0.946 lr 2.14311e-05 
09/15/2020 14:16:40 - INFO - volta.utils -   [GQA]: iter 38181 Ep: 10.36 loss 0.291 score 0.949 lr 2.1419e-05 
09/15/2020 14:18:13 - INFO - volta.utils -   [GQA]: iter 38201 Ep: 10.37 loss 0.322 score 0.945 lr 2.1407e-05 
09/15/2020 14:20:24 - INFO - volta.utils -   [GQA]: iter 38221 Ep: 10.37 loss 0.306 score 0.951 lr 2.13949e-05 
09/15/2020 14:21:39 - INFO - volta.utils -   [GQA]: iter 38241 Ep: 10.38 loss 0.318 score 0.942 lr 2.13829e-05 
09/15/2020 14:23:57 - INFO - volta.utils -   [GQA]: iter 38261 Ep: 10.39 loss 0.326 score 0.944 lr 2.13708e-05 
09/15/2020 14:25:39 - INFO - volta.utils -   [GQA]: iter 38281 Ep: 10.39 loss 0.287 score 0.951 lr 2.13587e-05 
09/15/2020 14:27:45 - INFO - volta.utils -   [GQA]: iter 38301 Ep: 10.40 loss 0.317 score 0.945 lr 2.13467e-05 
09/15/2020 14:29:15 - INFO - volta.utils -   [GQA]: iter 38321 Ep: 10.40 loss 0.306 score 0.950 lr 2.13346e-05 
09/15/2020 14:30:59 - INFO - volta.utils -   [GQA]: iter 38341 Ep: 10.41 loss 0.306 score 0.950 lr 2.13225e-05 
09/15/2020 14:32:27 - INFO - volta.utils -   [GQA]: iter 38361 Ep: 10.41 loss 0.306 score 0.946 lr 2.13105e-05 
09/15/2020 14:34:17 - INFO - volta.utils -   [GQA]: iter 38381 Ep: 10.42 loss 0.297 score 0.949 lr 2.12984e-05 
09/15/2020 14:36:04 - INFO - volta.utils -   [GQA]: iter 38401 Ep: 10.42 loss 0.326 score 0.946 lr 2.12863e-05 
09/15/2020 14:37:40 - INFO - volta.utils -   [GQA]: iter 38421 Ep: 10.43 loss 0.314 score 0.946 lr 2.12743e-05 
09/15/2020 14:39:20 - INFO - volta.utils -   [GQA]: iter 38441 Ep: 10.43 loss 0.308 score 0.949 lr 2.12622e-05 
09/15/2020 14:41:00 - INFO - volta.utils -   [GQA]: iter 38461 Ep: 10.44 loss 0.324 score 0.945 lr 2.12502e-05 
09/15/2020 14:42:55 - INFO - volta.utils -   [GQA]: iter 38481 Ep: 10.45 loss 0.304 score 0.949 lr 2.12381e-05 
09/15/2020 14:44:17 - INFO - volta.utils -   [GQA]: iter 38501 Ep: 10.45 loss 0.322 score 0.946 lr 2.1226e-05 
09/15/2020 14:46:10 - INFO - volta.utils -   [GQA]: iter 38521 Ep: 10.46 loss 0.332 score 0.947 lr 2.1214e-05 
09/15/2020 14:47:52 - INFO - volta.utils -   [GQA]: iter 38541 Ep: 10.46 loss 0.317 score 0.943 lr 2.12019e-05 
09/15/2020 14:50:21 - INFO - volta.utils -   [GQA]: iter 38561 Ep: 10.47 loss 0.319 score 0.945 lr 2.11898e-05 
09/15/2020 14:51:28 - INFO - volta.utils -   [GQA]: iter 38581 Ep: 10.47 loss 0.304 score 0.948 lr 2.11778e-05 
09/15/2020 14:52:59 - INFO - volta.utils -   [GQA]: iter 38601 Ep: 10.48 loss 0.307 score 0.947 lr 2.11657e-05 
09/15/2020 14:54:34 - INFO - volta.utils -   [GQA]: iter 38621 Ep: 10.48 loss 0.319 score 0.943 lr 2.11536e-05 
09/15/2020 14:56:27 - INFO - volta.utils -   [GQA]: iter 38641 Ep: 10.49 loss 0.321 score 0.944 lr 2.11416e-05 
09/15/2020 14:57:57 - INFO - volta.utils -   [GQA]: iter 38661 Ep: 10.49 loss 0.321 score 0.947 lr 2.11295e-05 
09/15/2020 14:59:35 - INFO - volta.utils -   [GQA]: iter 38681 Ep: 10.50 loss 0.355 score 0.936 lr 2.11174e-05 
09/15/2020 15:01:10 - INFO - volta.utils -   [GQA]: iter 38701 Ep: 10.51 loss 0.338 score 0.944 lr 2.11054e-05 
09/15/2020 15:03:19 - INFO - volta.utils -   [GQA]: iter 38721 Ep: 10.51 loss 0.337 score 0.943 lr 2.10933e-05 
09/15/2020 15:04:43 - INFO - volta.utils -   [GQA]: iter 38741 Ep: 10.52 loss 0.341 score 0.941 lr 2.10813e-05 
09/15/2020 15:06:09 - INFO - volta.utils -   [GQA]: iter 38761 Ep: 10.52 loss 0.317 score 0.946 lr 2.10692e-05 
09/15/2020 15:08:32 - INFO - volta.utils -   [GQA]: iter 38781 Ep: 10.53 loss 0.351 score 0.934 lr 2.10571e-05 
09/15/2020 15:09:51 - INFO - volta.utils -   [GQA]: iter 38801 Ep: 10.53 loss 0.296 score 0.950 lr 2.10451e-05 
09/15/2020 15:11:28 - INFO - volta.utils -   [GQA]: iter 38821 Ep: 10.54 loss 0.312 score 0.946 lr 2.1033e-05 
09/15/2020 15:13:20 - INFO - volta.utils -   [GQA]: iter 38841 Ep: 10.54 loss 0.291 score 0.954 lr 2.10209e-05 
09/15/2020 15:15:30 - INFO - volta.utils -   [GQA]: iter 38861 Ep: 10.55 loss 0.320 score 0.948 lr 2.10089e-05 
09/15/2020 15:18:00 - INFO - volta.utils -   [GQA]: iter 38881 Ep: 10.55 loss 0.327 score 0.942 lr 2.09968e-05 
09/15/2020 15:19:22 - INFO - volta.utils -   [GQA]: iter 38901 Ep: 10.56 loss 0.324 score 0.948 lr 2.09847e-05 
09/15/2020 15:20:48 - INFO - volta.utils -   [GQA]: iter 38921 Ep: 10.56 loss 0.309 score 0.953 lr 2.09727e-05 
09/15/2020 15:22:55 - INFO - volta.utils -   [GQA]: iter 38941 Ep: 10.57 loss 0.320 score 0.946 lr 2.09606e-05 
09/15/2020 15:24:46 - INFO - volta.utils -   [GQA]: iter 38961 Ep: 10.58 loss 0.350 score 0.943 lr 2.09485e-05 
09/15/2020 15:26:22 - INFO - volta.utils -   [GQA]: iter 38981 Ep: 10.58 loss 0.315 score 0.945 lr 2.09365e-05 
09/15/2020 15:26:54 - INFO - volta.utils -   [GQA]: iter 39001 Ep: 10.59 loss 0.305 score 0.947 lr 2.09244e-05 
09/15/2020 15:28:38 - INFO - volta.utils -   [GQA]: iter 39021 Ep: 10.59 loss 0.304 score 0.947 lr 2.09124e-05 
09/15/2020 15:31:06 - INFO - volta.utils -   [GQA]: iter 39041 Ep: 10.60 loss 0.312 score 0.946 lr 2.09003e-05 
09/15/2020 15:32:34 - INFO - volta.utils -   [GQA]: iter 39061 Ep: 10.60 loss 0.327 score 0.945 lr 2.08882e-05 
09/15/2020 15:34:11 - INFO - volta.utils -   [GQA]: iter 39081 Ep: 10.61 loss 0.340 score 0.946 lr 2.08762e-05 
09/15/2020 15:35:24 - INFO - volta.utils -   [GQA]: iter 39101 Ep: 10.61 loss 0.318 score 0.947 lr 2.08641e-05 
09/15/2020 15:38:05 - INFO - volta.utils -   [GQA]: iter 39121 Ep: 10.62 loss 0.318 score 0.945 lr 2.0852e-05 
09/15/2020 15:39:25 - INFO - volta.utils -   [GQA]: iter 39141 Ep: 10.62 loss 0.321 score 0.947 lr 2.084e-05 
09/15/2020 15:40:20 - INFO - volta.utils -   [GQA]: iter 39161 Ep: 10.63 loss 0.353 score 0.938 lr 2.08279e-05 
09/15/2020 15:42:11 - INFO - volta.utils -   [GQA]: iter 39181 Ep: 10.64 loss 0.314 score 0.946 lr 2.08158e-05 
09/15/2020 15:44:20 - INFO - volta.utils -   [GQA]: iter 39201 Ep: 10.64 loss 0.317 score 0.945 lr 2.08038e-05 
09/15/2020 15:46:02 - INFO - volta.utils -   [GQA]: iter 39221 Ep: 10.65 loss 0.291 score 0.949 lr 2.07917e-05 
09/15/2020 15:47:11 - INFO - volta.utils -   [GQA]: iter 39241 Ep: 10.65 loss 0.370 score 0.932 lr 2.07796e-05 
09/15/2020 15:49:31 - INFO - volta.utils -   [GQA]: iter 39261 Ep: 10.66 loss 0.339 score 0.941 lr 2.07676e-05 
09/15/2020 15:51:24 - INFO - volta.utils -   [GQA]: iter 39281 Ep: 10.66 loss 0.332 score 0.943 lr 2.07555e-05 
09/15/2020 15:52:03 - INFO - volta.utils -   [GQA]: iter 39301 Ep: 10.67 loss 0.339 score 0.943 lr 2.07435e-05 
09/15/2020 15:53:27 - INFO - volta.utils -   [GQA]: iter 39321 Ep: 10.67 loss 0.316 score 0.951 lr 2.07314e-05 
09/15/2020 15:55:15 - INFO - volta.utils -   [GQA]: iter 39341 Ep: 10.68 loss 0.320 score 0.945 lr 2.07193e-05 
09/15/2020 15:56:31 - INFO - volta.utils -   [GQA]: iter 39361 Ep: 10.68 loss 0.333 score 0.945 lr 2.07073e-05 
09/15/2020 15:58:17 - INFO - volta.utils -   [GQA]: iter 39381 Ep: 10.69 loss 0.337 score 0.940 lr 2.06952e-05 
09/15/2020 15:59:25 - INFO - volta.utils -   [GQA]: iter 39401 Ep: 10.70 loss 0.331 score 0.943 lr 2.06831e-05 
09/15/2020 16:01:53 - INFO - volta.utils -   [GQA]: iter 39421 Ep: 10.70 loss 0.324 score 0.943 lr 2.06711e-05 
09/15/2020 16:03:38 - INFO - volta.utils -   [GQA]: iter 39441 Ep: 10.71 loss 0.321 score 0.944 lr 2.0659e-05 
09/15/2020 16:05:00 - INFO - volta.utils -   [GQA]: iter 39461 Ep: 10.71 loss 0.356 score 0.938 lr 2.06469e-05 
09/15/2020 16:06:13 - INFO - volta.utils -   [GQA]: iter 39481 Ep: 10.72 loss 0.308 score 0.947 lr 2.06349e-05 
09/15/2020 16:09:06 - INFO - volta.utils -   [GQA]: iter 39501 Ep: 10.72 loss 0.322 score 0.947 lr 2.06228e-05 
09/15/2020 16:10:36 - INFO - volta.utils -   [GQA]: iter 39521 Ep: 10.73 loss 0.322 score 0.943 lr 2.06107e-05 
09/15/2020 16:12:03 - INFO - volta.utils -   [GQA]: iter 39541 Ep: 10.73 loss 0.337 score 0.941 lr 2.05987e-05 
09/15/2020 16:13:27 - INFO - volta.utils -   [GQA]: iter 39561 Ep: 10.74 loss 0.318 score 0.946 lr 2.05866e-05 
09/15/2020 16:15:40 - INFO - volta.utils -   [GQA]: iter 39581 Ep: 10.74 loss 0.326 score 0.944 lr 2.05746e-05 
09/15/2020 16:17:12 - INFO - volta.utils -   [GQA]: iter 39601 Ep: 10.75 loss 0.358 score 0.937 lr 2.05625e-05 
09/15/2020 16:18:55 - INFO - volta.utils -   [GQA]: iter 39621 Ep: 10.75 loss 0.341 score 0.940 lr 2.05504e-05 
09/15/2020 16:20:11 - INFO - volta.utils -   [GQA]: iter 39641 Ep: 10.76 loss 0.346 score 0.940 lr 2.05384e-05 
09/15/2020 16:22:25 - INFO - volta.utils -   [GQA]: iter 39661 Ep: 10.77 loss 0.316 score 0.946 lr 2.05263e-05 
09/15/2020 16:23:54 - INFO - volta.utils -   [GQA]: iter 39681 Ep: 10.77 loss 0.331 score 0.942 lr 2.05142e-05 
09/15/2020 16:25:27 - INFO - volta.utils -   [GQA]: iter 39701 Ep: 10.78 loss 0.339 score 0.945 lr 2.05022e-05 
09/15/2020 16:26:37 - INFO - volta.utils -   [GQA]: iter 39721 Ep: 10.78 loss 0.336 score 0.942 lr 2.04901e-05 
09/15/2020 16:28:42 - INFO - volta.utils -   [GQA]: iter 39741 Ep: 10.79 loss 0.335 score 0.941 lr 2.0478e-05 
09/15/2020 16:30:11 - INFO - volta.utils -   [GQA]: iter 39761 Ep: 10.79 loss 0.318 score 0.948 lr 2.0466e-05 
09/15/2020 16:32:16 - INFO - volta.utils -   [GQA]: iter 39781 Ep: 10.80 loss 0.326 score 0.943 lr 2.04539e-05 
09/15/2020 16:33:34 - INFO - volta.utils -   [GQA]: iter 39801 Ep: 10.80 loss 0.323 score 0.945 lr 2.04419e-05 
09/15/2020 16:35:43 - INFO - volta.utils -   [GQA]: iter 39821 Ep: 10.81 loss 0.294 score 0.953 lr 2.04298e-05 
09/15/2020 16:37:08 - INFO - volta.utils -   [GQA]: iter 39841 Ep: 10.81 loss 0.315 score 0.950 lr 2.04177e-05 
09/15/2020 16:38:57 - INFO - volta.utils -   [GQA]: iter 39861 Ep: 10.82 loss 0.326 score 0.944 lr 2.04057e-05 
09/15/2020 16:39:48 - INFO - volta.utils -   [GQA]: iter 39881 Ep: 10.83 loss 0.350 score 0.939 lr 2.03936e-05 
09/15/2020 16:42:31 - INFO - volta.utils -   [GQA]: iter 39901 Ep: 10.83 loss 0.346 score 0.938 lr 2.03815e-05 
09/15/2020 16:43:19 - INFO - volta.utils -   [GQA]: iter 39921 Ep: 10.84 loss 0.337 score 0.941 lr 2.03695e-05 
09/15/2020 16:45:05 - INFO - volta.utils -   [GQA]: iter 39941 Ep: 10.84 loss 0.326 score 0.941 lr 2.03574e-05 
09/15/2020 16:46:29 - INFO - volta.utils -   [GQA]: iter 39961 Ep: 10.85 loss 0.333 score 0.940 lr 2.03453e-05 
09/15/2020 16:48:55 - INFO - volta.utils -   [GQA]: iter 39981 Ep: 10.85 loss 0.337 score 0.943 lr 2.03333e-05 
09/15/2020 16:50:16 - INFO - volta.utils -   [GQA]: iter 40001 Ep: 10.86 loss 0.331 score 0.944 lr 2.03212e-05 
09/15/2020 16:52:38 - INFO - volta.utils -   [GQA]: iter 40021 Ep: 10.86 loss 0.324 score 0.944 lr 2.03091e-05 
09/15/2020 17:12:19 - INFO - volta.utils -   [GQA]: iter 40041 Ep: 10.87 loss 0.333 score 0.942 lr 2.02971e-05 
09/15/2020 17:17:13 - INFO - volta.utils -   [GQA]: iter 40061 Ep: 10.87 loss 0.327 score 0.946 lr 2.0285e-05 
09/15/2020 17:18:40 - INFO - volta.utils -   [GQA]: iter 40081 Ep: 10.88 loss 0.348 score 0.937 lr 2.0273e-05 
09/15/2020 17:20:20 - INFO - volta.utils -   [GQA]: iter 40101 Ep: 10.89 loss 0.327 score 0.945 lr 2.02609e-05 
09/15/2020 17:21:49 - INFO - volta.utils -   [GQA]: iter 40121 Ep: 10.89 loss 0.321 score 0.946 lr 2.02488e-05 
09/15/2020 17:23:26 - INFO - volta.utils -   [GQA]: iter 40141 Ep: 10.90 loss 0.331 score 0.941 lr 2.02368e-05 
09/15/2020 17:24:36 - INFO - volta.utils -   [GQA]: iter 40161 Ep: 10.90 loss 0.323 score 0.943 lr 2.02247e-05 
09/15/2020 17:26:32 - INFO - volta.utils -   [GQA]: iter 40181 Ep: 10.91 loss 0.338 score 0.941 lr 2.02126e-05 
09/15/2020 17:27:51 - INFO - volta.utils -   [GQA]: iter 40201 Ep: 10.91 loss 0.349 score 0.941 lr 2.02006e-05 
09/15/2020 17:29:46 - INFO - volta.utils -   [GQA]: iter 40221 Ep: 10.92 loss 0.316 score 0.941 lr 2.01885e-05 
09/15/2020 17:31:49 - INFO - volta.utils -   [GQA]: iter 40241 Ep: 10.92 loss 0.333 score 0.941 lr 2.01764e-05 
09/15/2020 17:33:59 - INFO - volta.utils -   [GQA]: iter 40261 Ep: 10.93 loss 0.333 score 0.941 lr 2.01644e-05 
09/15/2020 17:35:14 - INFO - volta.utils -   [GQA]: iter 40281 Ep: 10.93 loss 0.348 score 0.937 lr 2.01523e-05 
09/15/2020 17:37:03 - INFO - volta.utils -   [GQA]: iter 40301 Ep: 10.94 loss 0.331 score 0.941 lr 2.01402e-05 
09/15/2020 17:38:37 - INFO - volta.utils -   [GQA]: iter 40321 Ep: 10.94 loss 0.313 score 0.946 lr 2.01282e-05 
09/15/2020 17:40:43 - INFO - volta.utils -   [GQA]: iter 40341 Ep: 10.95 loss 0.329 score 0.943 lr 2.01161e-05 
09/15/2020 17:42:08 - INFO - volta.utils -   [GQA]: iter 40361 Ep: 10.96 loss 0.344 score 0.941 lr 2.01041e-05 
09/15/2020 17:44:06 - INFO - volta.utils -   [GQA]: iter 40381 Ep: 10.96 loss 0.357 score 0.942 lr 2.0092e-05 
09/15/2020 17:44:49 - INFO - volta.utils -   [GQA]: iter 40401 Ep: 10.97 loss 0.366 score 0.933 lr 2.00799e-05 
09/15/2020 17:47:05 - INFO - volta.utils -   [GQA]: iter 40421 Ep: 10.97 loss 0.321 score 0.944 lr 2.00679e-05 
09/15/2020 17:48:15 - INFO - volta.utils -   [GQA]: iter 40441 Ep: 10.98 loss 0.349 score 0.939 lr 2.00558e-05 
09/15/2020 17:49:44 - INFO - volta.utils -   [GQA]: iter 40461 Ep: 10.98 loss 0.328 score 0.943 lr 2.00437e-05 
09/15/2020 17:51:23 - INFO - volta.utils -   [GQA]: iter 40481 Ep: 10.99 loss 0.330 score 0.945 lr 2.00317e-05 
09/15/2020 17:53:30 - INFO - volta.utils -   [GQA]: iter 40501 Ep: 10.99 loss 0.311 score 0.948 lr 2.00196e-05 
09/15/2020 17:54:53 - INFO - volta.utils -   [GQA]: iter 40521 Ep: 11.00 loss 0.325 score 0.944 lr 2.00075e-05 
09/15/2020 17:55:07 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  25%|       | 3/12 [16:35:20<49:33:49, 19825.49s/it]09/15/2020 18:14:27 - INFO - volta.utils -   Eval task TASK15 on iteration 40525 
09/15/2020 18:14:27 - INFO - volta.utils -   Validation [GQA]: loss 2.936 score 64.355 
09/15/2020 18:14:40 - INFO - volta.utils -   [GQA]: iter 40545 Ep: 11.01 loss 0.247 score 0.964 lr 1.99943e-05 
09/15/2020 18:16:06 - INFO - volta.utils -   [GQA]: iter 40565 Ep: 11.01 loss 0.207 score 0.970 lr 1.9981e-05 
09/15/2020 18:17:19 - INFO - volta.utils -   [GQA]: iter 40585 Ep: 11.02 loss 0.211 score 0.969 lr 1.99689e-05 
09/15/2020 18:18:43 - INFO - volta.utils -   [GQA]: iter 40605 Ep: 11.02 loss 0.214 score 0.967 lr 1.99569e-05 
09/15/2020 18:20:26 - INFO - volta.utils -   [GQA]: iter 40625 Ep: 11.03 loss 0.253 score 0.960 lr 1.99448e-05 
09/15/2020 18:21:22 - INFO - volta.utils -   [GQA]: iter 40645 Ep: 11.03 loss 0.229 score 0.967 lr 1.99327e-05 
09/15/2020 18:22:46 - INFO - volta.utils -   [GQA]: iter 40665 Ep: 11.04 loss 0.215 score 0.966 lr 1.99207e-05 
09/15/2020 18:24:08 - INFO - volta.utils -   [GQA]: iter 40685 Ep: 11.04 loss 0.226 score 0.967 lr 1.99086e-05 
09/15/2020 18:26:32 - INFO - volta.utils -   [GQA]: iter 40705 Ep: 11.05 loss 0.238 score 0.964 lr 1.98965e-05 
09/15/2020 18:28:08 - INFO - volta.utils -   [GQA]: iter 40725 Ep: 11.05 loss 0.230 score 0.964 lr 1.98845e-05 
09/15/2020 18:29:30 - INFO - volta.utils -   [GQA]: iter 40745 Ep: 11.06 loss 0.227 score 0.965 lr 1.98724e-05 
09/15/2020 18:30:44 - INFO - volta.utils -   [GQA]: iter 40765 Ep: 11.07 loss 0.205 score 0.969 lr 1.98604e-05 
09/15/2020 18:32:29 - INFO - volta.utils -   [GQA]: iter 40785 Ep: 11.07 loss 0.234 score 0.963 lr 1.98483e-05 
09/15/2020 18:33:54 - INFO - volta.utils -   [GQA]: iter 40805 Ep: 11.08 loss 0.221 score 0.966 lr 1.98362e-05 
09/15/2020 18:35:39 - INFO - volta.utils -   [GQA]: iter 40825 Ep: 11.08 loss 0.204 score 0.968 lr 1.98242e-05 
09/15/2020 18:37:06 - INFO - volta.utils -   [GQA]: iter 40845 Ep: 11.09 loss 0.223 score 0.964 lr 1.98121e-05 
09/15/2020 18:39:02 - INFO - volta.utils -   [GQA]: iter 40865 Ep: 11.09 loss 0.234 score 0.964 lr 1.98e-05 
09/15/2020 18:40:36 - INFO - volta.utils -   [GQA]: iter 40885 Ep: 11.10 loss 0.222 score 0.967 lr 1.9788e-05 
09/15/2020 18:42:33 - INFO - volta.utils -   [GQA]: iter 40905 Ep: 11.10 loss 0.231 score 0.966 lr 1.97759e-05 
09/15/2020 18:43:53 - INFO - volta.utils -   [GQA]: iter 40925 Ep: 11.11 loss 0.221 score 0.967 lr 1.97638e-05 
09/15/2020 18:45:59 - INFO - volta.utils -   [GQA]: iter 40945 Ep: 11.11 loss 0.213 score 0.966 lr 1.97518e-05 
09/15/2020 18:47:48 - INFO - volta.utils -   [GQA]: iter 40965 Ep: 11.12 loss 0.218 score 0.966 lr 1.97397e-05 
09/15/2020 18:49:38 - INFO - volta.utils -   [GQA]: iter 40985 Ep: 11.13 loss 0.233 score 0.964 lr 1.97277e-05 
09/15/2020 18:50:43 - INFO - volta.utils -   [GQA]: iter 41005 Ep: 11.13 loss 0.210 score 0.968 lr 1.97156e-05 
09/15/2020 18:53:15 - INFO - volta.utils -   [GQA]: iter 41025 Ep: 11.14 loss 0.201 score 0.969 lr 1.97035e-05 
09/15/2020 18:54:44 - INFO - volta.utils -   [GQA]: iter 41045 Ep: 11.14 loss 0.223 score 0.968 lr 1.96915e-05 
09/15/2020 18:56:24 - INFO - volta.utils -   [GQA]: iter 41065 Ep: 11.15 loss 0.222 score 0.967 lr 1.96794e-05 
09/15/2020 18:57:47 - INFO - volta.utils -   [GQA]: iter 41085 Ep: 11.15 loss 0.226 score 0.966 lr 1.96673e-05 
09/15/2020 18:59:51 - INFO - volta.utils -   [GQA]: iter 41105 Ep: 11.16 loss 0.220 score 0.965 lr 1.96553e-05 
09/15/2020 19:01:17 - INFO - volta.utils -   [GQA]: iter 41125 Ep: 11.16 loss 0.216 score 0.966 lr 1.96432e-05 
09/15/2020 19:03:11 - INFO - volta.utils -   [GQA]: iter 41145 Ep: 11.17 loss 0.230 score 0.963 lr 1.96311e-05 
09/15/2020 19:04:51 - INFO - volta.utils -   [GQA]: iter 41165 Ep: 11.17 loss 0.230 score 0.963 lr 1.96191e-05 
09/15/2020 19:06:38 - INFO - volta.utils -   [GQA]: iter 41185 Ep: 11.18 loss 0.237 score 0.961 lr 1.9607e-05 
09/15/2020 19:08:05 - INFO - volta.utils -   [GQA]: iter 41205 Ep: 11.18 loss 0.259 score 0.958 lr 1.95949e-05 
09/15/2020 19:09:31 - INFO - volta.utils -   [GQA]: iter 41225 Ep: 11.19 loss 0.222 score 0.965 lr 1.95829e-05 
09/15/2020 19:11:16 - INFO - volta.utils -   [GQA]: iter 41245 Ep: 11.20 loss 0.235 score 0.964 lr 1.95708e-05 
09/15/2020 19:13:09 - INFO - volta.utils -   [GQA]: iter 41265 Ep: 11.20 loss 0.225 score 0.964 lr 1.95588e-05 
09/15/2020 19:14:44 - INFO - volta.utils -   [GQA]: iter 41285 Ep: 11.21 loss 0.215 score 0.964 lr 1.95467e-05 
09/15/2020 19:16:18 - INFO - volta.utils -   [GQA]: iter 41305 Ep: 11.21 loss 0.249 score 0.961 lr 1.95346e-05 
09/15/2020 19:17:53 - INFO - volta.utils -   [GQA]: iter 41325 Ep: 11.22 loss 0.229 score 0.965 lr 1.95226e-05 
09/15/2020 19:20:23 - INFO - volta.utils -   [GQA]: iter 41345 Ep: 11.22 loss 0.229 score 0.967 lr 1.95105e-05 
09/15/2020 19:21:25 - INFO - volta.utils -   [GQA]: iter 41365 Ep: 11.23 loss 0.222 score 0.966 lr 1.94984e-05 
09/15/2020 19:22:54 - INFO - volta.utils -   [GQA]: iter 41385 Ep: 11.23 loss 0.237 score 0.962 lr 1.94864e-05 
09/15/2020 19:24:28 - INFO - volta.utils -   [GQA]: iter 41405 Ep: 11.24 loss 0.232 score 0.964 lr 1.94743e-05 
09/15/2020 19:27:11 - INFO - volta.utils -   [GQA]: iter 41425 Ep: 11.24 loss 0.250 score 0.962 lr 1.94622e-05 
09/15/2020 19:28:27 - INFO - volta.utils -   [GQA]: iter 41445 Ep: 11.25 loss 0.237 score 0.963 lr 1.94502e-05 
09/15/2020 19:30:05 - INFO - volta.utils -   [GQA]: iter 41465 Ep: 11.26 loss 0.252 score 0.957 lr 1.94381e-05 
09/15/2020 19:32:05 - INFO - volta.utils -   [GQA]: iter 41485 Ep: 11.26 loss 0.240 score 0.961 lr 1.9426e-05 
09/15/2020 19:34:12 - INFO - volta.utils -   [GQA]: iter 41505 Ep: 11.27 loss 0.254 score 0.956 lr 1.9414e-05 
09/15/2020 19:35:09 - INFO - volta.utils -   [GQA]: iter 41525 Ep: 11.27 loss 0.224 score 0.969 lr 1.94019e-05 
09/15/2020 19:36:06 - INFO - volta.utils -   [GQA]: iter 41545 Ep: 11.28 loss 0.222 score 0.966 lr 1.93899e-05 
09/15/2020 19:38:41 - INFO - volta.utils -   [GQA]: iter 41565 Ep: 11.28 loss 0.233 score 0.962 lr 1.93778e-05 
09/15/2020 19:40:31 - INFO - volta.utils -   [GQA]: iter 41585 Ep: 11.29 loss 0.241 score 0.960 lr 1.93657e-05 
09/15/2020 19:41:17 - INFO - volta.utils -   [GQA]: iter 41605 Ep: 11.29 loss 0.230 score 0.963 lr 1.93537e-05 
09/15/2020 19:42:47 - INFO - volta.utils -   [GQA]: iter 41625 Ep: 11.30 loss 0.223 score 0.966 lr 1.93416e-05 
09/15/2020 19:44:26 - INFO - volta.utils -   [GQA]: iter 41645 Ep: 11.30 loss 0.238 score 0.961 lr 1.93295e-05 
09/15/2020 19:46:39 - INFO - volta.utils -   [GQA]: iter 41665 Ep: 11.31 loss 0.242 score 0.960 lr 1.93175e-05 
09/15/2020 19:48:00 - INFO - volta.utils -   [GQA]: iter 41685 Ep: 11.32 loss 0.235 score 0.962 lr 1.93054e-05 
09/15/2020 19:49:20 - INFO - volta.utils -   [GQA]: iter 41705 Ep: 11.32 loss 0.247 score 0.960 lr 1.92933e-05 
09/15/2020 19:50:52 - INFO - volta.utils -   [GQA]: iter 41725 Ep: 11.33 loss 0.251 score 0.956 lr 1.92813e-05 
09/15/2020 19:53:04 - INFO - volta.utils -   [GQA]: iter 41745 Ep: 11.33 loss 0.227 score 0.965 lr 1.92692e-05 
09/15/2020 19:54:26 - INFO - volta.utils -   [GQA]: iter 41765 Ep: 11.34 loss 0.243 score 0.962 lr 1.92571e-05 
09/15/2020 19:55:40 - INFO - volta.utils -   [GQA]: iter 41785 Ep: 11.34 loss 0.213 score 0.969 lr 1.92451e-05 
09/15/2020 19:57:06 - INFO - volta.utils -   [GQA]: iter 41805 Ep: 11.35 loss 0.206 score 0.969 lr 1.9233e-05 
09/15/2020 19:59:18 - INFO - volta.utils -   [GQA]: iter 41825 Ep: 11.35 loss 0.259 score 0.957 lr 1.9221e-05 
09/15/2020 20:00:51 - INFO - volta.utils -   [GQA]: iter 41845 Ep: 11.36 loss 0.264 score 0.958 lr 1.92089e-05 
09/15/2020 20:02:36 - INFO - volta.utils -   [GQA]: iter 41865 Ep: 11.36 loss 0.239 score 0.960 lr 1.91968e-05 
09/15/2020 20:04:11 - INFO - volta.utils -   [GQA]: iter 41885 Ep: 11.37 loss 0.256 score 0.957 lr 1.91848e-05 
09/15/2020 20:06:33 - INFO - volta.utils -   [GQA]: iter 41905 Ep: 11.37 loss 0.231 score 0.965 lr 1.91727e-05 
09/15/2020 20:08:01 - INFO - volta.utils -   [GQA]: iter 41925 Ep: 11.38 loss 0.253 score 0.956 lr 1.91606e-05 
09/15/2020 20:09:32 - INFO - volta.utils -   [GQA]: iter 41945 Ep: 11.39 loss 0.224 score 0.963 lr 1.91486e-05 
09/15/2020 20:10:53 - INFO - volta.utils -   [GQA]: iter 41965 Ep: 11.39 loss 0.246 score 0.959 lr 1.91365e-05 
09/15/2020 20:12:58 - INFO - volta.utils -   [GQA]: iter 41985 Ep: 11.40 loss 0.233 score 0.963 lr 1.91244e-05 
09/15/2020 20:14:31 - INFO - volta.utils -   [GQA]: iter 42005 Ep: 11.40 loss 0.223 score 0.965 lr 1.91124e-05 
09/15/2020 20:16:06 - INFO - volta.utils -   [GQA]: iter 42025 Ep: 11.41 loss 0.247 score 0.959 lr 1.91003e-05 
09/15/2020 20:17:33 - INFO - volta.utils -   [GQA]: iter 42045 Ep: 11.41 loss 0.241 score 0.964 lr 1.90882e-05 
09/15/2020 20:19:31 - INFO - volta.utils -   [GQA]: iter 42065 Ep: 11.42 loss 0.250 score 0.963 lr 1.90762e-05 
09/15/2020 20:21:02 - INFO - volta.utils -   [GQA]: iter 42085 Ep: 11.42 loss 0.242 score 0.963 lr 1.90641e-05 
09/15/2020 20:22:39 - INFO - volta.utils -   [GQA]: iter 42105 Ep: 11.43 loss 0.287 score 0.952 lr 1.90521e-05 
09/15/2020 20:24:13 - INFO - volta.utils -   [GQA]: iter 42125 Ep: 11.43 loss 0.231 score 0.964 lr 1.904e-05 
09/15/2020 20:26:08 - INFO - volta.utils -   [GQA]: iter 42145 Ep: 11.44 loss 0.231 score 0.967 lr 1.90279e-05 
09/15/2020 20:27:33 - INFO - volta.utils -   [GQA]: iter 42165 Ep: 11.45 loss 0.229 score 0.963 lr 1.90159e-05 
09/15/2020 20:28:58 - INFO - volta.utils -   [GQA]: iter 42185 Ep: 11.45 loss 0.258 score 0.959 lr 1.90038e-05 
09/15/2020 20:30:23 - INFO - volta.utils -   [GQA]: iter 42205 Ep: 11.46 loss 0.223 score 0.966 lr 1.89917e-05 
09/15/2020 20:32:51 - INFO - volta.utils -   [GQA]: iter 42225 Ep: 11.46 loss 0.249 score 0.961 lr 1.89797e-05 
09/15/2020 20:34:32 - INFO - volta.utils -   [GQA]: iter 42245 Ep: 11.47 loss 0.246 score 0.961 lr 1.89676e-05 
09/15/2020 20:36:16 - INFO - volta.utils -   [GQA]: iter 42265 Ep: 11.47 loss 0.251 score 0.956 lr 1.89555e-05 
09/15/2020 20:37:47 - INFO - volta.utils -   [GQA]: iter 42285 Ep: 11.48 loss 0.254 score 0.962 lr 1.89435e-05 
09/15/2020 20:39:52 - INFO - volta.utils -   [GQA]: iter 42305 Ep: 11.48 loss 0.244 score 0.959 lr 1.89314e-05 
09/15/2020 20:41:33 - INFO - volta.utils -   [GQA]: iter 42325 Ep: 11.49 loss 0.270 score 0.954 lr 1.89194e-05 
09/15/2020 20:43:11 - INFO - volta.utils -   [GQA]: iter 42345 Ep: 11.49 loss 0.239 score 0.966 lr 1.89073e-05 
09/15/2020 20:44:46 - INFO - volta.utils -   [GQA]: iter 42365 Ep: 11.50 loss 0.218 score 0.965 lr 1.88952e-05 
09/15/2020 20:47:31 - INFO - volta.utils -   [GQA]: iter 42385 Ep: 11.51 loss 0.242 score 0.960 lr 1.88832e-05 
09/15/2020 20:48:45 - INFO - volta.utils -   [GQA]: iter 42405 Ep: 11.51 loss 0.255 score 0.960 lr 1.88711e-05 
09/15/2020 20:50:45 - INFO - volta.utils -   [GQA]: iter 42425 Ep: 11.52 loss 0.247 score 0.960 lr 1.8859e-05 
09/15/2020 20:52:29 - INFO - volta.utils -   [GQA]: iter 42445 Ep: 11.52 loss 0.250 score 0.958 lr 1.8847e-05 
09/15/2020 20:54:18 - INFO - volta.utils -   [GQA]: iter 42465 Ep: 11.53 loss 0.253 score 0.953 lr 1.88349e-05 
09/15/2020 20:55:44 - INFO - volta.utils -   [GQA]: iter 42485 Ep: 11.53 loss 0.242 score 0.960 lr 1.88228e-05 
09/15/2020 20:57:30 - INFO - volta.utils -   [GQA]: iter 42505 Ep: 11.54 loss 0.260 score 0.956 lr 1.88108e-05 
09/15/2020 20:59:00 - INFO - volta.utils -   [GQA]: iter 42525 Ep: 11.54 loss 0.258 score 0.956 lr 1.87987e-05 
09/15/2020 21:00:41 - INFO - volta.utils -   [GQA]: iter 42545 Ep: 11.55 loss 0.239 score 0.961 lr 1.87866e-05 
09/15/2020 21:02:22 - INFO - volta.utils -   [GQA]: iter 42565 Ep: 11.55 loss 0.258 score 0.954 lr 1.87746e-05 
09/15/2020 21:04:25 - INFO - volta.utils -   [GQA]: iter 42585 Ep: 11.56 loss 0.274 score 0.953 lr 1.87625e-05 
09/15/2020 21:05:55 - INFO - volta.utils -   [GQA]: iter 42605 Ep: 11.56 loss 0.250 score 0.962 lr 1.87505e-05 
09/15/2020 21:07:38 - INFO - volta.utils -   [GQA]: iter 42625 Ep: 11.57 loss 0.231 score 0.965 lr 1.87384e-05 
09/15/2020 21:09:22 - INFO - volta.utils -   [GQA]: iter 42645 Ep: 11.58 loss 0.260 score 0.952 lr 1.87263e-05 
09/15/2020 21:11:29 - INFO - volta.utils -   [GQA]: iter 42665 Ep: 11.58 loss 0.273 score 0.951 lr 1.87143e-05 
09/15/2020 21:12:58 - INFO - volta.utils -   [GQA]: iter 42685 Ep: 11.59 loss 0.249 score 0.960 lr 1.87022e-05 
09/15/2020 21:14:34 - INFO - volta.utils -   [GQA]: iter 42705 Ep: 11.59 loss 0.275 score 0.956 lr 1.86901e-05 
09/15/2020 21:16:16 - INFO - volta.utils -   [GQA]: iter 42725 Ep: 11.60 loss 0.244 score 0.961 lr 1.86781e-05 
09/15/2020 21:17:58 - INFO - volta.utils -   [GQA]: iter 42745 Ep: 11.60 loss 0.237 score 0.959 lr 1.8666e-05 
09/15/2020 21:18:38 - INFO - volta.utils -   [GQA]: iter 42765 Ep: 11.61 loss 0.281 score 0.951 lr 1.86539e-05 
09/15/2020 21:20:01 - INFO - volta.utils -   [GQA]: iter 42785 Ep: 11.61 loss 0.256 score 0.957 lr 1.86419e-05 
09/15/2020 21:22:37 - INFO - volta.utils -   [GQA]: iter 42805 Ep: 11.62 loss 0.238 score 0.958 lr 1.86298e-05 
09/15/2020 21:24:12 - INFO - volta.utils -   [GQA]: iter 42825 Ep: 11.62 loss 0.264 score 0.957 lr 1.86177e-05 
09/15/2020 21:25:25 - INFO - volta.utils -   [GQA]: iter 42845 Ep: 11.63 loss 0.275 score 0.954 lr 1.86057e-05 
09/15/2020 21:26:49 - INFO - volta.utils -   [GQA]: iter 42865 Ep: 11.64 loss 0.278 score 0.955 lr 1.85936e-05 
09/15/2020 21:29:32 - INFO - volta.utils -   [GQA]: iter 42885 Ep: 11.64 loss 0.238 score 0.962 lr 1.85816e-05 
09/15/2020 21:31:12 - INFO - volta.utils -   [GQA]: iter 42905 Ep: 11.65 loss 0.246 score 0.960 lr 1.85695e-05 
09/15/2020 21:32:36 - INFO - volta.utils -   [GQA]: iter 42925 Ep: 11.65 loss 0.231 score 0.963 lr 1.85574e-05 
09/15/2020 21:33:44 - INFO - volta.utils -   [GQA]: iter 42945 Ep: 11.66 loss 0.238 score 0.962 lr 1.85454e-05 
09/15/2020 21:36:41 - INFO - volta.utils -   [GQA]: iter 42965 Ep: 11.66 loss 0.238 score 0.963 lr 1.85333e-05 
09/15/2020 21:38:23 - INFO - volta.utils -   [GQA]: iter 42985 Ep: 11.67 loss 0.265 score 0.957 lr 1.85212e-05 
09/15/2020 21:40:02 - INFO - volta.utils -   [GQA]: iter 43005 Ep: 11.67 loss 0.238 score 0.962 lr 1.85092e-05 
09/15/2020 21:41:29 - INFO - volta.utils -   [GQA]: iter 43025 Ep: 11.68 loss 0.262 score 0.958 lr 1.84971e-05 
09/15/2020 21:44:14 - INFO - volta.utils -   [GQA]: iter 43045 Ep: 11.68 loss 0.249 score 0.956 lr 1.8485e-05 
09/15/2020 21:45:28 - INFO - volta.utils -   [GQA]: iter 43065 Ep: 11.69 loss 0.248 score 0.959 lr 1.8473e-05 
09/15/2020 21:46:37 - INFO - volta.utils -   [GQA]: iter 43085 Ep: 11.70 loss 0.244 score 0.959 lr 1.84609e-05 
09/15/2020 21:48:01 - INFO - volta.utils -   [GQA]: iter 43105 Ep: 11.70 loss 0.257 score 0.957 lr 1.84488e-05 
09/15/2020 21:49:39 - INFO - volta.utils -   [GQA]: iter 43125 Ep: 11.71 loss 0.251 score 0.959 lr 1.84368e-05 
09/15/2020 21:51:26 - INFO - volta.utils -   [GQA]: iter 43145 Ep: 11.71 loss 0.252 score 0.960 lr 1.84247e-05 
09/15/2020 21:53:53 - INFO - volta.utils -   [GQA]: iter 43165 Ep: 11.72 loss 0.277 score 0.950 lr 1.84127e-05 
09/15/2020 21:55:20 - INFO - volta.utils -   [GQA]: iter 43185 Ep: 11.72 loss 0.239 score 0.963 lr 1.84006e-05 
09/15/2020 21:56:38 - INFO - volta.utils -   [GQA]: iter 43205 Ep: 11.73 loss 0.241 score 0.963 lr 1.83885e-05 
09/15/2020 21:58:11 - INFO - volta.utils -   [GQA]: iter 43225 Ep: 11.73 loss 0.252 score 0.960 lr 1.83765e-05 
09/15/2020 22:00:58 - INFO - volta.utils -   [GQA]: iter 43245 Ep: 11.74 loss 0.235 score 0.962 lr 1.83644e-05 
09/15/2020 22:01:51 - INFO - volta.utils -   [GQA]: iter 43265 Ep: 11.74 loss 0.253 score 0.959 lr 1.83523e-05 
09/15/2020 22:03:22 - INFO - volta.utils -   [GQA]: iter 43285 Ep: 11.75 loss 0.265 score 0.955 lr 1.83403e-05 
09/15/2020 22:05:13 - INFO - volta.utils -   [GQA]: iter 43305 Ep: 11.75 loss 0.246 score 0.959 lr 1.83282e-05 
09/15/2020 22:07:19 - INFO - volta.utils -   [GQA]: iter 43325 Ep: 11.76 loss 0.270 score 0.954 lr 1.83161e-05 
09/15/2020 22:08:38 - INFO - volta.utils -   [GQA]: iter 43345 Ep: 11.77 loss 0.262 score 0.958 lr 1.83041e-05 
09/15/2020 22:10:09 - INFO - volta.utils -   [GQA]: iter 43365 Ep: 11.77 loss 0.253 score 0.960 lr 1.8292e-05 
09/15/2020 22:12:12 - INFO - volta.utils -   [GQA]: iter 43385 Ep: 11.78 loss 0.278 score 0.955 lr 1.82799e-05 
09/15/2020 22:13:53 - INFO - volta.utils -   [GQA]: iter 43405 Ep: 11.78 loss 0.254 score 0.958 lr 1.82679e-05 
09/15/2020 22:15:01 - INFO - volta.utils -   [GQA]: iter 43425 Ep: 11.79 loss 0.258 score 0.956 lr 1.82558e-05 
09/15/2020 22:16:41 - INFO - volta.utils -   [GQA]: iter 43445 Ep: 11.79 loss 0.263 score 0.958 lr 1.82438e-05 
09/15/2020 22:18:16 - INFO - volta.utils -   [GQA]: iter 43465 Ep: 11.80 loss 0.270 score 0.952 lr 1.82317e-05 
09/15/2020 22:19:54 - INFO - volta.utils -   [GQA]: iter 43485 Ep: 11.80 loss 0.241 score 0.963 lr 1.82196e-05 
09/15/2020 22:21:00 - INFO - volta.utils -   [GQA]: iter 43505 Ep: 11.81 loss 0.262 score 0.954 lr 1.82076e-05 
09/15/2020 22:23:46 - INFO - volta.utils -   [GQA]: iter 43525 Ep: 11.81 loss 0.226 score 0.964 lr 1.81955e-05 
09/15/2020 22:25:35 - INFO - volta.utils -   [GQA]: iter 43545 Ep: 11.82 loss 0.249 score 0.958 lr 1.81834e-05 
09/15/2020 22:27:08 - INFO - volta.utils -   [GQA]: iter 43565 Ep: 11.83 loss 0.257 score 0.957 lr 1.81714e-05 
09/15/2020 22:28:27 - INFO - volta.utils -   [GQA]: iter 43585 Ep: 11.83 loss 0.259 score 0.959 lr 1.81593e-05 
09/15/2020 22:30:51 - INFO - volta.utils -   [GQA]: iter 43605 Ep: 11.84 loss 0.258 score 0.959 lr 1.81472e-05 
09/15/2020 22:32:18 - INFO - volta.utils -   [GQA]: iter 43625 Ep: 11.84 loss 0.242 score 0.960 lr 1.81352e-05 
09/15/2020 22:33:55 - INFO - volta.utils -   [GQA]: iter 43645 Ep: 11.85 loss 0.265 score 0.959 lr 1.81231e-05 
09/15/2020 22:35:36 - INFO - volta.utils -   [GQA]: iter 43665 Ep: 11.85 loss 0.247 score 0.959 lr 1.81111e-05 
09/15/2020 22:37:36 - INFO - volta.utils -   [GQA]: iter 43685 Ep: 11.86 loss 0.266 score 0.955 lr 1.8099e-05 
09/15/2020 22:38:53 - INFO - volta.utils -   [GQA]: iter 43705 Ep: 11.86 loss 0.258 score 0.957 lr 1.80869e-05 
09/15/2020 22:40:26 - INFO - volta.utils -   [GQA]: iter 43725 Ep: 11.87 loss 0.250 score 0.958 lr 1.80749e-05 
09/15/2020 22:41:53 - INFO - volta.utils -   [GQA]: iter 43745 Ep: 11.87 loss 0.258 score 0.958 lr 1.80628e-05 
09/15/2020 22:44:25 - INFO - volta.utils -   [GQA]: iter 43765 Ep: 11.88 loss 0.242 score 0.959 lr 1.80507e-05 
09/15/2020 22:45:41 - INFO - volta.utils -   [GQA]: iter 43785 Ep: 11.89 loss 0.239 score 0.959 lr 1.80387e-05 
09/15/2020 22:47:29 - INFO - volta.utils -   [GQA]: iter 43805 Ep: 11.89 loss 0.275 score 0.954 lr 1.80266e-05 
09/15/2020 22:48:42 - INFO - volta.utils -   [GQA]: iter 43825 Ep: 11.90 loss 0.250 score 0.960 lr 1.80145e-05 
09/15/2020 22:50:55 - INFO - volta.utils -   [GQA]: iter 43845 Ep: 11.90 loss 0.262 score 0.956 lr 1.80025e-05 
09/15/2020 22:52:37 - INFO - volta.utils -   [GQA]: iter 43865 Ep: 11.91 loss 0.253 score 0.958 lr 1.79904e-05 
09/15/2020 22:53:46 - INFO - volta.utils -   [GQA]: iter 43885 Ep: 11.91 loss 0.239 score 0.963 lr 1.79783e-05 
09/15/2020 22:55:31 - INFO - volta.utils -   [GQA]: iter 43905 Ep: 11.92 loss 0.237 score 0.963 lr 1.79663e-05 
09/15/2020 22:57:12 - INFO - volta.utils -   [GQA]: iter 43925 Ep: 11.92 loss 0.233 score 0.963 lr 1.79542e-05 
09/15/2020 22:58:48 - INFO - volta.utils -   [GQA]: iter 43945 Ep: 11.93 loss 0.241 score 0.957 lr 1.79422e-05 
09/15/2020 22:59:57 - INFO - volta.utils -   [GQA]: iter 43965 Ep: 11.93 loss 0.266 score 0.957 lr 1.79301e-05 
09/15/2020 23:01:45 - INFO - volta.utils -   [GQA]: iter 43985 Ep: 11.94 loss 0.259 score 0.958 lr 1.7918e-05 
09/15/2020 23:03:50 - INFO - volta.utils -   [GQA]: iter 44005 Ep: 11.94 loss 0.256 score 0.959 lr 1.7906e-05 
09/15/2020 23:05:38 - INFO - volta.utils -   [GQA]: iter 44025 Ep: 11.95 loss 0.278 score 0.953 lr 1.78939e-05 
09/15/2020 23:07:19 - INFO - volta.utils -   [GQA]: iter 44045 Ep: 11.96 loss 0.238 score 0.959 lr 1.78818e-05 
09/15/2020 23:08:48 - INFO - volta.utils -   [GQA]: iter 44065 Ep: 11.96 loss 0.252 score 0.956 lr 1.78698e-05 
09/15/2020 23:10:43 - INFO - volta.utils -   [GQA]: iter 44085 Ep: 11.97 loss 0.287 score 0.953 lr 1.78577e-05 
09/15/2020 23:12:49 - INFO - volta.utils -   [GQA]: iter 44105 Ep: 11.97 loss 0.267 score 0.957 lr 1.78456e-05 
09/15/2020 23:14:22 - INFO - volta.utils -   [GQA]: iter 44125 Ep: 11.98 loss 0.231 score 0.962 lr 1.78336e-05 
09/15/2020 23:16:14 - INFO - volta.utils -   [GQA]: iter 44145 Ep: 11.98 loss 0.260 score 0.956 lr 1.78215e-05 
09/15/2020 23:17:31 - INFO - volta.utils -   [GQA]: iter 44165 Ep: 11.99 loss 0.260 score 0.957 lr 1.78094e-05 
09/15/2020 23:19:18 - INFO - volta.utils -   [GQA]: iter 44185 Ep: 11.99 loss 0.249 score 0.961 lr 1.77974e-05 
09/15/2020 23:20:34 - INFO - volta.utils -   [GQA]: iter 44205 Ep: 12.00 loss 0.250 score 0.958 lr 1.77853e-05 
09/15/2020 23:20:36 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  33%|      | 4/12 [22:00:49<43:51:33, 19736.65s/it]09/15/2020 23:39:53 - INFO - volta.utils -   Eval task TASK15 on iteration 44209 
09/15/2020 23:39:53 - INFO - volta.utils -   Validation [GQA]: loss 3.173 score 64.248 
09/15/2020 23:40:05 - INFO - volta.utils -   [GQA]: iter 44229 Ep: 12.01 loss 0.290 score 0.953 lr 1.7772e-05 
09/15/2020 23:41:25 - INFO - volta.utils -   [GQA]: iter 44249 Ep: 12.01 loss 0.305 score 0.950 lr 1.77588e-05 
09/15/2020 23:42:44 - INFO - volta.utils -   [GQA]: iter 44269 Ep: 12.02 loss 0.304 score 0.950 lr 1.77467e-05 
09/15/2020 23:43:45 - INFO - volta.utils -   [GQA]: iter 44289 Ep: 12.02 loss 0.299 score 0.949 lr 1.77346e-05 
09/15/2020 23:45:59 - INFO - volta.utils -   [GQA]: iter 44309 Ep: 12.03 loss 0.316 score 0.945 lr 1.77226e-05 
09/15/2020 23:47:02 - INFO - volta.utils -   [GQA]: iter 44329 Ep: 12.03 loss 0.312 score 0.949 lr 1.77105e-05 
09/15/2020 23:48:32 - INFO - volta.utils -   [GQA]: iter 44349 Ep: 12.04 loss 0.326 score 0.945 lr 1.76985e-05 
09/15/2020 23:49:59 - INFO - volta.utils -   [GQA]: iter 44369 Ep: 12.04 loss 0.304 score 0.950 lr 1.76864e-05 
09/15/2020 23:52:25 - INFO - volta.utils -   [GQA]: iter 44389 Ep: 12.05 loss 0.303 score 0.951 lr 1.76743e-05 
09/15/2020 23:53:47 - INFO - volta.utils -   [GQA]: iter 44409 Ep: 12.05 loss 0.312 score 0.948 lr 1.76623e-05 
09/15/2020 23:55:15 - INFO - volta.utils -   [GQA]: iter 44429 Ep: 12.06 loss 0.299 score 0.951 lr 1.76502e-05 
09/15/2020 23:56:37 - INFO - volta.utils -   [GQA]: iter 44449 Ep: 12.07 loss 0.323 score 0.945 lr 1.76381e-05 
09/15/2020 23:59:32 - INFO - volta.utils -   [GQA]: iter 44469 Ep: 12.07 loss 0.314 score 0.951 lr 1.76261e-05 
09/16/2020 00:00:40 - INFO - volta.utils -   [GQA]: iter 44489 Ep: 12.08 loss 0.284 score 0.954 lr 1.7614e-05 
09/16/2020 00:01:59 - INFO - volta.utils -   [GQA]: iter 44509 Ep: 12.08 loss 0.337 score 0.944 lr 1.76019e-05 
09/16/2020 00:03:19 - INFO - volta.utils -   [GQA]: iter 44529 Ep: 12.09 loss 0.315 score 0.947 lr 1.75899e-05 
09/16/2020 00:05:52 - INFO - volta.utils -   [GQA]: iter 44549 Ep: 12.09 loss 0.318 score 0.948 lr 1.75778e-05 
09/16/2020 00:07:16 - INFO - volta.utils -   [GQA]: iter 44569 Ep: 12.10 loss 0.321 score 0.945 lr 1.75657e-05 
09/16/2020 00:08:31 - INFO - volta.utils -   [GQA]: iter 44589 Ep: 12.10 loss 0.337 score 0.941 lr 1.75537e-05 
09/16/2020 00:09:47 - INFO - volta.utils -   [GQA]: iter 44609 Ep: 12.11 loss 0.298 score 0.950 lr 1.75416e-05 
09/16/2020 00:12:10 - INFO - volta.utils -   [GQA]: iter 44629 Ep: 12.11 loss 0.334 score 0.946 lr 1.75296e-05 
09/16/2020 00:13:43 - INFO - volta.utils -   [GQA]: iter 44649 Ep: 12.12 loss 0.330 score 0.945 lr 1.75175e-05 
09/16/2020 00:15:02 - INFO - volta.utils -   [GQA]: iter 44669 Ep: 12.13 loss 0.309 score 0.950 lr 1.75054e-05 
09/16/2020 00:17:14 - INFO - volta.utils -   [GQA]: iter 44689 Ep: 12.13 loss 0.326 score 0.942 lr 1.74934e-05 
09/16/2020 00:19:22 - INFO - volta.utils -   [GQA]: iter 44709 Ep: 12.14 loss 0.303 score 0.950 lr 1.74813e-05 
09/16/2020 00:21:11 - INFO - volta.utils -   [GQA]: iter 44729 Ep: 12.14 loss 0.313 score 0.946 lr 1.74692e-05 
09/16/2020 00:23:02 - INFO - volta.utils -   [GQA]: iter 44749 Ep: 12.15 loss 0.314 score 0.948 lr 1.74572e-05 
09/16/2020 00:24:30 - INFO - volta.utils -   [GQA]: iter 44769 Ep: 12.15 loss 0.321 score 0.947 lr 1.74451e-05 
09/16/2020 00:27:32 - INFO - volta.utils -   [GQA]: iter 44789 Ep: 12.16 loss 0.327 score 0.944 lr 1.7433e-05 
09/16/2020 00:28:58 - INFO - volta.utils -   [GQA]: iter 44809 Ep: 12.16 loss 0.334 score 0.943 lr 1.7421e-05 
09/16/2020 00:30:25 - INFO - volta.utils -   [GQA]: iter 44829 Ep: 12.17 loss 0.307 score 0.950 lr 1.74089e-05 
09/16/2020 00:32:08 - INFO - volta.utils -   [GQA]: iter 44849 Ep: 12.17 loss 0.295 score 0.951 lr 1.73969e-05 
09/16/2020 00:34:40 - INFO - volta.utils -   [GQA]: iter 44869 Ep: 12.18 loss 0.301 score 0.949 lr 1.73848e-05 
09/16/2020 00:35:40 - INFO - volta.utils -   [GQA]: iter 44889 Ep: 12.18 loss 0.329 score 0.944 lr 1.73727e-05 
09/16/2020 00:37:10 - INFO - volta.utils -   [GQA]: iter 44909 Ep: 12.19 loss 0.313 score 0.946 lr 1.73607e-05 
09/16/2020 00:38:38 - INFO - volta.utils -   [GQA]: iter 44929 Ep: 12.20 loss 0.315 score 0.946 lr 1.73486e-05 
09/16/2020 00:41:33 - INFO - volta.utils -   [GQA]: iter 44949 Ep: 12.20 loss 0.331 score 0.945 lr 1.73365e-05 
09/16/2020 00:42:45 - INFO - volta.utils -   [GQA]: iter 44969 Ep: 12.21 loss 0.315 score 0.946 lr 1.73245e-05 
09/16/2020 00:44:10 - INFO - volta.utils -   [GQA]: iter 44989 Ep: 12.21 loss 0.331 score 0.944 lr 1.73124e-05 
09/16/2020 00:45:45 - INFO - volta.utils -   [GQA]: iter 45009 Ep: 12.22 loss 0.321 score 0.946 lr 1.73003e-05 
09/16/2020 00:48:27 - INFO - volta.utils -   [GQA]: iter 45029 Ep: 12.22 loss 0.315 score 0.948 lr 1.72883e-05 
09/16/2020 00:50:00 - INFO - volta.utils -   [GQA]: iter 45049 Ep: 12.23 loss 0.342 score 0.942 lr 1.72762e-05 
09/16/2020 00:51:32 - INFO - volta.utils -   [GQA]: iter 45069 Ep: 12.23 loss 0.324 score 0.944 lr 1.72641e-05 
09/16/2020 00:53:06 - INFO - volta.utils -   [GQA]: iter 45089 Ep: 12.24 loss 0.307 score 0.950 lr 1.72521e-05 
09/16/2020 00:55:19 - INFO - volta.utils -   [GQA]: iter 45109 Ep: 12.24 loss 0.307 score 0.948 lr 1.724e-05 
09/16/2020 00:57:05 - INFO - volta.utils -   [GQA]: iter 45129 Ep: 12.25 loss 0.325 score 0.946 lr 1.7228e-05 
09/16/2020 00:58:37 - INFO - volta.utils -   [GQA]: iter 45149 Ep: 12.26 loss 0.315 score 0.944 lr 1.72159e-05 
09/16/2020 01:00:19 - INFO - volta.utils -   [GQA]: iter 45169 Ep: 12.26 loss 0.327 score 0.946 lr 1.72038e-05 
09/16/2020 01:03:01 - INFO - volta.utils -   [GQA]: iter 45189 Ep: 12.27 loss 0.325 score 0.943 lr 1.71918e-05 
09/16/2020 01:04:32 - INFO - volta.utils -   [GQA]: iter 45209 Ep: 12.27 loss 0.337 score 0.940 lr 1.71797e-05 
09/16/2020 01:06:09 - INFO - volta.utils -   [GQA]: iter 45229 Ep: 12.28 loss 0.317 score 0.951 lr 1.71676e-05 
09/16/2020 01:07:35 - INFO - volta.utils -   [GQA]: iter 45249 Ep: 12.28 loss 0.342 score 0.939 lr 1.71556e-05 
09/16/2020 01:10:02 - INFO - volta.utils -   [GQA]: iter 45269 Ep: 12.29 loss 0.330 score 0.944 lr 1.71435e-05 
