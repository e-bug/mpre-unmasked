/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
09/13/2020 19:44:29 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
09/13/2020 19:44:31 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/13/2020 19:44:32 - INFO - volta.task_utils -   Loading GQA Dataset with batch size 256
09/13/2020 19:44:32 - INFO - volta.datasets.gqa_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/gqa/cache/GQA_train_26.pkl
09/13/2020 19:49:24 - INFO - volta.datasets.gqa_dataset -   Loading from /gs/hs0/tgb-deepmt/bugliarello.e/data/gqa/cache/GQA_val_26.pkl
09/13/2020 19:50:07 - INFO - volta.utils -   logging file at: ../../logs/volta/gqa/GQA_vilbert_base
09/13/2020 19:50:10 - INFO - volta.utils -   loading weights file /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/volta/vilbert/vilbert_base/pytorch_model_9.bin
09/13/2020 19:50:16 - INFO - volta.utils -   
09/13/2020 19:50:17 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK15.logit_fc.0.weight', 'clfs_dict.TASK15.logit_fc.0.bias', 'clfs_dict.TASK15.logit_fc.2.weight', 'clfs_dict.TASK15.logit_fc.2.bias', 'clfs_dict.TASK15.logit_fc.3.weight', 'clfs_dict.TASK15.logit_fc.3.bias']
09/13/2020 19:50:17 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLTasks: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
09/13/2020 19:50:27 - INFO - __main__ -   >> Trainable Parameters:
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(1024, 2048)    |2097152     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(1024, 5)       |5120        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.weight                           |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.bias                             |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.bias                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.bias              |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.bias                      |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                   |torch.float32    |(1024, 1024)    |1048576     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.0.weight                           |torch.float32    |(1536, 1024)    |1572864     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.0.bias                             |torch.float32    |(1536,)         |1536        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.2.weight                           |torch.float32    |(1536,)         |1536        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.2.bias                             |torch.float32    |(1536,)         |1536        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.3.weight                           |torch.float32    |(1842, 1536)    |2829312     |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   |module.clfs_dict.TASK15.logit_fc.3.bias                             |torch.float32    |(1842,)         |1842        |
09/13/2020 19:50:27 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
09/13/2020 19:50:27 - INFO - __main__ -   >> # TrainableParams:       	240.11	M
09/13/2020 19:50:27 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
09/13/2020 19:50:27 - INFO - __main__ -   >> # TotalParams:           	240.11	M

Epoch:   0%|          | 0/16 [00:00<?, ?it/s]09/13/2020 20:11:04 - INFO - volta.utils -   Eval task TASK15 on iteration 14737 
09/13/2020 20:11:04 - INFO - volta.utils -   Validation [GQA]: loss 1.821 score 63.530 
09/13/2020 20:11:17 - INFO - volta.utils -   [GQA]: iter 14757 Ep: 4.01 loss 1.500 score 0.697 lr 3.55498e-05 
09/13/2020 20:12:47 - INFO - volta.utils -   [GQA]: iter 14777 Ep: 4.01 loss 1.397 score 0.710 lr 3.55366e-05 
09/13/2020 20:14:19 - INFO - volta.utils -   [GQA]: iter 14797 Ep: 4.02 loss 1.425 score 0.708 lr 3.55245e-05 
09/13/2020 20:15:32 - INFO - volta.utils -   [GQA]: iter 14817 Ep: 4.02 loss 1.436 score 0.705 lr 3.55124e-05 
09/13/2020 20:16:48 - INFO - volta.utils -   [GQA]: iter 14837 Ep: 4.03 loss 1.437 score 0.715 lr 3.55004e-05 
09/13/2020 20:18:11 - INFO - volta.utils -   [GQA]: iter 14857 Ep: 4.03 loss 1.398 score 0.713 lr 3.54883e-05 
09/13/2020 20:18:43 - INFO - volta.utils -   [GQA]: iter 14877 Ep: 4.04 loss 1.440 score 0.704 lr 3.54762e-05 
09/13/2020 20:20:04 - INFO - volta.utils -   [GQA]: iter 14897 Ep: 4.04 loss 1.397 score 0.723 lr 3.54642e-05 
09/13/2020 20:22:03 - INFO - volta.utils -   [GQA]: iter 14917 Ep: 4.05 loss 1.446 score 0.711 lr 3.54521e-05 
09/13/2020 20:23:49 - INFO - volta.utils -   [GQA]: iter 14937 Ep: 4.05 loss 1.400 score 0.715 lr 3.544e-05 
09/13/2020 20:25:12 - INFO - volta.utils -   [GQA]: iter 14957 Ep: 4.06 loss 1.452 score 0.708 lr 3.5428e-05 
09/13/2020 20:26:52 - INFO - volta.utils -   [GQA]: iter 14977 Ep: 4.07 loss 1.439 score 0.712 lr 3.54159e-05 
09/13/2020 20:29:29 - INFO - volta.utils -   [GQA]: iter 14997 Ep: 4.07 loss 1.475 score 0.705 lr 3.54038e-05 
09/13/2020 20:30:43 - INFO - volta.utils -   [GQA]: iter 15017 Ep: 4.08 loss 1.388 score 0.720 lr 3.53918e-05 
09/13/2020 20:32:24 - INFO - volta.utils -   [GQA]: iter 15037 Ep: 4.08 loss 1.441 score 0.700 lr 3.53797e-05 
09/13/2020 20:33:47 - INFO - volta.utils -   [GQA]: iter 15057 Ep: 4.09 loss 1.431 score 0.715 lr 3.53677e-05 
09/13/2020 20:36:16 - INFO - volta.utils -   [GQA]: iter 15077 Ep: 4.09 loss 1.427 score 0.724 lr 3.53556e-05 
09/13/2020 20:37:24 - INFO - volta.utils -   [GQA]: iter 15097 Ep: 4.10 loss 1.418 score 0.715 lr 3.53435e-05 
09/13/2020 20:38:48 - INFO - volta.utils -   [GQA]: iter 15117 Ep: 4.10 loss 1.425 score 0.707 lr 3.53315e-05 
09/13/2020 20:40:55 - INFO - volta.utils -   [GQA]: iter 15137 Ep: 4.11 loss 1.417 score 0.704 lr 3.53194e-05 
09/13/2020 20:42:42 - INFO - volta.utils -   [GQA]: iter 15157 Ep: 4.11 loss 1.446 score 0.704 lr 3.53073e-05 
09/13/2020 20:43:56 - INFO - volta.utils -   [GQA]: iter 15177 Ep: 4.12 loss 1.464 score 0.700 lr 3.52953e-05 
09/13/2020 20:45:27 - INFO - volta.utils -   [GQA]: iter 15197 Ep: 4.13 loss 1.409 score 0.713 lr 3.52832e-05 
09/13/2020 20:48:15 - INFO - volta.utils -   [GQA]: iter 15217 Ep: 4.13 loss 1.449 score 0.709 lr 3.52711e-05 
09/13/2020 20:49:43 - INFO - volta.utils -   [GQA]: iter 15237 Ep: 4.14 loss 1.422 score 0.712 lr 3.52591e-05 
09/13/2020 20:50:58 - INFO - volta.utils -   [GQA]: iter 15257 Ep: 4.14 loss 1.470 score 0.704 lr 3.5247e-05 
09/13/2020 20:52:32 - INFO - volta.utils -   [GQA]: iter 15277 Ep: 4.15 loss 1.405 score 0.712 lr 3.52349e-05 
09/13/2020 20:55:11 - INFO - volta.utils -   [GQA]: iter 15297 Ep: 4.15 loss 1.468 score 0.701 lr 3.52229e-05 
09/13/2020 20:56:14 - INFO - volta.utils -   [GQA]: iter 15317 Ep: 4.16 loss 1.418 score 0.715 lr 3.52108e-05 
09/13/2020 20:57:43 - INFO - volta.utils -   [GQA]: iter 15337 Ep: 4.16 loss 1.415 score 0.715 lr 3.51988e-05 
09/13/2020 20:59:19 - INFO - volta.utils -   [GQA]: iter 15357 Ep: 4.17 loss 1.423 score 0.716 lr 3.51867e-05 
09/13/2020 21:02:19 - INFO - volta.utils -   [GQA]: iter 15377 Ep: 4.17 loss 1.447 score 0.713 lr 3.51746e-05 
09/13/2020 21:03:44 - INFO - volta.utils -   [GQA]: iter 15397 Ep: 4.18 loss 1.425 score 0.711 lr 3.51626e-05 
09/13/2020 21:05:19 - INFO - volta.utils -   [GQA]: iter 15417 Ep: 4.18 loss 1.493 score 0.696 lr 3.51505e-05 
09/13/2020 21:06:26 - INFO - volta.utils -   [GQA]: iter 15437 Ep: 4.19 loss 1.440 score 0.711 lr 3.51384e-05 
09/13/2020 21:08:50 - INFO - volta.utils -   [GQA]: iter 15457 Ep: 4.20 loss 1.441 score 0.706 lr 3.51264e-05 
09/13/2020 21:10:47 - INFO - volta.utils -   [GQA]: iter 15477 Ep: 4.20 loss 1.415 score 0.717 lr 3.51143e-05 
09/13/2020 21:12:04 - INFO - volta.utils -   [GQA]: iter 15497 Ep: 4.21 loss 1.447 score 0.704 lr 3.51022e-05 
09/13/2020 21:13:02 - INFO - volta.utils -   [GQA]: iter 15517 Ep: 4.21 loss 1.448 score 0.710 lr 3.50902e-05 
09/13/2020 21:14:49 - INFO - volta.utils -   [GQA]: iter 15537 Ep: 4.22 loss 1.374 score 0.724 lr 3.50781e-05 
09/13/2020 21:16:57 - INFO - volta.utils -   [GQA]: iter 15557 Ep: 4.22 loss 1.399 score 0.717 lr 3.50661e-05 
09/13/2020 21:18:46 - INFO - volta.utils -   [GQA]: iter 15577 Ep: 4.23 loss 1.454 score 0.704 lr 3.5054e-05 
09/13/2020 21:19:45 - INFO - volta.utils -   [GQA]: iter 15597 Ep: 4.23 loss 1.465 score 0.710 lr 3.50419e-05 
09/13/2020 21:20:58 - INFO - volta.utils -   [GQA]: iter 15617 Ep: 4.24 loss 1.389 score 0.726 lr 3.50299e-05 
09/13/2020 21:22:40 - INFO - volta.utils -   [GQA]: iter 15637 Ep: 4.24 loss 1.410 score 0.714 lr 3.50178e-05 
09/13/2020 21:24:23 - INFO - volta.utils -   [GQA]: iter 15657 Ep: 4.25 loss 1.435 score 0.711 lr 3.50057e-05 
09/13/2020 21:25:53 - INFO - volta.utils -   [GQA]: iter 15677 Ep: 4.26 loss 1.410 score 0.719 lr 3.49937e-05 
09/13/2020 21:27:49 - INFO - volta.utils -   [GQA]: iter 15697 Ep: 4.26 loss 1.410 score 0.717 lr 3.49816e-05 
09/13/2020 21:29:32 - INFO - volta.utils -   [GQA]: iter 15717 Ep: 4.27 loss 1.402 score 0.716 lr 3.49695e-05 
09/13/2020 21:31:07 - INFO - volta.utils -   [GQA]: iter 15737 Ep: 4.27 loss 1.382 score 0.719 lr 3.49575e-05 
09/13/2020 21:33:05 - INFO - volta.utils -   [GQA]: iter 15757 Ep: 4.28 loss 1.421 score 0.713 lr 3.49454e-05 
09/13/2020 21:35:50 - INFO - volta.utils -   [GQA]: iter 15777 Ep: 4.28 loss 1.412 score 0.704 lr 3.49333e-05 
09/13/2020 21:37:09 - INFO - volta.utils -   [GQA]: iter 15797 Ep: 4.29 loss 1.374 score 0.717 lr 3.49213e-05 
09/13/2020 21:38:37 - INFO - volta.utils -   [GQA]: iter 15817 Ep: 4.29 loss 1.425 score 0.712 lr 3.49092e-05 
09/13/2020 21:40:14 - INFO - volta.utils -   [GQA]: iter 15837 Ep: 4.30 loss 1.440 score 0.710 lr 3.48972e-05 
09/13/2020 21:43:18 - INFO - volta.utils -   [GQA]: iter 15857 Ep: 4.30 loss 1.441 score 0.705 lr 3.48851e-05 
09/13/2020 21:44:40 - INFO - volta.utils -   [GQA]: iter 15877 Ep: 4.31 loss 1.428 score 0.710 lr 3.4873e-05 
09/13/2020 21:45:57 - INFO - volta.utils -   [GQA]: iter 15897 Ep: 4.32 loss 1.414 score 0.714 lr 3.4861e-05 
09/13/2020 21:47:37 - INFO - volta.utils -   [GQA]: iter 15917 Ep: 4.32 loss 1.402 score 0.719 lr 3.48489e-05 
09/13/2020 21:50:03 - INFO - volta.utils -   [GQA]: iter 15937 Ep: 4.33 loss 1.379 score 0.719 lr 3.48368e-05 
09/13/2020 21:51:36 - INFO - volta.utils -   [GQA]: iter 15957 Ep: 4.33 loss 1.438 score 0.714 lr 3.48248e-05 
09/13/2020 21:53:18 - INFO - volta.utils -   [GQA]: iter 15977 Ep: 4.34 loss 1.451 score 0.707 lr 3.48127e-05 
09/13/2020 21:54:38 - INFO - volta.utils -   [GQA]: iter 15997 Ep: 4.34 loss 1.409 score 0.715 lr 3.48006e-05 
09/13/2020 21:57:01 - INFO - volta.utils -   [GQA]: iter 16017 Ep: 4.35 loss 1.408 score 0.715 lr 3.47886e-05 
09/13/2020 21:58:34 - INFO - volta.utils -   [GQA]: iter 16037 Ep: 4.35 loss 1.432 score 0.713 lr 3.47765e-05 
09/13/2020 22:00:06 - INFO - volta.utils -   [GQA]: iter 16057 Ep: 4.36 loss 1.439 score 0.707 lr 3.47644e-05 
09/13/2020 22:01:56 - INFO - volta.utils -   [GQA]: iter 16077 Ep: 4.36 loss 1.429 score 0.709 lr 3.47524e-05 
09/13/2020 22:04:44 - INFO - volta.utils -   [GQA]: iter 16097 Ep: 4.37 loss 1.367 score 0.733 lr 3.47403e-05 
09/13/2020 22:06:05 - INFO - volta.utils -   [GQA]: iter 16117 Ep: 4.37 loss 1.399 score 0.717 lr 3.47283e-05 
09/13/2020 22:07:16 - INFO - volta.utils -   [GQA]: iter 16137 Ep: 4.38 loss 1.390 score 0.715 lr 3.47162e-05 
09/13/2020 22:08:51 - INFO - volta.utils -   [GQA]: iter 16157 Ep: 4.39 loss 1.388 score 0.710 lr 3.47041e-05 
09/13/2020 22:10:50 - INFO - volta.utils -   [GQA]: iter 16177 Ep: 4.39 loss 1.398 score 0.719 lr 3.46921e-05 
09/13/2020 22:12:20 - INFO - volta.utils -   [GQA]: iter 16197 Ep: 4.40 loss 1.403 score 0.714 lr 3.468e-05 
09/13/2020 22:13:56 - INFO - volta.utils -   [GQA]: iter 16217 Ep: 4.40 loss 1.437 score 0.711 lr 3.46679e-05 
09/13/2020 22:15:33 - INFO - volta.utils -   [GQA]: iter 16237 Ep: 4.41 loss 1.399 score 0.715 lr 3.46559e-05 
09/13/2020 22:18:21 - INFO - volta.utils -   [GQA]: iter 16257 Ep: 4.41 loss 1.363 score 0.722 lr 3.46438e-05 
09/13/2020 22:19:27 - INFO - volta.utils -   [GQA]: iter 16277 Ep: 4.42 loss 1.392 score 0.726 lr 3.46317e-05 
09/13/2020 22:20:50 - INFO - volta.utils -   [GQA]: iter 16297 Ep: 4.42 loss 1.392 score 0.711 lr 3.46197e-05 
09/13/2020 22:22:28 - INFO - volta.utils -   [GQA]: iter 16317 Ep: 4.43 loss 1.437 score 0.704 lr 3.46076e-05 
09/13/2020 22:25:25 - INFO - volta.utils -   [GQA]: iter 16337 Ep: 4.43 loss 1.417 score 0.707 lr 3.45955e-05 
09/13/2020 22:26:44 - INFO - volta.utils -   [GQA]: iter 16357 Ep: 4.44 loss 1.378 score 0.722 lr 3.45835e-05 
09/13/2020 22:27:44 - INFO - volta.utils -   [GQA]: iter 16377 Ep: 4.45 loss 1.401 score 0.720 lr 3.45714e-05 
09/13/2020 22:29:06 - INFO - volta.utils -   [GQA]: iter 16397 Ep: 4.45 loss 1.411 score 0.713 lr 3.45594e-05 
09/13/2020 22:31:24 - INFO - volta.utils -   [GQA]: iter 16417 Ep: 4.46 loss 1.428 score 0.708 lr 3.45473e-05 
09/13/2020 22:32:57 - INFO - volta.utils -   [GQA]: iter 16437 Ep: 4.46 loss 1.427 score 0.709 lr 3.45352e-05 
09/13/2020 22:34:15 - INFO - volta.utils -   [GQA]: iter 16457 Ep: 4.47 loss 1.416 score 0.712 lr 3.45232e-05 
09/13/2020 22:35:42 - INFO - volta.utils -   [GQA]: iter 16477 Ep: 4.47 loss 1.411 score 0.717 lr 3.45111e-05 
09/13/2020 22:37:55 - INFO - volta.utils -   [GQA]: iter 16497 Ep: 4.48 loss 1.414 score 0.714 lr 3.4499e-05 
09/13/2020 22:39:19 - INFO - volta.utils -   [GQA]: iter 16517 Ep: 4.48 loss 1.442 score 0.706 lr 3.4487e-05 
09/13/2020 22:39:54 - INFO - volta.utils -   [GQA]: iter 16537 Ep: 4.49 loss 1.391 score 0.710 lr 3.44749e-05 
09/13/2020 22:41:24 - INFO - volta.utils -   [GQA]: iter 16557 Ep: 4.49 loss 1.438 score 0.708 lr 3.44628e-05 
09/13/2020 22:44:38 - INFO - volta.utils -   [GQA]: iter 16577 Ep: 4.50 loss 1.389 score 0.719 lr 3.44508e-05 
09/13/2020 22:46:16 - INFO - volta.utils -   [GQA]: iter 16597 Ep: 4.51 loss 1.407 score 0.719 lr 3.44387e-05 
09/13/2020 22:47:47 - INFO - volta.utils -   [GQA]: iter 16617 Ep: 4.51 loss 1.404 score 0.720 lr 3.44266e-05 
09/13/2020 22:48:40 - INFO - volta.utils -   [GQA]: iter 16637 Ep: 4.52 loss 1.400 score 0.718 lr 3.44146e-05 
09/13/2020 22:51:33 - INFO - volta.utils -   [GQA]: iter 16657 Ep: 4.52 loss 1.346 score 0.722 lr 3.44025e-05 
09/13/2020 22:52:38 - INFO - volta.utils -   [GQA]: iter 16677 Ep: 4.53 loss 1.388 score 0.720 lr 3.43905e-05 
09/13/2020 22:53:46 - INFO - volta.utils -   [GQA]: iter 16697 Ep: 4.53 loss 1.386 score 0.725 lr 3.43784e-05 
09/13/2020 22:55:24 - INFO - volta.utils -   [GQA]: iter 16717 Ep: 4.54 loss 1.409 score 0.707 lr 3.43663e-05 
09/13/2020 22:57:49 - INFO - volta.utils -   [GQA]: iter 16737 Ep: 4.54 loss 1.416 score 0.715 lr 3.43543e-05 
09/13/2020 22:58:53 - INFO - volta.utils -   [GQA]: iter 16757 Ep: 4.55 loss 1.362 score 0.716 lr 3.43422e-05 
09/13/2020 23:00:29 - INFO - volta.utils -   [GQA]: iter 16777 Ep: 4.55 loss 1.394 score 0.716 lr 3.43301e-05 
09/13/2020 23:02:16 - INFO - volta.utils -   [GQA]: iter 16797 Ep: 4.56 loss 1.399 score 0.712 lr 3.43181e-05 
09/13/2020 23:05:02 - INFO - volta.utils -   [GQA]: iter 16817 Ep: 4.56 loss 1.386 score 0.717 lr 3.4306e-05 
09/13/2020 23:06:52 - INFO - volta.utils -   [GQA]: iter 16837 Ep: 4.57 loss 1.387 score 0.724 lr 3.42939e-05 
09/13/2020 23:08:21 - INFO - volta.utils -   [GQA]: iter 16857 Ep: 4.58 loss 1.393 score 0.716 lr 3.42819e-05 
09/13/2020 23:09:35 - INFO - volta.utils -   [GQA]: iter 16877 Ep: 4.58 loss 1.420 score 0.714 lr 3.42698e-05 
09/13/2020 23:12:21 - INFO - volta.utils -   [GQA]: iter 16897 Ep: 4.59 loss 1.392 score 0.717 lr 3.42578e-05 
09/13/2020 23:14:06 - INFO - volta.utils -   [GQA]: iter 16917 Ep: 4.59 loss 1.366 score 0.720 lr 3.42457e-05 
09/13/2020 23:15:25 - INFO - volta.utils -   [GQA]: iter 16937 Ep: 4.60 loss 1.386 score 0.720 lr 3.42336e-05 
09/13/2020 23:16:39 - INFO - volta.utils -   [GQA]: iter 16957 Ep: 4.60 loss 1.355 score 0.722 lr 3.42216e-05 
09/13/2020 23:19:29 - INFO - volta.utils -   [GQA]: iter 16977 Ep: 4.61 loss 1.412 score 0.714 lr 3.42095e-05 
09/13/2020 23:20:55 - INFO - volta.utils -   [GQA]: iter 16997 Ep: 4.61 loss 1.381 score 0.721 lr 3.41974e-05 
09/13/2020 23:21:52 - INFO - volta.utils -   [GQA]: iter 17017 Ep: 4.62 loss 1.368 score 0.720 lr 3.41854e-05 
09/13/2020 23:23:14 - INFO - volta.utils -   [GQA]: iter 17037 Ep: 4.62 loss 1.357 score 0.726 lr 3.41733e-05 
09/13/2020 23:25:50 - INFO - volta.utils -   [GQA]: iter 17057 Ep: 4.63 loss 1.410 score 0.720 lr 3.41612e-05 
09/13/2020 23:26:53 - INFO - volta.utils -   [GQA]: iter 17077 Ep: 4.64 loss 1.377 score 0.722 lr 3.41492e-05 
09/13/2020 23:28:20 - INFO - volta.utils -   [GQA]: iter 17097 Ep: 4.64 loss 1.373 score 0.716 lr 3.41371e-05 
09/13/2020 23:29:54 - INFO - volta.utils -   [GQA]: iter 17117 Ep: 4.65 loss 1.363 score 0.721 lr 3.4125e-05 
09/13/2020 23:32:43 - INFO - volta.utils -   [GQA]: iter 17137 Ep: 4.65 loss 1.385 score 0.716 lr 3.4113e-05 
09/13/2020 23:33:56 - INFO - volta.utils -   [GQA]: iter 17157 Ep: 4.66 loss 1.401 score 0.712 lr 3.41009e-05 
09/13/2020 23:35:15 - INFO - volta.utils -   [GQA]: iter 17177 Ep: 4.66 loss 1.353 score 0.722 lr 3.40889e-05 
09/13/2020 23:36:46 - INFO - volta.utils -   [GQA]: iter 17197 Ep: 4.67 loss 1.388 score 0.724 lr 3.40768e-05 
09/13/2020 23:38:41 - INFO - volta.utils -   [GQA]: iter 17217 Ep: 4.67 loss 1.395 score 0.719 lr 3.40647e-05 
09/13/2020 23:40:10 - INFO - volta.utils -   [GQA]: iter 17237 Ep: 4.68 loss 1.369 score 0.731 lr 3.40527e-05 
09/13/2020 23:41:22 - INFO - volta.utils -   [GQA]: iter 17257 Ep: 4.68 loss 1.425 score 0.721 lr 3.40406e-05 
09/13/2020 23:42:24 - INFO - volta.utils -   [GQA]: iter 17277 Ep: 4.69 loss 1.381 score 0.714 lr 3.40285e-05 
09/13/2020 23:45:03 - INFO - volta.utils -   [GQA]: iter 17297 Ep: 4.70 loss 1.384 score 0.725 lr 3.40165e-05 
09/13/2020 23:46:20 - INFO - volta.utils -   [GQA]: iter 17317 Ep: 4.70 loss 1.345 score 0.730 lr 3.40044e-05 
09/13/2020 23:47:28 - INFO - volta.utils -   [GQA]: iter 17337 Ep: 4.71 loss 1.412 score 0.714 lr 3.39923e-05 
09/13/2020 23:48:56 - INFO - volta.utils -   [GQA]: iter 17357 Ep: 4.71 loss 1.355 score 0.718 lr 3.39803e-05 
09/13/2020 23:51:13 - INFO - volta.utils -   [GQA]: iter 17377 Ep: 4.72 loss 1.379 score 0.725 lr 3.39682e-05 
09/13/2020 23:52:42 - INFO - volta.utils -   [GQA]: iter 17397 Ep: 4.72 loss 1.375 score 0.721 lr 3.39561e-05 
09/13/2020 23:54:03 - INFO - volta.utils -   [GQA]: iter 17417 Ep: 4.73 loss 1.352 score 0.725 lr 3.39441e-05 
09/13/2020 23:55:31 - INFO - volta.utils -   [GQA]: iter 17437 Ep: 4.73 loss 1.343 score 0.722 lr 3.3932e-05 
09/13/2020 23:58:39 - INFO - volta.utils -   [GQA]: iter 17457 Ep: 4.74 loss 1.363 score 0.715 lr 3.392e-05 
09/14/2020 00:00:11 - INFO - volta.utils -   [GQA]: iter 17477 Ep: 4.74 loss 1.389 score 0.713 lr 3.39079e-05 
09/14/2020 00:01:14 - INFO - volta.utils -   [GQA]: iter 17497 Ep: 4.75 loss 1.358 score 0.727 lr 3.38958e-05 
09/14/2020 00:02:54 - INFO - volta.utils -   [GQA]: iter 17517 Ep: 4.75 loss 1.389 score 0.717 lr 3.38838e-05 
09/14/2020 00:05:29 - INFO - volta.utils -   [GQA]: iter 17537 Ep: 4.76 loss 1.386 score 0.719 lr 3.38717e-05 
09/14/2020 00:06:56 - INFO - volta.utils -   [GQA]: iter 17557 Ep: 4.77 loss 1.399 score 0.712 lr 3.38596e-05 
09/14/2020 00:08:54 - INFO - volta.utils -   [GQA]: iter 17577 Ep: 4.77 loss 1.363 score 0.721 lr 3.38476e-05 
09/14/2020 00:10:10 - INFO - volta.utils -   [GQA]: iter 17597 Ep: 4.78 loss 1.364 score 0.727 lr 3.38355e-05 
09/14/2020 00:12:48 - INFO - volta.utils -   [GQA]: iter 17617 Ep: 4.78 loss 1.354 score 0.722 lr 3.38234e-05 
09/14/2020 00:14:08 - INFO - volta.utils -   [GQA]: iter 17637 Ep: 4.79 loss 1.415 score 0.713 lr 3.38114e-05 
09/14/2020 00:15:22 - INFO - volta.utils -   [GQA]: iter 17657 Ep: 4.79 loss 1.335 score 0.731 lr 3.37993e-05 
09/14/2020 00:16:54 - INFO - volta.utils -   [GQA]: iter 17677 Ep: 4.80 loss 1.399 score 0.717 lr 3.37872e-05 
09/14/2020 00:19:37 - INFO - volta.utils -   [GQA]: iter 17697 Ep: 4.80 loss 1.327 score 0.729 lr 3.37752e-05 
09/14/2020 00:20:44 - INFO - volta.utils -   [GQA]: iter 17717 Ep: 4.81 loss 1.345 score 0.718 lr 3.37631e-05 
09/14/2020 00:22:12 - INFO - volta.utils -   [GQA]: iter 17737 Ep: 4.81 loss 1.353 score 0.729 lr 3.37511e-05 
09/14/2020 00:23:44 - INFO - volta.utils -   [GQA]: iter 17757 Ep: 4.82 loss 1.344 score 0.732 lr 3.3739e-05 
09/14/2020 00:25:46 - INFO - volta.utils -   [GQA]: iter 17777 Ep: 4.83 loss 1.365 score 0.718 lr 3.37269e-05 
09/14/2020 00:27:14 - INFO - volta.utils -   [GQA]: iter 17797 Ep: 4.83 loss 1.363 score 0.725 lr 3.37149e-05 
09/14/2020 00:28:28 - INFO - volta.utils -   [GQA]: iter 17817 Ep: 4.84 loss 1.312 score 0.727 lr 3.37028e-05 
09/14/2020 00:29:52 - INFO - volta.utils -   [GQA]: iter 17837 Ep: 4.84 loss 1.331 score 0.737 lr 3.36907e-05 
09/14/2020 00:32:29 - INFO - volta.utils -   [GQA]: iter 17857 Ep: 4.85 loss 1.385 score 0.718 lr 3.36787e-05 
09/14/2020 00:34:14 - INFO - volta.utils -   [GQA]: iter 17877 Ep: 4.85 loss 1.388 score 0.722 lr 3.36666e-05 
09/14/2020 00:36:04 - INFO - volta.utils -   [GQA]: iter 17897 Ep: 4.86 loss 1.370 score 0.721 lr 3.36545e-05 
09/14/2020 00:37:31 - INFO - volta.utils -   [GQA]: iter 17917 Ep: 4.86 loss 1.388 score 0.719 lr 3.36425e-05 
09/14/2020 00:39:18 - INFO - volta.utils -   [GQA]: iter 17937 Ep: 4.87 loss 1.398 score 0.723 lr 3.36304e-05 
09/14/2020 00:40:15 - INFO - volta.utils -   [GQA]: iter 17957 Ep: 4.87 loss 1.389 score 0.719 lr 3.36183e-05 
09/14/2020 00:42:39 - INFO - volta.utils -   [GQA]: iter 17977 Ep: 4.88 loss 1.376 score 0.717 lr 3.36063e-05 
09/14/2020 00:43:59 - INFO - volta.utils -   [GQA]: iter 17997 Ep: 4.89 loss 1.396 score 0.715 lr 3.35942e-05 
09/14/2020 00:45:43 - INFO - volta.utils -   [GQA]: iter 18017 Ep: 4.89 loss 1.339 score 0.727 lr 3.35822e-05 
09/14/2020 00:47:08 - INFO - volta.utils -   [GQA]: iter 18037 Ep: 4.90 loss 1.358 score 0.721 lr 3.35701e-05 
09/14/2020 00:49:14 - INFO - volta.utils -   [GQA]: iter 18057 Ep: 4.90 loss 1.349 score 0.722 lr 3.3558e-05 
09/14/2020 00:50:45 - INFO - volta.utils -   [GQA]: iter 18077 Ep: 4.91 loss 1.326 score 0.729 lr 3.3546e-05 
09/14/2020 00:52:19 - INFO - volta.utils -   [GQA]: iter 18097 Ep: 4.91 loss 1.380 score 0.729 lr 3.35339e-05 
09/14/2020 00:53:32 - INFO - volta.utils -   [GQA]: iter 18117 Ep: 4.92 loss 1.393 score 0.712 lr 3.35218e-05 
09/14/2020 00:55:46 - INFO - volta.utils -   [GQA]: iter 18137 Ep: 4.92 loss 1.361 score 0.724 lr 3.35098e-05 
09/14/2020 00:57:10 - INFO - volta.utils -   [GQA]: iter 18157 Ep: 4.93 loss 1.365 score 0.726 lr 3.34977e-05 
09/14/2020 00:58:37 - INFO - volta.utils -   [GQA]: iter 18177 Ep: 4.93 loss 1.333 score 0.728 lr 3.34856e-05 
09/14/2020 00:59:48 - INFO - volta.utils -   [GQA]: iter 18197 Ep: 4.94 loss 1.363 score 0.724 lr 3.34736e-05 
09/14/2020 01:02:31 - INFO - volta.utils -   [GQA]: iter 18217 Ep: 4.94 loss 1.379 score 0.721 lr 3.34615e-05 
09/14/2020 01:03:20 - INFO - volta.utils -   [GQA]: iter 18237 Ep: 4.95 loss 1.320 score 0.742 lr 3.34495e-05 
09/14/2020 01:04:44 - INFO - volta.utils -   [GQA]: iter 18257 Ep: 4.96 loss 1.314 score 0.741 lr 3.34374e-05 
09/14/2020 01:06:03 - INFO - volta.utils -   [GQA]: iter 18277 Ep: 4.96 loss 1.370 score 0.722 lr 3.34253e-05 
09/14/2020 01:08:01 - INFO - volta.utils -   [GQA]: iter 18297 Ep: 4.97 loss 1.374 score 0.727 lr 3.34133e-05 
09/14/2020 01:09:22 - INFO - volta.utils -   [GQA]: iter 18317 Ep: 4.97 loss 1.311 score 0.731 lr 3.34012e-05 
09/14/2020 01:10:15 - INFO - volta.utils -   [GQA]: iter 18337 Ep: 4.98 loss 1.406 score 0.713 lr 3.33891e-05 
09/14/2020 01:11:35 - INFO - volta.utils -   [GQA]: iter 18357 Ep: 4.98 loss 1.360 score 0.720 lr 3.33771e-05 
09/14/2020 01:14:15 - INFO - volta.utils -   [GQA]: iter 18377 Ep: 4.99 loss 1.317 score 0.728 lr 3.3365e-05 
09/14/2020 01:15:45 - INFO - volta.utils -   [GQA]: iter 18397 Ep: 4.99 loss 1.320 score 0.730 lr 3.33529e-05 
09/14/2020 01:16:40 - INFO - volta.utils -   [GQA]: iter 18417 Ep: 5.00 loss 1.355 score 0.720 lr 3.33409e-05 
09/14/2020 01:16:43 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:   6%|         | 1/16 [5:26:26<81:36:31, 19586.07s/it]09/14/2020 01:36:05 - INFO - volta.utils -   Eval task TASK15 on iteration 18421 
09/14/2020 01:36:05 - INFO - volta.utils -   Validation [GQA]: loss 1.869 score 63.985 
09/14/2020 01:36:18 - INFO - volta.utils -   [GQA]: iter 18441 Ep: 5.01 loss 1.195 score 0.760 lr 3.33276e-05 
09/14/2020 01:37:28 - INFO - volta.utils -   [GQA]: iter 18461 Ep: 5.01 loss 1.105 score 0.785 lr 3.33143e-05 
09/14/2020 01:38:24 - INFO - volta.utils -   [GQA]: iter 18481 Ep: 5.02 loss 1.170 score 0.768 lr 3.33023e-05 
09/14/2020 01:39:28 - INFO - volta.utils -   [GQA]: iter 18501 Ep: 5.02 loss 1.123 score 0.776 lr 3.32902e-05 
09/14/2020 01:40:59 - INFO - volta.utils -   [GQA]: iter 18521 Ep: 5.03 loss 1.159 score 0.768 lr 3.32781e-05 
09/14/2020 01:42:01 - INFO - volta.utils -   [GQA]: iter 18541 Ep: 5.03 loss 1.184 score 0.763 lr 3.32661e-05 
09/14/2020 01:42:49 - INFO - volta.utils -   [GQA]: iter 18561 Ep: 5.04 loss 1.133 score 0.773 lr 3.3254e-05 
09/14/2020 01:43:38 - INFO - volta.utils -   [GQA]: iter 18581 Ep: 5.04 loss 1.139 score 0.775 lr 3.32419e-05 
09/14/2020 01:45:57 - INFO - volta.utils -   [GQA]: iter 18601 Ep: 5.05 loss 1.157 score 0.766 lr 3.32299e-05 
09/14/2020 01:46:45 - INFO - volta.utils -   [GQA]: iter 18621 Ep: 5.05 loss 1.167 score 0.767 lr 3.32178e-05 
09/14/2020 01:47:56 - INFO - volta.utils -   [GQA]: iter 18641 Ep: 5.06 loss 1.177 score 0.767 lr 3.32058e-05 
09/14/2020 01:49:02 - INFO - volta.utils -   [GQA]: iter 18661 Ep: 5.07 loss 1.154 score 0.766 lr 3.31937e-05 
09/14/2020 01:51:11 - INFO - volta.utils -   [GQA]: iter 18681 Ep: 5.07 loss 1.145 score 0.768 lr 3.31816e-05 
09/14/2020 01:52:26 - INFO - volta.utils -   [GQA]: iter 18701 Ep: 5.08 loss 1.217 score 0.756 lr 3.31696e-05 
09/14/2020 01:53:54 - INFO - volta.utils -   [GQA]: iter 18721 Ep: 5.08 loss 1.131 score 0.775 lr 3.31575e-05 
09/14/2020 01:55:05 - INFO - volta.utils -   [GQA]: iter 18741 Ep: 5.09 loss 1.179 score 0.761 lr 3.31454e-05 
09/14/2020 01:56:45 - INFO - volta.utils -   [GQA]: iter 18761 Ep: 5.09 loss 1.192 score 0.764 lr 3.31334e-05 
09/14/2020 01:58:07 - INFO - volta.utils -   [GQA]: iter 18781 Ep: 5.10 loss 1.118 score 0.776 lr 3.31213e-05 
09/14/2020 02:00:03 - INFO - volta.utils -   [GQA]: iter 18801 Ep: 5.10 loss 1.203 score 0.758 lr 3.31092e-05 
09/14/2020 02:01:32 - INFO - volta.utils -   [GQA]: iter 18821 Ep: 5.11 loss 1.156 score 0.763 lr 3.30972e-05 
09/14/2020 02:03:25 - INFO - volta.utils -   [GQA]: iter 18841 Ep: 5.11 loss 1.188 score 0.763 lr 3.30851e-05 
09/14/2020 02:05:02 - INFO - volta.utils -   [GQA]: iter 18861 Ep: 5.12 loss 1.161 score 0.767 lr 3.3073e-05 
09/14/2020 02:06:53 - INFO - volta.utils -   [GQA]: iter 18881 Ep: 5.13 loss 1.163 score 0.761 lr 3.3061e-05 
09/14/2020 02:08:25 - INFO - volta.utils -   [GQA]: iter 18901 Ep: 5.13 loss 1.204 score 0.761 lr 3.30489e-05 
09/14/2020 02:09:57 - INFO - volta.utils -   [GQA]: iter 18921 Ep: 5.14 loss 1.189 score 0.758 lr 3.30369e-05 
09/14/2020 02:11:23 - INFO - volta.utils -   [GQA]: iter 18941 Ep: 5.14 loss 1.158 score 0.771 lr 3.30248e-05 
09/14/2020 02:13:13 - INFO - volta.utils -   [GQA]: iter 18961 Ep: 5.15 loss 1.189 score 0.763 lr 3.30127e-05 
09/14/2020 02:14:57 - INFO - volta.utils -   [GQA]: iter 18981 Ep: 5.15 loss 1.210 score 0.755 lr 3.30007e-05 
09/14/2020 02:16:38 - INFO - volta.utils -   [GQA]: iter 19001 Ep: 5.16 loss 1.156 score 0.770 lr 3.29886e-05 
09/14/2020 02:18:21 - INFO - volta.utils -   [GQA]: iter 19021 Ep: 5.16 loss 1.164 score 0.762 lr 3.29765e-05 
09/14/2020 02:21:05 - INFO - volta.utils -   [GQA]: iter 19041 Ep: 5.17 loss 1.145 score 0.776 lr 3.29645e-05 
09/14/2020 02:22:11 - INFO - volta.utils -   [GQA]: iter 19061 Ep: 5.17 loss 1.156 score 0.770 lr 3.29524e-05 
09/14/2020 02:23:33 - INFO - volta.utils -   [GQA]: iter 19081 Ep: 5.18 loss 1.177 score 0.764 lr 3.29403e-05 
09/14/2020 02:25:07 - INFO - volta.utils -   [GQA]: iter 19101 Ep: 5.18 loss 1.173 score 0.761 lr 3.29283e-05 
09/14/2020 02:26:58 - INFO - volta.utils -   [GQA]: iter 19121 Ep: 5.19 loss 1.158 score 0.770 lr 3.29162e-05 
09/14/2020 02:28:25 - INFO - volta.utils -   [GQA]: iter 19141 Ep: 5.20 loss 1.167 score 0.764 lr 3.29042e-05 
09/14/2020 02:29:43 - INFO - volta.utils -   [GQA]: iter 19161 Ep: 5.20 loss 1.178 score 0.762 lr 3.28921e-05 
09/14/2020 02:31:24 - INFO - volta.utils -   [GQA]: iter 19181 Ep: 5.21 loss 1.174 score 0.771 lr 3.288e-05 
09/14/2020 02:33:23 - INFO - volta.utils -   [GQA]: iter 19201 Ep: 5.21 loss 1.136 score 0.770 lr 3.2868e-05 
09/14/2020 02:34:47 - INFO - volta.utils -   [GQA]: iter 19221 Ep: 5.22 loss 1.145 score 0.771 lr 3.28559e-05 
09/14/2020 02:36:29 - INFO - volta.utils -   [GQA]: iter 19241 Ep: 5.22 loss 1.172 score 0.765 lr 3.28438e-05 
09/14/2020 02:37:50 - INFO - volta.utils -   [GQA]: iter 19261 Ep: 5.23 loss 1.176 score 0.762 lr 3.28318e-05 
09/14/2020 02:40:12 - INFO - volta.utils -   [GQA]: iter 19281 Ep: 5.23 loss 1.153 score 0.759 lr 3.28197e-05 
09/14/2020 02:41:31 - INFO - volta.utils -   [GQA]: iter 19301 Ep: 5.24 loss 1.139 score 0.768 lr 3.28076e-05 
09/14/2020 02:42:32 - INFO - volta.utils -   [GQA]: iter 19321 Ep: 5.24 loss 1.191 score 0.756 lr 3.27956e-05 
09/14/2020 02:43:39 - INFO - volta.utils -   [GQA]: iter 19341 Ep: 5.25 loss 1.157 score 0.765 lr 3.27835e-05 
09/14/2020 02:46:14 - INFO - volta.utils -   [GQA]: iter 19361 Ep: 5.26 loss 1.189 score 0.765 lr 3.27714e-05 
09/14/2020 02:47:32 - INFO - volta.utils -   [GQA]: iter 19381 Ep: 5.26 loss 1.196 score 0.762 lr 3.27594e-05 
09/14/2020 02:48:46 - INFO - volta.utils -   [GQA]: iter 19401 Ep: 5.27 loss 1.172 score 0.767 lr 3.27473e-05 
09/14/2020 02:50:19 - INFO - volta.utils -   [GQA]: iter 19421 Ep: 5.27 loss 1.168 score 0.771 lr 3.27353e-05 
09/14/2020 02:52:12 - INFO - volta.utils -   [GQA]: iter 19441 Ep: 5.28 loss 1.181 score 0.763 lr 3.27232e-05 
09/14/2020 02:53:38 - INFO - volta.utils -   [GQA]: iter 19461 Ep: 5.28 loss 1.129 score 0.780 lr 3.27111e-05 
09/14/2020 02:54:57 - INFO - volta.utils -   [GQA]: iter 19481 Ep: 5.29 loss 1.152 score 0.767 lr 3.26991e-05 
09/14/2020 02:56:27 - INFO - volta.utils -   [GQA]: iter 19501 Ep: 5.29 loss 1.184 score 0.751 lr 3.2687e-05 
09/14/2020 02:58:27 - INFO - volta.utils -   [GQA]: iter 19521 Ep: 5.30 loss 1.167 score 0.763 lr 3.26749e-05 
09/14/2020 02:59:40 - INFO - volta.utils -   [GQA]: iter 19541 Ep: 5.30 loss 1.209 score 0.761 lr 3.26629e-05 
09/14/2020 03:01:07 - INFO - volta.utils -   [GQA]: iter 19561 Ep: 5.31 loss 1.200 score 0.757 lr 3.26508e-05 
09/14/2020 03:02:27 - INFO - volta.utils -   [GQA]: iter 19581 Ep: 5.32 loss 1.137 score 0.772 lr 3.26387e-05 
09/14/2020 03:04:42 - INFO - volta.utils -   [GQA]: iter 19601 Ep: 5.32 loss 1.176 score 0.767 lr 3.26267e-05 
09/14/2020 03:06:03 - INFO - volta.utils -   [GQA]: iter 19621 Ep: 5.33 loss 1.148 score 0.768 lr 3.26146e-05 
09/14/2020 03:07:22 - INFO - volta.utils -   [GQA]: iter 19641 Ep: 5.33 loss 1.190 score 0.765 lr 3.26025e-05 
09/14/2020 03:08:34 - INFO - volta.utils -   [GQA]: iter 19661 Ep: 5.34 loss 1.121 score 0.781 lr 3.25905e-05 
09/14/2020 03:10:26 - INFO - volta.utils -   [GQA]: iter 19681 Ep: 5.34 loss 1.119 score 0.775 lr 3.25784e-05 
09/14/2020 03:11:42 - INFO - volta.utils -   [GQA]: iter 19701 Ep: 5.35 loss 1.160 score 0.764 lr 3.25664e-05 
09/14/2020 03:13:31 - INFO - volta.utils -   [GQA]: iter 19721 Ep: 5.35 loss 1.203 score 0.761 lr 3.25543e-05 
09/14/2020 03:14:30 - INFO - volta.utils -   [GQA]: iter 19741 Ep: 5.36 loss 1.166 score 0.767 lr 3.25422e-05 
09/14/2020 03:15:52 - INFO - volta.utils -   [GQA]: iter 19761 Ep: 5.36 loss 1.160 score 0.772 lr 3.25302e-05 
09/14/2020 03:17:32 - INFO - volta.utils -   [GQA]: iter 19781 Ep: 5.37 loss 1.128 score 0.778 lr 3.25181e-05 
09/14/2020 03:20:07 - INFO - volta.utils -   [GQA]: iter 19801 Ep: 5.37 loss 1.152 score 0.769 lr 3.2506e-05 
09/14/2020 03:21:26 - INFO - volta.utils -   [GQA]: iter 19821 Ep: 5.38 loss 1.165 score 0.767 lr 3.2494e-05 
09/14/2020 03:22:34 - INFO - volta.utils -   [GQA]: iter 19841 Ep: 5.39 loss 1.126 score 0.767 lr 3.24819e-05 
09/14/2020 03:24:36 - INFO - volta.utils -   [GQA]: iter 19861 Ep: 5.39 loss 1.158 score 0.771 lr 3.24698e-05 
09/14/2020 03:26:49 - INFO - volta.utils -   [GQA]: iter 19881 Ep: 5.40 loss 1.161 score 0.770 lr 3.24578e-05 
09/14/2020 03:28:05 - INFO - volta.utils -   [GQA]: iter 19901 Ep: 5.40 loss 1.160 score 0.764 lr 3.24457e-05 
09/14/2020 03:29:04 - INFO - volta.utils -   [GQA]: iter 19921 Ep: 5.41 loss 1.119 score 0.778 lr 3.24336e-05 
09/14/2020 03:30:51 - INFO - volta.utils -   [GQA]: iter 19941 Ep: 5.41 loss 1.154 score 0.766 lr 3.24216e-05 
09/14/2020 03:32:58 - INFO - volta.utils -   [GQA]: iter 19961 Ep: 5.42 loss 1.162 score 0.775 lr 3.24095e-05 
09/14/2020 03:34:29 - INFO - volta.utils -   [GQA]: iter 19981 Ep: 5.42 loss 1.204 score 0.759 lr 3.23975e-05 
09/14/2020 03:35:44 - INFO - volta.utils -   [GQA]: iter 20001 Ep: 5.43 loss 1.191 score 0.754 lr 3.23854e-05 
09/14/2020 03:36:52 - INFO - volta.utils -   [GQA]: iter 20021 Ep: 5.43 loss 1.172 score 0.760 lr 3.23733e-05 
09/14/2020 03:38:50 - INFO - volta.utils -   [GQA]: iter 20041 Ep: 5.44 loss 1.180 score 0.769 lr 3.23613e-05 
09/14/2020 03:39:57 - INFO - volta.utils -   [GQA]: iter 20061 Ep: 5.45 loss 1.183 score 0.762 lr 3.23492e-05 
09/14/2020 03:41:21 - INFO - volta.utils -   [GQA]: iter 20081 Ep: 5.45 loss 1.221 score 0.747 lr 3.23371e-05 
09/14/2020 03:42:38 - INFO - volta.utils -   [GQA]: iter 20101 Ep: 5.46 loss 1.226 score 0.753 lr 3.23251e-05 
09/14/2020 03:45:09 - INFO - volta.utils -   [GQA]: iter 20121 Ep: 5.46 loss 1.135 score 0.779 lr 3.2313e-05 
09/14/2020 03:46:43 - INFO - volta.utils -   [GQA]: iter 20141 Ep: 5.47 loss 1.170 score 0.765 lr 3.23009e-05 
09/14/2020 03:48:16 - INFO - volta.utils -   [GQA]: iter 20161 Ep: 5.47 loss 1.141 score 0.770 lr 3.22889e-05 
09/14/2020 03:48:51 - INFO - volta.utils -   [GQA]: iter 20181 Ep: 5.48 loss 1.165 score 0.765 lr 3.22768e-05 
09/14/2020 03:51:03 - INFO - volta.utils -   [GQA]: iter 20201 Ep: 5.48 loss 1.176 score 0.763 lr 3.22647e-05 
09/14/2020 03:52:10 - INFO - volta.utils -   [GQA]: iter 20221 Ep: 5.49 loss 1.208 score 0.760 lr 3.22527e-05 
09/14/2020 03:53:42 - INFO - volta.utils -   [GQA]: iter 20241 Ep: 5.49 loss 1.178 score 0.765 lr 3.22406e-05 
09/14/2020 03:55:15 - INFO - volta.utils -   [GQA]: iter 20261 Ep: 5.50 loss 1.134 score 0.776 lr 3.22286e-05 
09/14/2020 03:57:17 - INFO - volta.utils -   [GQA]: iter 20281 Ep: 5.51 loss 1.182 score 0.766 lr 3.22165e-05 
09/14/2020 03:58:51 - INFO - volta.utils -   [GQA]: iter 20301 Ep: 5.51 loss 1.133 score 0.767 lr 3.22044e-05 
09/14/2020 04:00:22 - INFO - volta.utils -   [GQA]: iter 20321 Ep: 5.52 loss 1.180 score 0.766 lr 3.21924e-05 
09/14/2020 04:01:48 - INFO - volta.utils -   [GQA]: iter 20341 Ep: 5.52 loss 1.168 score 0.767 lr 3.21803e-05 
09/14/2020 04:03:58 - INFO - volta.utils -   [GQA]: iter 20361 Ep: 5.53 loss 1.169 score 0.762 lr 3.21682e-05 
09/14/2020 04:04:54 - INFO - volta.utils -   [GQA]: iter 20381 Ep: 5.53 loss 1.176 score 0.767 lr 3.21562e-05 
09/14/2020 04:06:03 - INFO - volta.utils -   [GQA]: iter 20401 Ep: 5.54 loss 1.188 score 0.758 lr 3.21441e-05 
09/14/2020 04:07:28 - INFO - volta.utils -   [GQA]: iter 20421 Ep: 5.54 loss 1.136 score 0.775 lr 3.2132e-05 
09/14/2020 04:09:16 - INFO - volta.utils -   [GQA]: iter 20441 Ep: 5.55 loss 1.167 score 0.763 lr 3.212e-05 
09/14/2020 04:10:40 - INFO - volta.utils -   [GQA]: iter 20461 Ep: 5.55 loss 1.128 score 0.774 lr 3.21079e-05 
09/14/2020 04:11:21 - INFO - volta.utils -   [GQA]: iter 20481 Ep: 5.56 loss 1.154 score 0.769 lr 3.20958e-05 
09/14/2020 04:12:31 - INFO - volta.utils -   [GQA]: iter 20501 Ep: 5.56 loss 1.168 score 0.763 lr 3.20838e-05 
09/14/2020 04:14:23 - INFO - volta.utils -   [GQA]: iter 20521 Ep: 5.57 loss 1.166 score 0.766 lr 3.20717e-05 
09/14/2020 04:15:11 - INFO - volta.utils -   [GQA]: iter 20541 Ep: 5.58 loss 1.213 score 0.754 lr 3.20597e-05 
09/14/2020 04:16:53 - INFO - volta.utils -   [GQA]: iter 20561 Ep: 5.58 loss 1.157 score 0.767 lr 3.20476e-05 
09/14/2020 04:18:21 - INFO - volta.utils -   [GQA]: iter 20581 Ep: 5.59 loss 1.116 score 0.778 lr 3.20355e-05 
09/14/2020 04:20:59 - INFO - volta.utils -   [GQA]: iter 20601 Ep: 5.59 loss 1.187 score 0.762 lr 3.20235e-05 
09/14/2020 04:22:13 - INFO - volta.utils -   [GQA]: iter 20621 Ep: 5.60 loss 1.149 score 0.766 lr 3.20114e-05 
09/14/2020 04:23:32 - INFO - volta.utils -   [GQA]: iter 20641 Ep: 5.60 loss 1.158 score 0.772 lr 3.19993e-05 
09/14/2020 04:25:02 - INFO - volta.utils -   [GQA]: iter 20661 Ep: 5.61 loss 1.131 score 0.774 lr 3.19873e-05 
09/14/2020 04:26:46 - INFO - volta.utils -   [GQA]: iter 20681 Ep: 5.61 loss 1.143 score 0.763 lr 3.19752e-05 
09/14/2020 04:28:38 - INFO - volta.utils -   [GQA]: iter 20701 Ep: 5.62 loss 1.124 score 0.768 lr 3.19631e-05 
09/14/2020 04:29:56 - INFO - volta.utils -   [GQA]: iter 20721 Ep: 5.62 loss 1.198 score 0.758 lr 3.19511e-05 
09/14/2020 04:31:08 - INFO - volta.utils -   [GQA]: iter 20741 Ep: 5.63 loss 1.146 score 0.767 lr 3.1939e-05 
09/14/2020 04:33:10 - INFO - volta.utils -   [GQA]: iter 20761 Ep: 5.64 loss 1.153 score 0.760 lr 3.1927e-05 
09/14/2020 04:34:18 - INFO - volta.utils -   [GQA]: iter 20781 Ep: 5.64 loss 1.175 score 0.759 lr 3.19149e-05 
09/14/2020 04:35:29 - INFO - volta.utils -   [GQA]: iter 20801 Ep: 5.65 loss 1.169 score 0.765 lr 3.19028e-05 
09/14/2020 04:37:09 - INFO - volta.utils -   [GQA]: iter 20821 Ep: 5.65 loss 1.181 score 0.760 lr 3.18908e-05 
09/14/2020 04:38:41 - INFO - volta.utils -   [GQA]: iter 20841 Ep: 5.66 loss 1.146 score 0.771 lr 3.18787e-05 
09/14/2020 04:40:04 - INFO - volta.utils -   [GQA]: iter 20861 Ep: 5.66 loss 1.202 score 0.762 lr 3.18666e-05 
09/14/2020 04:41:02 - INFO - volta.utils -   [GQA]: iter 20881 Ep: 5.67 loss 1.192 score 0.765 lr 3.18546e-05 
09/14/2020 04:42:38 - INFO - volta.utils -   [GQA]: iter 20901 Ep: 5.67 loss 1.129 score 0.776 lr 3.18425e-05 
09/14/2020 04:44:21 - INFO - volta.utils -   [GQA]: iter 20921 Ep: 5.68 loss 1.182 score 0.758 lr 3.18304e-05 
09/14/2020 04:46:12 - INFO - volta.utils -   [GQA]: iter 20941 Ep: 5.68 loss 1.147 score 0.770 lr 3.18184e-05 
09/14/2020 04:48:12 - INFO - volta.utils -   [GQA]: iter 20961 Ep: 5.69 loss 1.187 score 0.764 lr 3.18063e-05 
09/14/2020 04:52:44 - INFO - volta.utils -   [GQA]: iter 20981 Ep: 5.70 loss 1.169 score 0.770 lr 3.17942e-05 
09/14/2020 04:54:25 - INFO - volta.utils -   [GQA]: iter 21001 Ep: 5.70 loss 1.169 score 0.762 lr 3.17822e-05 
09/14/2020 04:56:16 - INFO - volta.utils -   [GQA]: iter 21021 Ep: 5.71 loss 1.215 score 0.756 lr 3.17701e-05 
09/14/2020 04:57:20 - INFO - volta.utils -   [GQA]: iter 21041 Ep: 5.71 loss 1.147 score 0.766 lr 3.17581e-05 
09/14/2020 04:58:41 - INFO - volta.utils -   [GQA]: iter 21061 Ep: 5.72 loss 1.157 score 0.771 lr 3.1746e-05 
09/14/2020 05:00:01 - INFO - volta.utils -   [GQA]: iter 21081 Ep: 5.72 loss 1.154 score 0.771 lr 3.17339e-05 
09/14/2020 05:01:21 - INFO - volta.utils -   [GQA]: iter 21101 Ep: 5.73 loss 1.102 score 0.779 lr 3.17219e-05 
09/14/2020 05:02:35 - INFO - volta.utils -   [GQA]: iter 21121 Ep: 5.73 loss 1.118 score 0.775 lr 3.17098e-05 
09/14/2020 05:05:03 - INFO - volta.utils -   [GQA]: iter 21141 Ep: 5.74 loss 1.125 score 0.771 lr 3.16977e-05 
09/14/2020 05:06:20 - INFO - volta.utils -   [GQA]: iter 21161 Ep: 5.74 loss 1.114 score 0.781 lr 3.16857e-05 
09/14/2020 05:07:50 - INFO - volta.utils -   [GQA]: iter 21181 Ep: 5.75 loss 1.152 score 0.768 lr 3.16736e-05 
09/14/2020 05:09:12 - INFO - volta.utils -   [GQA]: iter 21201 Ep: 5.75 loss 1.151 score 0.773 lr 3.16615e-05 
09/14/2020 05:11:24 - INFO - volta.utils -   [GQA]: iter 21221 Ep: 5.76 loss 1.149 score 0.769 lr 3.16495e-05 
09/14/2020 05:12:54 - INFO - volta.utils -   [GQA]: iter 21241 Ep: 5.77 loss 1.157 score 0.768 lr 3.16374e-05 
09/14/2020 05:14:42 - INFO - volta.utils -   [GQA]: iter 21261 Ep: 5.77 loss 1.132 score 0.778 lr 3.16253e-05 
09/14/2020 05:16:18 - INFO - volta.utils -   [GQA]: iter 21281 Ep: 5.78 loss 1.193 score 0.764 lr 3.16133e-05 
09/14/2020 05:18:12 - INFO - volta.utils -   [GQA]: iter 21301 Ep: 5.78 loss 1.143 score 0.776 lr 3.16012e-05 
09/14/2020 05:19:40 - INFO - volta.utils -   [GQA]: iter 21321 Ep: 5.79 loss 1.138 score 0.767 lr 3.15892e-05 
09/14/2020 05:21:45 - INFO - volta.utils -   [GQA]: iter 21341 Ep: 5.79 loss 1.138 score 0.774 lr 3.15771e-05 
09/14/2020 05:23:24 - INFO - volta.utils -   [GQA]: iter 21361 Ep: 5.80 loss 1.113 score 0.778 lr 3.1565e-05 
09/14/2020 05:24:53 - INFO - volta.utils -   [GQA]: iter 21381 Ep: 5.80 loss 1.136 score 0.773 lr 3.1553e-05 
09/14/2020 05:26:12 - INFO - volta.utils -   [GQA]: iter 21401 Ep: 5.81 loss 1.185 score 0.764 lr 3.15409e-05 
09/14/2020 05:28:32 - INFO - volta.utils -   [GQA]: iter 21421 Ep: 5.81 loss 1.115 score 0.783 lr 3.15288e-05 
09/14/2020 05:29:44 - INFO - volta.utils -   [GQA]: iter 21441 Ep: 5.82 loss 1.120 score 0.785 lr 3.15168e-05 
09/14/2020 05:30:46 - INFO - volta.utils -   [GQA]: iter 21461 Ep: 5.83 loss 1.116 score 0.775 lr 3.15047e-05 
09/14/2020 05:32:20 - INFO - volta.utils -   [GQA]: iter 21481 Ep: 5.83 loss 1.153 score 0.777 lr 3.14926e-05 
09/14/2020 05:34:58 - INFO - volta.utils -   [GQA]: iter 21501 Ep: 5.84 loss 1.150 score 0.773 lr 3.14806e-05 
09/14/2020 05:36:10 - INFO - volta.utils -   [GQA]: iter 21521 Ep: 5.84 loss 1.164 score 0.766 lr 3.14685e-05 
09/14/2020 05:37:11 - INFO - volta.utils -   [GQA]: iter 21541 Ep: 5.85 loss 1.100 score 0.778 lr 3.14564e-05 
09/14/2020 05:38:28 - INFO - volta.utils -   [GQA]: iter 21561 Ep: 5.85 loss 1.160 score 0.770 lr 3.14444e-05 
09/14/2020 05:41:01 - INFO - volta.utils -   [GQA]: iter 21581 Ep: 5.86 loss 1.137 score 0.769 lr 3.14323e-05 
09/14/2020 05:42:00 - INFO - volta.utils -   [GQA]: iter 21601 Ep: 5.86 loss 1.162 score 0.764 lr 3.14203e-05 
09/14/2020 05:43:28 - INFO - volta.utils -   [GQA]: iter 21621 Ep: 5.87 loss 1.097 score 0.778 lr 3.14082e-05 
09/14/2020 05:44:29 - INFO - volta.utils -   [GQA]: iter 21641 Ep: 5.87 loss 1.127 score 0.776 lr 3.13961e-05 
09/14/2020 05:46:56 - INFO - volta.utils -   [GQA]: iter 21661 Ep: 5.88 loss 1.157 score 0.763 lr 3.13841e-05 
09/14/2020 05:47:56 - INFO - volta.utils -   [GQA]: iter 21681 Ep: 5.89 loss 1.125 score 0.778 lr 3.1372e-05 
09/14/2020 05:48:54 - INFO - volta.utils -   [GQA]: iter 21701 Ep: 5.89 loss 1.155 score 0.775 lr 3.13599e-05 
09/14/2020 05:50:04 - INFO - volta.utils -   [GQA]: iter 21721 Ep: 5.90 loss 1.167 score 0.761 lr 3.13479e-05 
09/14/2020 05:52:04 - INFO - volta.utils -   [GQA]: iter 21741 Ep: 5.90 loss 1.144 score 0.771 lr 3.13358e-05 
09/14/2020 05:53:25 - INFO - volta.utils -   [GQA]: iter 21761 Ep: 5.91 loss 1.151 score 0.765 lr 3.13237e-05 
09/14/2020 05:54:51 - INFO - volta.utils -   [GQA]: iter 21781 Ep: 5.91 loss 1.093 score 0.785 lr 3.13117e-05 
09/14/2020 05:55:54 - INFO - volta.utils -   [GQA]: iter 21801 Ep: 5.92 loss 1.116 score 0.771 lr 3.12996e-05 
09/14/2020 05:57:20 - INFO - volta.utils -   [GQA]: iter 21821 Ep: 5.92 loss 1.101 score 0.780 lr 3.12875e-05 
09/14/2020 05:58:38 - INFO - volta.utils -   [GQA]: iter 21841 Ep: 5.93 loss 1.149 score 0.769 lr 3.12755e-05 
09/14/2020 05:59:41 - INFO - volta.utils -   [GQA]: iter 21861 Ep: 5.93 loss 1.132 score 0.778 lr 3.12634e-05 
09/14/2020 06:01:07 - INFO - volta.utils -   [GQA]: iter 21881 Ep: 5.94 loss 1.177 score 0.761 lr 3.12514e-05 
09/14/2020 06:02:58 - INFO - volta.utils -   [GQA]: iter 21901 Ep: 5.94 loss 1.120 score 0.772 lr 3.12393e-05 
09/14/2020 06:04:37 - INFO - volta.utils -   [GQA]: iter 21921 Ep: 5.95 loss 1.193 score 0.762 lr 3.12272e-05 
09/14/2020 06:05:55 - INFO - volta.utils -   [GQA]: iter 21941 Ep: 5.96 loss 1.129 score 0.772 lr 3.12152e-05 
09/14/2020 06:07:05 - INFO - volta.utils -   [GQA]: iter 21961 Ep: 5.96 loss 1.170 score 0.765 lr 3.12031e-05 
09/14/2020 06:09:19 - INFO - volta.utils -   [GQA]: iter 21981 Ep: 5.97 loss 1.105 score 0.780 lr 3.1191e-05 
09/14/2020 06:10:29 - INFO - volta.utils -   [GQA]: iter 22001 Ep: 5.97 loss 1.166 score 0.763 lr 3.1179e-05 
09/14/2020 06:11:39 - INFO - volta.utils -   [GQA]: iter 22021 Ep: 5.98 loss 1.099 score 0.777 lr 3.11669e-05 
09/14/2020 06:12:47 - INFO - volta.utils -   [GQA]: iter 22041 Ep: 5.98 loss 1.133 score 0.776 lr 3.11548e-05 
09/14/2020 06:14:58 - INFO - volta.utils -   [GQA]: iter 22061 Ep: 5.99 loss 1.143 score 0.768 lr 3.11428e-05 
09/14/2020 06:16:37 - INFO - volta.utils -   [GQA]: iter 22081 Ep: 5.99 loss 1.111 score 0.782 lr 3.11307e-05 
09/14/2020 06:17:52 - INFO - volta.utils -   [GQA]: iter 22101 Ep: 6.00 loss 1.138 score 0.770 lr 3.11187e-05 
09/14/2020 06:17:54 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  12%|        | 2/16 [10:27:37<74:24:04, 19131.72s/it]09/14/2020 06:37:12 - INFO - volta.utils -   Eval task TASK15 on iteration 22105 
09/14/2020 06:37:12 - INFO - volta.utils -   Validation [GQA]: loss 1.924 score 64.358 
09/14/2020 06:37:25 - INFO - volta.utils -   [GQA]: iter 22125 Ep: 6.01 loss 1.003 score 0.807 lr 3.11054e-05 
09/14/2020 06:38:46 - INFO - volta.utils -   [GQA]: iter 22145 Ep: 6.01 loss 0.933 score 0.816 lr 3.10921e-05 
09/14/2020 06:39:37 - INFO - volta.utils -   [GQA]: iter 22165 Ep: 6.02 loss 0.936 score 0.819 lr 3.108e-05 
09/14/2020 06:40:42 - INFO - volta.utils -   [GQA]: iter 22185 Ep: 6.02 loss 0.915 score 0.821 lr 3.1068e-05 
09/14/2020 06:42:27 - INFO - volta.utils -   [GQA]: iter 22205 Ep: 6.03 loss 0.930 score 0.822 lr 3.10559e-05 
09/14/2020 06:43:36 - INFO - volta.utils -   [GQA]: iter 22225 Ep: 6.03 loss 0.917 score 0.823 lr 3.10439e-05 
09/14/2020 06:44:32 - INFO - volta.utils -   [GQA]: iter 22245 Ep: 6.04 loss 0.927 score 0.821 lr 3.10318e-05 
09/14/2020 06:45:40 - INFO - volta.utils -   [GQA]: iter 22265 Ep: 6.04 loss 0.968 score 0.811 lr 3.10197e-05 
09/14/2020 06:47:31 - INFO - volta.utils -   [GQA]: iter 22285 Ep: 6.05 loss 0.939 score 0.818 lr 3.10077e-05 
09/14/2020 06:48:40 - INFO - volta.utils -   [GQA]: iter 22305 Ep: 6.05 loss 0.944 score 0.812 lr 3.09956e-05 
09/14/2020 06:50:36 - INFO - volta.utils -   [GQA]: iter 22325 Ep: 6.06 loss 0.913 score 0.825 lr 3.09835e-05 
09/14/2020 06:51:24 - INFO - volta.utils -   [GQA]: iter 22345 Ep: 6.07 loss 0.956 score 0.813 lr 3.09715e-05 
09/14/2020 06:52:51 - INFO - volta.utils -   [GQA]: iter 22365 Ep: 6.07 loss 0.927 score 0.819 lr 3.09594e-05 
09/14/2020 06:54:18 - INFO - volta.utils -   [GQA]: iter 22385 Ep: 6.08 loss 0.962 score 0.821 lr 3.09473e-05 
09/14/2020 06:56:45 - INFO - volta.utils -   [GQA]: iter 22405 Ep: 6.08 loss 0.934 score 0.820 lr 3.09353e-05 
09/14/2020 06:57:58 - INFO - volta.utils -   [GQA]: iter 22425 Ep: 6.09 loss 0.947 score 0.816 lr 3.09232e-05 
09/14/2020 06:59:29 - INFO - volta.utils -   [GQA]: iter 22445 Ep: 6.09 loss 0.952 score 0.816 lr 3.09111e-05 
09/14/2020 07:00:52 - INFO - volta.utils -   [GQA]: iter 22465 Ep: 6.10 loss 0.985 score 0.806 lr 3.08991e-05 
09/14/2020 07:03:30 - INFO - volta.utils -   [GQA]: iter 22485 Ep: 6.10 loss 0.954 score 0.812 lr 3.0887e-05 
09/14/2020 07:04:54 - INFO - volta.utils -   [GQA]: iter 22505 Ep: 6.11 loss 0.969 score 0.812 lr 3.0875e-05 
09/14/2020 07:05:54 - INFO - volta.utils -   [GQA]: iter 22525 Ep: 6.11 loss 0.967 score 0.809 lr 3.08629e-05 
09/14/2020 07:07:27 - INFO - volta.utils -   [GQA]: iter 22545 Ep: 6.12 loss 0.967 score 0.809 lr 3.08508e-05 
09/14/2020 07:09:48 - INFO - volta.utils -   [GQA]: iter 22565 Ep: 6.13 loss 0.940 score 0.819 lr 3.08388e-05 
09/14/2020 07:10:54 - INFO - volta.utils -   [GQA]: iter 22585 Ep: 6.13 loss 0.917 score 0.819 lr 3.08267e-05 
09/14/2020 07:12:10 - INFO - volta.utils -   [GQA]: iter 22605 Ep: 6.14 loss 0.912 score 0.825 lr 3.08146e-05 
09/14/2020 07:13:09 - INFO - volta.utils -   [GQA]: iter 22625 Ep: 6.14 loss 0.960 score 0.813 lr 3.08026e-05 
09/14/2020 07:15:32 - INFO - volta.utils -   [GQA]: iter 22645 Ep: 6.15 loss 0.967 score 0.818 lr 3.07905e-05 
09/14/2020 07:16:52 - INFO - volta.utils -   [GQA]: iter 22665 Ep: 6.15 loss 0.931 score 0.820 lr 3.07784e-05 
09/14/2020 07:17:52 - INFO - volta.utils -   [GQA]: iter 22685 Ep: 6.16 loss 0.954 score 0.814 lr 3.07664e-05 
09/14/2020 07:19:21 - INFO - volta.utils -   [GQA]: iter 22705 Ep: 6.16 loss 0.967 score 0.810 lr 3.07543e-05 
09/14/2020 07:21:50 - INFO - volta.utils -   [GQA]: iter 22725 Ep: 6.17 loss 0.928 score 0.816 lr 3.07422e-05 
09/14/2020 07:22:55 - INFO - volta.utils -   [GQA]: iter 22745 Ep: 6.17 loss 0.925 score 0.822 lr 3.07302e-05 
09/14/2020 07:24:17 - INFO - volta.utils -   [GQA]: iter 22765 Ep: 6.18 loss 0.912 score 0.821 lr 3.07181e-05 
09/14/2020 07:25:48 - INFO - volta.utils -   [GQA]: iter 22785 Ep: 6.18 loss 0.950 score 0.817 lr 3.07061e-05 
09/14/2020 07:27:49 - INFO - volta.utils -   [GQA]: iter 22805 Ep: 6.19 loss 0.964 score 0.811 lr 3.0694e-05 
09/14/2020 07:29:09 - INFO - volta.utils -   [GQA]: iter 22825 Ep: 6.20 loss 0.950 score 0.812 lr 3.06819e-05 
09/14/2020 07:30:22 - INFO - volta.utils -   [GQA]: iter 22845 Ep: 6.20 loss 0.958 score 0.809 lr 3.06699e-05 
09/14/2020 07:31:39 - INFO - volta.utils -   [GQA]: iter 22865 Ep: 6.21 loss 0.947 score 0.813 lr 3.06578e-05 
09/14/2020 07:33:42 - INFO - volta.utils -   [GQA]: iter 22885 Ep: 6.21 loss 0.956 score 0.818 lr 3.06457e-05 
09/14/2020 07:34:44 - INFO - volta.utils -   [GQA]: iter 22905 Ep: 6.22 loss 0.960 score 0.819 lr 3.06337e-05 
09/14/2020 07:36:09 - INFO - volta.utils -   [GQA]: iter 22925 Ep: 6.22 loss 0.972 score 0.808 lr 3.06216e-05 
09/14/2020 07:37:37 - INFO - volta.utils -   [GQA]: iter 22945 Ep: 6.23 loss 0.959 score 0.806 lr 3.06095e-05 
09/14/2020 07:39:52 - INFO - volta.utils -   [GQA]: iter 22965 Ep: 6.23 loss 0.951 score 0.810 lr 3.05975e-05 
09/14/2020 07:41:26 - INFO - volta.utils -   [GQA]: iter 22985 Ep: 6.24 loss 0.956 score 0.818 lr 3.05854e-05 
09/14/2020 07:42:18 - INFO - volta.utils -   [GQA]: iter 23005 Ep: 6.24 loss 0.947 score 0.820 lr 3.05734e-05 
09/14/2020 07:43:42 - INFO - volta.utils -   [GQA]: iter 23025 Ep: 6.25 loss 0.964 score 0.813 lr 3.05613e-05 
09/14/2020 07:45:44 - INFO - volta.utils -   [GQA]: iter 23045 Ep: 6.26 loss 0.947 score 0.819 lr 3.05492e-05 
09/14/2020 07:47:21 - INFO - volta.utils -   [GQA]: iter 23065 Ep: 6.26 loss 0.930 score 0.819 lr 3.05372e-05 
09/14/2020 07:48:49 - INFO - volta.utils -   [GQA]: iter 23085 Ep: 6.27 loss 0.939 score 0.810 lr 3.05251e-05 
09/14/2020 07:49:58 - INFO - volta.utils -   [GQA]: iter 23105 Ep: 6.27 loss 0.917 score 0.827 lr 3.0513e-05 
09/14/2020 07:51:25 - INFO - volta.utils -   [GQA]: iter 23125 Ep: 6.28 loss 0.954 score 0.809 lr 3.0501e-05 
09/14/2020 07:53:05 - INFO - volta.utils -   [GQA]: iter 23145 Ep: 6.28 loss 0.984 score 0.802 lr 3.04889e-05 
09/14/2020 07:54:22 - INFO - volta.utils -   [GQA]: iter 23165 Ep: 6.29 loss 0.967 score 0.812 lr 3.04768e-05 
09/14/2020 07:55:26 - INFO - volta.utils -   [GQA]: iter 23185 Ep: 6.29 loss 0.954 score 0.817 lr 3.04648e-05 
09/14/2020 07:57:10 - INFO - volta.utils -   [GQA]: iter 23205 Ep: 6.30 loss 0.947 score 0.814 lr 3.04527e-05 
09/14/2020 07:58:51 - INFO - volta.utils -   [GQA]: iter 23225 Ep: 6.30 loss 0.942 score 0.805 lr 3.04406e-05 
09/14/2020 08:00:30 - INFO - volta.utils -   [GQA]: iter 23245 Ep: 6.31 loss 0.974 score 0.808 lr 3.04286e-05 
09/14/2020 08:01:47 - INFO - volta.utils -   [GQA]: iter 23265 Ep: 6.32 loss 0.945 score 0.811 lr 3.04165e-05 
09/14/2020 08:02:52 - INFO - volta.utils -   [GQA]: iter 23285 Ep: 6.32 loss 0.953 score 0.815 lr 3.04045e-05 
09/14/2020 08:04:29 - INFO - volta.utils -   [GQA]: iter 23305 Ep: 6.33 loss 0.951 score 0.816 lr 3.03924e-05 
09/14/2020 08:05:53 - INFO - volta.utils -   [GQA]: iter 23325 Ep: 6.33 loss 0.973 score 0.813 lr 3.03803e-05 
09/14/2020 08:07:05 - INFO - volta.utils -   [GQA]: iter 23345 Ep: 6.34 loss 0.935 score 0.818 lr 3.03683e-05 
09/14/2020 08:08:46 - INFO - volta.utils -   [GQA]: iter 23365 Ep: 6.34 loss 0.942 score 0.815 lr 3.03562e-05 
09/14/2020 08:10:56 - INFO - volta.utils -   [GQA]: iter 23385 Ep: 6.35 loss 0.908 score 0.822 lr 3.03441e-05 
09/14/2020 08:12:18 - INFO - volta.utils -   [GQA]: iter 23405 Ep: 6.35 loss 0.941 score 0.814 lr 3.03321e-05 
09/14/2020 08:13:19 - INFO - volta.utils -   [GQA]: iter 23425 Ep: 6.36 loss 0.944 score 0.809 lr 3.032e-05 
09/14/2020 08:14:43 - INFO - volta.utils -   [GQA]: iter 23445 Ep: 6.36 loss 0.914 score 0.819 lr 3.03079e-05 
09/14/2020 08:16:25 - INFO - volta.utils -   [GQA]: iter 23465 Ep: 6.37 loss 0.962 score 0.810 lr 3.02959e-05 
09/14/2020 08:17:49 - INFO - volta.utils -   [GQA]: iter 23485 Ep: 6.37 loss 0.982 score 0.811 lr 3.02838e-05 
09/14/2020 08:19:29 - INFO - volta.utils -   [GQA]: iter 23505 Ep: 6.38 loss 0.987 score 0.811 lr 3.02717e-05 
09/14/2020 08:20:56 - INFO - volta.utils -   [GQA]: iter 23525 Ep: 6.39 loss 0.961 score 0.809 lr 3.02597e-05 
09/14/2020 08:22:49 - INFO - volta.utils -   [GQA]: iter 23545 Ep: 6.39 loss 0.933 score 0.809 lr 3.02476e-05 
09/14/2020 08:24:18 - INFO - volta.utils -   [GQA]: iter 23565 Ep: 6.40 loss 0.969 score 0.808 lr 3.02356e-05 
09/14/2020 08:25:24 - INFO - volta.utils -   [GQA]: iter 23585 Ep: 6.40 loss 0.919 score 0.818 lr 3.02235e-05 
09/14/2020 08:26:53 - INFO - volta.utils -   [GQA]: iter 23605 Ep: 6.41 loss 0.947 score 0.816 lr 3.02114e-05 
09/14/2020 08:29:09 - INFO - volta.utils -   [GQA]: iter 23625 Ep: 6.41 loss 0.915 score 0.821 lr 3.01994e-05 
09/14/2020 08:30:36 - INFO - volta.utils -   [GQA]: iter 23645 Ep: 6.42 loss 0.953 score 0.815 lr 3.01873e-05 
09/14/2020 08:31:58 - INFO - volta.utils -   [GQA]: iter 23665 Ep: 6.42 loss 0.981 score 0.805 lr 3.01752e-05 
09/14/2020 08:33:46 - INFO - volta.utils -   [GQA]: iter 23685 Ep: 6.43 loss 0.947 score 0.821 lr 3.01632e-05 
09/14/2020 08:35:14 - INFO - volta.utils -   [GQA]: iter 23705 Ep: 6.43 loss 0.975 score 0.812 lr 3.01511e-05 
09/14/2020 08:36:40 - INFO - volta.utils -   [GQA]: iter 23725 Ep: 6.44 loss 0.967 score 0.814 lr 3.0139e-05 
09/14/2020 08:38:16 - INFO - volta.utils -   [GQA]: iter 23745 Ep: 6.45 loss 0.947 score 0.820 lr 3.0127e-05 
09/14/2020 08:39:39 - INFO - volta.utils -   [GQA]: iter 23765 Ep: 6.45 loss 0.991 score 0.809 lr 3.01149e-05 
09/14/2020 08:40:42 - INFO - volta.utils -   [GQA]: iter 23785 Ep: 6.46 loss 0.964 score 0.810 lr 3.01028e-05 
09/14/2020 08:42:02 - INFO - volta.utils -   [GQA]: iter 23805 Ep: 6.46 loss 0.953 score 0.816 lr 3.00908e-05 
09/14/2020 08:43:39 - INFO - volta.utils -   [GQA]: iter 23825 Ep: 6.47 loss 0.945 score 0.818 lr 3.00787e-05 
09/14/2020 08:44:53 - INFO - volta.utils -   [GQA]: iter 23845 Ep: 6.47 loss 0.957 score 0.816 lr 3.00667e-05 
09/14/2020 08:46:38 - INFO - volta.utils -   [GQA]: iter 23865 Ep: 6.48 loss 0.949 score 0.813 lr 3.00546e-05 
09/14/2020 08:47:38 - INFO - volta.utils -   [GQA]: iter 23885 Ep: 6.48 loss 0.952 score 0.807 lr 3.00425e-05 
09/14/2020 08:49:20 - INFO - volta.utils -   [GQA]: iter 23905 Ep: 6.49 loss 0.970 score 0.810 lr 3.00305e-05 
09/14/2020 08:50:53 - INFO - volta.utils -   [GQA]: iter 23925 Ep: 6.49 loss 0.941 score 0.821 lr 3.00184e-05 
09/14/2020 08:52:52 - INFO - volta.utils -   [GQA]: iter 23945 Ep: 6.50 loss 0.956 score 0.816 lr 3.00063e-05 
09/14/2020 08:53:33 - INFO - volta.utils -   [GQA]: iter 23965 Ep: 6.51 loss 0.979 score 0.807 lr 2.99943e-05 
09/14/2020 08:55:42 - INFO - volta.utils -   [GQA]: iter 23985 Ep: 6.51 loss 0.976 score 0.805 lr 2.99822e-05 
09/14/2020 08:57:09 - INFO - volta.utils -   [GQA]: iter 24005 Ep: 6.52 loss 0.987 score 0.806 lr 2.99701e-05 
09/14/2020 08:58:55 - INFO - volta.utils -   [GQA]: iter 24025 Ep: 6.52 loss 0.930 score 0.820 lr 2.99581e-05 
09/14/2020 09:00:16 - INFO - volta.utils -   [GQA]: iter 24045 Ep: 6.53 loss 0.983 score 0.807 lr 2.9946e-05 
09/14/2020 09:01:59 - INFO - volta.utils -   [GQA]: iter 24065 Ep: 6.53 loss 0.921 score 0.825 lr 2.99339e-05 
09/14/2020 09:03:09 - INFO - volta.utils -   [GQA]: iter 24085 Ep: 6.54 loss 0.934 score 0.816 lr 2.99219e-05 
09/14/2020 09:05:24 - INFO - volta.utils -   [GQA]: iter 24105 Ep: 6.54 loss 0.928 score 0.825 lr 2.99098e-05 
09/14/2020 09:06:44 - INFO - volta.utils -   [GQA]: iter 24125 Ep: 6.55 loss 0.965 score 0.807 lr 2.98978e-05 
09/14/2020 09:07:43 - INFO - volta.utils -   [GQA]: iter 24145 Ep: 6.55 loss 0.988 score 0.803 lr 2.98857e-05 
09/14/2020 09:09:06 - INFO - volta.utils -   [GQA]: iter 24165 Ep: 6.56 loss 1.003 score 0.802 lr 2.98736e-05 
09/14/2020 09:10:53 - INFO - volta.utils -   [GQA]: iter 24185 Ep: 6.56 loss 0.994 score 0.803 lr 2.98616e-05 
09/14/2020 09:12:12 - INFO - volta.utils -   [GQA]: iter 24205 Ep: 6.57 loss 0.935 score 0.820 lr 2.98495e-05 
09/14/2020 09:13:39 - INFO - volta.utils -   [GQA]: iter 24225 Ep: 6.58 loss 0.955 score 0.810 lr 2.98374e-05 
09/14/2020 09:14:43 - INFO - volta.utils -   [GQA]: iter 24245 Ep: 6.58 loss 0.954 score 0.810 lr 2.98254e-05 
09/14/2020 09:17:02 - INFO - volta.utils -   [GQA]: iter 24265 Ep: 6.59 loss 0.960 score 0.816 lr 2.98133e-05 
09/14/2020 09:18:38 - INFO - volta.utils -   [GQA]: iter 24285 Ep: 6.59 loss 0.937 score 0.819 lr 2.98012e-05 
09/14/2020 09:19:41 - INFO - volta.utils -   [GQA]: iter 24305 Ep: 6.60 loss 0.920 score 0.817 lr 2.97892e-05 
09/14/2020 09:21:22 - INFO - volta.utils -   [GQA]: iter 24325 Ep: 6.60 loss 0.935 score 0.816 lr 2.97771e-05 
09/14/2020 09:23:33 - INFO - volta.utils -   [GQA]: iter 24345 Ep: 6.61 loss 0.993 score 0.802 lr 2.97651e-05 
09/14/2020 09:24:43 - INFO - volta.utils -   [GQA]: iter 24365 Ep: 6.61 loss 0.957 score 0.808 lr 2.9753e-05 
09/14/2020 09:26:18 - INFO - volta.utils -   [GQA]: iter 24385 Ep: 6.62 loss 0.905 score 0.822 lr 2.97409e-05 
09/14/2020 09:27:54 - INFO - volta.utils -   [GQA]: iter 24405 Ep: 6.62 loss 0.970 score 0.809 lr 2.97289e-05 
09/14/2020 09:29:48 - INFO - volta.utils -   [GQA]: iter 24425 Ep: 6.63 loss 0.950 score 0.812 lr 2.97168e-05 
09/14/2020 09:31:23 - INFO - volta.utils -   [GQA]: iter 24445 Ep: 6.64 loss 0.951 score 0.816 lr 2.97047e-05 
09/14/2020 09:32:32 - INFO - volta.utils -   [GQA]: iter 24465 Ep: 6.64 loss 0.968 score 0.808 lr 2.96927e-05 
09/14/2020 09:33:58 - INFO - volta.utils -   [GQA]: iter 24485 Ep: 6.65 loss 0.947 score 0.816 lr 2.96806e-05 
09/14/2020 09:35:51 - INFO - volta.utils -   [GQA]: iter 24505 Ep: 6.65 loss 1.007 score 0.802 lr 2.96685e-05 
09/14/2020 09:37:18 - INFO - volta.utils -   [GQA]: iter 24525 Ep: 6.66 loss 0.971 score 0.808 lr 2.96565e-05 
09/14/2020 09:37:53 - INFO - volta.utils -   [GQA]: iter 24545 Ep: 6.66 loss 0.967 score 0.814 lr 2.96444e-05 
09/14/2020 09:39:12 - INFO - volta.utils -   [GQA]: iter 24565 Ep: 6.67 loss 0.967 score 0.809 lr 2.96323e-05 
09/14/2020 09:40:45 - INFO - volta.utils -   [GQA]: iter 24585 Ep: 6.67 loss 0.964 score 0.810 lr 2.96203e-05 
09/14/2020 09:42:15 - INFO - volta.utils -   [GQA]: iter 24605 Ep: 6.68 loss 0.939 score 0.820 lr 2.96082e-05 
09/14/2020 09:43:31 - INFO - volta.utils -   [GQA]: iter 24625 Ep: 6.68 loss 0.972 score 0.810 lr 2.95962e-05 
09/14/2020 09:44:18 - INFO - volta.utils -   [GQA]: iter 24645 Ep: 6.69 loss 0.964 score 0.810 lr 2.95841e-05 
09/14/2020 09:46:03 - INFO - volta.utils -   [GQA]: iter 24665 Ep: 6.70 loss 0.970 score 0.808 lr 2.9572e-05 
09/14/2020 09:47:34 - INFO - volta.utils -   [GQA]: iter 24685 Ep: 6.70 loss 0.940 score 0.811 lr 2.956e-05 
09/14/2020 09:48:48 - INFO - volta.utils -   [GQA]: iter 24705 Ep: 6.71 loss 0.954 score 0.814 lr 2.95479e-05 
09/14/2020 09:49:54 - INFO - volta.utils -   [GQA]: iter 24725 Ep: 6.71 loss 0.993 score 0.807 lr 2.95358e-05 
09/14/2020 09:51:49 - INFO - volta.utils -   [GQA]: iter 24745 Ep: 6.72 loss 0.975 score 0.808 lr 2.95238e-05 
09/14/2020 09:53:31 - INFO - volta.utils -   [GQA]: iter 24765 Ep: 6.72 loss 0.965 score 0.812 lr 2.95117e-05 
09/14/2020 09:55:39 - INFO - volta.utils -   [GQA]: iter 24785 Ep: 6.73 loss 0.947 score 0.815 lr 2.94996e-05 
09/14/2020 09:56:57 - INFO - volta.utils -   [GQA]: iter 24805 Ep: 6.73 loss 0.925 score 0.821 lr 2.94876e-05 
09/14/2020 09:58:22 - INFO - volta.utils -   [GQA]: iter 24825 Ep: 6.74 loss 0.937 score 0.823 lr 2.94755e-05 
09/14/2020 10:00:06 - INFO - volta.utils -   [GQA]: iter 24845 Ep: 6.74 loss 0.956 score 0.813 lr 2.94634e-05 
09/14/2020 10:01:43 - INFO - volta.utils -   [GQA]: iter 24865 Ep: 6.75 loss 0.986 score 0.807 lr 2.94514e-05 
09/14/2020 10:03:22 - INFO - volta.utils -   [GQA]: iter 24885 Ep: 6.75 loss 0.990 score 0.809 lr 2.94393e-05 
09/14/2020 10:04:43 - INFO - volta.utils -   [GQA]: iter 24905 Ep: 6.76 loss 0.981 score 0.803 lr 2.94273e-05 
09/14/2020 10:06:32 - INFO - volta.utils -   [GQA]: iter 24925 Ep: 6.77 loss 0.980 score 0.809 lr 2.94152e-05 
09/14/2020 10:07:38 - INFO - volta.utils -   [GQA]: iter 24945 Ep: 6.77 loss 0.955 score 0.810 lr 2.94031e-05 
09/14/2020 10:09:00 - INFO - volta.utils -   [GQA]: iter 24965 Ep: 6.78 loss 0.977 score 0.815 lr 2.93911e-05 
09/14/2020 10:10:35 - INFO - volta.utils -   [GQA]: iter 24985 Ep: 6.78 loss 0.946 score 0.818 lr 2.9379e-05 
09/14/2020 10:12:28 - INFO - volta.utils -   [GQA]: iter 25005 Ep: 6.79 loss 0.965 score 0.810 lr 2.93669e-05 
09/14/2020 10:13:55 - INFO - volta.utils -   [GQA]: iter 25025 Ep: 6.79 loss 0.933 score 0.816 lr 2.93549e-05 
09/14/2020 10:15:18 - INFO - volta.utils -   [GQA]: iter 25045 Ep: 6.80 loss 0.923 score 0.822 lr 2.93428e-05 
09/14/2020 10:16:11 - INFO - volta.utils -   [GQA]: iter 25065 Ep: 6.80 loss 0.932 score 0.818 lr 2.93307e-05 
09/14/2020 10:17:44 - INFO - volta.utils -   [GQA]: iter 25085 Ep: 6.81 loss 0.946 score 0.814 lr 2.93187e-05 
09/14/2020 10:19:06 - INFO - volta.utils -   [GQA]: iter 25105 Ep: 6.81 loss 0.957 score 0.819 lr 2.93066e-05 
09/14/2020 10:19:53 - INFO - volta.utils -   [GQA]: iter 25125 Ep: 6.82 loss 0.982 score 0.809 lr 2.92945e-05 
09/14/2020 10:21:18 - INFO - volta.utils -   [GQA]: iter 25145 Ep: 6.83 loss 0.981 score 0.812 lr 2.92825e-05 
09/14/2020 10:23:18 - INFO - volta.utils -   [GQA]: iter 25165 Ep: 6.83 loss 0.972 score 0.811 lr 2.92704e-05 
09/14/2020 10:24:44 - INFO - volta.utils -   [GQA]: iter 25185 Ep: 6.84 loss 0.968 score 0.806 lr 2.92584e-05 
09/14/2020 10:26:11 - INFO - volta.utils -   [GQA]: iter 25205 Ep: 6.84 loss 0.975 score 0.810 lr 2.92463e-05 
09/14/2020 10:27:33 - INFO - volta.utils -   [GQA]: iter 25225 Ep: 6.85 loss 0.952 score 0.818 lr 2.92342e-05 
09/14/2020 10:30:03 - INFO - volta.utils -   [GQA]: iter 25245 Ep: 6.85 loss 0.980 score 0.809 lr 2.92222e-05 
09/14/2020 10:31:06 - INFO - volta.utils -   [GQA]: iter 25265 Ep: 6.86 loss 0.980 score 0.808 lr 2.92101e-05 
09/14/2020 10:32:40 - INFO - volta.utils -   [GQA]: iter 25285 Ep: 6.86 loss 0.943 score 0.813 lr 2.9198e-05 
09/14/2020 10:33:58 - INFO - volta.utils -   [GQA]: iter 25305 Ep: 6.87 loss 0.959 score 0.813 lr 2.9186e-05 
09/14/2020 10:36:09 - INFO - volta.utils -   [GQA]: iter 25325 Ep: 6.87 loss 0.968 score 0.811 lr 2.91739e-05 
09/14/2020 10:37:38 - INFO - volta.utils -   [GQA]: iter 25345 Ep: 6.88 loss 0.966 score 0.807 lr 2.91618e-05 
09/14/2020 10:39:04 - INFO - volta.utils -   [GQA]: iter 25365 Ep: 6.89 loss 0.924 score 0.821 lr 2.91498e-05 
09/14/2020 10:40:23 - INFO - volta.utils -   [GQA]: iter 25385 Ep: 6.89 loss 0.936 score 0.817 lr 2.91377e-05 
09/14/2020 10:41:52 - INFO - volta.utils -   [GQA]: iter 25405 Ep: 6.90 loss 0.965 score 0.809 lr 2.91256e-05 
09/14/2020 10:44:11 - INFO - volta.utils -   [GQA]: iter 25425 Ep: 6.90 loss 0.943 score 0.813 lr 2.91136e-05 
09/14/2020 10:45:25 - INFO - volta.utils -   [GQA]: iter 25445 Ep: 6.91 loss 0.997 score 0.809 lr 2.91015e-05 
09/14/2020 10:46:24 - INFO - volta.utils -   [GQA]: iter 25465 Ep: 6.91 loss 0.976 score 0.807 lr 2.90895e-05 
09/14/2020 10:48:54 - INFO - volta.utils -   [GQA]: iter 25485 Ep: 6.92 loss 0.929 score 0.820 lr 2.90774e-05 
09/14/2020 10:50:37 - INFO - volta.utils -   [GQA]: iter 25505 Ep: 6.92 loss 0.933 score 0.814 lr 2.90653e-05 
09/14/2020 10:51:36 - INFO - volta.utils -   [GQA]: iter 25525 Ep: 6.93 loss 0.956 score 0.815 lr 2.90533e-05 
09/14/2020 10:53:04 - INFO - volta.utils -   [GQA]: iter 25545 Ep: 6.93 loss 0.988 score 0.809 lr 2.90412e-05 
09/14/2020 10:55:22 - INFO - volta.utils -   [GQA]: iter 25565 Ep: 6.94 loss 0.975 score 0.816 lr 2.90291e-05 
09/14/2020 10:57:07 - INFO - volta.utils -   [GQA]: iter 25585 Ep: 6.94 loss 0.957 score 0.809 lr 2.90171e-05 
09/14/2020 10:58:28 - INFO - volta.utils -   [GQA]: iter 25605 Ep: 6.95 loss 0.936 score 0.812 lr 2.9005e-05 
09/14/2020 11:00:01 - INFO - volta.utils -   [GQA]: iter 25625 Ep: 6.96 loss 0.960 score 0.813 lr 2.89929e-05 
09/14/2020 11:01:14 - INFO - volta.utils -   [GQA]: iter 25645 Ep: 6.96 loss 0.951 score 0.817 lr 2.89809e-05 
09/14/2020 11:03:16 - INFO - volta.utils -   [GQA]: iter 25665 Ep: 6.97 loss 0.983 score 0.808 lr 2.89688e-05 
09/14/2020 11:04:47 - INFO - volta.utils -   [GQA]: iter 25685 Ep: 6.97 loss 0.936 score 0.820 lr 2.89567e-05 
09/14/2020 11:05:34 - INFO - volta.utils -   [GQA]: iter 25705 Ep: 6.98 loss 0.933 score 0.823 lr 2.89447e-05 
09/14/2020 11:06:46 - INFO - volta.utils -   [GQA]: iter 25725 Ep: 6.98 loss 0.943 score 0.814 lr 2.89326e-05 
09/14/2020 11:08:36 - INFO - volta.utils -   [GQA]: iter 25745 Ep: 6.99 loss 0.979 score 0.814 lr 2.89206e-05 
09/14/2020 11:10:09 - INFO - volta.utils -   [GQA]: iter 25765 Ep: 6.99 loss 0.947 score 0.809 lr 2.89085e-05 
09/14/2020 11:11:19 - INFO - volta.utils -   [GQA]: iter 25785 Ep: 7.00 loss 0.951 score 0.815 lr 2.88964e-05 
09/14/2020 11:11:20 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  19%|        | 3/16 [15:21:05<67:26:10, 18674.65s/it]09/14/2020 11:30:43 - INFO - volta.utils -   Eval task TASK15 on iteration 25789 
09/14/2020 11:30:43 - INFO - volta.utils -   Validation [GQA]: loss 2.038 score 64.639 
09/14/2020 11:30:57 - INFO - volta.utils -   [GQA]: iter 25809 Ep: 7.01 loss 0.812 score 0.851 lr 2.88832e-05 
09/14/2020 11:31:55 - INFO - volta.utils -   [GQA]: iter 25829 Ep: 7.01 loss 0.723 score 0.866 lr 2.88699e-05 
09/14/2020 11:33:05 - INFO - volta.utils -   [GQA]: iter 25849 Ep: 7.02 loss 0.729 score 0.865 lr 2.88578e-05 
09/14/2020 11:33:53 - INFO - volta.utils -   [GQA]: iter 25869 Ep: 7.02 loss 0.737 score 0.861 lr 2.88458e-05 
09/14/2020 11:35:45 - INFO - volta.utils -   [GQA]: iter 25889 Ep: 7.03 loss 0.781 score 0.854 lr 2.88337e-05 
09/14/2020 11:36:59 - INFO - volta.utils -   [GQA]: iter 25909 Ep: 7.03 loss 0.740 score 0.861 lr 2.88216e-05 
09/14/2020 11:38:01 - INFO - volta.utils -   [GQA]: iter 25929 Ep: 7.04 loss 0.736 score 0.860 lr 2.88096e-05 
09/14/2020 11:38:56 - INFO - volta.utils -   [GQA]: iter 25949 Ep: 7.04 loss 0.754 score 0.862 lr 2.87975e-05 
09/14/2020 11:41:17 - INFO - volta.utils -   [GQA]: iter 25969 Ep: 7.05 loss 0.766 score 0.857 lr 2.87854e-05 
09/14/2020 11:42:19 - INFO - volta.utils -   [GQA]: iter 25989 Ep: 7.05 loss 0.745 score 0.864 lr 2.87734e-05 
09/14/2020 11:43:28 - INFO - volta.utils -   [GQA]: iter 26009 Ep: 7.06 loss 0.759 score 0.857 lr 2.87613e-05 
09/14/2020 11:44:15 - INFO - volta.utils -   [GQA]: iter 26029 Ep: 7.07 loss 0.716 score 0.872 lr 2.87492e-05 
09/14/2020 11:46:42 - INFO - volta.utils -   [GQA]: iter 26049 Ep: 7.07 loss 0.761 score 0.851 lr 2.87372e-05 
09/14/2020 11:47:24 - INFO - volta.utils -   [GQA]: iter 26069 Ep: 7.08 loss 0.746 score 0.862 lr 2.87251e-05 
09/14/2020 11:48:45 - INFO - volta.utils -   [GQA]: iter 26089 Ep: 7.08 loss 0.743 score 0.864 lr 2.87131e-05 
09/14/2020 11:50:00 - INFO - volta.utils -   [GQA]: iter 26109 Ep: 7.09 loss 0.739 score 0.861 lr 2.8701e-05 
09/14/2020 11:52:09 - INFO - volta.utils -   [GQA]: iter 26129 Ep: 7.09 loss 0.749 score 0.858 lr 2.86889e-05 
09/14/2020 11:53:25 - INFO - volta.utils -   [GQA]: iter 26149 Ep: 7.10 loss 0.753 score 0.858 lr 2.86769e-05 
09/14/2020 11:54:19 - INFO - volta.utils -   [GQA]: iter 26169 Ep: 7.10 loss 0.784 score 0.857 lr 2.86648e-05 
09/14/2020 11:56:24 - INFO - volta.utils -   [GQA]: iter 26189 Ep: 7.11 loss 0.746 score 0.856 lr 2.86527e-05 
09/14/2020 11:58:25 - INFO - volta.utils -   [GQA]: iter 26209 Ep: 7.11 loss 0.770 score 0.856 lr 2.86407e-05 
09/14/2020 11:59:59 - INFO - volta.utils -   [GQA]: iter 26229 Ep: 7.12 loss 0.756 score 0.859 lr 2.86286e-05 
09/14/2020 12:01:07 - INFO - volta.utils -   [GQA]: iter 26249 Ep: 7.13 loss 0.781 score 0.851 lr 2.86165e-05 
09/14/2020 12:03:37 - INFO - volta.utils -   [GQA]: iter 26269 Ep: 7.13 loss 0.747 score 0.860 lr 2.86045e-05 
09/14/2020 12:05:29 - INFO - volta.utils -   [GQA]: iter 26289 Ep: 7.14 loss 0.743 score 0.856 lr 2.85924e-05 
09/14/2020 12:06:46 - INFO - volta.utils -   [GQA]: iter 26309 Ep: 7.14 loss 0.760 score 0.854 lr 2.85803e-05 
09/14/2020 12:07:46 - INFO - volta.utils -   [GQA]: iter 26329 Ep: 7.15 loss 0.761 score 0.854 lr 2.85683e-05 
09/14/2020 12:09:36 - INFO - volta.utils -   [GQA]: iter 26349 Ep: 7.15 loss 0.793 score 0.849 lr 2.85562e-05 
09/14/2020 12:11:09 - INFO - volta.utils -   [GQA]: iter 26369 Ep: 7.16 loss 0.760 score 0.856 lr 2.85442e-05 
09/14/2020 12:12:46 - INFO - volta.utils -   [GQA]: iter 26389 Ep: 7.16 loss 0.763 score 0.853 lr 2.85321e-05 
09/14/2020 12:14:21 - INFO - volta.utils -   [GQA]: iter 26409 Ep: 7.17 loss 0.763 score 0.854 lr 2.852e-05 
09/14/2020 12:15:23 - INFO - volta.utils -   [GQA]: iter 26429 Ep: 7.17 loss 0.727 score 0.859 lr 2.8508e-05 
09/14/2020 12:17:31 - INFO - volta.utils -   [GQA]: iter 26449 Ep: 7.18 loss 0.770 score 0.848 lr 2.84959e-05 
09/14/2020 12:19:02 - INFO - volta.utils -   [GQA]: iter 26469 Ep: 7.18 loss 0.764 score 0.854 lr 2.84838e-05 
09/14/2020 12:20:23 - INFO - volta.utils -   [GQA]: iter 26489 Ep: 7.19 loss 0.749 score 0.858 lr 2.84718e-05 
09/14/2020 12:21:45 - INFO - volta.utils -   [GQA]: iter 26509 Ep: 7.20 loss 0.782 score 0.854 lr 2.84597e-05 
09/14/2020 12:24:06 - INFO - volta.utils -   [GQA]: iter 26529 Ep: 7.20 loss 0.761 score 0.860 lr 2.84476e-05 
09/14/2020 12:25:28 - INFO - volta.utils -   [GQA]: iter 26549 Ep: 7.21 loss 0.779 score 0.854 lr 2.84356e-05 
09/14/2020 12:26:41 - INFO - volta.utils -   [GQA]: iter 26569 Ep: 7.21 loss 0.781 score 0.852 lr 2.84235e-05 
09/14/2020 12:28:27 - INFO - volta.utils -   [GQA]: iter 26589 Ep: 7.22 loss 0.792 score 0.848 lr 2.84114e-05 
09/14/2020 12:29:58 - INFO - volta.utils -   [GQA]: iter 26609 Ep: 7.22 loss 0.770 score 0.848 lr 2.83994e-05 
09/14/2020 12:31:41 - INFO - volta.utils -   [GQA]: iter 26629 Ep: 7.23 loss 0.764 score 0.857 lr 2.83873e-05 
09/14/2020 12:33:08 - INFO - volta.utils -   [GQA]: iter 26649 Ep: 7.23 loss 0.767 score 0.854 lr 2.83753e-05 
09/14/2020 12:34:41 - INFO - volta.utils -   [GQA]: iter 26669 Ep: 7.24 loss 0.804 score 0.845 lr 2.83632e-05 
09/14/2020 12:36:47 - INFO - volta.utils -   [GQA]: iter 26689 Ep: 7.24 loss 0.772 score 0.850 lr 2.83511e-05 
09/14/2020 12:38:24 - INFO - volta.utils -   [GQA]: iter 26709 Ep: 7.25 loss 0.783 score 0.847 lr 2.83391e-05 
09/14/2020 12:39:50 - INFO - volta.utils -   [GQA]: iter 26729 Ep: 7.26 loss 0.776 score 0.850 lr 2.8327e-05 
09/14/2020 12:41:16 - INFO - volta.utils -   [GQA]: iter 26749 Ep: 7.26 loss 0.799 score 0.849 lr 2.83149e-05 
09/14/2020 12:43:34 - INFO - volta.utils -   [GQA]: iter 26769 Ep: 7.27 loss 0.776 score 0.854 lr 2.83029e-05 
09/14/2020 12:44:55 - INFO - volta.utils -   [GQA]: iter 26789 Ep: 7.27 loss 0.745 score 0.859 lr 2.82908e-05 
09/14/2020 12:46:00 - INFO - volta.utils -   [GQA]: iter 26809 Ep: 7.28 loss 0.785 score 0.850 lr 2.82787e-05 
09/14/2020 12:47:21 - INFO - volta.utils -   [GQA]: iter 26829 Ep: 7.28 loss 0.776 score 0.845 lr 2.82667e-05 
09/14/2020 12:49:15 - INFO - volta.utils -   [GQA]: iter 26849 Ep: 7.29 loss 0.781 score 0.851 lr 2.82546e-05 
09/14/2020 12:50:45 - INFO - volta.utils -   [GQA]: iter 26869 Ep: 7.29 loss 0.772 score 0.857 lr 2.82426e-05 
09/14/2020 12:52:13 - INFO - volta.utils -   [GQA]: iter 26889 Ep: 7.30 loss 0.769 score 0.854 lr 2.82305e-05 
09/14/2020 12:53:28 - INFO - volta.utils -   [GQA]: iter 26909 Ep: 7.30 loss 0.782 score 0.848 lr 2.82184e-05 
09/14/2020 12:55:49 - INFO - volta.utils -   [GQA]: iter 26929 Ep: 7.31 loss 0.779 score 0.855 lr 2.82064e-05 
09/14/2020 12:57:11 - INFO - volta.utils -   [GQA]: iter 26949 Ep: 7.32 loss 0.768 score 0.855 lr 2.81943e-05 
09/14/2020 12:58:34 - INFO - volta.utils -   [GQA]: iter 26969 Ep: 7.32 loss 0.818 score 0.843 lr 2.81822e-05 
09/14/2020 12:59:23 - INFO - volta.utils -   [GQA]: iter 26989 Ep: 7.33 loss 0.803 score 0.846 lr 2.81702e-05 
09/14/2020 13:01:19 - INFO - volta.utils -   [GQA]: iter 27009 Ep: 7.33 loss 0.742 score 0.859 lr 2.81581e-05 
09/14/2020 13:02:48 - INFO - volta.utils -   [GQA]: iter 27029 Ep: 7.34 loss 0.775 score 0.857 lr 2.8146e-05 
09/14/2020 13:04:22 - INFO - volta.utils -   [GQA]: iter 27049 Ep: 7.34 loss 0.755 score 0.856 lr 2.8134e-05 
09/14/2020 13:05:30 - INFO - volta.utils -   [GQA]: iter 27069 Ep: 7.35 loss 0.742 score 0.856 lr 2.81219e-05 
09/14/2020 13:07:41 - INFO - volta.utils -   [GQA]: iter 27089 Ep: 7.35 loss 0.794 score 0.844 lr 2.81098e-05 
09/14/2020 13:08:43 - INFO - volta.utils -   [GQA]: iter 27109 Ep: 7.36 loss 0.796 score 0.849 lr 2.80978e-05 
09/14/2020 13:10:01 - INFO - volta.utils -   [GQA]: iter 27129 Ep: 7.36 loss 0.762 score 0.852 lr 2.80857e-05 
09/14/2020 13:10:48 - INFO - volta.utils -   [GQA]: iter 27149 Ep: 7.37 loss 0.819 score 0.846 lr 2.80737e-05 
09/14/2020 13:12:44 - INFO - volta.utils -   [GQA]: iter 27169 Ep: 7.37 loss 0.778 score 0.852 lr 2.80616e-05 
09/14/2020 13:13:52 - INFO - volta.utils -   [GQA]: iter 27189 Ep: 7.38 loss 0.810 score 0.846 lr 2.80495e-05 
09/14/2020 13:15:14 - INFO - volta.utils -   [GQA]: iter 27209 Ep: 7.39 loss 0.751 score 0.858 lr 2.80375e-05 
09/14/2020 13:16:55 - INFO - volta.utils -   [GQA]: iter 27229 Ep: 7.39 loss 0.808 score 0.846 lr 2.80254e-05 
09/14/2020 13:18:59 - INFO - volta.utils -   [GQA]: iter 27249 Ep: 7.40 loss 0.770 score 0.860 lr 2.80133e-05 
09/14/2020 13:20:48 - INFO - volta.utils -   [GQA]: iter 27269 Ep: 7.40 loss 0.777 score 0.850 lr 2.80013e-05 
09/14/2020 13:22:21 - INFO - volta.utils -   [GQA]: iter 27289 Ep: 7.41 loss 0.792 score 0.852 lr 2.79892e-05 
09/14/2020 13:22:55 - INFO - volta.utils -   [GQA]: iter 27309 Ep: 7.41 loss 0.785 score 0.847 lr 2.79771e-05 
09/14/2020 13:25:07 - INFO - volta.utils -   [GQA]: iter 27329 Ep: 7.42 loss 0.804 score 0.849 lr 2.79651e-05 
09/14/2020 13:26:49 - INFO - volta.utils -   [GQA]: iter 27349 Ep: 7.42 loss 0.798 score 0.849 lr 2.7953e-05 
09/14/2020 13:28:12 - INFO - volta.utils -   [GQA]: iter 27369 Ep: 7.43 loss 0.836 score 0.836 lr 2.79409e-05 
09/14/2020 13:29:14 - INFO - volta.utils -   [GQA]: iter 27389 Ep: 7.43 loss 0.765 score 0.860 lr 2.79289e-05 
09/14/2020 13:30:16 - INFO - volta.utils -   [GQA]: iter 27409 Ep: 7.44 loss 0.766 score 0.857 lr 2.79168e-05 
09/14/2020 13:32:44 - INFO - volta.utils -   [GQA]: iter 27429 Ep: 7.45 loss 0.754 score 0.853 lr 2.79048e-05 
09/14/2020 13:33:47 - INFO - volta.utils -   [GQA]: iter 27449 Ep: 7.45 loss 0.832 score 0.842 lr 2.78927e-05 
09/14/2020 13:34:43 - INFO - volta.utils -   [GQA]: iter 27469 Ep: 7.46 loss 0.765 score 0.854 lr 2.78806e-05 
09/14/2020 13:36:57 - INFO - volta.utils -   [GQA]: iter 27489 Ep: 7.46 loss 0.804 score 0.847 lr 2.78686e-05 
09/14/2020 13:38:44 - INFO - volta.utils -   [GQA]: iter 27509 Ep: 7.47 loss 0.792 score 0.849 lr 2.78565e-05 
09/14/2020 13:40:54 - INFO - volta.utils -   [GQA]: iter 27529 Ep: 7.47 loss 0.767 score 0.855 lr 2.78444e-05 
09/14/2020 13:41:34 - INFO - volta.utils -   [GQA]: iter 27549 Ep: 7.48 loss 0.801 score 0.847 lr 2.78324e-05 
09/14/2020 13:43:08 - INFO - volta.utils -   [GQA]: iter 27569 Ep: 7.48 loss 0.790 score 0.846 lr 2.78203e-05 
09/14/2020 13:44:46 - INFO - volta.utils -   [GQA]: iter 27589 Ep: 7.49 loss 0.806 score 0.840 lr 2.78082e-05 
09/14/2020 13:46:29 - INFO - volta.utils -   [GQA]: iter 27609 Ep: 7.49 loss 0.747 score 0.857 lr 2.77962e-05 
09/14/2020 13:47:39 - INFO - volta.utils -   [GQA]: iter 27629 Ep: 7.50 loss 0.750 score 0.856 lr 2.77841e-05 
09/14/2020 13:49:58 - INFO - volta.utils -   [GQA]: iter 27649 Ep: 7.51 loss 0.788 score 0.846 lr 2.7772e-05 
09/14/2020 13:51:01 - INFO - volta.utils -   [GQA]: iter 27669 Ep: 7.51 loss 0.838 score 0.841 lr 2.776e-05 
09/14/2020 13:52:57 - INFO - volta.utils -   [GQA]: iter 27689 Ep: 7.52 loss 0.751 score 0.858 lr 2.77479e-05 
09/14/2020 13:53:54 - INFO - volta.utils -   [GQA]: iter 27709 Ep: 7.52 loss 0.801 score 0.847 lr 2.77359e-05 
09/14/2020 13:55:18 - INFO - volta.utils -   [GQA]: iter 27729 Ep: 7.53 loss 0.779 score 0.852 lr 2.77238e-05 
09/14/2020 13:56:46 - INFO - volta.utils -   [GQA]: iter 27749 Ep: 7.53 loss 0.793 score 0.852 lr 2.77117e-05 
09/14/2020 13:58:28 - INFO - volta.utils -   [GQA]: iter 27769 Ep: 7.54 loss 0.814 score 0.838 lr 2.76997e-05 
09/14/2020 13:59:46 - INFO - volta.utils -   [GQA]: iter 27789 Ep: 7.54 loss 0.816 score 0.844 lr 2.76876e-05 
09/14/2020 14:00:47 - INFO - volta.utils -   [GQA]: iter 27809 Ep: 7.55 loss 0.809 score 0.843 lr 2.76755e-05 
09/14/2020 14:02:09 - INFO - volta.utils -   [GQA]: iter 27829 Ep: 7.55 loss 0.806 score 0.844 lr 2.76635e-05 
09/14/2020 14:03:55 - INFO - volta.utils -   [GQA]: iter 27849 Ep: 7.56 loss 0.810 score 0.842 lr 2.76514e-05 
09/14/2020 14:05:27 - INFO - volta.utils -   [GQA]: iter 27869 Ep: 7.56 loss 0.786 score 0.848 lr 2.76393e-05 
09/14/2020 14:06:34 - INFO - volta.utils -   [GQA]: iter 27889 Ep: 7.57 loss 0.784 score 0.851 lr 2.76273e-05 
09/14/2020 14:08:15 - INFO - volta.utils -   [GQA]: iter 27909 Ep: 7.58 loss 0.797 score 0.847 lr 2.76152e-05 
09/14/2020 14:10:38 - INFO - volta.utils -   [GQA]: iter 27929 Ep: 7.58 loss 0.811 score 0.851 lr 2.76031e-05 
09/14/2020 14:12:07 - INFO - volta.utils -   [GQA]: iter 27949 Ep: 7.59 loss 0.789 score 0.852 lr 2.75911e-05 
09/14/2020 14:13:03 - INFO - volta.utils -   [GQA]: iter 27969 Ep: 7.59 loss 0.829 score 0.839 lr 2.7579e-05 
09/14/2020 14:14:38 - INFO - volta.utils -   [GQA]: iter 27989 Ep: 7.60 loss 0.767 score 0.853 lr 2.7567e-05 
09/14/2020 14:16:07 - INFO - volta.utils -   [GQA]: iter 28009 Ep: 7.60 loss 0.770 score 0.854 lr 2.75549e-05 
09/14/2020 14:18:08 - INFO - volta.utils -   [GQA]: iter 28029 Ep: 7.61 loss 0.797 score 0.848 lr 2.75428e-05 
09/14/2020 14:19:29 - INFO - volta.utils -   [GQA]: iter 28049 Ep: 7.61 loss 0.829 score 0.839 lr 2.75308e-05 
09/14/2020 14:20:56 - INFO - volta.utils -   [GQA]: iter 28069 Ep: 7.62 loss 0.765 score 0.853 lr 2.75187e-05 
09/14/2020 14:22:42 - INFO - volta.utils -   [GQA]: iter 28089 Ep: 7.62 loss 0.814 score 0.843 lr 2.75066e-05 
09/14/2020 14:24:32 - INFO - volta.utils -   [GQA]: iter 28109 Ep: 7.63 loss 0.817 score 0.841 lr 2.74946e-05 
09/14/2020 14:25:49 - INFO - volta.utils -   [GQA]: iter 28129 Ep: 7.64 loss 0.808 score 0.840 lr 2.74825e-05 
09/14/2020 14:26:42 - INFO - volta.utils -   [GQA]: iter 28149 Ep: 7.64 loss 0.773 score 0.851 lr 2.74704e-05 
09/14/2020 14:28:21 - INFO - volta.utils -   [GQA]: iter 28169 Ep: 7.65 loss 0.797 score 0.847 lr 2.74584e-05 
09/14/2020 14:29:47 - INFO - volta.utils -   [GQA]: iter 28189 Ep: 7.65 loss 0.755 score 0.850 lr 2.74463e-05 
09/14/2020 14:31:35 - INFO - volta.utils -   [GQA]: iter 28209 Ep: 7.66 loss 0.774 score 0.852 lr 2.74343e-05 
09/14/2020 14:32:58 - INFO - volta.utils -   [GQA]: iter 28229 Ep: 7.66 loss 0.736 score 0.863 lr 2.74222e-05 
09/14/2020 14:35:05 - INFO - volta.utils -   [GQA]: iter 28249 Ep: 7.67 loss 0.803 score 0.848 lr 2.74101e-05 
09/14/2020 14:36:35 - INFO - volta.utils -   [GQA]: iter 28269 Ep: 7.67 loss 0.763 score 0.849 lr 2.73981e-05 
09/14/2020 14:38:01 - INFO - volta.utils -   [GQA]: iter 28289 Ep: 7.68 loss 0.829 score 0.839 lr 2.7386e-05 
09/14/2020 14:39:06 - INFO - volta.utils -   [GQA]: iter 28309 Ep: 7.68 loss 0.797 score 0.845 lr 2.73739e-05 
09/14/2020 14:41:49 - INFO - volta.utils -   [GQA]: iter 28329 Ep: 7.69 loss 0.814 score 0.843 lr 2.73619e-05 
09/14/2020 14:43:17 - INFO - volta.utils -   [GQA]: iter 28349 Ep: 7.70 loss 0.809 score 0.848 lr 2.73498e-05 
09/14/2020 14:44:43 - INFO - volta.utils -   [GQA]: iter 28369 Ep: 7.70 loss 0.780 score 0.849 lr 2.73377e-05 
09/14/2020 14:45:59 - INFO - volta.utils -   [GQA]: iter 28389 Ep: 7.71 loss 0.756 score 0.855 lr 2.73257e-05 
09/14/2020 14:48:36 - INFO - volta.utils -   [GQA]: iter 28409 Ep: 7.71 loss 0.785 score 0.850 lr 2.73136e-05 
09/14/2020 14:50:04 - INFO - volta.utils -   [GQA]: iter 28429 Ep: 7.72 loss 0.807 score 0.842 lr 2.73015e-05 
09/14/2020 14:51:20 - INFO - volta.utils -   [GQA]: iter 28449 Ep: 7.72 loss 0.772 score 0.853 lr 2.72895e-05 
09/14/2020 14:52:26 - INFO - volta.utils -   [GQA]: iter 28469 Ep: 7.73 loss 0.787 score 0.845 lr 2.72774e-05 
09/14/2020 14:54:49 - INFO - volta.utils -   [GQA]: iter 28489 Ep: 7.73 loss 0.791 score 0.845 lr 2.72654e-05 
09/14/2020 14:55:46 - INFO - volta.utils -   [GQA]: iter 28509 Ep: 7.74 loss 0.762 score 0.850 lr 2.72533e-05 
09/14/2020 14:56:52 - INFO - volta.utils -   [GQA]: iter 28529 Ep: 7.74 loss 0.826 score 0.840 lr 2.72412e-05 
09/14/2020 14:57:43 - INFO - volta.utils -   [GQA]: iter 28549 Ep: 7.75 loss 0.804 score 0.842 lr 2.72292e-05 
09/14/2020 15:00:27 - INFO - volta.utils -   [GQA]: iter 28569 Ep: 7.75 loss 0.802 score 0.847 lr 2.72171e-05 
09/14/2020 15:02:00 - INFO - volta.utils -   [GQA]: iter 28589 Ep: 7.76 loss 0.772 score 0.849 lr 2.7205e-05 
09/14/2020 15:03:14 - INFO - volta.utils -   [GQA]: iter 28609 Ep: 7.77 loss 0.804 score 0.844 lr 2.7193e-05 
09/14/2020 15:04:23 - INFO - volta.utils -   [GQA]: iter 28629 Ep: 7.77 loss 0.832 score 0.845 lr 2.71809e-05 
09/14/2020 15:06:08 - INFO - volta.utils -   [GQA]: iter 28649 Ep: 7.78 loss 0.828 score 0.842 lr 2.71688e-05 
09/14/2020 15:07:46 - INFO - volta.utils -   [GQA]: iter 28669 Ep: 7.78 loss 0.801 score 0.844 lr 2.71568e-05 
09/14/2020 15:09:02 - INFO - volta.utils -   [GQA]: iter 28689 Ep: 7.79 loss 0.801 score 0.843 lr 2.71447e-05 
09/14/2020 15:09:54 - INFO - volta.utils -   [GQA]: iter 28709 Ep: 7.79 loss 0.802 score 0.846 lr 2.71326e-05 
09/14/2020 15:12:21 - INFO - volta.utils -   [GQA]: iter 28729 Ep: 7.80 loss 0.816 score 0.847 lr 2.71206e-05 
09/14/2020 15:13:21 - INFO - volta.utils -   [GQA]: iter 28749 Ep: 7.80 loss 0.811 score 0.846 lr 2.71085e-05 
09/14/2020 15:14:40 - INFO - volta.utils -   [GQA]: iter 28769 Ep: 7.81 loss 0.847 score 0.838 lr 2.70965e-05 
09/14/2020 15:16:11 - INFO - volta.utils -   [GQA]: iter 28789 Ep: 7.81 loss 0.732 score 0.861 lr 2.70844e-05 
09/14/2020 15:18:29 - INFO - volta.utils -   [GQA]: iter 28809 Ep: 7.82 loss 0.786 score 0.847 lr 2.70723e-05 
09/14/2020 15:20:02 - INFO - volta.utils -   [GQA]: iter 28829 Ep: 7.83 loss 0.787 score 0.852 lr 2.70603e-05 
09/14/2020 15:20:39 - INFO - volta.utils -   [GQA]: iter 28849 Ep: 7.83 loss 0.796 score 0.851 lr 2.70482e-05 
09/14/2020 15:22:04 - INFO - volta.utils -   [GQA]: iter 28869 Ep: 7.84 loss 0.796 score 0.850 lr 2.70361e-05 
09/14/2020 15:24:10 - INFO - volta.utils -   [GQA]: iter 28889 Ep: 7.84 loss 0.785 score 0.845 lr 2.70241e-05 
09/14/2020 15:25:35 - INFO - volta.utils -   [GQA]: iter 28909 Ep: 7.85 loss 0.820 score 0.839 lr 2.7012e-05 
09/14/2020 15:26:59 - INFO - volta.utils -   [GQA]: iter 28929 Ep: 7.85 loss 0.770 score 0.853 lr 2.69999e-05 
09/14/2020 15:28:28 - INFO - volta.utils -   [GQA]: iter 28949 Ep: 7.86 loss 0.787 score 0.846 lr 2.69879e-05 
09/14/2020 15:30:19 - INFO - volta.utils -   [GQA]: iter 28969 Ep: 7.86 loss 0.798 score 0.848 lr 2.69758e-05 
09/14/2020 15:32:32 - INFO - volta.utils -   [GQA]: iter 28989 Ep: 7.87 loss 0.806 score 0.849 lr 2.69637e-05 
09/14/2020 15:34:03 - INFO - volta.utils -   [GQA]: iter 29009 Ep: 7.87 loss 0.787 score 0.854 lr 2.69517e-05 
09/14/2020 15:35:19 - INFO - volta.utils -   [GQA]: iter 29029 Ep: 7.88 loss 0.762 score 0.857 lr 2.69396e-05 
09/14/2020 15:36:30 - INFO - volta.utils -   [GQA]: iter 29049 Ep: 7.89 loss 0.749 score 0.853 lr 2.69276e-05 
09/14/2020 15:39:19 - INFO - volta.utils -   [GQA]: iter 29069 Ep: 7.89 loss 0.844 score 0.830 lr 2.69155e-05 
09/14/2020 15:40:24 - INFO - volta.utils -   [GQA]: iter 29089 Ep: 7.90 loss 0.800 score 0.850 lr 2.69034e-05 
09/14/2020 15:41:31 - INFO - volta.utils -   [GQA]: iter 29109 Ep: 7.90 loss 0.823 score 0.843 lr 2.68914e-05 
09/14/2020 15:43:11 - INFO - volta.utils -   [GQA]: iter 29129 Ep: 7.91 loss 0.826 score 0.834 lr 2.68793e-05 
09/14/2020 15:45:26 - INFO - volta.utils -   [GQA]: iter 29149 Ep: 7.91 loss 0.766 score 0.853 lr 2.68672e-05 
09/14/2020 15:46:53 - INFO - volta.utils -   [GQA]: iter 29169 Ep: 7.92 loss 0.783 score 0.850 lr 2.68552e-05 
09/14/2020 15:48:10 - INFO - volta.utils -   [GQA]: iter 29189 Ep: 7.92 loss 0.753 score 0.854 lr 2.68431e-05 
09/14/2020 15:50:01 - INFO - volta.utils -   [GQA]: iter 29209 Ep: 7.93 loss 0.798 score 0.847 lr 2.6831e-05 
09/14/2020 15:52:12 - INFO - volta.utils -   [GQA]: iter 29229 Ep: 7.93 loss 0.812 score 0.844 lr 2.6819e-05 
09/14/2020 15:53:40 - INFO - volta.utils -   [GQA]: iter 29249 Ep: 7.94 loss 0.806 score 0.841 lr 2.68069e-05 
09/14/2020 15:55:19 - INFO - volta.utils -   [GQA]: iter 29269 Ep: 7.94 loss 0.783 score 0.851 lr 2.67948e-05 
09/14/2020 15:56:53 - INFO - volta.utils -   [GQA]: iter 29289 Ep: 7.95 loss 0.797 score 0.844 lr 2.67828e-05 
09/14/2020 15:59:47 - INFO - volta.utils -   [GQA]: iter 29309 Ep: 7.96 loss 0.777 score 0.853 lr 2.67707e-05 
09/14/2020 16:00:43 - INFO - volta.utils -   [GQA]: iter 29329 Ep: 7.96 loss 0.794 score 0.842 lr 2.67587e-05 
09/14/2020 16:02:20 - INFO - volta.utils -   [GQA]: iter 29349 Ep: 7.97 loss 0.831 score 0.840 lr 2.67466e-05 
09/14/2020 16:03:37 - INFO - volta.utils -   [GQA]: iter 29369 Ep: 7.97 loss 0.808 score 0.838 lr 2.67345e-05 
09/14/2020 16:05:33 - INFO - volta.utils -   [GQA]: iter 29389 Ep: 7.98 loss 0.767 score 0.852 lr 2.67225e-05 
09/14/2020 16:06:55 - INFO - volta.utils -   [GQA]: iter 29409 Ep: 7.98 loss 0.786 score 0.846 lr 2.67104e-05 
09/14/2020 16:07:52 - INFO - volta.utils -   [GQA]: iter 29429 Ep: 7.99 loss 0.790 score 0.848 lr 2.66983e-05 
09/14/2020 16:09:10 - INFO - volta.utils -   [GQA]: iter 29449 Ep: 7.99 loss 0.821 score 0.842 lr 2.66863e-05 
09/14/2020 16:10:40 - INFO - volta.utils -   [GQA]: iter 29469 Ep: 8.00 loss 0.779 score 0.849 lr 2.66742e-05 
09/14/2020 16:10:41 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  25%|       | 4/16 [20:20:25<61:32:02, 18460.24s/it]09/14/2020 16:30:07 - INFO - volta.utils -   Eval task TASK15 on iteration 29473 
09/14/2020 16:30:07 - INFO - volta.utils -   Validation [GQA]: loss 2.156 score 64.774 
09/14/2020 16:30:21 - INFO - volta.utils -   [GQA]: iter 29493 Ep: 8.01 loss 0.628 score 0.887 lr 2.66609e-05 
09/14/2020 16:31:35 - INFO - volta.utils -   [GQA]: iter 29513 Ep: 8.01 loss 0.621 score 0.884 lr 2.66477e-05 
09/14/2020 16:32:38 - INFO - volta.utils -   [GQA]: iter 29533 Ep: 8.02 loss 0.581 score 0.891 lr 2.66356e-05 
09/14/2020 16:33:25 - INFO - volta.utils -   [GQA]: iter 29553 Ep: 8.02 loss 0.602 score 0.890 lr 2.66235e-05 
09/14/2020 16:35:00 - INFO - volta.utils -   [GQA]: iter 29573 Ep: 8.03 loss 0.582 score 0.888 lr 2.66115e-05 
09/14/2020 16:35:31 - INFO - volta.utils -   [GQA]: iter 29593 Ep: 8.03 loss 0.598 score 0.892 lr 2.65994e-05 
09/14/2020 16:36:33 - INFO - volta.utils -   [GQA]: iter 29613 Ep: 8.04 loss 0.605 score 0.889 lr 2.65873e-05 
09/14/2020 16:37:27 - INFO - volta.utils -   [GQA]: iter 29633 Ep: 8.04 loss 0.607 score 0.887 lr 2.65753e-05 
09/14/2020 16:38:51 - INFO - volta.utils -   [GQA]: iter 29653 Ep: 8.05 loss 0.593 score 0.892 lr 2.65632e-05 
09/14/2020 16:40:22 - INFO - volta.utils -   [GQA]: iter 29673 Ep: 8.05 loss 0.621 score 0.885 lr 2.65512e-05 
09/14/2020 16:41:44 - INFO - volta.utils -   [GQA]: iter 29693 Ep: 8.06 loss 0.611 score 0.887 lr 2.65391e-05 
09/14/2020 16:43:08 - INFO - volta.utils -   [GQA]: iter 29713 Ep: 8.07 loss 0.602 score 0.890 lr 2.6527e-05 
09/14/2020 16:44:00 - INFO - volta.utils -   [GQA]: iter 29733 Ep: 8.07 loss 0.613 score 0.887 lr 2.6515e-05 
09/14/2020 16:45:38 - INFO - volta.utils -   [GQA]: iter 29753 Ep: 8.08 loss 0.561 score 0.898 lr 2.65029e-05 
09/14/2020 16:46:33 - INFO - volta.utils -   [GQA]: iter 29773 Ep: 8.08 loss 0.603 score 0.891 lr 2.64908e-05 
09/14/2020 16:48:06 - INFO - volta.utils -   [GQA]: iter 29793 Ep: 8.09 loss 0.625 score 0.885 lr 2.64788e-05 
09/14/2020 16:49:31 - INFO - volta.utils -   [GQA]: iter 29813 Ep: 8.09 loss 0.615 score 0.891 lr 2.64667e-05 
09/14/2020 16:50:44 - INFO - volta.utils -   [GQA]: iter 29833 Ep: 8.10 loss 0.611 score 0.884 lr 2.64546e-05 
09/14/2020 16:52:16 - INFO - volta.utils -   [GQA]: iter 29853 Ep: 8.10 loss 0.627 score 0.884 lr 2.64426e-05 
09/14/2020 16:54:23 - INFO - volta.utils -   [GQA]: iter 29873 Ep: 8.11 loss 0.589 score 0.893 lr 2.64305e-05 
09/14/2020 16:55:38 - INFO - volta.utils -   [GQA]: iter 29893 Ep: 8.11 loss 0.623 score 0.887 lr 2.64184e-05 
09/14/2020 16:57:10 - INFO - volta.utils -   [GQA]: iter 29913 Ep: 8.12 loss 0.618 score 0.882 lr 2.64064e-05 
09/14/2020 16:58:52 - INFO - volta.utils -   [GQA]: iter 29933 Ep: 8.13 loss 0.604 score 0.886 lr 2.63943e-05 
09/14/2020 17:00:33 - INFO - volta.utils -   [GQA]: iter 29953 Ep: 8.13 loss 0.619 score 0.883 lr 2.63823e-05 
09/14/2020 17:02:18 - INFO - volta.utils -   [GQA]: iter 29973 Ep: 8.14 loss 0.592 score 0.892 lr 2.63702e-05 
09/14/2020 17:03:56 - INFO - volta.utils -   [GQA]: iter 29993 Ep: 8.14 loss 0.620 score 0.888 lr 2.63581e-05 
09/14/2020 17:05:19 - INFO - volta.utils -   [GQA]: iter 30013 Ep: 8.15 loss 0.603 score 0.889 lr 2.63461e-05 
09/14/2020 17:06:16 - INFO - volta.utils -   [GQA]: iter 30033 Ep: 8.15 loss 0.615 score 0.884 lr 2.6334e-05 
09/14/2020 17:07:44 - INFO - volta.utils -   [GQA]: iter 30053 Ep: 8.16 loss 0.635 score 0.882 lr 2.63219e-05 
09/14/2020 17:09:30 - INFO - volta.utils -   [GQA]: iter 30073 Ep: 8.16 loss 0.635 score 0.884 lr 2.63099e-05 
09/14/2020 17:10:44 - INFO - volta.utils -   [GQA]: iter 30093 Ep: 8.17 loss 0.625 score 0.881 lr 2.62978e-05 
09/14/2020 17:12:18 - INFO - volta.utils -   [GQA]: iter 30113 Ep: 8.17 loss 0.596 score 0.887 lr 2.62857e-05 
09/14/2020 17:13:45 - INFO - volta.utils -   [GQA]: iter 30133 Ep: 8.18 loss 0.613 score 0.887 lr 2.62737e-05 
09/14/2020 17:15:31 - INFO - volta.utils -   [GQA]: iter 30153 Ep: 8.18 loss 0.629 score 0.887 lr 2.62616e-05 
09/14/2020 17:16:50 - INFO - volta.utils -   [GQA]: iter 30173 Ep: 8.19 loss 0.614 score 0.883 lr 2.62495e-05 
09/14/2020 17:17:50 - INFO - volta.utils -   [GQA]: iter 30193 Ep: 8.20 loss 0.630 score 0.882 lr 2.62375e-05 
09/14/2020 17:19:20 - INFO - volta.utils -   [GQA]: iter 30213 Ep: 8.20 loss 0.614 score 0.887 lr 2.62254e-05 
09/14/2020 17:21:26 - INFO - volta.utils -   [GQA]: iter 30233 Ep: 8.21 loss 0.621 score 0.884 lr 2.62134e-05 
09/14/2020 17:22:38 - INFO - volta.utils -   [GQA]: iter 30253 Ep: 8.21 loss 0.621 score 0.885 lr 2.62013e-05 
09/14/2020 17:24:05 - INFO - volta.utils -   [GQA]: iter 30273 Ep: 8.22 loss 0.634 score 0.879 lr 2.61892e-05 
09/14/2020 17:25:56 - INFO - volta.utils -   [GQA]: iter 30293 Ep: 8.22 loss 0.632 score 0.881 lr 2.61772e-05 
09/14/2020 17:27:23 - INFO - volta.utils -   [GQA]: iter 30313 Ep: 8.23 loss 0.651 score 0.880 lr 2.61651e-05 
09/14/2020 17:29:00 - INFO - volta.utils -   [GQA]: iter 30333 Ep: 8.23 loss 0.620 score 0.889 lr 2.6153e-05 
09/14/2020 17:29:53 - INFO - volta.utils -   [GQA]: iter 30353 Ep: 8.24 loss 0.625 score 0.887 lr 2.6141e-05 
09/14/2020 17:31:51 - INFO - volta.utils -   [GQA]: iter 30373 Ep: 8.24 loss 0.618 score 0.885 lr 2.61289e-05 
09/14/2020 17:33:50 - INFO - volta.utils -   [GQA]: iter 30393 Ep: 8.25 loss 0.637 score 0.885 lr 2.61168e-05 
09/14/2020 17:35:02 - INFO - volta.utils -   [GQA]: iter 30413 Ep: 8.26 loss 0.610 score 0.884 lr 2.61048e-05 
09/14/2020 17:36:15 - INFO - volta.utils -   [GQA]: iter 30433 Ep: 8.26 loss 0.622 score 0.884 lr 2.60927e-05 
09/14/2020 17:38:08 - INFO - volta.utils -   [GQA]: iter 30453 Ep: 8.27 loss 0.633 score 0.884 lr 2.60806e-05 
09/14/2020 17:39:40 - INFO - volta.utils -   [GQA]: iter 30473 Ep: 8.27 loss 0.650 score 0.877 lr 2.60686e-05 
09/14/2020 17:41:12 - INFO - volta.utils -   [GQA]: iter 30493 Ep: 8.28 loss 0.626 score 0.884 lr 2.60565e-05 
09/14/2020 17:42:27 - INFO - volta.utils -   [GQA]: iter 30513 Ep: 8.28 loss 0.635 score 0.882 lr 2.60445e-05 
09/14/2020 17:44:00 - INFO - volta.utils -   [GQA]: iter 30533 Ep: 8.29 loss 0.636 score 0.879 lr 2.60324e-05 
09/14/2020 17:46:09 - INFO - volta.utils -   [GQA]: iter 30553 Ep: 8.29 loss 0.677 score 0.873 lr 2.60203e-05 
09/14/2020 17:47:17 - INFO - volta.utils -   [GQA]: iter 30573 Ep: 8.30 loss 0.631 score 0.879 lr 2.60083e-05 
09/14/2020 17:48:45 - INFO - volta.utils -   [GQA]: iter 30593 Ep: 8.30 loss 0.652 score 0.877 lr 2.59962e-05 
09/14/2020 17:50:05 - INFO - volta.utils -   [GQA]: iter 30613 Ep: 8.31 loss 0.621 score 0.884 lr 2.59841e-05 
09/14/2020 17:52:01 - INFO - volta.utils -   [GQA]: iter 30633 Ep: 8.32 loss 0.619 score 0.882 lr 2.59721e-05 
09/14/2020 17:52:37 - INFO - volta.utils -   [GQA]: iter 30653 Ep: 8.32 loss 0.645 score 0.883 lr 2.596e-05 
09/14/2020 17:53:32 - INFO - volta.utils -   [GQA]: iter 30673 Ep: 8.33 loss 0.634 score 0.880 lr 2.59479e-05 
09/14/2020 17:54:53 - INFO - volta.utils -   [GQA]: iter 30693 Ep: 8.33 loss 0.634 score 0.881 lr 2.59359e-05 
09/14/2020 17:56:44 - INFO - volta.utils -   [GQA]: iter 30713 Ep: 8.34 loss 0.639 score 0.880 lr 2.59238e-05 
09/14/2020 17:58:00 - INFO - volta.utils -   [GQA]: iter 30733 Ep: 8.34 loss 0.657 score 0.872 lr 2.59118e-05 
09/14/2020 17:58:46 - INFO - volta.utils -   [GQA]: iter 30753 Ep: 8.35 loss 0.626 score 0.887 lr 2.58997e-05 
09/14/2020 18:00:32 - INFO - volta.utils -   [GQA]: iter 30773 Ep: 8.35 loss 0.639 score 0.881 lr 2.58876e-05 
09/14/2020 18:02:27 - INFO - volta.utils -   [GQA]: iter 30793 Ep: 8.36 loss 0.661 score 0.874 lr 2.58756e-05 
09/14/2020 18:03:55 - INFO - volta.utils -   [GQA]: iter 30813 Ep: 8.36 loss 0.629 score 0.882 lr 2.58635e-05 
09/14/2020 18:04:41 - INFO - volta.utils -   [GQA]: iter 30833 Ep: 8.37 loss 0.605 score 0.889 lr 2.58514e-05 
09/14/2020 18:05:55 - INFO - volta.utils -   [GQA]: iter 30853 Ep: 8.37 loss 0.671 score 0.871 lr 2.58394e-05 
09/14/2020 18:07:43 - INFO - volta.utils -   [GQA]: iter 30873 Ep: 8.38 loss 0.659 score 0.876 lr 2.58273e-05 
09/14/2020 18:09:28 - INFO - volta.utils -   [GQA]: iter 30893 Ep: 8.39 loss 0.643 score 0.875 lr 2.58152e-05 
09/14/2020 18:11:04 - INFO - volta.utils -   [GQA]: iter 30913 Ep: 8.39 loss 0.669 score 0.875 lr 2.58032e-05 
09/14/2020 18:12:34 - INFO - volta.utils -   [GQA]: iter 30933 Ep: 8.40 loss 0.648 score 0.874 lr 2.57911e-05 
09/14/2020 18:14:20 - INFO - volta.utils -   [GQA]: iter 30953 Ep: 8.40 loss 0.618 score 0.884 lr 2.5779e-05 
09/14/2020 18:15:59 - INFO - volta.utils -   [GQA]: iter 30973 Ep: 8.41 loss 0.608 score 0.882 lr 2.5767e-05 
09/14/2020 18:17:15 - INFO - volta.utils -   [GQA]: iter 30993 Ep: 8.41 loss 0.639 score 0.881 lr 2.57549e-05 
09/14/2020 18:18:20 - INFO - volta.utils -   [GQA]: iter 31013 Ep: 8.42 loss 0.640 score 0.883 lr 2.57429e-05 
09/14/2020 18:20:47 - INFO - volta.utils -   [GQA]: iter 31033 Ep: 8.42 loss 0.618 score 0.886 lr 2.57308e-05 
09/14/2020 18:22:51 - INFO - volta.utils -   [GQA]: iter 31053 Ep: 8.43 loss 0.608 score 0.886 lr 2.57187e-05 
09/14/2020 18:24:10 - INFO - volta.utils -   [GQA]: iter 31073 Ep: 8.43 loss 0.637 score 0.881 lr 2.57067e-05 
09/14/2020 18:25:18 - INFO - volta.utils -   [GQA]: iter 31093 Ep: 8.44 loss 0.661 score 0.879 lr 2.56946e-05 
09/14/2020 18:26:55 - INFO - volta.utils -   [GQA]: iter 31113 Ep: 8.45 loss 0.665 score 0.878 lr 2.56825e-05 
09/14/2020 18:28:41 - INFO - volta.utils -   [GQA]: iter 31133 Ep: 8.45 loss 0.676 score 0.879 lr 2.56705e-05 
09/14/2020 18:30:09 - INFO - volta.utils -   [GQA]: iter 31153 Ep: 8.46 loss 0.658 score 0.876 lr 2.56584e-05 
09/14/2020 18:31:50 - INFO - volta.utils -   [GQA]: iter 31173 Ep: 8.46 loss 0.629 score 0.880 lr 2.56463e-05 
09/14/2020 18:33:15 - INFO - volta.utils -   [GQA]: iter 31193 Ep: 8.47 loss 0.647 score 0.880 lr 2.56343e-05 
09/14/2020 18:35:50 - INFO - volta.utils -   [GQA]: iter 31213 Ep: 8.47 loss 0.635 score 0.881 lr 2.56222e-05 
09/14/2020 18:37:14 - INFO - volta.utils -   [GQA]: iter 31233 Ep: 8.48 loss 0.652 score 0.875 lr 2.56101e-05 
09/14/2020 18:38:40 - INFO - volta.utils -   [GQA]: iter 31253 Ep: 8.48 loss 0.666 score 0.877 lr 2.55981e-05 
09/14/2020 18:40:10 - INFO - volta.utils -   [GQA]: iter 31273 Ep: 8.49 loss 0.641 score 0.883 lr 2.5586e-05 
09/14/2020 18:42:07 - INFO - volta.utils -   [GQA]: iter 31293 Ep: 8.49 loss 0.670 score 0.873 lr 2.5574e-05 
09/14/2020 18:43:33 - INFO - volta.utils -   [GQA]: iter 31313 Ep: 8.50 loss 0.631 score 0.883 lr 2.55619e-05 
09/14/2020 18:44:59 - INFO - volta.utils -   [GQA]: iter 31333 Ep: 8.51 loss 0.652 score 0.871 lr 2.55498e-05 
09/14/2020 18:46:17 - INFO - volta.utils -   [GQA]: iter 31353 Ep: 8.51 loss 0.660 score 0.881 lr 2.55378e-05 
09/14/2020 18:48:48 - INFO - volta.utils -   [GQA]: iter 31373 Ep: 8.52 loss 0.669 score 0.878 lr 2.55257e-05 
09/14/2020 18:49:57 - INFO - volta.utils -   [GQA]: iter 31393 Ep: 8.52 loss 0.628 score 0.885 lr 2.55136e-05 
09/14/2020 18:50:54 - INFO - volta.utils -   [GQA]: iter 31413 Ep: 8.53 loss 0.651 score 0.879 lr 2.55016e-05 
09/14/2020 18:52:16 - INFO - volta.utils -   [GQA]: iter 31433 Ep: 8.53 loss 0.639 score 0.880 lr 2.54895e-05 
09/14/2020 18:54:09 - INFO - volta.utils -   [GQA]: iter 31453 Ep: 8.54 loss 0.667 score 0.877 lr 2.54774e-05 
09/14/2020 18:55:47 - INFO - volta.utils -   [GQA]: iter 31473 Ep: 8.54 loss 0.661 score 0.878 lr 2.54654e-05 
09/14/2020 18:56:48 - INFO - volta.utils -   [GQA]: iter 31493 Ep: 8.55 loss 0.638 score 0.883 lr 2.54533e-05 
09/14/2020 18:57:57 - INFO - volta.utils -   [GQA]: iter 31513 Ep: 8.55 loss 0.629 score 0.880 lr 2.54412e-05 
09/14/2020 18:59:41 - INFO - volta.utils -   [GQA]: iter 31533 Ep: 8.56 loss 0.659 score 0.878 lr 2.54292e-05 
09/14/2020 19:01:06 - INFO - volta.utils -   [GQA]: iter 31553 Ep: 8.56 loss 0.668 score 0.873 lr 2.54171e-05 
09/14/2020 19:02:28 - INFO - volta.utils -   [GQA]: iter 31573 Ep: 8.57 loss 0.667 score 0.874 lr 2.54051e-05 
09/14/2020 19:03:30 - INFO - volta.utils -   [GQA]: iter 31593 Ep: 8.58 loss 0.695 score 0.870 lr 2.5393e-05 
09/14/2020 19:05:57 - INFO - volta.utils -   [GQA]: iter 31613 Ep: 8.58 loss 0.673 score 0.877 lr 2.53809e-05 
09/14/2020 19:07:48 - INFO - volta.utils -   [GQA]: iter 31633 Ep: 8.59 loss 0.672 score 0.870 lr 2.53689e-05 
09/14/2020 19:08:24 - INFO - volta.utils -   [GQA]: iter 31653 Ep: 8.59 loss 0.677 score 0.871 lr 2.53568e-05 
09/14/2020 19:09:52 - INFO - volta.utils -   [GQA]: iter 31673 Ep: 8.60 loss 0.638 score 0.880 lr 2.53447e-05 
09/14/2020 19:11:32 - INFO - volta.utils -   [GQA]: iter 31693 Ep: 8.60 loss 0.655 score 0.879 lr 2.53327e-05 
09/14/2020 19:13:10 - INFO - volta.utils -   [GQA]: iter 31713 Ep: 8.61 loss 0.664 score 0.873 lr 2.53206e-05 
09/14/2020 19:14:32 - INFO - volta.utils -   [GQA]: iter 31733 Ep: 8.61 loss 0.624 score 0.883 lr 2.53085e-05 
09/14/2020 19:15:47 - INFO - volta.utils -   [GQA]: iter 31753 Ep: 8.62 loss 0.653 score 0.878 lr 2.52965e-05 
09/14/2020 19:18:01 - INFO - volta.utils -   [GQA]: iter 31773 Ep: 8.62 loss 0.645 score 0.876 lr 2.52844e-05 
09/14/2020 19:19:25 - INFO - volta.utils -   [GQA]: iter 31793 Ep: 8.63 loss 0.659 score 0.878 lr 2.52723e-05 
09/14/2020 19:21:09 - INFO - volta.utils -   [GQA]: iter 31813 Ep: 8.64 loss 0.654 score 0.874 lr 2.52603e-05 
09/14/2020 19:22:41 - INFO - volta.utils -   [GQA]: iter 31833 Ep: 8.64 loss 0.663 score 0.877 lr 2.52482e-05 
09/14/2020 19:25:18 - INFO - volta.utils -   [GQA]: iter 31853 Ep: 8.65 loss 0.644 score 0.878 lr 2.52362e-05 
09/14/2020 19:26:27 - INFO - volta.utils -   [GQA]: iter 31873 Ep: 8.65 loss 0.656 score 0.874 lr 2.52241e-05 
09/14/2020 19:27:30 - INFO - volta.utils -   [GQA]: iter 31893 Ep: 8.66 loss 0.639 score 0.881 lr 2.5212e-05 
09/14/2020 19:29:01 - INFO - volta.utils -   [GQA]: iter 31913 Ep: 8.66 loss 0.655 score 0.874 lr 2.52e-05 
09/14/2020 19:31:45 - INFO - volta.utils -   [GQA]: iter 31933 Ep: 8.67 loss 0.671 score 0.877 lr 2.51879e-05 
09/14/2020 19:33:08 - INFO - volta.utils -   [GQA]: iter 31953 Ep: 8.67 loss 0.672 score 0.868 lr 2.51758e-05 
09/14/2020 19:34:27 - INFO - volta.utils -   [GQA]: iter 31973 Ep: 8.68 loss 0.678 score 0.875 lr 2.51638e-05 
09/14/2020 19:35:50 - INFO - volta.utils -   [GQA]: iter 31993 Ep: 8.68 loss 0.658 score 0.875 lr 2.51517e-05 
09/14/2020 19:37:23 - INFO - volta.utils -   [GQA]: iter 32013 Ep: 8.69 loss 0.663 score 0.873 lr 2.51396e-05 
09/14/2020 19:38:36 - INFO - volta.utils -   [GQA]: iter 32033 Ep: 8.70 loss 0.683 score 0.876 lr 2.51276e-05 
09/14/2020 19:39:52 - INFO - volta.utils -   [GQA]: iter 32053 Ep: 8.70 loss 0.666 score 0.871 lr 2.51155e-05 
09/14/2020 19:41:14 - INFO - volta.utils -   [GQA]: iter 32073 Ep: 8.71 loss 0.628 score 0.886 lr 2.51035e-05 
