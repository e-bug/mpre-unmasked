/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
08/25/2020 06:42:21 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
08/25/2020 06:42:22 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
08/25/2020 06:42:22 - INFO - volta.task_utils -   Loading refcocog Dataset with batch size 256
08/25/2020 06:43:07 - INFO - volta.utils -   logging file at: ../../logs/volta/refcocog_umd/refcocog_vilbert_base
08/25/2020 06:43:07 - INFO - volta.utils -   loading weights file /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/volta/vilbert/vilbert_base/pytorch_model_9.bin
08/25/2020 06:43:14 - INFO - volta.utils -   
08/25/2020 06:43:14 - INFO - volta.utils -   Weights of BertForVLTasks not initialized from pretrained model: ['clfs_dict.TASK11.weight', 'clfs_dict.TASK11.bias']
08/25/2020 06:43:18 - INFO - __main__ -   >> Trainable Parameters:
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(1024, 2048)    |2097152     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(1024, 5)       |5120        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.weight                           |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.v_embeddings.LayerNorm.bias                             |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.13.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.15.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.17.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.19.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.20.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.21.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.25.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.26.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.27.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.31.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.query.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.weight              |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.key.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.weight            |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.value.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.weight          |torch.float32    |(768, 1024)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.32.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.33.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.query.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.key.bias                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.value.bias              |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_query.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_key.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.weight          |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_self.v_value.bias            |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.weight        |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_dense.bias          |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.weight    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.34.attention_output.v_LayerNorm.bias      |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.weight            |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.intermediate.v_dense.bias              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.output.dense.bias                      |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.encoder.layer.35.output.v_LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                   |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.predictions.bias                                         |torch.float32    |(30522,)        |30522       |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.predictions.transform.dense.weight                       |torch.float32    |(768, 768)      |589824      |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.predictions.transform.dense.bias                         |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.weight                   |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.bias                     |torch.float32    |(768,)          |768         |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.bi_seq_relationship.weight                               |torch.float32    |(2, 1024)       |2048        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.bi_seq_relationship.bias                                 |torch.float32    |(2,)            |2           |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.weight                  |torch.float32    |(1024, 1024)    |1048576     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.bias                    |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.weight              |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.bias                |torch.float32    |(1024,)         |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.weight                   |torch.float32    |(1601, 1024)    |1639424     |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.bias                     |torch.float32    |(1601,)         |1601        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.clfs_dict.TASK11.weight                                      |torch.float32    |(1, 1024)       |1024        |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   |module.clfs_dict.TASK11.bias                                        |torch.float32    |(1,)            |1           |
08/25/2020 06:43:18 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
08/25/2020 06:43:18 - INFO - __main__ -   >> # TrainableParams:       	239.02	M
08/25/2020 06:43:18 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
08/25/2020 06:43:18 - INFO - __main__ -   >> # TotalParams:           	239.02	M

Epoch:   0%|          | 0/20 [00:00<?, ?it/s]08/25/2020 06:44:02 - INFO - volta.utils -   [refcocog]: iter 21 Ep: 0.07 loss 4.067 score 0.257 lr 3.49206e-07 
08/25/2020 06:44:14 - INFO - volta.utils -   [refcocog]: iter 41 Ep: 0.13 loss 3.131 score 0.333 lr 1e-06 
08/25/2020 06:44:26 - INFO - volta.utils -   [refcocog]: iter 61 Ep: 0.19 loss 2.902 score 0.387 lr 1.63492e-06 
08/25/2020 06:44:38 - INFO - volta.utils -   [refcocog]: iter 81 Ep: 0.26 loss 2.743 score 0.468 lr 2.26984e-06 
08/25/2020 06:44:50 - INFO - volta.utils -   [refcocog]: iter 101 Ep: 0.32 loss 2.660 score 0.512 lr 2.90476e-06 
08/25/2020 06:45:03 - INFO - volta.utils -   [refcocog]: iter 121 Ep: 0.38 loss 2.576 score 0.551 lr 3.53968e-06 
08/25/2020 06:45:15 - INFO - volta.utils -   [refcocog]: iter 141 Ep: 0.45 loss 2.519 score 0.579 lr 4.1746e-06 
08/25/2020 06:45:26 - INFO - volta.utils -   [refcocog]: iter 161 Ep: 0.51 loss 2.483 score 0.586 lr 4.80952e-06 
08/25/2020 06:45:38 - INFO - volta.utils -   [refcocog]: iter 181 Ep: 0.57 loss 2.438 score 0.598 lr 5.44444e-06 
08/25/2020 06:45:52 - INFO - volta.utils -   [refcocog]: iter 201 Ep: 0.64 loss 2.417 score 0.611 lr 6.07937e-06 
08/25/2020 06:46:03 - INFO - volta.utils -   [refcocog]: iter 221 Ep: 0.70 loss 2.402 score 0.607 lr 6.71429e-06 
08/25/2020 06:46:15 - INFO - volta.utils -   [refcocog]: iter 241 Ep: 0.77 loss 2.387 score 0.620 lr 7.34921e-06 
08/25/2020 06:46:27 - INFO - volta.utils -   [refcocog]: iter 261 Ep: 0.83 loss 2.357 score 0.627 lr 7.98413e-06 
08/25/2020 06:46:40 - INFO - volta.utils -   [refcocog]: iter 281 Ep: 0.89 loss 2.345 score 0.629 lr 8.61905e-06 
08/25/2020 06:46:52 - INFO - volta.utils -   [refcocog]: iter 301 Ep: 0.96 loss 2.316 score 0.652 lr 9.25397e-06 
08/25/2020 06:47:00 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:   5%|         | 1/20 [03:45<1:11:33, 225.99s/it]08/25/2020 06:47:13 - INFO - volta.utils -   Eval task TASK11 on iteration 316 
08/25/2020 06:47:13 - INFO - volta.utils -   Validation [refcocog]: loss 2.187 score 64.767 
08/25/2020 06:47:25 - INFO - volta.utils -   [refcocog]: iter 336 Ep: 1.07 loss 2.296 score 0.643 lr 1.0127e-05 
08/25/2020 06:47:38 - INFO - volta.utils -   [refcocog]: iter 356 Ep: 1.13 loss 2.258 score 0.659 lr 1.1e-05 
08/25/2020 06:47:49 - INFO - volta.utils -   [refcocog]: iter 376 Ep: 1.19 loss 2.248 score 0.670 lr 1.16349e-05 
08/25/2020 06:48:01 - INFO - volta.utils -   [refcocog]: iter 396 Ep: 1.26 loss 2.262 score 0.657 lr 1.22698e-05 
08/25/2020 06:48:12 - INFO - volta.utils -   [refcocog]: iter 416 Ep: 1.32 loss 2.219 score 0.672 lr 1.29048e-05 
08/25/2020 06:48:25 - INFO - volta.utils -   [refcocog]: iter 436 Ep: 1.38 loss 2.226 score 0.667 lr 1.35397e-05 
08/25/2020 06:48:37 - INFO - volta.utils -   [refcocog]: iter 456 Ep: 1.45 loss 2.214 score 0.678 lr 1.41746e-05 
08/25/2020 06:48:48 - INFO - volta.utils -   [refcocog]: iter 476 Ep: 1.51 loss 2.214 score 0.671 lr 1.48095e-05 
08/25/2020 06:49:00 - INFO - volta.utils -   [refcocog]: iter 496 Ep: 1.57 loss 2.222 score 0.673 lr 1.54444e-05 
08/25/2020 06:49:13 - INFO - volta.utils -   [refcocog]: iter 516 Ep: 1.64 loss 2.178 score 0.688 lr 1.60794e-05 
08/25/2020 06:49:24 - INFO - volta.utils -   [refcocog]: iter 536 Ep: 1.70 loss 2.203 score 0.671 lr 1.67143e-05 
08/25/2020 06:49:36 - INFO - volta.utils -   [refcocog]: iter 556 Ep: 1.77 loss 2.191 score 0.691 lr 1.73492e-05 
08/25/2020 06:49:47 - INFO - volta.utils -   [refcocog]: iter 576 Ep: 1.83 loss 2.167 score 0.693 lr 1.79841e-05 
08/25/2020 06:50:00 - INFO - volta.utils -   [refcocog]: iter 596 Ep: 1.89 loss 2.165 score 0.685 lr 1.8619e-05 
08/25/2020 06:50:12 - INFO - volta.utils -   [refcocog]: iter 616 Ep: 1.96 loss 2.171 score 0.698 lr 1.9254e-05 
08/25/2020 06:50:20 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  10%|         | 2/20 [07:06<1:05:31, 218.42s/it]08/25/2020 06:50:32 - INFO - volta.utils -   Eval task TASK11 on iteration 631 
08/25/2020 06:50:32 - INFO - volta.utils -   Validation [refcocog]: loss 2.085 score 68.525 
08/25/2020 06:50:46 - INFO - volta.utils -   [refcocog]: iter 651 Ep: 2.07 loss 2.121 score 0.723 lr 1.98942e-05 
08/25/2020 06:50:58 - INFO - volta.utils -   [refcocog]: iter 671 Ep: 2.13 loss 2.057 score 0.742 lr 1.98889e-05 
08/25/2020 06:51:09 - INFO - volta.utils -   [refcocog]: iter 691 Ep: 2.19 loss 2.067 score 0.736 lr 1.98183e-05 
08/25/2020 06:51:21 - INFO - volta.utils -   [refcocog]: iter 711 Ep: 2.26 loss 2.064 score 0.745 lr 1.97478e-05 
08/25/2020 06:51:34 - INFO - volta.utils -   [refcocog]: iter 731 Ep: 2.32 loss 2.059 score 0.750 lr 1.96772e-05 
08/25/2020 06:51:46 - INFO - volta.utils -   [refcocog]: iter 751 Ep: 2.38 loss 2.033 score 0.746 lr 1.96067e-05 
08/25/2020 06:51:59 - INFO - volta.utils -   [refcocog]: iter 771 Ep: 2.45 loss 2.055 score 0.740 lr 1.95362e-05 
08/25/2020 06:52:10 - INFO - volta.utils -   [refcocog]: iter 791 Ep: 2.51 loss 2.002 score 0.751 lr 1.94656e-05 
08/25/2020 06:52:23 - INFO - volta.utils -   [refcocog]: iter 811 Ep: 2.57 loss 2.029 score 0.747 lr 1.93951e-05 
08/25/2020 06:52:35 - INFO - volta.utils -   [refcocog]: iter 831 Ep: 2.64 loss 2.026 score 0.747 lr 1.93245e-05 
08/25/2020 06:52:47 - INFO - volta.utils -   [refcocog]: iter 851 Ep: 2.70 loss 2.033 score 0.750 lr 1.9254e-05 
08/25/2020 06:52:58 - INFO - volta.utils -   [refcocog]: iter 871 Ep: 2.77 loss 2.033 score 0.745 lr 1.91834e-05 
08/25/2020 06:53:11 - INFO - volta.utils -   [refcocog]: iter 891 Ep: 2.83 loss 2.036 score 0.744 lr 1.91129e-05 
08/25/2020 06:53:24 - INFO - volta.utils -   [refcocog]: iter 911 Ep: 2.89 loss 1.981 score 0.765 lr 1.90423e-05 
08/25/2020 06:53:36 - INFO - volta.utils -   [refcocog]: iter 931 Ep: 2.96 loss 2.034 score 0.741 lr 1.89718e-05 
08/25/2020 06:53:44 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  15%|        | 3/20 [10:30<1:00:37, 213.96s/it]08/25/2020 06:53:56 - INFO - volta.utils -   Eval task TASK11 on iteration 946 
08/25/2020 06:53:56 - INFO - volta.utils -   Validation [refcocog]: loss 2.019 score 71.303 
08/25/2020 06:54:09 - INFO - volta.utils -   [refcocog]: iter 966 Ep: 3.07 loss 1.967 score 0.775 lr 1.88748e-05 
08/25/2020 06:54:21 - INFO - volta.utils -   [refcocog]: iter 986 Ep: 3.13 loss 1.944 score 0.781 lr 1.87778e-05 
08/25/2020 06:54:32 - INFO - volta.utils -   [refcocog]: iter 1006 Ep: 3.19 loss 1.926 score 0.773 lr 1.87072e-05 
08/25/2020 06:54:44 - INFO - volta.utils -   [refcocog]: iter 1026 Ep: 3.26 loss 1.924 score 0.787 lr 1.86367e-05 
08/25/2020 06:54:57 - INFO - volta.utils -   [refcocog]: iter 1046 Ep: 3.32 loss 1.907 score 0.789 lr 1.85661e-05 
08/25/2020 06:55:09 - INFO - volta.utils -   [refcocog]: iter 1066 Ep: 3.38 loss 1.907 score 0.791 lr 1.84956e-05 
08/25/2020 06:55:21 - INFO - volta.utils -   [refcocog]: iter 1086 Ep: 3.45 loss 1.920 score 0.793 lr 1.8425e-05 
08/25/2020 06:55:33 - INFO - volta.utils -   [refcocog]: iter 1106 Ep: 3.51 loss 1.911 score 0.785 lr 1.83545e-05 
08/25/2020 06:55:44 - INFO - volta.utils -   [refcocog]: iter 1126 Ep: 3.57 loss 1.927 score 0.783 lr 1.8284e-05 
08/25/2020 06:55:57 - INFO - volta.utils -   [refcocog]: iter 1146 Ep: 3.64 loss 1.906 score 0.785 lr 1.82134e-05 
08/25/2020 06:56:08 - INFO - volta.utils -   [refcocog]: iter 1166 Ep: 3.70 loss 1.917 score 0.793 lr 1.81429e-05 
08/25/2020 06:56:20 - INFO - volta.utils -   [refcocog]: iter 1186 Ep: 3.77 loss 1.930 score 0.789 lr 1.80723e-05 
08/25/2020 06:56:32 - INFO - volta.utils -   [refcocog]: iter 1206 Ep: 3.83 loss 1.923 score 0.780 lr 1.80018e-05 
08/25/2020 06:56:45 - INFO - volta.utils -   [refcocog]: iter 1226 Ep: 3.89 loss 1.936 score 0.783 lr 1.79312e-05 
08/25/2020 06:56:56 - INFO - volta.utils -   [refcocog]: iter 1246 Ep: 3.96 loss 1.926 score 0.786 lr 1.78607e-05 
08/25/2020 06:57:05 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  20%|        | 4/20 [13:51<56:00, 210.06s/it]  08/25/2020 06:57:17 - INFO - volta.utils -   Eval task TASK11 on iteration 1261 
08/25/2020 06:57:17 - INFO - volta.utils -   Validation [refcocog]: loss 2.019 score 71.671 
08/25/2020 06:57:29 - INFO - volta.utils -   [refcocog]: iter 1281 Ep: 4.07 loss 1.868 score 0.807 lr 1.77637e-05 
08/25/2020 06:57:42 - INFO - volta.utils -   [refcocog]: iter 1301 Ep: 4.13 loss 1.854 score 0.815 lr 1.76667e-05 
08/25/2020 06:57:54 - INFO - volta.utils -   [refcocog]: iter 1321 Ep: 4.19 loss 1.838 score 0.811 lr 1.75961e-05 
08/25/2020 06:58:06 - INFO - volta.utils -   [refcocog]: iter 1341 Ep: 4.26 loss 1.821 score 0.815 lr 1.75256e-05 
08/25/2020 06:58:18 - INFO - volta.utils -   [refcocog]: iter 1361 Ep: 4.32 loss 1.854 score 0.808 lr 1.7455e-05 
08/25/2020 06:58:31 - INFO - volta.utils -   [refcocog]: iter 1381 Ep: 4.38 loss 1.842 score 0.812 lr 1.73845e-05 
08/25/2020 06:58:43 - INFO - volta.utils -   [refcocog]: iter 1401 Ep: 4.45 loss 1.859 score 0.807 lr 1.73139e-05 
08/25/2020 06:58:55 - INFO - volta.utils -   [refcocog]: iter 1421 Ep: 4.51 loss 1.842 score 0.816 lr 1.72434e-05 
08/25/2020 06:59:06 - INFO - volta.utils -   [refcocog]: iter 1441 Ep: 4.57 loss 1.840 score 0.815 lr 1.71728e-05 
08/25/2020 06:59:20 - INFO - volta.utils -   [refcocog]: iter 1461 Ep: 4.64 loss 1.834 score 0.807 lr 1.71023e-05 
08/25/2020 06:59:32 - INFO - volta.utils -   [refcocog]: iter 1481 Ep: 4.70 loss 1.820 score 0.819 lr 1.70317e-05 
08/25/2020 06:59:44 - INFO - volta.utils -   [refcocog]: iter 1501 Ep: 4.77 loss 1.857 score 0.821 lr 1.69612e-05 
08/25/2020 06:59:56 - INFO - volta.utils -   [refcocog]: iter 1521 Ep: 4.83 loss 1.821 score 0.822 lr 1.68907e-05 
08/25/2020 07:00:09 - INFO - volta.utils -   [refcocog]: iter 1541 Ep: 4.89 loss 1.839 score 0.813 lr 1.68201e-05 
08/25/2020 07:00:20 - INFO - volta.utils -   [refcocog]: iter 1561 Ep: 4.96 loss 1.850 score 0.809 lr 1.67496e-05 
08/25/2020 07:00:28 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  25%|       | 5/20 [17:14<51:58, 207.88s/it]08/25/2020 07:00:40 - INFO - volta.utils -   Eval task TASK11 on iteration 1576 
08/25/2020 07:00:40 - INFO - volta.utils -   Validation [refcocog]: loss 2.037 score 71.855 
08/25/2020 07:00:53 - INFO - volta.utils -   [refcocog]: iter 1596 Ep: 5.07 loss 1.801 score 0.821 lr 1.66526e-05 
08/25/2020 07:01:05 - INFO - volta.utils -   [refcocog]: iter 1616 Ep: 5.13 loss 1.772 score 0.841 lr 1.65556e-05 
08/25/2020 07:01:17 - INFO - volta.utils -   [refcocog]: iter 1636 Ep: 5.19 loss 1.786 score 0.835 lr 1.6485e-05 
08/25/2020 07:01:29 - INFO - volta.utils -   [refcocog]: iter 1656 Ep: 5.26 loss 1.760 score 0.836 lr 1.64145e-05 
08/25/2020 07:01:41 - INFO - volta.utils -   [refcocog]: iter 1676 Ep: 5.32 loss 1.788 score 0.839 lr 1.63439e-05 
08/25/2020 07:01:55 - INFO - volta.utils -   [refcocog]: iter 1696 Ep: 5.38 loss 1.773 score 0.836 lr 1.62734e-05 
08/25/2020 07:02:07 - INFO - volta.utils -   [refcocog]: iter 1716 Ep: 5.45 loss 1.774 score 0.836 lr 1.62028e-05 
08/25/2020 07:02:19 - INFO - volta.utils -   [refcocog]: iter 1736 Ep: 5.51 loss 1.789 score 0.829 lr 1.61323e-05 
08/25/2020 07:02:31 - INFO - volta.utils -   [refcocog]: iter 1756 Ep: 5.57 loss 1.792 score 0.826 lr 1.60617e-05 
08/25/2020 07:02:45 - INFO - volta.utils -   [refcocog]: iter 1776 Ep: 5.64 loss 1.794 score 0.830 lr 1.59912e-05 
08/25/2020 07:02:57 - INFO - volta.utils -   [refcocog]: iter 1796 Ep: 5.70 loss 1.764 score 0.837 lr 1.59206e-05 
08/25/2020 07:03:09 - INFO - volta.utils -   [refcocog]: iter 1816 Ep: 5.77 loss 1.809 score 0.826 lr 1.58501e-05 
08/25/2020 07:03:21 - INFO - volta.utils -   [refcocog]: iter 1836 Ep: 5.83 loss 1.791 score 0.832 lr 1.57795e-05 
08/25/2020 07:03:35 - INFO - volta.utils -   [refcocog]: iter 1856 Ep: 5.89 loss 1.791 score 0.832 lr 1.5709e-05 
08/25/2020 07:03:47 - INFO - volta.utils -   [refcocog]: iter 1876 Ep: 5.96 loss 1.770 score 0.827 lr 1.56384e-05 
08/25/2020 07:03:55 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  30%|       | 6/20 [20:41<48:27, 207.70s/it]08/25/2020 07:04:08 - INFO - volta.utils -   Eval task TASK11 on iteration 1891 
08/25/2020 07:04:08 - INFO - volta.utils -   Validation [refcocog]: loss 2.036 score 72.141 
08/25/2020 07:04:20 - INFO - volta.utils -   [refcocog]: iter 1911 Ep: 6.07 loss 1.753 score 0.842 lr 1.55414e-05 
08/25/2020 07:04:33 - INFO - volta.utils -   [refcocog]: iter 1931 Ep: 6.13 loss 1.739 score 0.848 lr 1.54444e-05 
08/25/2020 07:04:44 - INFO - volta.utils -   [refcocog]: iter 1951 Ep: 6.19 loss 1.730 score 0.849 lr 1.53739e-05 
08/25/2020 07:04:56 - INFO - volta.utils -   [refcocog]: iter 1971 Ep: 6.26 loss 1.734 score 0.849 lr 1.53034e-05 
08/25/2020 07:05:07 - INFO - volta.utils -   [refcocog]: iter 1991 Ep: 6.32 loss 1.735 score 0.841 lr 1.52328e-05 
08/25/2020 07:05:20 - INFO - volta.utils -   [refcocog]: iter 2011 Ep: 6.38 loss 1.746 score 0.839 lr 1.51623e-05 
08/25/2020 07:05:32 - INFO - volta.utils -   [refcocog]: iter 2031 Ep: 6.45 loss 1.741 score 0.846 lr 1.50917e-05 
08/25/2020 07:05:43 - INFO - volta.utils -   [refcocog]: iter 2051 Ep: 6.51 loss 1.748 score 0.849 lr 1.50212e-05 
08/25/2020 07:05:55 - INFO - volta.utils -   [refcocog]: iter 2071 Ep: 6.57 loss 1.741 score 0.845 lr 1.49506e-05 
08/25/2020 07:06:08 - INFO - volta.utils -   [refcocog]: iter 2091 Ep: 6.64 loss 1.744 score 0.852 lr 1.48801e-05 
08/25/2020 07:06:21 - INFO - volta.utils -   [refcocog]: iter 2111 Ep: 6.70 loss 1.720 score 0.845 lr 1.48095e-05 
08/25/2020 07:06:33 - INFO - volta.utils -   [refcocog]: iter 2131 Ep: 6.77 loss 1.735 score 0.853 lr 1.4739e-05 
08/25/2020 07:06:44 - INFO - volta.utils -   [refcocog]: iter 2151 Ep: 6.83 loss 1.735 score 0.845 lr 1.46684e-05 
08/25/2020 07:06:58 - INFO - volta.utils -   [refcocog]: iter 2171 Ep: 6.89 loss 1.719 score 0.847 lr 1.45979e-05 
08/25/2020 07:07:10 - INFO - volta.utils -   [refcocog]: iter 2191 Ep: 6.96 loss 1.735 score 0.847 lr 1.45273e-05 
08/25/2020 07:07:18 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  35%|      | 7/20 [24:04<44:42, 206.32s/it]08/25/2020 07:07:30 - INFO - volta.utils -   Eval task TASK11 on iteration 2206 
08/25/2020 07:07:30 - INFO - volta.utils -   Validation [refcocog]: loss 2.044 score 72.222 
08/25/2020 07:07:44 - INFO - volta.utils -   [refcocog]: iter 2226 Ep: 7.07 loss 1.712 score 0.847 lr 1.44303e-05 
08/25/2020 07:07:56 - INFO - volta.utils -   [refcocog]: iter 2246 Ep: 7.13 loss 1.691 score 0.864 lr 1.43333e-05 
08/25/2020 07:08:08 - INFO - volta.utils -   [refcocog]: iter 2266 Ep: 7.19 loss 1.706 score 0.860 lr 1.42628e-05 
08/25/2020 07:08:20 - INFO - volta.utils -   [refcocog]: iter 2286 Ep: 7.26 loss 1.725 score 0.855 lr 1.41922e-05 
08/25/2020 07:08:32 - INFO - volta.utils -   [refcocog]: iter 2306 Ep: 7.32 loss 1.698 score 0.856 lr 1.41217e-05 
08/25/2020 07:08:45 - INFO - volta.utils -   [refcocog]: iter 2326 Ep: 7.38 loss 1.707 score 0.861 lr 1.40511e-05 
08/25/2020 07:08:57 - INFO - volta.utils -   [refcocog]: iter 2346 Ep: 7.45 loss 1.685 score 0.861 lr 1.39806e-05 
08/25/2020 07:09:09 - INFO - volta.utils -   [refcocog]: iter 2366 Ep: 7.51 loss 1.708 score 0.863 lr 1.39101e-05 
08/25/2020 07:09:20 - INFO - volta.utils -   [refcocog]: iter 2386 Ep: 7.57 loss 1.701 score 0.858 lr 1.38395e-05 
08/25/2020 07:09:33 - INFO - volta.utils -   [refcocog]: iter 2406 Ep: 7.64 loss 1.711 score 0.851 lr 1.3769e-05 
08/25/2020 07:09:45 - INFO - volta.utils -   [refcocog]: iter 2426 Ep: 7.70 loss 1.705 score 0.854 lr 1.36984e-05 
08/25/2020 07:09:56 - INFO - volta.utils -   [refcocog]: iter 2446 Ep: 7.77 loss 1.697 score 0.857 lr 1.36279e-05 
08/25/2020 07:10:08 - INFO - volta.utils -   [refcocog]: iter 2466 Ep: 7.83 loss 1.696 score 0.861 lr 1.35573e-05 
08/25/2020 07:10:20 - INFO - volta.utils -   [refcocog]: iter 2486 Ep: 7.89 loss 1.711 score 0.852 lr 1.34868e-05 
08/25/2020 07:10:33 - INFO - volta.utils -   [refcocog]: iter 2506 Ep: 7.96 loss 1.702 score 0.852 lr 1.34162e-05 
08/25/2020 07:10:41 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  40%|      | 8/20 [27:27<41:04, 205.35s/it]08/25/2020 07:10:54 - INFO - volta.utils -   Eval task TASK11 on iteration 2521 
08/25/2020 07:10:54 - INFO - volta.utils -   Validation [refcocog]: loss 2.072 score 72.038 
08/25/2020 07:11:05 - INFO - volta.utils -   [refcocog]: iter 2541 Ep: 8.07 loss 1.690 score 0.859 lr 1.33192e-05 
08/25/2020 07:11:19 - INFO - volta.utils -   [refcocog]: iter 2561 Ep: 8.13 loss 1.686 score 0.867 lr 1.32222e-05 
08/25/2020 07:11:30 - INFO - volta.utils -   [refcocog]: iter 2581 Ep: 8.19 loss 1.677 score 0.856 lr 1.31517e-05 
08/25/2020 07:11:42 - INFO - volta.utils -   [refcocog]: iter 2601 Ep: 8.26 loss 1.659 score 0.874 lr 1.30811e-05 
08/25/2020 07:11:54 - INFO - volta.utils -   [refcocog]: iter 2621 Ep: 8.32 loss 1.678 score 0.856 lr 1.30106e-05 
08/25/2020 07:12:07 - INFO - volta.utils -   [refcocog]: iter 2641 Ep: 8.38 loss 1.684 score 0.866 lr 1.294e-05 
08/25/2020 07:12:18 - INFO - volta.utils -   [refcocog]: iter 2661 Ep: 8.45 loss 1.681 score 0.866 lr 1.28695e-05 
08/25/2020 07:12:30 - INFO - volta.utils -   [refcocog]: iter 2681 Ep: 8.51 loss 1.676 score 0.869 lr 1.27989e-05 
08/25/2020 07:12:42 - INFO - volta.utils -   [refcocog]: iter 2701 Ep: 8.57 loss 1.691 score 0.861 lr 1.27284e-05 
08/25/2020 07:12:55 - INFO - volta.utils -   [refcocog]: iter 2721 Ep: 8.64 loss 1.667 score 0.862 lr 1.26578e-05 
08/25/2020 07:13:06 - INFO - volta.utils -   [refcocog]: iter 2741 Ep: 8.70 loss 1.676 score 0.863 lr 1.25873e-05 
08/25/2020 07:13:18 - INFO - volta.utils -   [refcocog]: iter 2761 Ep: 8.77 loss 1.672 score 0.864 lr 1.25168e-05 
08/25/2020 07:13:30 - INFO - volta.utils -   [refcocog]: iter 2781 Ep: 8.83 loss 1.676 score 0.870 lr 1.24462e-05 
08/25/2020 07:13:43 - INFO - volta.utils -   [refcocog]: iter 2801 Ep: 8.89 loss 1.687 score 0.865 lr 1.23757e-05 
08/25/2020 07:13:54 - INFO - volta.utils -   [refcocog]: iter 2821 Ep: 8.96 loss 1.680 score 0.863 lr 1.23051e-05 
08/25/2020 07:14:02 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  45%|     | 9/20 [30:48<37:23, 203.93s/it]08/25/2020 07:14:14 - INFO - volta.utils -   Eval task TASK11 on iteration 2836 
08/25/2020 07:14:14 - INFO - volta.utils -   Validation [refcocog]: loss 2.078 score 72.059 
08/25/2020 07:14:26 - INFO - volta.utils -   [refcocog]: iter 2856 Ep: 9.07 loss 1.675 score 0.870 lr 1.22081e-05 
08/25/2020 07:14:39 - INFO - volta.utils -   [refcocog]: iter 2876 Ep: 9.13 loss 1.665 score 0.873 lr 1.21111e-05 
08/25/2020 07:14:51 - INFO - volta.utils -   [refcocog]: iter 2896 Ep: 9.19 loss 1.638 score 0.881 lr 1.20406e-05 
08/25/2020 07:15:03 - INFO - volta.utils -   [refcocog]: iter 2916 Ep: 9.26 loss 1.654 score 0.874 lr 1.197e-05 
08/25/2020 07:15:15 - INFO - volta.utils -   [refcocog]: iter 2936 Ep: 9.32 loss 1.670 score 0.865 lr 1.18995e-05 
08/25/2020 07:15:28 - INFO - volta.utils -   [refcocog]: iter 2956 Ep: 9.38 loss 1.673 score 0.879 lr 1.18289e-05 
08/25/2020 07:15:39 - INFO - volta.utils -   [refcocog]: iter 2976 Ep: 9.45 loss 1.637 score 0.873 lr 1.17584e-05 
08/25/2020 07:15:51 - INFO - volta.utils -   [refcocog]: iter 2996 Ep: 9.51 loss 1.657 score 0.864 lr 1.16878e-05 
08/25/2020 07:16:03 - INFO - volta.utils -   [refcocog]: iter 3016 Ep: 9.57 loss 1.627 score 0.874 lr 1.16173e-05 
08/25/2020 07:16:15 - INFO - volta.utils -   [refcocog]: iter 3036 Ep: 9.64 loss 1.651 score 0.877 lr 1.15467e-05 
08/25/2020 07:16:28 - INFO - volta.utils -   [refcocog]: iter 3056 Ep: 9.70 loss 1.654 score 0.864 lr 1.14762e-05 
08/25/2020 07:16:39 - INFO - volta.utils -   [refcocog]: iter 3076 Ep: 9.77 loss 1.668 score 0.863 lr 1.14056e-05 
08/25/2020 07:16:51 - INFO - volta.utils -   [refcocog]: iter 3096 Ep: 9.83 loss 1.657 score 0.870 lr 1.13351e-05 
08/25/2020 07:17:02 - INFO - volta.utils -   [refcocog]: iter 3116 Ep: 9.89 loss 1.650 score 0.871 lr 1.12646e-05 
08/25/2020 07:17:15 - INFO - volta.utils -   [refcocog]: iter 3136 Ep: 9.96 loss 1.653 score 0.874 lr 1.1194e-05 
08/25/2020 07:17:24 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  50%|     | 10/20 [34:10<33:53, 203.38s/it]08/25/2020 07:17:36 - INFO - volta.utils -   Eval task TASK11 on iteration 3151 
08/25/2020 07:17:36 - INFO - volta.utils -   Validation [refcocog]: loss 2.072 score 72.386 
08/25/2020 07:17:48 - INFO - volta.utils -   [refcocog]: iter 3171 Ep: 10.07 loss 1.660 score 0.869 lr 1.1097e-05 
08/25/2020 07:18:01 - INFO - volta.utils -   [refcocog]: iter 3191 Ep: 10.13 loss 1.635 score 0.879 lr 1.1e-05 
08/25/2020 07:18:14 - INFO - volta.utils -   [refcocog]: iter 3211 Ep: 10.19 loss 1.621 score 0.874 lr 1.09295e-05 
08/25/2020 07:18:26 - INFO - volta.utils -   [refcocog]: iter 3231 Ep: 10.26 loss 1.632 score 0.876 lr 1.08589e-05 
08/25/2020 07:18:38 - INFO - volta.utils -   [refcocog]: iter 3251 Ep: 10.32 loss 1.658 score 0.867 lr 1.07884e-05 
08/25/2020 07:18:49 - INFO - volta.utils -   [refcocog]: iter 3271 Ep: 10.38 loss 1.631 score 0.874 lr 1.07178e-05 
08/25/2020 07:19:03 - INFO - volta.utils -   [refcocog]: iter 3291 Ep: 10.45 loss 1.651 score 0.876 lr 1.06473e-05 
08/25/2020 07:19:15 - INFO - volta.utils -   [refcocog]: iter 3311 Ep: 10.51 loss 1.651 score 0.867 lr 1.05767e-05 
08/25/2020 07:19:27 - INFO - volta.utils -   [refcocog]: iter 3331 Ep: 10.57 loss 1.642 score 0.872 lr 1.05062e-05 
08/25/2020 07:19:39 - INFO - volta.utils -   [refcocog]: iter 3351 Ep: 10.64 loss 1.643 score 0.880 lr 1.04356e-05 
08/25/2020 07:19:52 - INFO - volta.utils -   [refcocog]: iter 3371 Ep: 10.70 loss 1.639 score 0.879 lr 1.03651e-05 
08/25/2020 07:20:04 - INFO - volta.utils -   [refcocog]: iter 3391 Ep: 10.77 loss 1.637 score 0.865 lr 1.02945e-05 
08/25/2020 07:20:16 - INFO - volta.utils -   [refcocog]: iter 3411 Ep: 10.83 loss 1.629 score 0.880 lr 1.0224e-05 
08/25/2020 07:20:28 - INFO - volta.utils -   [refcocog]: iter 3431 Ep: 10.89 loss 1.636 score 0.874 lr 1.01534e-05 
08/25/2020 07:20:41 - INFO - volta.utils -   [refcocog]: iter 3451 Ep: 10.96 loss 1.655 score 0.871 lr 1.00829e-05 
08/25/2020 07:20:49 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  55%|    | 11/20 [37:35<30:34, 203.85s/it]08/25/2020 07:21:01 - INFO - volta.utils -   Eval task TASK11 on iteration 3466 
08/25/2020 07:21:01 - INFO - volta.utils -   Validation [refcocog]: loss 2.109 score 72.243 
08/25/2020 07:21:13 - INFO - volta.utils -   [refcocog]: iter 3486 Ep: 11.07 loss 1.630 score 0.876 lr 9.98589e-06 
08/25/2020 07:21:26 - INFO - volta.utils -   [refcocog]: iter 3506 Ep: 11.13 loss 1.641 score 0.880 lr 9.88889e-06 
08/25/2020 07:21:38 - INFO - volta.utils -   [refcocog]: iter 3526 Ep: 11.19 loss 1.621 score 0.870 lr 9.81834e-06 
08/25/2020 07:21:49 - INFO - volta.utils -   [refcocog]: iter 3546 Ep: 11.26 loss 1.626 score 0.879 lr 9.7478e-06 
08/25/2020 07:22:01 - INFO - volta.utils -   [refcocog]: iter 3566 Ep: 11.32 loss 1.621 score 0.879 lr 9.67725e-06 
08/25/2020 07:22:12 - INFO - volta.utils -   [refcocog]: iter 3586 Ep: 11.38 loss 1.622 score 0.884 lr 9.6067e-06 
08/25/2020 07:22:25 - INFO - volta.utils -   [refcocog]: iter 3606 Ep: 11.45 loss 1.618 score 0.881 lr 9.53616e-06 
08/25/2020 07:22:36 - INFO - volta.utils -   [refcocog]: iter 3626 Ep: 11.51 loss 1.593 score 0.878 lr 9.46561e-06 
08/25/2020 07:22:48 - INFO - volta.utils -   [refcocog]: iter 3646 Ep: 11.57 loss 1.630 score 0.884 lr 9.39506e-06 
08/25/2020 07:22:59 - INFO - volta.utils -   [refcocog]: iter 3666 Ep: 11.64 loss 1.634 score 0.881 lr 9.32451e-06 
08/25/2020 07:23:12 - INFO - volta.utils -   [refcocog]: iter 3686 Ep: 11.70 loss 1.628 score 0.880 lr 9.25397e-06 
08/25/2020 07:23:23 - INFO - volta.utils -   [refcocog]: iter 3706 Ep: 11.77 loss 1.630 score 0.872 lr 9.18342e-06 
08/25/2020 07:23:35 - INFO - volta.utils -   [refcocog]: iter 3726 Ep: 11.83 loss 1.625 score 0.883 lr 9.11287e-06 
08/25/2020 07:23:47 - INFO - volta.utils -   [refcocog]: iter 3746 Ep: 11.89 loss 1.616 score 0.877 lr 9.04233e-06 
08/25/2020 07:24:00 - INFO - volta.utils -   [refcocog]: iter 3766 Ep: 11.96 loss 1.633 score 0.878 lr 8.97178e-06 
08/25/2020 07:24:08 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  60%|    | 12/20 [40:54<27:00, 202.51s/it]08/25/2020 07:24:20 - INFO - volta.utils -   Eval task TASK11 on iteration 3781 
08/25/2020 07:24:20 - INFO - volta.utils -   Validation [refcocog]: loss 2.105 score 71.895 
08/25/2020 07:24:33 - INFO - volta.utils -   [refcocog]: iter 3801 Ep: 12.07 loss 1.614 score 0.886 lr 8.87478e-06 
08/25/2020 07:24:44 - INFO - volta.utils -   [refcocog]: iter 3821 Ep: 12.13 loss 1.609 score 0.882 lr 8.77778e-06 
08/25/2020 07:24:57 - INFO - volta.utils -   [refcocog]: iter 3841 Ep: 12.19 loss 1.597 score 0.887 lr 8.70723e-06 
08/25/2020 07:25:09 - INFO - volta.utils -   [refcocog]: iter 3861 Ep: 12.26 loss 1.615 score 0.878 lr 8.63668e-06 
08/25/2020 07:25:21 - INFO - volta.utils -   [refcocog]: iter 3881 Ep: 12.32 loss 1.635 score 0.873 lr 8.56614e-06 
08/25/2020 07:25:32 - INFO - volta.utils -   [refcocog]: iter 3901 Ep: 12.38 loss 1.605 score 0.879 lr 8.49559e-06 
08/25/2020 07:25:46 - INFO - volta.utils -   [refcocog]: iter 3921 Ep: 12.45 loss 1.600 score 0.883 lr 8.42504e-06 
08/25/2020 07:25:58 - INFO - volta.utils -   [refcocog]: iter 3941 Ep: 12.51 loss 1.640 score 0.880 lr 8.3545e-06 
08/25/2020 07:26:09 - INFO - volta.utils -   [refcocog]: iter 3961 Ep: 12.57 loss 1.610 score 0.879 lr 8.28395e-06 
08/25/2020 07:26:21 - INFO - volta.utils -   [refcocog]: iter 3981 Ep: 12.64 loss 1.627 score 0.877 lr 8.2134e-06 
08/25/2020 07:26:35 - INFO - volta.utils -   [refcocog]: iter 4001 Ep: 12.70 loss 1.622 score 0.879 lr 8.14286e-06 
08/25/2020 07:26:46 - INFO - volta.utils -   [refcocog]: iter 4021 Ep: 12.77 loss 1.610 score 0.884 lr 8.07231e-06 
08/25/2020 07:26:58 - INFO - volta.utils -   [refcocog]: iter 4041 Ep: 12.83 loss 1.614 score 0.884 lr 8.00176e-06 
08/25/2020 07:27:10 - INFO - volta.utils -   [refcocog]: iter 4061 Ep: 12.89 loss 1.617 score 0.883 lr 7.93122e-06 
08/25/2020 07:27:23 - INFO - volta.utils -   [refcocog]: iter 4081 Ep: 12.96 loss 1.610 score 0.883 lr 7.86067e-06 
08/25/2020 07:27:31 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  65%|   | 13/20 [44:17<23:37, 202.50s/it]08/25/2020 07:27:43 - INFO - volta.utils -   Eval task TASK11 on iteration 4096 
08/25/2020 07:27:43 - INFO - volta.utils -   Validation [refcocog]: loss 2.114 score 72.141 
08/25/2020 07:27:55 - INFO - volta.utils -   [refcocog]: iter 4116 Ep: 13.07 loss 1.596 score 0.887 lr 7.76367e-06 
08/25/2020 07:28:08 - INFO - volta.utils -   [refcocog]: iter 4136 Ep: 13.13 loss 1.614 score 0.888 lr 7.66667e-06 
08/25/2020 07:28:19 - INFO - volta.utils -   [refcocog]: iter 4156 Ep: 13.19 loss 1.607 score 0.882 lr 7.59612e-06 
08/25/2020 07:28:31 - INFO - volta.utils -   [refcocog]: iter 4176 Ep: 13.26 loss 1.599 score 0.882 lr 7.52557e-06 
08/25/2020 07:28:43 - INFO - volta.utils -   [refcocog]: iter 4196 Ep: 13.32 loss 1.612 score 0.887 lr 7.45503e-06 
08/25/2020 07:28:54 - INFO - volta.utils -   [refcocog]: iter 4216 Ep: 13.38 loss 1.604 score 0.880 lr 7.38448e-06 
08/25/2020 07:29:07 - INFO - volta.utils -   [refcocog]: iter 4236 Ep: 13.45 loss 1.591 score 0.879 lr 7.31393e-06 
08/25/2020 07:29:19 - INFO - volta.utils -   [refcocog]: iter 4256 Ep: 13.51 loss 1.596 score 0.883 lr 7.24339e-06 
08/25/2020 07:29:30 - INFO - volta.utils -   [refcocog]: iter 4276 Ep: 13.57 loss 1.610 score 0.886 lr 7.17284e-06 
08/25/2020 07:29:42 - INFO - volta.utils -   [refcocog]: iter 4296 Ep: 13.64 loss 1.588 score 0.885 lr 7.10229e-06 
08/25/2020 07:29:54 - INFO - volta.utils -   [refcocog]: iter 4316 Ep: 13.70 loss 1.609 score 0.876 lr 7.03175e-06 
08/25/2020 07:30:06 - INFO - volta.utils -   [refcocog]: iter 4336 Ep: 13.77 loss 1.604 score 0.887 lr 6.9612e-06 
08/25/2020 07:30:18 - INFO - volta.utils -   [refcocog]: iter 4356 Ep: 13.83 loss 1.620 score 0.885 lr 6.89065e-06 
08/25/2020 07:30:29 - INFO - volta.utils -   [refcocog]: iter 4376 Ep: 13.89 loss 1.611 score 0.884 lr 6.82011e-06 
08/25/2020 07:30:41 - INFO - volta.utils -   [refcocog]: iter 4396 Ep: 13.96 loss 1.608 score 0.885 lr 6.74956e-06 
08/25/2020 07:30:51 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  70%|   | 14/20 [47:37<20:11, 201.99s/it]08/25/2020 07:31:04 - INFO - volta.utils -   Eval task TASK11 on iteration 4411 
08/25/2020 07:31:04 - INFO - volta.utils -   Validation [refcocog]: loss 2.111 score 72.263 
08/25/2020 07:31:15 - INFO - volta.utils -   [refcocog]: iter 4431 Ep: 14.07 loss 1.602 score 0.891 lr 6.65256e-06 
08/25/2020 07:31:27 - INFO - volta.utils -   [refcocog]: iter 4451 Ep: 14.13 loss 1.597 score 0.885 lr 6.55556e-06 
08/25/2020 07:31:40 - INFO - volta.utils -   [refcocog]: iter 4471 Ep: 14.19 loss 1.594 score 0.882 lr 6.48501e-06 
08/25/2020 07:31:52 - INFO - volta.utils -   [refcocog]: iter 4491 Ep: 14.26 loss 1.599 score 0.894 lr 6.41446e-06 
08/25/2020 07:32:04 - INFO - volta.utils -   [refcocog]: iter 4511 Ep: 14.32 loss 1.608 score 0.883 lr 6.34392e-06 
08/25/2020 07:32:15 - INFO - volta.utils -   [refcocog]: iter 4531 Ep: 14.38 loss 1.609 score 0.881 lr 6.27337e-06 
08/25/2020 07:32:28 - INFO - volta.utils -   [refcocog]: iter 4551 Ep: 14.45 loss 1.603 score 0.885 lr 6.20282e-06 
08/25/2020 07:32:40 - INFO - volta.utils -   [refcocog]: iter 4571 Ep: 14.51 loss 1.599 score 0.884 lr 6.13228e-06 
08/25/2020 07:32:52 - INFO - volta.utils -   [refcocog]: iter 4591 Ep: 14.57 loss 1.600 score 0.888 lr 6.06173e-06 
08/25/2020 07:33:03 - INFO - volta.utils -   [refcocog]: iter 4611 Ep: 14.64 loss 1.593 score 0.890 lr 5.99118e-06 
08/25/2020 07:33:16 - INFO - volta.utils -   [refcocog]: iter 4631 Ep: 14.70 loss 1.590 score 0.885 lr 5.92063e-06 
08/25/2020 07:33:28 - INFO - volta.utils -   [refcocog]: iter 4651 Ep: 14.77 loss 1.593 score 0.892 lr 5.85009e-06 
08/25/2020 07:33:40 - INFO - volta.utils -   [refcocog]: iter 4671 Ep: 14.83 loss 1.595 score 0.887 lr 5.77954e-06 
08/25/2020 07:33:51 - INFO - volta.utils -   [refcocog]: iter 4691 Ep: 14.89 loss 1.600 score 0.885 lr 5.70899e-06 
08/25/2020 07:34:04 - INFO - volta.utils -   [refcocog]: iter 4711 Ep: 14.96 loss 1.584 score 0.888 lr 5.63845e-06 
08/25/2020 07:34:12 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  75%|  | 15/20 [50:58<16:47, 201.57s/it]08/25/2020 07:34:24 - INFO - volta.utils -   Eval task TASK11 on iteration 4726 
08/25/2020 07:34:24 - INFO - volta.utils -   Validation [refcocog]: loss 2.118 score 72.610 
08/25/2020 07:34:36 - INFO - volta.utils -   [refcocog]: iter 4746 Ep: 15.07 loss 1.603 score 0.885 lr 5.54145e-06 
08/25/2020 07:34:47 - INFO - volta.utils -   [refcocog]: iter 4766 Ep: 15.13 loss 1.604 score 0.887 lr 5.44444e-06 
08/25/2020 07:35:01 - INFO - volta.utils -   [refcocog]: iter 4786 Ep: 15.19 loss 1.592 score 0.891 lr 5.3739e-06 
08/25/2020 07:35:13 - INFO - volta.utils -   [refcocog]: iter 4806 Ep: 15.26 loss 1.602 score 0.885 lr 5.30335e-06 
08/25/2020 07:35:25 - INFO - volta.utils -   [refcocog]: iter 4826 Ep: 15.32 loss 1.600 score 0.889 lr 5.2328e-06 
08/25/2020 07:35:37 - INFO - volta.utils -   [refcocog]: iter 4846 Ep: 15.38 loss 1.580 score 0.885 lr 5.16226e-06 
08/25/2020 07:35:49 - INFO - volta.utils -   [refcocog]: iter 4866 Ep: 15.45 loss 1.593 score 0.881 lr 5.09171e-06 
08/25/2020 07:36:02 - INFO - volta.utils -   [refcocog]: iter 4886 Ep: 15.51 loss 1.607 score 0.892 lr 5.02116e-06 
08/25/2020 07:36:13 - INFO - volta.utils -   [refcocog]: iter 4906 Ep: 15.57 loss 1.572 score 0.887 lr 4.95062e-06 
08/25/2020 07:36:26 - INFO - volta.utils -   [refcocog]: iter 4926 Ep: 15.64 loss 1.569 score 0.885 lr 4.88007e-06 
08/25/2020 07:36:37 - INFO - volta.utils -   [refcocog]: iter 4946 Ep: 15.70 loss 1.605 score 0.890 lr 4.80952e-06 
08/25/2020 07:36:49 - INFO - volta.utils -   [refcocog]: iter 4966 Ep: 15.77 loss 1.591 score 0.898 lr 4.73898e-06 
08/25/2020 07:37:02 - INFO - volta.utils -   [refcocog]: iter 4986 Ep: 15.83 loss 1.594 score 0.892 lr 4.66843e-06 
08/25/2020 07:37:14 - INFO - volta.utils -   [refcocog]: iter 5006 Ep: 15.89 loss 1.583 score 0.880 lr 4.59788e-06 
08/25/2020 07:37:26 - INFO - volta.utils -   [refcocog]: iter 5026 Ep: 15.96 loss 1.586 score 0.893 lr 4.52734e-06 
08/25/2020 07:37:35 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 

Epoch:  80%|  | 16/20 [54:20<13:27, 201.81s/it]08/25/2020 07:37:47 - INFO - volta.utils -   Eval task TASK11 on iteration 5041 
08/25/2020 07:37:47 - INFO - volta.utils -   Validation [refcocog]: loss 2.132 score 72.426 
08/25/2020 07:38:00 - INFO - volta.utils -   [refcocog]: iter 5061 Ep: 16.07 loss 1.588 score 0.894 lr 4.43034e-06 
08/25/2020 07:38:12 - INFO - volta.utils -   [refcocog]: iter 5081 Ep: 16.13 loss 1.592 score 0.885 lr 4.33333e-06 
08/25/2020 07:38:23 - INFO - volta.utils -   [refcocog]: iter 5101 Ep: 16.19 loss 1.570 score 0.886 lr 4.26279e-06 
08/25/2020 07:38:35 - INFO - volta.utils -   [refcocog]: iter 5121 Ep: 16.26 loss 1.601 score 0.892 lr 4.19224e-06 
08/25/2020 07:38:48 - INFO - volta.utils -   [refcocog]: iter 5141 Ep: 16.32 loss 1.578 score 0.890 lr 4.12169e-06 
08/25/2020 07:39:00 - INFO - volta.utils -   [refcocog]: iter 5161 Ep: 16.38 loss 1.587 score 0.885 lr 4.05115e-06 
08/25/2020 07:39:11 - INFO - volta.utils -   [refcocog]: iter 5181 Ep: 16.45 loss 1.573 score 0.888 lr 3.9806e-06 
08/25/2020 07:39:23 - INFO - volta.utils -   [refcocog]: iter 5201 Ep: 16.51 loss 1.595 score 0.892 lr 3.91005e-06 
08/25/2020 07:39:36 - INFO - volta.utils -   [refcocog]: iter 5221 Ep: 16.57 loss 1.587 score 0.891 lr 3.83951e-06 
08/25/2020 07:39:48 - INFO - volta.utils -   [refcocog]: iter 5241 Ep: 16.64 loss 1.580 score 0.886 lr 3.76896e-06 
08/25/2020 07:40:00 - INFO - volta.utils -   [refcocog]: iter 5261 Ep: 16.70 loss 1.589 score 0.890 lr 3.69841e-06 
08/25/2020 07:40:12 - INFO - volta.utils -   [refcocog]: iter 5281 Ep: 16.77 loss 1.584 score 0.886 lr 3.62787e-06 
08/25/2020 07:40:24 - INFO - volta.utils -   [refcocog]: iter 5301 Ep: 16.83 loss 1.596 score 0.887 lr 3.55732e-06 
