/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/callbacks/hooks.py:17: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/optimizer.py:18: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.

WARNING:tensorflow:From /gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/tensorpack/tfutils/sesscreate.py:20: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.


Bad key "text.kerning_factor" on line 4 in
/gs/hs0/tgb-deepmt/bugliarello.e/envs/volta/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.
You probably need to get an updated matplotlibrc file from
https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template
or from the matplotlib source distribution
10/29/2020 17:53:49 - INFO - __main__ -   device: cuda n_gpu: 4, distributed training: False, 16-bits training: False
10/29/2020 17:53:50 - INFO - pytorch_transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/4/19ITA380/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
10/29/2020 17:53:54 - INFO - volta.utils -   logging file at: /gs/hs0/tgb-deepmt/bugliarello.e/logs/volta/conceptual_captions_s89/ctrl_lxmert
10/29/2020 17:53:55 - INFO - volta.utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/4/19ITA380/.pytorch_pretrained_bert/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
10/29/2020 17:53:59 - INFO - volta.utils -   
10/29/2020 17:54:00 - INFO - volta.utils -   Weights of BertForVLPreTraining not initialized from pretrained model: ['bert.v_embeddings.image_embeddings.weight', 'bert.v_embeddings.image_embeddings.bias', 'bert.v_embeddings.image_location_embeddings.weight', 'bert.v_embeddings.image_location_embeddings.bias', 'bert.v_embeddings.ImgLayerNorm.weight', 'bert.v_embeddings.ImgLayerNorm.bias', 'bert.v_embeddings.LocLayerNorm.weight', 'bert.v_embeddings.LocLayerNorm.bias', 'bert.encoder.layer.0.attention_self.v_query.weight', 'bert.encoder.layer.0.attention_self.v_query.bias', 'bert.encoder.layer.0.attention_self.v_key.weight', 'bert.encoder.layer.0.attention_self.v_key.bias', 'bert.encoder.layer.0.attention_self.v_value.weight', 'bert.encoder.layer.0.attention_self.v_value.bias', 'bert.encoder.layer.0.attention_output.v_dense.weight', 'bert.encoder.layer.0.attention_output.v_dense.bias', 'bert.encoder.layer.0.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.0.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.1.intermediate.v_dense.weight', 'bert.encoder.layer.1.intermediate.v_dense.bias', 'bert.encoder.layer.1.output.v_dense.weight', 'bert.encoder.layer.1.output.v_dense.bias', 'bert.encoder.layer.1.output.v_LayerNorm.weight', 'bert.encoder.layer.1.output.v_LayerNorm.bias', 'bert.encoder.layer.2.attention_self.v_query.weight', 'bert.encoder.layer.2.attention_self.v_query.bias', 'bert.encoder.layer.2.attention_self.v_key.weight', 'bert.encoder.layer.2.attention_self.v_key.bias', 'bert.encoder.layer.2.attention_self.v_value.weight', 'bert.encoder.layer.2.attention_self.v_value.bias', 'bert.encoder.layer.2.attention_output.v_dense.weight', 'bert.encoder.layer.2.attention_output.v_dense.bias', 'bert.encoder.layer.2.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.2.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.3.intermediate.v_dense.weight', 'bert.encoder.layer.3.intermediate.v_dense.bias', 'bert.encoder.layer.3.output.v_dense.weight', 'bert.encoder.layer.3.output.v_dense.bias', 'bert.encoder.layer.3.output.v_LayerNorm.weight', 'bert.encoder.layer.3.output.v_LayerNorm.bias', 'bert.encoder.layer.4.attention_self.v_query.weight', 'bert.encoder.layer.4.attention_self.v_query.bias', 'bert.encoder.layer.4.attention_self.v_key.weight', 'bert.encoder.layer.4.attention_self.v_key.bias', 'bert.encoder.layer.4.attention_self.v_value.weight', 'bert.encoder.layer.4.attention_self.v_value.bias', 'bert.encoder.layer.4.attention_output.v_dense.weight', 'bert.encoder.layer.4.attention_output.v_dense.bias', 'bert.encoder.layer.4.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.4.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.5.intermediate.v_dense.weight', 'bert.encoder.layer.5.intermediate.v_dense.bias', 'bert.encoder.layer.5.output.v_dense.weight', 'bert.encoder.layer.5.output.v_dense.bias', 'bert.encoder.layer.5.output.v_LayerNorm.weight', 'bert.encoder.layer.5.output.v_LayerNorm.bias', 'bert.encoder.layer.6.attention_self.v_query.weight', 'bert.encoder.layer.6.attention_self.v_query.bias', 'bert.encoder.layer.6.attention_self.v_key.weight', 'bert.encoder.layer.6.attention_self.v_key.bias', 'bert.encoder.layer.6.attention_self.v_value.weight', 'bert.encoder.layer.6.attention_self.v_value.bias', 'bert.encoder.layer.6.attention_output.v_dense.weight', 'bert.encoder.layer.6.attention_output.v_dense.bias', 'bert.encoder.layer.6.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.6.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.7.intermediate.v_dense.weight', 'bert.encoder.layer.7.intermediate.v_dense.bias', 'bert.encoder.layer.7.output.v_dense.weight', 'bert.encoder.layer.7.output.v_dense.bias', 'bert.encoder.layer.7.output.v_LayerNorm.weight', 'bert.encoder.layer.7.output.v_LayerNorm.bias', 'bert.encoder.layer.8.attention_self.v_query.weight', 'bert.encoder.layer.8.attention_self.v_query.bias', 'bert.encoder.layer.8.attention_self.v_key.weight', 'bert.encoder.layer.8.attention_self.v_key.bias', 'bert.encoder.layer.8.attention_self.v_value.weight', 'bert.encoder.layer.8.attention_self.v_value.bias', 'bert.encoder.layer.8.attention_output.v_dense.weight', 'bert.encoder.layer.8.attention_output.v_dense.bias', 'bert.encoder.layer.8.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.8.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.9.intermediate.v_dense.weight', 'bert.encoder.layer.9.intermediate.v_dense.bias', 'bert.encoder.layer.9.output.v_dense.weight', 'bert.encoder.layer.9.output.v_dense.bias', 'bert.encoder.layer.9.output.v_LayerNorm.weight', 'bert.encoder.layer.9.output.v_LayerNorm.bias', 'bert.encoder.layer.18.attention_self.query.weight', 'bert.encoder.layer.18.attention_self.query.bias', 'bert.encoder.layer.18.attention_self.key.weight', 'bert.encoder.layer.18.attention_self.key.bias', 'bert.encoder.layer.18.attention_self.value.weight', 'bert.encoder.layer.18.attention_self.value.bias', 'bert.encoder.layer.18.attention_self.v_query.weight', 'bert.encoder.layer.18.attention_self.v_query.bias', 'bert.encoder.layer.18.attention_self.v_key.weight', 'bert.encoder.layer.18.attention_self.v_key.bias', 'bert.encoder.layer.18.attention_self.v_value.weight', 'bert.encoder.layer.18.attention_self.v_value.bias', 'bert.encoder.layer.18.attention_output.dense.weight', 'bert.encoder.layer.18.attention_output.dense.bias', 'bert.encoder.layer.18.attention_output.LayerNorm.weight', 'bert.encoder.layer.18.attention_output.LayerNorm.bias', 'bert.encoder.layer.18.attention_output.v_dense.weight', 'bert.encoder.layer.18.attention_output.v_dense.bias', 'bert.encoder.layer.18.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.18.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.19.attention_self.v_query.weight', 'bert.encoder.layer.19.attention_self.v_query.bias', 'bert.encoder.layer.19.attention_self.v_key.weight', 'bert.encoder.layer.19.attention_self.v_key.bias', 'bert.encoder.layer.19.attention_self.v_value.weight', 'bert.encoder.layer.19.attention_self.v_value.bias', 'bert.encoder.layer.19.attention_output.v_dense.weight', 'bert.encoder.layer.19.attention_output.v_dense.bias', 'bert.encoder.layer.19.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.19.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.20.intermediate.v_dense.weight', 'bert.encoder.layer.20.intermediate.v_dense.bias', 'bert.encoder.layer.20.output.v_dense.weight', 'bert.encoder.layer.20.output.v_dense.bias', 'bert.encoder.layer.20.output.v_LayerNorm.weight', 'bert.encoder.layer.20.output.v_LayerNorm.bias', 'bert.encoder.layer.21.attention_self.query.weight', 'bert.encoder.layer.21.attention_self.query.bias', 'bert.encoder.layer.21.attention_self.key.weight', 'bert.encoder.layer.21.attention_self.key.bias', 'bert.encoder.layer.21.attention_self.value.weight', 'bert.encoder.layer.21.attention_self.value.bias', 'bert.encoder.layer.21.attention_self.v_query.weight', 'bert.encoder.layer.21.attention_self.v_query.bias', 'bert.encoder.layer.21.attention_self.v_key.weight', 'bert.encoder.layer.21.attention_self.v_key.bias', 'bert.encoder.layer.21.attention_self.v_value.weight', 'bert.encoder.layer.21.attention_self.v_value.bias', 'bert.encoder.layer.21.attention_output.dense.weight', 'bert.encoder.layer.21.attention_output.dense.bias', 'bert.encoder.layer.21.attention_output.LayerNorm.weight', 'bert.encoder.layer.21.attention_output.LayerNorm.bias', 'bert.encoder.layer.21.attention_output.v_dense.weight', 'bert.encoder.layer.21.attention_output.v_dense.bias', 'bert.encoder.layer.21.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.21.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.22.attention_self.v_query.weight', 'bert.encoder.layer.22.attention_self.v_query.bias', 'bert.encoder.layer.22.attention_self.v_key.weight', 'bert.encoder.layer.22.attention_self.v_key.bias', 'bert.encoder.layer.22.attention_self.v_value.weight', 'bert.encoder.layer.22.attention_self.v_value.bias', 'bert.encoder.layer.22.attention_output.v_dense.weight', 'bert.encoder.layer.22.attention_output.v_dense.bias', 'bert.encoder.layer.22.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.22.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.23.intermediate.v_dense.weight', 'bert.encoder.layer.23.intermediate.v_dense.bias', 'bert.encoder.layer.23.output.v_dense.weight', 'bert.encoder.layer.23.output.v_dense.bias', 'bert.encoder.layer.23.output.v_LayerNorm.weight', 'bert.encoder.layer.23.output.v_LayerNorm.bias', 'bert.encoder.layer.24.attention_self.query.weight', 'bert.encoder.layer.24.attention_self.query.bias', 'bert.encoder.layer.24.attention_self.key.weight', 'bert.encoder.layer.24.attention_self.key.bias', 'bert.encoder.layer.24.attention_self.value.weight', 'bert.encoder.layer.24.attention_self.value.bias', 'bert.encoder.layer.24.attention_self.v_query.weight', 'bert.encoder.layer.24.attention_self.v_query.bias', 'bert.encoder.layer.24.attention_self.v_key.weight', 'bert.encoder.layer.24.attention_self.v_key.bias', 'bert.encoder.layer.24.attention_self.v_value.weight', 'bert.encoder.layer.24.attention_self.v_value.bias', 'bert.encoder.layer.24.attention_output.dense.weight', 'bert.encoder.layer.24.attention_output.dense.bias', 'bert.encoder.layer.24.attention_output.LayerNorm.weight', 'bert.encoder.layer.24.attention_output.LayerNorm.bias', 'bert.encoder.layer.24.attention_output.v_dense.weight', 'bert.encoder.layer.24.attention_output.v_dense.bias', 'bert.encoder.layer.24.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.24.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.25.attention_self.v_query.weight', 'bert.encoder.layer.25.attention_self.v_query.bias', 'bert.encoder.layer.25.attention_self.v_key.weight', 'bert.encoder.layer.25.attention_self.v_key.bias', 'bert.encoder.layer.25.attention_self.v_value.weight', 'bert.encoder.layer.25.attention_self.v_value.bias', 'bert.encoder.layer.25.attention_output.v_dense.weight', 'bert.encoder.layer.25.attention_output.v_dense.bias', 'bert.encoder.layer.25.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.25.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.26.intermediate.v_dense.weight', 'bert.encoder.layer.26.intermediate.v_dense.bias', 'bert.encoder.layer.26.output.v_dense.weight', 'bert.encoder.layer.26.output.v_dense.bias', 'bert.encoder.layer.26.output.v_LayerNorm.weight', 'bert.encoder.layer.26.output.v_LayerNorm.bias', 'bert.encoder.layer.27.attention_self.query.weight', 'bert.encoder.layer.27.attention_self.query.bias', 'bert.encoder.layer.27.attention_self.key.weight', 'bert.encoder.layer.27.attention_self.key.bias', 'bert.encoder.layer.27.attention_self.value.weight', 'bert.encoder.layer.27.attention_self.value.bias', 'bert.encoder.layer.27.attention_self.v_query.weight', 'bert.encoder.layer.27.attention_self.v_query.bias', 'bert.encoder.layer.27.attention_self.v_key.weight', 'bert.encoder.layer.27.attention_self.v_key.bias', 'bert.encoder.layer.27.attention_self.v_value.weight', 'bert.encoder.layer.27.attention_self.v_value.bias', 'bert.encoder.layer.27.attention_output.dense.weight', 'bert.encoder.layer.27.attention_output.dense.bias', 'bert.encoder.layer.27.attention_output.LayerNorm.weight', 'bert.encoder.layer.27.attention_output.LayerNorm.bias', 'bert.encoder.layer.27.attention_output.v_dense.weight', 'bert.encoder.layer.27.attention_output.v_dense.bias', 'bert.encoder.layer.27.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.27.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.28.attention_self.query.weight', 'bert.encoder.layer.28.attention_self.query.bias', 'bert.encoder.layer.28.attention_self.key.weight', 'bert.encoder.layer.28.attention_self.key.bias', 'bert.encoder.layer.28.attention_self.value.weight', 'bert.encoder.layer.28.attention_self.value.bias', 'bert.encoder.layer.28.attention_self.v_query.weight', 'bert.encoder.layer.28.attention_self.v_query.bias', 'bert.encoder.layer.28.attention_self.v_key.weight', 'bert.encoder.layer.28.attention_self.v_key.bias', 'bert.encoder.layer.28.attention_self.v_value.weight', 'bert.encoder.layer.28.attention_self.v_value.bias', 'bert.encoder.layer.28.attention_output.dense.weight', 'bert.encoder.layer.28.attention_output.dense.bias', 'bert.encoder.layer.28.attention_output.LayerNorm.weight', 'bert.encoder.layer.28.attention_output.LayerNorm.bias', 'bert.encoder.layer.28.attention_output.v_dense.weight', 'bert.encoder.layer.28.attention_output.v_dense.bias', 'bert.encoder.layer.28.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.28.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.29.intermediate.dense.weight', 'bert.encoder.layer.29.intermediate.dense.bias', 'bert.encoder.layer.29.intermediate.v_dense.weight', 'bert.encoder.layer.29.intermediate.v_dense.bias', 'bert.encoder.layer.29.output.dense.weight', 'bert.encoder.layer.29.output.dense.bias', 'bert.encoder.layer.29.output.LayerNorm.weight', 'bert.encoder.layer.29.output.LayerNorm.bias', 'bert.encoder.layer.29.output.v_dense.weight', 'bert.encoder.layer.29.output.v_dense.bias', 'bert.encoder.layer.29.output.v_LayerNorm.weight', 'bert.encoder.layer.29.output.v_LayerNorm.bias', 'bert.encoder.layer.30.attention_self.query.weight', 'bert.encoder.layer.30.attention_self.query.bias', 'bert.encoder.layer.30.attention_self.key.weight', 'bert.encoder.layer.30.attention_self.key.bias', 'bert.encoder.layer.30.attention_self.value.weight', 'bert.encoder.layer.30.attention_self.value.bias', 'bert.encoder.layer.30.attention_self.v_query.weight', 'bert.encoder.layer.30.attention_self.v_query.bias', 'bert.encoder.layer.30.attention_self.v_key.weight', 'bert.encoder.layer.30.attention_self.v_key.bias', 'bert.encoder.layer.30.attention_self.v_value.weight', 'bert.encoder.layer.30.attention_self.v_value.bias', 'bert.encoder.layer.30.attention_output.dense.weight', 'bert.encoder.layer.30.attention_output.dense.bias', 'bert.encoder.layer.30.attention_output.LayerNorm.weight', 'bert.encoder.layer.30.attention_output.LayerNorm.bias', 'bert.encoder.layer.30.attention_output.v_dense.weight', 'bert.encoder.layer.30.attention_output.v_dense.bias', 'bert.encoder.layer.30.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.30.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.31.attention_self.query.weight', 'bert.encoder.layer.31.attention_self.query.bias', 'bert.encoder.layer.31.attention_self.key.weight', 'bert.encoder.layer.31.attention_self.key.bias', 'bert.encoder.layer.31.attention_self.value.weight', 'bert.encoder.layer.31.attention_self.value.bias', 'bert.encoder.layer.31.attention_self.v_query.weight', 'bert.encoder.layer.31.attention_self.v_query.bias', 'bert.encoder.layer.31.attention_self.v_key.weight', 'bert.encoder.layer.31.attention_self.v_key.bias', 'bert.encoder.layer.31.attention_self.v_value.weight', 'bert.encoder.layer.31.attention_self.v_value.bias', 'bert.encoder.layer.31.attention_output.dense.weight', 'bert.encoder.layer.31.attention_output.dense.bias', 'bert.encoder.layer.31.attention_output.LayerNorm.weight', 'bert.encoder.layer.31.attention_output.LayerNorm.bias', 'bert.encoder.layer.31.attention_output.v_dense.weight', 'bert.encoder.layer.31.attention_output.v_dense.bias', 'bert.encoder.layer.31.attention_output.v_LayerNorm.weight', 'bert.encoder.layer.31.attention_output.v_LayerNorm.bias', 'bert.encoder.layer.32.intermediate.dense.weight', 'bert.encoder.layer.32.intermediate.dense.bias', 'bert.encoder.layer.32.intermediate.v_dense.weight', 'bert.encoder.layer.32.intermediate.v_dense.bias', 'bert.encoder.layer.32.output.dense.weight', 'bert.encoder.layer.32.output.dense.bias', 'bert.encoder.layer.32.output.LayerNorm.weight', 'bert.encoder.layer.32.output.LayerNorm.bias', 'bert.encoder.layer.32.output.v_dense.weight', 'bert.encoder.layer.32.output.v_dense.bias', 'bert.encoder.layer.32.output.v_LayerNorm.weight', 'bert.encoder.layer.32.output.v_LayerNorm.bias', 'bert.t_pooler.dense.weight', 'bert.t_pooler.dense.bias', 'bert.v_pooler.dense.weight', 'bert.v_pooler.dense.bias', 'cls.bi_seq_relationship.weight', 'cls.bi_seq_relationship.bias', 'cls.imagePredictions.transform.dense.weight', 'cls.imagePredictions.transform.dense.bias', 'cls.imagePredictions.transform.LayerNorm.weight', 'cls.imagePredictions.transform.LayerNorm.bias', 'cls.imagePredictions.decoder_dict.0.weight', 'cls.imagePredictions.decoder_dict.0.bias']
10/29/2020 17:54:00 - INFO - volta.utils -   Weights from pretrained model not used in BertForVLPreTraining: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']
10/29/2020 17:54:09 - INFO - __main__ -   >> Trainable Parameters:
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |Name                                                                |Dtype            |Shape           |#Params     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.embeddings.word_embeddings.weight                       |torch.float32    |(30522, 768)    |23440896    |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.embeddings.position_embeddings.weight                   |torch.float32    |(512, 768)      |393216      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.embeddings.token_type_embeddings.weight                 |torch.float32    |(2, 768)        |1536        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.weight                             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.embeddings.LayerNorm.bias                               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.weight                    |torch.float32    |(768, 2048)     |1572864     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.v_embeddings.image_embeddings.bias                      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.weight           |torch.float32    |(768, 5)        |3840        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.v_embeddings.image_location_embeddings.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.v_embeddings.ImgLayerNorm.weight                        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.v_embeddings.ImgLayerNorm.bias                          |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.v_embeddings.LocLayerNorm.weight                        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.v_embeddings.LocLayerNorm.bias                          |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.query.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.value.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.0.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.output.dense.bias                       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.1.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.query.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.value.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.2.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.output.dense.bias                       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.3.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.query.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.value.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.4.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.output.dense.bias                       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.5.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.query.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.value.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.6.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.output.dense.bias                       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.7.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.query.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.weight               |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.key.bias                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.value.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_query.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_query.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_key.weight             |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_key.bias               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_value.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_self.v_value.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.weight           |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.dense.bias             |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.weight       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.LayerNorm.bias         |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_dense.weight         |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_dense.bias           |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_LayerNorm.weight     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.8.attention_output.v_LayerNorm.bias       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.weight               |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.dense.bias                 |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.v_dense.weight             |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.intermediate.v_dense.bias               |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.weight                     |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.output.dense.bias                       |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.weight                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.output.LayerNorm.bias                   |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_dense.bias                     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_LayerNorm.weight               |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.9.output.v_LayerNorm.bias                 |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.10.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.11.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.11.output.dense.bias                      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.11.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.12.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.13.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.13.output.dense.bias                      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.13.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.14.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.15.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.15.output.dense.bias                      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.15.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.16.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.17.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.17.output.dense.bias                      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.17.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.18.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.19.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.output.dense.bias                      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.20.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.21.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.22.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.output.dense.bias                      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.23.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.24.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.25.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.output.dense.bias                      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.26.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.27.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.28.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.output.dense.bias                      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.29.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.30.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.query.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.query.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.key.weight              |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.key.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.value.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.value.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_query.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_query.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_key.weight            |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_key.bias              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_value.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_self.v_value.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.dense.weight          |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.dense.bias            |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.LayerNorm.weight      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.LayerNorm.bias        |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_dense.weight        |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_dense.bias          |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_LayerNorm.weight    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.31.attention_output.v_LayerNorm.bias      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.dense.weight              |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.dense.bias                |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.v_dense.weight            |torch.float32    |(3072, 768)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.intermediate.v_dense.bias              |torch.float32    |(3072,)         |3072        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.output.dense.weight                    |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.output.dense.bias                      |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.output.LayerNorm.weight                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.output.LayerNorm.bias                  |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_dense.bias                    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_LayerNorm.weight              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.encoder.layer.32.output.v_LayerNorm.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.t_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.t_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.v_pooler.dense.weight                                   |torch.float32    |(1024, 768)     |786432      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.bert.v_pooler.dense.bias                                     |torch.float32    |(1024,)         |1024        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.predictions.bias                                         |torch.float32    |(30522,)        |30522       |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.predictions.transform.dense.weight                       |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.predictions.transform.dense.bias                         |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.weight                   |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.predictions.transform.LayerNorm.bias                     |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.bi_seq_relationship.weight                               |torch.float32    |(2, 1024)       |2048        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.bi_seq_relationship.bias                                 |torch.float32    |(2,)            |2           |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.weight                  |torch.float32    |(768, 768)      |589824      |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.imagePredictions.transform.dense.bias                    |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.weight              |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.imagePredictions.transform.LayerNorm.bias                |torch.float32    |(768,)          |768         |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.weight                   |torch.float32    |(1601, 768)     |1229568     |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   |module.cls.imagePredictions.decoder_dict.0.bias                     |torch.float32    |(1601,)         |1601        |
10/29/2020 17:54:09 - INFO - __main__ -   ----------------------------------------------------------------------------------------------------------------------
10/29/2020 17:54:09 - INFO - __main__ -   >> # TrainableParams:       	211.37	M
10/29/2020 17:54:09 - INFO - __main__ -   >> # NonTrainableParams:    	0.00	M
10/29/2020 17:54:09 - INFO - __main__ -   >> # TotalParams:           	211.37	M
10/29/2020 17:54:09 - INFO - __main__ -   ***** Running training *****
10/29/2020 17:54:09 - INFO - __main__ -     Num examples = 2777649
10/29/2020 17:54:09 - INFO - __main__ -     Batch size = 256
10/29/2020 17:54:09 - INFO - __main__ -     Num steps = 108500
10/29/2020 17:54:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 21 Ep: 0.00 masked_t 1.730 masked_v 0.228 NSP 0.105 lr 3.33221e-05
10/29/2020 17:54:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 41 Ep: 0.00 masked_t 1.722 masked_v 0.237 NSP 0.093 lr 3.33011e-05
10/29/2020 17:55:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 61 Ep: 0.01 masked_t 1.787 masked_v 0.231 NSP 0.102 lr 3.32806e-05
10/29/2020 17:55:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 81 Ep: 0.01 masked_t 1.768 masked_v 0.234 NSP 0.097 lr 3.32601e-05
10/29/2020 17:56:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 101 Ep: 0.01 masked_t 1.713 masked_v 0.229 NSP 0.104 lr 3.32396e-05
10/29/2020 17:56:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 121 Ep: 0.01 masked_t 1.663 masked_v 0.230 NSP 0.105 lr 3.32192e-05
10/29/2020 17:56:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 141 Ep: 0.01 masked_t 1.663 masked_v 0.233 NSP 0.089 lr 3.31987e-05
10/29/2020 17:57:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 161 Ep: 0.01 masked_t 1.752 masked_v 0.233 NSP 0.093 lr 3.31782e-05
10/29/2020 17:57:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 181 Ep: 0.02 masked_t 1.717 masked_v 0.238 NSP 0.093 lr 3.31577e-05
10/29/2020 17:57:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 201 Ep: 0.02 masked_t 1.701 masked_v 0.225 NSP 0.105 lr 3.31372e-05
10/29/2020 17:58:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 221 Ep: 0.02 masked_t 1.752 masked_v 0.229 NSP 0.103 lr 3.31167e-05
10/29/2020 17:58:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 241 Ep: 0.02 masked_t 1.609 masked_v 0.235 NSP 0.096 lr 3.30963e-05
10/29/2020 17:58:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 261 Ep: 0.02 masked_t 1.758 masked_v 0.228 NSP 0.103 lr 3.30758e-05
10/29/2020 17:59:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 281 Ep: 0.03 masked_t 1.733 masked_v 0.231 NSP 0.106 lr 3.30553e-05
10/29/2020 17:59:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 301 Ep: 0.03 masked_t 1.710 masked_v 0.229 NSP 0.092 lr 3.30348e-05
10/29/2020 17:59:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 321 Ep: 0.03 masked_t 1.747 masked_v 0.228 NSP 0.097 lr 3.30143e-05
10/29/2020 18:00:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 341 Ep: 0.03 masked_t 1.735 masked_v 0.234 NSP 0.096 lr 3.29939e-05
10/29/2020 18:00:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 361 Ep: 0.03 masked_t 1.740 masked_v 0.230 NSP 0.095 lr 3.29734e-05
10/29/2020 18:00:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 381 Ep: 0.04 masked_t 1.706 masked_v 0.230 NSP 0.102 lr 3.29529e-05
10/29/2020 18:01:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 401 Ep: 0.04 masked_t 1.762 masked_v 0.229 NSP 0.092 lr 3.29324e-05
10/29/2020 18:01:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 421 Ep: 0.04 masked_t 1.821 masked_v 0.228 NSP 0.108 lr 3.29119e-05
10/29/2020 18:01:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 441 Ep: 0.04 masked_t 1.724 masked_v 0.232 NSP 0.097 lr 3.28914e-05
10/29/2020 18:02:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 461 Ep: 0.04 masked_t 1.670 masked_v 0.233 NSP 0.098 lr 3.2871e-05
10/29/2020 18:02:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 481 Ep: 0.04 masked_t 1.718 masked_v 0.225 NSP 0.102 lr 3.28505e-05
10/29/2020 18:02:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 501 Ep: 0.05 masked_t 1.720 masked_v 0.232 NSP 0.088 lr 3.283e-05
10/29/2020 18:03:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 521 Ep: 0.05 masked_t 1.785 masked_v 0.238 NSP 0.106 lr 3.28095e-05
10/29/2020 18:03:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 541 Ep: 0.05 masked_t 1.701 masked_v 0.231 NSP 0.112 lr 3.2789e-05
10/29/2020 18:03:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 561 Ep: 0.05 masked_t 1.662 masked_v 0.230 NSP 0.097 lr 3.27686e-05
10/29/2020 18:04:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 581 Ep: 0.05 masked_t 1.722 masked_v 0.227 NSP 0.102 lr 3.27481e-05
10/29/2020 18:04:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 601 Ep: 0.06 masked_t 1.742 masked_v 0.225 NSP 0.101 lr 3.27276e-05
10/29/2020 18:05:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 621 Ep: 0.06 masked_t 1.760 masked_v 0.235 NSP 0.090 lr 3.27071e-05
10/29/2020 18:05:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 641 Ep: 0.06 masked_t 1.704 masked_v 0.229 NSP 0.100 lr 3.26866e-05
10/29/2020 18:05:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 661 Ep: 0.06 masked_t 1.741 masked_v 0.223 NSP 0.097 lr 3.26662e-05
10/29/2020 18:06:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 681 Ep: 0.06 masked_t 1.681 masked_v 0.232 NSP 0.103 lr 3.26457e-05
10/29/2020 18:06:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 701 Ep: 0.06 masked_t 1.732 masked_v 0.227 NSP 0.094 lr 3.26252e-05
10/29/2020 18:06:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 721 Ep: 0.07 masked_t 1.752 masked_v 0.232 NSP 0.107 lr 3.26047e-05
10/29/2020 18:07:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 741 Ep: 0.07 masked_t 1.754 masked_v 0.230 NSP 0.105 lr 3.25842e-05
10/29/2020 18:07:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 761 Ep: 0.07 masked_t 1.697 masked_v 0.227 NSP 0.089 lr 3.25637e-05
10/29/2020 18:07:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 781 Ep: 0.07 masked_t 1.736 masked_v 0.233 NSP 0.105 lr 3.25433e-05
10/29/2020 18:08:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 801 Ep: 0.07 masked_t 1.684 masked_v 0.229 NSP 0.113 lr 3.25228e-05
10/29/2020 18:08:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 821 Ep: 0.08 masked_t 1.693 masked_v 0.231 NSP 0.085 lr 3.25023e-05
10/29/2020 18:08:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 841 Ep: 0.08 masked_t 1.674 masked_v 0.236 NSP 0.099 lr 3.24818e-05
10/29/2020 18:09:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 861 Ep: 0.08 masked_t 1.737 masked_v 0.229 NSP 0.101 lr 3.24613e-05
10/29/2020 18:09:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 881 Ep: 0.08 masked_t 1.701 masked_v 0.227 NSP 0.093 lr 3.24409e-05
10/29/2020 18:09:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 901 Ep: 0.08 masked_t 1.715 masked_v 0.229 NSP 0.101 lr 3.24204e-05
10/29/2020 18:10:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 921 Ep: 0.08 masked_t 1.728 masked_v 0.229 NSP 0.099 lr 3.23999e-05
10/29/2020 18:10:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 941 Ep: 0.09 masked_t 1.687 masked_v 0.227 NSP 0.090 lr 3.23794e-05
10/29/2020 18:10:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 961 Ep: 0.09 masked_t 1.704 masked_v 0.232 NSP 0.088 lr 3.23589e-05
10/29/2020 18:11:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 981 Ep: 0.09 masked_t 1.714 masked_v 0.233 NSP 0.092 lr 3.23385e-05
10/29/2020 18:11:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 1001 Ep: 0.09 masked_t 1.657 masked_v 0.227 NSP 0.098 lr 3.2318e-05
10/29/2020 18:12:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 1021 Ep: 0.09 masked_t 1.659 masked_v 0.230 NSP 0.092 lr 3.22975e-05
10/29/2020 18:12:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 1041 Ep: 0.10 masked_t 1.622 masked_v 0.224 NSP 0.094 lr 3.2277e-05
10/29/2020 18:12:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 1061 Ep: 0.10 masked_t 1.751 masked_v 0.225 NSP 0.100 lr 3.22565e-05
10/29/2020 18:13:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 1081 Ep: 0.10 masked_t 1.688 masked_v 0.234 NSP 0.084 lr 3.2236e-05
10/29/2020 18:13:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 1101 Ep: 0.10 masked_t 1.784 masked_v 0.224 NSP 0.103 lr 3.22156e-05
10/29/2020 18:13:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 1121 Ep: 0.10 masked_t 1.772 masked_v 0.230 NSP 0.108 lr 3.21951e-05
10/29/2020 18:14:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 1141 Ep: 0.11 masked_t 1.647 masked_v 0.224 NSP 0.096 lr 3.21746e-05
10/29/2020 18:14:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 1161 Ep: 0.11 masked_t 1.694 masked_v 0.223 NSP 0.086 lr 3.21541e-05
10/29/2020 18:14:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 1181 Ep: 0.11 masked_t 1.847 masked_v 0.229 NSP 0.090 lr 3.21336e-05
10/29/2020 18:15:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 1201 Ep: 0.11 masked_t 1.730 masked_v 0.234 NSP 0.096 lr 3.21132e-05
10/29/2020 18:15:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 1221 Ep: 0.11 masked_t 1.743 masked_v 0.227 NSP 0.101 lr 3.20927e-05
10/29/2020 18:15:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 1241 Ep: 0.11 masked_t 1.656 masked_v 0.227 NSP 0.097 lr 3.20722e-05
10/29/2020 18:16:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 1261 Ep: 0.12 masked_t 1.702 masked_v 0.225 NSP 0.095 lr 3.20517e-05
10/29/2020 18:16:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 1281 Ep: 0.12 masked_t 1.687 masked_v 0.228 NSP 0.095 lr 3.20312e-05
10/29/2020 18:16:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 1301 Ep: 0.12 masked_t 1.685 masked_v 0.220 NSP 0.101 lr 3.20108e-05
10/29/2020 18:17:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 1321 Ep: 0.12 masked_t 1.664 masked_v 0.231 NSP 0.093 lr 3.19903e-05
10/29/2020 18:17:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 1341 Ep: 0.12 masked_t 1.720 masked_v 0.227 NSP 0.100 lr 3.19698e-05
10/29/2020 18:17:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 1361 Ep: 0.13 masked_t 1.631 masked_v 0.231 NSP 0.098 lr 3.19493e-05
10/29/2020 18:18:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 1381 Ep: 0.13 masked_t 1.722 masked_v 0.224 NSP 0.093 lr 3.19288e-05
10/29/2020 18:18:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 1401 Ep: 0.13 masked_t 1.737 masked_v 0.228 NSP 0.102 lr 3.19083e-05
10/29/2020 18:18:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 1421 Ep: 0.13 masked_t 1.732 masked_v 0.229 NSP 0.099 lr 3.18879e-05
10/29/2020 18:19:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 1441 Ep: 0.13 masked_t 1.784 masked_v 0.232 NSP 0.097 lr 3.18674e-05
10/29/2020 18:19:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 1461 Ep: 0.13 masked_t 1.731 masked_v 0.228 NSP 0.103 lr 3.18469e-05
10/29/2020 18:20:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 1481 Ep: 0.14 masked_t 1.752 masked_v 0.229 NSP 0.097 lr 3.18264e-05
10/29/2020 18:20:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 1501 Ep: 0.14 masked_t 1.715 masked_v 0.228 NSP 0.112 lr 3.18059e-05
10/29/2020 18:20:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 1521 Ep: 0.14 masked_t 1.720 masked_v 0.227 NSP 0.094 lr 3.17855e-05
10/29/2020 18:21:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 1541 Ep: 0.14 masked_t 1.718 masked_v 0.222 NSP 0.085 lr 3.1765e-05
10/29/2020 18:21:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 1561 Ep: 0.14 masked_t 1.689 masked_v 0.228 NSP 0.097 lr 3.17445e-05
10/29/2020 18:21:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 1581 Ep: 0.15 masked_t 1.693 masked_v 0.229 NSP 0.096 lr 3.1724e-05
10/29/2020 18:22:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 1601 Ep: 0.15 masked_t 1.598 masked_v 0.230 NSP 0.096 lr 3.17035e-05
10/29/2020 18:22:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 1621 Ep: 0.15 masked_t 1.678 masked_v 0.225 NSP 0.093 lr 3.16831e-05
10/29/2020 18:22:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 1641 Ep: 0.15 masked_t 1.664 masked_v 0.224 NSP 0.092 lr 3.16626e-05
10/29/2020 18:23:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 1661 Ep: 0.15 masked_t 1.672 masked_v 0.222 NSP 0.090 lr 3.16421e-05
10/29/2020 18:23:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 1681 Ep: 0.15 masked_t 1.676 masked_v 0.227 NSP 0.095 lr 3.16216e-05
10/29/2020 18:23:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 1701 Ep: 0.16 masked_t 1.732 masked_v 0.231 NSP 0.094 lr 3.16011e-05
10/29/2020 18:24:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 1721 Ep: 0.16 masked_t 1.635 masked_v 0.224 NSP 0.083 lr 3.15806e-05
10/29/2020 18:24:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 1741 Ep: 0.16 masked_t 1.752 masked_v 0.221 NSP 0.101 lr 3.15602e-05
10/29/2020 18:24:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 1761 Ep: 0.16 masked_t 1.669 masked_v 0.226 NSP 0.106 lr 3.15397e-05
10/29/2020 18:25:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 1781 Ep: 0.16 masked_t 1.688 masked_v 0.228 NSP 0.089 lr 3.15192e-05
10/29/2020 18:25:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 1801 Ep: 0.17 masked_t 1.708 masked_v 0.229 NSP 0.100 lr 3.14987e-05
10/29/2020 18:25:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 1821 Ep: 0.17 masked_t 1.693 masked_v 0.223 NSP 0.094 lr 3.14782e-05
10/29/2020 18:26:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 1841 Ep: 0.17 masked_t 1.651 masked_v 0.225 NSP 0.103 lr 3.14578e-05
10/29/2020 18:26:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 1861 Ep: 0.17 masked_t 1.697 masked_v 0.226 NSP 0.091 lr 3.14373e-05
10/29/2020 18:26:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 1881 Ep: 0.17 masked_t 1.724 masked_v 0.225 NSP 0.087 lr 3.14168e-05
10/29/2020 18:27:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 1901 Ep: 0.18 masked_t 1.658 masked_v 0.224 NSP 0.086 lr 3.13963e-05
10/29/2020 18:27:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 1921 Ep: 0.18 masked_t 1.659 masked_v 0.227 NSP 0.089 lr 3.13758e-05
10/29/2020 18:28:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 1941 Ep: 0.18 masked_t 1.763 masked_v 0.231 NSP 0.109 lr 3.13554e-05
10/29/2020 18:28:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 1961 Ep: 0.18 masked_t 1.734 masked_v 0.231 NSP 0.097 lr 3.13349e-05
10/29/2020 18:28:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 1981 Ep: 0.18 masked_t 1.726 masked_v 0.228 NSP 0.097 lr 3.13144e-05
10/29/2020 18:29:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 2001 Ep: 0.18 masked_t 1.759 masked_v 0.225 NSP 0.099 lr 3.12939e-05
10/29/2020 18:29:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 2021 Ep: 0.19 masked_t 1.790 masked_v 0.233 NSP 0.103 lr 3.12734e-05
10/29/2020 18:29:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 2041 Ep: 0.19 masked_t 1.677 masked_v 0.230 NSP 0.093 lr 3.12529e-05
10/29/2020 18:30:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 2061 Ep: 0.19 masked_t 1.604 masked_v 0.226 NSP 0.092 lr 3.12325e-05
10/29/2020 18:30:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 2081 Ep: 0.19 masked_t 1.729 masked_v 0.229 NSP 0.103 lr 3.1212e-05
10/29/2020 18:30:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 2101 Ep: 0.19 masked_t 1.755 masked_v 0.229 NSP 0.099 lr 3.11915e-05
10/29/2020 18:31:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 2121 Ep: 0.20 masked_t 1.651 masked_v 0.232 NSP 0.106 lr 3.1171e-05
10/29/2020 18:31:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 2141 Ep: 0.20 masked_t 1.737 masked_v 0.228 NSP 0.093 lr 3.11505e-05
10/29/2020 18:31:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 2161 Ep: 0.20 masked_t 1.768 masked_v 0.222 NSP 0.092 lr 3.11301e-05
10/29/2020 18:32:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 2181 Ep: 0.20 masked_t 1.668 masked_v 0.226 NSP 0.093 lr 3.11096e-05
10/29/2020 18:32:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 2201 Ep: 0.20 masked_t 1.707 masked_v 0.221 NSP 0.095 lr 3.10891e-05
10/29/2020 18:32:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 2221 Ep: 0.20 masked_t 1.623 masked_v 0.228 NSP 0.102 lr 3.10686e-05
10/29/2020 18:33:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 2241 Ep: 0.21 masked_t 1.707 masked_v 0.233 NSP 0.089 lr 3.10481e-05
10/29/2020 18:33:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 2261 Ep: 0.21 masked_t 1.765 masked_v 0.226 NSP 0.099 lr 3.10276e-05
10/29/2020 18:33:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 2281 Ep: 0.21 masked_t 1.727 masked_v 0.234 NSP 0.097 lr 3.10072e-05
10/29/2020 18:34:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 2301 Ep: 0.21 masked_t 1.594 masked_v 0.227 NSP 0.108 lr 3.09867e-05
10/29/2020 18:34:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 2321 Ep: 0.21 masked_t 1.800 masked_v 0.227 NSP 0.102 lr 3.09662e-05
10/29/2020 18:35:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 2341 Ep: 0.22 masked_t 1.697 masked_v 0.224 NSP 0.085 lr 3.09457e-05
10/29/2020 18:35:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 2361 Ep: 0.22 masked_t 1.762 masked_v 0.232 NSP 0.095 lr 3.09252e-05
10/29/2020 18:35:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 2381 Ep: 0.22 masked_t 1.713 masked_v 0.225 NSP 0.086 lr 3.09048e-05
10/29/2020 18:36:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 2401 Ep: 0.22 masked_t 1.764 masked_v 0.224 NSP 0.099 lr 3.08843e-05
10/29/2020 18:36:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 2421 Ep: 0.22 masked_t 1.744 masked_v 0.223 NSP 0.099 lr 3.08638e-05
10/29/2020 18:36:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 2441 Ep: 0.22 masked_t 1.679 masked_v 0.217 NSP 0.091 lr 3.08433e-05
10/29/2020 18:37:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 2461 Ep: 0.23 masked_t 1.725 masked_v 0.225 NSP 0.098 lr 3.08228e-05
10/29/2020 18:37:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 2481 Ep: 0.23 masked_t 1.729 masked_v 0.230 NSP 0.095 lr 3.08024e-05
10/29/2020 18:37:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 2501 Ep: 0.23 masked_t 1.656 masked_v 0.228 NSP 0.092 lr 3.07819e-05
10/29/2020 18:38:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 2521 Ep: 0.23 masked_t 1.762 masked_v 0.223 NSP 0.095 lr 3.07614e-05
10/29/2020 18:38:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 2541 Ep: 0.23 masked_t 1.744 masked_v 0.222 NSP 0.103 lr 3.07409e-05
10/29/2020 18:38:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 2561 Ep: 0.24 masked_t 1.745 masked_v 0.220 NSP 0.099 lr 3.07204e-05
10/29/2020 18:39:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 2581 Ep: 0.24 masked_t 1.703 masked_v 0.232 NSP 0.099 lr 3.06999e-05
10/29/2020 18:39:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 2601 Ep: 0.24 masked_t 1.693 masked_v 0.228 NSP 0.098 lr 3.06795e-05
10/29/2020 18:39:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 2621 Ep: 0.24 masked_t 1.808 masked_v 0.227 NSP 0.099 lr 3.0659e-05
10/29/2020 18:40:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 2641 Ep: 0.24 masked_t 1.759 masked_v 0.228 NSP 0.096 lr 3.06385e-05
10/29/2020 18:40:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 2661 Ep: 0.25 masked_t 1.771 masked_v 0.227 NSP 0.091 lr 3.0618e-05
10/29/2020 18:40:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 2681 Ep: 0.25 masked_t 1.692 masked_v 0.223 NSP 0.097 lr 3.05975e-05
10/29/2020 18:41:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 2701 Ep: 0.25 masked_t 1.694 masked_v 0.232 NSP 0.107 lr 3.05771e-05
10/29/2020 18:41:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 2721 Ep: 0.25 masked_t 1.701 masked_v 0.226 NSP 0.089 lr 3.05566e-05
10/29/2020 18:41:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 2741 Ep: 0.25 masked_t 1.652 masked_v 0.232 NSP 0.097 lr 3.05361e-05
10/29/2020 18:42:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 2761 Ep: 0.25 masked_t 1.741 masked_v 0.232 NSP 0.095 lr 3.05156e-05
10/29/2020 18:42:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 2781 Ep: 0.26 masked_t 1.712 masked_v 0.230 NSP 0.102 lr 3.04951e-05
10/29/2020 18:43:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 2801 Ep: 0.26 masked_t 1.675 masked_v 0.225 NSP 0.088 lr 3.04747e-05
10/29/2020 18:43:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 2821 Ep: 0.26 masked_t 1.737 masked_v 0.232 NSP 0.094 lr 3.04542e-05
10/29/2020 18:43:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 2841 Ep: 0.26 masked_t 1.646 masked_v 0.227 NSP 0.098 lr 3.04337e-05
10/29/2020 18:44:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 2861 Ep: 0.26 masked_t 1.739 masked_v 0.224 NSP 0.090 lr 3.04132e-05
10/29/2020 18:44:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 2881 Ep: 0.27 masked_t 1.697 masked_v 0.221 NSP 0.096 lr 3.03927e-05
10/29/2020 18:44:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 2901 Ep: 0.27 masked_t 1.639 masked_v 0.229 NSP 0.100 lr 3.03722e-05
10/29/2020 18:45:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 2921 Ep: 0.27 masked_t 1.666 masked_v 0.228 NSP 0.091 lr 3.03518e-05
10/29/2020 18:45:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 2941 Ep: 0.27 masked_t 1.646 masked_v 0.226 NSP 0.092 lr 3.03313e-05
10/29/2020 18:45:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 2961 Ep: 0.27 masked_t 1.583 masked_v 0.229 NSP 0.099 lr 3.03108e-05
10/29/2020 18:46:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 2981 Ep: 0.27 masked_t 1.744 masked_v 0.227 NSP 0.103 lr 3.02903e-05
10/29/2020 18:46:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 3001 Ep: 0.28 masked_t 1.694 masked_v 0.218 NSP 0.097 lr 3.02698e-05
10/29/2020 18:46:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 3021 Ep: 0.28 masked_t 1.662 masked_v 0.231 NSP 0.105 lr 3.02494e-05
10/29/2020 18:47:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 3041 Ep: 0.28 masked_t 1.725 masked_v 0.226 NSP 0.096 lr 3.02289e-05
10/29/2020 18:47:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 3061 Ep: 0.28 masked_t 1.816 masked_v 0.222 NSP 0.104 lr 3.02084e-05
10/29/2020 18:47:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 3081 Ep: 0.28 masked_t 1.755 masked_v 0.227 NSP 0.100 lr 3.01879e-05
10/29/2020 18:48:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 3101 Ep: 0.29 masked_t 1.742 masked_v 0.227 NSP 0.105 lr 3.01674e-05
10/29/2020 18:48:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 3121 Ep: 0.29 masked_t 1.751 masked_v 0.224 NSP 0.090 lr 3.0147e-05
10/29/2020 18:48:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 3141 Ep: 0.29 masked_t 1.695 masked_v 0.225 NSP 0.105 lr 3.01265e-05
10/29/2020 18:49:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 3161 Ep: 0.29 masked_t 1.667 masked_v 0.226 NSP 0.114 lr 3.0106e-05
10/29/2020 18:49:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 3181 Ep: 0.29 masked_t 1.726 masked_v 0.225 NSP 0.103 lr 3.00855e-05
10/29/2020 18:49:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 3201 Ep: 0.30 masked_t 1.691 masked_v 0.220 NSP 0.086 lr 3.0065e-05
10/29/2020 18:50:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 3221 Ep: 0.30 masked_t 1.698 masked_v 0.225 NSP 0.095 lr 3.00445e-05
10/29/2020 18:50:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 3241 Ep: 0.30 masked_t 1.729 masked_v 0.224 NSP 0.094 lr 3.00241e-05
10/29/2020 18:51:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 3261 Ep: 0.30 masked_t 1.735 masked_v 0.222 NSP 0.104 lr 3.00036e-05
10/29/2020 18:51:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 3281 Ep: 0.30 masked_t 1.724 masked_v 0.225 NSP 0.094 lr 2.99831e-05
10/29/2020 18:51:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 3301 Ep: 0.30 masked_t 1.702 masked_v 0.223 NSP 0.095 lr 2.99626e-05
10/29/2020 18:52:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 3321 Ep: 0.31 masked_t 1.780 masked_v 0.224 NSP 0.090 lr 2.99421e-05
10/29/2020 18:52:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 3341 Ep: 0.31 masked_t 1.680 masked_v 0.234 NSP 0.104 lr 2.99217e-05
10/29/2020 18:52:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 3361 Ep: 0.31 masked_t 1.696 masked_v 0.227 NSP 0.091 lr 2.99012e-05
10/29/2020 18:53:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 3381 Ep: 0.31 masked_t 1.733 masked_v 0.221 NSP 0.092 lr 2.98807e-05
10/29/2020 18:53:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 3401 Ep: 0.31 masked_t 1.770 masked_v 0.227 NSP 0.099 lr 2.98602e-05
10/29/2020 18:53:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 3421 Ep: 0.32 masked_t 1.689 masked_v 0.227 NSP 0.090 lr 2.98397e-05
10/29/2020 18:54:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 3441 Ep: 0.32 masked_t 1.746 masked_v 0.227 NSP 0.102 lr 2.98193e-05
10/29/2020 18:54:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 3461 Ep: 0.32 masked_t 1.738 masked_v 0.228 NSP 0.080 lr 2.97988e-05
10/29/2020 18:54:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 3481 Ep: 0.32 masked_t 1.776 masked_v 0.222 NSP 0.096 lr 2.97783e-05
10/29/2020 18:55:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 3501 Ep: 0.32 masked_t 1.698 masked_v 0.227 NSP 0.097 lr 2.97578e-05
10/29/2020 18:55:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 3521 Ep: 0.32 masked_t 1.753 masked_v 0.231 NSP 0.091 lr 2.97373e-05
10/29/2020 18:55:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 3541 Ep: 0.33 masked_t 1.641 masked_v 0.228 NSP 0.097 lr 2.97168e-05
10/29/2020 18:56:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 3561 Ep: 0.33 masked_t 1.719 masked_v 0.215 NSP 0.095 lr 2.96964e-05
10/29/2020 18:56:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 3581 Ep: 0.33 masked_t 1.730 masked_v 0.226 NSP 0.108 lr 2.96759e-05
10/29/2020 18:56:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 3601 Ep: 0.33 masked_t 1.725 masked_v 0.223 NSP 0.092 lr 2.96554e-05
10/29/2020 18:57:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 3621 Ep: 0.33 masked_t 1.768 masked_v 0.225 NSP 0.089 lr 2.96349e-05
10/29/2020 18:57:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 3641 Ep: 0.34 masked_t 1.690 masked_v 0.227 NSP 0.099 lr 2.96144e-05
10/29/2020 18:57:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 3661 Ep: 0.34 masked_t 1.634 masked_v 0.222 NSP 0.097 lr 2.9594e-05
10/29/2020 18:58:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 3681 Ep: 0.34 masked_t 1.725 masked_v 0.220 NSP 0.101 lr 2.95735e-05
10/29/2020 18:58:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 3701 Ep: 0.34 masked_t 1.698 masked_v 0.232 NSP 0.085 lr 2.9553e-05
10/29/2020 18:59:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 3721 Ep: 0.34 masked_t 1.671 masked_v 0.229 NSP 0.092 lr 2.95325e-05
10/29/2020 18:59:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 3741 Ep: 0.34 masked_t 1.691 masked_v 0.227 NSP 0.087 lr 2.9512e-05
10/29/2020 18:59:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 3761 Ep: 0.35 masked_t 1.665 masked_v 0.223 NSP 0.083 lr 2.94916e-05
10/29/2020 19:00:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 3781 Ep: 0.35 masked_t 1.707 masked_v 0.226 NSP 0.098 lr 2.94711e-05
10/29/2020 19:00:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 3801 Ep: 0.35 masked_t 1.760 masked_v 0.224 NSP 0.090 lr 2.94506e-05
10/29/2020 19:00:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 3821 Ep: 0.35 masked_t 1.725 masked_v 0.224 NSP 0.093 lr 2.94301e-05
10/29/2020 19:01:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 3841 Ep: 0.35 masked_t 1.701 masked_v 0.226 NSP 0.094 lr 2.94096e-05
10/29/2020 19:01:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 3861 Ep: 0.36 masked_t 1.684 masked_v 0.229 NSP 0.091 lr 2.93891e-05
10/29/2020 19:01:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 3881 Ep: 0.36 masked_t 1.712 masked_v 0.229 NSP 0.110 lr 2.93687e-05
10/29/2020 19:02:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 3901 Ep: 0.36 masked_t 1.745 masked_v 0.225 NSP 0.088 lr 2.93482e-05
10/29/2020 19:02:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 3921 Ep: 0.36 masked_t 1.737 masked_v 0.223 NSP 0.089 lr 2.93277e-05
10/29/2020 19:02:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 3941 Ep: 0.36 masked_t 1.737 masked_v 0.230 NSP 0.091 lr 2.93072e-05
10/29/2020 19:03:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 3961 Ep: 0.37 masked_t 1.746 masked_v 0.225 NSP 0.094 lr 2.92867e-05
10/29/2020 19:03:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 3981 Ep: 0.37 masked_t 1.683 masked_v 0.230 NSP 0.093 lr 2.92663e-05
10/29/2020 19:03:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 4001 Ep: 0.37 masked_t 1.677 masked_v 0.230 NSP 0.098 lr 2.92458e-05
10/29/2020 19:04:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 4021 Ep: 0.37 masked_t 1.708 masked_v 0.222 NSP 0.097 lr 2.92253e-05
10/29/2020 19:04:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 4041 Ep: 0.37 masked_t 1.686 masked_v 0.226 NSP 0.099 lr 2.92048e-05
10/29/2020 19:04:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 4061 Ep: 0.37 masked_t 1.729 masked_v 0.226 NSP 0.101 lr 2.91843e-05
10/29/2020 19:05:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 4081 Ep: 0.38 masked_t 1.737 masked_v 0.227 NSP 0.093 lr 2.91639e-05
10/29/2020 19:05:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 4101 Ep: 0.38 masked_t 1.707 masked_v 0.230 NSP 0.093 lr 2.91434e-05
10/29/2020 19:05:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 4121 Ep: 0.38 masked_t 1.653 masked_v 0.229 NSP 0.086 lr 2.91229e-05
10/29/2020 19:06:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 4141 Ep: 0.38 masked_t 1.730 masked_v 0.222 NSP 0.109 lr 2.91024e-05
10/29/2020 19:06:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 4161 Ep: 0.38 masked_t 1.756 masked_v 0.228 NSP 0.095 lr 2.90819e-05
10/29/2020 19:06:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 4181 Ep: 0.39 masked_t 1.719 masked_v 0.227 NSP 0.089 lr 2.90614e-05
10/29/2020 19:07:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 4201 Ep: 0.39 masked_t 1.743 masked_v 0.220 NSP 0.090 lr 2.9041e-05
10/29/2020 19:07:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 4221 Ep: 0.39 masked_t 1.638 masked_v 0.221 NSP 0.089 lr 2.90205e-05
10/29/2020 19:08:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 4241 Ep: 0.39 masked_t 1.749 masked_v 0.228 NSP 0.096 lr 2.9e-05
10/29/2020 19:08:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 4261 Ep: 0.39 masked_t 1.668 masked_v 0.229 NSP 0.113 lr 2.89795e-05
10/29/2020 19:08:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 4281 Ep: 0.39 masked_t 1.733 masked_v 0.227 NSP 0.082 lr 2.8959e-05
10/29/2020 19:09:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 4301 Ep: 0.40 masked_t 1.702 masked_v 0.229 NSP 0.102 lr 2.89386e-05
10/29/2020 19:09:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 4321 Ep: 0.40 masked_t 1.735 masked_v 0.224 NSP 0.103 lr 2.89181e-05
10/29/2020 19:09:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 4341 Ep: 0.40 masked_t 1.701 masked_v 0.225 NSP 0.099 lr 2.88976e-05
10/29/2020 19:10:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 4361 Ep: 0.40 masked_t 1.681 masked_v 0.226 NSP 0.108 lr 2.88771e-05
10/29/2020 19:10:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 4381 Ep: 0.40 masked_t 1.786 masked_v 0.220 NSP 0.102 lr 2.88566e-05
10/29/2020 19:10:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 4401 Ep: 0.41 masked_t 1.650 masked_v 0.230 NSP 0.093 lr 2.88361e-05
10/29/2020 19:11:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 4421 Ep: 0.41 masked_t 1.652 masked_v 0.222 NSP 0.090 lr 2.88157e-05
10/29/2020 19:11:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 4441 Ep: 0.41 masked_t 1.607 masked_v 0.227 NSP 0.093 lr 2.87952e-05
10/29/2020 19:11:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 4461 Ep: 0.41 masked_t 1.693 masked_v 0.229 NSP 0.099 lr 2.87747e-05
10/29/2020 19:12:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 4481 Ep: 0.41 masked_t 1.592 masked_v 0.225 NSP 0.094 lr 2.87542e-05
10/29/2020 19:12:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 4501 Ep: 0.41 masked_t 1.748 masked_v 0.224 NSP 0.093 lr 2.87337e-05
10/29/2020 19:12:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 4521 Ep: 0.42 masked_t 1.734 masked_v 0.227 NSP 0.088 lr 2.87133e-05
10/29/2020 19:13:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 4541 Ep: 0.42 masked_t 1.662 masked_v 0.226 NSP 0.097 lr 2.86928e-05
10/29/2020 19:13:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 4561 Ep: 0.42 masked_t 1.692 masked_v 0.222 NSP 0.092 lr 2.86723e-05
10/29/2020 19:13:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 4581 Ep: 0.42 masked_t 1.660 masked_v 0.225 NSP 0.093 lr 2.86518e-05
10/29/2020 19:14:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 4601 Ep: 0.42 masked_t 1.638 masked_v 0.227 NSP 0.099 lr 2.86313e-05
10/29/2020 19:14:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 4621 Ep: 0.43 masked_t 1.656 masked_v 0.227 NSP 0.090 lr 2.86109e-05
10/29/2020 19:14:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 4641 Ep: 0.43 masked_t 1.769 masked_v 0.222 NSP 0.092 lr 2.85904e-05
10/29/2020 19:15:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 4661 Ep: 0.43 masked_t 1.777 masked_v 0.221 NSP 0.093 lr 2.85699e-05
10/29/2020 19:15:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 4681 Ep: 0.43 masked_t 1.700 masked_v 0.224 NSP 0.106 lr 2.85494e-05
10/29/2020 19:16:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 4701 Ep: 0.43 masked_t 1.692 masked_v 0.230 NSP 0.100 lr 2.85289e-05
10/29/2020 19:16:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 4721 Ep: 0.44 masked_t 1.720 masked_v 0.223 NSP 0.101 lr 2.85084e-05
10/29/2020 19:16:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 4741 Ep: 0.44 masked_t 1.798 masked_v 0.217 NSP 0.102 lr 2.8488e-05
10/29/2020 19:17:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 4761 Ep: 0.44 masked_t 1.744 masked_v 0.228 NSP 0.089 lr 2.84675e-05
10/29/2020 19:17:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 4781 Ep: 0.44 masked_t 1.724 masked_v 0.224 NSP 0.086 lr 2.8447e-05
10/29/2020 19:17:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 4801 Ep: 0.44 masked_t 1.711 masked_v 0.221 NSP 0.084 lr 2.84265e-05
10/29/2020 19:18:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 4821 Ep: 0.44 masked_t 1.782 masked_v 0.222 NSP 0.084 lr 2.8406e-05
10/29/2020 19:18:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 4841 Ep: 0.45 masked_t 1.657 masked_v 0.220 NSP 0.092 lr 2.83856e-05
10/29/2020 19:18:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 4861 Ep: 0.45 masked_t 1.672 masked_v 0.222 NSP 0.091 lr 2.83651e-05
10/29/2020 19:19:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 4881 Ep: 0.45 masked_t 1.706 masked_v 0.222 NSP 0.094 lr 2.83446e-05
10/29/2020 19:19:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 4901 Ep: 0.45 masked_t 1.705 masked_v 0.225 NSP 0.087 lr 2.83241e-05
10/29/2020 19:19:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 4921 Ep: 0.45 masked_t 1.692 masked_v 0.222 NSP 0.098 lr 2.83036e-05
10/29/2020 19:20:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 4941 Ep: 0.46 masked_t 1.725 masked_v 0.217 NSP 0.092 lr 2.82832e-05
10/29/2020 19:20:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 4961 Ep: 0.46 masked_t 1.733 masked_v 0.225 NSP 0.092 lr 2.82627e-05
10/29/2020 19:20:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 4981 Ep: 0.46 masked_t 1.835 masked_v 0.225 NSP 0.087 lr 2.82422e-05
10/29/2020 19:21:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 5001 Ep: 0.46 masked_t 1.661 masked_v 0.225 NSP 0.089 lr 2.82217e-05
10/29/2020 19:21:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 5021 Ep: 0.46 masked_t 1.770 masked_v 0.218 NSP 0.088 lr 2.82012e-05
10/29/2020 19:21:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 5041 Ep: 0.46 masked_t 1.755 masked_v 0.216 NSP 0.096 lr 2.81807e-05
10/29/2020 19:22:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 5061 Ep: 0.47 masked_t 1.704 masked_v 0.224 NSP 0.091 lr 2.81603e-05
10/29/2020 19:22:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 5081 Ep: 0.47 masked_t 1.767 masked_v 0.228 NSP 0.103 lr 2.81398e-05
10/29/2020 19:22:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 5101 Ep: 0.47 masked_t 1.627 masked_v 0.227 NSP 0.103 lr 2.81193e-05
10/29/2020 19:23:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 5121 Ep: 0.47 masked_t 1.620 masked_v 0.224 NSP 0.091 lr 2.80988e-05
10/29/2020 19:23:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 5141 Ep: 0.47 masked_t 1.653 masked_v 0.224 NSP 0.091 lr 2.80783e-05
10/29/2020 19:24:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 5161 Ep: 0.48 masked_t 1.614 masked_v 0.225 NSP 0.090 lr 2.80579e-05
10/29/2020 19:24:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 5181 Ep: 0.48 masked_t 1.686 masked_v 0.217 NSP 0.091 lr 2.80374e-05
10/29/2020 19:24:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 5201 Ep: 0.48 masked_t 1.600 masked_v 0.228 NSP 0.096 lr 2.80169e-05
10/29/2020 19:25:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 5221 Ep: 0.48 masked_t 1.706 masked_v 0.222 NSP 0.087 lr 2.79964e-05
10/29/2020 19:25:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 5241 Ep: 0.48 masked_t 1.643 masked_v 0.220 NSP 0.089 lr 2.79759e-05
10/29/2020 19:25:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 5261 Ep: 0.48 masked_t 1.708 masked_v 0.227 NSP 0.088 lr 2.79555e-05
10/29/2020 19:26:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 5281 Ep: 0.49 masked_t 1.674 masked_v 0.218 NSP 0.099 lr 2.7935e-05
10/29/2020 19:26:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 5301 Ep: 0.49 masked_t 1.728 masked_v 0.223 NSP 0.093 lr 2.79145e-05
10/29/2020 19:26:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 5321 Ep: 0.49 masked_t 1.708 masked_v 0.227 NSP 0.105 lr 2.7894e-05
10/29/2020 19:27:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 5341 Ep: 0.49 masked_t 1.778 masked_v 0.226 NSP 0.086 lr 2.78735e-05
10/29/2020 19:27:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 5361 Ep: 0.49 masked_t 1.671 masked_v 0.220 NSP 0.091 lr 2.7853e-05
10/29/2020 19:27:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 5381 Ep: 0.50 masked_t 1.718 masked_v 0.228 NSP 0.088 lr 2.78326e-05
10/29/2020 19:28:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 5401 Ep: 0.50 masked_t 1.709 masked_v 0.226 NSP 0.091 lr 2.78121e-05
10/29/2020 19:28:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 5421 Ep: 0.50 masked_t 1.691 masked_v 0.217 NSP 0.094 lr 2.77916e-05
10/29/2020 19:28:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 5441 Ep: 0.50 masked_t 1.650 masked_v 0.222 NSP 0.085 lr 2.77711e-05
10/29/2020 19:29:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 5461 Ep: 0.50 masked_t 1.676 masked_v 0.215 NSP 0.095 lr 2.77506e-05
10/29/2020 19:29:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 5481 Ep: 0.51 masked_t 1.709 masked_v 0.229 NSP 0.100 lr 2.77302e-05
10/29/2020 19:29:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 5501 Ep: 0.51 masked_t 1.683 masked_v 0.220 NSP 0.094 lr 2.77097e-05
10/29/2020 19:30:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 5521 Ep: 0.51 masked_t 1.747 masked_v 0.229 NSP 0.100 lr 2.76892e-05
10/29/2020 19:30:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 5541 Ep: 0.51 masked_t 1.647 masked_v 0.224 NSP 0.089 lr 2.76687e-05
10/29/2020 19:30:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 5561 Ep: 0.51 masked_t 1.709 masked_v 0.222 NSP 0.087 lr 2.76482e-05
10/29/2020 19:31:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 5581 Ep: 0.51 masked_t 1.713 masked_v 0.220 NSP 0.096 lr 2.76278e-05
10/29/2020 19:31:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 5601 Ep: 0.52 masked_t 1.736 masked_v 0.219 NSP 0.084 lr 2.76073e-05
10/29/2020 19:31:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 5621 Ep: 0.52 masked_t 1.653 masked_v 0.221 NSP 0.099 lr 2.75868e-05
10/29/2020 19:32:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 5641 Ep: 0.52 masked_t 1.689 masked_v 0.224 NSP 0.102 lr 2.75663e-05
10/29/2020 19:32:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 5661 Ep: 0.52 masked_t 1.645 masked_v 0.218 NSP 0.092 lr 2.75458e-05
10/29/2020 19:33:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 5681 Ep: 0.52 masked_t 1.718 masked_v 0.222 NSP 0.085 lr 2.75253e-05
10/29/2020 19:33:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 5701 Ep: 0.53 masked_t 1.692 masked_v 0.219 NSP 0.093 lr 2.75049e-05
10/29/2020 19:33:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 5721 Ep: 0.53 masked_t 1.710 masked_v 0.219 NSP 0.097 lr 2.74844e-05
10/29/2020 19:34:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 5741 Ep: 0.53 masked_t 1.636 masked_v 0.221 NSP 0.087 lr 2.74639e-05
10/29/2020 19:34:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 5761 Ep: 0.53 masked_t 1.687 masked_v 0.216 NSP 0.093 lr 2.74434e-05
10/29/2020 19:34:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 5781 Ep: 0.53 masked_t 1.570 masked_v 0.225 NSP 0.088 lr 2.74229e-05
10/29/2020 19:35:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 5801 Ep: 0.53 masked_t 1.672 masked_v 0.224 NSP 0.084 lr 2.74025e-05
10/29/2020 19:35:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 5821 Ep: 0.54 masked_t 1.727 masked_v 0.226 NSP 0.092 lr 2.7382e-05
10/29/2020 19:35:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 5841 Ep: 0.54 masked_t 1.744 masked_v 0.225 NSP 0.101 lr 2.73615e-05
10/29/2020 19:36:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 5861 Ep: 0.54 masked_t 1.674 masked_v 0.220 NSP 0.086 lr 2.7341e-05
10/29/2020 19:36:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 5881 Ep: 0.54 masked_t 1.707 masked_v 0.223 NSP 0.086 lr 2.73205e-05
10/29/2020 19:36:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 5901 Ep: 0.54 masked_t 1.683 masked_v 0.220 NSP 0.091 lr 2.73001e-05
10/29/2020 19:37:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 5921 Ep: 0.55 masked_t 1.742 masked_v 0.231 NSP 0.098 lr 2.72796e-05
10/29/2020 19:37:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 5941 Ep: 0.55 masked_t 1.662 masked_v 0.226 NSP 0.091 lr 2.72591e-05
10/29/2020 19:37:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 5961 Ep: 0.55 masked_t 1.693 masked_v 0.224 NSP 0.081 lr 2.72386e-05
10/29/2020 19:38:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 5981 Ep: 0.55 masked_t 1.690 masked_v 0.220 NSP 0.090 lr 2.72181e-05
10/29/2020 19:38:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 6001 Ep: 0.55 masked_t 1.756 masked_v 0.220 NSP 0.091 lr 2.71976e-05
10/29/2020 19:38:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 6021 Ep: 0.55 masked_t 1.722 masked_v 0.218 NSP 0.102 lr 2.71772e-05
10/29/2020 19:39:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 6041 Ep: 0.56 masked_t 1.678 masked_v 0.218 NSP 0.108 lr 2.71567e-05
10/29/2020 19:39:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 6061 Ep: 0.56 masked_t 1.587 masked_v 0.226 NSP 0.107 lr 2.71362e-05
10/29/2020 19:39:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 6081 Ep: 0.56 masked_t 1.727 masked_v 0.223 NSP 0.090 lr 2.71157e-05
10/29/2020 19:40:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 6101 Ep: 0.56 masked_t 1.704 masked_v 0.223 NSP 0.092 lr 2.70952e-05
10/29/2020 19:40:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 6121 Ep: 0.56 masked_t 1.620 masked_v 0.224 NSP 0.089 lr 2.70748e-05
10/29/2020 19:41:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 6141 Ep: 0.57 masked_t 1.678 masked_v 0.219 NSP 0.084 lr 2.70543e-05
10/29/2020 19:41:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 6161 Ep: 0.57 masked_t 1.680 masked_v 0.220 NSP 0.088 lr 2.70338e-05
10/29/2020 19:41:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 6181 Ep: 0.57 masked_t 1.710 masked_v 0.220 NSP 0.093 lr 2.70133e-05
10/29/2020 19:42:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 6201 Ep: 0.57 masked_t 1.687 masked_v 0.218 NSP 0.091 lr 2.69928e-05
10/29/2020 19:42:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 6221 Ep: 0.57 masked_t 1.710 masked_v 0.222 NSP 0.091 lr 2.69724e-05
10/29/2020 19:42:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 6241 Ep: 0.58 masked_t 1.637 masked_v 0.220 NSP 0.095 lr 2.69519e-05
10/29/2020 19:43:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 6261 Ep: 0.58 masked_t 1.637 masked_v 0.221 NSP 0.098 lr 2.69314e-05
10/29/2020 19:43:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 6281 Ep: 0.58 masked_t 1.711 masked_v 0.219 NSP 0.094 lr 2.69109e-05
10/29/2020 19:43:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 6301 Ep: 0.58 masked_t 1.718 masked_v 0.224 NSP 0.089 lr 2.68904e-05
10/29/2020 19:44:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 6321 Ep: 0.58 masked_t 1.682 masked_v 0.221 NSP 0.104 lr 2.68699e-05
10/29/2020 19:44:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 6341 Ep: 0.58 masked_t 1.682 masked_v 0.224 NSP 0.088 lr 2.68495e-05
10/29/2020 19:44:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 6361 Ep: 0.59 masked_t 1.696 masked_v 0.222 NSP 0.089 lr 2.6829e-05
10/29/2020 19:45:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 6381 Ep: 0.59 masked_t 1.673 masked_v 0.221 NSP 0.098 lr 2.68085e-05
10/29/2020 19:45:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 6401 Ep: 0.59 masked_t 1.672 masked_v 0.227 NSP 0.093 lr 2.6788e-05
10/29/2020 19:45:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 6421 Ep: 0.59 masked_t 1.724 masked_v 0.226 NSP 0.088 lr 2.67675e-05
10/29/2020 19:46:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 6441 Ep: 0.59 masked_t 1.746 masked_v 0.226 NSP 0.097 lr 2.67471e-05
10/29/2020 19:46:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 6461 Ep: 0.60 masked_t 1.756 masked_v 0.223 NSP 0.090 lr 2.67266e-05
10/29/2020 19:46:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 6481 Ep: 0.60 masked_t 1.687 masked_v 0.225 NSP 0.099 lr 2.67061e-05
10/29/2020 19:47:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 6501 Ep: 0.60 masked_t 1.677 masked_v 0.220 NSP 0.087 lr 2.66856e-05
10/29/2020 19:47:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 6521 Ep: 0.60 masked_t 1.736 masked_v 0.224 NSP 0.082 lr 2.66651e-05
10/29/2020 19:47:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 6541 Ep: 0.60 masked_t 1.704 masked_v 0.226 NSP 0.094 lr 2.66446e-05
10/29/2020 19:48:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 6561 Ep: 0.60 masked_t 1.766 masked_v 0.221 NSP 0.102 lr 2.66242e-05
10/29/2020 19:48:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 6581 Ep: 0.61 masked_t 1.710 masked_v 0.223 NSP 0.096 lr 2.66037e-05
10/29/2020 19:49:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 6601 Ep: 0.61 masked_t 1.702 masked_v 0.226 NSP 0.089 lr 2.65832e-05
10/29/2020 19:49:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 6621 Ep: 0.61 masked_t 1.714 masked_v 0.223 NSP 0.093 lr 2.65627e-05
10/29/2020 19:49:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 6641 Ep: 0.61 masked_t 1.717 masked_v 0.221 NSP 0.092 lr 2.65422e-05
10/29/2020 19:50:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 6661 Ep: 0.61 masked_t 1.659 masked_v 0.224 NSP 0.098 lr 2.65218e-05
10/29/2020 19:50:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 6681 Ep: 0.62 masked_t 1.657 masked_v 0.222 NSP 0.094 lr 2.65013e-05
10/29/2020 19:50:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 6701 Ep: 0.62 masked_t 1.693 masked_v 0.219 NSP 0.101 lr 2.64808e-05
10/29/2020 19:51:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 6721 Ep: 0.62 masked_t 1.802 masked_v 0.222 NSP 0.086 lr 2.64603e-05
10/29/2020 19:51:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 6741 Ep: 0.62 masked_t 1.718 masked_v 0.219 NSP 0.089 lr 2.64398e-05
10/29/2020 19:51:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 6761 Ep: 0.62 masked_t 1.704 masked_v 0.227 NSP 0.098 lr 2.64194e-05
10/29/2020 19:52:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 6781 Ep: 0.62 masked_t 1.702 masked_v 0.226 NSP 0.088 lr 2.63989e-05
10/29/2020 19:52:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 6801 Ep: 0.63 masked_t 1.680 masked_v 0.217 NSP 0.090 lr 2.63784e-05
10/29/2020 19:52:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 6821 Ep: 0.63 masked_t 1.752 masked_v 0.222 NSP 0.094 lr 2.63579e-05
10/29/2020 19:53:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 6841 Ep: 0.63 masked_t 1.859 masked_v 0.221 NSP 0.088 lr 2.63374e-05
10/29/2020 19:53:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 6861 Ep: 0.63 masked_t 1.746 masked_v 0.221 NSP 0.106 lr 2.63169e-05
10/29/2020 19:53:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 6881 Ep: 0.63 masked_t 1.715 masked_v 0.216 NSP 0.082 lr 2.62965e-05
10/29/2020 19:54:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 6901 Ep: 0.64 masked_t 1.759 masked_v 0.219 NSP 0.093 lr 2.6276e-05
10/29/2020 19:54:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 6921 Ep: 0.64 masked_t 1.692 masked_v 0.224 NSP 0.091 lr 2.62555e-05
10/29/2020 19:54:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 6941 Ep: 0.64 masked_t 1.683 masked_v 0.223 NSP 0.092 lr 2.6235e-05
10/29/2020 19:55:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 6961 Ep: 0.64 masked_t 1.743 masked_v 0.226 NSP 0.093 lr 2.62145e-05
10/29/2020 19:55:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 6981 Ep: 0.64 masked_t 1.710 masked_v 0.225 NSP 0.091 lr 2.61941e-05
10/29/2020 19:56:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 7001 Ep: 0.65 masked_t 1.608 masked_v 0.220 NSP 0.098 lr 2.61736e-05
10/29/2020 19:56:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 7021 Ep: 0.65 masked_t 1.748 masked_v 0.226 NSP 0.092 lr 2.61531e-05
10/29/2020 19:56:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 7041 Ep: 0.65 masked_t 1.713 masked_v 0.225 NSP 0.090 lr 2.61326e-05
10/29/2020 19:57:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 7061 Ep: 0.65 masked_t 1.684 masked_v 0.220 NSP 0.095 lr 2.61121e-05
10/29/2020 19:57:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 7081 Ep: 0.65 masked_t 1.715 masked_v 0.226 NSP 0.086 lr 2.60917e-05
10/29/2020 19:57:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 7101 Ep: 0.65 masked_t 1.740 masked_v 0.226 NSP 0.092 lr 2.60712e-05
10/29/2020 19:58:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 7121 Ep: 0.66 masked_t 1.783 masked_v 0.216 NSP 0.090 lr 2.60507e-05
10/29/2020 19:58:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 7141 Ep: 0.66 masked_t 1.702 masked_v 0.225 NSP 0.091 lr 2.60302e-05
10/29/2020 19:58:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 7161 Ep: 0.66 masked_t 1.649 masked_v 0.219 NSP 0.082 lr 2.60097e-05
10/29/2020 19:59:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 7181 Ep: 0.66 masked_t 1.698 masked_v 0.220 NSP 0.092 lr 2.59892e-05
10/29/2020 19:59:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 7201 Ep: 0.66 masked_t 1.721 masked_v 0.215 NSP 0.098 lr 2.59688e-05
10/29/2020 19:59:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 7221 Ep: 0.67 masked_t 1.764 masked_v 0.227 NSP 0.088 lr 2.59483e-05
10/29/2020 20:00:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 7241 Ep: 0.67 masked_t 1.706 masked_v 0.223 NSP 0.093 lr 2.59278e-05
10/29/2020 20:00:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 7261 Ep: 0.67 masked_t 1.685 masked_v 0.231 NSP 0.093 lr 2.59073e-05
10/29/2020 20:00:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 7281 Ep: 0.67 masked_t 1.657 masked_v 0.225 NSP 0.088 lr 2.58868e-05
10/29/2020 20:01:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 7301 Ep: 0.67 masked_t 1.727 masked_v 0.226 NSP 0.082 lr 2.58664e-05
10/29/2020 20:01:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 7321 Ep: 0.67 masked_t 1.742 masked_v 0.227 NSP 0.097 lr 2.58459e-05
10/29/2020 20:01:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 7341 Ep: 0.68 masked_t 1.743 masked_v 0.227 NSP 0.087 lr 2.58254e-05
10/29/2020 20:02:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 7361 Ep: 0.68 masked_t 1.705 masked_v 0.222 NSP 0.089 lr 2.58049e-05
10/29/2020 20:02:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 7381 Ep: 0.68 masked_t 1.652 masked_v 0.228 NSP 0.092 lr 2.57844e-05
10/29/2020 20:02:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 7401 Ep: 0.68 masked_t 1.726 masked_v 0.226 NSP 0.083 lr 2.5764e-05
10/29/2020 20:03:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 7421 Ep: 0.68 masked_t 1.617 masked_v 0.226 NSP 0.089 lr 2.57435e-05
10/29/2020 20:03:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 7441 Ep: 0.69 masked_t 1.660 masked_v 0.225 NSP 0.082 lr 2.5723e-05
10/29/2020 20:04:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 7461 Ep: 0.69 masked_t 1.676 masked_v 0.227 NSP 0.099 lr 2.57025e-05
10/29/2020 20:04:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 7481 Ep: 0.69 masked_t 1.669 masked_v 0.222 NSP 0.088 lr 2.5682e-05
10/29/2020 20:04:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 7501 Ep: 0.69 masked_t 1.776 masked_v 0.220 NSP 0.100 lr 2.56615e-05
10/29/2020 20:05:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 7521 Ep: 0.69 masked_t 1.697 masked_v 0.222 NSP 0.092 lr 2.56411e-05
10/29/2020 20:05:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 7541 Ep: 0.70 masked_t 1.707 masked_v 0.215 NSP 0.085 lr 2.56206e-05
10/29/2020 20:05:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 7561 Ep: 0.70 masked_t 1.657 masked_v 0.225 NSP 0.089 lr 2.56001e-05
10/29/2020 20:06:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 7581 Ep: 0.70 masked_t 1.663 masked_v 0.224 NSP 0.088 lr 2.55796e-05
10/29/2020 20:06:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 7601 Ep: 0.70 masked_t 1.603 masked_v 0.220 NSP 0.095 lr 2.55591e-05
10/29/2020 20:06:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 7621 Ep: 0.70 masked_t 1.706 masked_v 0.218 NSP 0.096 lr 2.55387e-05
10/29/2020 20:07:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 7641 Ep: 0.70 masked_t 1.782 masked_v 0.216 NSP 0.090 lr 2.55182e-05
10/29/2020 20:07:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 7661 Ep: 0.71 masked_t 1.642 masked_v 0.225 NSP 0.096 lr 2.54977e-05
10/29/2020 20:07:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 7681 Ep: 0.71 masked_t 1.684 masked_v 0.222 NSP 0.088 lr 2.54772e-05
10/29/2020 20:08:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 7701 Ep: 0.71 masked_t 1.738 masked_v 0.218 NSP 0.090 lr 2.54567e-05
10/29/2020 20:08:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 7721 Ep: 0.71 masked_t 1.640 masked_v 0.224 NSP 0.091 lr 2.54363e-05
10/29/2020 20:08:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 7741 Ep: 0.71 masked_t 1.669 masked_v 0.220 NSP 0.095 lr 2.54158e-05
10/29/2020 20:09:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 7761 Ep: 0.72 masked_t 1.651 masked_v 0.224 NSP 0.105 lr 2.53953e-05
10/29/2020 20:09:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 7781 Ep: 0.72 masked_t 1.674 masked_v 0.224 NSP 0.092 lr 2.53748e-05
10/29/2020 20:09:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 7801 Ep: 0.72 masked_t 1.696 masked_v 0.227 NSP 0.095 lr 2.53543e-05
10/29/2020 20:10:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 7821 Ep: 0.72 masked_t 1.715 masked_v 0.221 NSP 0.086 lr 2.53338e-05
10/29/2020 20:10:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 7841 Ep: 0.72 masked_t 1.658 masked_v 0.225 NSP 0.101 lr 2.53134e-05
10/29/2020 20:10:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 7861 Ep: 0.72 masked_t 1.672 masked_v 0.227 NSP 0.084 lr 2.52929e-05
10/29/2020 20:11:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 7881 Ep: 0.73 masked_t 1.654 masked_v 0.224 NSP 0.092 lr 2.52724e-05
10/29/2020 20:11:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 7901 Ep: 0.73 masked_t 1.689 masked_v 0.218 NSP 0.090 lr 2.52519e-05
10/29/2020 20:12:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 7921 Ep: 0.73 masked_t 1.738 masked_v 0.218 NSP 0.095 lr 2.52314e-05
10/29/2020 20:12:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 7941 Ep: 0.73 masked_t 1.719 masked_v 0.214 NSP 0.091 lr 2.5211e-05
10/29/2020 20:12:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 7961 Ep: 0.73 masked_t 1.670 masked_v 0.218 NSP 0.082 lr 2.51905e-05
10/29/2020 20:13:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 7981 Ep: 0.74 masked_t 1.612 masked_v 0.227 NSP 0.089 lr 2.517e-05
10/29/2020 20:13:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 8001 Ep: 0.74 masked_t 1.573 masked_v 0.221 NSP 0.096 lr 2.51495e-05
10/29/2020 20:13:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 8021 Ep: 0.74 masked_t 1.671 masked_v 0.220 NSP 0.088 lr 2.5129e-05
10/29/2020 20:14:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 8041 Ep: 0.74 masked_t 1.642 masked_v 0.226 NSP 0.090 lr 2.51086e-05
10/29/2020 20:14:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 8061 Ep: 0.74 masked_t 1.675 masked_v 0.223 NSP 0.084 lr 2.50881e-05
10/29/2020 20:14:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 8081 Ep: 0.74 masked_t 1.657 masked_v 0.227 NSP 0.091 lr 2.50676e-05
10/29/2020 20:15:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 8101 Ep: 0.75 masked_t 1.620 masked_v 0.225 NSP 0.096 lr 2.50471e-05
10/29/2020 20:15:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 8121 Ep: 0.75 masked_t 1.703 masked_v 0.226 NSP 0.093 lr 2.50266e-05
10/29/2020 20:15:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 8141 Ep: 0.75 masked_t 1.690 masked_v 0.220 NSP 0.094 lr 2.50061e-05
10/29/2020 20:16:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 8161 Ep: 0.75 masked_t 1.716 masked_v 0.228 NSP 0.087 lr 2.49857e-05
10/29/2020 20:16:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 8181 Ep: 0.75 masked_t 1.682 masked_v 0.222 NSP 0.092 lr 2.49652e-05
10/29/2020 20:16:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 8201 Ep: 0.76 masked_t 1.682 masked_v 0.222 NSP 0.094 lr 2.49447e-05
10/29/2020 20:17:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 8221 Ep: 0.76 masked_t 1.703 masked_v 0.219 NSP 0.088 lr 2.49242e-05
10/29/2020 20:17:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 8241 Ep: 0.76 masked_t 1.688 masked_v 0.217 NSP 0.090 lr 2.49037e-05
10/29/2020 20:17:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 8261 Ep: 0.76 masked_t 1.719 masked_v 0.219 NSP 0.094 lr 2.48833e-05
10/29/2020 20:18:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 8281 Ep: 0.76 masked_t 1.639 masked_v 0.223 NSP 0.097 lr 2.48628e-05
10/29/2020 20:18:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 8301 Ep: 0.77 masked_t 1.644 masked_v 0.226 NSP 0.097 lr 2.48423e-05
10/29/2020 20:18:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 8321 Ep: 0.77 masked_t 1.685 masked_v 0.219 NSP 0.091 lr 2.48218e-05
10/29/2020 20:19:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 8341 Ep: 0.77 masked_t 1.685 masked_v 0.226 NSP 0.080 lr 2.48013e-05
10/29/2020 20:19:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 8361 Ep: 0.77 masked_t 1.675 masked_v 0.220 NSP 0.088 lr 2.47808e-05
10/29/2020 20:20:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 8381 Ep: 0.77 masked_t 1.716 masked_v 0.225 NSP 0.094 lr 2.47604e-05
10/29/2020 20:20:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 8401 Ep: 0.77 masked_t 1.691 masked_v 0.216 NSP 0.091 lr 2.47399e-05
10/29/2020 20:20:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 8421 Ep: 0.78 masked_t 1.667 masked_v 0.222 NSP 0.089 lr 2.47194e-05
10/29/2020 20:21:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 8441 Ep: 0.78 masked_t 1.680 masked_v 0.224 NSP 0.077 lr 2.46989e-05
10/29/2020 20:21:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 8461 Ep: 0.78 masked_t 1.746 masked_v 0.224 NSP 0.095 lr 2.46784e-05
10/29/2020 20:21:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 8481 Ep: 0.78 masked_t 1.764 masked_v 0.221 NSP 0.086 lr 2.4658e-05
10/29/2020 20:22:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 8501 Ep: 0.78 masked_t 1.776 masked_v 0.229 NSP 0.096 lr 2.46375e-05
10/29/2020 20:22:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 8521 Ep: 0.79 masked_t 1.641 masked_v 0.220 NSP 0.090 lr 2.4617e-05
10/29/2020 20:22:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 8541 Ep: 0.79 masked_t 1.639 masked_v 0.226 NSP 0.089 lr 2.45965e-05
10/29/2020 20:23:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 8561 Ep: 0.79 masked_t 1.727 masked_v 0.221 NSP 0.088 lr 2.4576e-05
10/29/2020 20:23:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 8581 Ep: 0.79 masked_t 1.636 masked_v 0.222 NSP 0.087 lr 2.45556e-05
10/29/2020 20:23:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 8601 Ep: 0.79 masked_t 1.641 masked_v 0.227 NSP 0.080 lr 2.45351e-05
10/29/2020 20:24:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 8621 Ep: 0.79 masked_t 1.653 masked_v 0.223 NSP 0.097 lr 2.45146e-05
10/29/2020 20:24:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 8641 Ep: 0.80 masked_t 1.639 masked_v 0.225 NSP 0.098 lr 2.44941e-05
10/29/2020 20:24:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 8661 Ep: 0.80 masked_t 1.577 masked_v 0.220 NSP 0.096 lr 2.44736e-05
10/29/2020 20:25:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 8681 Ep: 0.80 masked_t 1.633 masked_v 0.222 NSP 0.099 lr 2.44531e-05
10/29/2020 20:25:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 8701 Ep: 0.80 masked_t 1.695 masked_v 0.222 NSP 0.083 lr 2.44327e-05
10/29/2020 20:25:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 8721 Ep: 0.80 masked_t 1.746 masked_v 0.220 NSP 0.085 lr 2.44122e-05
10/29/2020 20:26:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 8741 Ep: 0.81 masked_t 1.673 masked_v 0.217 NSP 0.092 lr 2.43917e-05
10/29/2020 20:26:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 8761 Ep: 0.81 masked_t 1.716 masked_v 0.224 NSP 0.086 lr 2.43712e-05
10/29/2020 20:27:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 8781 Ep: 0.81 masked_t 1.658 masked_v 0.223 NSP 0.089 lr 2.43507e-05
10/29/2020 20:27:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 8801 Ep: 0.81 masked_t 1.566 masked_v 0.223 NSP 0.090 lr 2.43303e-05
10/29/2020 20:27:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 8821 Ep: 0.81 masked_t 1.660 masked_v 0.218 NSP 0.090 lr 2.43098e-05
10/29/2020 20:28:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 8841 Ep: 0.81 masked_t 1.651 masked_v 0.218 NSP 0.093 lr 2.42893e-05
10/29/2020 20:28:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 8861 Ep: 0.82 masked_t 1.577 masked_v 0.218 NSP 0.102 lr 2.42688e-05
10/29/2020 20:28:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 8881 Ep: 0.82 masked_t 1.666 masked_v 0.210 NSP 0.087 lr 2.42483e-05
10/29/2020 20:29:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 8901 Ep: 0.82 masked_t 1.676 masked_v 0.218 NSP 0.088 lr 2.42279e-05
10/29/2020 20:29:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 8921 Ep: 0.82 masked_t 1.725 masked_v 0.224 NSP 0.089 lr 2.42074e-05
10/29/2020 20:29:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 8941 Ep: 0.82 masked_t 1.636 masked_v 0.221 NSP 0.103 lr 2.41869e-05
10/29/2020 20:30:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 8961 Ep: 0.83 masked_t 1.757 masked_v 0.223 NSP 0.097 lr 2.41664e-05
10/29/2020 20:30:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 8981 Ep: 0.83 masked_t 1.652 masked_v 0.217 NSP 0.082 lr 2.41459e-05
10/29/2020 20:30:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 9001 Ep: 0.83 masked_t 1.675 masked_v 0.223 NSP 0.094 lr 2.41254e-05
10/29/2020 20:31:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 9021 Ep: 0.83 masked_t 1.680 masked_v 0.225 NSP 0.094 lr 2.4105e-05
10/29/2020 20:31:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 9041 Ep: 0.83 masked_t 1.732 masked_v 0.226 NSP 0.096 lr 2.40845e-05
10/29/2020 20:31:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 9061 Ep: 0.84 masked_t 1.722 masked_v 0.221 NSP 0.094 lr 2.4064e-05
10/29/2020 20:32:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 9081 Ep: 0.84 masked_t 1.692 masked_v 0.216 NSP 0.095 lr 2.40435e-05
10/29/2020 20:32:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 9101 Ep: 0.84 masked_t 1.648 masked_v 0.221 NSP 0.091 lr 2.4023e-05
10/29/2020 20:32:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 9121 Ep: 0.84 masked_t 1.703 masked_v 0.216 NSP 0.090 lr 2.40026e-05
10/29/2020 20:33:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 9141 Ep: 0.84 masked_t 1.676 masked_v 0.231 NSP 0.098 lr 2.39821e-05
10/29/2020 20:33:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 9161 Ep: 0.84 masked_t 1.707 masked_v 0.222 NSP 0.091 lr 2.39616e-05
10/29/2020 20:34:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 9181 Ep: 0.85 masked_t 1.696 masked_v 0.223 NSP 0.096 lr 2.39411e-05
10/29/2020 20:34:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 9201 Ep: 0.85 masked_t 1.679 masked_v 0.222 NSP 0.092 lr 2.39206e-05
10/29/2020 20:34:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 9221 Ep: 0.85 masked_t 1.687 masked_v 0.222 NSP 0.100 lr 2.39002e-05
10/29/2020 20:35:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 9241 Ep: 0.85 masked_t 1.710 masked_v 0.224 NSP 0.083 lr 2.38797e-05
10/29/2020 20:35:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 9261 Ep: 0.85 masked_t 1.699 masked_v 0.219 NSP 0.096 lr 2.38592e-05
10/29/2020 20:35:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 9281 Ep: 0.86 masked_t 1.724 masked_v 0.222 NSP 0.090 lr 2.38387e-05
10/29/2020 20:36:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 9301 Ep: 0.86 masked_t 1.790 masked_v 0.223 NSP 0.094 lr 2.38182e-05
10/29/2020 20:36:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 9321 Ep: 0.86 masked_t 1.720 masked_v 0.216 NSP 0.089 lr 2.37977e-05
10/29/2020 20:36:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 9341 Ep: 0.86 masked_t 1.709 masked_v 0.219 NSP 0.091 lr 2.37773e-05
10/29/2020 20:37:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 9361 Ep: 0.86 masked_t 1.648 masked_v 0.216 NSP 0.094 lr 2.37568e-05
10/29/2020 20:37:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 9381 Ep: 0.86 masked_t 1.669 masked_v 0.221 NSP 0.086 lr 2.37363e-05
10/29/2020 20:37:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 9401 Ep: 0.87 masked_t 1.715 masked_v 0.219 NSP 0.084 lr 2.37158e-05
10/29/2020 20:38:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 9421 Ep: 0.87 masked_t 1.767 masked_v 0.225 NSP 0.097 lr 2.36953e-05
10/29/2020 20:38:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 9441 Ep: 0.87 masked_t 1.779 masked_v 0.226 NSP 0.088 lr 2.36749e-05
10/29/2020 20:38:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 9461 Ep: 0.87 masked_t 1.660 masked_v 0.220 NSP 0.084 lr 2.36544e-05
10/29/2020 20:39:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 9481 Ep: 0.87 masked_t 1.685 masked_v 0.225 NSP 0.088 lr 2.36339e-05
10/29/2020 20:39:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 9501 Ep: 0.88 masked_t 1.685 masked_v 0.223 NSP 0.094 lr 2.36134e-05
10/29/2020 20:39:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 9521 Ep: 0.88 masked_t 1.659 masked_v 0.220 NSP 0.092 lr 2.35929e-05
10/29/2020 20:40:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 9541 Ep: 0.88 masked_t 1.651 masked_v 0.220 NSP 0.093 lr 2.35725e-05
10/29/2020 20:40:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 9561 Ep: 0.88 masked_t 1.701 masked_v 0.216 NSP 0.081 lr 2.3552e-05
10/29/2020 20:41:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 9581 Ep: 0.88 masked_t 1.690 masked_v 0.221 NSP 0.083 lr 2.35315e-05
10/29/2020 20:41:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 9601 Ep: 0.88 masked_t 1.667 masked_v 0.224 NSP 0.092 lr 2.3511e-05
10/29/2020 20:41:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 9621 Ep: 0.89 masked_t 1.740 masked_v 0.217 NSP 0.077 lr 2.34905e-05
10/29/2020 20:42:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 9641 Ep: 0.89 masked_t 1.692 masked_v 0.223 NSP 0.089 lr 2.347e-05
10/29/2020 20:42:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 9661 Ep: 0.89 masked_t 1.684 masked_v 0.217 NSP 0.089 lr 2.34496e-05
10/29/2020 20:42:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 9681 Ep: 0.89 masked_t 1.676 masked_v 0.223 NSP 0.084 lr 2.34291e-05
10/29/2020 20:43:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 9701 Ep: 0.89 masked_t 1.687 masked_v 0.224 NSP 0.084 lr 2.34086e-05
10/29/2020 20:43:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 9721 Ep: 0.90 masked_t 1.619 masked_v 0.223 NSP 0.082 lr 2.33881e-05
10/29/2020 20:43:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 9741 Ep: 0.90 masked_t 1.709 masked_v 0.216 NSP 0.093 lr 2.33676e-05
10/29/2020 20:44:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 9761 Ep: 0.90 masked_t 1.594 masked_v 0.213 NSP 0.082 lr 2.33472e-05
10/29/2020 20:44:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 9781 Ep: 0.90 masked_t 1.610 masked_v 0.223 NSP 0.082 lr 2.33267e-05
10/29/2020 20:45:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 9801 Ep: 0.90 masked_t 1.614 masked_v 0.221 NSP 0.092 lr 2.33062e-05
10/29/2020 20:45:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 9821 Ep: 0.91 masked_t 1.633 masked_v 0.218 NSP 0.088 lr 2.32857e-05
10/29/2020 20:45:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 9841 Ep: 0.91 masked_t 1.635 masked_v 0.221 NSP 0.088 lr 2.32652e-05
10/29/2020 20:46:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 9861 Ep: 0.91 masked_t 1.652 masked_v 0.221 NSP 0.085 lr 2.32448e-05
10/29/2020 20:46:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 9881 Ep: 0.91 masked_t 1.657 masked_v 0.219 NSP 0.095 lr 2.32243e-05
10/29/2020 20:46:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 9901 Ep: 0.91 masked_t 1.666 masked_v 0.218 NSP 0.081 lr 2.32038e-05
10/29/2020 20:47:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 9921 Ep: 0.91 masked_t 1.740 masked_v 0.222 NSP 0.093 lr 2.31833e-05
10/29/2020 20:47:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 9941 Ep: 0.92 masked_t 1.712 masked_v 0.220 NSP 0.084 lr 2.31628e-05
10/29/2020 20:48:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 9961 Ep: 0.92 masked_t 1.645 masked_v 0.223 NSP 0.080 lr 2.31423e-05
10/29/2020 20:48:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 9981 Ep: 0.92 masked_t 1.747 masked_v 0.224 NSP 0.085 lr 2.31219e-05
10/29/2020 20:48:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 10001 Ep: 0.92 masked_t 1.676 masked_v 0.218 NSP 0.083 lr 2.31014e-05
10/29/2020 20:49:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 10021 Ep: 0.92 masked_t 1.671 masked_v 0.224 NSP 0.083 lr 2.30809e-05
10/29/2020 20:49:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 10041 Ep: 0.93 masked_t 1.688 masked_v 0.220 NSP 0.084 lr 2.30604e-05
10/29/2020 20:49:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 10061 Ep: 0.93 masked_t 1.599 masked_v 0.223 NSP 0.089 lr 2.30399e-05
10/29/2020 20:50:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 10081 Ep: 0.93 masked_t 1.661 masked_v 0.210 NSP 0.088 lr 2.30195e-05
10/29/2020 20:50:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 10101 Ep: 0.93 masked_t 1.645 masked_v 0.223 NSP 0.092 lr 2.2999e-05
10/29/2020 20:51:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 10121 Ep: 0.93 masked_t 1.748 masked_v 0.220 NSP 0.090 lr 2.29785e-05
10/29/2020 20:51:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 10141 Ep: 0.93 masked_t 1.571 masked_v 0.220 NSP 0.085 lr 2.2958e-05
10/29/2020 20:51:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 10161 Ep: 0.94 masked_t 1.726 masked_v 0.219 NSP 0.092 lr 2.29375e-05
10/29/2020 20:52:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 10181 Ep: 0.94 masked_t 1.722 masked_v 0.223 NSP 0.087 lr 2.29171e-05
10/29/2020 20:52:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 10201 Ep: 0.94 masked_t 1.657 masked_v 0.219 NSP 0.095 lr 2.28966e-05
10/29/2020 20:53:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 10221 Ep: 0.94 masked_t 1.699 masked_v 0.221 NSP 0.102 lr 2.28761e-05
10/29/2020 20:53:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 10241 Ep: 0.94 masked_t 1.616 masked_v 0.223 NSP 0.088 lr 2.28556e-05
10/29/2020 20:53:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 10261 Ep: 0.95 masked_t 1.639 masked_v 0.223 NSP 0.086 lr 2.28351e-05
10/29/2020 20:54:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 10281 Ep: 0.95 masked_t 1.724 masked_v 0.220 NSP 0.090 lr 2.28146e-05
10/29/2020 20:54:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 10301 Ep: 0.95 masked_t 1.665 masked_v 0.212 NSP 0.084 lr 2.27942e-05
10/29/2020 20:55:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 10321 Ep: 0.95 masked_t 1.700 masked_v 0.220 NSP 0.094 lr 2.27737e-05
10/29/2020 20:55:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 10341 Ep: 0.95 masked_t 1.637 masked_v 0.221 NSP 0.088 lr 2.27532e-05
10/29/2020 20:55:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 10361 Ep: 0.95 masked_t 1.669 masked_v 0.225 NSP 0.094 lr 2.27327e-05
10/29/2020 20:56:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 10381 Ep: 0.96 masked_t 1.674 masked_v 0.217 NSP 0.091 lr 2.27122e-05
10/29/2020 20:56:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 10401 Ep: 0.96 masked_t 1.713 masked_v 0.220 NSP 0.094 lr 2.26918e-05
10/29/2020 20:56:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 10421 Ep: 0.96 masked_t 1.654 masked_v 0.220 NSP 0.085 lr 2.26713e-05
10/29/2020 20:57:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 10441 Ep: 0.96 masked_t 1.682 masked_v 0.220 NSP 0.091 lr 2.26508e-05
10/29/2020 20:57:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 10461 Ep: 0.96 masked_t 1.647 masked_v 0.219 NSP 0.090 lr 2.26303e-05
10/29/2020 20:58:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 10481 Ep: 0.97 masked_t 1.704 masked_v 0.217 NSP 0.087 lr 2.26098e-05
10/29/2020 20:58:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 10501 Ep: 0.97 masked_t 1.712 masked_v 0.218 NSP 0.086 lr 2.25893e-05
10/29/2020 20:58:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 10521 Ep: 0.97 masked_t 1.706 masked_v 0.216 NSP 0.079 lr 2.25689e-05
10/29/2020 20:59:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 10541 Ep: 0.97 masked_t 1.682 masked_v 0.224 NSP 0.097 lr 2.25484e-05
10/29/2020 20:59:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 10561 Ep: 0.97 masked_t 1.672 masked_v 0.222 NSP 0.087 lr 2.25279e-05
10/29/2020 21:00:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 10581 Ep: 0.98 masked_t 1.677 masked_v 0.222 NSP 0.082 lr 2.25074e-05
10/29/2020 21:00:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 10601 Ep: 0.98 masked_t 1.729 masked_v 0.220 NSP 0.089 lr 2.24869e-05
10/29/2020 21:00:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 10621 Ep: 0.98 masked_t 1.629 masked_v 0.221 NSP 0.082 lr 2.24665e-05
10/29/2020 21:01:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 10641 Ep: 0.98 masked_t 1.658 masked_v 0.219 NSP 0.098 lr 2.2446e-05
10/29/2020 21:01:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 10661 Ep: 0.98 masked_t 1.614 masked_v 0.217 NSP 0.090 lr 2.24255e-05
10/29/2020 21:01:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 10681 Ep: 0.98 masked_t 1.676 masked_v 0.219 NSP 0.089 lr 2.2405e-05
10/29/2020 21:02:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 10701 Ep: 0.99 masked_t 1.634 masked_v 0.220 NSP 0.086 lr 2.23845e-05
10/29/2020 21:02:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 10721 Ep: 0.99 masked_t 1.642 masked_v 0.216 NSP 0.086 lr 2.23641e-05
10/29/2020 21:03:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 10741 Ep: 0.99 masked_t 1.736 masked_v 0.226 NSP 0.090 lr 2.23436e-05
10/29/2020 21:03:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 10761 Ep: 0.99 masked_t 1.604 masked_v 0.218 NSP 0.091 lr 2.23231e-05
10/29/2020 21:03:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 10781 Ep: 0.99 masked_t 1.716 masked_v 0.217 NSP 0.085 lr 2.23026e-05
10/29/2020 21:04:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 10801 Ep: 1.00 masked_t 1.687 masked_v 0.221 NSP 0.097 lr 2.22821e-05
10/29/2020 21:04:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 10821 Ep: 1.00 masked_t 1.687 masked_v 0.214 NSP 0.091 lr 2.22616e-05
10/29/2020 21:05:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 10841 Ep: 1.00 masked_t 1.618 masked_v 0.219 NSP 0.088 lr 2.22412e-05
10/29/2020 21:05:54 - INFO - volta.utils -   Validation [Conceptual_Caption]: masked_t 2.248 masked_v 0.202 NSP 0.115
10/29/2020 21:05:54 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 
10/29/2020 21:06:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 10871 Ep: 1.00 masked_t 1.658 masked_v 0.219 NSP 0.089 lr 2.22156e-05
10/29/2020 21:07:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 10891 Ep: 1.00 masked_t 1.701 masked_v 0.217 NSP 0.100 lr 2.219e-05
10/29/2020 21:07:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 10911 Ep: 1.01 masked_t 1.604 masked_v 0.220 NSP 0.098 lr 2.21695e-05
10/29/2020 21:07:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 10931 Ep: 1.01 masked_t 1.697 masked_v 0.218 NSP 0.089 lr 2.2149e-05
10/29/2020 21:08:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 10951 Ep: 1.01 masked_t 1.717 masked_v 0.214 NSP 0.083 lr 2.21285e-05
10/29/2020 21:08:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 10971 Ep: 1.01 masked_t 1.673 masked_v 0.220 NSP 0.093 lr 2.2108e-05
10/29/2020 21:08:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 10991 Ep: 1.01 masked_t 1.582 masked_v 0.219 NSP 0.090 lr 2.20876e-05
10/29/2020 21:09:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 11011 Ep: 1.01 masked_t 1.714 masked_v 0.213 NSP 0.086 lr 2.20671e-05
10/29/2020 21:09:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 11031 Ep: 1.02 masked_t 1.754 masked_v 0.221 NSP 0.093 lr 2.20466e-05
10/29/2020 21:09:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 11051 Ep: 1.02 masked_t 1.563 masked_v 0.218 NSP 0.096 lr 2.20261e-05
10/29/2020 21:10:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 11071 Ep: 1.02 masked_t 1.760 masked_v 0.214 NSP 0.101 lr 2.20056e-05
10/29/2020 21:10:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 11091 Ep: 1.02 masked_t 1.733 masked_v 0.218 NSP 0.096 lr 2.19852e-05
10/29/2020 21:10:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 11111 Ep: 1.02 masked_t 1.644 masked_v 0.224 NSP 0.088 lr 2.19647e-05
10/29/2020 21:11:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 11131 Ep: 1.03 masked_t 1.668 masked_v 0.219 NSP 0.096 lr 2.19442e-05
10/29/2020 21:11:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 11151 Ep: 1.03 masked_t 1.717 masked_v 0.219 NSP 0.084 lr 2.19237e-05
10/29/2020 21:11:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 11171 Ep: 1.03 masked_t 1.668 masked_v 0.220 NSP 0.097 lr 2.19032e-05
10/29/2020 21:12:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 11191 Ep: 1.03 masked_t 1.676 masked_v 0.218 NSP 0.080 lr 2.18827e-05
10/29/2020 21:12:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 11211 Ep: 1.03 masked_t 1.700 masked_v 0.216 NSP 0.087 lr 2.18623e-05
10/29/2020 21:12:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 11231 Ep: 1.04 masked_t 1.630 masked_v 0.217 NSP 0.091 lr 2.18418e-05
10/29/2020 21:13:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 11251 Ep: 1.04 masked_t 1.700 masked_v 0.217 NSP 0.098 lr 2.18213e-05
10/29/2020 21:13:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 11271 Ep: 1.04 masked_t 1.665 masked_v 0.218 NSP 0.084 lr 2.18008e-05
10/29/2020 21:13:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 11291 Ep: 1.04 masked_t 1.576 masked_v 0.222 NSP 0.086 lr 2.17803e-05
10/29/2020 21:14:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 11311 Ep: 1.04 masked_t 1.639 masked_v 0.224 NSP 0.093 lr 2.17599e-05
10/29/2020 21:14:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 11331 Ep: 1.04 masked_t 1.635 masked_v 0.226 NSP 0.099 lr 2.17394e-05
10/29/2020 21:15:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 11351 Ep: 1.05 masked_t 1.720 masked_v 0.220 NSP 0.095 lr 2.17189e-05
10/29/2020 21:15:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 11371 Ep: 1.05 masked_t 1.674 masked_v 0.226 NSP 0.091 lr 2.16984e-05
10/29/2020 21:15:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 11391 Ep: 1.05 masked_t 1.685 masked_v 0.215 NSP 0.089 lr 2.16779e-05
10/29/2020 21:16:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 11411 Ep: 1.05 masked_t 1.622 masked_v 0.223 NSP 0.093 lr 2.16575e-05
10/29/2020 21:16:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 11431 Ep: 1.05 masked_t 1.579 masked_v 0.213 NSP 0.084 lr 2.1637e-05
10/29/2020 21:16:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 11451 Ep: 1.06 masked_t 1.658 masked_v 0.220 NSP 0.091 lr 2.16165e-05
10/29/2020 21:17:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 11471 Ep: 1.06 masked_t 1.676 masked_v 0.220 NSP 0.087 lr 2.1596e-05
10/29/2020 21:17:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 11491 Ep: 1.06 masked_t 1.688 masked_v 0.222 NSP 0.090 lr 2.15755e-05
10/29/2020 21:17:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 11511 Ep: 1.06 masked_t 1.687 masked_v 0.219 NSP 0.104 lr 2.1555e-05
10/29/2020 21:18:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 11531 Ep: 1.06 masked_t 1.650 masked_v 0.226 NSP 0.085 lr 2.15346e-05
10/29/2020 21:18:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 11551 Ep: 1.06 masked_t 1.699 masked_v 0.212 NSP 0.087 lr 2.15141e-05
10/29/2020 21:19:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 11571 Ep: 1.07 masked_t 1.747 masked_v 0.221 NSP 0.085 lr 2.14936e-05
10/29/2020 21:19:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 11591 Ep: 1.07 masked_t 1.725 masked_v 0.221 NSP 0.098 lr 2.14731e-05
10/29/2020 21:19:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 11611 Ep: 1.07 masked_t 1.635 masked_v 0.212 NSP 0.085 lr 2.14526e-05
10/29/2020 21:20:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 11631 Ep: 1.07 masked_t 1.692 masked_v 0.227 NSP 0.090 lr 2.14322e-05
10/29/2020 21:20:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 11651 Ep: 1.07 masked_t 1.678 masked_v 0.224 NSP 0.094 lr 2.14117e-05
10/29/2020 21:20:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 11671 Ep: 1.08 masked_t 1.675 masked_v 0.222 NSP 0.092 lr 2.13912e-05
10/29/2020 21:21:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 11691 Ep: 1.08 masked_t 1.707 masked_v 0.217 NSP 0.101 lr 2.13707e-05
10/29/2020 21:21:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 11711 Ep: 1.08 masked_t 1.689 masked_v 0.218 NSP 0.089 lr 2.13502e-05
10/29/2020 21:22:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 11731 Ep: 1.08 masked_t 1.691 masked_v 0.218 NSP 0.094 lr 2.13297e-05
10/29/2020 21:22:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 11751 Ep: 1.08 masked_t 1.594 masked_v 0.218 NSP 0.094 lr 2.13093e-05
10/29/2020 21:22:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 11771 Ep: 1.08 masked_t 1.774 masked_v 0.221 NSP 0.084 lr 2.12888e-05
10/29/2020 21:23:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 11791 Ep: 1.09 masked_t 1.714 masked_v 0.224 NSP 0.093 lr 2.12683e-05
10/29/2020 21:23:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 11811 Ep: 1.09 masked_t 1.637 masked_v 0.215 NSP 0.094 lr 2.12478e-05
10/29/2020 21:24:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 11831 Ep: 1.09 masked_t 1.637 masked_v 0.222 NSP 0.089 lr 2.12273e-05
10/29/2020 21:24:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 11851 Ep: 1.09 masked_t 1.659 masked_v 0.216 NSP 0.090 lr 2.12069e-05
10/29/2020 21:24:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 11871 Ep: 1.09 masked_t 1.672 masked_v 0.217 NSP 0.094 lr 2.11864e-05
10/29/2020 21:25:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 11891 Ep: 1.10 masked_t 1.607 masked_v 0.217 NSP 0.104 lr 2.11659e-05
10/29/2020 21:25:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 11911 Ep: 1.10 masked_t 1.604 masked_v 0.216 NSP 0.093 lr 2.11454e-05
10/29/2020 21:26:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 11931 Ep: 1.10 masked_t 1.639 masked_v 0.216 NSP 0.092 lr 2.11249e-05
10/29/2020 21:26:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 11951 Ep: 1.10 masked_t 1.730 masked_v 0.221 NSP 0.095 lr 2.11045e-05
10/29/2020 21:26:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 11971 Ep: 1.10 masked_t 1.734 masked_v 0.215 NSP 0.088 lr 2.1084e-05
10/29/2020 21:27:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 11991 Ep: 1.11 masked_t 1.682 masked_v 0.217 NSP 0.089 lr 2.10635e-05
10/29/2020 21:27:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 12011 Ep: 1.11 masked_t 1.590 masked_v 0.216 NSP 0.087 lr 2.1043e-05
10/29/2020 21:27:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 12031 Ep: 1.11 masked_t 1.647 masked_v 0.226 NSP 0.083 lr 2.10225e-05
10/29/2020 21:28:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 12051 Ep: 1.11 masked_t 1.695 masked_v 0.216 NSP 0.087 lr 2.1002e-05
10/29/2020 21:28:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 12071 Ep: 1.11 masked_t 1.603 masked_v 0.216 NSP 0.089 lr 2.09816e-05
10/29/2020 21:29:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 12091 Ep: 1.11 masked_t 1.638 masked_v 0.217 NSP 0.079 lr 2.09611e-05
10/29/2020 21:29:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 12111 Ep: 1.12 masked_t 1.624 masked_v 0.216 NSP 0.088 lr 2.09406e-05
10/29/2020 21:29:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 12131 Ep: 1.12 masked_t 1.574 masked_v 0.212 NSP 0.079 lr 2.09201e-05
10/29/2020 21:30:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 12151 Ep: 1.12 masked_t 1.684 masked_v 0.216 NSP 0.090 lr 2.08996e-05
10/29/2020 21:30:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 12171 Ep: 1.12 masked_t 1.595 masked_v 0.218 NSP 0.089 lr 2.08792e-05
10/29/2020 21:31:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 12191 Ep: 1.12 masked_t 1.718 masked_v 0.223 NSP 0.091 lr 2.08587e-05
10/29/2020 21:31:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 12211 Ep: 1.13 masked_t 1.718 masked_v 0.219 NSP 0.089 lr 2.08382e-05
10/29/2020 21:31:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 12231 Ep: 1.13 masked_t 1.763 masked_v 0.224 NSP 0.095 lr 2.08177e-05
10/29/2020 21:32:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 12251 Ep: 1.13 masked_t 1.631 masked_v 0.218 NSP 0.089 lr 2.07972e-05
10/29/2020 21:32:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 12271 Ep: 1.13 masked_t 1.719 masked_v 0.220 NSP 0.083 lr 2.07768e-05
10/29/2020 21:33:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 12291 Ep: 1.13 masked_t 1.673 masked_v 0.216 NSP 0.097 lr 2.07563e-05
10/29/2020 21:33:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 12311 Ep: 1.13 masked_t 1.676 masked_v 0.220 NSP 0.083 lr 2.07358e-05
10/29/2020 21:33:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 12331 Ep: 1.14 masked_t 1.636 masked_v 0.215 NSP 0.082 lr 2.07153e-05
10/29/2020 21:34:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 12351 Ep: 1.14 masked_t 1.727 masked_v 0.215 NSP 0.087 lr 2.06948e-05
10/29/2020 21:34:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 12371 Ep: 1.14 masked_t 1.693 masked_v 0.216 NSP 0.090 lr 2.06743e-05
10/29/2020 21:35:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 12391 Ep: 1.14 masked_t 1.637 masked_v 0.221 NSP 0.086 lr 2.06539e-05
10/29/2020 21:35:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 12411 Ep: 1.14 masked_t 1.657 masked_v 0.219 NSP 0.092 lr 2.06334e-05
10/29/2020 21:35:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 12431 Ep: 1.15 masked_t 1.647 masked_v 0.212 NSP 0.092 lr 2.06129e-05
10/29/2020 21:36:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 12451 Ep: 1.15 masked_t 1.611 masked_v 0.217 NSP 0.085 lr 2.05924e-05
10/29/2020 21:36:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 12471 Ep: 1.15 masked_t 1.648 masked_v 0.223 NSP 0.092 lr 2.05719e-05
10/29/2020 21:37:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 12491 Ep: 1.15 masked_t 1.673 masked_v 0.218 NSP 0.082 lr 2.05515e-05
10/29/2020 21:37:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 12511 Ep: 1.15 masked_t 1.626 masked_v 0.210 NSP 0.094 lr 2.0531e-05
10/29/2020 21:37:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 12531 Ep: 1.15 masked_t 1.633 masked_v 0.222 NSP 0.079 lr 2.05105e-05
10/29/2020 21:38:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 12551 Ep: 1.16 masked_t 1.703 masked_v 0.217 NSP 0.080 lr 2.049e-05
10/29/2020 21:38:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 12571 Ep: 1.16 masked_t 1.620 masked_v 0.223 NSP 0.083 lr 2.04695e-05
10/29/2020 21:39:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 12591 Ep: 1.16 masked_t 1.586 masked_v 0.220 NSP 0.101 lr 2.04491e-05
10/29/2020 21:39:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 12611 Ep: 1.16 masked_t 1.669 masked_v 0.222 NSP 0.091 lr 2.04286e-05
10/29/2020 21:39:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 12631 Ep: 1.16 masked_t 1.724 masked_v 0.216 NSP 0.078 lr 2.04081e-05
10/29/2020 21:40:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 12651 Ep: 1.17 masked_t 1.700 masked_v 0.215 NSP 0.094 lr 2.03876e-05
10/29/2020 21:40:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 12671 Ep: 1.17 masked_t 1.602 masked_v 0.225 NSP 0.100 lr 2.03671e-05
10/29/2020 21:41:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 12691 Ep: 1.17 masked_t 1.632 masked_v 0.211 NSP 0.080 lr 2.03466e-05
10/29/2020 21:41:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 12711 Ep: 1.17 masked_t 1.655 masked_v 0.216 NSP 0.087 lr 2.03262e-05
10/29/2020 21:41:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 12731 Ep: 1.17 masked_t 1.576 masked_v 0.221 NSP 0.103 lr 2.03057e-05
10/29/2020 21:42:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 12751 Ep: 1.18 masked_t 1.565 masked_v 0.218 NSP 0.092 lr 2.02852e-05
10/29/2020 21:42:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 12771 Ep: 1.18 masked_t 1.714 masked_v 0.221 NSP 0.097 lr 2.02647e-05
10/29/2020 21:43:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 12791 Ep: 1.18 masked_t 1.640 masked_v 0.219 NSP 0.089 lr 2.02442e-05
10/29/2020 21:43:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 12811 Ep: 1.18 masked_t 1.623 masked_v 0.212 NSP 0.087 lr 2.02238e-05
10/29/2020 21:43:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 12831 Ep: 1.18 masked_t 1.675 masked_v 0.216 NSP 0.086 lr 2.02033e-05
10/29/2020 21:44:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 12851 Ep: 1.18 masked_t 1.653 masked_v 0.216 NSP 0.086 lr 2.01828e-05
10/29/2020 21:44:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 12871 Ep: 1.19 masked_t 1.624 masked_v 0.209 NSP 0.092 lr 2.01623e-05
10/29/2020 21:45:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 12891 Ep: 1.19 masked_t 1.654 masked_v 0.218 NSP 0.083 lr 2.01418e-05
10/29/2020 21:45:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 12911 Ep: 1.19 masked_t 1.667 masked_v 0.217 NSP 0.097 lr 2.01214e-05
10/29/2020 21:45:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 12931 Ep: 1.19 masked_t 1.641 masked_v 0.222 NSP 0.101 lr 2.01009e-05
10/29/2020 21:46:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 12951 Ep: 1.19 masked_t 1.555 masked_v 0.215 NSP 0.083 lr 2.00804e-05
10/29/2020 21:46:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 12971 Ep: 1.20 masked_t 1.693 masked_v 0.220 NSP 0.084 lr 2.00599e-05
10/29/2020 21:46:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 12991 Ep: 1.20 masked_t 1.639 masked_v 0.213 NSP 0.085 lr 2.00394e-05
10/29/2020 21:47:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 13011 Ep: 1.20 masked_t 1.642 masked_v 0.211 NSP 0.094 lr 2.00189e-05
10/29/2020 21:47:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 13031 Ep: 1.20 masked_t 1.560 masked_v 0.222 NSP 0.080 lr 1.99985e-05
10/29/2020 21:47:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 13051 Ep: 1.20 masked_t 1.609 masked_v 0.220 NSP 0.090 lr 1.9978e-05
10/29/2020 21:48:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 13071 Ep: 1.20 masked_t 1.639 masked_v 0.216 NSP 0.079 lr 1.99575e-05
10/29/2020 21:48:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 13091 Ep: 1.21 masked_t 1.573 masked_v 0.220 NSP 0.075 lr 1.9937e-05
10/29/2020 21:49:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 13111 Ep: 1.21 masked_t 1.535 masked_v 0.219 NSP 0.098 lr 1.99165e-05
10/29/2020 21:49:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 13131 Ep: 1.21 masked_t 1.727 masked_v 0.217 NSP 0.086 lr 1.98961e-05
10/29/2020 21:49:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 13151 Ep: 1.21 masked_t 1.652 masked_v 0.215 NSP 0.088 lr 1.98756e-05
10/29/2020 21:50:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 13171 Ep: 1.21 masked_t 1.658 masked_v 0.219 NSP 0.098 lr 1.98551e-05
10/29/2020 21:50:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 13191 Ep: 1.22 masked_t 1.673 masked_v 0.222 NSP 0.091 lr 1.98346e-05
10/29/2020 21:50:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 13211 Ep: 1.22 masked_t 1.643 masked_v 0.211 NSP 0.101 lr 1.98141e-05
10/29/2020 21:51:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 13231 Ep: 1.22 masked_t 1.625 masked_v 0.211 NSP 0.090 lr 1.97937e-05
10/29/2020 21:51:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 13251 Ep: 1.22 masked_t 1.580 masked_v 0.222 NSP 0.083 lr 1.97732e-05
10/29/2020 21:51:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 13271 Ep: 1.22 masked_t 1.594 masked_v 0.217 NSP 0.086 lr 1.97527e-05
10/29/2020 21:52:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 13291 Ep: 1.22 masked_t 1.623 masked_v 0.215 NSP 0.087 lr 1.97322e-05
10/29/2020 21:52:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 13311 Ep: 1.23 masked_t 1.591 masked_v 0.218 NSP 0.089 lr 1.97117e-05
10/29/2020 21:52:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 13331 Ep: 1.23 masked_t 1.681 masked_v 0.217 NSP 0.082 lr 1.96912e-05
10/29/2020 21:53:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 13351 Ep: 1.23 masked_t 1.658 masked_v 0.214 NSP 0.100 lr 1.96708e-05
10/29/2020 21:53:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 13371 Ep: 1.23 masked_t 1.610 masked_v 0.221 NSP 0.087 lr 1.96503e-05
10/29/2020 21:53:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 13391 Ep: 1.23 masked_t 1.671 masked_v 0.216 NSP 0.082 lr 1.96298e-05
10/29/2020 21:54:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 13411 Ep: 1.24 masked_t 1.589 masked_v 0.215 NSP 0.096 lr 1.96093e-05
10/29/2020 21:54:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 13431 Ep: 1.24 masked_t 1.652 masked_v 0.221 NSP 0.094 lr 1.95888e-05
10/29/2020 21:54:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 13451 Ep: 1.24 masked_t 1.634 masked_v 0.218 NSP 0.083 lr 1.95684e-05
10/29/2020 21:55:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 13471 Ep: 1.24 masked_t 1.759 masked_v 0.217 NSP 0.085 lr 1.95479e-05
10/29/2020 21:55:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 13491 Ep: 1.24 masked_t 1.605 masked_v 0.217 NSP 0.086 lr 1.95274e-05
10/29/2020 21:56:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 13511 Ep: 1.25 masked_t 1.689 masked_v 0.221 NSP 0.092 lr 1.95069e-05
10/29/2020 21:56:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 13531 Ep: 1.25 masked_t 1.686 masked_v 0.217 NSP 0.090 lr 1.94864e-05
10/29/2020 21:56:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 13551 Ep: 1.25 masked_t 1.660 masked_v 0.213 NSP 0.084 lr 1.94659e-05
10/29/2020 21:57:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 13571 Ep: 1.25 masked_t 1.686 masked_v 0.222 NSP 0.088 lr 1.94455e-05
10/29/2020 21:57:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 13591 Ep: 1.25 masked_t 1.661 masked_v 0.219 NSP 0.088 lr 1.9425e-05
10/29/2020 21:57:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 13611 Ep: 1.25 masked_t 1.666 masked_v 0.215 NSP 0.085 lr 1.94045e-05
10/29/2020 21:58:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 13631 Ep: 1.26 masked_t 1.629 masked_v 0.213 NSP 0.102 lr 1.9384e-05
10/29/2020 21:58:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 13651 Ep: 1.26 masked_t 1.683 masked_v 0.219 NSP 0.086 lr 1.93635e-05
10/29/2020 21:58:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 13671 Ep: 1.26 masked_t 1.593 masked_v 0.222 NSP 0.088 lr 1.93431e-05
10/29/2020 21:59:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 13691 Ep: 1.26 masked_t 1.659 masked_v 0.214 NSP 0.084 lr 1.93226e-05
10/29/2020 21:59:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 13711 Ep: 1.26 masked_t 1.718 masked_v 0.212 NSP 0.095 lr 1.93021e-05
10/29/2020 21:59:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 13731 Ep: 1.27 masked_t 1.652 masked_v 0.217 NSP 0.084 lr 1.92816e-05
10/29/2020 22:00:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 13751 Ep: 1.27 masked_t 1.600 masked_v 0.219 NSP 0.079 lr 1.92611e-05
10/29/2020 22:00:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 13771 Ep: 1.27 masked_t 1.587 masked_v 0.212 NSP 0.078 lr 1.92407e-05
10/29/2020 22:00:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 13791 Ep: 1.27 masked_t 1.623 masked_v 0.215 NSP 0.084 lr 1.92202e-05
10/29/2020 22:01:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 13811 Ep: 1.27 masked_t 1.730 masked_v 0.215 NSP 0.083 lr 1.91997e-05
10/29/2020 22:01:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 13831 Ep: 1.27 masked_t 1.635 masked_v 0.215 NSP 0.079 lr 1.91792e-05
10/29/2020 22:01:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 13851 Ep: 1.28 masked_t 1.675 masked_v 0.216 NSP 0.091 lr 1.91587e-05
10/29/2020 22:02:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 13871 Ep: 1.28 masked_t 1.702 masked_v 0.224 NSP 0.094 lr 1.91382e-05
10/29/2020 22:02:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 13891 Ep: 1.28 masked_t 1.619 masked_v 0.212 NSP 0.093 lr 1.91178e-05
10/29/2020 22:03:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 13911 Ep: 1.28 masked_t 1.608 masked_v 0.215 NSP 0.094 lr 1.90973e-05
10/29/2020 22:03:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 13931 Ep: 1.28 masked_t 1.687 masked_v 0.215 NSP 0.093 lr 1.90768e-05
10/29/2020 22:03:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 13951 Ep: 1.29 masked_t 1.526 masked_v 0.217 NSP 0.093 lr 1.90563e-05
10/29/2020 22:04:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 13971 Ep: 1.29 masked_t 1.709 masked_v 0.216 NSP 0.094 lr 1.90358e-05
10/29/2020 22:04:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 13991 Ep: 1.29 masked_t 1.674 masked_v 0.214 NSP 0.093 lr 1.90154e-05
10/29/2020 22:04:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 14011 Ep: 1.29 masked_t 1.592 masked_v 0.208 NSP 0.088 lr 1.89949e-05
10/29/2020 22:05:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 14031 Ep: 1.29 masked_t 1.685 masked_v 0.223 NSP 0.078 lr 1.89744e-05
10/29/2020 22:05:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 14051 Ep: 1.30 masked_t 1.638 masked_v 0.217 NSP 0.086 lr 1.89539e-05
10/29/2020 22:05:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 14071 Ep: 1.30 masked_t 1.614 masked_v 0.215 NSP 0.090 lr 1.89334e-05
10/29/2020 22:06:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 14091 Ep: 1.30 masked_t 1.655 masked_v 0.216 NSP 0.092 lr 1.8913e-05
10/29/2020 22:06:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 14111 Ep: 1.30 masked_t 1.663 masked_v 0.216 NSP 0.081 lr 1.88925e-05
10/29/2020 22:06:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 14131 Ep: 1.30 masked_t 1.553 masked_v 0.215 NSP 0.084 lr 1.8872e-05
10/29/2020 22:07:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 14151 Ep: 1.30 masked_t 1.590 masked_v 0.219 NSP 0.079 lr 1.88515e-05
10/29/2020 22:07:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 14171 Ep: 1.31 masked_t 1.661 masked_v 0.213 NSP 0.081 lr 1.8831e-05
10/29/2020 22:07:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 14191 Ep: 1.31 masked_t 1.755 masked_v 0.216 NSP 0.085 lr 1.88105e-05
10/29/2020 22:08:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 14211 Ep: 1.31 masked_t 1.667 masked_v 0.211 NSP 0.089 lr 1.87901e-05
10/29/2020 22:08:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 14231 Ep: 1.31 masked_t 1.605 masked_v 0.217 NSP 0.087 lr 1.87696e-05
10/29/2020 22:08:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 14251 Ep: 1.31 masked_t 1.701 masked_v 0.211 NSP 0.084 lr 1.87491e-05
10/29/2020 22:09:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 14271 Ep: 1.32 masked_t 1.606 masked_v 0.215 NSP 0.097 lr 1.87286e-05
10/29/2020 22:09:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 14291 Ep: 1.32 masked_t 1.668 masked_v 0.219 NSP 0.093 lr 1.87081e-05
10/29/2020 22:10:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 14311 Ep: 1.32 masked_t 1.653 masked_v 0.216 NSP 0.080 lr 1.86877e-05
10/29/2020 22:10:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 14331 Ep: 1.32 masked_t 1.702 masked_v 0.215 NSP 0.091 lr 1.86672e-05
10/29/2020 22:10:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 14351 Ep: 1.32 masked_t 1.625 masked_v 0.217 NSP 0.092 lr 1.86467e-05
10/29/2020 22:11:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 14371 Ep: 1.32 masked_t 1.672 masked_v 0.215 NSP 0.083 lr 1.86262e-05
10/29/2020 22:11:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 14391 Ep: 1.33 masked_t 1.602 masked_v 0.216 NSP 0.087 lr 1.86057e-05
10/29/2020 22:11:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 14411 Ep: 1.33 masked_t 1.715 masked_v 0.215 NSP 0.096 lr 1.85853e-05
10/29/2020 22:12:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 14431 Ep: 1.33 masked_t 1.673 masked_v 0.212 NSP 0.086 lr 1.85648e-05
10/29/2020 22:12:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 14451 Ep: 1.33 masked_t 1.699 masked_v 0.210 NSP 0.093 lr 1.85443e-05
10/29/2020 22:12:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 14471 Ep: 1.33 masked_t 1.630 masked_v 0.213 NSP 0.091 lr 1.85238e-05
10/29/2020 22:13:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 14491 Ep: 1.34 masked_t 1.641 masked_v 0.218 NSP 0.082 lr 1.85033e-05
10/29/2020 22:13:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 14511 Ep: 1.34 masked_t 1.664 masked_v 0.216 NSP 0.106 lr 1.84828e-05
10/29/2020 22:13:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 14531 Ep: 1.34 masked_t 1.560 masked_v 0.223 NSP 0.086 lr 1.84624e-05
10/29/2020 22:14:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 14551 Ep: 1.34 masked_t 1.668 masked_v 0.214 NSP 0.084 lr 1.84419e-05
10/29/2020 22:14:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 14571 Ep: 1.34 masked_t 1.633 masked_v 0.216 NSP 0.077 lr 1.84214e-05
10/29/2020 22:14:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 14591 Ep: 1.34 masked_t 1.607 masked_v 0.214 NSP 0.086 lr 1.84009e-05
10/29/2020 22:15:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 14611 Ep: 1.35 masked_t 1.642 masked_v 0.217 NSP 0.091 lr 1.83804e-05
10/29/2020 22:15:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 14631 Ep: 1.35 masked_t 1.689 masked_v 0.217 NSP 0.080 lr 1.836e-05
10/29/2020 22:15:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 14651 Ep: 1.35 masked_t 1.659 masked_v 0.214 NSP 0.101 lr 1.83395e-05
10/29/2020 22:16:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 14671 Ep: 1.35 masked_t 1.656 masked_v 0.215 NSP 0.077 lr 1.8319e-05
10/29/2020 22:16:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 14691 Ep: 1.35 masked_t 1.626 masked_v 0.212 NSP 0.087 lr 1.82985e-05
10/29/2020 22:17:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 14711 Ep: 1.36 masked_t 1.581 masked_v 0.220 NSP 0.088 lr 1.8278e-05
10/29/2020 22:17:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 14731 Ep: 1.36 masked_t 1.628 masked_v 0.211 NSP 0.094 lr 1.82576e-05
10/29/2020 22:17:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 14751 Ep: 1.36 masked_t 1.661 masked_v 0.216 NSP 0.089 lr 1.82371e-05
10/29/2020 22:18:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 14771 Ep: 1.36 masked_t 1.630 masked_v 0.215 NSP 0.082 lr 1.82166e-05
10/29/2020 22:18:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 14791 Ep: 1.36 masked_t 1.594 masked_v 0.212 NSP 0.088 lr 1.81961e-05
10/29/2020 22:18:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 14811 Ep: 1.37 masked_t 1.710 masked_v 0.214 NSP 0.097 lr 1.81756e-05
10/29/2020 22:19:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 14831 Ep: 1.37 masked_t 1.636 masked_v 0.215 NSP 0.086 lr 1.81551e-05
10/29/2020 22:19:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 14851 Ep: 1.37 masked_t 1.599 masked_v 0.217 NSP 0.088 lr 1.81347e-05
10/29/2020 22:19:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 14871 Ep: 1.37 masked_t 1.597 masked_v 0.214 NSP 0.091 lr 1.81142e-05
10/29/2020 22:20:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 14891 Ep: 1.37 masked_t 1.719 masked_v 0.210 NSP 0.086 lr 1.80937e-05
10/29/2020 22:20:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 14911 Ep: 1.37 masked_t 1.681 masked_v 0.213 NSP 0.080 lr 1.80732e-05
10/29/2020 22:20:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 14931 Ep: 1.38 masked_t 1.598 masked_v 0.213 NSP 0.082 lr 1.80527e-05
10/29/2020 22:21:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 14951 Ep: 1.38 masked_t 1.628 masked_v 0.218 NSP 0.091 lr 1.80323e-05
10/29/2020 22:21:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 14971 Ep: 1.38 masked_t 1.638 masked_v 0.219 NSP 0.090 lr 1.80118e-05
10/29/2020 22:21:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 14991 Ep: 1.38 masked_t 1.684 masked_v 0.213 NSP 0.083 lr 1.79913e-05
10/29/2020 22:22:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 15011 Ep: 1.38 masked_t 1.770 masked_v 0.213 NSP 0.079 lr 1.79708e-05
10/29/2020 22:22:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 15031 Ep: 1.39 masked_t 1.693 masked_v 0.219 NSP 0.095 lr 1.79503e-05
10/29/2020 22:22:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 15051 Ep: 1.39 masked_t 1.625 masked_v 0.214 NSP 0.090 lr 1.79299e-05
10/29/2020 22:23:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 15071 Ep: 1.39 masked_t 1.768 masked_v 0.219 NSP 0.088 lr 1.79094e-05
10/29/2020 22:23:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 15091 Ep: 1.39 masked_t 1.616 masked_v 0.215 NSP 0.092 lr 1.78889e-05
10/29/2020 22:24:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 15111 Ep: 1.39 masked_t 1.790 masked_v 0.213 NSP 0.086 lr 1.78684e-05
10/29/2020 22:24:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 15131 Ep: 1.39 masked_t 1.663 masked_v 0.216 NSP 0.090 lr 1.78479e-05
10/29/2020 22:24:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 15151 Ep: 1.40 masked_t 1.651 masked_v 0.218 NSP 0.101 lr 1.78274e-05
10/29/2020 22:25:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 15171 Ep: 1.40 masked_t 1.646 masked_v 0.216 NSP 0.088 lr 1.7807e-05
10/29/2020 22:25:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 15191 Ep: 1.40 masked_t 1.687 masked_v 0.215 NSP 0.085 lr 1.77865e-05
10/29/2020 22:25:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 15211 Ep: 1.40 masked_t 1.646 masked_v 0.216 NSP 0.078 lr 1.7766e-05
10/29/2020 22:26:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 15231 Ep: 1.40 masked_t 1.545 masked_v 0.215 NSP 0.082 lr 1.77455e-05
10/29/2020 22:26:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 15251 Ep: 1.41 masked_t 1.650 masked_v 0.214 NSP 0.097 lr 1.7725e-05
10/29/2020 22:26:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 15271 Ep: 1.41 masked_t 1.647 masked_v 0.213 NSP 0.086 lr 1.77046e-05
10/29/2020 22:27:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 15291 Ep: 1.41 masked_t 1.610 masked_v 0.213 NSP 0.085 lr 1.76841e-05
10/29/2020 22:27:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 15311 Ep: 1.41 masked_t 1.623 masked_v 0.213 NSP 0.093 lr 1.76636e-05
10/29/2020 22:27:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 15331 Ep: 1.41 masked_t 1.644 masked_v 0.219 NSP 0.099 lr 1.76431e-05
10/29/2020 22:28:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 15351 Ep: 1.41 masked_t 1.589 masked_v 0.215 NSP 0.074 lr 1.76226e-05
10/29/2020 22:28:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 15371 Ep: 1.42 masked_t 1.766 masked_v 0.217 NSP 0.087 lr 1.76022e-05
10/29/2020 22:28:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 15391 Ep: 1.42 masked_t 1.586 masked_v 0.212 NSP 0.092 lr 1.75817e-05
10/29/2020 22:29:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 15411 Ep: 1.42 masked_t 1.691 masked_v 0.219 NSP 0.091 lr 1.75612e-05
10/29/2020 22:29:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 15431 Ep: 1.42 masked_t 1.645 masked_v 0.218 NSP 0.082 lr 1.75407e-05
10/29/2020 22:29:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 15451 Ep: 1.42 masked_t 1.683 masked_v 0.215 NSP 0.082 lr 1.75202e-05
10/29/2020 22:30:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 15471 Ep: 1.43 masked_t 1.611 masked_v 0.222 NSP 0.079 lr 1.74997e-05
10/29/2020 22:30:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 15491 Ep: 1.43 masked_t 1.706 masked_v 0.217 NSP 0.079 lr 1.74793e-05
10/29/2020 22:31:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 15511 Ep: 1.43 masked_t 1.657 masked_v 0.214 NSP 0.095 lr 1.74588e-05
10/29/2020 22:31:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 15531 Ep: 1.43 masked_t 1.659 masked_v 0.212 NSP 0.093 lr 1.74383e-05
10/29/2020 22:31:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 15551 Ep: 1.43 masked_t 1.630 masked_v 0.215 NSP 0.093 lr 1.74178e-05
10/29/2020 22:32:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 15571 Ep: 1.44 masked_t 1.677 masked_v 0.211 NSP 0.082 lr 1.73973e-05
10/29/2020 22:32:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 15591 Ep: 1.44 masked_t 1.698 masked_v 0.221 NSP 0.089 lr 1.73769e-05
10/29/2020 22:32:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 15611 Ep: 1.44 masked_t 1.664 masked_v 0.215 NSP 0.082 lr 1.73564e-05
10/29/2020 22:33:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 15631 Ep: 1.44 masked_t 1.591 masked_v 0.212 NSP 0.098 lr 1.73359e-05
10/29/2020 22:33:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 15651 Ep: 1.44 masked_t 1.714 masked_v 0.213 NSP 0.085 lr 1.73154e-05
10/29/2020 22:33:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 15671 Ep: 1.44 masked_t 1.659 masked_v 0.213 NSP 0.078 lr 1.72949e-05
10/29/2020 22:34:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 15691 Ep: 1.45 masked_t 1.637 masked_v 0.218 NSP 0.099 lr 1.72744e-05
10/29/2020 22:34:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 15711 Ep: 1.45 masked_t 1.639 masked_v 0.208 NSP 0.081 lr 1.7254e-05
10/29/2020 22:34:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 15731 Ep: 1.45 masked_t 1.696 masked_v 0.214 NSP 0.086 lr 1.72335e-05
10/29/2020 22:35:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 15751 Ep: 1.45 masked_t 1.663 masked_v 0.212 NSP 0.090 lr 1.7213e-05
10/29/2020 22:35:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 15771 Ep: 1.45 masked_t 1.653 masked_v 0.212 NSP 0.092 lr 1.71925e-05
10/29/2020 22:35:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 15791 Ep: 1.46 masked_t 1.621 masked_v 0.209 NSP 0.093 lr 1.7172e-05
10/29/2020 22:36:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 15811 Ep: 1.46 masked_t 1.625 masked_v 0.217 NSP 0.088 lr 1.71516e-05
10/29/2020 22:36:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 15831 Ep: 1.46 masked_t 1.659 masked_v 0.213 NSP 0.093 lr 1.71311e-05
10/29/2020 22:36:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 15851 Ep: 1.46 masked_t 1.689 masked_v 0.210 NSP 0.092 lr 1.71106e-05
10/29/2020 22:37:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 15871 Ep: 1.46 masked_t 1.718 masked_v 0.211 NSP 0.093 lr 1.70901e-05
10/29/2020 22:37:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 15891 Ep: 1.46 masked_t 1.687 masked_v 0.217 NSP 0.082 lr 1.70696e-05
10/29/2020 22:38:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 15911 Ep: 1.47 masked_t 1.715 masked_v 0.210 NSP 0.088 lr 1.70492e-05
10/29/2020 22:38:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 15931 Ep: 1.47 masked_t 1.714 masked_v 0.226 NSP 0.087 lr 1.70287e-05
10/29/2020 22:38:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 15951 Ep: 1.47 masked_t 1.627 masked_v 0.217 NSP 0.084 lr 1.70082e-05
10/29/2020 22:39:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 15971 Ep: 1.47 masked_t 1.700 masked_v 0.212 NSP 0.079 lr 1.69877e-05
10/29/2020 22:39:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 15991 Ep: 1.47 masked_t 1.705 masked_v 0.212 NSP 0.089 lr 1.69672e-05
10/29/2020 22:39:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 16011 Ep: 1.48 masked_t 1.659 masked_v 0.210 NSP 0.078 lr 1.69467e-05
10/29/2020 22:40:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 16031 Ep: 1.48 masked_t 1.666 masked_v 0.211 NSP 0.084 lr 1.69263e-05
10/29/2020 22:40:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 16051 Ep: 1.48 masked_t 1.558 masked_v 0.210 NSP 0.080 lr 1.69058e-05
10/29/2020 22:40:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 16071 Ep: 1.48 masked_t 1.707 masked_v 0.211 NSP 0.086 lr 1.68853e-05
10/29/2020 22:41:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 16091 Ep: 1.48 masked_t 1.724 masked_v 0.209 NSP 0.097 lr 1.68648e-05
10/29/2020 22:41:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 16111 Ep: 1.48 masked_t 1.767 masked_v 0.213 NSP 0.083 lr 1.68443e-05
10/29/2020 22:41:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 16131 Ep: 1.49 masked_t 1.643 masked_v 0.211 NSP 0.087 lr 1.68239e-05
10/29/2020 22:42:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 16151 Ep: 1.49 masked_t 1.631 masked_v 0.218 NSP 0.099 lr 1.68034e-05
10/29/2020 22:42:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 16171 Ep: 1.49 masked_t 1.614 masked_v 0.213 NSP 0.085 lr 1.67829e-05
10/29/2020 22:42:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 16191 Ep: 1.49 masked_t 1.617 masked_v 0.210 NSP 0.096 lr 1.67624e-05
10/29/2020 22:43:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 16211 Ep: 1.49 masked_t 1.638 masked_v 0.208 NSP 0.086 lr 1.67419e-05
10/29/2020 22:43:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 16231 Ep: 1.50 masked_t 1.583 masked_v 0.210 NSP 0.081 lr 1.67215e-05
10/29/2020 22:44:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 16251 Ep: 1.50 masked_t 1.609 masked_v 0.213 NSP 0.088 lr 1.6701e-05
10/29/2020 22:44:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 16271 Ep: 1.50 masked_t 1.598 masked_v 0.216 NSP 0.083 lr 1.66805e-05
10/29/2020 22:44:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 16291 Ep: 1.50 masked_t 1.688 masked_v 0.212 NSP 0.080 lr 1.666e-05
10/29/2020 22:45:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 16311 Ep: 1.50 masked_t 1.684 masked_v 0.212 NSP 0.084 lr 1.66395e-05
10/29/2020 22:45:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 16331 Ep: 1.51 masked_t 1.559 masked_v 0.213 NSP 0.092 lr 1.6619e-05
10/29/2020 22:45:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 16351 Ep: 1.51 masked_t 1.656 masked_v 0.220 NSP 0.086 lr 1.65986e-05
10/29/2020 22:46:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 16371 Ep: 1.51 masked_t 1.623 masked_v 0.218 NSP 0.087 lr 1.65781e-05
10/29/2020 22:46:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 16391 Ep: 1.51 masked_t 1.665 masked_v 0.219 NSP 0.079 lr 1.65576e-05
10/29/2020 22:46:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 16411 Ep: 1.51 masked_t 1.674 masked_v 0.215 NSP 0.091 lr 1.65371e-05
10/29/2020 22:47:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 16431 Ep: 1.51 masked_t 1.698 masked_v 0.211 NSP 0.089 lr 1.65166e-05
10/29/2020 22:47:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 16451 Ep: 1.52 masked_t 1.694 masked_v 0.208 NSP 0.087 lr 1.64962e-05
10/29/2020 22:47:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 16471 Ep: 1.52 masked_t 1.660 masked_v 0.214 NSP 0.085 lr 1.64757e-05
10/29/2020 22:48:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 16491 Ep: 1.52 masked_t 1.609 masked_v 0.216 NSP 0.086 lr 1.64552e-05
10/29/2020 22:48:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 16511 Ep: 1.52 masked_t 1.626 masked_v 0.212 NSP 0.099 lr 1.64347e-05
10/29/2020 22:48:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 16531 Ep: 1.52 masked_t 1.617 masked_v 0.211 NSP 0.087 lr 1.64142e-05
10/29/2020 22:49:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 16551 Ep: 1.53 masked_t 1.586 masked_v 0.214 NSP 0.085 lr 1.63938e-05
10/29/2020 22:49:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 16571 Ep: 1.53 masked_t 1.656 masked_v 0.210 NSP 0.092 lr 1.63733e-05
10/29/2020 22:49:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 16591 Ep: 1.53 masked_t 1.572 masked_v 0.212 NSP 0.086 lr 1.63528e-05
10/29/2020 22:50:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 16611 Ep: 1.53 masked_t 1.620 masked_v 0.210 NSP 0.072 lr 1.63323e-05
10/29/2020 22:50:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 16631 Ep: 1.53 masked_t 1.612 masked_v 0.214 NSP 0.075 lr 1.63118e-05
10/29/2020 22:50:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 16651 Ep: 1.53 masked_t 1.619 masked_v 0.213 NSP 0.075 lr 1.62913e-05
10/29/2020 22:51:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 16671 Ep: 1.54 masked_t 1.662 masked_v 0.211 NSP 0.087 lr 1.62709e-05
10/29/2020 22:51:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 16691 Ep: 1.54 masked_t 1.625 masked_v 0.216 NSP 0.080 lr 1.62504e-05
10/29/2020 22:52:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 16711 Ep: 1.54 masked_t 1.684 masked_v 0.216 NSP 0.086 lr 1.62299e-05
10/29/2020 22:52:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 16731 Ep: 1.54 masked_t 1.600 masked_v 0.214 NSP 0.090 lr 1.62094e-05
10/29/2020 22:52:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 16751 Ep: 1.54 masked_t 1.698 masked_v 0.215 NSP 0.088 lr 1.61889e-05
10/29/2020 22:53:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 16771 Ep: 1.55 masked_t 1.666 masked_v 0.214 NSP 0.078 lr 1.61685e-05
10/29/2020 22:53:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 16791 Ep: 1.55 masked_t 1.586 masked_v 0.213 NSP 0.073 lr 1.6148e-05
10/29/2020 22:53:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 16811 Ep: 1.55 masked_t 1.664 masked_v 0.213 NSP 0.090 lr 1.61275e-05
10/29/2020 22:54:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 16831 Ep: 1.55 masked_t 1.633 masked_v 0.212 NSP 0.087 lr 1.6107e-05
10/29/2020 22:54:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 16851 Ep: 1.55 masked_t 1.659 masked_v 0.217 NSP 0.079 lr 1.60865e-05
10/29/2020 22:54:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 16871 Ep: 1.55 masked_t 1.674 masked_v 0.215 NSP 0.079 lr 1.60661e-05
10/29/2020 22:55:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 16891 Ep: 1.56 masked_t 1.634 masked_v 0.215 NSP 0.081 lr 1.60456e-05
10/29/2020 22:55:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 16911 Ep: 1.56 masked_t 1.727 masked_v 0.219 NSP 0.084 lr 1.60251e-05
10/29/2020 22:55:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 16931 Ep: 1.56 masked_t 1.636 masked_v 0.217 NSP 0.084 lr 1.60046e-05
10/29/2020 22:56:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 16951 Ep: 1.56 masked_t 1.636 masked_v 0.215 NSP 0.071 lr 1.59841e-05
10/29/2020 22:56:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 16971 Ep: 1.56 masked_t 1.575 masked_v 0.213 NSP 0.084 lr 1.59636e-05
10/29/2020 22:56:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 16991 Ep: 1.57 masked_t 1.671 masked_v 0.214 NSP 0.085 lr 1.59432e-05
10/29/2020 22:57:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 17011 Ep: 1.57 masked_t 1.627 masked_v 0.213 NSP 0.076 lr 1.59227e-05
10/29/2020 22:57:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 17031 Ep: 1.57 masked_t 1.757 masked_v 0.214 NSP 0.088 lr 1.59022e-05
10/29/2020 22:57:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 17051 Ep: 1.57 masked_t 1.589 masked_v 0.219 NSP 0.083 lr 1.58817e-05
10/29/2020 22:58:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 17071 Ep: 1.57 masked_t 1.717 masked_v 0.207 NSP 0.086 lr 1.58612e-05
10/29/2020 22:58:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 17091 Ep: 1.58 masked_t 1.605 masked_v 0.220 NSP 0.081 lr 1.58408e-05
10/29/2020 22:59:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 17111 Ep: 1.58 masked_t 1.647 masked_v 0.211 NSP 0.100 lr 1.58203e-05
10/29/2020 22:59:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 17131 Ep: 1.58 masked_t 1.648 masked_v 0.210 NSP 0.089 lr 1.57998e-05
10/29/2020 22:59:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 17151 Ep: 1.58 masked_t 1.629 masked_v 0.215 NSP 0.091 lr 1.57793e-05
10/29/2020 23:00:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 17171 Ep: 1.58 masked_t 1.647 masked_v 0.211 NSP 0.093 lr 1.57588e-05
10/29/2020 23:00:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 17191 Ep: 1.58 masked_t 1.627 masked_v 0.217 NSP 0.097 lr 1.57384e-05
10/29/2020 23:00:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 17211 Ep: 1.59 masked_t 1.650 masked_v 0.211 NSP 0.085 lr 1.57179e-05
10/29/2020 23:01:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 17231 Ep: 1.59 masked_t 1.690 masked_v 0.213 NSP 0.081 lr 1.56974e-05
10/29/2020 23:01:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 17251 Ep: 1.59 masked_t 1.710 masked_v 0.208 NSP 0.089 lr 1.56769e-05
10/29/2020 23:01:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 17271 Ep: 1.59 masked_t 1.663 masked_v 0.220 NSP 0.083 lr 1.56564e-05
10/29/2020 23:02:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 17291 Ep: 1.59 masked_t 1.699 masked_v 0.211 NSP 0.089 lr 1.56359e-05
10/29/2020 23:02:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 17311 Ep: 1.60 masked_t 1.698 masked_v 0.218 NSP 0.097 lr 1.56155e-05
10/29/2020 23:02:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 17331 Ep: 1.60 masked_t 1.577 masked_v 0.211 NSP 0.082 lr 1.5595e-05
10/29/2020 23:03:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 17351 Ep: 1.60 masked_t 1.661 masked_v 0.207 NSP 0.092 lr 1.55745e-05
10/29/2020 23:03:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 17371 Ep: 1.60 masked_t 1.679 masked_v 0.215 NSP 0.083 lr 1.5554e-05
10/29/2020 23:03:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 17391 Ep: 1.60 masked_t 1.587 masked_v 0.207 NSP 0.076 lr 1.55335e-05
10/29/2020 23:04:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 17411 Ep: 1.60 masked_t 1.691 masked_v 0.212 NSP 0.088 lr 1.55131e-05
10/29/2020 23:04:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 17431 Ep: 1.61 masked_t 1.595 masked_v 0.213 NSP 0.092 lr 1.54926e-05
10/29/2020 23:04:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 17451 Ep: 1.61 masked_t 1.563 masked_v 0.213 NSP 0.090 lr 1.54721e-05
10/29/2020 23:05:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 17471 Ep: 1.61 masked_t 1.655 masked_v 0.216 NSP 0.094 lr 1.54516e-05
10/29/2020 23:05:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 17491 Ep: 1.61 masked_t 1.619 masked_v 0.211 NSP 0.085 lr 1.54311e-05
10/29/2020 23:06:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 17511 Ep: 1.61 masked_t 1.629 masked_v 0.220 NSP 0.080 lr 1.54107e-05
10/29/2020 23:06:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 17531 Ep: 1.62 masked_t 1.682 masked_v 0.214 NSP 0.090 lr 1.53902e-05
10/29/2020 23:06:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 17551 Ep: 1.62 masked_t 1.555 masked_v 0.214 NSP 0.082 lr 1.53697e-05
10/29/2020 23:07:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 17571 Ep: 1.62 masked_t 1.564 masked_v 0.215 NSP 0.094 lr 1.53492e-05
10/29/2020 23:07:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 17591 Ep: 1.62 masked_t 1.618 masked_v 0.220 NSP 0.081 lr 1.53287e-05
10/29/2020 23:07:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 17611 Ep: 1.62 masked_t 1.584 masked_v 0.213 NSP 0.081 lr 1.53082e-05
10/29/2020 23:08:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 17631 Ep: 1.62 masked_t 1.613 masked_v 0.215 NSP 0.086 lr 1.52878e-05
10/29/2020 23:08:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 17651 Ep: 1.63 masked_t 1.665 masked_v 0.209 NSP 0.084 lr 1.52673e-05
10/29/2020 23:08:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 17671 Ep: 1.63 masked_t 1.627 masked_v 0.223 NSP 0.089 lr 1.52468e-05
10/29/2020 23:09:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 17691 Ep: 1.63 masked_t 1.646 masked_v 0.210 NSP 0.089 lr 1.52263e-05
10/29/2020 23:09:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 17711 Ep: 1.63 masked_t 1.722 masked_v 0.214 NSP 0.084 lr 1.52058e-05
10/29/2020 23:09:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 17731 Ep: 1.63 masked_t 1.621 masked_v 0.209 NSP 0.090 lr 1.51854e-05
10/29/2020 23:10:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 17751 Ep: 1.64 masked_t 1.700 masked_v 0.212 NSP 0.086 lr 1.51649e-05
10/29/2020 23:10:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 17771 Ep: 1.64 masked_t 1.624 masked_v 0.216 NSP 0.077 lr 1.51444e-05
10/29/2020 23:10:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 17791 Ep: 1.64 masked_t 1.631 masked_v 0.214 NSP 0.077 lr 1.51239e-05
10/29/2020 23:11:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 17811 Ep: 1.64 masked_t 1.669 masked_v 0.214 NSP 0.082 lr 1.51034e-05
10/29/2020 23:11:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 17831 Ep: 1.64 masked_t 1.636 masked_v 0.214 NSP 0.083 lr 1.50829e-05
10/29/2020 23:11:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 17851 Ep: 1.65 masked_t 1.690 masked_v 0.214 NSP 0.085 lr 1.50625e-05
10/29/2020 23:12:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 17871 Ep: 1.65 masked_t 1.635 masked_v 0.215 NSP 0.089 lr 1.5042e-05
10/29/2020 23:12:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 17891 Ep: 1.65 masked_t 1.669 masked_v 0.211 NSP 0.087 lr 1.50215e-05
10/29/2020 23:13:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 17911 Ep: 1.65 masked_t 1.622 masked_v 0.210 NSP 0.079 lr 1.5001e-05
10/29/2020 23:13:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 17931 Ep: 1.65 masked_t 1.692 masked_v 0.214 NSP 0.082 lr 1.49805e-05
10/29/2020 23:13:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 17951 Ep: 1.65 masked_t 1.638 masked_v 0.211 NSP 0.081 lr 1.49601e-05
10/29/2020 23:14:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 17971 Ep: 1.66 masked_t 1.633 masked_v 0.206 NSP 0.094 lr 1.49396e-05
10/29/2020 23:14:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 17991 Ep: 1.66 masked_t 1.708 masked_v 0.212 NSP 0.084 lr 1.49191e-05
10/29/2020 23:14:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 18011 Ep: 1.66 masked_t 1.596 masked_v 0.214 NSP 0.095 lr 1.48986e-05
10/29/2020 23:15:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 18031 Ep: 1.66 masked_t 1.613 masked_v 0.218 NSP 0.081 lr 1.48781e-05
10/29/2020 23:15:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 18051 Ep: 1.66 masked_t 1.645 masked_v 0.215 NSP 0.089 lr 1.48577e-05
10/29/2020 23:15:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 18071 Ep: 1.67 masked_t 1.622 masked_v 0.219 NSP 0.083 lr 1.48372e-05
10/29/2020 23:16:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 18091 Ep: 1.67 masked_t 1.693 masked_v 0.211 NSP 0.083 lr 1.48167e-05
10/29/2020 23:16:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 18111 Ep: 1.67 masked_t 1.601 masked_v 0.211 NSP 0.090 lr 1.47962e-05
10/29/2020 23:16:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 18131 Ep: 1.67 masked_t 1.699 masked_v 0.207 NSP 0.086 lr 1.47757e-05
10/29/2020 23:17:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 18151 Ep: 1.67 masked_t 1.667 masked_v 0.207 NSP 0.081 lr 1.47552e-05
10/29/2020 23:17:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 18171 Ep: 1.67 masked_t 1.613 masked_v 0.213 NSP 0.078 lr 1.47348e-05
10/29/2020 23:17:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 18191 Ep: 1.68 masked_t 1.617 masked_v 0.217 NSP 0.090 lr 1.47143e-05
10/29/2020 23:18:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 18211 Ep: 1.68 masked_t 1.597 masked_v 0.217 NSP 0.085 lr 1.46938e-05
10/29/2020 23:18:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 18231 Ep: 1.68 masked_t 1.595 masked_v 0.212 NSP 0.077 lr 1.46733e-05
10/29/2020 23:18:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 18251 Ep: 1.68 masked_t 1.596 masked_v 0.215 NSP 0.089 lr 1.46528e-05
10/29/2020 23:19:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 18271 Ep: 1.68 masked_t 1.557 masked_v 0.216 NSP 0.081 lr 1.46324e-05
10/29/2020 23:19:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 18291 Ep: 1.69 masked_t 1.649 masked_v 0.212 NSP 0.084 lr 1.46119e-05
10/29/2020 23:20:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 18311 Ep: 1.69 masked_t 1.600 masked_v 0.217 NSP 0.082 lr 1.45914e-05
10/29/2020 23:20:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 18331 Ep: 1.69 masked_t 1.590 masked_v 0.208 NSP 0.084 lr 1.45709e-05
10/29/2020 23:20:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 18351 Ep: 1.69 masked_t 1.562 masked_v 0.213 NSP 0.092 lr 1.45504e-05
10/29/2020 23:21:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 18371 Ep: 1.69 masked_t 1.692 masked_v 0.219 NSP 0.092 lr 1.453e-05
10/29/2020 23:21:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 18391 Ep: 1.69 masked_t 1.649 masked_v 0.212 NSP 0.080 lr 1.45095e-05
10/29/2020 23:21:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 18411 Ep: 1.70 masked_t 1.652 masked_v 0.214 NSP 0.090 lr 1.4489e-05
10/29/2020 23:22:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 18431 Ep: 1.70 masked_t 1.620 masked_v 0.211 NSP 0.087 lr 1.44685e-05
10/29/2020 23:22:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 18451 Ep: 1.70 masked_t 1.555 masked_v 0.216 NSP 0.083 lr 1.4448e-05
10/29/2020 23:22:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 18471 Ep: 1.70 masked_t 1.650 masked_v 0.211 NSP 0.084 lr 1.44275e-05
10/29/2020 23:23:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 18491 Ep: 1.70 masked_t 1.548 masked_v 0.217 NSP 0.084 lr 1.44071e-05
10/29/2020 23:23:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 18511 Ep: 1.71 masked_t 1.634 masked_v 0.208 NSP 0.086 lr 1.43866e-05
10/29/2020 23:23:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 18531 Ep: 1.71 masked_t 1.690 masked_v 0.214 NSP 0.080 lr 1.43661e-05
10/29/2020 23:24:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 18551 Ep: 1.71 masked_t 1.622 masked_v 0.216 NSP 0.077 lr 1.43456e-05
10/29/2020 23:24:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 18571 Ep: 1.71 masked_t 1.672 masked_v 0.211 NSP 0.082 lr 1.43251e-05
10/29/2020 23:24:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 18591 Ep: 1.71 masked_t 1.616 masked_v 0.214 NSP 0.091 lr 1.43047e-05
10/29/2020 23:25:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 18611 Ep: 1.72 masked_t 1.587 masked_v 0.210 NSP 0.080 lr 1.42842e-05
10/29/2020 23:25:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 18631 Ep: 1.72 masked_t 1.634 masked_v 0.212 NSP 0.089 lr 1.42637e-05
10/29/2020 23:25:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 18651 Ep: 1.72 masked_t 1.659 masked_v 0.213 NSP 0.088 lr 1.42432e-05
10/29/2020 23:26:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 18671 Ep: 1.72 masked_t 1.599 masked_v 0.217 NSP 0.082 lr 1.42227e-05
10/29/2020 23:26:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 18691 Ep: 1.72 masked_t 1.678 masked_v 0.218 NSP 0.088 lr 1.42023e-05
10/29/2020 23:27:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 18711 Ep: 1.72 masked_t 1.578 masked_v 0.212 NSP 0.088 lr 1.41818e-05
10/29/2020 23:27:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 18731 Ep: 1.73 masked_t 1.553 masked_v 0.214 NSP 0.083 lr 1.41613e-05
10/29/2020 23:27:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 18751 Ep: 1.73 masked_t 1.587 masked_v 0.212 NSP 0.095 lr 1.41408e-05
10/29/2020 23:28:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 18771 Ep: 1.73 masked_t 1.615 masked_v 0.216 NSP 0.092 lr 1.41203e-05
10/29/2020 23:28:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 18791 Ep: 1.73 masked_t 1.693 masked_v 0.218 NSP 0.080 lr 1.40998e-05
10/29/2020 23:28:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 18811 Ep: 1.73 masked_t 1.590 masked_v 0.209 NSP 0.086 lr 1.40794e-05
10/29/2020 23:29:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 18831 Ep: 1.74 masked_t 1.637 masked_v 0.210 NSP 0.078 lr 1.40589e-05
10/29/2020 23:29:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 18851 Ep: 1.74 masked_t 1.706 masked_v 0.213 NSP 0.097 lr 1.40384e-05
10/29/2020 23:29:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 18871 Ep: 1.74 masked_t 1.657 masked_v 0.216 NSP 0.084 lr 1.40179e-05
10/29/2020 23:30:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 18891 Ep: 1.74 masked_t 1.650 masked_v 0.217 NSP 0.084 lr 1.39974e-05
10/29/2020 23:30:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 18911 Ep: 1.74 masked_t 1.637 masked_v 0.216 NSP 0.085 lr 1.3977e-05
10/29/2020 23:30:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 18931 Ep: 1.74 masked_t 1.673 masked_v 0.215 NSP 0.091 lr 1.39565e-05
10/29/2020 23:31:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 18951 Ep: 1.75 masked_t 1.460 masked_v 0.218 NSP 0.093 lr 1.3936e-05
10/29/2020 23:31:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 18971 Ep: 1.75 masked_t 1.567 masked_v 0.212 NSP 0.090 lr 1.39155e-05
10/29/2020 23:31:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 18991 Ep: 1.75 masked_t 1.569 masked_v 0.213 NSP 0.076 lr 1.3895e-05
10/29/2020 23:32:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 19011 Ep: 1.75 masked_t 1.556 masked_v 0.220 NSP 0.076 lr 1.38746e-05
10/29/2020 23:32:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 19031 Ep: 1.75 masked_t 1.608 masked_v 0.214 NSP 0.076 lr 1.38541e-05
10/29/2020 23:32:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 19051 Ep: 1.76 masked_t 1.620 masked_v 0.213 NSP 0.091 lr 1.38336e-05
10/29/2020 23:33:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 19071 Ep: 1.76 masked_t 1.641 masked_v 0.208 NSP 0.075 lr 1.38131e-05
10/29/2020 23:33:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 19091 Ep: 1.76 masked_t 1.587 masked_v 0.209 NSP 0.081 lr 1.37926e-05
10/29/2020 23:34:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 19111 Ep: 1.76 masked_t 1.687 masked_v 0.209 NSP 0.083 lr 1.37721e-05
10/29/2020 23:34:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 19131 Ep: 1.76 masked_t 1.666 masked_v 0.216 NSP 0.079 lr 1.37517e-05
10/29/2020 23:34:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 19151 Ep: 1.77 masked_t 1.614 masked_v 0.215 NSP 0.087 lr 1.37312e-05
10/29/2020 23:35:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 19171 Ep: 1.77 masked_t 1.614 masked_v 0.212 NSP 0.095 lr 1.37107e-05
10/29/2020 23:35:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 19191 Ep: 1.77 masked_t 1.696 masked_v 0.205 NSP 0.086 lr 1.36902e-05
10/29/2020 23:35:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 19211 Ep: 1.77 masked_t 1.600 masked_v 0.217 NSP 0.084 lr 1.36697e-05
10/29/2020 23:36:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 19231 Ep: 1.77 masked_t 1.568 masked_v 0.210 NSP 0.076 lr 1.36493e-05
10/29/2020 23:36:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 19251 Ep: 1.77 masked_t 1.664 masked_v 0.210 NSP 0.083 lr 1.36288e-05
10/29/2020 23:36:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 19271 Ep: 1.78 masked_t 1.607 masked_v 0.212 NSP 0.099 lr 1.36083e-05
10/29/2020 23:37:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 19291 Ep: 1.78 masked_t 1.565 masked_v 0.211 NSP 0.085 lr 1.35878e-05
10/29/2020 23:37:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 19311 Ep: 1.78 masked_t 1.625 masked_v 0.214 NSP 0.082 lr 1.35673e-05
10/29/2020 23:37:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 19331 Ep: 1.78 masked_t 1.583 masked_v 0.215 NSP 0.089 lr 1.35469e-05
10/29/2020 23:38:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 19351 Ep: 1.78 masked_t 1.664 masked_v 0.209 NSP 0.082 lr 1.35264e-05
10/29/2020 23:38:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 19371 Ep: 1.79 masked_t 1.665 masked_v 0.216 NSP 0.080 lr 1.35059e-05
10/29/2020 23:38:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 19391 Ep: 1.79 masked_t 1.661 masked_v 0.221 NSP 0.083 lr 1.34854e-05
10/29/2020 23:39:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 19411 Ep: 1.79 masked_t 1.638 masked_v 0.209 NSP 0.079 lr 1.34649e-05
10/29/2020 23:39:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 19431 Ep: 1.79 masked_t 1.684 masked_v 0.214 NSP 0.082 lr 1.34444e-05
10/29/2020 23:39:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 19451 Ep: 1.79 masked_t 1.593 masked_v 0.212 NSP 0.087 lr 1.3424e-05
10/29/2020 23:40:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 19471 Ep: 1.79 masked_t 1.653 masked_v 0.217 NSP 0.087 lr 1.34035e-05
10/29/2020 23:40:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 19491 Ep: 1.80 masked_t 1.600 masked_v 0.208 NSP 0.085 lr 1.3383e-05
10/29/2020 23:41:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 19511 Ep: 1.80 masked_t 1.636 masked_v 0.217 NSP 0.079 lr 1.33625e-05
10/29/2020 23:41:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 19531 Ep: 1.80 masked_t 1.552 masked_v 0.211 NSP 0.087 lr 1.3342e-05
10/29/2020 23:41:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 19551 Ep: 1.80 masked_t 1.651 masked_v 0.207 NSP 0.078 lr 1.33216e-05
10/29/2020 23:42:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 19571 Ep: 1.80 masked_t 1.532 masked_v 0.214 NSP 0.081 lr 1.33011e-05
10/29/2020 23:42:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 19591 Ep: 1.81 masked_t 1.609 masked_v 0.212 NSP 0.075 lr 1.32806e-05
10/29/2020 23:42:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 19611 Ep: 1.81 masked_t 1.602 masked_v 0.213 NSP 0.080 lr 1.32601e-05
10/29/2020 23:43:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 19631 Ep: 1.81 masked_t 1.579 masked_v 0.210 NSP 0.079 lr 1.32396e-05
10/29/2020 23:43:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 19651 Ep: 1.81 masked_t 1.626 masked_v 0.209 NSP 0.079 lr 1.32192e-05
10/29/2020 23:43:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 19671 Ep: 1.81 masked_t 1.540 masked_v 0.208 NSP 0.076 lr 1.31987e-05
10/29/2020 23:44:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 19691 Ep: 1.81 masked_t 1.608 masked_v 0.211 NSP 0.089 lr 1.31782e-05
10/29/2020 23:44:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 19711 Ep: 1.82 masked_t 1.645 masked_v 0.215 NSP 0.084 lr 1.31577e-05
10/29/2020 23:44:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 19731 Ep: 1.82 masked_t 1.540 masked_v 0.206 NSP 0.073 lr 1.31372e-05
10/29/2020 23:45:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 19751 Ep: 1.82 masked_t 1.672 masked_v 0.211 NSP 0.091 lr 1.31167e-05
10/29/2020 23:45:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 19771 Ep: 1.82 masked_t 1.586 masked_v 0.217 NSP 0.087 lr 1.30963e-05
10/29/2020 23:45:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 19791 Ep: 1.82 masked_t 1.636 masked_v 0.209 NSP 0.086 lr 1.30758e-05
10/29/2020 23:46:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 19811 Ep: 1.83 masked_t 1.633 masked_v 0.217 NSP 0.086 lr 1.30553e-05
10/29/2020 23:46:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 19831 Ep: 1.83 masked_t 1.632 masked_v 0.207 NSP 0.086 lr 1.30348e-05
10/29/2020 23:46:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 19851 Ep: 1.83 masked_t 1.624 masked_v 0.203 NSP 0.087 lr 1.30143e-05
10/29/2020 23:47:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 19871 Ep: 1.83 masked_t 1.600 masked_v 0.211 NSP 0.078 lr 1.29939e-05
10/29/2020 23:47:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 19891 Ep: 1.83 masked_t 1.643 masked_v 0.215 NSP 0.081 lr 1.29734e-05
10/29/2020 23:48:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 19911 Ep: 1.84 masked_t 1.598 masked_v 0.206 NSP 0.091 lr 1.29529e-05
10/29/2020 23:48:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 19931 Ep: 1.84 masked_t 1.558 masked_v 0.212 NSP 0.081 lr 1.29324e-05
10/29/2020 23:48:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 19951 Ep: 1.84 masked_t 1.682 masked_v 0.216 NSP 0.090 lr 1.29119e-05
10/29/2020 23:49:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 19971 Ep: 1.84 masked_t 1.602 masked_v 0.216 NSP 0.089 lr 1.28914e-05
10/29/2020 23:49:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 19991 Ep: 1.84 masked_t 1.585 masked_v 0.213 NSP 0.083 lr 1.2871e-05
10/29/2020 23:49:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 20011 Ep: 1.84 masked_t 1.642 masked_v 0.217 NSP 0.077 lr 1.28505e-05
10/29/2020 23:50:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 20031 Ep: 1.85 masked_t 1.668 masked_v 0.210 NSP 0.087 lr 1.283e-05
10/29/2020 23:50:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 20051 Ep: 1.85 masked_t 1.616 masked_v 0.214 NSP 0.090 lr 1.28095e-05
10/29/2020 23:50:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 20071 Ep: 1.85 masked_t 1.613 masked_v 0.213 NSP 0.092 lr 1.2789e-05
10/29/2020 23:51:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 20091 Ep: 1.85 masked_t 1.591 masked_v 0.210 NSP 0.082 lr 1.27686e-05
10/29/2020 23:51:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 20111 Ep: 1.85 masked_t 1.546 masked_v 0.208 NSP 0.077 lr 1.27481e-05
10/29/2020 23:51:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 20131 Ep: 1.86 masked_t 1.599 masked_v 0.214 NSP 0.083 lr 1.27276e-05
10/29/2020 23:52:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 20151 Ep: 1.86 masked_t 1.677 masked_v 0.213 NSP 0.085 lr 1.27071e-05
10/29/2020 23:52:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 20171 Ep: 1.86 masked_t 1.605 masked_v 0.209 NSP 0.078 lr 1.26866e-05
10/29/2020 23:52:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 20191 Ep: 1.86 masked_t 1.699 masked_v 0.212 NSP 0.086 lr 1.26662e-05
10/29/2020 23:53:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 20211 Ep: 1.86 masked_t 1.660 masked_v 0.211 NSP 0.078 lr 1.26457e-05
10/29/2020 23:53:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 20231 Ep: 1.86 masked_t 1.624 masked_v 0.211 NSP 0.087 lr 1.26252e-05
10/29/2020 23:54:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 20251 Ep: 1.87 masked_t 1.665 masked_v 0.217 NSP 0.087 lr 1.26047e-05
10/29/2020 23:54:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 20271 Ep: 1.87 masked_t 1.685 masked_v 0.213 NSP 0.081 lr 1.25842e-05
10/29/2020 23:54:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 20291 Ep: 1.87 masked_t 1.649 masked_v 0.207 NSP 0.079 lr 1.25637e-05
10/29/2020 23:55:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 20311 Ep: 1.87 masked_t 1.546 masked_v 0.209 NSP 0.080 lr 1.25433e-05
10/29/2020 23:55:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 20331 Ep: 1.87 masked_t 1.720 masked_v 0.214 NSP 0.076 lr 1.25228e-05
10/29/2020 23:55:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 20351 Ep: 1.88 masked_t 1.678 masked_v 0.212 NSP 0.083 lr 1.25023e-05
10/29/2020 23:56:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 20371 Ep: 1.88 masked_t 1.549 masked_v 0.210 NSP 0.079 lr 1.24818e-05
10/29/2020 23:56:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 20391 Ep: 1.88 masked_t 1.626 masked_v 0.206 NSP 0.085 lr 1.24613e-05
10/29/2020 23:56:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 20411 Ep: 1.88 masked_t 1.614 masked_v 0.211 NSP 0.088 lr 1.24409e-05
10/29/2020 23:57:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 20431 Ep: 1.88 masked_t 1.684 masked_v 0.208 NSP 0.089 lr 1.24204e-05
10/29/2020 23:57:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 20451 Ep: 1.88 masked_t 1.597 masked_v 0.213 NSP 0.083 lr 1.23999e-05
10/29/2020 23:57:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 20471 Ep: 1.89 masked_t 1.568 masked_v 0.208 NSP 0.085 lr 1.23794e-05
10/29/2020 23:58:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 20491 Ep: 1.89 masked_t 1.471 masked_v 0.211 NSP 0.081 lr 1.23589e-05
10/29/2020 23:58:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 20511 Ep: 1.89 masked_t 1.533 masked_v 0.212 NSP 0.083 lr 1.23385e-05
10/29/2020 23:58:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 20531 Ep: 1.89 masked_t 1.591 masked_v 0.206 NSP 0.073 lr 1.2318e-05
10/29/2020 23:59:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 20551 Ep: 1.89 masked_t 1.681 masked_v 0.217 NSP 0.082 lr 1.22975e-05
10/29/2020 23:59:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 20571 Ep: 1.90 masked_t 1.620 masked_v 0.206 NSP 0.080 lr 1.2277e-05
10/29/2020 23:59:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 20591 Ep: 1.90 masked_t 1.582 masked_v 0.213 NSP 0.082 lr 1.22565e-05
10/30/2020 00:00:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 20611 Ep: 1.90 masked_t 1.654 masked_v 0.206 NSP 0.084 lr 1.2236e-05
10/30/2020 00:00:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 20631 Ep: 1.90 masked_t 1.582 masked_v 0.212 NSP 0.082 lr 1.22156e-05
10/30/2020 00:01:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 20651 Ep: 1.90 masked_t 1.663 masked_v 0.209 NSP 0.085 lr 1.21951e-05
10/30/2020 00:01:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 20671 Ep: 1.91 masked_t 1.683 masked_v 0.218 NSP 0.096 lr 1.21746e-05
10/30/2020 00:01:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 20691 Ep: 1.91 masked_t 1.643 masked_v 0.212 NSP 0.077 lr 1.21541e-05
10/30/2020 00:02:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 20711 Ep: 1.91 masked_t 1.663 masked_v 0.207 NSP 0.082 lr 1.21336e-05
10/30/2020 00:02:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 20731 Ep: 1.91 masked_t 1.685 masked_v 0.209 NSP 0.077 lr 1.21132e-05
10/30/2020 00:02:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 20751 Ep: 1.91 masked_t 1.621 masked_v 0.208 NSP 0.093 lr 1.20927e-05
10/30/2020 00:03:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 20771 Ep: 1.91 masked_t 1.547 masked_v 0.209 NSP 0.081 lr 1.20722e-05
10/30/2020 00:03:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 20791 Ep: 1.92 masked_t 1.635 masked_v 0.212 NSP 0.094 lr 1.20517e-05
10/30/2020 00:03:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 20811 Ep: 1.92 masked_t 1.596 masked_v 0.207 NSP 0.093 lr 1.20312e-05
10/30/2020 00:04:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 20831 Ep: 1.92 masked_t 1.619 masked_v 0.219 NSP 0.085 lr 1.20108e-05
10/30/2020 00:04:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 20851 Ep: 1.92 masked_t 1.609 masked_v 0.210 NSP 0.081 lr 1.19903e-05
10/30/2020 00:04:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 20871 Ep: 1.92 masked_t 1.510 masked_v 0.210 NSP 0.076 lr 1.19698e-05
10/30/2020 00:05:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 20891 Ep: 1.93 masked_t 1.675 masked_v 0.211 NSP 0.076 lr 1.19493e-05
10/30/2020 00:05:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 20911 Ep: 1.93 masked_t 1.590 masked_v 0.218 NSP 0.073 lr 1.19288e-05
10/30/2020 00:05:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 20931 Ep: 1.93 masked_t 1.694 masked_v 0.210 NSP 0.084 lr 1.19083e-05
10/30/2020 00:06:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 20951 Ep: 1.93 masked_t 1.554 masked_v 0.218 NSP 0.073 lr 1.18879e-05
10/30/2020 00:06:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 20971 Ep: 1.93 masked_t 1.613 masked_v 0.215 NSP 0.079 lr 1.18674e-05
10/30/2020 00:06:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 20991 Ep: 1.93 masked_t 1.686 masked_v 0.212 NSP 0.077 lr 1.18469e-05
10/30/2020 00:07:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 21011 Ep: 1.94 masked_t 1.617 masked_v 0.206 NSP 0.085 lr 1.18264e-05
10/30/2020 00:07:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 21031 Ep: 1.94 masked_t 1.605 masked_v 0.212 NSP 0.086 lr 1.18059e-05
10/30/2020 00:08:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 21051 Ep: 1.94 masked_t 1.585 masked_v 0.213 NSP 0.081 lr 1.17855e-05
10/30/2020 00:08:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 21071 Ep: 1.94 masked_t 1.592 masked_v 0.219 NSP 0.084 lr 1.1765e-05
10/30/2020 00:08:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 21091 Ep: 1.94 masked_t 1.585 masked_v 0.219 NSP 0.081 lr 1.17445e-05
10/30/2020 00:09:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 21111 Ep: 1.95 masked_t 1.606 masked_v 0.208 NSP 0.082 lr 1.1724e-05
10/30/2020 00:09:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 21131 Ep: 1.95 masked_t 1.646 masked_v 0.218 NSP 0.084 lr 1.17035e-05
10/30/2020 00:09:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 21151 Ep: 1.95 masked_t 1.597 masked_v 0.210 NSP 0.079 lr 1.16831e-05
10/30/2020 00:10:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 21171 Ep: 1.95 masked_t 1.557 masked_v 0.214 NSP 0.086 lr 1.16626e-05
10/30/2020 00:10:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 21191 Ep: 1.95 masked_t 1.640 masked_v 0.213 NSP 0.088 lr 1.16421e-05
10/30/2020 00:10:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 21211 Ep: 1.95 masked_t 1.560 masked_v 0.211 NSP 0.070 lr 1.16216e-05
10/30/2020 00:11:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 21231 Ep: 1.96 masked_t 1.569 masked_v 0.204 NSP 0.083 lr 1.16011e-05
10/30/2020 00:11:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 21251 Ep: 1.96 masked_t 1.621 masked_v 0.211 NSP 0.080 lr 1.15806e-05
10/30/2020 00:11:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 21271 Ep: 1.96 masked_t 1.634 masked_v 0.212 NSP 0.092 lr 1.15602e-05
10/30/2020 00:12:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 21291 Ep: 1.96 masked_t 1.608 masked_v 0.212 NSP 0.080 lr 1.15397e-05
10/30/2020 00:12:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 21311 Ep: 1.96 masked_t 1.555 masked_v 0.212 NSP 0.080 lr 1.15192e-05
10/30/2020 00:13:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 21331 Ep: 1.97 masked_t 1.629 masked_v 0.210 NSP 0.087 lr 1.14987e-05
10/30/2020 00:13:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 21351 Ep: 1.97 masked_t 1.693 masked_v 0.210 NSP 0.072 lr 1.14782e-05
10/30/2020 00:13:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 21371 Ep: 1.97 masked_t 1.575 masked_v 0.213 NSP 0.083 lr 1.14578e-05
10/30/2020 00:14:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 21391 Ep: 1.97 masked_t 1.627 masked_v 0.212 NSP 0.084 lr 1.14373e-05
10/30/2020 00:14:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 21411 Ep: 1.97 masked_t 1.595 masked_v 0.215 NSP 0.084 lr 1.14168e-05
10/30/2020 00:14:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 21431 Ep: 1.98 masked_t 1.650 masked_v 0.212 NSP 0.076 lr 1.13963e-05
10/30/2020 00:15:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 21451 Ep: 1.98 masked_t 1.741 masked_v 0.212 NSP 0.084 lr 1.13758e-05
10/30/2020 00:15:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 21471 Ep: 1.98 masked_t 1.657 masked_v 0.205 NSP 0.083 lr 1.13554e-05
10/30/2020 00:15:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 21491 Ep: 1.98 masked_t 1.563 masked_v 0.214 NSP 0.083 lr 1.13349e-05
10/30/2020 00:16:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 21511 Ep: 1.98 masked_t 1.557 masked_v 0.218 NSP 0.069 lr 1.13144e-05
10/30/2020 00:16:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 21531 Ep: 1.98 masked_t 1.625 masked_v 0.207 NSP 0.086 lr 1.12939e-05
10/30/2020 00:16:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 21551 Ep: 1.99 masked_t 1.553 masked_v 0.215 NSP 0.083 lr 1.12734e-05
10/30/2020 00:17:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 21571 Ep: 1.99 masked_t 1.630 masked_v 0.211 NSP 0.089 lr 1.12529e-05
10/30/2020 00:17:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 21591 Ep: 1.99 masked_t 1.557 masked_v 0.205 NSP 0.086 lr 1.12325e-05
10/30/2020 00:18:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 21611 Ep: 1.99 masked_t 1.644 masked_v 0.221 NSP 0.083 lr 1.1212e-05
10/30/2020 00:18:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 21631 Ep: 1.99 masked_t 1.607 masked_v 0.208 NSP 0.087 lr 1.11915e-05
10/30/2020 00:18:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 21651 Ep: 2.00 masked_t 1.630 masked_v 0.208 NSP 0.082 lr 1.1171e-05
10/30/2020 00:19:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 21671 Ep: 2.00 masked_t 1.586 masked_v 0.210 NSP 0.087 lr 1.11505e-05
10/30/2020 00:19:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 21691 Ep: 2.00 masked_t 1.628 masked_v 0.215 NSP 0.086 lr 1.11301e-05
10/30/2020 00:20:33 - INFO - volta.utils -   Validation [Conceptual_Caption]: masked_t 2.191 masked_v 0.195 NSP 0.109
10/30/2020 00:20:33 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 
10/30/2020 00:21:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 21721 Ep: 2.00 masked_t 1.613 masked_v 0.209 NSP 0.087 lr 1.11045e-05
10/30/2020 00:21:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 21741 Ep: 2.00 masked_t 1.606 masked_v 0.219 NSP 0.090 lr 1.10789e-05
10/30/2020 00:21:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 21761 Ep: 2.01 masked_t 1.576 masked_v 0.215 NSP 0.091 lr 1.10584e-05
10/30/2020 00:22:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 21781 Ep: 2.01 masked_t 1.556 masked_v 0.216 NSP 0.097 lr 1.10379e-05
10/30/2020 00:22:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 21801 Ep: 2.01 masked_t 1.608 masked_v 0.213 NSP 0.091 lr 1.10174e-05
10/30/2020 00:22:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 21821 Ep: 2.01 masked_t 1.563 masked_v 0.210 NSP 0.082 lr 1.09969e-05
10/30/2020 00:23:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 21841 Ep: 2.01 masked_t 1.691 masked_v 0.209 NSP 0.093 lr 1.09764e-05
10/30/2020 00:23:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 21861 Ep: 2.01 masked_t 1.502 masked_v 0.217 NSP 0.083 lr 1.0956e-05
10/30/2020 00:23:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 21881 Ep: 2.02 masked_t 1.579 masked_v 0.209 NSP 0.082 lr 1.09355e-05
10/30/2020 00:24:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 21901 Ep: 2.02 masked_t 1.619 masked_v 0.215 NSP 0.078 lr 1.0915e-05
10/30/2020 00:24:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 21921 Ep: 2.02 masked_t 1.561 masked_v 0.210 NSP 0.083 lr 1.08945e-05
10/30/2020 00:24:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 21941 Ep: 2.02 masked_t 1.643 masked_v 0.214 NSP 0.103 lr 1.0874e-05
10/30/2020 00:25:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 21961 Ep: 2.02 masked_t 1.618 masked_v 0.211 NSP 0.080 lr 1.08536e-05
10/30/2020 00:25:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 21981 Ep: 2.03 masked_t 1.628 masked_v 0.212 NSP 0.085 lr 1.08331e-05
10/30/2020 00:25:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 22001 Ep: 2.03 masked_t 1.648 masked_v 0.215 NSP 0.081 lr 1.08126e-05
10/30/2020 00:26:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 22021 Ep: 2.03 masked_t 1.600 masked_v 0.214 NSP 0.079 lr 1.07921e-05
10/30/2020 00:26:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 22041 Ep: 2.03 masked_t 1.658 masked_v 0.208 NSP 0.084 lr 1.07716e-05
10/30/2020 00:27:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 22061 Ep: 2.03 masked_t 1.692 masked_v 0.206 NSP 0.088 lr 1.07512e-05
10/30/2020 00:27:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 22081 Ep: 2.04 masked_t 1.570 masked_v 0.212 NSP 0.090 lr 1.07307e-05
10/30/2020 00:27:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 22101 Ep: 2.04 masked_t 1.635 masked_v 0.206 NSP 0.084 lr 1.07102e-05
10/30/2020 00:28:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 22121 Ep: 2.04 masked_t 1.576 masked_v 0.207 NSP 0.087 lr 1.06897e-05
10/30/2020 00:28:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 22141 Ep: 2.04 masked_t 1.596 masked_v 0.207 NSP 0.077 lr 1.06692e-05
10/30/2020 00:28:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 22161 Ep: 2.04 masked_t 1.678 masked_v 0.212 NSP 0.073 lr 1.06487e-05
10/30/2020 00:29:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 22181 Ep: 2.04 masked_t 1.653 masked_v 0.212 NSP 0.087 lr 1.06283e-05
10/30/2020 00:29:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 22201 Ep: 2.05 masked_t 1.646 masked_v 0.212 NSP 0.089 lr 1.06078e-05
10/30/2020 00:29:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 22221 Ep: 2.05 masked_t 1.613 masked_v 0.207 NSP 0.077 lr 1.05873e-05
10/30/2020 00:30:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 22241 Ep: 2.05 masked_t 1.584 masked_v 0.210 NSP 0.087 lr 1.05668e-05
10/30/2020 00:30:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 22261 Ep: 2.05 masked_t 1.607 masked_v 0.215 NSP 0.083 lr 1.05463e-05
10/30/2020 00:30:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 22281 Ep: 2.05 masked_t 1.673 masked_v 0.209 NSP 0.092 lr 1.05259e-05
10/30/2020 00:31:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 22301 Ep: 2.06 masked_t 1.544 masked_v 0.211 NSP 0.084 lr 1.05054e-05
10/30/2020 00:31:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 22321 Ep: 2.06 masked_t 1.590 masked_v 0.209 NSP 0.084 lr 1.04849e-05
10/30/2020 00:31:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 22341 Ep: 2.06 masked_t 1.690 masked_v 0.211 NSP 0.084 lr 1.04644e-05
10/30/2020 00:32:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 22361 Ep: 2.06 masked_t 1.547 masked_v 0.216 NSP 0.082 lr 1.04439e-05
10/30/2020 00:32:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 22381 Ep: 2.06 masked_t 1.652 masked_v 0.208 NSP 0.077 lr 1.04235e-05
10/30/2020 00:32:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 22401 Ep: 2.06 masked_t 1.697 masked_v 0.209 NSP 0.087 lr 1.0403e-05
10/30/2020 00:33:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 22421 Ep: 2.07 masked_t 1.644 masked_v 0.219 NSP 0.086 lr 1.03825e-05
10/30/2020 00:33:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 22441 Ep: 2.07 masked_t 1.571 masked_v 0.212 NSP 0.082 lr 1.0362e-05
10/30/2020 00:34:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 22461 Ep: 2.07 masked_t 1.599 masked_v 0.208 NSP 0.086 lr 1.03415e-05
10/30/2020 00:34:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 22481 Ep: 2.07 masked_t 1.616 masked_v 0.206 NSP 0.078 lr 1.0321e-05
10/30/2020 00:34:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 22501 Ep: 2.07 masked_t 1.655 masked_v 0.212 NSP 0.086 lr 1.03006e-05
10/30/2020 00:35:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 22521 Ep: 2.08 masked_t 1.621 masked_v 0.213 NSP 0.073 lr 1.02801e-05
10/30/2020 00:35:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 22541 Ep: 2.08 masked_t 1.596 masked_v 0.209 NSP 0.085 lr 1.02596e-05
10/30/2020 00:35:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 22561 Ep: 2.08 masked_t 1.642 masked_v 0.210 NSP 0.086 lr 1.02391e-05
10/30/2020 00:36:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 22581 Ep: 2.08 masked_t 1.567 masked_v 0.206 NSP 0.085 lr 1.02186e-05
10/30/2020 00:36:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 22601 Ep: 2.08 masked_t 1.650 masked_v 0.209 NSP 0.082 lr 1.01982e-05
10/30/2020 00:36:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 22621 Ep: 2.08 masked_t 1.614 masked_v 0.212 NSP 0.076 lr 1.01777e-05
10/30/2020 00:37:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 22641 Ep: 2.09 masked_t 1.539 masked_v 0.206 NSP 0.078 lr 1.01572e-05
10/30/2020 00:37:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 22661 Ep: 2.09 masked_t 1.656 masked_v 0.211 NSP 0.080 lr 1.01367e-05
10/30/2020 00:37:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 22681 Ep: 2.09 masked_t 1.643 masked_v 0.207 NSP 0.083 lr 1.01162e-05
10/30/2020 00:38:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 22701 Ep: 2.09 masked_t 1.577 masked_v 0.207 NSP 0.076 lr 1.00958e-05
10/30/2020 00:38:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 22721 Ep: 2.09 masked_t 1.625 masked_v 0.208 NSP 0.078 lr 1.00753e-05
10/30/2020 00:38:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 22741 Ep: 2.10 masked_t 1.615 masked_v 0.204 NSP 0.093 lr 1.00548e-05
10/30/2020 00:39:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 22761 Ep: 2.10 masked_t 1.556 masked_v 0.206 NSP 0.090 lr 1.00343e-05
10/30/2020 00:39:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 22781 Ep: 2.10 masked_t 1.597 masked_v 0.216 NSP 0.088 lr 1.00138e-05
10/30/2020 00:40:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 22801 Ep: 2.10 masked_t 1.617 masked_v 0.205 NSP 0.073 lr 9.99334e-06
10/30/2020 00:40:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 22821 Ep: 2.10 masked_t 1.638 masked_v 0.209 NSP 0.087 lr 9.97286e-06
10/30/2020 00:40:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 22841 Ep: 2.11 masked_t 1.590 masked_v 0.205 NSP 0.078 lr 9.95238e-06
10/30/2020 00:41:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 22861 Ep: 2.11 masked_t 1.670 masked_v 0.206 NSP 0.074 lr 9.9319e-06
10/30/2020 00:41:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 22881 Ep: 2.11 masked_t 1.572 masked_v 0.207 NSP 0.088 lr 9.91142e-06
10/30/2020 00:42:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 22901 Ep: 2.11 masked_t 1.632 masked_v 0.207 NSP 0.093 lr 9.89094e-06
10/30/2020 00:42:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 22921 Ep: 2.11 masked_t 1.558 masked_v 0.210 NSP 0.087 lr 9.87046e-06
10/30/2020 00:42:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 22941 Ep: 2.11 masked_t 1.620 masked_v 0.201 NSP 0.083 lr 9.84997e-06
10/30/2020 00:43:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 22961 Ep: 2.12 masked_t 1.562 masked_v 0.211 NSP 0.088 lr 9.82949e-06
10/30/2020 00:43:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 22981 Ep: 2.12 masked_t 1.612 masked_v 0.212 NSP 0.078 lr 9.80901e-06
10/30/2020 00:44:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 23001 Ep: 2.12 masked_t 1.618 masked_v 0.212 NSP 0.088 lr 9.78853e-06
10/30/2020 00:44:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 23021 Ep: 2.12 masked_t 1.547 masked_v 0.214 NSP 0.080 lr 9.76805e-06
10/30/2020 00:44:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 23041 Ep: 2.12 masked_t 1.567 masked_v 0.208 NSP 0.088 lr 9.74757e-06
10/30/2020 00:45:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 23061 Ep: 2.13 masked_t 1.571 masked_v 0.209 NSP 0.075 lr 9.72709e-06
10/30/2020 00:45:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 23081 Ep: 2.13 masked_t 1.648 masked_v 0.215 NSP 0.076 lr 9.70661e-06
10/30/2020 00:46:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 23101 Ep: 2.13 masked_t 1.636 masked_v 0.210 NSP 0.082 lr 9.68612e-06
10/30/2020 00:46:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 23121 Ep: 2.13 masked_t 1.615 masked_v 0.218 NSP 0.096 lr 9.66564e-06
10/30/2020 00:46:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 23141 Ep: 2.13 masked_t 1.672 masked_v 0.209 NSP 0.084 lr 9.64516e-06
10/30/2020 00:47:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 23161 Ep: 2.13 masked_t 1.576 masked_v 0.215 NSP 0.088 lr 9.62468e-06
10/30/2020 00:47:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 23181 Ep: 2.14 masked_t 1.709 masked_v 0.206 NSP 0.096 lr 9.6042e-06
10/30/2020 00:47:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 23201 Ep: 2.14 masked_t 1.641 masked_v 0.209 NSP 0.080 lr 9.58372e-06
10/30/2020 00:48:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 23221 Ep: 2.14 masked_t 1.605 masked_v 0.212 NSP 0.085 lr 9.56324e-06
10/30/2020 00:48:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 23241 Ep: 2.14 masked_t 1.656 masked_v 0.208 NSP 0.083 lr 9.54275e-06
10/30/2020 00:48:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 23261 Ep: 2.14 masked_t 1.646 masked_v 0.211 NSP 0.090 lr 9.52227e-06
10/30/2020 00:49:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 23281 Ep: 2.15 masked_t 1.577 masked_v 0.211 NSP 0.077 lr 9.50179e-06
10/30/2020 00:49:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 23301 Ep: 2.15 masked_t 1.562 masked_v 0.208 NSP 0.078 lr 9.48131e-06
10/30/2020 00:49:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 23321 Ep: 2.15 masked_t 1.689 masked_v 0.214 NSP 0.082 lr 9.46083e-06
10/30/2020 00:50:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 23341 Ep: 2.15 masked_t 1.527 masked_v 0.207 NSP 0.078 lr 9.44035e-06
10/30/2020 00:50:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 23361 Ep: 2.15 masked_t 1.601 masked_v 0.211 NSP 0.086 lr 9.41987e-06
10/30/2020 00:51:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 23381 Ep: 2.15 masked_t 1.517 masked_v 0.210 NSP 0.074 lr 9.39939e-06
10/30/2020 00:51:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 23401 Ep: 2.16 masked_t 1.678 masked_v 0.211 NSP 0.085 lr 9.3789e-06
10/30/2020 00:51:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 23421 Ep: 2.16 masked_t 1.537 masked_v 0.210 NSP 0.079 lr 9.35842e-06
10/30/2020 00:52:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 23441 Ep: 2.16 masked_t 1.686 masked_v 0.203 NSP 0.080 lr 9.33794e-06
10/30/2020 00:52:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 23461 Ep: 2.16 masked_t 1.439 masked_v 0.214 NSP 0.089 lr 9.31746e-06
10/30/2020 00:52:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 23481 Ep: 2.16 masked_t 1.512 masked_v 0.207 NSP 0.084 lr 9.29698e-06
10/30/2020 00:53:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 23501 Ep: 2.17 masked_t 1.623 masked_v 0.208 NSP 0.082 lr 9.2765e-06
10/30/2020 00:53:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 23521 Ep: 2.17 masked_t 1.646 masked_v 0.203 NSP 0.082 lr 9.25602e-06
10/30/2020 00:53:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 23541 Ep: 2.17 masked_t 1.570 masked_v 0.207 NSP 0.080 lr 9.23554e-06
10/30/2020 00:54:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 23561 Ep: 2.17 masked_t 1.628 masked_v 0.202 NSP 0.080 lr 9.21505e-06
10/30/2020 00:54:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 23581 Ep: 2.17 masked_t 1.618 masked_v 0.211 NSP 0.091 lr 9.19457e-06
10/30/2020 00:54:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 23601 Ep: 2.18 masked_t 1.588 masked_v 0.214 NSP 0.078 lr 9.17409e-06
10/30/2020 00:55:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 23621 Ep: 2.18 masked_t 1.665 masked_v 0.209 NSP 0.086 lr 9.15361e-06
10/30/2020 00:55:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 23641 Ep: 2.18 masked_t 1.569 masked_v 0.207 NSP 0.077 lr 9.13313e-06
10/30/2020 00:55:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 23661 Ep: 2.18 masked_t 1.620 masked_v 0.214 NSP 0.090 lr 9.11265e-06
10/30/2020 00:56:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 23681 Ep: 2.18 masked_t 1.585 masked_v 0.205 NSP 0.091 lr 9.09217e-06
10/30/2020 00:56:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 23701 Ep: 2.18 masked_t 1.588 masked_v 0.211 NSP 0.085 lr 9.07168e-06
10/30/2020 00:56:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 23721 Ep: 2.19 masked_t 1.656 masked_v 0.208 NSP 0.085 lr 9.0512e-06
10/30/2020 00:57:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 23741 Ep: 2.19 masked_t 1.684 masked_v 0.210 NSP 0.091 lr 9.03072e-06
10/30/2020 00:57:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 23761 Ep: 2.19 masked_t 1.565 masked_v 0.214 NSP 0.087 lr 9.01024e-06
10/30/2020 00:58:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 23781 Ep: 2.19 masked_t 1.535 masked_v 0.207 NSP 0.085 lr 8.98976e-06
10/30/2020 00:58:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 23801 Ep: 2.19 masked_t 1.527 masked_v 0.208 NSP 0.073 lr 8.96928e-06
10/30/2020 00:58:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 23821 Ep: 2.20 masked_t 1.528 masked_v 0.215 NSP 0.093 lr 8.9488e-06
10/30/2020 00:59:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 23841 Ep: 2.20 masked_t 1.572 masked_v 0.206 NSP 0.078 lr 8.92832e-06
10/30/2020 00:59:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 23861 Ep: 2.20 masked_t 1.680 masked_v 0.210 NSP 0.094 lr 8.90783e-06
10/30/2020 00:59:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 23881 Ep: 2.20 masked_t 1.549 masked_v 0.208 NSP 0.079 lr 8.88735e-06
10/30/2020 01:00:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 23901 Ep: 2.20 masked_t 1.609 masked_v 0.206 NSP 0.081 lr 8.86687e-06
10/30/2020 01:00:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 23921 Ep: 2.20 masked_t 1.624 masked_v 0.210 NSP 0.078 lr 8.84639e-06
10/30/2020 01:00:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 23941 Ep: 2.21 masked_t 1.588 masked_v 0.211 NSP 0.080 lr 8.82591e-06
10/30/2020 01:01:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 23961 Ep: 2.21 masked_t 1.484 masked_v 0.207 NSP 0.086 lr 8.80543e-06
10/30/2020 01:01:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 23981 Ep: 2.21 masked_t 1.613 masked_v 0.214 NSP 0.075 lr 8.78495e-06
10/30/2020 01:01:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 24001 Ep: 2.21 masked_t 1.636 masked_v 0.209 NSP 0.083 lr 8.76446e-06
10/30/2020 01:02:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 24021 Ep: 2.21 masked_t 1.645 masked_v 0.212 NSP 0.089 lr 8.74398e-06
10/30/2020 01:02:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 24041 Ep: 2.22 masked_t 1.672 masked_v 0.209 NSP 0.087 lr 8.7235e-06
10/30/2020 01:02:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 24061 Ep: 2.22 masked_t 1.604 masked_v 0.204 NSP 0.080 lr 8.70302e-06
10/30/2020 01:03:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 24081 Ep: 2.22 masked_t 1.589 masked_v 0.213 NSP 0.082 lr 8.68254e-06
10/30/2020 01:03:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 24101 Ep: 2.22 masked_t 1.588 masked_v 0.209 NSP 0.093 lr 8.66206e-06
10/30/2020 01:03:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 24121 Ep: 2.22 masked_t 1.504 masked_v 0.205 NSP 0.081 lr 8.64158e-06
10/30/2020 01:04:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 24141 Ep: 2.22 masked_t 1.639 masked_v 0.209 NSP 0.087 lr 8.6211e-06
10/30/2020 01:04:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 24161 Ep: 2.23 masked_t 1.606 masked_v 0.207 NSP 0.086 lr 8.60061e-06
10/30/2020 01:05:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 24181 Ep: 2.23 masked_t 1.653 masked_v 0.209 NSP 0.084 lr 8.58013e-06
10/30/2020 01:05:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 24201 Ep: 2.23 masked_t 1.667 masked_v 0.207 NSP 0.082 lr 8.55965e-06
10/30/2020 01:05:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 24221 Ep: 2.23 masked_t 1.659 masked_v 0.216 NSP 0.073 lr 8.53917e-06
10/30/2020 01:06:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 24241 Ep: 2.23 masked_t 1.602 masked_v 0.204 NSP 0.087 lr 8.51869e-06
10/30/2020 01:06:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 24261 Ep: 2.24 masked_t 1.661 masked_v 0.205 NSP 0.081 lr 8.49821e-06
10/30/2020 01:06:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 24281 Ep: 2.24 masked_t 1.558 masked_v 0.212 NSP 0.081 lr 8.47773e-06
10/30/2020 01:07:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 24301 Ep: 2.24 masked_t 1.553 masked_v 0.204 NSP 0.078 lr 8.45725e-06
10/30/2020 01:07:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 24321 Ep: 2.24 masked_t 1.587 masked_v 0.214 NSP 0.084 lr 8.43676e-06
10/30/2020 01:07:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 24341 Ep: 2.24 masked_t 1.624 masked_v 0.213 NSP 0.094 lr 8.41628e-06
10/30/2020 01:08:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 24361 Ep: 2.25 masked_t 1.603 masked_v 0.206 NSP 0.093 lr 8.3958e-06
10/30/2020 01:08:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 24381 Ep: 2.25 masked_t 1.621 masked_v 0.209 NSP 0.090 lr 8.37532e-06
10/30/2020 01:08:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 24401 Ep: 2.25 masked_t 1.568 masked_v 0.208 NSP 0.088 lr 8.35484e-06
10/30/2020 01:09:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 24421 Ep: 2.25 masked_t 1.650 masked_v 0.212 NSP 0.094 lr 8.33436e-06
10/30/2020 01:09:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 24441 Ep: 2.25 masked_t 1.607 masked_v 0.214 NSP 0.093 lr 8.31388e-06
10/30/2020 01:09:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 24461 Ep: 2.25 masked_t 1.554 masked_v 0.211 NSP 0.083 lr 8.29339e-06
10/30/2020 01:10:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 24481 Ep: 2.26 masked_t 1.636 masked_v 0.209 NSP 0.087 lr 8.27291e-06
10/30/2020 01:10:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 24501 Ep: 2.26 masked_t 1.614 masked_v 0.202 NSP 0.091 lr 8.25243e-06
10/30/2020 01:10:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 24521 Ep: 2.26 masked_t 1.690 masked_v 0.209 NSP 0.083 lr 8.23195e-06
10/30/2020 01:11:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 24541 Ep: 2.26 masked_t 1.617 masked_v 0.212 NSP 0.077 lr 8.21147e-06
10/30/2020 01:11:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 24561 Ep: 2.26 masked_t 1.531 masked_v 0.202 NSP 0.089 lr 8.19099e-06
10/30/2020 01:12:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 24581 Ep: 2.27 masked_t 1.641 masked_v 0.208 NSP 0.076 lr 8.17051e-06
10/30/2020 01:12:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 24601 Ep: 2.27 masked_t 1.608 masked_v 0.213 NSP 0.078 lr 8.15003e-06
10/30/2020 01:12:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 24621 Ep: 2.27 masked_t 1.543 masked_v 0.207 NSP 0.081 lr 8.12954e-06
10/30/2020 01:13:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 24641 Ep: 2.27 masked_t 1.593 masked_v 0.214 NSP 0.084 lr 8.10906e-06
10/30/2020 01:13:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 24661 Ep: 2.27 masked_t 1.565 masked_v 0.212 NSP 0.085 lr 8.08858e-06
10/30/2020 01:13:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 24681 Ep: 2.27 masked_t 1.591 masked_v 0.206 NSP 0.083 lr 8.0681e-06
10/30/2020 01:14:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 24701 Ep: 2.28 masked_t 1.581 masked_v 0.208 NSP 0.083 lr 8.04762e-06
10/30/2020 01:14:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 24721 Ep: 2.28 masked_t 1.562 masked_v 0.206 NSP 0.085 lr 8.02714e-06
10/30/2020 01:14:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 24741 Ep: 2.28 masked_t 1.565 masked_v 0.215 NSP 0.085 lr 8.00666e-06
10/30/2020 01:15:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 24761 Ep: 2.28 masked_t 1.589 masked_v 0.212 NSP 0.087 lr 7.98618e-06
10/30/2020 01:15:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 24781 Ep: 2.28 masked_t 1.573 masked_v 0.206 NSP 0.074 lr 7.96569e-06
10/30/2020 01:15:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 24801 Ep: 2.29 masked_t 1.658 masked_v 0.213 NSP 0.095 lr 7.94521e-06
10/30/2020 01:16:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 24821 Ep: 2.29 masked_t 1.664 masked_v 0.208 NSP 0.081 lr 7.92473e-06
10/30/2020 01:16:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 24841 Ep: 2.29 masked_t 1.566 masked_v 0.213 NSP 0.080 lr 7.90425e-06
10/30/2020 01:16:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 24861 Ep: 2.29 masked_t 1.623 masked_v 0.205 NSP 0.088 lr 7.88377e-06
10/30/2020 01:17:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 24881 Ep: 2.29 masked_t 1.605 masked_v 0.204 NSP 0.075 lr 7.86329e-06
10/30/2020 01:17:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 24901 Ep: 2.29 masked_t 1.543 masked_v 0.212 NSP 0.083 lr 7.84281e-06
10/30/2020 01:17:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 24921 Ep: 2.30 masked_t 1.613 masked_v 0.211 NSP 0.083 lr 7.82232e-06
10/30/2020 01:18:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 24941 Ep: 2.30 masked_t 1.696 masked_v 0.212 NSP 0.075 lr 7.80184e-06
10/30/2020 01:18:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 24961 Ep: 2.30 masked_t 1.644 masked_v 0.207 NSP 0.081 lr 7.78136e-06
10/30/2020 01:19:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 24981 Ep: 2.30 masked_t 1.576 masked_v 0.212 NSP 0.090 lr 7.76088e-06
10/30/2020 01:19:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 25001 Ep: 2.30 masked_t 1.646 masked_v 0.210 NSP 0.085 lr 7.7404e-06
10/30/2020 01:19:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 25021 Ep: 2.31 masked_t 1.631 masked_v 0.211 NSP 0.078 lr 7.71992e-06
10/30/2020 01:20:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 25041 Ep: 2.31 masked_t 1.653 masked_v 0.205 NSP 0.079 lr 7.69944e-06
10/30/2020 01:20:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 25061 Ep: 2.31 masked_t 1.606 masked_v 0.211 NSP 0.068 lr 7.67896e-06
10/30/2020 01:20:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 25081 Ep: 2.31 masked_t 1.547 masked_v 0.205 NSP 0.076 lr 7.65847e-06
10/30/2020 01:21:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 25101 Ep: 2.31 masked_t 1.504 masked_v 0.209 NSP 0.085 lr 7.63799e-06
10/30/2020 01:21:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 25121 Ep: 2.32 masked_t 1.552 masked_v 0.205 NSP 0.086 lr 7.61751e-06
10/30/2020 01:21:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 25141 Ep: 2.32 masked_t 1.645 masked_v 0.204 NSP 0.086 lr 7.59703e-06
10/30/2020 01:22:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 25161 Ep: 2.32 masked_t 1.646 masked_v 0.204 NSP 0.085 lr 7.57655e-06
10/30/2020 01:22:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 25181 Ep: 2.32 masked_t 1.579 masked_v 0.205 NSP 0.075 lr 7.55607e-06
10/30/2020 01:22:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 25201 Ep: 2.32 masked_t 1.568 masked_v 0.210 NSP 0.077 lr 7.53559e-06
10/30/2020 01:23:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 25221 Ep: 2.32 masked_t 1.607 masked_v 0.207 NSP 0.079 lr 7.5151e-06
10/30/2020 01:23:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 25241 Ep: 2.33 masked_t 1.698 masked_v 0.210 NSP 0.085 lr 7.49462e-06
10/30/2020 01:23:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 25261 Ep: 2.33 masked_t 1.592 masked_v 0.203 NSP 0.088 lr 7.47414e-06
10/30/2020 01:24:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 25281 Ep: 2.33 masked_t 1.603 masked_v 0.204 NSP 0.079 lr 7.45366e-06
10/30/2020 01:24:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 25301 Ep: 2.33 masked_t 1.650 masked_v 0.207 NSP 0.078 lr 7.43318e-06
10/30/2020 01:25:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 25321 Ep: 2.33 masked_t 1.604 masked_v 0.212 NSP 0.089 lr 7.4127e-06
10/30/2020 01:25:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 25341 Ep: 2.34 masked_t 1.539 masked_v 0.205 NSP 0.080 lr 7.39222e-06
10/30/2020 01:25:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 25361 Ep: 2.34 masked_t 1.575 masked_v 0.208 NSP 0.083 lr 7.37174e-06
10/30/2020 01:26:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 25381 Ep: 2.34 masked_t 1.585 masked_v 0.207 NSP 0.085 lr 7.35125e-06
10/30/2020 01:26:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 25401 Ep: 2.34 masked_t 1.615 masked_v 0.211 NSP 0.070 lr 7.33077e-06
10/30/2020 01:26:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 25421 Ep: 2.34 masked_t 1.553 masked_v 0.211 NSP 0.088 lr 7.31029e-06
10/30/2020 01:27:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 25441 Ep: 2.34 masked_t 1.527 masked_v 0.210 NSP 0.080 lr 7.28981e-06
10/30/2020 01:27:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 25461 Ep: 2.35 masked_t 1.643 masked_v 0.207 NSP 0.081 lr 7.26933e-06
10/30/2020 01:27:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 25481 Ep: 2.35 masked_t 1.678 masked_v 0.209 NSP 0.081 lr 7.24885e-06
10/30/2020 01:28:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 25501 Ep: 2.35 masked_t 1.612 masked_v 0.208 NSP 0.082 lr 7.22837e-06
10/30/2020 01:28:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 25521 Ep: 2.35 masked_t 1.576 masked_v 0.210 NSP 0.087 lr 7.20789e-06
10/30/2020 01:28:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 25541 Ep: 2.35 masked_t 1.545 masked_v 0.208 NSP 0.080 lr 7.1874e-06
10/30/2020 01:29:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 25561 Ep: 2.36 masked_t 1.519 masked_v 0.207 NSP 0.075 lr 7.16692e-06
10/30/2020 01:29:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 25581 Ep: 2.36 masked_t 1.563 masked_v 0.209 NSP 0.076 lr 7.14644e-06
10/30/2020 01:29:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 25601 Ep: 2.36 masked_t 1.679 masked_v 0.205 NSP 0.078 lr 7.12596e-06
10/30/2020 01:30:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 25621 Ep: 2.36 masked_t 1.624 masked_v 0.214 NSP 0.084 lr 7.10548e-06
10/30/2020 01:30:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 25641 Ep: 2.36 masked_t 1.649 masked_v 0.206 NSP 0.074 lr 7.085e-06
10/30/2020 01:30:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 25661 Ep: 2.37 masked_t 1.555 masked_v 0.216 NSP 0.076 lr 7.06452e-06
10/30/2020 01:31:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 25681 Ep: 2.37 masked_t 1.585 masked_v 0.205 NSP 0.089 lr 7.04403e-06
10/30/2020 01:31:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 25701 Ep: 2.37 masked_t 1.625 masked_v 0.207 NSP 0.080 lr 7.02355e-06
10/30/2020 01:32:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 25721 Ep: 2.37 masked_t 1.549 masked_v 0.203 NSP 0.080 lr 7.00307e-06
10/30/2020 01:32:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 25741 Ep: 2.37 masked_t 1.564 masked_v 0.209 NSP 0.075 lr 6.98259e-06
10/30/2020 01:32:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 25761 Ep: 2.37 masked_t 1.609 masked_v 0.205 NSP 0.078 lr 6.96211e-06
10/30/2020 01:33:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 25781 Ep: 2.38 masked_t 1.593 masked_v 0.212 NSP 0.075 lr 6.94163e-06
10/30/2020 01:33:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 25801 Ep: 2.38 masked_t 1.551 masked_v 0.206 NSP 0.082 lr 6.92115e-06
10/30/2020 01:33:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 25821 Ep: 2.38 masked_t 1.631 masked_v 0.209 NSP 0.078 lr 6.90067e-06
10/30/2020 01:34:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 25841 Ep: 2.38 masked_t 1.638 masked_v 0.206 NSP 0.080 lr 6.88018e-06
10/30/2020 01:34:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 25861 Ep: 2.38 masked_t 1.661 masked_v 0.207 NSP 0.082 lr 6.8597e-06
10/30/2020 01:34:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 25881 Ep: 2.39 masked_t 1.638 masked_v 0.206 NSP 0.082 lr 6.83922e-06
10/30/2020 01:35:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 25901 Ep: 2.39 masked_t 1.629 masked_v 0.208 NSP 0.073 lr 6.81874e-06
10/30/2020 01:35:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 25921 Ep: 2.39 masked_t 1.594 masked_v 0.207 NSP 0.077 lr 6.79826e-06
10/30/2020 01:35:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 25941 Ep: 2.39 masked_t 1.557 masked_v 0.209 NSP 0.083 lr 6.77778e-06
10/30/2020 01:36:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 25961 Ep: 2.39 masked_t 1.639 masked_v 0.207 NSP 0.076 lr 6.7573e-06
10/30/2020 01:36:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 25981 Ep: 2.39 masked_t 1.559 masked_v 0.201 NSP 0.079 lr 6.73682e-06
10/30/2020 01:36:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 26001 Ep: 2.40 masked_t 1.615 masked_v 0.204 NSP 0.086 lr 6.71633e-06
10/30/2020 01:37:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 26021 Ep: 2.40 masked_t 1.613 masked_v 0.214 NSP 0.083 lr 6.69585e-06
10/30/2020 01:37:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 26041 Ep: 2.40 masked_t 1.616 masked_v 0.211 NSP 0.077 lr 6.67537e-06
10/30/2020 01:37:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 26061 Ep: 2.40 masked_t 1.697 masked_v 0.213 NSP 0.094 lr 6.65489e-06
10/30/2020 01:38:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 26081 Ep: 2.40 masked_t 1.583 masked_v 0.206 NSP 0.079 lr 6.63441e-06
10/30/2020 01:38:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 26101 Ep: 2.41 masked_t 1.653 masked_v 0.209 NSP 0.075 lr 6.61393e-06
10/30/2020 01:39:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 26121 Ep: 2.41 masked_t 1.581 masked_v 0.211 NSP 0.075 lr 6.59345e-06
10/30/2020 01:39:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 26141 Ep: 2.41 masked_t 1.564 masked_v 0.211 NSP 0.083 lr 6.57296e-06
10/30/2020 01:39:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 26161 Ep: 2.41 masked_t 1.563 masked_v 0.204 NSP 0.083 lr 6.55248e-06
10/30/2020 01:40:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 26181 Ep: 2.41 masked_t 1.567 masked_v 0.210 NSP 0.082 lr 6.532e-06
10/30/2020 01:40:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 26201 Ep: 2.41 masked_t 1.629 masked_v 0.209 NSP 0.069 lr 6.51152e-06
10/30/2020 01:40:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 26221 Ep: 2.42 masked_t 1.571 masked_v 0.211 NSP 0.088 lr 6.49104e-06
10/30/2020 01:41:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 26241 Ep: 2.42 masked_t 1.605 masked_v 0.204 NSP 0.085 lr 6.47056e-06
10/30/2020 01:41:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 26261 Ep: 2.42 masked_t 1.525 masked_v 0.209 NSP 0.073 lr 6.45008e-06
10/30/2020 01:41:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 26281 Ep: 2.42 masked_t 1.662 masked_v 0.214 NSP 0.081 lr 6.4296e-06
10/30/2020 01:42:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 26301 Ep: 2.42 masked_t 1.609 masked_v 0.206 NSP 0.084 lr 6.40911e-06
10/30/2020 01:42:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 26321 Ep: 2.43 masked_t 1.610 masked_v 0.210 NSP 0.081 lr 6.38863e-06
10/30/2020 01:42:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 26341 Ep: 2.43 masked_t 1.596 masked_v 0.208 NSP 0.086 lr 6.36815e-06
10/30/2020 01:43:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 26361 Ep: 2.43 masked_t 1.630 masked_v 0.208 NSP 0.089 lr 6.34767e-06
10/30/2020 01:43:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 26381 Ep: 2.43 masked_t 1.649 masked_v 0.212 NSP 0.090 lr 6.32719e-06
10/30/2020 01:43:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 26401 Ep: 2.43 masked_t 1.573 masked_v 0.201 NSP 0.080 lr 6.30671e-06
10/30/2020 01:44:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 26421 Ep: 2.44 masked_t 1.600 masked_v 0.210 NSP 0.089 lr 6.28623e-06
10/30/2020 01:44:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 26441 Ep: 2.44 masked_t 1.572 masked_v 0.205 NSP 0.076 lr 6.26575e-06
10/30/2020 01:44:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 26461 Ep: 2.44 masked_t 1.657 masked_v 0.208 NSP 0.083 lr 6.24526e-06
10/30/2020 01:45:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 26481 Ep: 2.44 masked_t 1.595 masked_v 0.206 NSP 0.092 lr 6.22478e-06
10/30/2020 01:45:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 26501 Ep: 2.44 masked_t 1.591 masked_v 0.202 NSP 0.085 lr 6.2043e-06
10/30/2020 01:46:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 26521 Ep: 2.44 masked_t 1.592 masked_v 0.205 NSP 0.082 lr 6.18382e-06
10/30/2020 01:46:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 26541 Ep: 2.45 masked_t 1.527 masked_v 0.205 NSP 0.087 lr 6.16334e-06
10/30/2020 01:46:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 26561 Ep: 2.45 masked_t 1.559 masked_v 0.206 NSP 0.077 lr 6.14286e-06
10/30/2020 01:47:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 26581 Ep: 2.45 masked_t 1.578 masked_v 0.202 NSP 0.081 lr 6.12238e-06
10/30/2020 01:47:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 26601 Ep: 2.45 masked_t 1.576 masked_v 0.210 NSP 0.077 lr 6.10189e-06
10/30/2020 01:47:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 26621 Ep: 2.45 masked_t 1.612 masked_v 0.204 NSP 0.094 lr 6.08141e-06
10/30/2020 01:48:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 26641 Ep: 2.46 masked_t 1.677 masked_v 0.203 NSP 0.080 lr 6.06093e-06
10/30/2020 01:48:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 26661 Ep: 2.46 masked_t 1.605 masked_v 0.210 NSP 0.074 lr 6.04045e-06
10/30/2020 01:48:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 26681 Ep: 2.46 masked_t 1.587 masked_v 0.212 NSP 0.078 lr 6.01997e-06
10/30/2020 01:49:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 26701 Ep: 2.46 masked_t 1.606 masked_v 0.204 NSP 0.083 lr 5.99949e-06
10/30/2020 01:49:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 26721 Ep: 2.46 masked_t 1.629 masked_v 0.206 NSP 0.085 lr 5.97901e-06
10/30/2020 01:49:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 26741 Ep: 2.46 masked_t 1.618 masked_v 0.204 NSP 0.079 lr 5.95853e-06
10/30/2020 01:50:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 26761 Ep: 2.47 masked_t 1.565 masked_v 0.207 NSP 0.082 lr 5.93804e-06
10/30/2020 01:50:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 26781 Ep: 2.47 masked_t 1.622 masked_v 0.211 NSP 0.082 lr 5.91756e-06
10/30/2020 01:50:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 26801 Ep: 2.47 masked_t 1.586 masked_v 0.205 NSP 0.081 lr 5.89708e-06
10/30/2020 01:51:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 26821 Ep: 2.47 masked_t 1.548 masked_v 0.201 NSP 0.075 lr 5.8766e-06
10/30/2020 01:51:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 26841 Ep: 2.47 masked_t 1.645 masked_v 0.206 NSP 0.086 lr 5.85612e-06
10/30/2020 01:51:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 26861 Ep: 2.48 masked_t 1.644 masked_v 0.202 NSP 0.080 lr 5.83564e-06
10/30/2020 01:52:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 26881 Ep: 2.48 masked_t 1.562 masked_v 0.200 NSP 0.077 lr 5.81516e-06
10/30/2020 01:52:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 26901 Ep: 2.48 masked_t 1.586 masked_v 0.209 NSP 0.087 lr 5.79467e-06
10/30/2020 01:53:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 26921 Ep: 2.48 masked_t 1.597 masked_v 0.209 NSP 0.087 lr 5.77419e-06
10/30/2020 01:53:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 26941 Ep: 2.48 masked_t 1.589 masked_v 0.208 NSP 0.088 lr 5.75371e-06
10/30/2020 01:53:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 26961 Ep: 2.48 masked_t 1.576 masked_v 0.204 NSP 0.081 lr 5.73323e-06
10/30/2020 01:54:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 26981 Ep: 2.49 masked_t 1.574 masked_v 0.206 NSP 0.079 lr 5.71275e-06
10/30/2020 01:54:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 27001 Ep: 2.49 masked_t 1.590 masked_v 0.207 NSP 0.074 lr 5.69227e-06
10/30/2020 01:54:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 27021 Ep: 2.49 masked_t 1.588 masked_v 0.211 NSP 0.087 lr 5.67179e-06
10/30/2020 01:55:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 27041 Ep: 2.49 masked_t 1.611 masked_v 0.207 NSP 0.085 lr 5.65131e-06
10/30/2020 01:55:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 27061 Ep: 2.49 masked_t 1.584 masked_v 0.209 NSP 0.082 lr 5.63082e-06
10/30/2020 01:55:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 27081 Ep: 2.50 masked_t 1.598 masked_v 0.207 NSP 0.089 lr 5.61034e-06
10/30/2020 01:56:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 27101 Ep: 2.50 masked_t 1.522 masked_v 0.203 NSP 0.077 lr 5.58986e-06
10/30/2020 01:56:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 27121 Ep: 2.50 masked_t 1.537 masked_v 0.205 NSP 0.086 lr 5.56938e-06
10/30/2020 01:56:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 27141 Ep: 2.50 masked_t 1.526 masked_v 0.207 NSP 0.074 lr 5.5489e-06
10/30/2020 01:57:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 27161 Ep: 2.50 masked_t 1.520 masked_v 0.204 NSP 0.082 lr 5.52842e-06
10/30/2020 01:57:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 27181 Ep: 2.51 masked_t 1.630 masked_v 0.206 NSP 0.078 lr 5.50794e-06
10/30/2020 01:57:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 27201 Ep: 2.51 masked_t 1.520 masked_v 0.208 NSP 0.085 lr 5.48746e-06
10/30/2020 01:58:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 27221 Ep: 2.51 masked_t 1.650 masked_v 0.214 NSP 0.072 lr 5.46697e-06
10/30/2020 01:58:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 27241 Ep: 2.51 masked_t 1.592 masked_v 0.210 NSP 0.074 lr 5.44649e-06
10/30/2020 01:58:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 27261 Ep: 2.51 masked_t 1.583 masked_v 0.206 NSP 0.088 lr 5.42601e-06
10/30/2020 01:59:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 27281 Ep: 2.51 masked_t 1.595 masked_v 0.205 NSP 0.078 lr 5.40553e-06
10/30/2020 01:59:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 27301 Ep: 2.52 masked_t 1.527 masked_v 0.202 NSP 0.087 lr 5.38505e-06
10/30/2020 02:00:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 27321 Ep: 2.52 masked_t 1.575 masked_v 0.202 NSP 0.073 lr 5.36457e-06
10/30/2020 02:00:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 27341 Ep: 2.52 masked_t 1.659 masked_v 0.210 NSP 0.076 lr 5.34409e-06
10/30/2020 02:00:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 27361 Ep: 2.52 masked_t 1.579 masked_v 0.214 NSP 0.087 lr 5.3236e-06
10/30/2020 02:01:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 27381 Ep: 2.52 masked_t 1.525 masked_v 0.203 NSP 0.098 lr 5.30312e-06
10/30/2020 02:01:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 27401 Ep: 2.53 masked_t 1.508 masked_v 0.204 NSP 0.081 lr 5.28264e-06
10/30/2020 02:01:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 27421 Ep: 2.53 masked_t 1.625 masked_v 0.205 NSP 0.078 lr 5.26216e-06
10/30/2020 02:02:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 27441 Ep: 2.53 masked_t 1.583 masked_v 0.203 NSP 0.071 lr 5.24168e-06
10/30/2020 02:02:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 27461 Ep: 2.53 masked_t 1.583 masked_v 0.201 NSP 0.084 lr 5.2212e-06
10/30/2020 02:02:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 27481 Ep: 2.53 masked_t 1.588 masked_v 0.210 NSP 0.086 lr 5.20072e-06
10/30/2020 02:03:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 27501 Ep: 2.53 masked_t 1.568 masked_v 0.206 NSP 0.079 lr 5.18024e-06
10/30/2020 02:03:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 27521 Ep: 2.54 masked_t 1.676 masked_v 0.209 NSP 0.086 lr 5.15975e-06
10/30/2020 02:03:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 27541 Ep: 2.54 masked_t 1.553 masked_v 0.206 NSP 0.074 lr 5.13927e-06
10/30/2020 02:04:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 27561 Ep: 2.54 masked_t 1.726 masked_v 0.205 NSP 0.073 lr 5.11879e-06
10/30/2020 02:04:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 27581 Ep: 2.54 masked_t 1.571 masked_v 0.202 NSP 0.090 lr 5.09831e-06
10/30/2020 02:04:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 27601 Ep: 2.54 masked_t 1.658 masked_v 0.203 NSP 0.071 lr 5.07783e-06
10/30/2020 02:05:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 27621 Ep: 2.55 masked_t 1.599 masked_v 0.200 NSP 0.078 lr 5.05735e-06
10/30/2020 02:05:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 27641 Ep: 2.55 masked_t 1.548 masked_v 0.210 NSP 0.075 lr 5.03687e-06
10/30/2020 02:05:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 27661 Ep: 2.55 masked_t 1.639 masked_v 0.205 NSP 0.083 lr 5.01639e-06
10/30/2020 02:06:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 27681 Ep: 2.55 masked_t 1.635 masked_v 0.206 NSP 0.072 lr 4.9959e-06
10/30/2020 02:06:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 27701 Ep: 2.55 masked_t 1.553 masked_v 0.203 NSP 0.086 lr 4.97542e-06
10/30/2020 02:06:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 27721 Ep: 2.55 masked_t 1.584 masked_v 0.204 NSP 0.075 lr 4.95494e-06
10/30/2020 02:07:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 27741 Ep: 2.56 masked_t 1.559 masked_v 0.207 NSP 0.073 lr 4.93446e-06
10/30/2020 02:07:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 27761 Ep: 2.56 masked_t 1.604 masked_v 0.203 NSP 0.088 lr 4.91398e-06
10/30/2020 02:08:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 27781 Ep: 2.56 masked_t 1.637 masked_v 0.203 NSP 0.087 lr 4.8935e-06
10/30/2020 02:08:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 27801 Ep: 2.56 masked_t 1.532 masked_v 0.207 NSP 0.091 lr 4.87302e-06
10/30/2020 02:08:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 27821 Ep: 2.56 masked_t 1.582 masked_v 0.205 NSP 0.085 lr 4.85253e-06
10/30/2020 02:09:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 27841 Ep: 2.57 masked_t 1.571 masked_v 0.210 NSP 0.076 lr 4.83205e-06
10/30/2020 02:09:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 27861 Ep: 2.57 masked_t 1.598 masked_v 0.210 NSP 0.066 lr 4.81157e-06
10/30/2020 02:09:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 27881 Ep: 2.57 masked_t 1.594 masked_v 0.207 NSP 0.089 lr 4.79109e-06
10/30/2020 02:10:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 27901 Ep: 2.57 masked_t 1.613 masked_v 0.207 NSP 0.074 lr 4.77061e-06
10/30/2020 02:10:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 27921 Ep: 2.57 masked_t 1.608 masked_v 0.208 NSP 0.080 lr 4.75013e-06
10/30/2020 02:10:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 27941 Ep: 2.58 masked_t 1.594 masked_v 0.203 NSP 0.080 lr 4.72965e-06
10/30/2020 02:11:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 27961 Ep: 2.58 masked_t 1.611 masked_v 0.204 NSP 0.079 lr 4.70917e-06
10/30/2020 02:11:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 27981 Ep: 2.58 masked_t 1.609 masked_v 0.204 NSP 0.079 lr 4.68868e-06
10/30/2020 02:11:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 28001 Ep: 2.58 masked_t 1.562 masked_v 0.208 NSP 0.087 lr 4.6682e-06
10/30/2020 02:12:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 28021 Ep: 2.58 masked_t 1.583 masked_v 0.209 NSP 0.087 lr 4.64772e-06
10/30/2020 02:12:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 28041 Ep: 2.58 masked_t 1.599 masked_v 0.208 NSP 0.083 lr 4.62724e-06
10/30/2020 02:12:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 28061 Ep: 2.59 masked_t 1.666 masked_v 0.206 NSP 0.086 lr 4.60676e-06
10/30/2020 02:13:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 28081 Ep: 2.59 masked_t 1.603 masked_v 0.207 NSP 0.076 lr 4.58628e-06
10/30/2020 02:13:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 28101 Ep: 2.59 masked_t 1.629 masked_v 0.205 NSP 0.089 lr 4.5658e-06
10/30/2020 02:13:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 28121 Ep: 2.59 masked_t 1.610 masked_v 0.205 NSP 0.083 lr 4.54531e-06
10/30/2020 02:14:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 28141 Ep: 2.59 masked_t 1.617 masked_v 0.211 NSP 0.078 lr 4.52483e-06
10/30/2020 02:14:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 28161 Ep: 2.60 masked_t 1.500 masked_v 0.207 NSP 0.080 lr 4.50435e-06
10/30/2020 02:14:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 28181 Ep: 2.60 masked_t 1.620 masked_v 0.202 NSP 0.081 lr 4.48387e-06
10/30/2020 02:15:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 28201 Ep: 2.60 masked_t 1.526 masked_v 0.205 NSP 0.079 lr 4.46339e-06
10/30/2020 02:15:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 28221 Ep: 2.60 masked_t 1.644 masked_v 0.210 NSP 0.081 lr 4.44291e-06
10/30/2020 02:16:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 28241 Ep: 2.60 masked_t 1.577 masked_v 0.203 NSP 0.081 lr 4.42243e-06
10/30/2020 02:16:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 28261 Ep: 2.60 masked_t 1.570 masked_v 0.211 NSP 0.080 lr 4.40195e-06
10/30/2020 02:16:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 28281 Ep: 2.61 masked_t 1.622 masked_v 0.208 NSP 0.084 lr 4.38146e-06
10/30/2020 02:17:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 28301 Ep: 2.61 masked_t 1.677 masked_v 0.212 NSP 0.086 lr 4.36098e-06
10/30/2020 02:17:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 28321 Ep: 2.61 masked_t 1.577 masked_v 0.212 NSP 0.072 lr 4.3405e-06
10/30/2020 02:17:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 28341 Ep: 2.61 masked_t 1.565 masked_v 0.205 NSP 0.085 lr 4.32002e-06
10/30/2020 02:18:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 28361 Ep: 2.61 masked_t 1.569 masked_v 0.205 NSP 0.078 lr 4.29954e-06
10/30/2020 02:18:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 28381 Ep: 2.62 masked_t 1.708 masked_v 0.201 NSP 0.080 lr 4.27906e-06
10/30/2020 02:18:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 28401 Ep: 2.62 masked_t 1.633 masked_v 0.206 NSP 0.083 lr 4.25858e-06
10/30/2020 02:19:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 28421 Ep: 2.62 masked_t 1.549 masked_v 0.212 NSP 0.082 lr 4.2381e-06
10/30/2020 02:19:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 28441 Ep: 2.62 masked_t 1.488 masked_v 0.203 NSP 0.077 lr 4.21761e-06
10/30/2020 02:20:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 28461 Ep: 2.62 masked_t 1.623 masked_v 0.199 NSP 0.069 lr 4.19713e-06
10/30/2020 02:20:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 28481 Ep: 2.62 masked_t 1.616 masked_v 0.204 NSP 0.079 lr 4.17665e-06
10/30/2020 02:20:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 28501 Ep: 2.63 masked_t 1.636 masked_v 0.208 NSP 0.090 lr 4.15617e-06
10/30/2020 02:21:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 28521 Ep: 2.63 masked_t 1.537 masked_v 0.202 NSP 0.080 lr 4.13569e-06
10/30/2020 02:21:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 28541 Ep: 2.63 masked_t 1.598 masked_v 0.207 NSP 0.075 lr 4.11521e-06
10/30/2020 02:21:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 28561 Ep: 2.63 masked_t 1.473 masked_v 0.209 NSP 0.072 lr 4.09473e-06
10/30/2020 02:22:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 28581 Ep: 2.63 masked_t 1.664 masked_v 0.205 NSP 0.089 lr 4.07424e-06
10/30/2020 02:22:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 28601 Ep: 2.64 masked_t 1.613 masked_v 0.204 NSP 0.086 lr 4.05376e-06
10/30/2020 02:22:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 28621 Ep: 2.64 masked_t 1.569 masked_v 0.210 NSP 0.074 lr 4.03328e-06
10/30/2020 02:23:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 28641 Ep: 2.64 masked_t 1.539 masked_v 0.207 NSP 0.076 lr 4.0128e-06
10/30/2020 02:23:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 28661 Ep: 2.64 masked_t 1.719 masked_v 0.204 NSP 0.083 lr 3.99232e-06
10/30/2020 02:24:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 28681 Ep: 2.64 masked_t 1.590 masked_v 0.201 NSP 0.082 lr 3.97184e-06
10/30/2020 02:24:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 28701 Ep: 2.65 masked_t 1.519 masked_v 0.209 NSP 0.082 lr 3.95136e-06
10/30/2020 02:24:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 28721 Ep: 2.65 masked_t 1.569 masked_v 0.208 NSP 0.086 lr 3.93088e-06
10/30/2020 02:25:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 28741 Ep: 2.65 masked_t 1.558 masked_v 0.202 NSP 0.084 lr 3.91039e-06
10/30/2020 02:25:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 28761 Ep: 2.65 masked_t 1.530 masked_v 0.208 NSP 0.070 lr 3.88991e-06
10/30/2020 02:25:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 28781 Ep: 2.65 masked_t 1.629 masked_v 0.204 NSP 0.082 lr 3.86943e-06
10/30/2020 02:26:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 28801 Ep: 2.65 masked_t 1.610 masked_v 0.204 NSP 0.086 lr 3.84895e-06
10/30/2020 02:26:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 28821 Ep: 2.66 masked_t 1.527 masked_v 0.201 NSP 0.082 lr 3.82847e-06
10/30/2020 02:26:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 28841 Ep: 2.66 masked_t 1.672 masked_v 0.211 NSP 0.071 lr 3.80799e-06
10/30/2020 02:27:15 - INFO - volta.utils -   [Conceptual_Caption]: iter 28861 Ep: 2.66 masked_t 1.608 masked_v 0.207 NSP 0.086 lr 3.78751e-06
10/30/2020 02:27:37 - INFO - volta.utils -   [Conceptual_Caption]: iter 28881 Ep: 2.66 masked_t 1.580 masked_v 0.208 NSP 0.073 lr 3.76703e-06
10/30/2020 02:28:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 28901 Ep: 2.66 masked_t 1.665 masked_v 0.207 NSP 0.080 lr 3.74654e-06
10/30/2020 02:28:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 28921 Ep: 2.67 masked_t 1.558 masked_v 0.208 NSP 0.082 lr 3.72606e-06
10/30/2020 02:28:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 28941 Ep: 2.67 masked_t 1.636 masked_v 0.203 NSP 0.081 lr 3.70558e-06
10/30/2020 02:29:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 28961 Ep: 2.67 masked_t 1.535 masked_v 0.211 NSP 0.075 lr 3.6851e-06
10/30/2020 02:29:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 28981 Ep: 2.67 masked_t 1.595 masked_v 0.209 NSP 0.072 lr 3.66462e-06
10/30/2020 02:29:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 29001 Ep: 2.67 masked_t 1.674 masked_v 0.201 NSP 0.076 lr 3.64414e-06
10/30/2020 02:30:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 29021 Ep: 2.67 masked_t 1.625 masked_v 0.210 NSP 0.073 lr 3.62366e-06
10/30/2020 02:30:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 29041 Ep: 2.68 masked_t 1.665 masked_v 0.207 NSP 0.070 lr 3.60317e-06
10/30/2020 02:31:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 29061 Ep: 2.68 masked_t 1.620 masked_v 0.205 NSP 0.079 lr 3.58269e-06
10/30/2020 02:31:27 - INFO - volta.utils -   [Conceptual_Caption]: iter 29081 Ep: 2.68 masked_t 1.570 masked_v 0.208 NSP 0.079 lr 3.56221e-06
10/30/2020 02:31:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 29101 Ep: 2.68 masked_t 1.569 masked_v 0.211 NSP 0.077 lr 3.54173e-06
10/30/2020 02:32:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 29121 Ep: 2.68 masked_t 1.567 masked_v 0.203 NSP 0.077 lr 3.52125e-06
10/30/2020 02:32:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 29141 Ep: 2.69 masked_t 1.566 masked_v 0.204 NSP 0.077 lr 3.50077e-06
10/30/2020 02:32:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 29161 Ep: 2.69 masked_t 1.587 masked_v 0.207 NSP 0.077 lr 3.48029e-06
10/30/2020 02:33:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 29181 Ep: 2.69 masked_t 1.637 masked_v 0.203 NSP 0.078 lr 3.45981e-06
10/30/2020 02:33:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 29201 Ep: 2.69 masked_t 1.655 masked_v 0.204 NSP 0.083 lr 3.43932e-06
10/30/2020 02:34:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 29221 Ep: 2.69 masked_t 1.574 masked_v 0.214 NSP 0.077 lr 3.41884e-06
10/30/2020 02:34:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 29241 Ep: 2.69 masked_t 1.607 masked_v 0.209 NSP 0.072 lr 3.39836e-06
10/30/2020 02:34:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 29261 Ep: 2.70 masked_t 1.491 masked_v 0.208 NSP 0.078 lr 3.37788e-06
10/30/2020 02:35:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 29281 Ep: 2.70 masked_t 1.582 masked_v 0.208 NSP 0.076 lr 3.3574e-06
10/30/2020 02:35:33 - INFO - volta.utils -   [Conceptual_Caption]: iter 29301 Ep: 2.70 masked_t 1.604 masked_v 0.209 NSP 0.085 lr 3.33692e-06
10/30/2020 02:35:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 29321 Ep: 2.70 masked_t 1.614 masked_v 0.200 NSP 0.082 lr 3.31644e-06
10/30/2020 02:36:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 29341 Ep: 2.70 masked_t 1.572 masked_v 0.202 NSP 0.080 lr 3.29595e-06
10/30/2020 02:36:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 29361 Ep: 2.71 masked_t 1.648 masked_v 0.205 NSP 0.082 lr 3.27547e-06
10/30/2020 02:37:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 29381 Ep: 2.71 masked_t 1.671 masked_v 0.202 NSP 0.081 lr 3.25499e-06
10/30/2020 02:37:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 29401 Ep: 2.71 masked_t 1.601 masked_v 0.211 NSP 0.084 lr 3.23451e-06
10/30/2020 02:37:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 29421 Ep: 2.71 masked_t 1.555 masked_v 0.206 NSP 0.079 lr 3.21403e-06
10/30/2020 02:38:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 29441 Ep: 2.71 masked_t 1.619 masked_v 0.211 NSP 0.078 lr 3.19355e-06
10/30/2020 02:38:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 29461 Ep: 2.72 masked_t 1.556 masked_v 0.209 NSP 0.076 lr 3.17307e-06
10/30/2020 02:38:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 29481 Ep: 2.72 masked_t 1.532 masked_v 0.207 NSP 0.081 lr 3.15259e-06
10/30/2020 02:39:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 29501 Ep: 2.72 masked_t 1.640 masked_v 0.204 NSP 0.079 lr 3.1321e-06
10/30/2020 02:39:36 - INFO - volta.utils -   [Conceptual_Caption]: iter 29521 Ep: 2.72 masked_t 1.620 masked_v 0.205 NSP 0.088 lr 3.11162e-06
10/30/2020 02:39:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 29541 Ep: 2.72 masked_t 1.544 masked_v 0.203 NSP 0.084 lr 3.09114e-06
10/30/2020 02:40:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 29561 Ep: 2.72 masked_t 1.632 masked_v 0.206 NSP 0.067 lr 3.07066e-06
10/30/2020 02:40:43 - INFO - volta.utils -   [Conceptual_Caption]: iter 29581 Ep: 2.73 masked_t 1.523 masked_v 0.203 NSP 0.087 lr 3.05018e-06
10/30/2020 02:41:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 29601 Ep: 2.73 masked_t 1.561 masked_v 0.206 NSP 0.082 lr 3.0297e-06
10/30/2020 02:41:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 29621 Ep: 2.73 masked_t 1.674 masked_v 0.208 NSP 0.072 lr 3.00922e-06
10/30/2020 02:41:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 29641 Ep: 2.73 masked_t 1.572 masked_v 0.206 NSP 0.071 lr 2.98874e-06
10/30/2020 02:42:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 29661 Ep: 2.73 masked_t 1.506 masked_v 0.210 NSP 0.077 lr 2.96825e-06
10/30/2020 02:42:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 29681 Ep: 2.74 masked_t 1.562 masked_v 0.210 NSP 0.069 lr 2.94777e-06
10/30/2020 02:42:52 - INFO - volta.utils -   [Conceptual_Caption]: iter 29701 Ep: 2.74 masked_t 1.564 masked_v 0.208 NSP 0.081 lr 2.92729e-06
10/30/2020 02:43:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 29721 Ep: 2.74 masked_t 1.562 masked_v 0.205 NSP 0.069 lr 2.90681e-06
10/30/2020 02:43:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 29741 Ep: 2.74 masked_t 1.695 masked_v 0.207 NSP 0.079 lr 2.88633e-06
10/30/2020 02:43:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 29761 Ep: 2.74 masked_t 1.512 masked_v 0.204 NSP 0.084 lr 2.86585e-06
10/30/2020 02:44:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 29781 Ep: 2.74 masked_t 1.598 masked_v 0.209 NSP 0.065 lr 2.84537e-06
10/30/2020 02:44:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 29801 Ep: 2.75 masked_t 1.651 masked_v 0.205 NSP 0.075 lr 2.82488e-06
10/30/2020 02:45:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 29821 Ep: 2.75 masked_t 1.582 masked_v 0.208 NSP 0.086 lr 2.8044e-06
10/30/2020 02:45:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 29841 Ep: 2.75 masked_t 1.546 masked_v 0.204 NSP 0.073 lr 2.78392e-06
10/30/2020 02:45:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 29861 Ep: 2.75 masked_t 1.614 masked_v 0.211 NSP 0.074 lr 2.76344e-06
10/30/2020 02:46:09 - INFO - volta.utils -   [Conceptual_Caption]: iter 29881 Ep: 2.75 masked_t 1.658 masked_v 0.207 NSP 0.075 lr 2.74296e-06
10/30/2020 02:46:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 29901 Ep: 2.76 masked_t 1.586 masked_v 0.209 NSP 0.067 lr 2.72248e-06
10/30/2020 02:46:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 29921 Ep: 2.76 masked_t 1.568 masked_v 0.202 NSP 0.081 lr 2.702e-06
10/30/2020 02:47:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 29941 Ep: 2.76 masked_t 1.632 masked_v 0.207 NSP 0.076 lr 2.68152e-06
10/30/2020 02:47:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 29961 Ep: 2.76 masked_t 1.579 masked_v 0.206 NSP 0.082 lr 2.66103e-06
10/30/2020 02:47:58 - INFO - volta.utils -   [Conceptual_Caption]: iter 29981 Ep: 2.76 masked_t 1.589 masked_v 0.208 NSP 0.071 lr 2.64055e-06
10/30/2020 02:48:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 30001 Ep: 2.77 masked_t 1.600 masked_v 0.203 NSP 0.075 lr 2.62007e-06
10/30/2020 02:48:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 30021 Ep: 2.77 masked_t 1.586 masked_v 0.210 NSP 0.077 lr 2.59959e-06
10/30/2020 02:49:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 30041 Ep: 2.77 masked_t 1.562 masked_v 0.202 NSP 0.075 lr 2.57911e-06
10/30/2020 02:49:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 30061 Ep: 2.77 masked_t 1.518 masked_v 0.206 NSP 0.084 lr 2.55863e-06
10/30/2020 02:49:48 - INFO - volta.utils -   [Conceptual_Caption]: iter 30081 Ep: 2.77 masked_t 1.554 masked_v 0.206 NSP 0.082 lr 2.53815e-06
10/30/2020 02:50:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 30101 Ep: 2.77 masked_t 1.477 masked_v 0.204 NSP 0.090 lr 2.51767e-06
10/30/2020 02:50:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 30121 Ep: 2.78 masked_t 1.609 masked_v 0.203 NSP 0.090 lr 2.49718e-06
10/30/2020 02:50:54 - INFO - volta.utils -   [Conceptual_Caption]: iter 30141 Ep: 2.78 masked_t 1.681 masked_v 0.209 NSP 0.084 lr 2.4767e-06
10/30/2020 02:51:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 30161 Ep: 2.78 masked_t 1.574 masked_v 0.209 NSP 0.080 lr 2.45622e-06
10/30/2020 02:51:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 30181 Ep: 2.78 masked_t 1.661 masked_v 0.210 NSP 0.082 lr 2.43574e-06
10/30/2020 02:52:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 30201 Ep: 2.78 masked_t 1.584 masked_v 0.206 NSP 0.075 lr 2.41526e-06
10/30/2020 02:52:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 30221 Ep: 2.79 masked_t 1.640 masked_v 0.209 NSP 0.080 lr 2.39478e-06
10/30/2020 02:52:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 30241 Ep: 2.79 masked_t 1.607 masked_v 0.209 NSP 0.082 lr 2.3743e-06
10/30/2020 02:53:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 30261 Ep: 2.79 masked_t 1.602 masked_v 0.206 NSP 0.079 lr 2.35381e-06
10/30/2020 02:53:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 30281 Ep: 2.79 masked_t 1.531 masked_v 0.206 NSP 0.075 lr 2.33333e-06
10/30/2020 02:53:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 30301 Ep: 2.79 masked_t 1.562 masked_v 0.203 NSP 0.081 lr 2.31285e-06
10/30/2020 02:54:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 30321 Ep: 2.79 masked_t 1.594 masked_v 0.207 NSP 0.067 lr 2.29237e-06
10/30/2020 02:54:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 30341 Ep: 2.80 masked_t 1.609 masked_v 0.203 NSP 0.073 lr 2.27189e-06
10/30/2020 02:55:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 30361 Ep: 2.80 masked_t 1.496 masked_v 0.206 NSP 0.083 lr 2.25141e-06
10/30/2020 02:55:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 30381 Ep: 2.80 masked_t 1.568 masked_v 0.211 NSP 0.067 lr 2.23093e-06
10/30/2020 02:55:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 30401 Ep: 2.80 masked_t 1.517 masked_v 0.198 NSP 0.076 lr 2.21045e-06
10/30/2020 02:56:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 30421 Ep: 2.80 masked_t 1.593 masked_v 0.211 NSP 0.076 lr 2.18996e-06
10/30/2020 02:56:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 30441 Ep: 2.81 masked_t 1.642 masked_v 0.205 NSP 0.081 lr 2.16948e-06
10/30/2020 02:56:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 30461 Ep: 2.81 masked_t 1.606 masked_v 0.201 NSP 0.075 lr 2.149e-06
10/30/2020 02:57:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 30481 Ep: 2.81 masked_t 1.639 masked_v 0.208 NSP 0.069 lr 2.12852e-06
10/30/2020 02:57:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 30501 Ep: 2.81 masked_t 1.542 masked_v 0.204 NSP 0.084 lr 2.10804e-06
10/30/2020 02:57:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 30521 Ep: 2.81 masked_t 1.572 masked_v 0.207 NSP 0.092 lr 2.08756e-06
10/30/2020 02:58:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 30541 Ep: 2.81 masked_t 1.601 masked_v 0.209 NSP 0.077 lr 2.06708e-06
10/30/2020 02:58:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 30561 Ep: 2.82 masked_t 1.599 masked_v 0.203 NSP 0.086 lr 2.04659e-06
10/30/2020 02:59:03 - INFO - volta.utils -   [Conceptual_Caption]: iter 30581 Ep: 2.82 masked_t 1.549 masked_v 0.200 NSP 0.080 lr 2.02611e-06
10/30/2020 02:59:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 30601 Ep: 2.82 masked_t 1.539 masked_v 0.209 NSP 0.071 lr 2.00563e-06
10/30/2020 02:59:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 30621 Ep: 2.82 masked_t 1.615 masked_v 0.208 NSP 0.084 lr 1.98515e-06
10/30/2020 03:00:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 30641 Ep: 2.82 masked_t 1.544 masked_v 0.205 NSP 0.084 lr 1.96467e-06
10/30/2020 03:00:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 30661 Ep: 2.83 masked_t 1.579 masked_v 0.207 NSP 0.082 lr 1.94419e-06
10/30/2020 03:00:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 30681 Ep: 2.83 masked_t 1.565 masked_v 0.204 NSP 0.073 lr 1.92371e-06
10/30/2020 03:01:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 30701 Ep: 2.83 masked_t 1.560 masked_v 0.213 NSP 0.086 lr 1.90323e-06
10/30/2020 03:01:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 30721 Ep: 2.83 masked_t 1.541 masked_v 0.207 NSP 0.082 lr 1.88274e-06
10/30/2020 03:01:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 30741 Ep: 2.83 masked_t 1.559 masked_v 0.209 NSP 0.075 lr 1.86226e-06
10/30/2020 03:02:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 30761 Ep: 2.84 masked_t 1.532 masked_v 0.206 NSP 0.078 lr 1.84178e-06
10/30/2020 03:02:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 30781 Ep: 2.84 masked_t 1.624 masked_v 0.207 NSP 0.073 lr 1.8213e-06
10/30/2020 03:03:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 30801 Ep: 2.84 masked_t 1.511 masked_v 0.207 NSP 0.078 lr 1.80082e-06
10/30/2020 03:03:22 - INFO - volta.utils -   [Conceptual_Caption]: iter 30821 Ep: 2.84 masked_t 1.611 masked_v 0.212 NSP 0.070 lr 1.78034e-06
10/30/2020 03:03:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 30841 Ep: 2.84 masked_t 1.528 masked_v 0.209 NSP 0.080 lr 1.75986e-06
10/30/2020 03:04:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 30861 Ep: 2.84 masked_t 1.677 masked_v 0.203 NSP 0.078 lr 1.73938e-06
10/30/2020 03:04:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 30881 Ep: 2.85 masked_t 1.551 masked_v 0.206 NSP 0.077 lr 1.71889e-06
10/30/2020 03:04:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 30901 Ep: 2.85 masked_t 1.611 masked_v 0.207 NSP 0.077 lr 1.69841e-06
10/30/2020 03:05:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 30921 Ep: 2.85 masked_t 1.569 masked_v 0.206 NSP 0.077 lr 1.67793e-06
10/30/2020 03:05:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 30941 Ep: 2.85 masked_t 1.615 masked_v 0.207 NSP 0.083 lr 1.65745e-06
10/30/2020 03:05:57 - INFO - volta.utils -   [Conceptual_Caption]: iter 30961 Ep: 2.85 masked_t 1.550 masked_v 0.210 NSP 0.069 lr 1.63697e-06
10/30/2020 03:06:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 30981 Ep: 2.86 masked_t 1.646 masked_v 0.204 NSP 0.078 lr 1.61649e-06
10/30/2020 03:06:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 31001 Ep: 2.86 masked_t 1.597 masked_v 0.203 NSP 0.070 lr 1.59601e-06
10/30/2020 03:07:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 31021 Ep: 2.86 masked_t 1.570 masked_v 0.204 NSP 0.072 lr 1.57552e-06
10/30/2020 03:07:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 31041 Ep: 2.86 masked_t 1.539 masked_v 0.209 NSP 0.081 lr 1.55504e-06
10/30/2020 03:07:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 31061 Ep: 2.86 masked_t 1.604 masked_v 0.208 NSP 0.075 lr 1.53456e-06
10/30/2020 03:08:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 31081 Ep: 2.86 masked_t 1.670 masked_v 0.207 NSP 0.086 lr 1.51408e-06
10/30/2020 03:08:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 31101 Ep: 2.87 masked_t 1.588 masked_v 0.203 NSP 0.078 lr 1.4936e-06
10/30/2020 03:08:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 31121 Ep: 2.87 masked_t 1.697 masked_v 0.208 NSP 0.086 lr 1.47312e-06
10/30/2020 03:09:16 - INFO - volta.utils -   [Conceptual_Caption]: iter 31141 Ep: 2.87 masked_t 1.608 masked_v 0.204 NSP 0.082 lr 1.45264e-06
10/30/2020 03:09:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 31161 Ep: 2.87 masked_t 1.632 masked_v 0.201 NSP 0.077 lr 1.43216e-06
10/30/2020 03:10:00 - INFO - volta.utils -   [Conceptual_Caption]: iter 31181 Ep: 2.87 masked_t 1.564 masked_v 0.211 NSP 0.073 lr 1.41167e-06
10/30/2020 03:10:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 31201 Ep: 2.88 masked_t 1.609 masked_v 0.204 NSP 0.087 lr 1.39119e-06
10/30/2020 03:10:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 31221 Ep: 2.88 masked_t 1.528 masked_v 0.210 NSP 0.072 lr 1.37071e-06
10/30/2020 03:11:06 - INFO - volta.utils -   [Conceptual_Caption]: iter 31241 Ep: 2.88 masked_t 1.568 masked_v 0.208 NSP 0.076 lr 1.35023e-06
10/30/2020 03:11:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 31261 Ep: 2.88 masked_t 1.554 masked_v 0.208 NSP 0.076 lr 1.32975e-06
10/30/2020 03:11:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 31281 Ep: 2.88 masked_t 1.571 masked_v 0.203 NSP 0.082 lr 1.30927e-06
10/30/2020 03:12:12 - INFO - volta.utils -   [Conceptual_Caption]: iter 31301 Ep: 2.88 masked_t 1.642 masked_v 0.209 NSP 0.084 lr 1.28879e-06
10/30/2020 03:12:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 31321 Ep: 2.89 masked_t 1.740 masked_v 0.209 NSP 0.080 lr 1.26831e-06
10/30/2020 03:12:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 31341 Ep: 2.89 masked_t 1.589 masked_v 0.210 NSP 0.076 lr 1.24782e-06
10/30/2020 03:13:18 - INFO - volta.utils -   [Conceptual_Caption]: iter 31361 Ep: 2.89 masked_t 1.613 masked_v 0.209 NSP 0.079 lr 1.22734e-06
10/30/2020 03:13:39 - INFO - volta.utils -   [Conceptual_Caption]: iter 31381 Ep: 2.89 masked_t 1.569 masked_v 0.208 NSP 0.081 lr 1.20686e-06
10/30/2020 03:14:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 31401 Ep: 2.89 masked_t 1.534 masked_v 0.208 NSP 0.069 lr 1.18638e-06
10/30/2020 03:14:24 - INFO - volta.utils -   [Conceptual_Caption]: iter 31421 Ep: 2.90 masked_t 1.523 masked_v 0.204 NSP 0.080 lr 1.1659e-06
10/30/2020 03:14:45 - INFO - volta.utils -   [Conceptual_Caption]: iter 31441 Ep: 2.90 masked_t 1.588 masked_v 0.207 NSP 0.084 lr 1.14542e-06
10/30/2020 03:15:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 31461 Ep: 2.90 masked_t 1.577 masked_v 0.209 NSP 0.071 lr 1.12494e-06
10/30/2020 03:15:30 - INFO - volta.utils -   [Conceptual_Caption]: iter 31481 Ep: 2.90 masked_t 1.515 masked_v 0.204 NSP 0.076 lr 1.10445e-06
10/30/2020 03:15:51 - INFO - volta.utils -   [Conceptual_Caption]: iter 31501 Ep: 2.90 masked_t 1.574 masked_v 0.208 NSP 0.075 lr 1.08397e-06
10/30/2020 03:16:13 - INFO - volta.utils -   [Conceptual_Caption]: iter 31521 Ep: 2.91 masked_t 1.576 masked_v 0.208 NSP 0.084 lr 1.06349e-06
10/30/2020 03:16:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 31541 Ep: 2.91 masked_t 1.543 masked_v 0.209 NSP 0.087 lr 1.04301e-06
10/30/2020 03:16:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 31561 Ep: 2.91 masked_t 1.505 masked_v 0.205 NSP 0.079 lr 1.02253e-06
10/30/2020 03:17:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 31581 Ep: 2.91 masked_t 1.583 masked_v 0.204 NSP 0.082 lr 1.00205e-06
10/30/2020 03:17:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 31601 Ep: 2.91 masked_t 1.550 masked_v 0.203 NSP 0.085 lr 9.81567e-07
10/30/2020 03:17:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 31621 Ep: 2.91 masked_t 1.678 masked_v 0.205 NSP 0.078 lr 9.61086e-07
10/30/2020 03:18:19 - INFO - volta.utils -   [Conceptual_Caption]: iter 31641 Ep: 2.92 masked_t 1.606 masked_v 0.205 NSP 0.076 lr 9.40604e-07
10/30/2020 03:18:40 - INFO - volta.utils -   [Conceptual_Caption]: iter 31661 Ep: 2.92 masked_t 1.560 masked_v 0.201 NSP 0.080 lr 9.20123e-07
10/30/2020 03:19:01 - INFO - volta.utils -   [Conceptual_Caption]: iter 31681 Ep: 2.92 masked_t 1.570 masked_v 0.205 NSP 0.078 lr 8.99642e-07
10/30/2020 03:19:21 - INFO - volta.utils -   [Conceptual_Caption]: iter 31701 Ep: 2.92 masked_t 1.533 masked_v 0.201 NSP 0.076 lr 8.7916e-07
10/30/2020 03:19:42 - INFO - volta.utils -   [Conceptual_Caption]: iter 31721 Ep: 2.92 masked_t 1.593 masked_v 0.205 NSP 0.082 lr 8.58679e-07
10/30/2020 03:20:04 - INFO - volta.utils -   [Conceptual_Caption]: iter 31741 Ep: 2.93 masked_t 1.645 masked_v 0.207 NSP 0.073 lr 8.38198e-07
10/30/2020 03:20:25 - INFO - volta.utils -   [Conceptual_Caption]: iter 31761 Ep: 2.93 masked_t 1.500 masked_v 0.211 NSP 0.084 lr 8.17716e-07
10/30/2020 03:20:46 - INFO - volta.utils -   [Conceptual_Caption]: iter 31781 Ep: 2.93 masked_t 1.624 masked_v 0.206 NSP 0.081 lr 7.97235e-07
10/30/2020 03:21:07 - INFO - volta.utils -   [Conceptual_Caption]: iter 31801 Ep: 2.93 masked_t 1.574 masked_v 0.206 NSP 0.079 lr 7.76754e-07
10/30/2020 03:21:28 - INFO - volta.utils -   [Conceptual_Caption]: iter 31821 Ep: 2.93 masked_t 1.621 masked_v 0.206 NSP 0.071 lr 7.56272e-07
10/30/2020 03:21:49 - INFO - volta.utils -   [Conceptual_Caption]: iter 31841 Ep: 2.93 masked_t 1.653 masked_v 0.208 NSP 0.094 lr 7.35791e-07
10/30/2020 03:22:10 - INFO - volta.utils -   [Conceptual_Caption]: iter 31861 Ep: 2.94 masked_t 1.627 masked_v 0.211 NSP 0.087 lr 7.1531e-07
10/30/2020 03:22:32 - INFO - volta.utils -   [Conceptual_Caption]: iter 31881 Ep: 2.94 masked_t 1.578 masked_v 0.203 NSP 0.086 lr 6.94828e-07
10/30/2020 03:22:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 31901 Ep: 2.94 masked_t 1.645 masked_v 0.201 NSP 0.085 lr 6.74347e-07
10/30/2020 03:23:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 31921 Ep: 2.94 masked_t 1.607 masked_v 0.202 NSP 0.063 lr 6.53866e-07
10/30/2020 03:23:35 - INFO - volta.utils -   [Conceptual_Caption]: iter 31941 Ep: 2.94 masked_t 1.599 masked_v 0.205 NSP 0.079 lr 6.33385e-07
10/30/2020 03:23:55 - INFO - volta.utils -   [Conceptual_Caption]: iter 31961 Ep: 2.95 masked_t 1.618 masked_v 0.209 NSP 0.089 lr 6.12903e-07
10/30/2020 03:24:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 31981 Ep: 2.95 masked_t 1.538 masked_v 0.206 NSP 0.078 lr 5.92422e-07
10/30/2020 03:24:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 32001 Ep: 2.95 masked_t 1.548 masked_v 0.206 NSP 0.076 lr 5.71941e-07
10/30/2020 03:24:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 32021 Ep: 2.95 masked_t 1.594 masked_v 0.205 NSP 0.081 lr 5.51459e-07
10/30/2020 03:25:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 32041 Ep: 2.95 masked_t 1.586 masked_v 0.203 NSP 0.080 lr 5.30978e-07
10/30/2020 03:25:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 32061 Ep: 2.95 masked_t 1.547 masked_v 0.199 NSP 0.086 lr 5.10497e-07
10/30/2020 03:26:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 32081 Ep: 2.96 masked_t 1.511 masked_v 0.209 NSP 0.082 lr 4.90015e-07
10/30/2020 03:26:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 32101 Ep: 2.96 masked_t 1.581 masked_v 0.206 NSP 0.078 lr 4.69534e-07
10/30/2020 03:26:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 32121 Ep: 2.96 masked_t 1.614 masked_v 0.207 NSP 0.072 lr 4.49053e-07
10/30/2020 03:27:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 32141 Ep: 2.96 masked_t 1.558 masked_v 0.205 NSP 0.077 lr 4.28571e-07
10/30/2020 03:27:26 - INFO - volta.utils -   [Conceptual_Caption]: iter 32161 Ep: 2.96 masked_t 1.574 masked_v 0.203 NSP 0.076 lr 4.0809e-07
10/30/2020 03:27:47 - INFO - volta.utils -   [Conceptual_Caption]: iter 32181 Ep: 2.97 masked_t 1.519 masked_v 0.209 NSP 0.079 lr 3.87609e-07
10/30/2020 03:28:08 - INFO - volta.utils -   [Conceptual_Caption]: iter 32201 Ep: 2.97 masked_t 1.599 masked_v 0.207 NSP 0.071 lr 3.67127e-07
10/30/2020 03:28:29 - INFO - volta.utils -   [Conceptual_Caption]: iter 32221 Ep: 2.97 masked_t 1.539 masked_v 0.208 NSP 0.072 lr 3.46646e-07
10/30/2020 03:28:50 - INFO - volta.utils -   [Conceptual_Caption]: iter 32241 Ep: 2.97 masked_t 1.588 masked_v 0.205 NSP 0.078 lr 3.26165e-07
10/30/2020 03:29:11 - INFO - volta.utils -   [Conceptual_Caption]: iter 32261 Ep: 2.97 masked_t 1.519 masked_v 0.203 NSP 0.082 lr 3.05684e-07
10/30/2020 03:29:31 - INFO - volta.utils -   [Conceptual_Caption]: iter 32281 Ep: 2.98 masked_t 1.644 masked_v 0.204 NSP 0.077 lr 2.85202e-07
10/30/2020 03:29:53 - INFO - volta.utils -   [Conceptual_Caption]: iter 32301 Ep: 2.98 masked_t 1.549 masked_v 0.202 NSP 0.072 lr 2.64721e-07
10/30/2020 03:30:14 - INFO - volta.utils -   [Conceptual_Caption]: iter 32321 Ep: 2.98 masked_t 1.530 masked_v 0.205 NSP 0.076 lr 2.4424e-07
10/30/2020 03:30:34 - INFO - volta.utils -   [Conceptual_Caption]: iter 32341 Ep: 2.98 masked_t 1.585 masked_v 0.204 NSP 0.078 lr 2.23758e-07
10/30/2020 03:30:56 - INFO - volta.utils -   [Conceptual_Caption]: iter 32361 Ep: 2.98 masked_t 1.584 masked_v 0.206 NSP 0.084 lr 2.03277e-07
10/30/2020 03:31:17 - INFO - volta.utils -   [Conceptual_Caption]: iter 32381 Ep: 2.98 masked_t 1.487 masked_v 0.205 NSP 0.079 lr 1.82796e-07
10/30/2020 03:31:38 - INFO - volta.utils -   [Conceptual_Caption]: iter 32401 Ep: 2.99 masked_t 1.540 masked_v 0.214 NSP 0.066 lr 1.62314e-07
10/30/2020 03:31:59 - INFO - volta.utils -   [Conceptual_Caption]: iter 32421 Ep: 2.99 masked_t 1.544 masked_v 0.210 NSP 0.074 lr 1.41833e-07
10/30/2020 03:32:20 - INFO - volta.utils -   [Conceptual_Caption]: iter 32441 Ep: 2.99 masked_t 1.612 masked_v 0.202 NSP 0.083 lr 1.21352e-07
10/30/2020 03:32:41 - INFO - volta.utils -   [Conceptual_Caption]: iter 32461 Ep: 2.99 masked_t 1.622 masked_v 0.205 NSP 0.083 lr 1.0087e-07
10/30/2020 03:33:02 - INFO - volta.utils -   [Conceptual_Caption]: iter 32481 Ep: 2.99 masked_t 1.599 masked_v 0.206 NSP 0.069 lr 8.03891e-08
10/30/2020 03:33:23 - INFO - volta.utils -   [Conceptual_Caption]: iter 32501 Ep: 3.00 masked_t 1.629 masked_v 0.204 NSP 0.080 lr 5.99078e-08
10/30/2020 03:33:44 - INFO - volta.utils -   [Conceptual_Caption]: iter 32521 Ep: 3.00 masked_t 1.517 masked_v 0.205 NSP 0.080 lr 3.94265e-08
10/30/2020 03:34:05 - INFO - volta.utils -   [Conceptual_Caption]: iter 32541 Ep: 3.00 masked_t 1.473 masked_v 0.201 NSP 0.077 lr 1.89452e-08
10/30/2020 03:34:53 - INFO - volta.utils -   Validation [Conceptual_Caption]: masked_t 2.192 masked_v 0.189 NSP 0.106
10/30/2020 03:34:53 - INFO - __main__ -   ** ** * Saving fine - tuned model ** ** * 
