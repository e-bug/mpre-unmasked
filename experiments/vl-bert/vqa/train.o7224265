Namespace(cfg='cfgs/vqa/base_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/./output/vqa/vlbert/base_4x16G_fp32/train2014+val2014_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/', partial_pretrain=None, slurm=False)
Namespace(cfg='cfgs/vqa/base_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/./output/vqa/vlbert/base_4x16G_fp32/train2014+val2014_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/', partial_pretrain=None, slurm=False)
{'CHECKPOINT_FREQUENT': 1,
 {'CHECKPOINT_FREQUENT': 1,
 'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'ANSWER_VOCAB_FILE': '/gs/hs0/tgb-deepmt/bugliarello.e/data/vqa/vl-bert/answers_vqa.txt',
             'ANSWER_VOCAB_SIZE': 3129,
             'ANSWER_VOCAB_FILE': '/gs/hs0/tgb-deepmt/bugliarello.e/data/vqa/vl-bert/answers_vqa.txt',
             'APPEND_INDEX': False,
             'BASIC_ALIGN': False,
             'ANSWER_VOCAB_SIZE': 3129,
             'BOXES': '36',
             'APPEND_INDEX': False,
             'CACHE_MODE': False,
             'BASIC_ALIGN': False,
             'DATASET': 'vqa',
             'BOXES': '36',
             'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/',
             'CACHE_MODE': False,
             'IGNORE_DB_CACHE': False,
             'DATASET': 'vqa',
             'LABEL_INDEX_IN_BATCH': -1,
             'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/',
             'MASK_SIZE': 14,
             'IGNORE_DB_CACHE': False,
             'ONLY_USE_RELEVANT_DETS': True,
             'LABEL_INDEX_IN_BATCH': -1,
             'QA2R_AUG': False,
             'MASK_SIZE': 14,
             'QA2R_NOQ': False,
             'ONLY_USE_RELEVANT_DETS': True,
             'ROOT_PATH': './',
             'QA2R_AUG': False,
             'TASK': 'Q2AR',
             'QA2R_NOQ': False,
             'TEST_ANNOTATION_FILE': '',
             'ROOT_PATH': './',
             'TEST_IMAGE_SET': 'test2015',
             'TASK': 'Q2AR',
             'TRAIN_ANNOTATION_FILE': '',
             'TEST_ANNOTATION_FILE': '',
             'TRAIN_IMAGE_SET': 'train2014+val2014',
             'TEST_IMAGE_SET': 'test2015',
             'USE_IMDB': False,
             'TRAIN_ANNOTATION_FILE': '',
             'VAL_ANNOTATION_FILE': '',
             'TRAIN_IMAGE_SET': 'train2014+val2014',
             'VAL_IMAGE_SET': 'val2014',
             'USE_IMDB': False,
             'ZIP_MODE': False},
 'VAL_ANNOTATION_FILE': '',
             'GPUS': '0,1,2,3',
 'VAL_IMAGE_SET': 'val2014',
             'LOG_FREQUENT': 100,
 'ZIP_MODE': False},
 'MODEL_PREFIX': 'vl-bert_base_res101_vqa',
 'GPUS': '0,1,2,3',
 'MODULE': 'ResNetVLBERT',
 'LOG_FREQUENT': 100,
 'MODEL_PREFIX': 'vl-bert_base_res101_vqa',
 'MODULE': 'ResNetVLBERT',
 'NETWORK': {'ANS_LOSS_TYPE': 'bce',
             'ANS_LOSS_WEIGHT': 1.0,
             'BERT_ALIGN_ANSWER': True,
             'NETWORK': {'ANS_LOSS_TYPE': 'bce',
             'BERT_ALIGN_QUESTION': True,
             'ANS_LOSS_WEIGHT': 1.0,
             'BERT_FROZEN': False,
             'BERT_ALIGN_ANSWER': True,
             'BERT_ALIGN_QUESTION': True,
             'BERT_FROZEN': False,
             'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'BERT_PRETRAINED': '',
             'BERT_PRETRAINED_EPOCH': 0,
             'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'BERT_USE_LAYER': -2,
             'BERT_PRETRAINED': '',
             'BERT_WITH_MLM_LOSS': False,
             'BERT_PRETRAINED_EPOCH': 0,
             'BERT_WITH_NSP_LOSS': False,
             'BERT_USE_LAYER': -2,
             'BLIND': False,
             'BERT_WITH_MLM_LOSS': False,
             'CLASSIFIER_DROPOUT': 0.1,
             'BERT_WITH_NSP_LOSS': False,
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'BLIND': False,
             'CLASSIFIER_PRETRAINED': True,
             'CLASSIFIER_SIGMOID': False,
             'CLASSIFIER_DROPOUT': 0.1,
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'CLASSIFIER_TYPE': 'mlm',
             'CLASSIFIER_PRETRAINED': True,
             'CNN_LOSS_WEIGHT': 1.0,
             'CLASSIFIER_SIGMOID': False,
             'ENABLE_CNN_REG_LOSS': False,
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'CLASSIFIER_TYPE': 'mlm',
             'IMAGE_C5_DILATED': True,
             'CNN_LOSS_WEIGHT': 1.0,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'ENABLE_CNN_REG_LOSS': False,
             'IMAGE_FINAL_DIM': 768,
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'IMAGE_C5_DILATED': True,
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'IMAGE_FEAT_PRECOMPUTED': True,
             'IMAGE_FROZEN_BN': True,
             'IMAGE_FINAL_DIM': 768,
             'IMAGE_NUM_LAYERS': 101,
             'IMAGE_PRETRAINED': '',
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'IMAGE_PRETRAINED_EPOCH': 0,
             'IMAGE_FROZEN_BN': True,
             'IMAGE_SEMANTIC': False,
             'IMAGE_NUM_LAYERS': 101,
             'IMAGE_STRIDE_IN_1x1': True,
             'IMAGE_PRETRAINED': '',
             'NO_GROUNDING': False,
             'IMAGE_PRETRAINED_EPOCH': 0,
             'NO_OBJ_ATTENTION': False,
             'IMAGE_SEMANTIC': False,
             'OUTPUT_CONV5': False,
             'IMAGE_STRIDE_IN_1x1': True,
             'NO_GROUNDING': False,
             'NO_OBJ_ATTENTION': False,
             'PARTIAL_PRETRAIN': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-best.model',
             'OUTPUT_CONV5': False,
             'PARTIAL_PRETRAIN': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-best.model',
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': ['vlbert.mlm_head.predictions.transform->final_mlp.0',
                                                 'module.vlbert.mlm_head.predictions.transform->module.final_mlp.0',
                                                 'PARTIAL_PRETRAIN_PREFIX_CHANGES': ['vlbert.mlm_head.predictions.transform->final_mlp.0',
                                                 'vlbert->vlbert',
                                                 'module.vlbert.mlm_head.predictions.transform->module.final_mlp.0',
                                                 'module.vlbert->module.vlbert'],
             'vlbert->vlbert',
                                                 'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'module.vlbert->module.vlbert'],
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'REPLACE_OBJECT_CHANGE_LABEL': True,
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'REPLACE_OBJECT_CHANGE_LABEL': True,
             'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'hidden_act': 'gelu',
                        'hidden_dropout_prob': 0.1,
                        'hidden_size': 768,
                        'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'initializer_range': 0.02,
                        'hidden_act': 'gelu',
                        'input_size': 1280,
                        'hidden_dropout_prob': 0.1,
                        'input_transform_type': 1,
                        'hidden_size': 768,
                        'intermediate_size': 3072,
                        'initializer_range': 0.02,
                        'max_position_embeddings': 512,
                        'input_size': 1280,
                        'num_attention_heads': 12,
                        'input_transform_type': 1,
                        'num_hidden_layers': 12,
                        'intermediate_size': 3072,
                        'obj_pos_id_relative': True,
                        'max_position_embeddings': 512,
                        'object_word_embed_mode': 2,
                        'num_attention_heads': 12,
                        'position_padding_idx': -1,
                        'num_hidden_layers': 12,
                        'type_vocab_size': 3,
                        'obj_pos_id_relative': True,
                        'visual_ln': True,
                        'object_word_embed_mode': 2,
                        'visual_scale_object_init': 0.0,
                        'position_padding_idx': -1,
                        'visual_scale_text_init': 0.0,
                        'type_vocab_size': 3,
                        'visual_size': 768,
                        'visual_ln': True,
                        'vocab_size': 30522,
                        'visual_scale_object_init': 0.0,
                        'with_pooler': False,
                        'visual_scale_text_init': 0.0,
                        'visual_size': 768,
                        'word_embedding_frozen': False}},
 'vocab_size': 30522,
                        'NUM_WORKERS_PER_GPU': 4,
 'with_pooler': False,
                        'word_embedding_frozen': False}},
 'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/./output/vqa/vlbert',
 'NUM_WORKERS_PER_GPU': 4,
 'RNG_SEED': 12345,
 'SCALES': [600, 1000],
 'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/./output/vqa/vlbert',
 'RNG_SEED': 12345,
 'SCALES': [600, 1000],
 'TEST': {'BATCH_IMAGES': 64,
          'FLIP_PROB': 0,
          'SHUFFLE': False,
          'TEST_EPOCH': 0},
 'TEST': {'BATCH_IMAGES': 64,
          'FLIP_PROB': 0,
          'SHUFFLE': False,
          'TEST_EPOCH': 0},
 'TRAIN': {'ASPECT_GROUPING': False,
           'AUTO_RESUME': True,
           'BATCH_IMAGES': 64,
           'BEGIN_EPOCH': 0,
           'TRAIN': {'ASPECT_GROUPING': False,
           'CLIP_GRAD_NORM': 1.0,
           'AUTO_RESUME': True,
           'END_EPOCH': 5,
           'BATCH_IMAGES': 64,
           'FLIP_PROB': 0.5,
           'BEGIN_EPOCH': 0,
           'FP16': False,
           'CLIP_GRAD_NORM': 1.0,
           'FP16_LOSS_SCALE': 128.0,
           'END_EPOCH': 5,
           'GRAD_ACCUMULATE_STEPS': 1,
           'FLIP_PROB': 0.5,
           'FP16': False,
           'LOSS_LOGGERS': [('ans_loss', 'AnsLoss')],
           'FP16_LOSS_SCALE': 128.0,
           'LR': 6.25e-07,
           'GRAD_ACCUMULATE_STEPS': 1,
           'LR_FACTOR': 0.1,
           'LR_MULT': [],
           'LOSS_LOGGERS': [('ans_loss', 'AnsLoss')],
           'LR_SCHEDULE': 'triangle',
           'LR': 6.25e-07,
           'LR_STEP': [],
           'LR_FACTOR': 0.1,
           'MOMENTUM': 0.9,
           'LR_MULT': [],
           'OPTIMIZER': 'AdamW',
           'LR_SCHEDULE': 'triangle',
           'RESUME': False,
           'LR_STEP': [],
           'SHUFFLE': True,
           'MOMENTUM': 0.9,
           'VISUAL_SCALE_CLIP_GRAD_NORM': -1,
           'OPTIMIZER': 'AdamW',
           'VISUAL_SCALE_OBJECT_LR_MULT': 1.0,
           'RESUME': False,
           'VISUAL_SCALE_TEXT_LR_MULT': 1.0,
           'SHUFFLE': True,
           'WARMUP': True,
           'VISUAL_SCALE_CLIP_GRAD_NORM': -1,
           'WARMUP_FACTOR': 0.0,
           'VISUAL_SCALE_OBJECT_LR_MULT': 1.0,
           'WARMUP_METHOD': 'linear',
           'VISUAL_SCALE_TEXT_LR_MULT': 1.0,
           'WARMUP_STEPS': 500,
           'WARMUP': True,
           'WD': 0.0001},
 'WARMUP_FACTOR': 0.0,
           'WARMUP_METHOD': 'linear',
           'WARMUP_STEPS': 500,
           'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'WD': 0.0001},
 'VAL_FREQUENT': 1}
'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'VAL_FREQUENT': 1}
Namespace(cfg='cfgs/vqa/base_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/./output/vqa/vlbert/base_4x16G_fp32/train2014+val2014_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/', partial_pretrain=None, slurm=False)
Namespace(cfg='cfgs/vqa/base_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/./output/vqa/vlbert/base_4x16G_fp32/train2014+val2014_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/', partial_pretrain=None, slurm=False)
{'CHECKPOINT_FREQUENT': 1,
 'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'ANSWER_VOCAB_FILE': '/gs/hs0/tgb-deepmt/bugliarello.e/data/vqa/vl-bert/answers_vqa.txt',
             'ANSWER_VOCAB_SIZE': 3129,
             'APPEND_INDEX': False,
             'BASIC_ALIGN': False,
             'BOXES': '36',
             'CACHE_MODE': False,
             'DATASET': 'vqa',
             'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/',
             'IGNORE_DB_CACHE': False,
             'LABEL_INDEX_IN_BATCH': -1,
             'MASK_SIZE': 14,
             'ONLY_USE_RELEVANT_DETS': True,
             'QA2R_AUG': False,
             'QA2R_NOQ': False,
             'ROOT_PATH': './',
             'TASK': 'Q2AR',
             'TEST_ANNOTATION_FILE': '',
             'TEST_IMAGE_SET': 'test2015',
             'TRAIN_ANNOTATION_FILE': '',
             'TRAIN_IMAGE_SET': 'train2014+val2014',
             'USE_IMDB': False,
             'VAL_ANNOTATION_FILE': '',
             'VAL_IMAGE_SET': 'val2014',
             'ZIP_MODE': False},
 'GPUS': '0,1,2,3',
 'LOG_FREQUENT': 100,
 'MODEL_PREFIX': 'vl-bert_base_res101_vqa',
 'MODULE': 'ResNetVLBERT',
 {'CHECKPOINT_FREQUENT': 1,
 'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'ANSWER_VOCAB_FILE': '/gs/hs0/tgb-deepmt/bugliarello.e/data/vqa/vl-bert/answers_vqa.txt',
             'NETWORK': {'ANS_LOSS_TYPE': 'bce',
             'ANSWER_VOCAB_SIZE': 3129,
             'ANS_LOSS_WEIGHT': 1.0,
             'APPEND_INDEX': False,
             'BERT_ALIGN_ANSWER': True,
             'BASIC_ALIGN': False,
             'BERT_ALIGN_QUESTION': True,
             'BOXES': '36',
             'BERT_FROZEN': False,
             'CACHE_MODE': False,
             'DATASET': 'vqa',
             'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/',
             'IGNORE_DB_CACHE': False,
             'BERT_PRETRAINED': '',
             'LABEL_INDEX_IN_BATCH': -1,
             'BERT_PRETRAINED_EPOCH': 0,
             'MASK_SIZE': 14,
             'BERT_USE_LAYER': -2,
             'ONLY_USE_RELEVANT_DETS': True,
             'BERT_WITH_MLM_LOSS': False,
             'QA2R_AUG': False,
             'BERT_WITH_NSP_LOSS': False,
             'QA2R_NOQ': False,
             'BLIND': False,
             'ROOT_PATH': './',
             'CLASSIFIER_DROPOUT': 0.1,
             'TASK': 'Q2AR',
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'TEST_ANNOTATION_FILE': '',
             'CLASSIFIER_PRETRAINED': True,
             'TEST_IMAGE_SET': 'test2015',
             'CLASSIFIER_SIGMOID': False,
             'TRAIN_ANNOTATION_FILE': '',
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'TRAIN_IMAGE_SET': 'train2014+val2014',
             'CLASSIFIER_TYPE': 'mlm',
             'USE_IMDB': False,
             'CNN_LOSS_WEIGHT': 1.0,
             'VAL_ANNOTATION_FILE': '',
             'ENABLE_CNN_REG_LOSS': False,
             'VAL_IMAGE_SET': 'val2014',
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'IMAGE_C5_DILATED': True,
             'ZIP_MODE': False},
 'IMAGE_FEAT_PRECOMPUTED': True,
             'GPUS': '0,1,2,3',
 'IMAGE_FINAL_DIM': 768,
             'LOG_FREQUENT': 100,
 'MODEL_PREFIX': 'vl-bert_base_res101_vqa',
 'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'MODULE': 'ResNetVLBERT',
 'IMAGE_FROZEN_BN': True,
             'IMAGE_NUM_LAYERS': 101,
             'IMAGE_PRETRAINED': '',
             'IMAGE_PRETRAINED_EPOCH': 0,
             'IMAGE_SEMANTIC': False,
             'IMAGE_STRIDE_IN_1x1': True,
             'NO_GROUNDING': False,
             'NO_OBJ_ATTENTION': False,
             'OUTPUT_CONV5': False,
             'PARTIAL_PRETRAIN': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-best.model',
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': ['vlbert.mlm_head.predictions.transform->final_mlp.0',
                                                 'module.vlbert.mlm_head.predictions.transform->module.final_mlp.0',
                                                 'vlbert->vlbert',
                                                 'module.vlbert->module.vlbert'],
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'REPLACE_OBJECT_CHANGE_LABEL': True,
             'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'hidden_act': 'gelu',
                        'hidden_dropout_prob': 0.1,
                        'hidden_size': 768,
                        'initializer_range': 0.02,
                        'input_size': 1280,
                        'input_transform_type': 1,
                        'intermediate_size': 3072,
                        'max_position_embeddings': 512,
                        'num_attention_heads': 12,
                        'num_hidden_layers': 12,
                        'obj_pos_id_relative': True,
                        'object_word_embed_mode': 2,
                        'position_padding_idx': -1,
                        'type_vocab_size': 3,
                        'visual_ln': True,
                        'NETWORK': {'ANS_LOSS_TYPE': 'bce',
             'visual_scale_object_init': 0.0,
                        'ANS_LOSS_WEIGHT': 1.0,
             'visual_scale_text_init': 0.0,
                        'BERT_ALIGN_ANSWER': True,
             'visual_size': 768,
                        'BERT_ALIGN_QUESTION': True,
             'vocab_size': 30522,
                        'BERT_FROZEN': False,
             'with_pooler': False,
                        'word_embedding_frozen': False}},
 'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'NUM_WORKERS_PER_GPU': 4,
 'BERT_PRETRAINED': '',
             'BERT_PRETRAINED_EPOCH': 0,
             'BERT_USE_LAYER': -2,
             'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/./output/vqa/vlbert',
 'BERT_WITH_MLM_LOSS': False,
             'RNG_SEED': 12345,
 'BERT_WITH_NSP_LOSS': False,
             'BLIND': False,
             'SCALES': [600, 1000],
 'CLASSIFIER_DROPOUT': 0.1,
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'CLASSIFIER_PRETRAINED': True,
             'CLASSIFIER_SIGMOID': False,
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'CLASSIFIER_TYPE': 'mlm',
             'TEST': {'BATCH_IMAGES': 64,
          'CNN_LOSS_WEIGHT': 1.0,
             'FLIP_PROB': 0,
          'ENABLE_CNN_REG_LOSS': False,
             'SHUFFLE': False,
          'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'TEST_EPOCH': 0},
 'IMAGE_C5_DILATED': True,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'IMAGE_FINAL_DIM': 768,
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'IMAGE_FROZEN_BN': True,
             'IMAGE_NUM_LAYERS': 101,
             'IMAGE_PRETRAINED': '',
             'IMAGE_PRETRAINED_EPOCH': 0,
             'IMAGE_SEMANTIC': False,
             'IMAGE_STRIDE_IN_1x1': True,
             'NO_GROUNDING': False,
             'NO_OBJ_ATTENTION': False,
             'OUTPUT_CONV5': False,
             'PARTIAL_PRETRAIN': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-best.model',
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': ['vlbert.mlm_head.predictions.transform->final_mlp.0',
                                                 'module.vlbert.mlm_head.predictions.transform->module.final_mlp.0',
                                                 'vlbert->vlbert',
                                                 'module.vlbert->module.vlbert'],
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'REPLACE_OBJECT_CHANGE_LABEL': True,
             'TRAIN': {'ASPECT_GROUPING': False,
           'AUTO_RESUME': True,
           'BATCH_IMAGES': 64,
           'BEGIN_EPOCH': 0,
           'CLIP_GRAD_NORM': 1.0,
           'END_EPOCH': 5,
           'FLIP_PROB': 0.5,
           'FP16': False,
           'FP16_LOSS_SCALE': 128.0,
           'GRAD_ACCUMULATE_STEPS': 1,
           'LOSS_LOGGERS': [('ans_loss', 'AnsLoss')],
           'LR': 6.25e-07,
           'LR_FACTOR': 0.1,
           'LR_MULT': [],
           'LR_SCHEDULE': 'triangle',
           'LR_STEP': [],
           'MOMENTUM': 0.9,
           'OPTIMIZER': 'AdamW',
           'RESUME': False,
           'SHUFFLE': True,
           'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'VISUAL_SCALE_CLIP_GRAD_NORM': -1,
           'VISUAL_SCALE_OBJECT_LR_MULT': 1.0,
           'hidden_act': 'gelu',
                        'VISUAL_SCALE_TEXT_LR_MULT': 1.0,
           'hidden_dropout_prob': 0.1,
                        'WARMUP': True,
           'hidden_size': 768,
                        'WARMUP_FACTOR': 0.0,
           'initializer_range': 0.02,
                        'WARMUP_METHOD': 'linear',
           'input_size': 1280,
                        'WARMUP_STEPS': 500,
           'input_transform_type': 1,
                        'intermediate_size': 3072,
                        'WD': 0.0001},
 'max_position_embeddings': 512,
                        'num_attention_heads': 12,
                        'num_hidden_layers': 12,
                        'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'obj_pos_id_relative': True,
                        'object_word_embed_mode': 2,
                        'VAL_FREQUENT': 1}
'position_padding_idx': -1,
                        'type_vocab_size': 3,
                        'visual_ln': True,
                        'visual_scale_object_init': 0.0,
                        'visual_scale_text_init': 0.0,
                        'visual_size': 768,
                        'vocab_size': 30522,
                        'with_pooler': False,
                        'word_embedding_frozen': False}},
 'NUM_WORKERS_PER_GPU': 4,
 'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/vqa/vl-bert/./output/vqa/vlbert',
 'RNG_SEED': 12345,
 'SCALES': [600, 1000],
 'TEST': {'BATCH_IMAGES': 64,
          'FLIP_PROB': 0,
          'SHUFFLE': False,
          'TEST_EPOCH': 0},
 'TRAIN': {'ASPECT_GROUPING': False,
           'AUTO_RESUME': True,
           'BATCH_IMAGES': 64,
           'BEGIN_EPOCH': 0,
           'CLIP_GRAD_NORM': 1.0,
           'END_EPOCH': 5,
           'FLIP_PROB': 0.5,
           'FP16': False,
           'FP16_LOSS_SCALE': 128.0,
           'GRAD_ACCUMULATE_STEPS': 1,
           'LOSS_LOGGERS': [('ans_loss', 'AnsLoss')],
           'LR': 6.25e-07,
           'LR_FACTOR': 0.1,
           'LR_MULT': [],
           'LR_SCHEDULE': 'triangle',
           'LR_STEP': [],
           'MOMENTUM': 0.9,
           'OPTIMIZER': 'AdamW',
           'RESUME': False,
           'SHUFFLE': True,
           'VISUAL_SCALE_CLIP_GRAD_NORM': -1,
           'VISUAL_SCALE_OBJECT_LR_MULT': 1.0,
           'VISUAL_SCALE_TEXT_LR_MULT': 1.0,
           'WARMUP': True,
           'WARMUP_FACTOR': 0.0,
           'WARMUP_METHOD': 'linear',
           'WARMUP_STEPS': 500,
           'WD': 0.0001},
 'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'VAL_FREQUENT': 1}
Warnings: Unexpected keys: ['pooler.dense.weight', 'pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
Warnings: Unexpected keys: ['pooler.dense.weight', 'pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
Warnings: Unexpected keys: ['pooler.dense.weight', 'pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
Warnings: Unexpected keys: ['pooler.dense.weight', 'pooler.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
loading pretrained classifier transform keys: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta'].
loading pretrained classifier transform keys: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta'].
loading pretrained classifier transform keys: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta'].
loading pretrained classifier transform keys: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.gamma', 'cls.predictions.transform.LayerNorm.beta'].
native distributed, size: 4, rank: 3, local rank: 3
native distributed, size: 4, rank: 2, local rank: 2
native distributed, size: 4, rank: 1, local rank: 1
native distributed, size: 4, rank: 0, local rank: 0
>> Trainable Parameters:
---------------------------------------------------------------------------------------------------------------
|Name                                                         |Dtype            |Shape           |#Params     |
---------------------------------------------------------------------------------------------------------------
|image_feature_extractor.obj_downsample.1.weight              |torch.float32    |(768, 4096)     |3145728     |
---------------------------------------------------------------------------------------------------------------
|image_feature_extractor.obj_downsample.1.bias                |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|object_linguistic_embeddings.weight                          |torch.float32    |(1, 768)        |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.word_embeddings.weight                                |torch.float32    |(30522, 768)    |23440896    |
---------------------------------------------------------------------------------------------------------------
|vlbert.end_embedding.weight                                  |torch.float32    |(1, 768)        |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.position_embeddings.weight                            |torch.float32    |(512, 768)      |393216      |
---------------------------------------------------------------------------------------------------------------
|vlbert.token_type_embeddings.weight                          |torch.float32    |(3, 768)        |2304        |
---------------------------------------------------------------------------------------------------------------
|vlbert.embedding_LayerNorm.weight                            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.embedding_LayerNorm.bias                              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_text.weight                                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_text.bias                                   |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_object.weight                               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_object.bias                                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.query.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.query.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.key.weight            |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.key.bias              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.value.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.value.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.dense.weight        |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.dense.bias          |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.LayerNorm.weight    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.LayerNorm.bias      |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.intermediate.dense.weight            |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.intermediate.dense.bias              |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.dense.bias                    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.LayerNorm.weight              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.LayerNorm.bias                |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.query.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.query.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.key.weight            |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.key.bias              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.value.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.value.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.dense.weight        |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.dense.bias          |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.LayerNorm.weight    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.LayerNorm.bias      |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|final_mlp.0.dense.weight                                     |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|final_mlp.0.dense.bias                                       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|final_mlp.0.LayerNorm.weight                                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|final_mlp.0.LayerNorm.bias                                   |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|final_mlp.2.weight                                           |torch.float32    |(3129, 768)     |2403072     |
---------------------------------------------------------------------------------------------------------------
|final_mlp.2.bias                                             |torch.float32    |(3129,)         |3129        |
---------------------------------------------------------------------------------------------------------------
>> # TrainableParams:       	115.04	M
>> # NonTrainableParams:    	0.00	M
>> # TotalParams:           	115.04	M
cached database found in ./cache/vqa2_nonimdb_boxes36_train2014+val2014visualprecomp.pkl.
cached database found in ./cache/vqa2_nonimdb_boxes36_train2014+val2014visualprecomp.pkl.
loading cached database from ./cache/vqa2_nonimdb_boxes36_train2014+val2014visualprecomp.pkl...
loading cached database from ./cache/vqa2_nonimdb_boxes36_train2014+val2014visualprecomp.pkl...
cached database found in ./cache/vqa2_nonimdb_boxes36_train2014+val2014visualprecomp.pkl.
cached database found in ./cache/vqa2_nonimdb_boxes36_train2014+val2014visualprecomp.pkl.
loading cached database from ./cache/vqa2_nonimdb_boxes36_train2014+val2014visualprecomp.pkl...
loading cached database from ./cache/vqa2_nonimdb_boxes36_train2014+val2014visualprecomp.pkl...
Done (t=4.31s)
Done (t=4.31s)
Done (t=4.39s)
Done (t=4.40s)
cached database found in ./cache/vqa2_nonimdb_boxes36_val2014visualprecomp.pkl.
loading cached database from ./cache/vqa2_nonimdb_boxes36_val2014visualprecomp.pkl...
cached database found in ./cache/vqa2_nonimdb_boxes36_val2014visualprecomp.pkl.
loading cached database from ./cache/vqa2_nonimdb_boxes36_val2014visualprecomp.pkl...
cached database found in ./cache/vqa2_nonimdb_boxes36_val2014visualprecomp.pkl.
loading cached database from ./cache/vqa2_nonimdb_boxes36_val2014visualprecomp.pkl...
cached database found in ./cache/vqa2_nonimdb_boxes36_val2014visualprecomp.pkl.
loading cached database from ./cache/vqa2_nonimdb_boxes36_val2014visualprecomp.pkl...
Done (t=1.52s)
Done (t=1.52s)
Done (t=1.53s)
Done (t=1.55s)
[Partial Load] partial load state dict of keys: dict_keys(['module.image_feature_extractor.obj_downsample.1.weight', 'module.image_feature_extractor.obj_downsample.1.bias', 'module.object_linguistic_embeddings.weight', 'module.vlbert.word_embeddings.weight', 'module.vlbert.end_embedding.weight', 'module.vlbert.position_embeddings.weight', 'module.vlbert.token_type_embeddings.weight', 'module.vlbert.embedding_LayerNorm.weight', 'module.vlbert.embedding_LayerNorm.bias', 'module.vlbert.visual_ln_text.weight', 'module.vlbert.visual_ln_text.bias', 'module.vlbert.visual_ln_object.weight', 'module.vlbert.visual_ln_object.bias', 'module.vlbert.encoder.layer.0.attention.self.query.weight', 'module.vlbert.encoder.layer.0.attention.self.query.bias', 'module.vlbert.encoder.layer.0.attention.self.key.weight', 'module.vlbert.encoder.layer.0.attention.self.key.bias', 'module.vlbert.encoder.layer.0.attention.self.value.weight', 'module.vlbert.encoder.layer.0.attention.self.value.bias', 'module.vlbert.encoder.layer.0.attention.output.dense.weight', 'module.vlbert.encoder.layer.0.attention.output.dense.bias', 'module.vlbert.encoder.layer.0.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.0.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.0.intermediate.dense.weight', 'module.vlbert.encoder.layer.0.intermediate.dense.bias', 'module.vlbert.encoder.layer.0.output.dense.weight', 'module.vlbert.encoder.layer.0.output.dense.bias', 'module.vlbert.encoder.layer.0.output.LayerNorm.weight', 'module.vlbert.encoder.layer.0.output.LayerNorm.bias', 'module.vlbert.encoder.layer.1.attention.self.query.weight', 'module.vlbert.encoder.layer.1.attention.self.query.bias', 'module.vlbert.encoder.layer.1.attention.self.key.weight', 'module.vlbert.encoder.layer.1.attention.self.key.bias', 'module.vlbert.encoder.layer.1.attention.self.value.weight', 'module.vlbert.encoder.layer.1.attention.self.value.bias', 'module.vlbert.encoder.layer.1.attention.output.dense.weight', 'module.vlbert.encoder.layer.1.attention.output.dense.bias', 'module.vlbert.encoder.layer.1.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.1.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.1.intermediate.dense.weight', 'module.vlbert.encoder.layer.1.intermediate.dense.bias', 'module.vlbert.encoder.layer.1.output.dense.weight', 'module.vlbert.encoder.layer.1.output.dense.bias', 'module.vlbert.encoder.layer.1.output.LayerNorm.weight', 'module.vlbert.encoder.layer.1.output.LayerNorm.bias', 'module.vlbert.encoder.layer.2.attention.self.query.weight', 'module.vlbert.encoder.layer.2.attention.self.query.bias', 'module.vlbert.encoder.layer.2.attention.self.key.weight', 'module.vlbert.encoder.layer.2.attention.self.key.bias', 'module.vlbert.encoder.layer.2.attention.self.value.weight', 'module.vlbert.encoder.layer.2.attention.self.value.bias', 'module.vlbert.encoder.layer.2.attention.output.dense.weight', 'module.vlbert.encoder.layer.2.attention.output.dense.bias', 'module.vlbert.encoder.layer.2.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.2.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.2.intermediate.dense.weight', 'module.vlbert.encoder.layer.2.intermediate.dense.bias', 'module.vlbert.encoder.layer.2.output.dense.weight', 'module.vlbert.encoder.layer.2.output.dense.bias', 'module.vlbert.encoder.layer.2.output.LayerNorm.weight', 'module.vlbert.encoder.layer.2.output.LayerNorm.bias', 'module.vlbert.encoder.layer.3.attention.self.query.weight', 'module.vlbert.encoder.layer.3.attention.self.query.bias', 'module.vlbert.encoder.layer.3.attention.self.key.weight', 'module.vlbert.encoder.layer.3.attention.self.key.bias', 'module.vlbert.encoder.layer.3.attention.self.value.weight', 'module.vlbert.encoder.layer.3.attention.self.value.bias', 'module.vlbert.encoder.layer.3.attention.output.dense.weight', 'module.vlbert.encoder.layer.3.attention.output.dense.bias', 'module.vlbert.encoder.layer.3.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.3.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.3.intermediate.dense.weight', 'module.vlbert.encoder.layer.3.intermediate.dense.bias', 'module.vlbert.encoder.layer.3.output.dense.weight', 'module.vlbert.encoder.layer.3.output.dense.bias', 'module.vlbert.encoder.layer.3.output.LayerNorm.weight', 'module.vlbert.encoder.layer.3.output.LayerNorm.bias', 'module.vlbert.encoder.layer.4.attention.self.query.weight', 'module.vlbert.encoder.layer.4.attention.self.query.bias', 'module.vlbert.encoder.layer.4.attention.self.key.weight', 'module.vlbert.encoder.layer.4.attention.self.key.bias', 'module.vlbert.encoder.layer.4.attention.self.value.weight', 'module.vlbert.encoder.layer.4.attention.self.value.bias', 'module.vlbert.encoder.layer.4.attention.output.dense.weight', 'module.vlbert.encoder.layer.4.attention.output.dense.bias', 'module.vlbert.encoder.layer.4.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.4.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.4.intermediate.dense.weight', 'module.vlbert.encoder.layer.4.intermediate.dense.bias', 'module.vlbert.encoder.layer.4.output.dense.weight', 'module.vlbert.encoder.layer.4.output.dense.bias', 'module.vlbert.encoder.layer.4.output.LayerNorm.weight', 'module.vlbert.encoder.layer.4.output.LayerNorm.bias', 'module.vlbert.encoder.layer.5.attention.self.query.weight', 'module.vlbert.encoder.layer.5.attention.self.query.bias', 'module.vlbert.encoder.layer.5.attention.self.key.weight', 'module.vlbert.encoder.layer.5.attention.self.key.bias', 'module.vlbert.encoder.layer.5.attention.self.value.weight', 'module.vlbert.encoder.layer.5.attention.self.value.bias', 'module.vlbert.encoder.layer.5.attention.output.dense.weight', 'module.vlbert.encoder.layer.5.attention.output.dense.bias', 'module.vlbert.encoder.layer.5.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.5.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.5.intermediate.dense.weight', 'module.vlbert.encoder.layer.5.intermediate.dense.bias', 'module.vlbert.encoder.layer.5.output.dense.weight', 'module.vlbert.encoder.layer.5.output.dense.bias', 'module.vlbert.encoder.layer.5.output.LayerNorm.weight', 'module.vlbert.encoder.layer.5.output.LayerNorm.bias', 'module.vlbert.encoder.layer.6.attention.self.query.weight', 'module.vlbert.encoder.layer.6.attention.self.query.bias', 'module.vlbert.encoder.layer.6.attention.self.key.weight', 'module.vlbert.encoder.layer.6.attention.self.key.bias', 'module.vlbert.encoder.layer.6.attention.self.value.weight', 'module.vlbert.encoder.layer.6.attention.self.value.bias', 'module.vlbert.encoder.layer.6.attention.output.dense.weight', 'module.vlbert.encoder.layer.6.attention.output.dense.bias', 'module.vlbert.encoder.layer.6.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.6.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.6.intermediate.dense.weight', 'module.vlbert.encoder.layer.6.intermediate.dense.bias', 'module.vlbert.encoder.layer.6.output.dense.weight', 'module.vlbert.encoder.layer.6.output.dense.bias', 'module.vlbert.encoder.layer.6.output.LayerNorm.weight', 'module.vlbert.encoder.layer.6.output.LayerNorm.bias', 'module.vlbert.encoder.layer.7.attention.self.query.weight', 'module.vlbert.encoder.layer.7.attention.self.query.bias', 'module.vlbert.encoder.layer.7.attention.self.key.weight', 'module.vlbert.encoder.layer.7.attention.self.key.bias', 'module.vlbert.encoder.layer.7.attention.self.value.weight', 'module.vlbert.encoder.layer.7.attention.self.value.bias', 'module.vlbert.encoder.layer.7.attention.output.dense.weight', 'module.vlbert.encoder.layer.7.attention.output.dense.bias', 'module.vlbert.encoder.layer.7.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.7.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.7.intermediate.dense.weight', 'module.vlbert.encoder.layer.7.intermediate.dense.bias', 'module.vlbert.encoder.layer.7.output.dense.weight', 'module.vlbert.encoder.layer.7.output.dense.bias', 'module.vlbert.encoder.layer.7.output.LayerNorm.weight', 'module.vlbert.encoder.layer.7.output.LayerNorm.bias', 'module.vlbert.encoder.layer.8.attention.self.query.weight', 'module.vlbert.encoder.layer.8.attention.self.query.bias', 'module.vlbert.encoder.layer.8.attention.self.key.weight', 'module.vlbert.encoder.layer.8.attention.self.key.bias', 'module.vlbert.encoder.layer.8.attention.self.value.weight', 'module.vlbert.encoder.layer.8.attention.self.value.bias', 'module.vlbert.encoder.layer.8.attention.output.dense.weight', 'module.vlbert.encoder.layer.8.attention.output.dense.bias', 'module.vlbert.encoder.layer.8.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.8.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.8.intermediate.dense.weight', 'module.vlbert.encoder.layer.8.intermediate.dense.bias', 'module.vlbert.encoder.layer.8.output.dense.weight', 'module.vlbert.encoder.layer.8.output.dense.bias', 'module.vlbert.encoder.layer.8.output.LayerNorm.weight', 'module.vlbert.encoder.layer.8.output.LayerNorm.bias', 'module.vlbert.encoder.layer.9.attention.self.query.weight', 'module.vlbert.encoder.layer.9.attention.self.query.bias', 'module.vlbert.encoder.layer.9.attention.self.key.weight', 'module.vlbert.encoder.layer.9.attention.self.key.bias', 'module.vlbert.encoder.layer.9.attention.self.value.weight', 'module.vlbert.encoder.layer.9.attention.self.value.bias', 'module.vlbert.encoder.layer.9.attention.output.dense.weight', 'module.vlbert.encoder.layer.9.attention.output.dense.bias', 'module.vlbert.encoder.layer.9.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.9.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.9.intermediate.dense.weight', 'module.vlbert.encoder.layer.9.intermediate.dense.bias', 'module.vlbert.encoder.layer.9.output.dense.weight', 'module.vlbert.encoder.layer.9.output.dense.bias', 'module.vlbert.encoder.layer.9.output.LayerNorm.weight', 'module.vlbert.encoder.layer.9.output.LayerNorm.bias', 'module.vlbert.encoder.layer.10.attention.self.query.weight', 'module.vlbert.encoder.layer.10.attention.self.query.bias', 'module.vlbert.encoder.layer.10.attention.self.key.weight', 'module.vlbert.encoder.layer.10.attention.self.key.bias', 'module.vlbert.encoder.layer.10.attention.self.value.weight', 'module.vlbert.encoder.layer.10.attention.self.value.bias', 'module.vlbert.encoder.layer.10.attention.output.dense.weight', 'module.vlbert.encoder.layer.10.attention.output.dense.bias', 'module.vlbert.encoder.layer.10.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.10.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.10.intermediate.dense.weight', 'module.vlbert.encoder.layer.10.intermediate.dense.bias', 'module.vlbert.encoder.layer.10.output.dense.weight', 'module.vlbert.encoder.layer.10.output.dense.bias', 'module.vlbert.encoder.layer.10.output.LayerNorm.weight', 'module.vlbert.encoder.layer.10.output.LayerNorm.bias', 'module.vlbert.encoder.layer.11.attention.self.query.weight', 'module.vlbert.encoder.layer.11.attention.self.query.bias', 'module.vlbert.encoder.layer.11.attention.self.key.weight', 'module.vlbert.encoder.layer.11.attention.self.key.bias', 'module.vlbert.encoder.layer.11.attention.self.value.weight', 'module.vlbert.encoder.layer.11.attention.self.value.bias', 'module.vlbert.encoder.layer.11.attention.output.dense.weight', 'module.vlbert.encoder.layer.11.attention.output.dense.bias', 'module.vlbert.encoder.layer.11.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.11.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.11.intermediate.dense.weight', 'module.vlbert.encoder.layer.11.intermediate.dense.bias', 'module.vlbert.encoder.layer.11.output.dense.weight', 'module.vlbert.encoder.layer.11.output.dense.bias', 'module.vlbert.encoder.layer.11.output.LayerNorm.weight', 'module.vlbert.encoder.layer.11.output.LayerNorm.bias', 'module.final_mlp.0.dense.weight', 'module.final_mlp.0.dense.bias', 'module.final_mlp.0.LayerNorm.weight', 'module.final_mlp.0.LayerNorm.bias'])
[Partial Load] non matched keys: ['object_mask_visual_embedding.weight', 'object_mask_word_embedding.weight', 'vlbert.mlm_head.predictions.bias', 'vlbert.mlm_head.predictions.decoder.weight', 'vlbert.mvrc_head.transform.dense.weight', 'vlbert.mvrc_head.transform.dense.bias', 'vlbert.mvrc_head.region_cls_pred.weight', 'vlbert.mvrc_head.region_cls_pred.bias']
[Partial Load] non pretrain keys: ['module.final_mlp.2.weight', 'module.final_mlp.2.bias']
[Partial Load] partial load state dict of keys: dict_keys(['module.image_feature_extractor.obj_downsample.1.weight', 'module.image_feature_extractor.obj_downsample.1.bias', 'module.object_linguistic_embeddings.weight', 'module.vlbert.word_embeddings.weight', 'module.vlbert.end_embedding.weight', 'module.vlbert.position_embeddings.weight', 'module.vlbert.token_type_embeddings.weight', 'module.vlbert.embedding_LayerNorm.weight', 'module.vlbert.embedding_LayerNorm.bias', 'module.vlbert.visual_ln_text.weight', 'module.vlbert.visual_ln_text.bias', 'module.vlbert.visual_ln_object.weight', 'module.vlbert.visual_ln_object.bias', 'module.vlbert.encoder.layer.0.attention.self.query.weight', 'module.vlbert.encoder.layer.0.attention.self.query.bias', 'module.vlbert.encoder.layer.0.attention.self.key.weight', 'module.vlbert.encoder.layer.0.attention.self.key.bias', 'module.vlbert.encoder.layer.0.attention.self.value.weight', 'module.vlbert.encoder.layer.0.attention.self.value.bias', 'module.vlbert.encoder.layer.0.attention.output.dense.weight', 'module.vlbert.encoder.layer.0.attention.output.dense.bias', 'module.vlbert.encoder.layer.0.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.0.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.0.intermediate.dense.weight', 'module.vlbert.encoder.layer.0.intermediate.dense.bias', 'module.vlbert.encoder.layer.0.output.dense.weight', 'module.vlbert.encoder.layer.0.output.dense.bias', 'module.vlbert.encoder.layer.0.output.LayerNorm.weight', 'module.vlbert.encoder.layer.0.output.LayerNorm.bias', 'module.vlbert.encoder.layer.1.attention.self.query.weight', 'module.vlbert.encoder.layer.1.attention.self.query.bias', 'module.vlbert.encoder.layer.1.attention.self.key.weight', 'module.vlbert.encoder.layer.1.attention.self.key.bias', 'module.vlbert.encoder.layer.1.attention.self.value.weight', 'module.vlbert.encoder.layer.1.attention.self.value.bias', 'module.vlbert.encoder.layer.1.attention.output.dense.weight', 'module.vlbert.encoder.layer.1.attention.output.dense.bias', 'module.vlbert.encoder.layer.1.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.1.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.1.intermediate.dense.weight', 'module.vlbert.encoder.layer.1.intermediate.dense.bias', 'module.vlbert.encoder.layer.1.output.dense.weight', 'module.vlbert.encoder.layer.1.output.dense.bias', 'module.vlbert.encoder.layer.1.output.LayerNorm.weight', 'module.vlbert.encoder.layer.1.output.LayerNorm.bias', 'module.vlbert.encoder.layer.2.attention.self.query.weight', 'module.vlbert.encoder.layer.2.attention.self.query.bias', 'module.vlbert.encoder.layer.2.attention.self.key.weight', 'module.vlbert.encoder.layer.2.attention.self.key.bias', 'module.vlbert.encoder.layer.2.attention.self.value.weight', 'module.vlbert.encoder.layer.2.attention.self.value.bias', 'module.vlbert.encoder.layer.2.attention.output.dense.weight', 'module.vlbert.encoder.layer.2.attention.output.dense.bias', 'module.vlbert.encoder.layer.2.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.2.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.2.intermediate.dense.weight', 'module.vlbert.encoder.layer.2.intermediate.dense.bias', 'module.vlbert.encoder.layer.2.output.dense.weight', 'module.vlbert.encoder.layer.2.output.dense.bias', 'module.vlbert.encoder.layer.2.output.LayerNorm.weight', 'module.vlbert.encoder.layer.2.output.LayerNorm.bias', 'module.vlbert.encoder.layer.3.attention.self.query.weight', 'module.vlbert.encoder.layer.3.attention.self.query.bias', 'module.vlbert.encoder.layer.3.attention.self.key.weight', 'module.vlbert.encoder.layer.3.attention.self.key.bias', 'module.vlbert.encoder.layer.3.attention.self.value.weight', 'module.vlbert.encoder.layer.3.attention.self.value.bias', 'module.vlbert.encoder.layer.3.attention.output.dense.weight', 'module.vlbert.encoder.layer.3.attention.output.dense.bias', 'module.vlbert.encoder.layer.3.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.3.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.3.intermediate.dense.weight', 'module.vlbert.encoder.layer.3.intermediate.dense.bias', 'module.vlbert.encoder.layer.3.output.dense.weight', 'module.vlbert.encoder.layer.3.output.dense.bias', 'module.vlbert.encoder.layer.3.output.LayerNorm.weight', 'module.vlbert.encoder.layer.3.output.LayerNorm.bias', 'module.vlbert.encoder.layer.4.attention.self.query.weight', 'module.vlbert.encoder.layer.4.attention.self.query.bias', 'module.vlbert.encoder.layer.4.attention.self.key.weight', 'module.vlbert.encoder.layer.4.attention.self.key.bias', 'module.vlbert.encoder.layer.4.attention.self.value.weight', 'module.vlbert.encoder.layer.4.attention.self.value.bias', 'module.vlbert.encoder.layer.4.attention.output.dense.weight', 'module.vlbert.encoder.layer.4.attention.output.dense.bias', 'module.vlbert.encoder.layer.4.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.4.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.4.intermediate.dense.weight', 'module.vlbert.encoder.layer.4.intermediate.dense.bias', 'module.vlbert.encoder.layer.4.output.dense.weight', 'module.vlbert.encoder.layer.4.output.dense.bias', 'module.vlbert.encoder.layer.4.output.LayerNorm.weight', 'module.vlbert.encoder.layer.4.output.LayerNorm.bias', 'module.vlbert.encoder.layer.5.attention.self.query.weight', 'module.vlbert.encoder.layer.5.attention.self.query.bias', 'module.vlbert.encoder.layer.5.attention.self.key.weight', 'module.vlbert.encoder.layer.5.attention.self.key.bias', 'module.vlbert.encoder.layer.5.attention.self.value.weight', 'module.vlbert.encoder.layer.5.attention.self.value.bias', 'module.vlbert.encoder.layer.5.attention.output.dense.weight', 'module.vlbert.encoder.layer.5.attention.output.dense.bias', 'module.vlbert.encoder.layer.5.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.5.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.5.intermediate.dense.weight', 'module.vlbert.encoder.layer.5.intermediate.dense.bias', 'module.vlbert.encoder.layer.5.output.dense.weight', 'module.vlbert.encoder.layer.5.output.dense.bias', 'module.vlbert.encoder.layer.5.output.LayerNorm.weight', 'module.vlbert.encoder.layer.5.output.LayerNorm.bias', 'module.vlbert.encoder.layer.6.attention.self.query.weight', 'module.vlbert.encoder.layer.6.attention.self.query.bias', 'module.vlbert.encoder.layer.6.attention.self.key.weight', 'module.vlbert.encoder.layer.6.attention.self.key.bias', 'module.vlbert.encoder.layer.6.attention.self.value.weight', 'module.vlbert.encoder.layer.6.attention.self.value.bias', 'module.vlbert.encoder.layer.6.attention.output.dense.weight', 'module.vlbert.encoder.layer.6.attention.output.dense.bias', 'module.vlbert.encoder.layer.6.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.6.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.6.intermediate.dense.weight', 'module.vlbert.encoder.layer.6.intermediate.dense.bias', 'module.vlbert.encoder.layer.6.output.dense.weight', 'module.vlbert.encoder.layer.6.output.dense.bias', 'module.vlbert.encoder.layer.6.output.LayerNorm.weight', 'module.vlbert.encoder.layer.6.output.LayerNorm.bias', 'module.vlbert.encoder.layer.7.attention.self.query.weight', 'module.vlbert.encoder.layer.7.attention.self.query.bias', 'module.vlbert.encoder.layer.7.attention.self.key.weight', 'module.vlbert.encoder.layer.7.attention.self.key.bias', 'module.vlbert.encoder.layer.7.attention.self.value.weight', 'module.vlbert.encoder.layer.7.attention.self.value.bias', 'module.vlbert.encoder.layer.7.attention.output.dense.weight', 'module.vlbert.encoder.layer.7.attention.output.dense.bias', 'module.vlbert.encoder.layer.7.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.7.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.7.intermediate.dense.weight', 'module.vlbert.encoder.layer.7.intermediate.dense.bias', 'module.vlbert.encoder.layer.7.output.dense.weight', 'module.vlbert.encoder.layer.7.output.dense.bias', 'module.vlbert.encoder.layer.7.output.LayerNorm.weight', 'module.vlbert.encoder.layer.7.output.LayerNorm.bias', 'module.vlbert.encoder.layer.8.attention.self.query.weight', 'module.vlbert.encoder.layer.8.attention.self.query.bias', 'module.vlbert.encoder.layer.8.attention.self.key.weight', 'module.vlbert.encoder.layer.8.attention.self.key.bias', 'module.vlbert.encoder.layer.8.attention.self.value.weight', 'module.vlbert.encoder.layer.8.attention.self.value.bias', 'module.vlbert.encoder.layer.8.attention.output.dense.weight', 'module.vlbert.encoder.layer.8.attention.output.dense.bias', 'module.vlbert.encoder.layer.8.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.8.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.8.intermediate.dense.weight', 'module.vlbert.encoder.layer.8.intermediate.dense.bias', 'module.vlbert.encoder.layer.8.output.dense.weight', 'module.vlbert.encoder.layer.8.output.dense.bias', 'module.vlbert.encoder.layer.8.output.LayerNorm.weight', 'module.vlbert.encoder.layer.8.output.LayerNorm.bias', 'module.vlbert.encoder.layer.9.attention.self.query.weight', 'module.vlbert.encoder.layer.9.attention.self.query.bias', 'module.vlbert.encoder.layer.9.attention.self.key.weight', 'module.vlbert.encoder.layer.9.attention.self.key.bias', 'module.vlbert.encoder.layer.9.attention.self.value.weight', 'module.vlbert.encoder.layer.9.attention.self.value.bias', 'module.vlbert.encoder.layer.9.attention.output.dense.weight', 'module.vlbert.encoder.layer.9.attention.output.dense.bias', 'module.vlbert.encoder.layer.9.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.9.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.9.intermediate.dense.weight', 'module.vlbert.encoder.layer.9.intermediate.dense.bias', 'module.vlbert.encoder.layer.9.output.dense.weight', 'module.vlbert.encoder.layer.9.output.dense.bias', 'module.vlbert.encoder.layer.9.output.LayerNorm.weight', 'module.vlbert.encoder.layer.9.output.LayerNorm.bias', 'module.vlbert.encoder.layer.10.attention.self.query.weight', 'module.vlbert.encoder.layer.10.attention.self.query.bias', 'module.vlbert.encoder.layer.10.attention.self.key.weight', 'module.vlbert.encoder.layer.10.attention.self.key.bias', 'module.vlbert.encoder.layer.10.attention.self.value.weight', 'module.vlbert.encoder.layer.10.attention.self.value.bias', 'module.vlbert.encoder.layer.10.attention.output.dense.weight', 'module.vlbert.encoder.layer.10.attention.output.dense.bias', 'module.vlbert.encoder.layer.10.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.10.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.10.intermediate.dense.weight', 'module.vlbert.encoder.layer.10.intermediate.dense.bias', 'module.vlbert.encoder.layer.10.output.dense.weight', 'module.vlbert.encoder.layer.10.output.dense.bias', 'module.vlbert.encoder.layer.10.output.LayerNorm.weight', 'module.vlbert.encoder.layer.10.output.LayerNorm.bias', 'module.vlbert.encoder.layer.11.attention.self.query.weight', 'module.vlbert.encoder.layer.11.attention.self.query.bias', 'module.vlbert.encoder.layer.11.attention.self.key.weight', 'module.vlbert.encoder.layer.11.attention.self.key.bias', 'module.vlbert.encoder.layer.11.attention.self.value.weight', 'module.vlbert.encoder.layer.11.attention.self.value.bias', 'module.vlbert.encoder.layer.11.attention.output.dense.weight', 'module.vlbert.encoder.layer.11.attention.output.dense.bias', 'module.vlbert.encoder.layer.11.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.11.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.11.intermediate.dense.weight', 'module.vlbert.encoder.layer.11.intermediate.dense.bias', 'module.vlbert.encoder.layer.11.output.dense.weight', 'module.vlbert.encoder.layer.11.output.dense.bias', 'module.vlbert.encoder.layer.11.output.LayerNorm.weight', 'module.vlbert.encoder.layer.11.output.LayerNorm.bias', 'module.final_mlp.0.dense.weight', 'module.final_mlp.0.dense.bias', 'module.final_mlp.0.LayerNorm.weight', 'module.final_mlp.0.LayerNorm.bias'])
[Partial Load] non matched keys: ['object_mask_visual_embedding.weight', 'object_mask_word_embedding.weight', 'vlbert.mlm_head.predictions.bias', 'vlbert.mlm_head.predictions.decoder.weight', 'vlbert.mvrc_head.transform.dense.weight', 'vlbert.mvrc_head.transform.dense.bias', 'vlbert.mvrc_head.region_cls_pred.weight', 'vlbert.mvrc_head.region_cls_pred.bias']
[Partial Load] non pretrain keys: ['module.final_mlp.2.weight', 'module.final_mlp.2.bias']
[Partial Load] partial load state dict of keys: dict_keys(['module.image_feature_extractor.obj_downsample.1.weight', 'module.image_feature_extractor.obj_downsample.1.bias', 'module.object_linguistic_embeddings.weight', 'module.vlbert.word_embeddings.weight', 'module.vlbert.end_embedding.weight', 'module.vlbert.position_embeddings.weight', 'module.vlbert.token_type_embeddings.weight', 'module.vlbert.embedding_LayerNorm.weight', 'module.vlbert.embedding_LayerNorm.bias', 'module.vlbert.visual_ln_text.weight', 'module.vlbert.visual_ln_text.bias', 'module.vlbert.visual_ln_object.weight', 'module.vlbert.visual_ln_object.bias', 'module.vlbert.encoder.layer.0.attention.self.query.weight', 'module.vlbert.encoder.layer.0.attention.self.query.bias', 'module.vlbert.encoder.layer.0.attention.self.key.weight', 'module.vlbert.encoder.layer.0.attention.self.key.bias', 'module.vlbert.encoder.layer.0.attention.self.value.weight', 'module.vlbert.encoder.layer.0.attention.self.value.bias', 'module.vlbert.encoder.layer.0.attention.output.dense.weight', 'module.vlbert.encoder.layer.0.attention.output.dense.bias', 'module.vlbert.encoder.layer.0.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.0.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.0.intermediate.dense.weight', 'module.vlbert.encoder.layer.0.intermediate.dense.bias', 'module.vlbert.encoder.layer.0.output.dense.weight', 'module.vlbert.encoder.layer.0.output.dense.bias', 'module.vlbert.encoder.layer.0.output.LayerNorm.weight', 'module.vlbert.encoder.layer.0.output.LayerNorm.bias', 'module.vlbert.encoder.layer.1.attention.self.query.weight', 'module.vlbert.encoder.layer.1.attention.self.query.bias', 'module.vlbert.encoder.layer.1.attention.self.key.weight', 'module.vlbert.encoder.layer.1.attention.self.key.bias', 'module.vlbert.encoder.layer.1.attention.self.value.weight', 'module.vlbert.encoder.layer.1.attention.self.value.bias', 'module.vlbert.encoder.layer.1.attention.output.dense.weight', 'module.vlbert.encoder.layer.1.attention.output.dense.bias', 'module.vlbert.encoder.layer.1.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.1.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.1.intermediate.dense.weight', 'module.vlbert.encoder.layer.1.intermediate.dense.bias', 'module.vlbert.encoder.layer.1.output.dense.weight', 'module.vlbert.encoder.layer.1.output.dense.bias', 'module.vlbert.encoder.layer.1.output.LayerNorm.weight', 'module.vlbert.encoder.layer.1.output.LayerNorm.bias', 'module.vlbert.encoder.layer.2.attention.self.query.weight', 'module.vlbert.encoder.layer.2.attention.self.query.bias', 'module.vlbert.encoder.layer.2.attention.self.key.weight', 'module.vlbert.encoder.layer.2.attention.self.key.bias', 'module.vlbert.encoder.layer.2.attention.self.value.weight', 'module.vlbert.encoder.layer.2.attention.self.value.bias', 'module.vlbert.encoder.layer.2.attention.output.dense.weight', 'module.vlbert.encoder.layer.2.attention.output.dense.bias', 'module.vlbert.encoder.layer.2.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.2.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.2.intermediate.dense.weight', 'module.vlbert.encoder.layer.2.intermediate.dense.bias', 'module.vlbert.encoder.layer.2.output.dense.weight', 'module.vlbert.encoder.layer.2.output.dense.bias', 'module.vlbert.encoder.layer.2.output.LayerNorm.weight', 'module.vlbert.encoder.layer.2.output.LayerNorm.bias', 'module.vlbert.encoder.layer.3.attention.self.query.weight', 'module.vlbert.encoder.layer.3.attention.self.query.bias', 'module.vlbert.encoder.layer.3.attention.self.key.weight', 'module.vlbert.encoder.layer.3.attention.self.key.bias', 'module.vlbert.encoder.layer.3.attention.self.value.weight', 'module.vlbert.encoder.layer.3.attention.self.value.bias', 'module.vlbert.encoder.layer.3.attention.output.dense.weight', 'module.vlbert.encoder.layer.3.attention.output.dense.bias', 'module.vlbert.encoder.layer.3.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.3.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.3.intermediate.dense.weight', 'module.vlbert.encoder.layer.3.intermediate.dense.bias', 'module.vlbert.encoder.layer.3.output.dense.weight', 'module.vlbert.encoder.layer.3.output.dense.bias', 'module.vlbert.encoder.layer.3.output.LayerNorm.weight', 'module.vlbert.encoder.layer.3.output.LayerNorm.bias', 'module.vlbert.encoder.layer.4.attention.self.query.weight', 'module.vlbert.encoder.layer.4.attention.self.query.bias', 'module.vlbert.encoder.layer.4.attention.self.key.weight', 'module.vlbert.encoder.layer.4.attention.self.key.bias', 'module.vlbert.encoder.layer.4.attention.self.value.weight', 'module.vlbert.encoder.layer.4.attention.self.value.bias', 'module.vlbert.encoder.layer.4.attention.output.dense.weight', 'module.vlbert.encoder.layer.4.attention.output.dense.bias', 'module.vlbert.encoder.layer.4.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.4.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.4.intermediate.dense.weight', 'module.vlbert.encoder.layer.4.intermediate.dense.bias', 'module.vlbert.encoder.layer.4.output.dense.weight', 'module.vlbert.encoder.layer.4.output.dense.bias', 'module.vlbert.encoder.layer.4.output.LayerNorm.weight', 'module.vlbert.encoder.layer.4.output.LayerNorm.bias', 'module.vlbert.encoder.layer.5.attention.self.query.weight', 'module.vlbert.encoder.layer.5.attention.self.query.bias', 'module.vlbert.encoder.layer.5.attention.self.key.weight', 'module.vlbert.encoder.layer.5.attention.self.key.bias', 'module.vlbert.encoder.layer.5.attention.self.value.weight', 'module.vlbert.encoder.layer.5.attention.self.value.bias', 'module.vlbert.encoder.layer.5.attention.output.dense.weight', 'module.vlbert.encoder.layer.5.attention.output.dense.bias', 'module.vlbert.encoder.layer.5.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.5.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.5.intermediate.dense.weight', 'module.vlbert.encoder.layer.5.intermediate.dense.bias', 'module.vlbert.encoder.layer.5.output.dense.weight', 'module.vlbert.encoder.layer.5.output.dense.bias', 'module.vlbert.encoder.layer.5.output.LayerNorm.weight', 'module.vlbert.encoder.layer.5.output.LayerNorm.bias', 'module.vlbert.encoder.layer.6.attention.self.query.weight', 'module.vlbert.encoder.layer.6.attention.self.query.bias', 'module.vlbert.encoder.layer.6.attention.self.key.weight', 'module.vlbert.encoder.layer.6.attention.self.key.bias', 'module.vlbert.encoder.layer.6.attention.self.value.weight', 'module.vlbert.encoder.layer.6.attention.self.value.bias', 'module.vlbert.encoder.layer.6.attention.output.dense.weight', 'module.vlbert.encoder.layer.6.attention.output.dense.bias', 'module.vlbert.encoder.layer.6.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.6.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.6.intermediate.dense.weight', 'module.vlbert.encoder.layer.6.intermediate.dense.bias', 'module.vlbert.encoder.layer.6.output.dense.weight', 'module.vlbert.encoder.layer.6.output.dense.bias', 'module.vlbert.encoder.layer.6.output.LayerNorm.weight', 'module.vlbert.encoder.layer.6.output.LayerNorm.bias', 'module.vlbert.encoder.layer.7.attention.self.query.weight', 'module.vlbert.encoder.layer.7.attention.self.query.bias', 'module.vlbert.encoder.layer.7.attention.self.key.weight', 'module.vlbert.encoder.layer.7.attention.self.key.bias', 'module.vlbert.encoder.layer.7.attention.self.value.weight', 'module.vlbert.encoder.layer.7.attention.self.value.bias', 'module.vlbert.encoder.layer.7.attention.output.dense.weight', 'module.vlbert.encoder.layer.7.attention.output.dense.bias', 'module.vlbert.encoder.layer.7.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.7.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.7.intermediate.dense.weight', 'module.vlbert.encoder.layer.7.intermediate.dense.bias', 'module.vlbert.encoder.layer.7.output.dense.weight', 'module.vlbert.encoder.layer.7.output.dense.bias', 'module.vlbert.encoder.layer.7.output.LayerNorm.weight', 'module.vlbert.encoder.layer.7.output.LayerNorm.bias', 'module.vlbert.encoder.layer.8.attention.self.query.weight', 'module.vlbert.encoder.layer.8.attention.self.query.bias', 'module.vlbert.encoder.layer.8.attention.self.key.weight', 'module.vlbert.encoder.layer.8.attention.self.key.bias', 'module.vlbert.encoder.layer.8.attention.self.value.weight', 'module.vlbert.encoder.layer.8.attention.self.value.bias', 'module.vlbert.encoder.layer.8.attention.output.dense.weight', 'module.vlbert.encoder.layer.8.attention.output.dense.bias', 'module.vlbert.encoder.layer.8.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.8.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.8.intermediate.dense.weight', 'module.vlbert.encoder.layer.8.intermediate.dense.bias', 'module.vlbert.encoder.layer.8.output.dense.weight', 'module.vlbert.encoder.layer.8.output.dense.bias', 'module.vlbert.encoder.layer.8.output.LayerNorm.weight', 'module.vlbert.encoder.layer.8.output.LayerNorm.bias', 'module.vlbert.encoder.layer.9.attention.self.query.weight', 'module.vlbert.encoder.layer.9.attention.self.query.bias', 'module.vlbert.encoder.layer.9.attention.self.key.weight', 'module.vlbert.encoder.layer.9.attention.self.key.bias', 'module.vlbert.encoder.layer.9.attention.self.value.weight', 'module.vlbert.encoder.layer.9.attention.self.value.bias', 'module.vlbert.encoder.layer.9.attention.output.dense.weight', 'module.vlbert.encoder.layer.9.attention.output.dense.bias', 'module.vlbert.encoder.layer.9.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.9.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.9.intermediate.dense.weight', 'module.vlbert.encoder.layer.9.intermediate.dense.bias', 'module.vlbert.encoder.layer.9.output.dense.weight', 'module.vlbert.encoder.layer.9.output.dense.bias', 'module.vlbert.encoder.layer.9.output.LayerNorm.weight', 'module.vlbert.encoder.layer.9.output.LayerNorm.bias', 'module.vlbert.encoder.layer.10.attention.self.query.weight', 'module.vlbert.encoder.layer.10.attention.self.query.bias', 'module.vlbert.encoder.layer.10.attention.self.key.weight', 'module.vlbert.encoder.layer.10.attention.self.key.bias', 'module.vlbert.encoder.layer.10.attention.self.value.weight', 'module.vlbert.encoder.layer.10.attention.self.value.bias', 'module.vlbert.encoder.layer.10.attention.output.dense.weight', 'module.vlbert.encoder.layer.10.attention.output.dense.bias', 'module.vlbert.encoder.layer.10.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.10.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.10.intermediate.dense.weight', 'module.vlbert.encoder.layer.10.intermediate.dense.bias', 'module.vlbert.encoder.layer.10.output.dense.weight', 'module.vlbert.encoder.layer.10.output.dense.bias', 'module.vlbert.encoder.layer.10.output.LayerNorm.weight', 'module.vlbert.encoder.layer.10.output.LayerNorm.bias', 'module.vlbert.encoder.layer.11.attention.self.query.weight', 'module.vlbert.encoder.layer.11.attention.self.query.bias', 'module.vlbert.encoder.layer.11.attention.self.key.weight', 'module.vlbert.encoder.layer.11.attention.self.key.bias', 'module.vlbert.encoder.layer.11.attention.self.value.weight', 'module.vlbert.encoder.layer.11.attention.self.value.bias', 'module.vlbert.encoder.layer.11.attention.output.dense.weight', 'module.vlbert.encoder.layer.11.attention.output.dense.bias', 'module.vlbert.encoder.layer.11.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.11.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.11.intermediate.dense.weight', 'module.vlbert.encoder.layer.11.intermediate.dense.bias', 'module.vlbert.encoder.layer.11.output.dense.weight', 'module.vlbert.encoder.layer.11.output.dense.bias', 'module.vlbert.encoder.layer.11.output.LayerNorm.weight', 'module.vlbert.encoder.layer.11.output.LayerNorm.bias', 'module.final_mlp.0.dense.weight', 'module.final_mlp.0.dense.bias', 'module.final_mlp.0.LayerNorm.weight', 'module.final_mlp.0.LayerNorm.bias'])
[Partial Load] non matched keys: ['object_mask_visual_embedding.weight', 'object_mask_word_embedding.weight', 'vlbert.mlm_head.predictions.bias', 'vlbert.mlm_head.predictions.decoder.weight', 'vlbert.mvrc_head.transform.dense.weight', 'vlbert.mvrc_head.transform.dense.bias', 'vlbert.mvrc_head.region_cls_pred.weight', 'vlbert.mvrc_head.region_cls_pred.bias']
[Partial Load] non pretrain keys: ['module.final_mlp.2.weight', 'module.final_mlp.2.bias']
[Partial Load] partial load state dict of keys: dict_keys(['module.image_feature_extractor.obj_downsample.1.weight', 'module.image_feature_extractor.obj_downsample.1.bias', 'module.object_linguistic_embeddings.weight', 'module.vlbert.word_embeddings.weight', 'module.vlbert.end_embedding.weight', 'module.vlbert.position_embeddings.weight', 'module.vlbert.token_type_embeddings.weight', 'module.vlbert.embedding_LayerNorm.weight', 'module.vlbert.embedding_LayerNorm.bias', 'module.vlbert.visual_ln_text.weight', 'module.vlbert.visual_ln_text.bias', 'module.vlbert.visual_ln_object.weight', 'module.vlbert.visual_ln_object.bias', 'module.vlbert.encoder.layer.0.attention.self.query.weight', 'module.vlbert.encoder.layer.0.attention.self.query.bias', 'module.vlbert.encoder.layer.0.attention.self.key.weight', 'module.vlbert.encoder.layer.0.attention.self.key.bias', 'module.vlbert.encoder.layer.0.attention.self.value.weight', 'module.vlbert.encoder.layer.0.attention.self.value.bias', 'module.vlbert.encoder.layer.0.attention.output.dense.weight', 'module.vlbert.encoder.layer.0.attention.output.dense.bias', 'module.vlbert.encoder.layer.0.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.0.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.0.intermediate.dense.weight', 'module.vlbert.encoder.layer.0.intermediate.dense.bias', 'module.vlbert.encoder.layer.0.output.dense.weight', 'module.vlbert.encoder.layer.0.output.dense.bias', 'module.vlbert.encoder.layer.0.output.LayerNorm.weight', 'module.vlbert.encoder.layer.0.output.LayerNorm.bias', 'module.vlbert.encoder.layer.1.attention.self.query.weight', 'module.vlbert.encoder.layer.1.attention.self.query.bias', 'module.vlbert.encoder.layer.1.attention.self.key.weight', 'module.vlbert.encoder.layer.1.attention.self.key.bias', 'module.vlbert.encoder.layer.1.attention.self.value.weight', 'module.vlbert.encoder.layer.1.attention.self.value.bias', 'module.vlbert.encoder.layer.1.attention.output.dense.weight', 'module.vlbert.encoder.layer.1.attention.output.dense.bias', 'module.vlbert.encoder.layer.1.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.1.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.1.intermediate.dense.weight', 'module.vlbert.encoder.layer.1.intermediate.dense.bias', 'module.vlbert.encoder.layer.1.output.dense.weight', 'module.vlbert.encoder.layer.1.output.dense.bias', 'module.vlbert.encoder.layer.1.output.LayerNorm.weight', 'module.vlbert.encoder.layer.1.output.LayerNorm.bias', 'module.vlbert.encoder.layer.2.attention.self.query.weight', 'module.vlbert.encoder.layer.2.attention.self.query.bias', 'module.vlbert.encoder.layer.2.attention.self.key.weight', 'module.vlbert.encoder.layer.2.attention.self.key.bias', 'module.vlbert.encoder.layer.2.attention.self.value.weight', 'module.vlbert.encoder.layer.2.attention.self.value.bias', 'module.vlbert.encoder.layer.2.attention.output.dense.weight', 'module.vlbert.encoder.layer.2.attention.output.dense.bias', 'module.vlbert.encoder.layer.2.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.2.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.2.intermediate.dense.weight', 'module.vlbert.encoder.layer.2.intermediate.dense.bias', 'module.vlbert.encoder.layer.2.output.dense.weight', 'module.vlbert.encoder.layer.2.output.dense.bias', 'module.vlbert.encoder.layer.2.output.LayerNorm.weight', 'module.vlbert.encoder.layer.2.output.LayerNorm.bias', 'module.vlbert.encoder.layer.3.attention.self.query.weight', 'module.vlbert.encoder.layer.3.attention.self.query.bias', 'module.vlbert.encoder.layer.3.attention.self.key.weight', 'module.vlbert.encoder.layer.3.attention.self.key.bias', 'module.vlbert.encoder.layer.3.attention.self.value.weight', 'module.vlbert.encoder.layer.3.attention.self.value.bias', 'module.vlbert.encoder.layer.3.attention.output.dense.weight', 'module.vlbert.encoder.layer.3.attention.output.dense.bias', 'module.vlbert.encoder.layer.3.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.3.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.3.intermediate.dense.weight', 'module.vlbert.encoder.layer.3.intermediate.dense.bias', 'module.vlbert.encoder.layer.3.output.dense.weight', 'module.vlbert.encoder.layer.3.output.dense.bias', 'module.vlbert.encoder.layer.3.output.LayerNorm.weight', 'module.vlbert.encoder.layer.3.output.LayerNorm.bias', 'module.vlbert.encoder.layer.4.attention.self.query.weight', 'module.vlbert.encoder.layer.4.attention.self.query.bias', 'module.vlbert.encoder.layer.4.attention.self.key.weight', 'module.vlbert.encoder.layer.4.attention.self.key.bias', 'module.vlbert.encoder.layer.4.attention.self.value.weight', 'module.vlbert.encoder.layer.4.attention.self.value.bias', 'module.vlbert.encoder.layer.4.attention.output.dense.weight', 'module.vlbert.encoder.layer.4.attention.output.dense.bias', 'module.vlbert.encoder.layer.4.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.4.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.4.intermediate.dense.weight', 'module.vlbert.encoder.layer.4.intermediate.dense.bias', 'module.vlbert.encoder.layer.4.output.dense.weight', 'module.vlbert.encoder.layer.4.output.dense.bias', 'module.vlbert.encoder.layer.4.output.LayerNorm.weight', 'module.vlbert.encoder.layer.4.output.LayerNorm.bias', 'module.vlbert.encoder.layer.5.attention.self.query.weight', 'module.vlbert.encoder.layer.5.attention.self.query.bias', 'module.vlbert.encoder.layer.5.attention.self.key.weight', 'module.vlbert.encoder.layer.5.attention.self.key.bias', 'module.vlbert.encoder.layer.5.attention.self.value.weight', 'module.vlbert.encoder.layer.5.attention.self.value.bias', 'module.vlbert.encoder.layer.5.attention.output.dense.weight', 'module.vlbert.encoder.layer.5.attention.output.dense.bias', 'module.vlbert.encoder.layer.5.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.5.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.5.intermediate.dense.weight', 'module.vlbert.encoder.layer.5.intermediate.dense.bias', 'module.vlbert.encoder.layer.5.output.dense.weight', 'module.vlbert.encoder.layer.5.output.dense.bias', 'module.vlbert.encoder.layer.5.output.LayerNorm.weight', 'module.vlbert.encoder.layer.5.output.LayerNorm.bias', 'module.vlbert.encoder.layer.6.attention.self.query.weight', 'module.vlbert.encoder.layer.6.attention.self.query.bias', 'module.vlbert.encoder.layer.6.attention.self.key.weight', 'module.vlbert.encoder.layer.6.attention.self.key.bias', 'module.vlbert.encoder.layer.6.attention.self.value.weight', 'module.vlbert.encoder.layer.6.attention.self.value.bias', 'module.vlbert.encoder.layer.6.attention.output.dense.weight', 'module.vlbert.encoder.layer.6.attention.output.dense.bias', 'module.vlbert.encoder.layer.6.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.6.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.6.intermediate.dense.weight', 'module.vlbert.encoder.layer.6.intermediate.dense.bias', 'module.vlbert.encoder.layer.6.output.dense.weight', 'module.vlbert.encoder.layer.6.output.dense.bias', 'module.vlbert.encoder.layer.6.output.LayerNorm.weight', 'module.vlbert.encoder.layer.6.output.LayerNorm.bias', 'module.vlbert.encoder.layer.7.attention.self.query.weight', 'module.vlbert.encoder.layer.7.attention.self.query.bias', 'module.vlbert.encoder.layer.7.attention.self.key.weight', 'module.vlbert.encoder.layer.7.attention.self.key.bias', 'module.vlbert.encoder.layer.7.attention.self.value.weight', 'module.vlbert.encoder.layer.7.attention.self.value.bias', 'module.vlbert.encoder.layer.7.attention.output.dense.weight', 'module.vlbert.encoder.layer.7.attention.output.dense.bias', 'module.vlbert.encoder.layer.7.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.7.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.7.intermediate.dense.weight', 'module.vlbert.encoder.layer.7.intermediate.dense.bias', 'module.vlbert.encoder.layer.7.output.dense.weight', 'module.vlbert.encoder.layer.7.output.dense.bias', 'module.vlbert.encoder.layer.7.output.LayerNorm.weight', 'module.vlbert.encoder.layer.7.output.LayerNorm.bias', 'module.vlbert.encoder.layer.8.attention.self.query.weight', 'module.vlbert.encoder.layer.8.attention.self.query.bias', 'module.vlbert.encoder.layer.8.attention.self.key.weight', 'module.vlbert.encoder.layer.8.attention.self.key.bias', 'module.vlbert.encoder.layer.8.attention.self.value.weight', 'module.vlbert.encoder.layer.8.attention.self.value.bias', 'module.vlbert.encoder.layer.8.attention.output.dense.weight', 'module.vlbert.encoder.layer.8.attention.output.dense.bias', 'module.vlbert.encoder.layer.8.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.8.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.8.intermediate.dense.weight', 'module.vlbert.encoder.layer.8.intermediate.dense.bias', 'module.vlbert.encoder.layer.8.output.dense.weight', 'module.vlbert.encoder.layer.8.output.dense.bias', 'module.vlbert.encoder.layer.8.output.LayerNorm.weight', 'module.vlbert.encoder.layer.8.output.LayerNorm.bias', 'module.vlbert.encoder.layer.9.attention.self.query.weight', 'module.vlbert.encoder.layer.9.attention.self.query.bias', 'module.vlbert.encoder.layer.9.attention.self.key.weight', 'module.vlbert.encoder.layer.9.attention.self.key.bias', 'module.vlbert.encoder.layer.9.attention.self.value.weight', 'module.vlbert.encoder.layer.9.attention.self.value.bias', 'module.vlbert.encoder.layer.9.attention.output.dense.weight', 'module.vlbert.encoder.layer.9.attention.output.dense.bias', 'module.vlbert.encoder.layer.9.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.9.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.9.intermediate.dense.weight', 'module.vlbert.encoder.layer.9.intermediate.dense.bias', 'module.vlbert.encoder.layer.9.output.dense.weight', 'module.vlbert.encoder.layer.9.output.dense.bias', 'module.vlbert.encoder.layer.9.output.LayerNorm.weight', 'module.vlbert.encoder.layer.9.output.LayerNorm.bias', 'module.vlbert.encoder.layer.10.attention.self.query.weight', 'module.vlbert.encoder.layer.10.attention.self.query.bias', 'module.vlbert.encoder.layer.10.attention.self.key.weight', 'module.vlbert.encoder.layer.10.attention.self.key.bias', 'module.vlbert.encoder.layer.10.attention.self.value.weight', 'module.vlbert.encoder.layer.10.attention.self.value.bias', 'module.vlbert.encoder.layer.10.attention.output.dense.weight', 'module.vlbert.encoder.layer.10.attention.output.dense.bias', 'module.vlbert.encoder.layer.10.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.10.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.10.intermediate.dense.weight', 'module.vlbert.encoder.layer.10.intermediate.dense.bias', 'module.vlbert.encoder.layer.10.output.dense.weight', 'module.vlbert.encoder.layer.10.output.dense.bias', 'module.vlbert.encoder.layer.10.output.LayerNorm.weight', 'module.vlbert.encoder.layer.10.output.LayerNorm.bias', 'module.vlbert.encoder.layer.11.attention.self.query.weight', 'module.vlbert.encoder.layer.11.attention.self.query.bias', 'module.vlbert.encoder.layer.11.attention.self.key.weight', 'module.vlbert.encoder.layer.11.attention.self.key.bias', 'module.vlbert.encoder.layer.11.attention.self.value.weight', 'module.vlbert.encoder.layer.11.attention.self.value.bias', 'module.vlbert.encoder.layer.11.attention.output.dense.weight', 'module.vlbert.encoder.layer.11.attention.output.dense.bias', 'module.vlbert.encoder.layer.11.attention.output.LayerNorm.weight', 'module.vlbert.encoder.layer.11.attention.output.LayerNorm.bias', 'module.vlbert.encoder.layer.11.intermediate.dense.weight', 'module.vlbert.encoder.layer.11.intermediate.dense.bias', 'module.vlbert.encoder.layer.11.output.dense.weight', 'module.vlbert.encoder.layer.11.output.dense.bias', 'module.vlbert.encoder.layer.11.output.LayerNorm.weight', 'module.vlbert.encoder.layer.11.output.LayerNorm.bias', 'module.final_mlp.0.dense.weight', 'module.final_mlp.0.dense.bias', 'module.final_mlp.0.LayerNorm.weight', 'module.final_mlp.0.LayerNorm.bias'])
[Partial Load] non matched keys: ['object_mask_visual_embedding.weight', 'object_mask_word_embedding.weight', 'vlbert.mlm_head.predictions.bias', 'vlbert.mlm_head.predictions.decoder.weight', 'vlbert.mvrc_head.transform.dense.weight', 'vlbert.mvrc_head.transform.dense.bias', 'vlbert.mvrc_head.region_cls_pred.weight', 'vlbert.mvrc_head.region_cls_pred.bias']
[Partial Load] non pretrain keys: ['module.final_mlp.2.weight', 'module.final_mlp.2.bias']
Initializing classifier weight from pretrained word embeddings...
Initializing classifier weight from pretrained word embeddings...
Initializing classifier weight from pretrained word embeddings...
Initializing classifier weight from pretrained word embeddings...
PROGRESS: 0.00%
PROGRESS: 0.00%
PROGRESS: 0.00%
PROGRESS: 0.00%
Rank[  3]Epoch[0] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-SoftAcc=0.021094,	AnsLoss=1162.253174,	
Rank[  0]Epoch[0] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-SoftAcc=0.021094,	AnsLoss=1162.253174,	
Rank[  1]Epoch[0] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-SoftAcc=0.021094,	AnsLoss=1162.253174,	
Rank[  2]Epoch[0] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-SoftAcc=0.021094,	AnsLoss=1162.253174,	
Rank[  0]Epoch[0] Batch [100]	Speed: 100.52 samples/s ETA: 0 d  2 h 15 m	Data: 0.188 Tran: 0.004 F: 0.133 B: 0.236 O: 0.119 M: 0.004	Train-SoftAcc=0.227696,	AnsLoss=162.410202,	
Rank[  3]Epoch[0] Batch [100]	Speed: 100.52 samples/s ETA: 0 d  2 h 15 m	Data: 0.062 Tran: 0.005 F: 0.135 B: 0.245 O: 0.233 M: 0.004	Train-SoftAcc=0.227696,	AnsLoss=162.410202,	
Rank[  2]Epoch[0] Batch [100]	Speed: 100.52 samples/s ETA: 0 d  2 h 15 m	Data: 0.126 Tran: 0.005 F: 0.131 B: 0.237 O: 0.181 M: 0.003	Train-SoftAcc=0.227696,	AnsLoss=162.410202,	
Rank[  1]Epoch[0] Batch [100]	Speed: 100.52 samples/s ETA: 0 d  2 h 15 m	Data: 0.132 Tran: 0.004 F: 0.136 B: 0.244 O: 0.164 M: 0.004	Train-SoftAcc=0.227696,	AnsLoss=162.410202,	
Rank[  3]Epoch[0] Batch [200]	Speed: 122.36 samples/s ETA: 0 d  1 h 50 m	Data: 0.005 Tran: 0.005 F: 0.123 B: 0.241 O: 0.142 M: 0.006	Train-SoftAcc=0.327122,	AnsLoss=84.091629,	
Rank[  0]Epoch[0] Batch [200]	Speed: 122.36 samples/s ETA: 0 d  1 h 50 m	Data: 0.017 Tran: 0.005 F: 0.123 B: 0.235 O: 0.136 M: 0.006	Train-SoftAcc=0.327122,	AnsLoss=84.091629,	
Rank[  2]Epoch[0] Batch [200]	Speed: 122.36 samples/s ETA: 0 d  1 h 50 m	Data: 0.056 Tran: 0.004 F: 0.124 B: 0.234 O: 0.098 M: 0.005	Train-SoftAcc=0.327122,	AnsLoss=84.091629,	
Rank[  1]Epoch[0] Batch [200]	Speed: 122.36 samples/s ETA: 0 d  1 h 50 m	Data: 0.044 Tran: 0.004 F: 0.124 B: 0.241 O: 0.104 M: 0.006	Train-SoftAcc=0.327122,	AnsLoss=84.091629,	
Rank[  0]Epoch[0] Batch [300]	Speed: 142.95 samples/s ETA: 0 d  1 h 33 m	Data: 0.005 Tran: 0.005 F: 0.123 B: 0.235 O: 0.074 M: 0.005	Train-SoftAcc=0.371409,	AnsLoss=57.670460,	
Rank[  1]Epoch[0] Batch [300]	Speed: 142.94 samples/s ETA: 0 d  1 h 33 m	Data: 0.005 Tran: 0.005 F: 0.124 B: 0.241 O: 0.067 M: 0.005	Train-SoftAcc=0.371409,	AnsLoss=57.670460,	
Rank[  2]Epoch[0] Batch [300]	Speed: 142.94 samples/s ETA: 0 d  1 h 33 m	Data: 0.015 Tran: 0.004 F: 0.123 B: 0.235 O: 0.065 M: 0.005	Train-SoftAcc=0.371409,	AnsLoss=57.670460,	
Rank[  3]Epoch[0] Batch [300]	Speed: 142.94 samples/s ETA: 0 d  1 h 33 m	Data: 0.005 Tran: 0.005 F: 0.125 B: 0.242 O: 0.064 M: 0.005	Train-SoftAcc=0.371409,	AnsLoss=57.670460,	
Rank[  0]Epoch[0] Batch [400]	Speed: 146.49 samples/s ETA: 0 d  1 h 30 m	Data: 0.005 Tran: 0.005 F: 0.124 B: 0.235 O: 0.060 M: 0.007	Train-SoftAcc=0.397536,	AnsLoss=44.380054,	
Rank[  1]Epoch[0] Batch [400]	Speed: 146.49 samples/s ETA: 0 d  1 h 30 m	Data: 0.005 Tran: 0.005 F: 0.124 B: 0.240 O: 0.056 M: 0.005	Train-SoftAcc=0.397536,	AnsLoss=44.380054,	
Rank[  3]Epoch[0] Batch [400]	Speed: 146.49 samples/s ETA: 0 d  1 h 30 m	Data: 0.005 Tran: 0.005 F: 0.124 B: 0.240 O: 0.057 M: 0.005	Train-SoftAcc=0.397536,	AnsLoss=44.380054,	
Rank[  2]Epoch[0] Batch [400]	Speed: 146.49 samples/s ETA: 0 d  1 h 30 m	Data: 0.005 Tran: 0.006 F: 0.124 B: 0.236 O: 0.060 M: 0.005	Train-SoftAcc=0.397536,	AnsLoss=44.380054,	
Rank[  0]Epoch[0] Batch [500]	Speed: 146.25 samples/s ETA: 0 d  1 h 30 m	Data: 0.005 Tran: 0.006 F: 0.124 B: 0.236 O: 0.060 M: 0.005	Train-SoftAcc=0.415698,	AnsLoss=36.382202,	
Rank[  3]Epoch[0] Batch [500]	Speed: 146.25 samples/s ETA: 0 d  1 h 30 m	Data: 0.005 Tran: 0.005 F: 0.125 B: 0.241 O: 0.057 M: 0.005	Train-SoftAcc=0.415698,	AnsLoss=36.382202,	
Rank[  2]Epoch[0] Batch [500]	Speed: 146.25 samples/s ETA: 0 d  1 h 30 m	Data: 0.005 Tran: 0.007 F: 0.124 B: 0.235 O: 0.061 M: 0.004	Train-SoftAcc=0.415698,	AnsLoss=36.382202,	
Rank[  1]Epoch[0] Batch [500]	Speed: 146.25 samples/s ETA: 0 d  1 h 30 m	Data: 0.005 Tran: 0.006 F: 0.125 B: 0.240 O: 0.057 M: 0.005	Train-SoftAcc=0.415698,	AnsLoss=36.382202,	
Rank[  3]Epoch[0] Batch [600]	Speed: 146.56 samples/s ETA: 0 d  1 h 29 m	Data: 0.005 Tran: 0.005 F: 0.125 B: 0.242 O: 0.055 M: 0.004	Train-SoftAcc=0.430203,	AnsLoss=31.029140,	
Rank[  2]Epoch[0] Batch [600]	Speed: 146.56 samples/s ETA: 0 d  1 h 29 m	Data: 0.005 Tran: 0.006 F: 0.124 B: 0.236 O: 0.061 M: 0.004	Train-SoftAcc=0.430203,	AnsLoss=31.029140,	
Rank[  1]Epoch[0] Batch [600]	Speed: 146.56 samples/s ETA: 0 d  1 h 29 m	Data: 0.005 Tran: 0.006 F: 0.124 B: 0.240 O: 0.057 M: 0.005	Train-SoftAcc=0.430203,	AnsLoss=31.029140,	
Rank[  0]Epoch[0] Batch [600]	Speed: 146.56 samples/s ETA: 0 d  1 h 29 m	Data: 0.005 Tran: 0.006 F: 0.124 B: 0.235 O: 0.061 M: 0.004	Train-SoftAcc=0.430203,	AnsLoss=31.029140,	
Rank[  1]Epoch[0] Batch [700]	Speed: 145.47 samples/s ETA: 0 d  1 h 29 m	Data: 0.005 Tran: 0.005 F: 0.125 B: 0.241 O: 0.054 M: 0.009	Train-SoftAcc=0.443821,	AnsLoss=27.175468,	
Rank[  3]Epoch[0] Batch [700]	Speed: 145.47 samples/s ETA: 0 d  1 h 29 m	Data: 0.005 Tran: 0.005 F: 0.124 B: 0.239 O: 0.058 M: 0.008	Train-SoftAcc=0.443821,	AnsLoss=27.175468,	
Rank[  0]Epoch[0] Batch [700]	Speed: 145.47 samples/s ETA: 0 d  1 h 29 m	Data: 0.005 Tran: 0.005 F: 0.124 B: 0.234 O: 0.066 M: 0.004	Train-SoftAcc=0.443821,	AnsLoss=27.175468,	
Rank[  2]Epoch[0] Batch [700]	Speed: 145.47 samples/s ETA: 0 d  1 h 29 m	Data: 0.005 Tran: 0.006 F: 0.124 B: 0.235 O: 0.062 M: 0.008	Train-SoftAcc=0.443821,	AnsLoss=27.175468,	
Rank[  2]Epoch[0] Batch [800]	Speed: 145.24 samples/s ETA: 0 d  1 h 28 m	Data: 0.005 Tran: 0.005 F: 0.123 B: 0.235 O: 0.062 M: 0.010	Train-SoftAcc=0.455182,	AnsLoss=24.277939,	
Rank[  0]Epoch[0] Batch [800]	Speed: 145.24 samples/s ETA: 0 d  1 h 28 m	Data: 0.005 Tran: 0.005 F: 0.124 B: 0.236 O: 0.062 M: 0.009	Train-SoftAcc=0.455182,	AnsLoss=24.277939,	
Rank[  3]Epoch[0] Batch [800]	Speed: 145.24 samples/s ETA: 0 d  1 h 28 m	Data: 0.005 Tran: 0.005 F: 0.124 B: 0.240 O: 0.056 M: 0.010	Train-SoftAcc=0.455182,	AnsLoss=24.277939,	
Rank[  1]Epoch[0] Batch [800]	Speed: 145.24 samples/s ETA: 0 d  1 h 28 m	Data: 0.005 Tran: 0.005 F: 0.126 B: 0.241 O: 0.059 M: 0.005	Train-SoftAcc=0.455182,	AnsLoss=24.277939,	
Rank[  1]Epoch[0] Batch [900]	Speed: 145.74 samples/s ETA: 0 d  1 h 27 m	Data: 0.005 Tran: 0.005 F: 0.125 B: 0.241 O: 0.056 M: 0.007	Train-SoftAcc=0.465400,	AnsLoss=22.014673,	
Rank[  3]Epoch[0] Batch [900]	Speed: 145.74 samples/s ETA: 0 d  1 h 27 m	Data: 0.005 Tran: 0.006 F: 0.124 B: 0.240 O: 0.056 M: 0.007	Train-SoftAcc=0.465400,	AnsLoss=22.014673,	
Rank[  2]Epoch[0] Batch [900]	Speed: 145.74 samples/s ETA: 0 d  1 h 27 m	Data: 0.005 Tran: 0.006 F: 0.124 B: 0.235 O: 0.064 M: 0.004	Train-SoftAcc=0.465400,	AnsLoss=22.014673,	
Rank[  0]Epoch[0] Batch [900]	Speed: 145.74 samples/s ETA: 0 d  1 h 27 m	Data: 0.005 Tran: 0.006 F: 0.124 B: 0.235 O: 0.062 M: 0.007	Train-SoftAcc=0.465400,	AnsLoss=22.014673,	
Rank[  0]Epoch[0] Batch [1000]	Speed: 148.20 samples/s ETA: 0 d  1 h 25 m	Data: 0.005 Tran: 0.006 F: 0.123 B: 0.234 O: 0.060 M: 0.003	Train-SoftAcc=0.473786,	AnsLoss=20.197876,	
Rank[  3]Epoch[0] Batch [1000]	Speed: 148.20 samples/s ETA: 0 d  1 h 25 m	Data: 0.005 Tran: 0.005 F: 0.124 B: 0.239 O: 0.055 M: 0.003	Train-SoftAcc=0.473786,	AnsLoss=20.197876,	
Rank[  2]Epoch[0] Batch [1000]	Speed: 148.20 samples/s ETA: 0 d  1 h 25 m	Data: 0.005 Tran: 0.006 F: 0.122 B: 0.233 O: 0.061 M: 0.004	Train-SoftAcc=0.473786,	AnsLoss=20.197876,	
Rank[  1]Epoch[0] Batch [1000]	Speed: 148.20 samples/s ETA: 0 d  1 h 25 m	Data: 0.005 Tran: 0.006 F: 0.125 B: 0.241 O: 0.052 M: 0.003	Train-SoftAcc=0.473786,	AnsLoss=20.197876,	
