Namespace(cfg='cfgs/pretrain/base_prec_withouttextonly_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/', slurm=False)
Namespace(cfg='cfgs/pretrain/base_prec_withouttextonly_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/', slurm=False)
Namespace(cfg='cfgs/pretrain/base_prec_withouttextonly_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/', slurm=False)
Namespace(cfg='cfgs/pretrain/base_prec_withouttextonly_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/', slurm=False)
{'CHECKPOINT_FREQUENT': 1,
 'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'ANSWER_VOCAB_FILE': '',
             'ANSWER_VOCAB_SIZE': 3129,
             'APPEND_INDEX': False,
             'BASIC_ALIGN': False,
             'CACHE_MODE': False,
             'DATASET': 'conceptual_captions',
             {'CHECKPOINT_FREQUENT': 1,
 {'CHECKPOINT_FREQUENT': 1,
 'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/conceptual_captions/vl-bert/',
             {'CHECKPOINT_FREQUENT': 1,
 'IGNORE_DB_CACHE': False,
             'LABEL_INDEX_IN_BATCH': -1,
             'MASK_SIZE': 14,
             'MIN_SEQ_LEN': 0,
             'ONLY_USE_RELEVANT_DETS': True,
             'QA2R_AUG': False,
             'QA2R_NOQ': False,
             'ROOT_PATH': './',
             'SEQ_LEN': 64,
             'TASK': 'Q2AR',
             'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'TEST_ANNOTATION_FILE': '',
             'TEST_IMAGE_SET': 'val',
             'ANSWER_VOCAB_FILE': '',
             'TRAIN_ANNOTATION_FILE': '',
             'ANSWER_VOCAB_SIZE': 3129,
             'TRAIN_IMAGE_SET': 'train',
             'APPEND_INDEX': False,
             'VAL_ANNOTATION_FILE': '',
             'BASIC_ALIGN': False,
             'VAL_IMAGE_SET': 'val',
             'CACHE_MODE': False,
             'DATASET': 'conceptual_captions',
             'ZIP_MODE': False},
 'GPUS': '0,1,2,3',
 'LOG_FREQUENT': 100,
 'MODEL_PREFIX': 'vl-bert_base_res101_pretrain',
 'MODULE': 'ResNetVLBERTForPretraining',
 'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'ANSWER_VOCAB_FILE': '',
             'ANSWER_VOCAB_SIZE': 3129,
             'APPEND_INDEX': False,
             'BASIC_ALIGN': False,
             'CACHE_MODE': False,
             'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/conceptual_captions/vl-bert/',
             'DATASET': 'conceptual_captions',
             'ANSWER_VOCAB_FILE': '',
             'IGNORE_DB_CACHE': False,
             'ANSWER_VOCAB_SIZE': 3129,
             'LABEL_INDEX_IN_BATCH': -1,
             'MASK_SIZE': 14,
             'APPEND_INDEX': False,
             'MIN_SEQ_LEN': 0,
             'BASIC_ALIGN': False,
             'ONLY_USE_RELEVANT_DETS': True,
             'CACHE_MODE': False,
             'QA2R_AUG': False,
             'QA2R_NOQ': False,
             'DATASET': 'conceptual_captions',
             'ROOT_PATH': './',
             'SEQ_LEN': 64,
             'TASK': 'Q2AR',
             'TEST_ANNOTATION_FILE': '',
             'TEST_IMAGE_SET': 'val',
             'TRAIN_ANNOTATION_FILE': '',
             'TRAIN_IMAGE_SET': 'train',
             'VAL_ANNOTATION_FILE': '',
             'VAL_IMAGE_SET': 'val',
             'ZIP_MODE': False},
 'GPUS': '0,1,2,3',
 'LOG_FREQUENT': 100,
 'MODEL_PREFIX': 'vl-bert_base_res101_pretrain',
 'MODULE': 'ResNetVLBERTForPretraining',
 'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/conceptual_captions/vl-bert/',
             'IGNORE_DB_CACHE': False,
             'LABEL_INDEX_IN_BATCH': -1,
             'MASK_SIZE': 14,
             'MIN_SEQ_LEN': 0,
             'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/conceptual_captions/vl-bert/',
             'ONLY_USE_RELEVANT_DETS': True,
             'QA2R_AUG': False,
             'IGNORE_DB_CACHE': False,
             'QA2R_NOQ': False,
             'LABEL_INDEX_IN_BATCH': -1,
             'ROOT_PATH': './',
             'MASK_SIZE': 14,
             'SEQ_LEN': 64,
             'MIN_SEQ_LEN': 0,
             'TASK': 'Q2AR',
             'ONLY_USE_RELEVANT_DETS': True,
             'TEST_ANNOTATION_FILE': '',
             'QA2R_AUG': False,
             'NETWORK': {'ANS_LOSS_WEIGHT': 1.0,
             'TEST_IMAGE_SET': 'val',
             'QA2R_NOQ': False,
             'BERT_ALIGN_ANSWER': True,
             'TRAIN_ANNOTATION_FILE': '',
             'ROOT_PATH': './',
             'BERT_ALIGN_QUESTION': True,
             'TRAIN_IMAGE_SET': 'train',
             'BERT_FROZEN': False,
             'SEQ_LEN': 64,
             'VAL_ANNOTATION_FILE': '',
             'TASK': 'Q2AR',
             'VAL_IMAGE_SET': 'val',
             'TEST_ANNOTATION_FILE': '',
             'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'ZIP_MODE': False},
 'TEST_IMAGE_SET': 'val',
             'BERT_PRETRAINED': '',
             'GPUS': '0,1,2,3',
 'BERT_PRETRAINED_EPOCH': 0,
             'TRAIN_ANNOTATION_FILE': '',
             'BERT_USE_LAYER': -2,
             'LOG_FREQUENT': 100,
 'TRAIN_IMAGE_SET': 'train',
             'BERT_WITH_MLM_LOSS': False,
             'MODEL_PREFIX': 'vl-bert_base_res101_pretrain',
 'VAL_ANNOTATION_FILE': '',
             'BERT_WITH_NSP_LOSS': False,
             'MODULE': 'ResNetVLBERTForPretraining',
 'BLIND': False,
             'VAL_IMAGE_SET': 'val',
             'CLASSIFIER_DROPOUT': 0.1,
             'ZIP_MODE': False},
 'CLASSIFIER_HIDDEN_SIZE': 1024,
             'CLASSIFIER_SIGMOID': False,
             'GPUS': '0,1,2,3',
 'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'LOG_FREQUENT': 100,
 'CLASSIFIER_TYPE': '2fc',
             'CNN_LOSS_WEIGHT': 1.0,
             'MODEL_PREFIX': 'vl-bert_base_res101_pretrain',
 'ENABLE_CNN_REG_LOSS': False,
             'MODULE': 'ResNetVLBERTForPretraining',
 'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'IMAGE_C5_DILATED': True,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'IMAGE_FINAL_DIM': 768,
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'IMAGE_FROZEN_BN': True,
             'IMAGE_NUM_LAYERS': 101,
             'IMAGE_PRETRAINED': '',
             'IMAGE_PRETRAINED_EPOCH': 0,
             'IMAGE_SEMANTIC': False,
             'IMAGE_STRIDE_IN_1x1': True,
             'MASK_RAW_PIXELS': True,
             'MLM_LOSS_NORM_IN_BATCH_FIRST': False,
             'MVRC_LOSS_NORM_IN_BATCH_FIRST': False,
             'NO_GROUNDING': False,
             'NO_OBJ_ATTENTION': False,
             'OUTPUT_CONV5': False,
             'PARTIAL_PRETRAIN': '',
             'NETWORK': {'ANS_LOSS_WEIGHT': 1.0,
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': [],
             'BERT_ALIGN_ANSWER': True,
             'BERT_ALIGN_QUESTION': True,
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'BERT_FROZEN': False,
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'BERT_PRETRAINED': '',
             'BERT_PRETRAINED_EPOCH': 0,
             'BERT_USE_LAYER': -2,
             'BERT_WITH_MLM_LOSS': False,
             'BERT_WITH_NSP_LOSS': False,
             'BLIND': False,
             'CLASSIFIER_DROPOUT': 0.1,
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'CLASSIFIER_SIGMOID': False,
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'CLASSIFIER_TYPE': '2fc',
             'CNN_LOSS_WEIGHT': 1.0,
             'ENABLE_CNN_REG_LOSS': False,
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'IMAGE_C5_DILATED': True,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'IMAGE_FINAL_DIM': 768,
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'IMAGE_FROZEN_BN': True,
             'IMAGE_NUM_LAYERS': 101,
             'IMAGE_PRETRAINED': '',
             'IMAGE_PRETRAINED_EPOCH': 0,
             'IMAGE_SEMANTIC': False,
             'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'IMAGE_STRIDE_IN_1x1': True,
             'from_scratch': False,
                        'MASK_RAW_PIXELS': True,
             'hidden_act': 'gelu',
                        'MLM_LOSS_NORM_IN_BATCH_FIRST': False,
             'hidden_dropout_prob': 0.1,
                        'MVRC_LOSS_NORM_IN_BATCH_FIRST': False,
             'hidden_size': 768,
                        'NO_GROUNDING': False,
             'initializer_range': 0.02,
                        'NO_OBJ_ATTENTION': False,
             'input_size': 1280,
                        'OUTPUT_CONV5': False,
             'input_transform_type': 1,
                        'PARTIAL_PRETRAIN': '',
             'intermediate_size': 3072,
                        'PARTIAL_PRETRAIN_PREFIX_CHANGES': [],
             'max_position_embeddings': 512,
                        'num_attention_heads': 12,
                        'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'num_hidden_layers': 12,
                        'obj_pos_id_relative': True,
                        'PIXEL_STDS': [1.0, 1.0, 1.0],
             'object_word_embed_mode': 2,
                        'pos_embedding_frozen': False,
                        'position_padding_idx': -1,
                        'type_vocab_size': 3,
                        'visual_ln': True,
                        'visual_region_classes': 1601,
                        'visual_scale_object_init': 0.0,
                        'visual_scale_text_init': 0.0,
                        'visual_size': 768,
                        'vocab_size': 30522,
                        'with_pooler': False,
                        'word_embedding_frozen': False},
             'WITH_MLM_LOSS': True,
             'WITH_MVRC_LOSS': True,
             'WITH_REL_LOSS': False},
 'NUM_WORKERS_PER_GPU': 4,
 'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert',
 'RNG_SEED': 12345,
 'SCALES': [600, 1000],
 'NETWORK': {'ANS_LOSS_WEIGHT': 1.0,
             'BERT_ALIGN_ANSWER': True,
             'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'BERT_ALIGN_QUESTION': True,
             'from_scratch': False,
                        'TEST': {'BATCH_IMAGES': 64,
          'BERT_FROZEN': False,
             'hidden_act': 'gelu',
                        'FLIP_PROB': 0,
          'hidden_dropout_prob': 0.1,
                        'SHUFFLE': False,
          'hidden_size': 768,
                        'TEST_EPOCH': 0},
 'initializer_range': 0.02,
                        'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'input_size': 1280,
                        'input_transform_type': 1,
                        'BERT_PRETRAINED': '',
             'NETWORK': {'ANS_LOSS_WEIGHT': 1.0,
             'intermediate_size': 3072,
                        'BERT_PRETRAINED_EPOCH': 0,
             'max_position_embeddings': 512,
                        'BERT_ALIGN_ANSWER': True,
             'num_attention_heads': 12,
                        'BERT_USE_LAYER': -2,
             'num_hidden_layers': 12,
                        'BERT_ALIGN_QUESTION': True,
             'BERT_WITH_MLM_LOSS': False,
             'obj_pos_id_relative': True,
                        'BERT_FROZEN': False,
             'BERT_WITH_NSP_LOSS': False,
             'object_word_embed_mode': 2,
                        'pos_embedding_frozen': False,
                        'BLIND': False,
             'position_padding_idx': -1,
                        'CLASSIFIER_DROPOUT': 0.1,
             'type_vocab_size': 3,
                        'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'visual_ln': True,
                        'CLASSIFIER_HIDDEN_SIZE': 1024,
             'visual_region_classes': 1601,
                        'BERT_PRETRAINED': '',
             'CLASSIFIER_SIGMOID': False,
             'visual_scale_object_init': 0.0,
                        'BERT_PRETRAINED_EPOCH': 0,
             'visual_scale_text_init': 0.0,
                        'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'visual_size': 768,
                        'BERT_USE_LAYER': -2,
             'CLASSIFIER_TYPE': '2fc',
             'vocab_size': 30522,
                        'BERT_WITH_MLM_LOSS': False,
             'with_pooler': False,
                        'CNN_LOSS_WEIGHT': 1.0,
             'BERT_WITH_NSP_LOSS': False,
             'word_embedding_frozen': False},
             'ENABLE_CNN_REG_LOSS': False,
             'WITH_MLM_LOSS': True,
             'BLIND': False,
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'WITH_MVRC_LOSS': True,
             'CLASSIFIER_DROPOUT': 0.1,
             'IMAGE_C5_DILATED': True,
             'WITH_REL_LOSS': False},
 'CLASSIFIER_HIDDEN_SIZE': 1024,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'NUM_WORKERS_PER_GPU': 4,
 'CLASSIFIER_SIGMOID': False,
             'IMAGE_FINAL_DIM': 768,
             'TRAIN': {'ASPECT_GROUPING': False,
           'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'AUTO_RESUME': True,
           'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert',
 'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'CLASSIFIER_TYPE': '2fc',
             'BATCH_IMAGES': 64,
           'RNG_SEED': 12345,
 'IMAGE_FROZEN_BN': True,
             'BEGIN_EPOCH': 0,
           'CNN_LOSS_WEIGHT': 1.0,
             'SCALES': [600, 1000],
 'CLIP_GRAD_NORM': 10,
           'IMAGE_NUM_LAYERS': 101,
             'ENABLE_CNN_REG_LOSS': False,
             'END_EPOCH': 10,
           'IMAGE_PRETRAINED': '',
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'FLIP_PROB': 0.5,
           'IMAGE_PRETRAINED_EPOCH': 0,
             'FP16': False,
           'IMAGE_C5_DILATED': True,
             'FP16_LOSS_SCALE': 128.0,
           'IMAGE_SEMANTIC': False,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'TEST': {'BATCH_IMAGES': 64,
          'GRAD_ACCUMULATE_STEPS': 1,
           'IMAGE_STRIDE_IN_1x1': True,
             'IMAGE_FINAL_DIM': 768,
             'FLIP_PROB': 0,
          'MASK_RAW_PIXELS': True,
             'SHUFFLE': False,
          'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'MLM_LOSS_NORM_IN_BATCH_FIRST': False,
             'TEST_EPOCH': 0},
 'IMAGE_FROZEN_BN': True,
             'LOSS_LOGGERS': [('mlm_loss', 'MLMLossWVC'),
                            'MVRC_LOSS_NORM_IN_BATCH_FIRST': False,
             'IMAGE_NUM_LAYERS': 101,
             'NO_GROUNDING': False,
             ('mvrc_loss', 'MVRCLoss')],
           'IMAGE_PRETRAINED': '',
             'NO_OBJ_ATTENTION': False,
             'IMAGE_PRETRAINED_EPOCH': 0,
             'LR': 1e-07,
           'OUTPUT_CONV5': False,
             'IMAGE_SEMANTIC': False,
             'PARTIAL_PRETRAIN': '',
             'LR_FACTOR': 0.1,
           'IMAGE_STRIDE_IN_1x1': True,
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': [],
             'MASK_RAW_PIXELS': True,
             'LR_MULT': [],
           'LR_SCHEDULE': 'triangle',
           'MLM_LOSS_NORM_IN_BATCH_FIRST': False,
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'LR_STEP': [],
           'MVRC_LOSS_NORM_IN_BATCH_FIRST': False,
             'MOMENTUM': 0.9,
           'PIXEL_STDS': [1.0, 1.0, 1.0],
             'NO_GROUNDING': False,
             'OPTIMIZER': 'AdamW',
           'NO_OBJ_ATTENTION': False,
             'RESUME': False,
           'SHUFFLE': True,
           'OUTPUT_CONV5': False,
             'WARMUP': True,
           'PARTIAL_PRETRAIN': '',
             'WARMUP_FACTOR': 0.0,
           'WARMUP_METHOD': 'linear',
           'PARTIAL_PRETRAIN_PREFIX_CHANGES': [],
             'WARMUP_STEPS': 8000,
           'WD': 0.0001},
 'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'VAL_FREQUENT': 1}
'TRAIN': {'ASPECT_GROUPING': False,
           'AUTO_RESUME': True,
           'BATCH_IMAGES': 64,
           'BEGIN_EPOCH': 0,
           'CLIP_GRAD_NORM': 10,
           'END_EPOCH': 10,
           'FLIP_PROB': 0.5,
           'FP16': False,
           'FP16_LOSS_SCALE': 128.0,
           'GRAD_ACCUMULATE_STEPS': 1,
           'LOSS_LOGGERS': [('mlm_loss', 'MLMLossWVC'),
                            ('mvrc_loss', 'MVRCLoss')],
           'LR': 1e-07,
           'LR_FACTOR': 0.1,
           'LR_MULT': [],
           'LR_SCHEDULE': 'triangle',
           'LR_STEP': [],
           'MOMENTUM': 0.9,
           'OPTIMIZER': 'AdamW',
           'RESUME': False,
           'SHUFFLE': True,
           'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'WARMUP': True,
           'from_scratch': False,
                        'WARMUP_FACTOR': 0.0,
           'WARMUP_METHOD': 'linear',
           'hidden_act': 'gelu',
                        'WARMUP_STEPS': 8000,
           'hidden_dropout_prob': 0.1,
                        'WD': 0.0001},
 'hidden_size': 768,
                        'initializer_range': 0.02,
                        'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'input_size': 1280,
                        'VAL_FREQUENT': 1}
'input_transform_type': 1,
                        'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'intermediate_size': 3072,
                        'from_scratch': False,
                        'max_position_embeddings': 512,
                        'hidden_act': 'gelu',
                        'num_attention_heads': 12,
                        'hidden_dropout_prob': 0.1,
                        'num_hidden_layers': 12,
                        'hidden_size': 768,
                        'obj_pos_id_relative': True,
                        'initializer_range': 0.02,
                        'object_word_embed_mode': 2,
                        'input_size': 1280,
                        'pos_embedding_frozen': False,
                        'input_transform_type': 1,
                        'position_padding_idx': -1,
                        'intermediate_size': 3072,
                        'type_vocab_size': 3,
                        'max_position_embeddings': 512,
                        'visual_ln': True,
                        'num_attention_heads': 12,
                        'visual_region_classes': 1601,
                        'num_hidden_layers': 12,
                        'visual_scale_object_init': 0.0,
                        'obj_pos_id_relative': True,
                        'visual_scale_text_init': 0.0,
                        'object_word_embed_mode': 2,
                        'visual_size': 768,
                        'pos_embedding_frozen': False,
                        'vocab_size': 30522,
                        'position_padding_idx': -1,
                        'with_pooler': False,
                        'type_vocab_size': 3,
                        'word_embedding_frozen': False},
             'visual_ln': True,
                        'WITH_MLM_LOSS': True,
             'visual_region_classes': 1601,
                        'WITH_MVRC_LOSS': True,
             'visual_scale_object_init': 0.0,
                        'WITH_REL_LOSS': False},
 'visual_scale_text_init': 0.0,
                        'NUM_WORKERS_PER_GPU': 4,
 'visual_size': 768,
                        'vocab_size': 30522,
                        'with_pooler': False,
                        'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert',
 'word_embedding_frozen': False},
             'RNG_SEED': 12345,
 'WITH_MLM_LOSS': True,
             'WITH_MVRC_LOSS': True,
             'SCALES': [600, 1000],
 'WITH_REL_LOSS': False},
 'NUM_WORKERS_PER_GPU': 4,
 'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert',
 'TEST': {'BATCH_IMAGES': 64,
          'RNG_SEED': 12345,
 'FLIP_PROB': 0,
          'SHUFFLE': False,
          'SCALES': [600, 1000],
 'TEST_EPOCH': 0},
 'TEST': {'BATCH_IMAGES': 64,
          'FLIP_PROB': 0,
          'SHUFFLE': False,
          'TEST_EPOCH': 0},
 'TRAIN': {'ASPECT_GROUPING': False,
           'AUTO_RESUME': True,
           'BATCH_IMAGES': 64,
           'BEGIN_EPOCH': 0,
           'CLIP_GRAD_NORM': 10,
           'END_EPOCH': 10,
           'FLIP_PROB': 0.5,
           'FP16': False,
           'FP16_LOSS_SCALE': 128.0,
           'TRAIN': {'ASPECT_GROUPING': False,
           'GRAD_ACCUMULATE_STEPS': 1,
           'AUTO_RESUME': True,
           'BATCH_IMAGES': 64,
           'BEGIN_EPOCH': 0,
           'CLIP_GRAD_NORM': 10,
           'LOSS_LOGGERS': [('mlm_loss', 'MLMLossWVC'),
                            'END_EPOCH': 10,
           'FLIP_PROB': 0.5,
           ('mvrc_loss', 'MVRCLoss')],
           'FP16': False,
           'LR': 1e-07,
           'FP16_LOSS_SCALE': 128.0,
           'LR_FACTOR': 0.1,
           'GRAD_ACCUMULATE_STEPS': 1,
           'LR_MULT': [],
           'LR_SCHEDULE': 'triangle',
           'LR_STEP': [],
           'MOMENTUM': 0.9,
           'OPTIMIZER': 'AdamW',
           'LOSS_LOGGERS': [('mlm_loss', 'MLMLossWVC'),
                            'RESUME': False,
           ('mvrc_loss', 'MVRCLoss')],
           'SHUFFLE': True,
           'WARMUP': True,
           'LR': 1e-07,
           'WARMUP_FACTOR': 0.0,
           'LR_FACTOR': 0.1,
           'WARMUP_METHOD': 'linear',
           'LR_MULT': [],
           'WARMUP_STEPS': 8000,
           'LR_SCHEDULE': 'triangle',
           'WD': 0.0001},
 'LR_STEP': [],
           'MOMENTUM': 0.9,
           'OPTIMIZER': 'AdamW',
           'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'RESUME': False,
           'SHUFFLE': True,
           'VAL_FREQUENT': 1}
'WARMUP': True,
           'WARMUP_FACTOR': 0.0,
           'WARMUP_METHOD': 'linear',
           'WARMUP_STEPS': 8000,
           'WD': 0.0001},
 'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'VAL_FREQUENT': 1}
Warnings: Unexpected keys: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
Warnings: Unexpected keys: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
Warnings: Unexpected keys: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
Warnings: Unexpected keys: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
native distributed, size: 4, rank: 1, local rank: 1
native distributed, size: 4, rank: 2, local rank: 2
native distributed, size: 4, rank: 3, local rank: 3
native distributed, size: 4, rank: 0, local rank: 0
>> Trainable Parameters:
---------------------------------------------------------------------------------------------------------------
|Name                                                         |Dtype            |Shape           |#Params     |
---------------------------------------------------------------------------------------------------------------
|image_feature_extractor.obj_downsample.1.weight              |torch.float32    |(768, 4096)     |3145728     |
---------------------------------------------------------------------------------------------------------------
|image_feature_extractor.obj_downsample.1.bias                |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|object_linguistic_embeddings.weight                          |torch.float32    |(1, 768)        |768         |
---------------------------------------------------------------------------------------------------------------
|object_mask_visual_embedding.weight                          |torch.float32    |(1, 2048)       |2048        |
---------------------------------------------------------------------------------------------------------------
|object_mask_word_embedding.weight                            |torch.float32    |(1, 768)        |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.word_embeddings.weight                                |torch.float32    |(30522, 768)    |23440896    |
---------------------------------------------------------------------------------------------------------------
|vlbert.end_embedding.weight                                  |torch.float32    |(1, 768)        |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.position_embeddings.weight                            |torch.float32    |(512, 768)      |393216      |
---------------------------------------------------------------------------------------------------------------
|vlbert.token_type_embeddings.weight                          |torch.float32    |(3, 768)        |2304        |
---------------------------------------------------------------------------------------------------------------
|vlbert.embedding_LayerNorm.weight                            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.embedding_LayerNorm.bias                              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_text.weight                                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_text.bias                                   |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_object.weight                               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_object.bias                                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.query.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.query.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.key.weight            |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.key.bias              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.value.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.value.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.dense.weight        |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.dense.bias          |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.LayerNorm.weight    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.LayerNorm.bias      |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.intermediate.dense.weight            |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.intermediate.dense.bias              |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.dense.bias                    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.LayerNorm.weight              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.LayerNorm.bias                |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.query.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.query.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.key.weight            |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.key.bias              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.value.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.value.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.dense.weight        |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.dense.bias          |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.LayerNorm.weight    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.LayerNorm.bias      |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.mlm_head.predictions.bias                             |torch.float32    |(30522,)        |30522       |
---------------------------------------------------------------------------------------------------------------
|vlbert.mlm_head.predictions.transform.dense.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.mlm_head.predictions.transform.dense.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.mlm_head.predictions.transform.LayerNorm.weight       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.mlm_head.predictions.transform.LayerNorm.bias         |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.mvrc_head.transform.dense.weight                      |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.mvrc_head.transform.dense.bias                        |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.mvrc_head.region_cls_pred.weight                      |torch.float32    |(1601, 768)     |1229568     |
---------------------------------------------------------------------------------------------------------------
|vlbert.mvrc_head.region_cls_pred.bias                        |torch.float32    |(1601,)         |1601        |
---------------------------------------------------------------------------------------------------------------
>> # TrainableParams:       	114.49	M
>> # NonTrainableParams:    	0.00	M
>> # TotalParams:           	114.49	M
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
Best Val MLMAcc: 0.5998316407203674, Epoch: 5
Auto continue training from /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-0005.model
PROGRESS: 60.00%
PROGRESS: 60.00%
PROGRESS: 60.00%
PROGRESS: 60.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Rank[  3]Epoch[6] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.644258,	MVRCAccuracy=0.677892,	MLMLossWVC=1.687809,	MVRCLoss=2.472816,	
Rank[  2]Epoch[6] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.644258,	MVRCAccuracy=0.677892,	MLMLossWVC=1.687809,	MVRCLoss=2.472816,	
Rank[  1]Epoch[6] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.644258,	MVRCAccuracy=0.677892,	MLMLossWVC=1.687809,	MVRCLoss=2.472816,	
Rank[  0]Epoch[6] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.644258,	MVRCAccuracy=0.677892,	MLMLossWVC=1.687809,	MVRCLoss=2.472816,	
Rank[  0]Epoch[6] Batch [100]	Speed: 27.89 samples/s ETA: 1 d  3 h 36 m	Data: 2.163 Tran: 0.007 F: 0.154 B: 0.295 O: 0.098 M: 0.005	Train-MLMAcc=0.627822,	MVRCAccuracy=0.672847,	MLMLossWVC=1.805889,	MVRCLoss=2.452215,	
Rank[  2]Epoch[6] Batch [100]	Speed: 27.89 samples/s ETA: 1 d  3 h 36 m	Data: 1.744 Tran: 0.007 F: 0.154 B: 0.296 O: 0.512 M: 0.007	Train-MLMAcc=0.627822,	MVRCAccuracy=0.672847,	MLMLossWVC=1.805889,	MVRCLoss=2.452215,	
Rank[  1]Epoch[6] Batch [100]	Speed: 27.89 samples/s ETA: 1 d  3 h 36 m	Data: 2.095 Tran: 0.007 F: 0.158 B: 0.298 O: 0.155 M: 0.008	Train-MLMAcc=0.627822,	MVRCAccuracy=0.672847,	MLMLossWVC=1.805889,	MVRCLoss=2.452215,	
Rank[  3]Epoch[6] Batch [100]	Speed: 27.89 samples/s ETA: 1 d  3 h 36 m	Data: 1.975 Tran: 0.007 F: 0.156 B: 0.296 O: 0.280 M: 0.008	Train-MLMAcc=0.627822,	MVRCAccuracy=0.672847,	MLMLossWVC=1.805889,	MVRCLoss=2.452215,	
Rank[  0]Epoch[6] Batch [200]	Speed: 27.73 samples/s ETA: 1 d  3 h 41 m	Data: 1.797 Tran: 0.007 F: 0.152 B: 0.295 O: 0.051 M: 0.006	Train-MLMAcc=0.624439,	MVRCAccuracy=0.673091,	MLMLossWVC=1.818914,	MVRCLoss=2.454623,	
Rank[  2]Epoch[6] Batch [200]	Speed: 27.73 samples/s ETA: 1 d  3 h 41 m	Data: 1.039 Tran: 0.007 F: 0.150 B: 0.292 O: 0.811 M: 0.008	Train-MLMAcc=0.624439,	MVRCAccuracy=0.673091,	MLMLossWVC=1.818914,	MVRCLoss=2.454623,	
Rank[  3]Epoch[6] Batch [200]	Speed: 27.73 samples/s ETA: 1 d  3 h 41 m	Data: 0.880 Tran: 0.007 F: 0.150 B: 0.290 O: 0.972 M: 0.008	Train-MLMAcc=0.624439,	MVRCAccuracy=0.673091,	MLMLossWVC=1.818914,	MVRCLoss=2.454623,	
Rank[  1]Epoch[6] Batch [200]	Speed: 27.73 samples/s ETA: 1 d  3 h 41 m	Data: 1.319 Tran: 0.007 F: 0.149 B: 0.294 O: 0.529 M: 0.009	Train-MLMAcc=0.624439,	MVRCAccuracy=0.673091,	MLMLossWVC=1.818914,	MVRCLoss=2.454623,	
Rank[  0]Epoch[6] Batch [300]	Speed: 28.22 samples/s ETA: 1 d  3 h  9 m	Data: 1.757 Tran: 0.007 F: 0.151 B: 0.293 O: 0.051 M: 0.007	Train-MLMAcc=0.624553,	MVRCAccuracy=0.672284,	MLMLossWVC=1.818408,	MVRCLoss=2.452721,	
Rank[  1]Epoch[6] Batch [300]	Speed: 28.22 samples/s ETA: 1 d  3 h  9 m	Data: 1.173 Tran: 0.007 F: 0.150 B: 0.295 O: 0.634 M: 0.008	Train-MLMAcc=0.624553,	MVRCAccuracy=0.672284,	MLMLossWVC=1.818408,	MVRCLoss=2.452721,	
Rank[  3]Epoch[6] Batch [300]	Speed: 28.22 samples/s ETA: 1 d  3 h  9 m	Data: 0.341 Tran: 0.007 F: 0.150 B: 0.291 O: 1.472 M: 0.006	Train-MLMAcc=0.624553,	MVRCAccuracy=0.672284,	MLMLossWVC=1.818408,	MVRCLoss=2.452721,	
Rank[  2]Epoch[6] Batch [300]	Speed: 28.22 samples/s ETA: 1 d  3 h  9 m	Data: 0.852 Tran: 0.007 F: 0.150 B: 0.293 O: 0.958 M: 0.008	Train-MLMAcc=0.624553,	MVRCAccuracy=0.672284,	MLMLossWVC=1.818408,	MVRCLoss=2.452721,	
Rank[  0]Epoch[6] Batch [400]	Speed: 28.16 samples/s ETA: 1 d  3 h  9 m	Data: 1.752 Tran: 0.008 F: 0.160 B: 0.295 O: 0.051 M: 0.006	Train-MLMAcc=0.626022,	MVRCAccuracy=0.671612,	MLMLossWVC=1.809518,	MVRCLoss=2.453533,	
Rank[  3]Epoch[6] Batch [400]	Speed: 28.16 samples/s ETA: 1 d  3 h  9 m	Data: 0.080 Tran: 0.007 F: 0.150 B: 0.291 O: 1.737 M: 0.008	Train-MLMAcc=0.626022,	MVRCAccuracy=0.671612,	MLMLossWVC=1.809518,	MVRCLoss=2.453533,	
Rank[  2]Epoch[6] Batch [400]	Speed: 28.16 samples/s ETA: 1 d  3 h  9 m	Data: 0.368 Tran: 0.007 F: 0.150 B: 0.292 O: 1.449 M: 0.007	Train-MLMAcc=0.626022,	MVRCAccuracy=0.671612,	MLMLossWVC=1.809518,	MVRCLoss=2.453533,	
Rank[  1]Epoch[6] Batch [400]	Speed: 28.16 samples/s ETA: 1 d  3 h  9 m	Data: 0.138 Tran: 0.007 F: 0.150 B: 0.296 O: 1.674 M: 0.007	Train-MLMAcc=0.626022,	MVRCAccuracy=0.671612,	MLMLossWVC=1.809518,	MVRCLoss=2.453533,	
Rank[  0]Epoch[6] Batch [500]	Speed: 28.15 samples/s ETA: 1 d  3 h  5 m	Data: 1.761 Tran: 0.007 F: 0.151 B: 0.292 O: 0.054 M: 0.009	Train-MLMAcc=0.625772,	MVRCAccuracy=0.671727,	MLMLossWVC=1.809088,	MVRCLoss=2.452056,	
Rank[  3]Epoch[6] Batch [500]	Speed: 28.15 samples/s ETA: 1 d  3 h  5 m	Data: 0.022 Tran: 0.007 F: 0.148 B: 0.286 O: 1.801 M: 0.009	Train-MLMAcc=0.625772,	MVRCAccuracy=0.671727,	MLMLossWVC=1.809088,	MVRCLoss=2.452056,	
Rank[  2]Epoch[6] Batch [500]	Speed: 28.15 samples/s ETA: 1 d  3 h  5 m	Data: 0.336 Tran: 0.007 F: 0.150 B: 0.292 O: 1.480 M: 0.009	Train-MLMAcc=0.625772,	MVRCAccuracy=0.671727,	MLMLossWVC=1.809088,	MVRCLoss=2.452056,	
Rank[  1]Epoch[6] Batch [500]	Speed: 28.15 samples/s ETA: 1 d  3 h  5 m	Data: 0.009 Tran: 0.007 F: 0.150 B: 0.297 O: 1.805 M: 0.006	Train-MLMAcc=0.625772,	MVRCAccuracy=0.671727,	MLMLossWVC=1.809088,	MVRCLoss=2.452056,	
Rank[  1]Epoch[6] Batch [600]	Speed: 28.39 samples/s ETA: 1 d  2 h 48 m	Data: 0.084 Tran: 0.007 F: 0.151 B: 0.298 O: 1.706 M: 0.007	Train-MLMAcc=0.626039,	MVRCAccuracy=0.671870,	MLMLossWVC=1.807252,	MVRCLoss=2.451869,	
Rank[  3]Epoch[6] Batch [600]	Speed: 28.39 samples/s ETA: 1 d  2 h 48 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.290 O: 1.792 M: 0.008	Train-MLMAcc=0.626039,	MVRCAccuracy=0.671870,	MLMLossWVC=1.807252,	MVRCLoss=2.451869,	
Rank[  2]Epoch[6] Batch [600]	Speed: 28.39 samples/s ETA: 1 d  2 h 48 m	Data: 0.128 Tran: 0.007 F: 0.150 B: 0.292 O: 1.668 M: 0.008	Train-MLMAcc=0.626039,	MVRCAccuracy=0.671870,	MLMLossWVC=1.807252,	MVRCLoss=2.451869,	
Rank[  0]Epoch[6] Batch [600]	Speed: 28.39 samples/s ETA: 1 d  2 h 48 m	Data: 1.730 Tran: 0.007 F: 0.151 B: 0.292 O: 0.066 M: 0.008	Train-MLMAcc=0.626039,	MVRCAccuracy=0.671870,	MLMLossWVC=1.807252,	MVRCLoss=2.451869,	
Rank[  1]Epoch[6] Batch [700]	Speed: 28.14 samples/s ETA: 1 d  2 h 59 m	Data: 0.289 Tran: 0.007 F: 0.150 B: 0.297 O: 1.525 M: 0.006	Train-MLMAcc=0.625762,	MVRCAccuracy=0.671936,	MLMLossWVC=1.808864,	MVRCLoss=2.452597,	
Rank[  0]Epoch[6] Batch [700]	Speed: 28.14 samples/s ETA: 1 d  2 h 59 m	Data: 1.765 Tran: 0.007 F: 0.151 B: 0.291 O: 0.056 M: 0.005	Train-MLMAcc=0.625762,	MVRCAccuracy=0.671936,	MLMLossWVC=1.808864,	MVRCLoss=2.452597,	
Rank[  2]Epoch[6] Batch [700]	Speed: 28.14 samples/s ETA: 1 d  2 h 59 m	Data: 0.014 Tran: 0.008 F: 0.149 B: 0.291 O: 1.806 M: 0.005	Train-MLMAcc=0.625762,	MVRCAccuracy=0.671936,	MLMLossWVC=1.808864,	MVRCLoss=2.452597,	
Rank[  3]Epoch[6] Batch [700]	Speed: 28.14 samples/s ETA: 1 d  2 h 59 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.290 O: 1.815 M: 0.006	Train-MLMAcc=0.625762,	MVRCAccuracy=0.671936,	MLMLossWVC=1.808864,	MVRCLoss=2.452597,	
Rank[  0]Epoch[6] Batch [800]	Speed: 28.83 samples/s ETA: 1 d  2 h 16 m	Data: 1.644 Tran: 0.007 F: 0.151 B: 0.292 O: 0.119 M: 0.006	Train-MLMAcc=0.625649,	MVRCAccuracy=0.671890,	MLMLossWVC=1.808386,	MVRCLoss=2.451743,	
Rank[  3]Epoch[6] Batch [800]	Speed: 28.83 samples/s ETA: 1 d  2 h 16 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.289 O: 1.760 M: 0.006	Train-MLMAcc=0.625649,	MVRCAccuracy=0.671890,	MLMLossWVC=1.808386,	MVRCLoss=2.451743,	
Rank[  2]Epoch[6] Batch [800]	Speed: 28.83 samples/s ETA: 1 d  2 h 16 m	Data: 0.875 Tran: 0.007 F: 0.150 B: 0.292 O: 0.889 M: 0.007	Train-MLMAcc=0.625649,	MVRCAccuracy=0.671890,	MLMLossWVC=1.808386,	MVRCLoss=2.451743,	
Rank[  1]Epoch[6] Batch [800]	Speed: 28.83 samples/s ETA: 1 d  2 h 16 m	Data: 0.467 Tran: 0.007 F: 0.150 B: 0.297 O: 1.292 M: 0.005	Train-MLMAcc=0.625649,	MVRCAccuracy=0.671890,	MLMLossWVC=1.808386,	MVRCLoss=2.451743,	
Rank[  2]Epoch[6] Batch [900]	Speed: 27.77 samples/s ETA: 1 d  3 h 12 m	Data: 1.782 Tran: 0.007 F: 0.150 B: 0.292 O: 0.068 M: 0.006	Train-MLMAcc=0.625798,	MVRCAccuracy=0.671932,	MLMLossWVC=1.807344,	MVRCLoss=2.451251,	
Rank[  1]Epoch[6] Batch [900]	Speed: 27.77 samples/s ETA: 1 d  3 h 12 m	Data: 0.591 Tran: 0.007 F: 0.150 B: 0.297 O: 1.254 M: 0.006	Train-MLMAcc=0.625798,	MVRCAccuracy=0.671932,	MLMLossWVC=1.807344,	MVRCLoss=2.451251,	
Rank[  0]Epoch[6] Batch [900]	Speed: 27.77 samples/s ETA: 1 d  3 h 12 m	Data: 1.040 Tran: 0.007 F: 0.150 B: 0.292 O: 0.809 M: 0.006	Train-MLMAcc=0.625798,	MVRCAccuracy=0.671932,	MLMLossWVC=1.807344,	MVRCLoss=2.451251,	
Rank[  3]Epoch[6] Batch [900]	Speed: 27.77 samples/s ETA: 1 d  3 h 12 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.290 O: 1.845 M: 0.006	Train-MLMAcc=0.625798,	MVRCAccuracy=0.671932,	MLMLossWVC=1.807344,	MVRCLoss=2.451251,	
Rank[  0]Epoch[6] Batch [1000]	Speed: 28.04 samples/s ETA: 1 d  2 h 52 m	Data: 0.499 Tran: 0.007 F: 0.150 B: 0.291 O: 1.328 M: 0.006	Train-MLMAcc=0.625667,	MVRCAccuracy=0.672095,	MLMLossWVC=1.807111,	MVRCLoss=2.450602,	
Rank[  3]Epoch[6] Batch [1000]	Speed: 28.04 samples/s ETA: 1 d  2 h 52 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.289 O: 1.822 M: 0.008	Train-MLMAcc=0.625667,	MVRCAccuracy=0.672095,	MLMLossWVC=1.807111,	MVRCLoss=2.450602,	
Rank[  2]Epoch[6] Batch [1000]	Speed: 28.04 samples/s ETA: 1 d  2 h 52 m	Data: 1.771 Tran: 0.007 F: 0.151 B: 0.294 O: 0.051 M: 0.007	Train-MLMAcc=0.625667,	MVRCAccuracy=0.672095,	MLMLossWVC=1.807111,	MVRCLoss=2.450602,	
Rank[  1]Epoch[6] Batch [1000]	Speed: 28.04 samples/s ETA: 1 d  2 h 52 m	Data: 0.018 Tran: 0.007 F: 0.151 B: 0.298 O: 1.800 M: 0.007	Train-MLMAcc=0.625667,	MVRCAccuracy=0.672095,	MLMLossWVC=1.807111,	MVRCLoss=2.450602,	
Rank[  0]Epoch[6] Batch [1100]	Speed: 28.24 samples/s ETA: 1 d  2 h 37 m	Data: 0.432 Tran: 0.007 F: 0.150 B: 0.292 O: 1.377 M: 0.007	Train-MLMAcc=0.625693,	MVRCAccuracy=0.671941,	MLMLossWVC=1.808636,	MVRCLoss=2.450618,	
Rank[  3]Epoch[6] Batch [1100]	Speed: 28.24 samples/s ETA: 1 d  2 h 37 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.290 O: 1.804 M: 0.008	Train-MLMAcc=0.625693,	MVRCAccuracy=0.671941,	MLMLossWVC=1.808636,	MVRCLoss=2.450618,	
Rank[  2]Epoch[6] Batch [1100]	Speed: 28.24 samples/s ETA: 1 d  2 h 37 m	Data: 1.755 Tran: 0.007 F: 0.150 B: 0.293 O: 0.055 M: 0.005	Train-MLMAcc=0.625693,	MVRCAccuracy=0.671941,	MLMLossWVC=1.808636,	MVRCLoss=2.450618,	
Rank[  1]Epoch[6] Batch [1100]	Speed: 28.24 samples/s ETA: 1 d  2 h 37 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.796 M: 0.008	Train-MLMAcc=0.625693,	MVRCAccuracy=0.671941,	MLMLossWVC=1.808636,	MVRCLoss=2.450618,	
Rank[  2]Epoch[6] Batch [1200]	Speed: 28.12 samples/s ETA: 1 d  2 h 40 m	Data: 1.765 Tran: 0.008 F: 0.150 B: 0.292 O: 0.053 M: 0.006	Train-MLMAcc=0.625533,	MVRCAccuracy=0.671956,	MLMLossWVC=1.809589,	MVRCLoss=2.450426,	
Rank[  3]Epoch[6] Batch [1200]	Speed: 28.12 samples/s ETA: 1 d  2 h 40 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.289 O: 1.815 M: 0.007	Train-MLMAcc=0.625533,	MVRCAccuracy=0.671956,	MLMLossWVC=1.809589,	MVRCLoss=2.450426,	
Rank[  0]Epoch[6] Batch [1200]	Speed: 28.12 samples/s ETA: 1 d  2 h 40 m	Data: 0.601 Tran: 0.007 F: 0.150 B: 0.291 O: 1.220 M: 0.007	Train-MLMAcc=0.625533,	MVRCAccuracy=0.671956,	MLMLossWVC=1.809589,	MVRCLoss=2.450426,	
Rank[  1]Epoch[6] Batch [1200]	Speed: 28.12 samples/s ETA: 1 d  2 h 40 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.807 M: 0.006	Train-MLMAcc=0.625533,	MVRCAccuracy=0.671956,	MLMLossWVC=1.809589,	MVRCLoss=2.450426,	
Rank[  1]Epoch[6] Batch [1300]	Speed: 28.22 samples/s ETA: 1 d  2 h 31 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.800 M: 0.007	Train-MLMAcc=0.625227,	MVRCAccuracy=0.671893,	MLMLossWVC=1.811730,	MVRCLoss=2.451323,	
Rank[  0]Epoch[6] Batch [1300]	Speed: 28.22 samples/s ETA: 1 d  2 h 31 m	Data: 0.258 Tran: 0.007 F: 0.151 B: 0.293 O: 1.552 M: 0.007	Train-MLMAcc=0.625227,	MVRCAccuracy=0.671893,	MLMLossWVC=1.811730,	MVRCLoss=2.451323,	
Rank[  3]Epoch[6] Batch [1300]	Speed: 28.22 samples/s ETA: 1 d  2 h 31 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.805 M: 0.007	Train-MLMAcc=0.625227,	MVRCAccuracy=0.671893,	MLMLossWVC=1.811730,	MVRCLoss=2.451323,	
Rank[  2]Epoch[6] Batch [1300]	Speed: 28.22 samples/s ETA: 1 d  2 h 31 m	Data: 1.756 Tran: 0.007 F: 0.151 B: 0.293 O: 0.053 M: 0.007	Train-MLMAcc=0.625227,	MVRCAccuracy=0.671893,	MLMLossWVC=1.811730,	MVRCLoss=2.451323,	
Rank[  0]Epoch[6] Batch [1400]	Speed: 28.57 samples/s ETA: 1 d  2 h  8 m	Data: 0.115 Tran: 0.007 F: 0.150 B: 0.292 O: 1.670 M: 0.006	Train-MLMAcc=0.625227,	MVRCAccuracy=0.672048,	MLMLossWVC=1.811476,	MVRCLoss=2.451586,	
Rank[  1]Epoch[6] Batch [1400]	Speed: 28.57 samples/s ETA: 1 d  2 h  8 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.297 O: 1.772 M: 0.005	Train-MLMAcc=0.625227,	MVRCAccuracy=0.672048,	MLMLossWVC=1.811476,	MVRCLoss=2.451586,	
Rank[  3]Epoch[6] Batch [1400]	Speed: 28.57 samples/s ETA: 1 d  2 h  8 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.289 O: 1.780 M: 0.006	Train-MLMAcc=0.625227,	MVRCAccuracy=0.672048,	MLMLossWVC=1.811476,	MVRCLoss=2.451586,	
Rank[  2]Epoch[6] Batch [1400]	Speed: 28.57 samples/s ETA: 1 d  2 h  8 m	Data: 1.729 Tran: 0.007 F: 0.151 B: 0.292 O: 0.055 M: 0.005	Train-MLMAcc=0.625227,	MVRCAccuracy=0.672048,	MLMLossWVC=1.811476,	MVRCLoss=2.451586,	
Rank[  0]Epoch[6] Batch [1500]	Speed: 27.94 samples/s ETA: 1 d  2 h 39 m	Data: 0.134 Tran: 0.007 F: 0.150 B: 0.291 O: 1.700 M: 0.008	Train-MLMAcc=0.625393,	MVRCAccuracy=0.672142,	MLMLossWVC=1.810587,	MVRCLoss=2.451718,	
Rank[  2]Epoch[6] Batch [1500]	Speed: 27.94 samples/s ETA: 1 d  2 h 39 m	Data: 1.778 Tran: 0.007 F: 0.151 B: 0.292 O: 0.054 M: 0.007	Train-MLMAcc=0.625393,	MVRCAccuracy=0.672142,	MLMLossWVC=1.810587,	MVRCLoss=2.451718,	
Rank[  3]Epoch[6] Batch [1500]	Speed: 27.94 samples/s ETA: 1 d  2 h 39 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.289 O: 1.830 M: 0.005	Train-MLMAcc=0.625393,	MVRCAccuracy=0.672142,	MLMLossWVC=1.810587,	MVRCLoss=2.451718,	
Rank[  1]Epoch[6] Batch [1500]	Speed: 27.94 samples/s ETA: 1 d  2 h 39 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.297 O: 1.820 M: 0.007	Train-MLMAcc=0.625393,	MVRCAccuracy=0.672142,	MLMLossWVC=1.810587,	MVRCLoss=2.451718,	
Rank[  0]Epoch[6] Batch [1600]	Speed: 28.19 samples/s ETA: 1 d  2 h 21 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.805 M: 0.007	Train-MLMAcc=0.625514,	MVRCAccuracy=0.672126,	MLMLossWVC=1.810470,	MVRCLoss=2.452576,	
Rank[  1]Epoch[6] Batch [1600]	Speed: 28.19 samples/s ETA: 1 d  2 h 21 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.300 O: 1.799 M: 0.006	Train-MLMAcc=0.625514,	MVRCAccuracy=0.672126,	MLMLossWVC=1.810470,	MVRCLoss=2.452576,	
Rank[  3]Epoch[6] Batch [1600]	Speed: 28.19 samples/s ETA: 1 d  2 h 21 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.805 M: 0.008	Train-MLMAcc=0.625514,	MVRCAccuracy=0.672126,	MLMLossWVC=1.810470,	MVRCLoss=2.452576,	
Rank[  2]Epoch[6] Batch [1600]	Speed: 28.19 samples/s ETA: 1 d  2 h 21 m	Data: 1.757 Tran: 0.007 F: 0.150 B: 0.291 O: 0.057 M: 0.008	Train-MLMAcc=0.625514,	MVRCAccuracy=0.672126,	MLMLossWVC=1.810470,	MVRCLoss=2.452576,	
Rank[  0]Epoch[6] Batch [1700]	Speed: 28.57 samples/s ETA: 1 d  1 h 56 m	Data: 0.017 Tran: 0.007 F: 0.149 B: 0.290 O: 1.767 M: 0.008	Train-MLMAcc=0.625455,	MVRCAccuracy=0.672154,	MLMLossWVC=1.811439,	MVRCLoss=2.452650,	
Rank[  3]Epoch[6] Batch [1700]	Speed: 28.57 samples/s ETA: 1 d  1 h 56 m	Data: 0.064 Tran: 0.007 F: 0.149 B: 0.289 O: 1.722 M: 0.008	Train-MLMAcc=0.625455,	MVRCAccuracy=0.672154,	MLMLossWVC=1.811439,	MVRCLoss=2.452650,	
Rank[  1]Epoch[6] Batch [1700]	Speed: 28.57 samples/s ETA: 1 d  1 h 56 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.771 M: 0.007	Train-MLMAcc=0.625455,	MVRCAccuracy=0.672154,	MLMLossWVC=1.811439,	MVRCLoss=2.452650,	
Rank[  2]Epoch[6] Batch [1700]	Speed: 28.57 samples/s ETA: 1 d  1 h 56 m	Data: 1.720 Tran: 0.007 F: 0.151 B: 0.295 O: 0.060 M: 0.006	Train-MLMAcc=0.625455,	MVRCAccuracy=0.672154,	MLMLossWVC=1.811439,	MVRCLoss=2.452650,	
Rank[  2]Epoch[6] Batch [1800]	Speed: 27.95 samples/s ETA: 1 d  2 h 28 m	Data: 1.569 Tran: 0.006 F: 0.150 B: 0.294 O: 0.263 M: 0.007	Train-MLMAcc=0.625426,	MVRCAccuracy=0.672149,	MLMLossWVC=1.811487,	MVRCLoss=2.452798,	
Rank[  0]Epoch[6] Batch [1800]	Speed: 27.95 samples/s ETA: 1 d  2 h 28 m	Data: 0.408 Tran: 0.006 F: 0.151 B: 0.294 O: 1.424 M: 0.006	Train-MLMAcc=0.625426,	MVRCAccuracy=0.672149,	MLMLossWVC=1.811487,	MVRCLoss=2.452798,	
Rank[  1]Epoch[6] Batch [1800]	Speed: 27.95 samples/s ETA: 1 d  2 h 28 m	Data: 0.012 Tran: 0.007 F: 0.150 B: 0.298 O: 1.816 M: 0.007	Train-MLMAcc=0.625426,	MVRCAccuracy=0.672149,	MLMLossWVC=1.811487,	MVRCLoss=2.452798,	
Rank[  3]Epoch[6] Batch [1800]	Speed: 27.95 samples/s ETA: 1 d  2 h 28 m	Data: 0.594 Tran: 0.007 F: 0.151 B: 0.292 O: 1.240 M: 0.007	Train-MLMAcc=0.625426,	MVRCAccuracy=0.672149,	MLMLossWVC=1.811487,	MVRCLoss=2.452798,	
Rank[  0]Epoch[6] Batch [1900]	Speed: 27.85 samples/s ETA: 1 d  2 h 29 m	Data: 0.214 Tran: 0.007 F: 0.151 B: 0.292 O: 1.623 M: 0.011	Train-MLMAcc=0.625392,	MVRCAccuracy=0.672259,	MLMLossWVC=1.810708,	MVRCLoss=2.452405,	
Rank[  3]Epoch[6] Batch [1900]	Speed: 27.85 samples/s ETA: 1 d  2 h 29 m	Data: 0.615 Tran: 0.007 F: 0.150 B: 0.291 O: 1.224 M: 0.010	Train-MLMAcc=0.625392,	MVRCAccuracy=0.672259,	MLMLossWVC=1.810708,	MVRCLoss=2.452405,	
Rank[  2]Epoch[6] Batch [1900]	Speed: 27.85 samples/s ETA: 1 d  2 h 29 m	Data: 1.711 Tran: 0.008 F: 0.162 B: 0.307 O: 0.100 M: 0.009	Train-MLMAcc=0.625392,	MVRCAccuracy=0.672259,	MLMLossWVC=1.810708,	MVRCLoss=2.452405,	
Rank[  1]Epoch[6] Batch [1900]	Speed: 27.85 samples/s ETA: 1 d  2 h 29 m	Data: 0.007 Tran: 0.007 F: 0.152 B: 0.299 O: 1.822 M: 0.010	Train-MLMAcc=0.625392,	MVRCAccuracy=0.672259,	MLMLossWVC=1.810708,	MVRCLoss=2.452405,	
Rank[  2]Epoch[6] Batch [2000]	Speed: 27.22 samples/s ETA: 1 d  3 h  2 m	Data: 1.684 Tran: 0.008 F: 0.188 B: 0.310 O: 0.150 M: 0.010	Train-MLMAcc=0.625399,	MVRCAccuracy=0.672099,	MLMLossWVC=1.810265,	MVRCLoss=2.452355,	
Rank[  0]Epoch[6] Batch [2000]	Speed: 27.22 samples/s ETA: 1 d  3 h  2 m	Data: 0.009 Tran: 0.007 F: 0.157 B: 0.305 O: 1.860 M: 0.010	Train-MLMAcc=0.625399,	MVRCAccuracy=0.672099,	MLMLossWVC=1.810265,	MVRCLoss=2.452355,	
Rank[  1]Epoch[6] Batch [2000]	Speed: 27.22 samples/s ETA: 1 d  3 h  2 m	Data: 0.009 Tran: 0.007 F: 0.157 B: 0.309 O: 1.857 M: 0.010	Train-MLMAcc=0.625399,	MVRCAccuracy=0.672099,	MLMLossWVC=1.810265,	MVRCLoss=2.452355,	
Rank[  3]Epoch[6] Batch [2000]	Speed: 27.22 samples/s ETA: 1 d  3 h  2 m	Data: 1.151 Tran: 0.008 F: 0.168 B: 0.306 O: 0.705 M: 0.010	Train-MLMAcc=0.625399,	MVRCAccuracy=0.672099,	MLMLossWVC=1.810265,	MVRCLoss=2.452355,	
Rank[  0]Epoch[6] Batch [2100]	Speed: 28.07 samples/s ETA: 1 d  2 h  9 m	Data: 0.098 Tran: 0.007 F: 0.149 B: 0.291 O: 1.728 M: 0.006	Train-MLMAcc=0.625573,	MVRCAccuracy=0.672196,	MLMLossWVC=1.808762,	MVRCLoss=2.452426,	
Rank[  2]Epoch[6] Batch [2100]	Speed: 28.07 samples/s ETA: 1 d  2 h  9 m	Data: 1.621 Tran: 0.006 F: 0.151 B: 0.295 O: 0.201 M: 0.006	Train-MLMAcc=0.625573,	MVRCAccuracy=0.672196,	MLMLossWVC=1.808762,	MVRCLoss=2.452426,	
Rank[  3]Epoch[6] Batch [2100]	Speed: 28.07 samples/s ETA: 1 d  2 h  9 m	Data: 0.628 Tran: 0.006 F: 0.149 B: 0.289 O: 1.199 M: 0.007	Train-MLMAcc=0.625573,	MVRCAccuracy=0.672196,	MLMLossWVC=1.808762,	MVRCLoss=2.452426,	
Rank[  1]Epoch[6] Batch [2100]	Speed: 28.07 samples/s ETA: 1 d  2 h  9 m	Data: 0.069 Tran: 0.006 F: 0.149 B: 0.296 O: 1.752 M: 0.007	Train-MLMAcc=0.625573,	MVRCAccuracy=0.672196,	MLMLossWVC=1.808762,	MVRCLoss=2.452426,	
Rank[  1]Epoch[6] Batch [2200]	Speed: 28.16 samples/s ETA: 1 d  2 h  0 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.802 M: 0.007	Train-MLMAcc=0.625685,	MVRCAccuracy=0.672367,	MLMLossWVC=1.808617,	MVRCLoss=2.451891,	
Rank[  0]Epoch[6] Batch [2200]	Speed: 28.16 samples/s ETA: 1 d  2 h  0 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.290 O: 1.812 M: 0.007	Train-MLMAcc=0.625685,	MVRCAccuracy=0.672367,	MLMLossWVC=1.808617,	MVRCLoss=2.451891,	
Rank[  2]Epoch[6] Batch [2200]	Speed: 28.16 samples/s ETA: 1 d  2 h  0 m	Data: 1.765 Tran: 0.007 F: 0.151 B: 0.294 O: 0.048 M: 0.007	Train-MLMAcc=0.625685,	MVRCAccuracy=0.672367,	MLMLossWVC=1.808617,	MVRCLoss=2.451891,	
Rank[  3]Epoch[6] Batch [2200]	Speed: 28.16 samples/s ETA: 1 d  2 h  0 m	Data: 0.051 Tran: 0.007 F: 0.149 B: 0.289 O: 1.769 M: 0.007	Train-MLMAcc=0.625685,	MVRCAccuracy=0.672367,	MLMLossWVC=1.808617,	MVRCLoss=2.451891,	
Rank[  0]Epoch[6] Batch [2300]	Speed: 28.10 samples/s ETA: 1 d  2 h  0 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.813 M: 0.007	Train-MLMAcc=0.625852,	MVRCAccuracy=0.672321,	MLMLossWVC=1.807799,	MVRCLoss=2.451614,	
Rank[  1]Epoch[6] Batch [2300]	Speed: 28.10 samples/s ETA: 1 d  2 h  0 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.808 M: 0.006	Train-MLMAcc=0.625852,	MVRCAccuracy=0.672321,	MLMLossWVC=1.807799,	MVRCLoss=2.451614,	
Rank[  3]Epoch[6] Batch [2300]	Speed: 28.10 samples/s ETA: 1 d  2 h  0 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.289 O: 1.817 M: 0.008	Train-MLMAcc=0.625852,	MVRCAccuracy=0.672321,	MLMLossWVC=1.807799,	MVRCLoss=2.451614,	
Rank[  2]Epoch[6] Batch [2300]	Speed: 28.10 samples/s ETA: 1 d  2 h  0 m	Data: 1.772 Tran: 0.006 F: 0.151 B: 0.295 O: 0.046 M: 0.006	Train-MLMAcc=0.625852,	MVRCAccuracy=0.672321,	MLMLossWVC=1.807799,	MVRCLoss=2.451614,	
Rank[  2]Epoch[6] Batch [2400]	Speed: 27.63 samples/s ETA: 1 d  2 h 22 m	Data: 1.755 Tran: 0.010 F: 0.180 B: 0.311 O: 0.052 M: 0.007	Train-MLMAcc=0.626000,	MVRCAccuracy=0.672413,	MLMLossWVC=1.806512,	MVRCLoss=2.451085,	
Rank[  3]Epoch[6] Batch [2400]	Speed: 27.63 samples/s ETA: 1 d  2 h 22 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.296 O: 1.845 M: 0.007	Train-MLMAcc=0.626000,	MVRCAccuracy=0.672413,	MLMLossWVC=1.806512,	MVRCLoss=2.451085,	
Rank[  1]Epoch[6] Batch [2400]	Speed: 27.63 samples/s ETA: 1 d  2 h 22 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.303 O: 1.838 M: 0.007	Train-MLMAcc=0.626000,	MVRCAccuracy=0.672413,	MLMLossWVC=1.806512,	MVRCLoss=2.451085,	
Rank[  0]Epoch[6] Batch [2400]	Speed: 27.63 samples/s ETA: 1 d  2 h 22 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.299 O: 1.841 M: 0.007	Train-MLMAcc=0.626000,	MVRCAccuracy=0.672413,	MLMLossWVC=1.806512,	MVRCLoss=2.451085,	
Rank[  3]Epoch[6] Batch [2500]	Speed: 27.40 samples/s ETA: 1 d  2 h 32 m	Data: 0.008 Tran: 0.008 F: 0.154 B: 0.295 O: 1.861 M: 0.009	Train-MLMAcc=0.626181,	MVRCAccuracy=0.672492,	MLMLossWVC=1.805188,	MVRCLoss=2.450969,	
Rank[  2]Epoch[6] Batch [2500]	Speed: 27.40 samples/s ETA: 1 d  2 h 32 m	Data: 1.796 Tran: 0.009 F: 0.165 B: 0.301 O: 0.056 M: 0.008	Train-MLMAcc=0.626181,	MVRCAccuracy=0.672492,	MLMLossWVC=1.805188,	MVRCLoss=2.450969,	
Rank[  1]Epoch[6] Batch [2500]	Speed: 27.40 samples/s ETA: 1 d  2 h 32 m	Data: 0.008 Tran: 0.008 F: 0.153 B: 0.300 O: 1.859 M: 0.007	Train-MLMAcc=0.626181,	MVRCAccuracy=0.672492,	MLMLossWVC=1.805188,	MVRCLoss=2.450969,	
Rank[  0]Epoch[6] Batch [2500]	Speed: 27.40 samples/s ETA: 1 d  2 h 32 m	Data: 0.008 Tran: 0.008 F: 0.155 B: 0.296 O: 1.859 M: 0.009	Train-MLMAcc=0.626181,	MVRCAccuracy=0.672492,	MLMLossWVC=1.805188,	MVRCLoss=2.450969,	
Rank[  0]Epoch[6] Batch [2600]	Speed: 28.43 samples/s ETA: 1 d  1 h 30 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.788 M: 0.005	Train-MLMAcc=0.626259,	MVRCAccuracy=0.672586,	MLMLossWVC=1.804429,	MVRCLoss=2.450872,	
Rank[  1]Epoch[6] Batch [2600]	Speed: 28.43 samples/s ETA: 1 d  1 h 30 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.296 O: 1.783 M: 0.006	Train-MLMAcc=0.626259,	MVRCAccuracy=0.672586,	MLMLossWVC=1.804429,	MVRCLoss=2.450872,	
Rank[  3]Epoch[6] Batch [2600]	Speed: 28.43 samples/s ETA: 1 d  1 h 30 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.289 O: 1.790 M: 0.006	Train-MLMAcc=0.626259,	MVRCAccuracy=0.672586,	MLMLossWVC=1.804429,	MVRCLoss=2.450872,	
Rank[  2]Epoch[6] Batch [2600]	Speed: 28.43 samples/s ETA: 1 d  1 h 30 m	Data: 1.739 Tran: 0.007 F: 0.151 B: 0.294 O: 0.054 M: 0.005	Train-MLMAcc=0.626259,	MVRCAccuracy=0.672586,	MLMLossWVC=1.804429,	MVRCLoss=2.450872,	
Rank[  0]Epoch[6] Batch [2700]	Speed: 27.92 samples/s ETA: 1 d  1 h 54 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.825 M: 0.010	Train-MLMAcc=0.626241,	MVRCAccuracy=0.672658,	MLMLossWVC=1.804584,	MVRCLoss=2.450888,	
Rank[  1]Epoch[6] Batch [2700]	Speed: 27.92 samples/s ETA: 1 d  1 h 54 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.823 M: 0.006	Train-MLMAcc=0.626241,	MVRCAccuracy=0.672658,	MLMLossWVC=1.804584,	MVRCLoss=2.450888,	
Rank[  3]Epoch[6] Batch [2700]	Speed: 27.92 samples/s ETA: 1 d  1 h 54 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.289 O: 1.828 M: 0.009	Train-MLMAcc=0.626241,	MVRCAccuracy=0.672658,	MLMLossWVC=1.804584,	MVRCLoss=2.450888,	
Rank[  2]Epoch[6] Batch [2700]	Speed: 27.92 samples/s ETA: 1 d  1 h 54 m	Data: 1.777 Tran: 0.007 F: 0.151 B: 0.294 O: 0.054 M: 0.008	Train-MLMAcc=0.626241,	MVRCAccuracy=0.672658,	MLMLossWVC=1.804584,	MVRCLoss=2.450888,	
Rank[  1]Epoch[6] Batch [2800]	Speed: 28.19 samples/s ETA: 1 d  1 h 36 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.804 M: 0.006	Train-MLMAcc=0.626104,	MVRCAccuracy=0.672737,	MLMLossWVC=1.805330,	MVRCLoss=2.450845,	
Rank[  2]Epoch[6] Batch [2800]	Speed: 28.19 samples/s ETA: 1 d  1 h 36 m	Data: 1.757 Tran: 0.007 F: 0.151 B: 0.292 O: 0.055 M: 0.008	Train-MLMAcc=0.626104,	MVRCAccuracy=0.672737,	MLMLossWVC=1.805330,	MVRCLoss=2.450845,	
Rank[  0]Epoch[6] Batch [2800]	Speed: 28.19 samples/s ETA: 1 d  1 h 36 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.802 M: 0.008	Train-MLMAcc=0.626104,	MVRCAccuracy=0.672737,	MLMLossWVC=1.805330,	MVRCLoss=2.450845,	
Rank[  3]Epoch[6] Batch [2800]	Speed: 28.19 samples/s ETA: 1 d  1 h 36 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.290 O: 1.807 M: 0.008	Train-MLMAcc=0.626104,	MVRCAccuracy=0.672737,	MLMLossWVC=1.805330,	MVRCLoss=2.450845,	
Rank[  1]Epoch[6] Batch [2900]	Speed: 28.35 samples/s ETA: 1 d  1 h 24 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.786 M: 0.007	Train-MLMAcc=0.626112,	MVRCAccuracy=0.672690,	MLMLossWVC=1.804901,	MVRCLoss=2.450867,	
Rank[  0]Epoch[6] Batch [2900]	Speed: 28.35 samples/s ETA: 1 d  1 h 24 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.794 M: 0.007	Train-MLMAcc=0.626112,	MVRCAccuracy=0.672690,	MLMLossWVC=1.804901,	MVRCLoss=2.450867,	
Rank[  2]Epoch[6] Batch [2900]	Speed: 28.35 samples/s ETA: 1 d  1 h 24 m	Data: 1.743 Tran: 0.007 F: 0.151 B: 0.293 O: 0.056 M: 0.007	Train-MLMAcc=0.626112,	MVRCAccuracy=0.672690,	MLMLossWVC=1.804901,	MVRCLoss=2.450867,	
Rank[  3]Epoch[6] Batch [2900]	Speed: 28.35 samples/s ETA: 1 d  1 h 24 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.796 M: 0.005	Train-MLMAcc=0.626112,	MVRCAccuracy=0.672690,	MLMLossWVC=1.804901,	MVRCLoss=2.450867,	
Rank[  0]Epoch[6] Batch [3000]	Speed: 28.31 samples/s ETA: 1 d  1 h 22 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.291 O: 1.799 M: 0.006	Train-MLMAcc=0.625999,	MVRCAccuracy=0.672648,	MLMLossWVC=1.805170,	MVRCLoss=2.450673,	
Rank[  1]Epoch[6] Batch [3000]	Speed: 28.31 samples/s ETA: 1 d  1 h 22 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.792 M: 0.006	Train-MLMAcc=0.625999,	MVRCAccuracy=0.672648,	MLMLossWVC=1.805170,	MVRCLoss=2.450673,	
Rank[  3]Epoch[6] Batch [3000]	Speed: 28.31 samples/s ETA: 1 d  1 h 22 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.289 O: 1.800 M: 0.008	Train-MLMAcc=0.625999,	MVRCAccuracy=0.672648,	MLMLossWVC=1.805170,	MVRCLoss=2.450673,	
Rank[  2]Epoch[6] Batch [3000]	Speed: 28.31 samples/s ETA: 1 d  1 h 22 m	Data: 1.749 Tran: 0.007 F: 0.151 B: 0.294 O: 0.051 M: 0.008	Train-MLMAcc=0.625999,	MVRCAccuracy=0.672648,	MLMLossWVC=1.805170,	MVRCLoss=2.450673,	
Rank[  1]Epoch[6] Batch [3100]	Speed: 28.02 samples/s ETA: 1 d  1 h 34 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.297 O: 1.817 M: 0.007	Train-MLMAcc=0.625978,	MVRCAccuracy=0.672639,	MLMLossWVC=1.805614,	MVRCLoss=2.450826,	
Rank[  3]Epoch[6] Batch [3100]	Speed: 28.02 samples/s ETA: 1 d  1 h 34 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.291 O: 1.819 M: 0.010	Train-MLMAcc=0.625978,	MVRCAccuracy=0.672639,	MLMLossWVC=1.805614,	MVRCLoss=2.450826,	
Rank[  0]Epoch[6] Batch [3100]	Speed: 28.02 samples/s ETA: 1 d  1 h 34 m	Data: 0.392 Tran: 0.007 F: 0.150 B: 0.292 O: 1.433 M: 0.009	Train-MLMAcc=0.625978,	MVRCAccuracy=0.672639,	MLMLossWVC=1.805614,	MVRCLoss=2.450826,	
Rank[  2]Epoch[6] Batch [3100]	Speed: 28.02 samples/s ETA: 1 d  1 h 34 m	Data: 1.386 Tran: 0.007 F: 0.150 B: 0.292 O: 0.440 M: 0.008	Train-MLMAcc=0.625978,	MVRCAccuracy=0.672639,	MLMLossWVC=1.805614,	MVRCLoss=2.450826,	
Rank[  2]Epoch[6] Batch [3200]	Speed: 27.91 samples/s ETA: 1 d  1 h 36 m	Data: 0.705 Tran: 0.007 F: 0.152 B: 0.296 O: 1.126 M: 0.007	Train-MLMAcc=0.626071,	MVRCAccuracy=0.672618,	MLMLossWVC=1.805292,	MVRCLoss=2.450939,	
Rank[  0]Epoch[6] Batch [3200]	Speed: 27.91 samples/s ETA: 1 d  1 h 36 m	Data: 1.079 Tran: 0.007 F: 0.151 B: 0.294 O: 0.753 M: 0.008	Train-MLMAcc=0.626071,	MVRCAccuracy=0.672618,	MLMLossWVC=1.805292,	MVRCLoss=2.450939,	
Rank[  3]Epoch[6] Batch [3200]	Speed: 27.91 samples/s ETA: 1 d  1 h 36 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.292 O: 1.826 M: 0.009	Train-MLMAcc=0.626071,	MVRCAccuracy=0.672618,	MLMLossWVC=1.805292,	MVRCLoss=2.450939,	
Rank[  1]Epoch[6] Batch [3200]	Speed: 27.91 samples/s ETA: 1 d  1 h 36 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.820 M: 0.010	Train-MLMAcc=0.626071,	MVRCAccuracy=0.672618,	MLMLossWVC=1.805292,	MVRCLoss=2.450939,	
Rank[  1]Epoch[6] Batch [3300]	Speed: 28.26 samples/s ETA: 1 d  1 h 13 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.793 M: 0.009	Train-MLMAcc=0.626094,	MVRCAccuracy=0.672632,	MLMLossWVC=1.805567,	MVRCLoss=2.450994,	
Rank[  0]Epoch[6] Batch [3300]	Speed: 28.26 samples/s ETA: 1 d  1 h 13 m	Data: 0.375 Tran: 0.007 F: 0.151 B: 0.294 O: 1.430 M: 0.008	Train-MLMAcc=0.626094,	MVRCAccuracy=0.672632,	MLMLossWVC=1.805567,	MVRCLoss=2.450994,	
Rank[  3]Epoch[6] Batch [3300]	Speed: 28.25 samples/s ETA: 1 d  1 h 13 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.802 M: 0.007	Train-MLMAcc=0.626094,	MVRCAccuracy=0.672632,	MLMLossWVC=1.805567,	MVRCLoss=2.450994,	
Rank[  2]Epoch[6] Batch [3300]	Speed: 28.25 samples/s ETA: 1 d  1 h 13 m	Data: 1.384 Tran: 0.006 F: 0.151 B: 0.293 O: 0.421 M: 0.009	Train-MLMAcc=0.626094,	MVRCAccuracy=0.672632,	MLMLossWVC=1.805567,	MVRCLoss=2.450994,	
Rank[  0]Epoch[6] Batch [3400]	Speed: 28.25 samples/s ETA: 1 d  1 h 10 m	Data: 0.015 Tran: 0.007 F: 0.150 B: 0.293 O: 1.792 M: 0.007	Train-MLMAcc=0.626028,	MVRCAccuracy=0.672644,	MLMLossWVC=1.805423,	MVRCLoss=2.451009,	
Rank[  3]Epoch[6] Batch [3400]	Speed: 28.25 samples/s ETA: 1 d  1 h 10 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.802 M: 0.007	Train-MLMAcc=0.626028,	MVRCAccuracy=0.672644,	MLMLossWVC=1.805423,	MVRCLoss=2.451009,	
Rank[  1]Epoch[6] Batch [3400]	Speed: 28.25 samples/s ETA: 1 d  1 h 10 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.795 M: 0.007	Train-MLMAcc=0.626028,	MVRCAccuracy=0.672644,	MLMLossWVC=1.805423,	MVRCLoss=2.451009,	
Rank[  2]Epoch[6] Batch [3400]	Speed: 28.25 samples/s ETA: 1 d  1 h 10 m	Data: 1.744 Tran: 0.006 F: 0.151 B: 0.293 O: 0.062 M: 0.008	Train-MLMAcc=0.626028,	MVRCAccuracy=0.672644,	MLMLossWVC=1.805423,	MVRCLoss=2.451009,	
Rank[  1]Epoch[6] Batch [3500]	Speed: 28.47 samples/s ETA: 1 d  0 h 55 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.777 M: 0.007	Train-MLMAcc=0.626021,	MVRCAccuracy=0.672702,	MLMLossWVC=1.805846,	MVRCLoss=2.451013,	
Rank[  0]Epoch[6] Batch [3500]	Speed: 28.47 samples/s ETA: 1 d  0 h 55 m	Data: 0.350 Tran: 0.007 F: 0.149 B: 0.291 O: 1.441 M: 0.009	Train-MLMAcc=0.626021,	MVRCAccuracy=0.672702,	MLMLossWVC=1.805846,	MVRCLoss=2.451013,	
Rank[  3]Epoch[6] Batch [3500]	Speed: 28.47 samples/s ETA: 1 d  0 h 55 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.784 M: 0.008	Train-MLMAcc=0.626021,	MVRCAccuracy=0.672702,	MLMLossWVC=1.805846,	MVRCLoss=2.451013,	
Rank[  2]Epoch[6] Batch [3500]	Speed: 28.47 samples/s ETA: 1 d  0 h 55 m	Data: 1.714 Tran: 0.007 F: 0.150 B: 0.290 O: 0.079 M: 0.007	Train-MLMAcc=0.626021,	MVRCAccuracy=0.672702,	MLMLossWVC=1.805846,	MVRCLoss=2.451013,	
Rank[  0]Epoch[6] Batch [3600]	Speed: 28.22 samples/s ETA: 1 d  1 h  4 m	Data: 0.338 Tran: 0.007 F: 0.150 B: 0.291 O: 1.473 M: 0.008	Train-MLMAcc=0.626133,	MVRCAccuracy=0.672712,	MLMLossWVC=1.804991,	MVRCLoss=2.450926,	
Rank[  3]Epoch[6] Batch [3600]	Speed: 28.22 samples/s ETA: 1 d  1 h  4 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.803 M: 0.009	Train-MLMAcc=0.626133,	MVRCAccuracy=0.672712,	MLMLossWVC=1.804991,	MVRCLoss=2.450926,	
Rank[  2]Epoch[6] Batch [3600]	Speed: 28.22 samples/s ETA: 1 d  1 h  4 m	Data: 1.735 Tran: 0.007 F: 0.151 B: 0.295 O: 0.071 M: 0.007	Train-MLMAcc=0.626133,	MVRCAccuracy=0.672712,	MLMLossWVC=1.804991,	MVRCLoss=2.450926,	
Rank[  1]Epoch[6] Batch [3600]	Speed: 28.22 samples/s ETA: 1 d  1 h  4 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 1.802 M: 0.007	Train-MLMAcc=0.626133,	MVRCAccuracy=0.672712,	MLMLossWVC=1.804991,	MVRCLoss=2.450926,	
Rank[  0]Epoch[6] Batch [3700]	Speed: 28.15 samples/s ETA: 1 d  1 h  4 m	Data: 0.424 Tran: 0.007 F: 0.149 B: 0.291 O: 1.394 M: 0.007	Train-MLMAcc=0.626184,	MVRCAccuracy=0.672700,	MLMLossWVC=1.804489,	MVRCLoss=2.450947,	
Rank[  1]Epoch[6] Batch [3700]	Speed: 28.15 samples/s ETA: 1 d  1 h  4 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.301 O: 1.801 M: 0.006	Train-MLMAcc=0.626184,	MVRCAccuracy=0.672700,	MLMLossWVC=1.804489,	MVRCLoss=2.450947,	
Rank[  3]Epoch[6] Batch [3700]	Speed: 28.15 samples/s ETA: 1 d  1 h  4 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.288 O: 1.813 M: 0.008	Train-MLMAcc=0.626184,	MVRCAccuracy=0.672700,	MLMLossWVC=1.804489,	MVRCLoss=2.450947,	
Rank[  2]Epoch[6] Batch [3700]	Speed: 28.15 samples/s ETA: 1 d  1 h  4 m	Data: 1.457 Tran: 0.006 F: 0.150 B: 0.292 O: 0.360 M: 0.008	Train-MLMAcc=0.626184,	MVRCAccuracy=0.672700,	MLMLossWVC=1.804489,	MVRCLoss=2.450947,	
Rank[  0]Epoch[6] Batch [3800]	Speed: 28.11 samples/s ETA: 1 d  1 h  2 m	Data: 1.122 Tran: 0.007 F: 0.150 B: 0.292 O: 0.699 M: 0.006	Train-MLMAcc=0.626311,	MVRCAccuracy=0.672673,	MLMLossWVC=1.803884,	MVRCLoss=2.451077,	
Rank[  2]Epoch[6] Batch [3800]	Speed: 28.11 samples/s ETA: 1 d  1 h  2 m	Data: 0.653 Tran: 0.007 F: 0.151 B: 0.294 O: 1.165 M: 0.006	Train-MLMAcc=0.626311,	MVRCAccuracy=0.672673,	MLMLossWVC=1.803884,	MVRCLoss=2.451077,	
Rank[  1]Epoch[6] Batch [3800]	Speed: 28.11 samples/s ETA: 1 d  1 h  2 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.807 M: 0.006	Train-MLMAcc=0.626311,	MVRCAccuracy=0.672673,	MLMLossWVC=1.803884,	MVRCLoss=2.451077,	
Rank[  3]Epoch[6] Batch [3800]	Speed: 28.11 samples/s ETA: 1 d  1 h  2 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.293 O: 1.811 M: 0.006	Train-MLMAcc=0.626311,	MVRCAccuracy=0.672673,	MLMLossWVC=1.803884,	MVRCLoss=2.451077,	
Rank[  1]Epoch[6] Batch [3900]	Speed: 28.37 samples/s ETA: 1 d  0 h 45 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.300 O: 1.779 M: 0.010	Train-MLMAcc=0.626331,	MVRCAccuracy=0.672609,	MLMLossWVC=1.804213,	MVRCLoss=2.451147,	
Rank[  0]Epoch[6] Batch [3900]	Speed: 28.37 samples/s ETA: 1 d  0 h 45 m	Data: 1.142 Tran: 0.007 F: 0.151 B: 0.292 O: 0.654 M: 0.008	Train-MLMAcc=0.626331,	MVRCAccuracy=0.672609,	MLMLossWVC=1.804213,	MVRCLoss=2.451147,	
Rank[  3]Epoch[6] Batch [3900]	Speed: 28.37 samples/s ETA: 1 d  0 h 45 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.289 O: 1.793 M: 0.009	Train-MLMAcc=0.626331,	MVRCAccuracy=0.672609,	MLMLossWVC=1.804213,	MVRCLoss=2.451147,	
Rank[  2]Epoch[6] Batch [3900]	Speed: 28.37 samples/s ETA: 1 d  0 h 45 m	Data: 0.608 Tran: 0.007 F: 0.151 B: 0.294 O: 1.188 M: 0.007	Train-MLMAcc=0.626331,	MVRCAccuracy=0.672609,	MLMLossWVC=1.804213,	MVRCLoss=2.451147,	
Rank[  1]Epoch[6] Batch [4000]	Speed: 28.40 samples/s ETA: 1 d  0 h 39 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.782 M: 0.008	Train-MLMAcc=0.626227,	MVRCAccuracy=0.672617,	MLMLossWVC=1.804522,	MVRCLoss=2.451071,	
Rank[  2]Epoch[6] Batch [4000]	Speed: 28.40 samples/s ETA: 1 d  0 h 39 m	Data: 1.217 Tran: 0.006 F: 0.150 B: 0.294 O: 0.576 M: 0.009	Train-MLMAcc=0.626227,	MVRCAccuracy=0.672617,	MLMLossWVC=1.804522,	MVRCLoss=2.451071,	
Rank[  0]Epoch[6] Batch [4000]	Speed: 28.40 samples/s ETA: 1 d  0 h 39 m	Data: 0.538 Tran: 0.007 F: 0.151 B: 0.294 O: 1.256 M: 0.008	Train-MLMAcc=0.626227,	MVRCAccuracy=0.672617,	MLMLossWVC=1.804522,	MVRCLoss=2.451071,	
Rank[  3]Epoch[6] Batch [4000]	Speed: 28.40 samples/s ETA: 1 d  0 h 39 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.787 M: 0.010	Train-MLMAcc=0.626227,	MVRCAccuracy=0.672617,	MLMLossWVC=1.804522,	MVRCLoss=2.451071,	
Rank[  2]Epoch[6] Batch [4100]	Speed: 27.89 samples/s ETA: 1 d  1 h  3 m	Data: 1.787 Tran: 0.006 F: 0.151 B: 0.295 O: 0.048 M: 0.006	Train-MLMAcc=0.626280,	MVRCAccuracy=0.672674,	MLMLossWVC=1.804325,	MVRCLoss=2.450943,	
Rank[  1]Epoch[6] Batch [4100]	Speed: 27.89 samples/s ETA: 1 d  1 h  3 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 1.826 M: 0.006	Train-MLMAcc=0.626280,	MVRCAccuracy=0.672674,	MLMLossWVC=1.804325,	MVRCLoss=2.450943,	
Rank[  3]Epoch[6] Batch [4100]	Speed: 27.89 samples/s ETA: 1 d  1 h  3 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.833 M: 0.005	Train-MLMAcc=0.626280,	MVRCAccuracy=0.672674,	MLMLossWVC=1.804325,	MVRCLoss=2.450943,	
Rank[  0]Epoch[6] Batch [4100]	Speed: 27.89 samples/s ETA: 1 d  1 h  3 m	Data: 0.008 Tran: 0.006 F: 0.150 B: 0.294 O: 1.830 M: 0.006	Train-MLMAcc=0.626280,	MVRCAccuracy=0.672674,	MLMLossWVC=1.804325,	MVRCLoss=2.450943,	
Rank[  2]Epoch[6] Batch [4200]	Speed: 28.09 samples/s ETA: 1 d  0 h 48 m	Data: 1.757 Tran: 0.006 F: 0.150 B: 0.293 O: 0.067 M: 0.005	Train-MLMAcc=0.626329,	MVRCAccuracy=0.672676,	MLMLossWVC=1.803814,	MVRCLoss=2.451019,	
Rank[  1]Epoch[6] Batch [4200]	Speed: 28.09 samples/s ETA: 1 d  0 h 48 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.809 M: 0.006	Train-MLMAcc=0.626329,	MVRCAccuracy=0.672676,	MLMLossWVC=1.803814,	MVRCLoss=2.451019,	
Rank[  0]Epoch[6] Batch [4200]	Speed: 28.09 samples/s ETA: 1 d  0 h 48 m	Data: 0.036 Tran: 0.007 F: 0.150 B: 0.293 O: 1.788 M: 0.005	Train-MLMAcc=0.626329,	MVRCAccuracy=0.672676,	MLMLossWVC=1.803814,	MVRCLoss=2.451019,	
Rank[  3]Epoch[6] Batch [4200]	Speed: 28.09 samples/s ETA: 1 d  0 h 48 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.289 O: 1.820 M: 0.006	Train-MLMAcc=0.626329,	MVRCAccuracy=0.672676,	MLMLossWVC=1.803814,	MVRCLoss=2.451019,	
Rank[  0]Epoch[6] Batch [4300]	Speed: 27.81 samples/s ETA: 1 d  0 h 59 m	Data: 0.476 Tran: 0.007 F: 0.150 B: 0.292 O: 1.370 M: 0.006	Train-MLMAcc=0.626311,	MVRCAccuracy=0.672713,	MLMLossWVC=1.804042,	MVRCLoss=2.451036,	
Rank[  1]Epoch[6] Batch [4300]	Speed: 27.81 samples/s ETA: 1 d  0 h 59 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.832 M: 0.006	Train-MLMAcc=0.626311,	MVRCAccuracy=0.672713,	MLMLossWVC=1.804042,	MVRCLoss=2.451036,	
Rank[  2]Epoch[6] Batch [4300]	Speed: 27.81 samples/s ETA: 1 d  0 h 59 m	Data: 1.324 Tran: 0.007 F: 0.150 B: 0.293 O: 0.520 M: 0.006	Train-MLMAcc=0.626311,	MVRCAccuracy=0.672713,	MLMLossWVC=1.804042,	MVRCLoss=2.451036,	
Rank[  3]Epoch[6] Batch [4300]	Speed: 27.81 samples/s ETA: 1 d  0 h 59 m	Data: 0.028 Tran: 0.007 F: 0.149 B: 0.290 O: 1.821 M: 0.006	Train-MLMAcc=0.626311,	MVRCAccuracy=0.672713,	MLMLossWVC=1.804042,	MVRCLoss=2.451036,	
Rank[  1]Epoch[6] Batch [4400]	Speed: 28.23 samples/s ETA: 1 d  0 h 33 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.795 M: 0.008	Train-MLMAcc=0.626337,	MVRCAccuracy=0.672748,	MLMLossWVC=1.803971,	MVRCLoss=2.450970,	
Rank[  2]Epoch[6] Batch [4400]	Speed: 28.23 samples/s ETA: 1 d  0 h 33 m	Data: 0.917 Tran: 0.006 F: 0.151 B: 0.296 O: 0.886 M: 0.009	Train-MLMAcc=0.626337,	MVRCAccuracy=0.672748,	MLMLossWVC=1.803971,	MVRCLoss=2.450970,	
Rank[  3]Epoch[6] Batch [4400]	Speed: 28.23 samples/s ETA: 1 d  0 h 33 m	Data: 0.239 Tran: 0.007 F: 0.150 B: 0.292 O: 1.571 M: 0.008	Train-MLMAcc=0.626337,	MVRCAccuracy=0.672748,	MLMLossWVC=1.803971,	MVRCLoss=2.450970,	
Rank[  0]Epoch[6] Batch [4400]	Speed: 28.23 samples/s ETA: 1 d  0 h 33 m	Data: 0.672 Tran: 0.007 F: 0.150 B: 0.291 O: 1.139 M: 0.008	Train-MLMAcc=0.626337,	MVRCAccuracy=0.672748,	MLMLossWVC=1.803971,	MVRCLoss=2.450970,	
Rank[  0]Epoch[6] Batch [4500]	Speed: 27.29 samples/s ETA: 1 d  1 h 20 m	Data: 1.191 Tran: 0.007 F: 0.153 B: 0.297 O: 0.689 M: 0.006	Train-MLMAcc=0.626386,	MVRCAccuracy=0.672742,	MLMLossWVC=1.803525,	MVRCLoss=2.450889,	
Rank[  2]Epoch[6] Batch [4500]	Speed: 27.29 samples/s ETA: 1 d  1 h 20 m	Data: 0.601 Tran: 0.009 F: 0.183 B: 0.303 O: 1.240 M: 0.008	Train-MLMAcc=0.626386,	MVRCAccuracy=0.672742,	MLMLossWVC=1.803525,	MVRCLoss=2.450889,	
Rank[  3]Epoch[6] Batch [4500]	Speed: 27.29 samples/s ETA: 1 d  1 h 20 m	Data: 0.042 Tran: 0.007 F: 0.151 B: 0.294 O: 1.843 M: 0.006	Train-MLMAcc=0.626386,	MVRCAccuracy=0.672742,	MLMLossWVC=1.803525,	MVRCLoss=2.450889,	
Rank[  1]Epoch[6] Batch [4500]	Speed: 27.29 samples/s ETA: 1 d  1 h 20 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.301 O: 1.869 M: 0.007	Train-MLMAcc=0.626386,	MVRCAccuracy=0.672742,	MLMLossWVC=1.803525,	MVRCLoss=2.450889,	
Rank[  0]Epoch[6] Batch [4600]	Speed: 27.80 samples/s ETA: 1 d  0 h 49 m	Data: 0.103 Tran: 0.007 F: 0.150 B: 0.292 O: 1.743 M: 0.006	Train-MLMAcc=0.626438,	MVRCAccuracy=0.672773,	MLMLossWVC=1.802872,	MVRCLoss=2.450688,	
Rank[  1]Epoch[6] Batch [4600]	Speed: 27.80 samples/s ETA: 1 d  0 h 49 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.835 M: 0.006	Train-MLMAcc=0.626438,	MVRCAccuracy=0.672773,	MLMLossWVC=1.802872,	MVRCLoss=2.450688,	
Rank[  2]Epoch[6] Batch [4600]	Speed: 27.80 samples/s ETA: 1 d  0 h 49 m	Data: 1.696 Tran: 0.007 F: 0.151 B: 0.293 O: 0.148 M: 0.007	Train-MLMAcc=0.626438,	MVRCAccuracy=0.672773,	MLMLossWVC=1.802872,	MVRCLoss=2.450688,	
Rank[  3]Epoch[6] Batch [4600]	Speed: 27.80 samples/s ETA: 1 d  0 h 49 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.291 O: 1.840 M: 0.006	Train-MLMAcc=0.626438,	MVRCAccuracy=0.672773,	MLMLossWVC=1.802872,	MVRCLoss=2.450688,	
Rank[  0]Epoch[6] Batch [4700]	Speed: 28.19 samples/s ETA: 1 d  0 h 24 m	Data: 0.053 Tran: 0.007 F: 0.150 B: 0.292 O: 1.761 M: 0.007	Train-MLMAcc=0.626413,	MVRCAccuracy=0.672839,	MLMLossWVC=1.802988,	MVRCLoss=2.450550,	
Rank[  1]Epoch[6] Batch [4700]	Speed: 28.19 samples/s ETA: 1 d  0 h 24 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.299 O: 1.799 M: 0.006	Train-MLMAcc=0.626413,	MVRCAccuracy=0.672839,	MLMLossWVC=1.802988,	MVRCLoss=2.450550,	
Rank[  2]Epoch[6] Batch [4700]	Speed: 28.19 samples/s ETA: 1 d  0 h 24 m	Data: 1.713 Tran: 0.007 F: 0.150 B: 0.293 O: 0.099 M: 0.007	Train-MLMAcc=0.626413,	MVRCAccuracy=0.672839,	MLMLossWVC=1.802988,	MVRCLoss=2.450550,	
Rank[  3]Epoch[6] Batch [4700]	Speed: 28.19 samples/s ETA: 1 d  0 h 24 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.289 O: 1.809 M: 0.008	Train-MLMAcc=0.626413,	MVRCAccuracy=0.672839,	MLMLossWVC=1.802988,	MVRCLoss=2.450550,	
Rank[  1]Epoch[6] Batch [4800]	Speed: 28.16 samples/s ETA: 1 d  0 h 22 m	Data: 0.274 Tran: 0.007 F: 0.151 B: 0.299 O: 1.534 M: 0.007	Train-MLMAcc=0.626480,	MVRCAccuracy=0.672901,	MLMLossWVC=1.802664,	MVRCLoss=2.450511,	
Rank[  2]Epoch[6] Batch [4800]	Speed: 28.16 samples/s ETA: 1 d  0 h 22 m	Data: 1.435 Tran: 0.006 F: 0.150 B: 0.294 O: 0.378 M: 0.008	Train-MLMAcc=0.626480,	MVRCAccuracy=0.672901,	MLMLossWVC=1.802664,	MVRCLoss=2.450511,	
Rank[  3]Epoch[6] Batch [4800]	Speed: 28.16 samples/s ETA: 1 d  0 h 22 m	Data: 0.263 Tran: 0.007 F: 0.150 B: 0.290 O: 1.555 M: 0.008	Train-MLMAcc=0.626480,	MVRCAccuracy=0.672901,	MLMLossWVC=1.802664,	MVRCLoss=2.450511,	
Rank[  0]Epoch[6] Batch [4800]	Speed: 28.16 samples/s ETA: 1 d  0 h 22 m	Data: 0.073 Tran: 0.006 F: 0.150 B: 0.292 O: 1.743 M: 0.008	Train-MLMAcc=0.626480,	MVRCAccuracy=0.672901,	MLMLossWVC=1.802664,	MVRCLoss=2.450511,	
Rank[  1]Epoch[6] Batch [4900]	Speed: 26.88 samples/s ETA: 1 d  1 h 28 m	Data: 0.667 Tran: 0.007 F: 0.150 B: 0.298 O: 1.251 M: 0.007	Train-MLMAcc=0.626498,	MVRCAccuracy=0.672924,	MLMLossWVC=1.802398,	MVRCLoss=2.450398,	
Rank[  0]Epoch[6] Batch [4900]	Speed: 26.88 samples/s ETA: 1 d  1 h 28 m	Data: 0.754 Tran: 0.006 F: 0.150 B: 0.292 O: 1.170 M: 0.007	Train-MLMAcc=0.626498,	MVRCAccuracy=0.672924,	MLMLossWVC=1.802398,	MVRCLoss=2.450398,	
Rank[  2]Epoch[6] Batch [4900]	Speed: 26.88 samples/s ETA: 1 d  1 h 28 m	Data: 0.618 Tran: 0.007 F: 0.150 B: 0.294 O: 1.305 M: 0.006	Train-MLMAcc=0.626498,	MVRCAccuracy=0.672924,	MLMLossWVC=1.802398,	MVRCLoss=2.450398,	
Rank[  3]Epoch[6] Batch [4900]	Speed: 26.88 samples/s ETA: 1 d  1 h 28 m	Data: 1.134 Tran: 0.007 F: 0.151 B: 0.292 O: 0.790 M: 0.007	Train-MLMAcc=0.626498,	MVRCAccuracy=0.672924,	MLMLossWVC=1.802398,	MVRCLoss=2.450398,	
Rank[  1]Epoch[6] Batch [5000]	Speed: 27.64 samples/s ETA: 1 d  0 h 42 m	Data: 0.293 Tran: 0.007 F: 0.150 B: 0.298 O: 1.558 M: 0.009	Train-MLMAcc=0.626677,	MVRCAccuracy=0.672917,	MLMLossWVC=1.801576,	MVRCLoss=2.450324,	
Rank[  2]Epoch[6] Batch [5000]	Speed: 27.64 samples/s ETA: 1 d  0 h 42 m	Data: 1.251 Tran: 0.006 F: 0.150 B: 0.293 O: 0.608 M: 0.007	Train-MLMAcc=0.626677,	MVRCAccuracy=0.672917,	MLMLossWVC=1.801576,	MVRCLoss=2.450324,	
Rank[  3]Epoch[6] Batch [5000]	Speed: 27.64 samples/s ETA: 1 d  0 h 42 m	Data: 0.384 Tran: 0.007 F: 0.150 B: 0.292 O: 1.474 M: 0.008	Train-MLMAcc=0.626677,	MVRCAccuracy=0.672917,	MLMLossWVC=1.801576,	MVRCLoss=2.450324,	
Rank[  0]Epoch[6] Batch [5000]	Speed: 27.64 samples/s ETA: 1 d  0 h 42 m	Data: 0.461 Tran: 0.006 F: 0.150 B: 0.292 O: 1.399 M: 0.007	Train-MLMAcc=0.626677,	MVRCAccuracy=0.672917,	MLMLossWVC=1.801576,	MVRCLoss=2.450324,	
Rank[  0]Epoch[6] Batch [5100]	Speed: 27.61 samples/s ETA: 1 d  0 h 40 m	Data: 0.025 Tran: 0.007 F: 0.151 B: 0.293 O: 1.833 M: 0.008	Train-MLMAcc=0.626651,	MVRCAccuracy=0.672923,	MLMLossWVC=1.801635,	MVRCLoss=2.450352,	
Rank[  2]Epoch[6] Batch [5100]	Speed: 27.61 samples/s ETA: 1 d  0 h 40 m	Data: 1.377 Tran: 0.006 F: 0.149 B: 0.292 O: 0.483 M: 0.010	Train-MLMAcc=0.626651,	MVRCAccuracy=0.672923,	MLMLossWVC=1.801635,	MVRCLoss=2.450352,	
Rank[  3]Epoch[6] Batch [5100]	Speed: 27.61 samples/s ETA: 1 d  0 h 40 m	Data: 0.435 Tran: 0.007 F: 0.150 B: 0.291 O: 1.426 M: 0.008	Train-MLMAcc=0.626651,	MVRCAccuracy=0.672923,	MLMLossWVC=1.801635,	MVRCLoss=2.450352,	
Rank[  1]Epoch[6] Batch [5100]	Speed: 27.61 samples/s ETA: 1 d  0 h 40 m	Data: 0.061 Tran: 0.007 F: 0.149 B: 0.297 O: 1.794 M: 0.009	Train-MLMAcc=0.626651,	MVRCAccuracy=0.672923,	MLMLossWVC=1.801635,	MVRCLoss=2.450352,	
Rank[  0]Epoch[6] Batch [5200]	Speed: 27.45 samples/s ETA: 1 d  0 h 44 m	Data: 0.071 Tran: 0.007 F: 0.149 B: 0.291 O: 1.804 M: 0.009	Train-MLMAcc=0.626655,	MVRCAccuracy=0.672958,	MLMLossWVC=1.801320,	MVRCLoss=2.450374,	
Rank[  1]Epoch[6] Batch [5200]	Speed: 27.45 samples/s ETA: 1 d  0 h 44 m	Data: 0.305 Tran: 0.007 F: 0.150 B: 0.299 O: 1.562 M: 0.008	Train-MLMAcc=0.626655,	MVRCAccuracy=0.672958,	MLMLossWVC=1.801320,	MVRCLoss=2.450374,	
Rank[  2]Epoch[6] Batch [5200]	Speed: 27.45 samples/s ETA: 1 d  0 h 44 m	Data: 1.553 Tran: 0.006 F: 0.151 B: 0.295 O: 0.317 M: 0.008	Train-MLMAcc=0.626655,	MVRCAccuracy=0.672958,	MLMLossWVC=1.801320,	MVRCLoss=2.450374,	
Rank[  3]Epoch[6] Batch [5200]	Speed: 27.45 samples/s ETA: 1 d  0 h 44 m	Data: 0.028 Tran: 0.007 F: 0.150 B: 0.291 O: 1.847 M: 0.008	Train-MLMAcc=0.626655,	MVRCAccuracy=0.672958,	MLMLossWVC=1.801320,	MVRCLoss=2.450374,	
Rank[  0]Epoch[6] Batch [5300]	Speed: 28.03 samples/s ETA: 1 d  0 h  9 m	Data: 0.760 Tran: 0.007 F: 0.150 B: 0.293 O: 1.065 M: 0.008	Train-MLMAcc=0.626619,	MVRCAccuracy=0.672991,	MLMLossWVC=1.801275,	MVRCLoss=2.450323,	
Rank[  3]Epoch[6] Batch [5300]	Speed: 28.03 samples/s ETA: 1 d  0 h  9 m	Data: 0.121 Tran: 0.007 F: 0.149 B: 0.290 O: 1.706 M: 0.009	Train-MLMAcc=0.626619,	MVRCAccuracy=0.672991,	MLMLossWVC=1.801275,	MVRCLoss=2.450323,	
Rank[  2]Epoch[6] Batch [5300]	Speed: 28.03 samples/s ETA: 1 d  0 h  9 m	Data: 0.913 Tran: 0.006 F: 0.150 B: 0.294 O: 0.911 M: 0.009	Train-MLMAcc=0.626619,	MVRCAccuracy=0.672991,	MLMLossWVC=1.801275,	MVRCLoss=2.450323,	
Rank[  1]Epoch[6] Batch [5300]	Speed: 28.03 samples/s ETA: 1 d  0 h  9 m	Data: 0.289 Tran: 0.007 F: 0.151 B: 0.300 O: 1.527 M: 0.008	Train-MLMAcc=0.626619,	MVRCAccuracy=0.672991,	MLMLossWVC=1.801275,	MVRCLoss=2.450323,	
Rank[  3]Epoch[6] Batch [5400]	Speed: 27.61 samples/s ETA: 1 d  0 h 28 m	Data: 0.301 Tran: 0.007 F: 0.149 B: 0.290 O: 1.561 M: 0.010	Train-MLMAcc=0.626670,	MVRCAccuracy=0.673038,	MLMLossWVC=1.801165,	MVRCLoss=2.450378,	
Rank[  0]Epoch[6] Batch [5400]	Speed: 27.61 samples/s ETA: 1 d  0 h 28 m	Data: 1.041 Tran: 0.007 F: 0.150 B: 0.291 O: 0.819 M: 0.010	Train-MLMAcc=0.626670,	MVRCAccuracy=0.673038,	MLMLossWVC=1.801165,	MVRCLoss=2.450378,	
Rank[  2]Epoch[6] Batch [5400]	Speed: 27.61 samples/s ETA: 1 d  0 h 28 m	Data: 0.818 Tran: 0.006 F: 0.150 B: 0.295 O: 1.038 M: 0.010	Train-MLMAcc=0.626670,	MVRCAccuracy=0.673038,	MLMLossWVC=1.801165,	MVRCLoss=2.450378,	
Rank[  1]Epoch[6] Batch [5400]	Speed: 27.61 samples/s ETA: 1 d  0 h 28 m	Data: 0.537 Tran: 0.007 F: 0.150 B: 0.298 O: 1.319 M: 0.007	Train-MLMAcc=0.626670,	MVRCAccuracy=0.673038,	MLMLossWVC=1.801165,	MVRCLoss=2.450378,	
Rank[  0]Epoch[6] Batch [5500]	Speed: 25.02 samples/s ETA: 1 d  2 h 55 m	Data: 0.773 Tran: 0.008 F: 0.189 B: 0.353 O: 1.218 M: 0.014	Train-MLMAcc=0.626662,	MVRCAccuracy=0.673043,	MLMLossWVC=1.801033,	MVRCLoss=2.450424,	
Rank[  1]Epoch[6] Batch [5500]	Speed: 25.02 samples/s ETA: 1 d  2 h 55 m	Data: 0.269 Tran: 0.008 F: 0.197 B: 0.344 O: 1.724 M: 0.014	Train-MLMAcc=0.626662,	MVRCAccuracy=0.673043,	MLMLossWVC=1.801033,	MVRCLoss=2.450424,	
Rank[  2]Epoch[6] Batch [5500]	Speed: 25.02 samples/s ETA: 1 d  2 h 55 m	Data: 0.755 Tran: 0.008 F: 0.185 B: 0.364 O: 1.229 M: 0.014	Train-MLMAcc=0.626662,	MVRCAccuracy=0.673043,	MLMLossWVC=1.801033,	MVRCLoss=2.450424,	
Rank[  3]Epoch[6] Batch [5500]	Speed: 25.02 samples/s ETA: 1 d  2 h 55 m	Data: 0.910 Tran: 0.008 F: 0.187 B: 0.356 O: 1.079 M: 0.016	Train-MLMAcc=0.626662,	MVRCAccuracy=0.673043,	MLMLossWVC=1.801033,	MVRCLoss=2.450424,	
Rank[  2]Epoch[6] Batch [5600]	Speed: 27.86 samples/s ETA: 1 d  0 h  7 m	Data: 0.759 Tran: 0.007 F: 0.150 B: 0.293 O: 1.080 M: 0.008	Train-MLMAcc=0.626713,	MVRCAccuracy=0.673015,	MLMLossWVC=1.800781,	MVRCLoss=2.450373,	
Rank[  0]Epoch[6] Batch [5600]	Speed: 27.86 samples/s ETA: 1 d  0 h  7 m	Data: 0.452 Tran: 0.007 F: 0.151 B: 0.293 O: 1.388 M: 0.007	Train-MLMAcc=0.626713,	MVRCAccuracy=0.673015,	MLMLossWVC=1.800781,	MVRCLoss=2.450373,	
Rank[  1]Epoch[6] Batch [5600]	Speed: 27.86 samples/s ETA: 1 d  0 h  7 m	Data: 0.171 Tran: 0.007 F: 0.150 B: 0.299 O: 1.663 M: 0.008	Train-MLMAcc=0.626713,	MVRCAccuracy=0.673015,	MLMLossWVC=1.800781,	MVRCLoss=2.450373,	
Rank[  3]Epoch[6] Batch [5600]	Speed: 27.86 samples/s ETA: 1 d  0 h  7 m	Data: 1.122 Tran: 0.007 F: 0.150 B: 0.290 O: 0.721 M: 0.007	Train-MLMAcc=0.626713,	MVRCAccuracy=0.673015,	MLMLossWVC=1.800781,	MVRCLoss=2.450373,	
Rank[  1]Epoch[6] Batch [5700]	Speed: 28.12 samples/s ETA: 0 d 23 h 50 m	Data: 0.543 Tran: 0.007 F: 0.149 B: 0.297 O: 1.272 M: 0.008	Train-MLMAcc=0.626771,	MVRCAccuracy=0.672997,	MLMLossWVC=1.800348,	MVRCLoss=2.450381,	
Rank[  0]Epoch[6] Batch [5700]	Speed: 28.12 samples/s ETA: 0 d 23 h 50 m	Data: 0.740 Tran: 0.007 F: 0.150 B: 0.293 O: 1.078 M: 0.007	Train-MLMAcc=0.626771,	MVRCAccuracy=0.672997,	MLMLossWVC=1.800348,	MVRCLoss=2.450381,	
Rank[  2]Epoch[6] Batch [5700]	Speed: 28.12 samples/s ETA: 0 d 23 h 50 m	Data: 0.430 Tran: 0.007 F: 0.150 B: 0.293 O: 1.389 M: 0.006	Train-MLMAcc=0.626771,	MVRCAccuracy=0.672997,	MLMLossWVC=1.800348,	MVRCLoss=2.450381,	
Rank[  3]Epoch[6] Batch [5700]	Speed: 28.12 samples/s ETA: 0 d 23 h 50 m	Data: 1.354 Tran: 0.006 F: 0.151 B: 0.291 O: 0.467 M: 0.006	Train-MLMAcc=0.626771,	MVRCAccuracy=0.672997,	MLMLossWVC=1.800348,	MVRCLoss=2.450381,	
Rank[  0]Epoch[6] Batch [5800]	Speed: 28.34 samples/s ETA: 0 d 23 h 35 m	Data: 0.025 Tran: 0.007 F: 0.150 B: 0.293 O: 1.776 M: 0.007	Train-MLMAcc=0.626762,	MVRCAccuracy=0.672979,	MLMLossWVC=1.800202,	MVRCLoss=2.450327,	
Rank[  3]Epoch[6] Batch [5800]	Speed: 28.34 samples/s ETA: 0 d 23 h 35 m	Data: 0.746 Tran: 0.007 F: 0.150 B: 0.291 O: 1.057 M: 0.007	Train-MLMAcc=0.626762,	MVRCAccuracy=0.672979,	MLMLossWVC=1.800202,	MVRCLoss=2.450327,	
Rank[  1]Epoch[6] Batch [5800]	Speed: 28.34 samples/s ETA: 0 d 23 h 35 m	Data: 0.044 Tran: 0.007 F: 0.150 B: 0.298 O: 1.752 M: 0.007	Train-MLMAcc=0.626762,	MVRCAccuracy=0.672979,	MLMLossWVC=1.800202,	MVRCLoss=2.450327,	
Rank[  2]Epoch[6] Batch [5800]	Speed: 28.34 samples/s ETA: 0 d 23 h 35 m	Data: 1.012 Tran: 0.006 F: 0.151 B: 0.295 O: 0.788 M: 0.006	Train-MLMAcc=0.626762,	MVRCAccuracy=0.672979,	MLMLossWVC=1.800202,	MVRCLoss=2.450327,	
Rank[  0]Epoch[6] Batch [5900]	Speed: 27.95 samples/s ETA: 0 d 23 h 51 m	Data: 0.009 Tran: 0.007 F: 0.150 B: 0.293 O: 1.821 M: 0.008	Train-MLMAcc=0.626743,	MVRCAccuracy=0.672997,	MLMLossWVC=1.800355,	MVRCLoss=2.450261,	
Rank[  1]Epoch[6] Batch [5900]	Speed: 27.95 samples/s ETA: 0 d 23 h 51 m	Data: 0.152 Tran: 0.007 F: 0.150 B: 0.297 O: 1.674 M: 0.009	Train-MLMAcc=0.626743,	MVRCAccuracy=0.672997,	MLMLossWVC=1.800355,	MVRCLoss=2.450261,	
Rank[  3]Epoch[6] Batch [5900]	Speed: 27.95 samples/s ETA: 0 d 23 h 51 m	Data: 1.133 Tran: 0.007 F: 0.150 B: 0.291 O: 0.700 M: 0.008	Train-MLMAcc=0.626743,	MVRCAccuracy=0.672997,	MLMLossWVC=1.800355,	MVRCLoss=2.450261,	
Rank[  2]Epoch[6] Batch [5900]	Speed: 27.95 samples/s ETA: 0 d 23 h 51 m	Data: 0.658 Tran: 0.007 F: 0.150 B: 0.293 O: 1.172 M: 0.010	Train-MLMAcc=0.626743,	MVRCAccuracy=0.672997,	MLMLossWVC=1.800355,	MVRCLoss=2.450261,	
Rank[  2]Epoch[6] Batch [6000]	Speed: 27.71 samples/s ETA: 0 d 23 h 59 m	Data: 0.221 Tran: 0.007 F: 0.168 B: 0.304 O: 1.602 M: 0.008	Train-MLMAcc=0.626672,	MVRCAccuracy=0.673034,	MLMLossWVC=1.800562,	MVRCLoss=2.450157,	
Rank[  1]Epoch[6] Batch [6000]	Speed: 27.71 samples/s ETA: 0 d 23 h 59 m	Data: 0.667 Tran: 0.007 F: 0.169 B: 0.309 O: 1.149 M: 0.008	Train-MLMAcc=0.626672,	MVRCAccuracy=0.673034,	MLMLossWVC=1.800562,	MVRCLoss=2.450157,	
Rank[  0]Epoch[6] Batch [6000]	Speed: 27.71 samples/s ETA: 0 d 23 h 59 m	Data: 0.220 Tran: 0.007 F: 0.167 B: 0.302 O: 1.604 M: 0.009	Train-MLMAcc=0.626672,	MVRCAccuracy=0.673034,	MLMLossWVC=1.800562,	MVRCLoss=2.450157,	
Rank[  3]Epoch[6] Batch [6000]	Speed: 27.71 samples/s ETA: 0 d 23 h 59 m	Data: 1.458 Tran: 0.007 F: 0.153 B: 0.290 O: 0.392 M: 0.009	Train-MLMAcc=0.626672,	MVRCAccuracy=0.673034,	MLMLossWVC=1.800562,	MVRCLoss=2.450157,	
Rank[  1]Epoch[6] Batch [6100]	Speed: 27.72 samples/s ETA: 0 d 23 h 55 m	Data: 1.362 Tran: 0.008 F: 0.151 B: 0.298 O: 0.482 M: 0.007	Train-MLMAcc=0.626741,	MVRCAccuracy=0.673055,	MLMLossWVC=1.800476,	MVRCLoss=2.450095,	
Rank[  0]Epoch[6] Batch [6100]	Speed: 27.72 samples/s ETA: 0 d 23 h 55 m	Data: 0.409 Tran: 0.007 F: 0.150 B: 0.293 O: 1.441 M: 0.008	Train-MLMAcc=0.626741,	MVRCAccuracy=0.673055,	MLMLossWVC=1.800476,	MVRCLoss=2.450095,	
Rank[  3]Epoch[6] Batch [6100]	Speed: 27.72 samples/s ETA: 0 d 23 h 55 m	Data: 0.249 Tran: 0.007 F: 0.150 B: 0.291 O: 1.604 M: 0.006	Train-MLMAcc=0.626741,	MVRCAccuracy=0.673055,	MLMLossWVC=1.800476,	MVRCLoss=2.450095,	
Rank[  2]Epoch[6] Batch [6100]	Speed: 27.72 samples/s ETA: 0 d 23 h 55 m	Data: 0.411 Tran: 0.006 F: 0.150 B: 0.293 O: 1.440 M: 0.008	Train-MLMAcc=0.626741,	MVRCAccuracy=0.673055,	MLMLossWVC=1.800476,	MVRCLoss=2.450095,	
Rank[  0]Epoch[6] Batch [6200]	Speed: 28.37 samples/s ETA: 0 d 23 h 18 m	Data: 0.696 Tran: 0.007 F: 0.149 B: 0.291 O: 1.103 M: 0.009	Train-MLMAcc=0.626757,	MVRCAccuracy=0.673081,	MLMLossWVC=1.799982,	MVRCLoss=2.450007,	
Rank[  1]Epoch[6] Batch [6200]	Speed: 28.37 samples/s ETA: 0 d 23 h 18 m	Data: 0.936 Tran: 0.007 F: 0.150 B: 0.298 O: 0.855 M: 0.008	Train-MLMAcc=0.626757,	MVRCAccuracy=0.673081,	MLMLossWVC=1.799982,	MVRCLoss=2.450007,	
Rank[  2]Epoch[6] Batch [6200]	Speed: 28.37 samples/s ETA: 0 d 23 h 18 m	Data: 0.794 Tran: 0.006 F: 0.150 B: 0.294 O: 1.003 M: 0.009	Train-MLMAcc=0.626757,	MVRCAccuracy=0.673081,	MLMLossWVC=1.799982,	MVRCLoss=2.450007,	
Rank[  3]Epoch[6] Batch [6200]	Speed: 28.37 samples/s ETA: 0 d 23 h 18 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.289 O: 1.795 M: 0.008	Train-MLMAcc=0.626757,	MVRCAccuracy=0.673081,	MLMLossWVC=1.799982,	MVRCLoss=2.450007,	
Rank[  0]Epoch[6] Batch [6300]	Speed: 27.84 samples/s ETA: 0 d 23 h 41 m	Data: 1.077 Tran: 0.007 F: 0.150 B: 0.292 O: 0.767 M: 0.006	Train-MLMAcc=0.626806,	MVRCAccuracy=0.673107,	MLMLossWVC=1.799765,	MVRCLoss=2.449990,	
Rank[  1]Epoch[6] Batch [6300]	Speed: 27.84 samples/s ETA: 0 d 23 h 41 m	Data: 0.217 Tran: 0.007 F: 0.149 B: 0.297 O: 1.621 M: 0.007	Train-MLMAcc=0.626806,	MVRCAccuracy=0.673107,	MLMLossWVC=1.799765,	MVRCLoss=2.449990,	
Rank[  3]Epoch[6] Batch [6300]	Speed: 27.84 samples/s ETA: 0 d 23 h 41 m	Data: 0.305 Tran: 0.007 F: 0.149 B: 0.291 O: 1.541 M: 0.005	Train-MLMAcc=0.626806,	MVRCAccuracy=0.673107,	MLMLossWVC=1.799765,	MVRCLoss=2.449990,	
Rank[  2]Epoch[6] Batch [6300]	Speed: 27.84 samples/s ETA: 0 d 23 h 41 m	Data: 1.019 Tran: 0.006 F: 0.150 B: 0.294 O: 0.822 M: 0.007	Train-MLMAcc=0.626806,	MVRCAccuracy=0.673107,	MLMLossWVC=1.799765,	MVRCLoss=2.449990,	
Rank[  0]Epoch[6] Batch [6400]	Speed: 27.82 samples/s ETA: 0 d 23 h 38 m	Data: 1.200 Tran: 0.007 F: 0.151 B: 0.292 O: 0.642 M: 0.008	Train-MLMAcc=0.626845,	MVRCAccuracy=0.673128,	MLMLossWVC=1.799407,	MVRCLoss=2.449946,	
Rank[  3]Epoch[6] Batch [6400]	Speed: 27.82 samples/s ETA: 0 d 23 h 38 m	Data: 0.010 Tran: 0.008 F: 0.150 B: 0.291 O: 1.835 M: 0.006	Train-MLMAcc=0.626845,	MVRCAccuracy=0.673128,	MLMLossWVC=1.799407,	MVRCLoss=2.449946,	
Rank[  2]Epoch[6] Batch [6400]	Speed: 27.82 samples/s ETA: 0 d 23 h 38 m	Data: 0.939 Tran: 0.007 F: 0.150 B: 0.294 O: 0.900 M: 0.009	Train-MLMAcc=0.626845,	MVRCAccuracy=0.673128,	MLMLossWVC=1.799407,	MVRCLoss=2.449946,	
Rank[  1]Epoch[6] Batch [6400]	Speed: 27.82 samples/s ETA: 0 d 23 h 38 m	Data: 0.022 Tran: 0.008 F: 0.149 B: 0.298 O: 1.814 M: 0.009	Train-MLMAcc=0.626845,	MVRCAccuracy=0.673128,	MLMLossWVC=1.799407,	MVRCLoss=2.449946,	
Rank[  0]Epoch[6] Batch [6500]	Speed: 28.05 samples/s ETA: 0 d 23 h 23 m	Data: 0.888 Tran: 0.007 F: 0.150 B: 0.290 O: 0.939 M: 0.007	Train-MLMAcc=0.626825,	MVRCAccuracy=0.673144,	MLMLossWVC=1.799428,	MVRCLoss=2.449879,	
Rank[  2]Epoch[6] Batch [6500]	Speed: 28.05 samples/s ETA: 0 d 23 h 23 m	Data: 1.171 Tran: 0.008 F: 0.150 B: 0.294 O: 0.651 M: 0.007	Train-MLMAcc=0.626825,	MVRCAccuracy=0.673144,	MLMLossWVC=1.799428,	MVRCLoss=2.449879,	
Rank[  3]Epoch[6] Batch [6500]	Speed: 28.05 samples/s ETA: 0 d 23 h 23 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.290 O: 1.819 M: 0.007	Train-MLMAcc=0.626825,	MVRCAccuracy=0.673144,	MLMLossWVC=1.799428,	MVRCLoss=2.449879,	
Rank[  1]Epoch[6] Batch [6500]	Speed: 28.05 samples/s ETA: 0 d 23 h 23 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.299 O: 1.810 M: 0.007	Train-MLMAcc=0.626825,	MVRCAccuracy=0.673144,	MLMLossWVC=1.799428,	MVRCLoss=2.449879,	
Rank[  0]Epoch[6] Batch [6600]	Speed: 27.82 samples/s ETA: 0 d 23 h 31 m	Data: 0.912 Tran: 0.007 F: 0.150 B: 0.291 O: 0.935 M: 0.006	Train-MLMAcc=0.626846,	MVRCAccuracy=0.673201,	MLMLossWVC=1.799413,	MVRCLoss=2.449657,	
Rank[  2]Epoch[6] Batch [6600]	Speed: 27.82 samples/s ETA: 0 d 23 h 31 m	Data: 0.969 Tran: 0.008 F: 0.151 B: 0.295 O: 0.871 M: 0.005	Train-MLMAcc=0.626846,	MVRCAccuracy=0.673201,	MLMLossWVC=1.799413,	MVRCLoss=2.449657,	
Rank[  3]Epoch[6] Batch [6600]	Speed: 27.82 samples/s ETA: 0 d 23 h 31 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.290 O: 1.840 M: 0.005	Train-MLMAcc=0.626846,	MVRCAccuracy=0.673201,	MLMLossWVC=1.799413,	MVRCLoss=2.449657,	
Rank[  1]Epoch[6] Batch [6600]	Speed: 27.82 samples/s ETA: 0 d 23 h 31 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.296 O: 1.833 M: 0.006	Train-MLMAcc=0.626846,	MVRCAccuracy=0.673201,	MLMLossWVC=1.799413,	MVRCLoss=2.449657,	
Rank[  1]Epoch[6] Batch [6700]	Speed: 27.84 samples/s ETA: 0 d 23 h 26 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.829 M: 0.006	Train-MLMAcc=0.626896,	MVRCAccuracy=0.673238,	MLMLossWVC=1.798970,	MVRCLoss=2.449638,	
Rank[  3]Epoch[6] Batch [6700]	Speed: 27.84 samples/s ETA: 0 d 23 h 26 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.290 O: 1.838 M: 0.008	Train-MLMAcc=0.626896,	MVRCAccuracy=0.673238,	MLMLossWVC=1.798970,	MVRCLoss=2.449638,	
Rank[  2]Epoch[6] Batch [6700]	Speed: 27.84 samples/s ETA: 0 d 23 h 26 m	Data: 0.262 Tran: 0.007 F: 0.149 B: 0.290 O: 1.583 M: 0.006	Train-MLMAcc=0.626896,	MVRCAccuracy=0.673238,	MLMLossWVC=1.798970,	MVRCLoss=2.449638,	
Rank[  0]Epoch[6] Batch [6700]	Speed: 27.84 samples/s ETA: 0 d 23 h 26 m	Data: 1.574 Tran: 0.007 F: 0.150 B: 0.291 O: 0.270 M: 0.007	Train-MLMAcc=0.626896,	MVRCAccuracy=0.673238,	MLMLossWVC=1.798970,	MVRCLoss=2.449638,	
Rank[  0]Epoch[6] Batch [6800]	Speed: 27.51 samples/s ETA: 0 d 23 h 39 m	Data: 1.751 Tran: 0.006 F: 0.150 B: 0.290 O: 0.121 M: 0.007	Train-MLMAcc=0.626903,	MVRCAccuracy=0.673250,	MLMLossWVC=1.799139,	MVRCLoss=2.449586,	
Rank[  1]Epoch[6] Batch [6800]	Speed: 27.51 samples/s ETA: 0 d 23 h 39 m	Data: 0.043 Tran: 0.007 F: 0.151 B: 0.301 O: 1.816 M: 0.009	Train-MLMAcc=0.626903,	MVRCAccuracy=0.673250,	MLMLossWVC=1.799139,	MVRCLoss=2.449586,	
Rank[  3]Epoch[6] Batch [6800]	Speed: 27.51 samples/s ETA: 0 d 23 h 39 m	Data: 0.026 Tran: 0.007 F: 0.150 B: 0.290 O: 1.844 M: 0.009	Train-MLMAcc=0.626903,	MVRCAccuracy=0.673250,	MLMLossWVC=1.799139,	MVRCLoss=2.449586,	
Rank[  2]Epoch[6] Batch [6800]	Speed: 27.51 samples/s ETA: 0 d 23 h 39 m	Data: 0.076 Tran: 0.007 F: 0.149 B: 0.292 O: 1.791 M: 0.010	Train-MLMAcc=0.626903,	MVRCAccuracy=0.673250,	MLMLossWVC=1.799139,	MVRCLoss=2.449586,	
Rank[  1]Epoch[6] Batch [6900]	Speed: 28.30 samples/s ETA: 0 d 22 h 55 m	Data: 0.028 Tran: 0.007 F: 0.149 B: 0.297 O: 1.770 M: 0.008	Train-MLMAcc=0.626907,	MVRCAccuracy=0.673280,	MLMLossWVC=1.798886,	MVRCLoss=2.449523,	
Rank[  2]Epoch[6] Batch [6900]	Speed: 28.30 samples/s ETA: 0 d 22 h 55 m	Data: 0.470 Tran: 0.007 F: 0.150 B: 0.293 O: 1.334 M: 0.008	Train-MLMAcc=0.626907,	MVRCAccuracy=0.673280,	MLMLossWVC=1.798886,	MVRCLoss=2.449523,	
Rank[  3]Epoch[6] Batch [6900]	Speed: 28.30 samples/s ETA: 0 d 22 h 55 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.797 M: 0.008	Train-MLMAcc=0.626907,	MVRCAccuracy=0.673280,	MLMLossWVC=1.798886,	MVRCLoss=2.449523,	
Rank[  0]Epoch[6] Batch [6900]	Speed: 28.30 samples/s ETA: 0 d 22 h 55 m	Data: 1.583 Tran: 0.007 F: 0.151 B: 0.292 O: 0.222 M: 0.006	Train-MLMAcc=0.626907,	MVRCAccuracy=0.673280,	MLMLossWVC=1.798886,	MVRCLoss=2.449523,	
Rank[  2]Epoch[6] Batch [7000]	Speed: 27.47 samples/s ETA: 0 d 23 h 33 m	Data: 0.697 Tran: 0.007 F: 0.150 B: 0.292 O: 1.176 M: 0.007	Train-MLMAcc=0.626868,	MVRCAccuracy=0.673295,	MLMLossWVC=1.798956,	MVRCLoss=2.449569,	
Rank[  1]Epoch[6] Batch [7000]	Speed: 27.47 samples/s ETA: 0 d 23 h 33 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.857 M: 0.008	Train-MLMAcc=0.626868,	MVRCAccuracy=0.673295,	MLMLossWVC=1.798956,	MVRCLoss=2.449569,	
Rank[  3]Epoch[6] Batch [7000]	Speed: 27.47 samples/s ETA: 0 d 23 h 33 m	Data: 0.082 Tran: 0.006 F: 0.151 B: 0.290 O: 1.792 M: 0.007	Train-MLMAcc=0.626868,	MVRCAccuracy=0.673295,	MLMLossWVC=1.798956,	MVRCLoss=2.449569,	
Rank[  0]Epoch[6] Batch [7000]	Speed: 27.47 samples/s ETA: 0 d 23 h 33 m	Data: 1.597 Tran: 0.010 F: 0.174 B: 0.302 O: 0.240 M: 0.006	Train-MLMAcc=0.626868,	MVRCAccuracy=0.673295,	MLMLossWVC=1.798956,	MVRCLoss=2.449569,	
Rank[  0]Epoch[6] Batch [7100]	Speed: 27.99 samples/s ETA: 0 d 23 h  3 m	Data: 1.587 Tran: 0.007 F: 0.150 B: 0.290 O: 0.244 M: 0.009	Train-MLMAcc=0.626844,	MVRCAccuracy=0.673288,	MLMLossWVC=1.798857,	MVRCLoss=2.449485,	
Rank[  3]Epoch[6] Batch [7100]	Speed: 27.99 samples/s ETA: 0 d 23 h  3 m	Data: 0.021 Tran: 0.007 F: 0.150 B: 0.290 O: 1.811 M: 0.007	Train-MLMAcc=0.626844,	MVRCAccuracy=0.673288,	MLMLossWVC=1.798857,	MVRCLoss=2.449485,	
Rank[  2]Epoch[6] Batch [7100]	Speed: 27.99 samples/s ETA: 0 d 23 h  3 m	Data: 0.340 Tran: 0.007 F: 0.150 B: 0.293 O: 1.488 M: 0.009	Train-MLMAcc=0.626844,	MVRCAccuracy=0.673288,	MLMLossWVC=1.798857,	MVRCLoss=2.449485,	
Rank[  1]Epoch[6] Batch [7100]	Speed: 27.99 samples/s ETA: 0 d 23 h  3 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.816 M: 0.008	Train-MLMAcc=0.626844,	MVRCAccuracy=0.673288,	MLMLossWVC=1.798857,	MVRCLoss=2.449485,	
Rank[  3]Epoch[6] Batch [7200]	Speed: 28.03 samples/s ETA: 0 d 22 h 57 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.821 M: 0.007	Train-MLMAcc=0.626916,	MVRCAccuracy=0.673323,	MLMLossWVC=1.798469,	MVRCLoss=2.449442,	
Rank[  2]Epoch[6] Batch [7200]	Speed: 28.03 samples/s ETA: 0 d 22 h 57 m	Data: 0.270 Tran: 0.007 F: 0.150 B: 0.295 O: 1.553 M: 0.008	Train-MLMAcc=0.626916,	MVRCAccuracy=0.673323,	MLMLossWVC=1.798469,	MVRCLoss=2.449442,	
Rank[  1]Epoch[6] Batch [7200]	Speed: 28.03 samples/s ETA: 0 d 22 h 57 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.297 O: 1.814 M: 0.008	Train-MLMAcc=0.626916,	MVRCAccuracy=0.673323,	MLMLossWVC=1.798469,	MVRCLoss=2.449442,	
Rank[  0]Epoch[6] Batch [7200]	Speed: 28.03 samples/s ETA: 0 d 22 h 57 m	Data: 1.512 Tran: 0.006 F: 0.151 B: 0.292 O: 0.314 M: 0.008	Train-MLMAcc=0.626916,	MVRCAccuracy=0.673323,	MLMLossWVC=1.798469,	MVRCLoss=2.449442,	
Rank[  1]Epoch[6] Batch [7300]	Speed: 27.86 samples/s ETA: 0 d 23 h  2 m	Data: 0.158 Tran: 0.007 F: 0.151 B: 0.299 O: 1.673 M: 0.008	Train-MLMAcc=0.626892,	MVRCAccuracy=0.673321,	MLMLossWVC=1.798440,	MVRCLoss=2.449371,	
Rank[  3]Epoch[6] Batch [7300]	Speed: 27.86 samples/s ETA: 0 d 23 h  2 m	Data: 0.008 Tran: 0.007 F: 0.148 B: 0.288 O: 1.833 M: 0.012	Train-MLMAcc=0.626892,	MVRCAccuracy=0.673321,	MLMLossWVC=1.798440,	MVRCLoss=2.449371,	
Rank[  0]Epoch[6] Batch [7300]	Speed: 27.86 samples/s ETA: 0 d 23 h  2 m	Data: 1.301 Tran: 0.007 F: 0.152 B: 0.294 O: 0.533 M: 0.009	Train-MLMAcc=0.626892,	MVRCAccuracy=0.673321,	MLMLossWVC=1.798440,	MVRCLoss=2.449371,	
Rank[  2]Epoch[6] Batch [7300]	Speed: 27.86 samples/s ETA: 0 d 23 h  2 m	Data: 0.480 Tran: 0.008 F: 0.150 B: 0.295 O: 1.352 M: 0.012	Train-MLMAcc=0.626892,	MVRCAccuracy=0.673321,	MLMLossWVC=1.798440,	MVRCLoss=2.449371,	
Rank[  3]Epoch[6] Batch [7400]	Speed: 27.67 samples/s ETA: 0 d 23 h  8 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.851 M: 0.006	Train-MLMAcc=0.626868,	MVRCAccuracy=0.673351,	MLMLossWVC=1.798630,	MVRCLoss=2.449315,	
Rank[  1]Epoch[6] Batch [7400]	Speed: 27.67 samples/s ETA: 0 d 23 h  8 m	Data: 0.088 Tran: 0.007 F: 0.149 B: 0.297 O: 1.765 M: 0.007	Train-MLMAcc=0.626868,	MVRCAccuracy=0.673351,	MLMLossWVC=1.798630,	MVRCLoss=2.449315,	
Rank[  2]Epoch[6] Batch [7400]	Speed: 27.67 samples/s ETA: 0 d 23 h  8 m	Data: 0.705 Tran: 0.007 F: 0.149 B: 0.292 O: 1.154 M: 0.006	Train-MLMAcc=0.626868,	MVRCAccuracy=0.673351,	MLMLossWVC=1.798630,	MVRCLoss=2.449315,	
Rank[  0]Epoch[6] Batch [7400]	Speed: 27.67 samples/s ETA: 0 d 23 h  8 m	Data: 1.162 Tran: 0.007 F: 0.151 B: 0.294 O: 0.692 M: 0.005	Train-MLMAcc=0.626868,	MVRCAccuracy=0.673351,	MLMLossWVC=1.798630,	MVRCLoss=2.449315,	
Rank[  0]Epoch[6] Batch [7500]	Speed: 28.05 samples/s ETA: 0 d 22 h 45 m	Data: 0.293 Tran: 0.007 F: 0.150 B: 0.292 O: 1.530 M: 0.008	Train-MLMAcc=0.626889,	MVRCAccuracy=0.673374,	MLMLossWVC=1.798418,	MVRCLoss=2.449228,	
Rank[  1]Epoch[6] Batch [7500]	Speed: 28.05 samples/s ETA: 0 d 22 h 45 m	Data: 0.406 Tran: 0.007 F: 0.150 B: 0.298 O: 1.411 M: 0.009	Train-MLMAcc=0.626889,	MVRCAccuracy=0.673374,	MLMLossWVC=1.798418,	MVRCLoss=2.449228,	
Rank[  3]Epoch[6] Batch [7500]	Speed: 28.05 samples/s ETA: 0 d 22 h 45 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.818 M: 0.008	Train-MLMAcc=0.626889,	MVRCAccuracy=0.673374,	MLMLossWVC=1.798418,	MVRCLoss=2.449228,	
Rank[  2]Epoch[6] Batch [7500]	Speed: 28.05 samples/s ETA: 0 d 22 h 45 m	Data: 1.085 Tran: 0.007 F: 0.151 B: 0.295 O: 0.735 M: 0.008	Train-MLMAcc=0.626889,	MVRCAccuracy=0.673374,	MLMLossWVC=1.798418,	MVRCLoss=2.449228,	
Rank[  1]Epoch[6] Batch [7600]	Speed: 27.88 samples/s ETA: 0 d 22 h 49 m	Data: 0.206 Tran: 0.007 F: 0.150 B: 0.299 O: 1.627 M: 0.006	Train-MLMAcc=0.626886,	MVRCAccuracy=0.673367,	MLMLossWVC=1.798477,	MVRCLoss=2.449185,	
Rank[  2]Epoch[6] Batch [7600]	Speed: 27.88 samples/s ETA: 0 d 22 h 49 m	Data: 1.570 Tran: 0.006 F: 0.150 B: 0.293 O: 0.268 M: 0.007	Train-MLMAcc=0.626886,	MVRCAccuracy=0.673367,	MLMLossWVC=1.798477,	MVRCLoss=2.449185,	
Rank[  0]Epoch[6] Batch [7600]	Speed: 27.88 samples/s ETA: 0 d 22 h 49 m	Data: 0.039 Tran: 0.007 F: 0.149 B: 0.291 O: 1.804 M: 0.006	Train-MLMAcc=0.626886,	MVRCAccuracy=0.673367,	MLMLossWVC=1.798477,	MVRCLoss=2.449185,	
Rank[  3]Epoch[6] Batch [7600]	Speed: 27.88 samples/s ETA: 0 d 22 h 49 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.290 O: 1.835 M: 0.007	Train-MLMAcc=0.626886,	MVRCAccuracy=0.673367,	MLMLossWVC=1.798477,	MVRCLoss=2.449185,	
Rank[  3]Epoch[6] Batch [7700]	Speed: 27.95 samples/s ETA: 0 d 22 h 42 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.289 O: 1.829 M: 0.008	Train-MLMAcc=0.626881,	MVRCAccuracy=0.673380,	MLMLossWVC=1.798330,	MVRCLoss=2.449140,	
Rank[  0]Epoch[6] Batch [7700]	Speed: 27.95 samples/s ETA: 0 d 22 h 42 m	Data: 0.168 Tran: 0.007 F: 0.149 B: 0.291 O: 1.668 M: 0.006	Train-MLMAcc=0.626881,	MVRCAccuracy=0.673380,	MLMLossWVC=1.798330,	MVRCLoss=2.449140,	
Rank[  2]Epoch[6] Batch [7700]	Speed: 27.95 samples/s ETA: 0 d 22 h 42 m	Data: 1.595 Tran: 0.006 F: 0.150 B: 0.295 O: 0.235 M: 0.007	Train-MLMAcc=0.626881,	MVRCAccuracy=0.673380,	MLMLossWVC=1.798330,	MVRCLoss=2.449140,	
Rank[  1]Epoch[6] Batch [7700]	Speed: 27.95 samples/s ETA: 0 d 22 h 42 m	Data: 0.038 Tran: 0.007 F: 0.150 B: 0.297 O: 1.791 M: 0.006	Train-MLMAcc=0.626881,	MVRCAccuracy=0.673380,	MLMLossWVC=1.798330,	MVRCLoss=2.449140,	
Rank[  2]Epoch[6] Batch [7800]	Speed: 27.27 samples/s ETA: 0 d 23 h 12 m	Data: 1.713 Tran: 0.006 F: 0.151 B: 0.294 O: 0.176 M: 0.007	Train-MLMAcc=0.626928,	MVRCAccuracy=0.673453,	MLMLossWVC=1.798089,	MVRCLoss=2.449009,	
Rank[  1]Epoch[6] Batch [7800]	Speed: 27.27 samples/s ETA: 0 d 23 h 12 m	Data: 0.042 Tran: 0.007 F: 0.149 B: 0.298 O: 1.842 M: 0.007	Train-MLMAcc=0.626928,	MVRCAccuracy=0.673453,	MLMLossWVC=1.798089,	MVRCLoss=2.449009,	
Rank[  3]Epoch[6] Batch [7800]	Speed: 27.27 samples/s ETA: 0 d 23 h 12 m	Data: 0.041 Tran: 0.007 F: 0.149 B: 0.290 O: 1.852 M: 0.007	Train-MLMAcc=0.626928,	MVRCAccuracy=0.673453,	MLMLossWVC=1.798089,	MVRCLoss=2.449009,	
Rank[  0]Epoch[6] Batch [7800]	Speed: 27.27 samples/s ETA: 0 d 23 h 12 m	Data: 0.127 Tran: 0.007 F: 0.150 B: 0.292 O: 1.764 M: 0.006	Train-MLMAcc=0.626928,	MVRCAccuracy=0.673453,	MLMLossWVC=1.798089,	MVRCLoss=2.449009,	
Rank[  3]Epoch[6] Batch [7900]	Speed: 27.84 samples/s ETA: 0 d 22 h 40 m	Data: 0.009 Tran: 0.007 F: 0.151 B: 0.294 O: 1.827 M: 0.010	Train-MLMAcc=0.626919,	MVRCAccuracy=0.673467,	MLMLossWVC=1.798079,	MVRCLoss=2.448962,	
Rank[  1]Epoch[6] Batch [7900]	Speed: 27.84 samples/s ETA: 0 d 22 h 40 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.302 O: 1.820 M: 0.009	Train-MLMAcc=0.626919,	MVRCAccuracy=0.673467,	MLMLossWVC=1.798079,	MVRCLoss=2.448962,	
Rank[  0]Epoch[6] Batch [7900]	Speed: 27.84 samples/s ETA: 0 d 22 h 40 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.295 O: 1.827 M: 0.009	Train-MLMAcc=0.626919,	MVRCAccuracy=0.673467,	MLMLossWVC=1.798079,	MVRCLoss=2.448962,	
Rank[  2]Epoch[6] Batch [7900]	Speed: 27.84 samples/s ETA: 0 d 22 h 40 m	Data: 1.724 Tran: 0.015 F: 0.180 B: 0.312 O: 0.057 M: 0.010	Train-MLMAcc=0.626919,	MVRCAccuracy=0.673467,	MLMLossWVC=1.798079,	MVRCLoss=2.448962,	
Rank[  0]Epoch[6] Batch [8000]	Speed: 27.77 samples/s ETA: 0 d 22 h 39 m	Data: 0.152 Tran: 0.007 F: 0.150 B: 0.294 O: 1.695 M: 0.006	Train-MLMAcc=0.626948,	MVRCAccuracy=0.673486,	MLMLossWVC=1.797901,	MVRCLoss=2.448947,	
Rank[  1]Epoch[6] Batch [8000]	Speed: 27.77 samples/s ETA: 0 d 22 h 39 m	Data: 0.520 Tran: 0.007 F: 0.150 B: 0.300 O: 1.320 M: 0.006	Train-MLMAcc=0.626948,	MVRCAccuracy=0.673486,	MLMLossWVC=1.797901,	MVRCLoss=2.448947,	
Rank[  2]Epoch[6] Batch [8000]	Speed: 27.77 samples/s ETA: 0 d 22 h 39 m	Data: 1.491 Tran: 0.006 F: 0.151 B: 0.295 O: 0.355 M: 0.006	Train-MLMAcc=0.626948,	MVRCAccuracy=0.673486,	MLMLossWVC=1.797901,	MVRCLoss=2.448947,	
Rank[  3]Epoch[6] Batch [8000]	Speed: 27.77 samples/s ETA: 0 d 22 h 39 m	Data: 0.276 Tran: 0.007 F: 0.149 B: 0.290 O: 1.576 M: 0.006	Train-MLMAcc=0.626948,	MVRCAccuracy=0.673486,	MLMLossWVC=1.797901,	MVRCLoss=2.448947,	
Rank[  2]Epoch[6] Batch [8100]	Speed: 27.66 samples/s ETA: 0 d 22 h 41 m	Data: 1.415 Tran: 0.006 F: 0.150 B: 0.294 O: 0.441 M: 0.007	Train-MLMAcc=0.626951,	MVRCAccuracy=0.673492,	MLMLossWVC=1.797892,	MVRCLoss=2.448952,	
Rank[  1]Epoch[6] Batch [8100]	Speed: 27.66 samples/s ETA: 0 d 22 h 41 m	Data: 0.672 Tran: 0.007 F: 0.149 B: 0.298 O: 1.181 M: 0.007	Train-MLMAcc=0.626951,	MVRCAccuracy=0.673492,	MLMLossWVC=1.797892,	MVRCLoss=2.448952,	
Rank[  0]Epoch[6] Batch [8100]	Speed: 27.66 samples/s ETA: 0 d 22 h 41 m	Data: 0.146 Tran: 0.007 F: 0.150 B: 0.293 O: 1.711 M: 0.007	Train-MLMAcc=0.626951,	MVRCAccuracy=0.673492,	MLMLossWVC=1.797892,	MVRCLoss=2.448952,	
Rank[  3]Epoch[6] Batch [8100]	Speed: 27.66 samples/s ETA: 0 d 22 h 41 m	Data: 0.246 Tran: 0.007 F: 0.150 B: 0.291 O: 1.612 M: 0.007	Train-MLMAcc=0.626951,	MVRCAccuracy=0.673492,	MLMLossWVC=1.797892,	MVRCLoss=2.448952,	
Rank[  0]Epoch[6] Batch [8200]	Speed: 27.92 samples/s ETA: 0 d 22 h 24 m	Data: 0.021 Tran: 0.007 F: 0.150 B: 0.294 O: 1.812 M: 0.007	Train-MLMAcc=0.627027,	MVRCAccuracy=0.673515,	MLMLossWVC=1.797423,	MVRCLoss=2.449004,	
Rank[  3]Epoch[6] Batch [8200]	Speed: 27.92 samples/s ETA: 0 d 22 h 24 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.828 M: 0.008	Train-MLMAcc=0.627027,	MVRCAccuracy=0.673515,	MLMLossWVC=1.797423,	MVRCLoss=2.449004,	
Rank[  2]Epoch[6] Batch [8200]	Speed: 27.92 samples/s ETA: 0 d 22 h 24 m	Data: 1.782 Tran: 0.006 F: 0.150 B: 0.293 O: 0.053 M: 0.006	Train-MLMAcc=0.627027,	MVRCAccuracy=0.673515,	MLMLossWVC=1.797423,	MVRCLoss=2.449004,	
Rank[  1]Epoch[6] Batch [8200]	Speed: 27.92 samples/s ETA: 0 d 22 h 24 m	Data: 0.009 Tran: 0.008 F: 0.149 B: 0.296 O: 1.822 M: 0.008	Train-MLMAcc=0.627027,	MVRCAccuracy=0.673515,	MLMLossWVC=1.797423,	MVRCLoss=2.449004,	
Rank[  0]Epoch[6] Batch [8300]	Speed: 28.55 samples/s ETA: 0 d 21 h 51 m	Data: 0.210 Tran: 0.007 F: 0.149 B: 0.290 O: 1.578 M: 0.006	Train-MLMAcc=0.627014,	MVRCAccuracy=0.673519,	MLMLossWVC=1.797445,	MVRCLoss=2.448956,	
Rank[  3]Epoch[6] Batch [8300]	Speed: 28.55 samples/s ETA: 0 d 21 h 51 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.291 O: 1.779 M: 0.007	Train-MLMAcc=0.627014,	MVRCAccuracy=0.673519,	MLMLossWVC=1.797445,	MVRCLoss=2.448956,	
Rank[  2]Epoch[6] Batch [8300]	Speed: 28.55 samples/s ETA: 0 d 21 h 51 m	Data: 1.707 Tran: 0.007 F: 0.150 B: 0.294 O: 0.076 M: 0.006	Train-MLMAcc=0.627014,	MVRCAccuracy=0.673519,	MLMLossWVC=1.797445,	MVRCLoss=2.448956,	
Rank[  1]Epoch[6] Batch [8300]	Speed: 28.55 samples/s ETA: 0 d 21 h 51 m	Data: 0.459 Tran: 0.007 F: 0.149 B: 0.297 O: 1.322 M: 0.006	Train-MLMAcc=0.627014,	MVRCAccuracy=0.673519,	MLMLossWVC=1.797445,	MVRCLoss=2.448956,	
Rank[  0]Epoch[6] Batch [8400]	Speed: 27.59 samples/s ETA: 0 d 22 h 33 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.290 O: 1.858 M: 0.007	Train-MLMAcc=0.626995,	MVRCAccuracy=0.673524,	MLMLossWVC=1.797464,	MVRCLoss=2.448887,	
Rank[  1]Epoch[6] Batch [8400]	Speed: 27.59 samples/s ETA: 0 d 22 h 33 m	Data: 0.401 Tran: 0.007 F: 0.150 B: 0.298 O: 1.455 M: 0.008	Train-MLMAcc=0.626995,	MVRCAccuracy=0.673524,	MLMLossWVC=1.797464,	MVRCLoss=2.448887,	
Rank[  2]Epoch[6] Batch [8400]	Speed: 27.59 samples/s ETA: 0 d 22 h 33 m	Data: 1.807 Tran: 0.007 F: 0.151 B: 0.295 O: 0.052 M: 0.007	Train-MLMAcc=0.626995,	MVRCAccuracy=0.673524,	MLMLossWVC=1.797464,	MVRCLoss=2.448887,	
Rank[  3]Epoch[6] Batch [8400]	Speed: 27.59 samples/s ETA: 0 d 22 h 33 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.855 M: 0.009	Train-MLMAcc=0.626995,	MVRCAccuracy=0.673524,	MLMLossWVC=1.797464,	MVRCLoss=2.448887,	
Rank[  1]Epoch[6] Batch [8500]	Speed: 27.00 samples/s ETA: 0 d 22 h 58 m	Data: 0.017 Tran: 0.007 F: 0.150 B: 0.298 O: 1.889 M: 0.007	Train-MLMAcc=0.627024,	MVRCAccuracy=0.673530,	MLMLossWVC=1.797300,	MVRCLoss=2.448886,	
Rank[  2]Epoch[6] Batch [8500]	Speed: 27.00 samples/s ETA: 0 d 22 h 58 m	Data: 1.859 Tran: 0.007 F: 0.150 B: 0.293 O: 0.051 M: 0.008	Train-MLMAcc=0.627024,	MVRCAccuracy=0.673530,	MLMLossWVC=1.797300,	MVRCLoss=2.448886,	
Rank[  3]Epoch[6] Batch [8500]	Speed: 27.00 samples/s ETA: 0 d 22 h 58 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.290 O: 1.909 M: 0.007	Train-MLMAcc=0.627024,	MVRCAccuracy=0.673530,	MLMLossWVC=1.797300,	MVRCLoss=2.448886,	
Rank[  0]Epoch[6] Batch [8500]	Speed: 27.00 samples/s ETA: 0 d 22 h 58 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.293 O: 1.904 M: 0.008	Train-MLMAcc=0.627024,	MVRCAccuracy=0.673530,	MLMLossWVC=1.797300,	MVRCLoss=2.448886,	
Rank[  2]Epoch[6] Batch [8600]	Speed: 28.02 samples/s ETA: 0 d 22 h  5 m	Data: 1.771 Tran: 0.007 F: 0.150 B: 0.292 O: 0.056 M: 0.007	Train-MLMAcc=0.627020,	MVRCAccuracy=0.673547,	MLMLossWVC=1.797347,	MVRCLoss=2.448920,	
Rank[  0]Epoch[6] Batch [8600]	Speed: 28.02 samples/s ETA: 0 d 22 h  5 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.294 O: 1.817 M: 0.006	Train-MLMAcc=0.627020,	MVRCAccuracy=0.673547,	MLMLossWVC=1.797347,	MVRCLoss=2.448920,	
Rank[  1]Epoch[6] Batch [8600]	Speed: 28.02 samples/s ETA: 0 d 22 h  5 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.812 M: 0.008	Train-MLMAcc=0.627020,	MVRCAccuracy=0.673547,	MLMLossWVC=1.797347,	MVRCLoss=2.448920,	
Rank[  3]Epoch[6] Batch [8600]	Speed: 28.02 samples/s ETA: 0 d 22 h  5 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.821 M: 0.007	Train-MLMAcc=0.627020,	MVRCAccuracy=0.673547,	MLMLossWVC=1.797347,	MVRCLoss=2.448920,	
Rank[  2]Epoch[6] Batch [8700]	Speed: 27.73 samples/s ETA: 0 d 22 h 14 m	Data: 1.799 Tran: 0.007 F: 0.151 B: 0.292 O: 0.052 M: 0.007	Train-MLMAcc=0.627052,	MVRCAccuracy=0.673554,	MLMLossWVC=1.797240,	MVRCLoss=2.448905,	
Rank[  3]Epoch[6] Batch [8700]	Speed: 27.73 samples/s ETA: 0 d 22 h 14 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.290 O: 1.846 M: 0.007	Train-MLMAcc=0.627052,	MVRCAccuracy=0.673554,	MLMLossWVC=1.797240,	MVRCLoss=2.448905,	
Rank[  0]Epoch[6] Batch [8700]	Speed: 27.73 samples/s ETA: 0 d 22 h 14 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.293 O: 1.842 M: 0.007	Train-MLMAcc=0.627052,	MVRCAccuracy=0.673554,	MLMLossWVC=1.797240,	MVRCLoss=2.448905,	
Rank[  1]Epoch[6] Batch [8700]	Speed: 27.73 samples/s ETA: 0 d 22 h 14 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 1.838 M: 0.007	Train-MLMAcc=0.627052,	MVRCAccuracy=0.673554,	MLMLossWVC=1.797240,	MVRCLoss=2.448905,	
Rank[  3]Epoch[6] Batch [8800]	Speed: 26.48 samples/s ETA: 0 d 23 h 14 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.291 O: 1.955 M: 0.006	Train-MLMAcc=0.627098,	MVRCAccuracy=0.673567,	MLMLossWVC=1.797078,	MVRCLoss=2.448904,	
Rank[  2]Epoch[6] Batch [8800]	Speed: 26.48 samples/s ETA: 0 d 23 h 14 m	Data: 1.872 Tran: 0.009 F: 0.174 B: 0.300 O: 0.056 M: 0.006	Train-MLMAcc=0.627098,	MVRCAccuracy=0.673567,	MLMLossWVC=1.797078,	MVRCLoss=2.448904,	
Rank[  1]Epoch[6] Batch [8800]	Speed: 26.48 samples/s ETA: 0 d 23 h 14 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.947 M: 0.006	Train-MLMAcc=0.627098,	MVRCAccuracy=0.673567,	MLMLossWVC=1.797078,	MVRCLoss=2.448904,	
Rank[  0]Epoch[6] Batch [8800]	Speed: 26.48 samples/s ETA: 0 d 23 h 14 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.292 O: 1.953 M: 0.006	Train-MLMAcc=0.627098,	MVRCAccuracy=0.673567,	MLMLossWVC=1.797078,	MVRCLoss=2.448904,	
Rank[  1]Epoch[6] Batch [8900]	Speed: 27.58 samples/s ETA: 0 d 22 h 14 m	Data: 0.008 Tran: 0.009 F: 0.152 B: 0.297 O: 1.845 M: 0.007	Train-MLMAcc=0.627113,	MVRCAccuracy=0.673574,	MLMLossWVC=1.797091,	MVRCLoss=2.448932,	
Rank[  0]Epoch[6] Batch [8900]	Speed: 27.58 samples/s ETA: 0 d 22 h 14 m	Data: 0.008 Tran: 0.009 F: 0.152 B: 0.292 O: 1.852 M: 0.007	Train-MLMAcc=0.627113,	MVRCAccuracy=0.673574,	MLMLossWVC=1.797091,	MVRCLoss=2.448932,	
Rank[  3]Epoch[6] Batch [8900]	Speed: 27.58 samples/s ETA: 0 d 22 h 14 m	Data: 0.008 Tran: 0.009 F: 0.152 B: 0.291 O: 1.851 M: 0.008	Train-MLMAcc=0.627113,	MVRCAccuracy=0.673574,	MLMLossWVC=1.797091,	MVRCLoss=2.448932,	
Rank[  2]Epoch[6] Batch [8900]	Speed: 27.58 samples/s ETA: 0 d 22 h 14 m	Data: 1.773 Tran: 0.008 F: 0.172 B: 0.297 O: 0.059 M: 0.008	Train-MLMAcc=0.627113,	MVRCAccuracy=0.673574,	MLMLossWVC=1.797091,	MVRCLoss=2.448932,	
Rank[  3]Epoch[6] Batch [9000]	Speed: 28.07 samples/s ETA: 0 d 21 h 47 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.289 O: 1.820 M: 0.006	Train-MLMAcc=0.627150,	MVRCAccuracy=0.673584,	MLMLossWVC=1.796700,	MVRCLoss=2.448952,	
Rank[  2]Epoch[6] Batch [9000]	Speed: 28.07 samples/s ETA: 0 d 21 h 47 m	Data: 1.771 Tran: 0.007 F: 0.150 B: 0.291 O: 0.056 M: 0.005	Train-MLMAcc=0.627150,	MVRCAccuracy=0.673584,	MLMLossWVC=1.796700,	MVRCLoss=2.448952,	
Rank[  0]Epoch[6] Batch [9000]	Speed: 28.07 samples/s ETA: 0 d 21 h 47 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.292 O: 1.818 M: 0.006	Train-MLMAcc=0.627150,	MVRCAccuracy=0.673584,	MLMLossWVC=1.796700,	MVRCLoss=2.448952,	
Rank[  1]Epoch[6] Batch [9000]	Speed: 28.07 samples/s ETA: 0 d 21 h 47 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.295 O: 1.815 M: 0.005	Train-MLMAcc=0.627150,	MVRCAccuracy=0.673584,	MLMLossWVC=1.796700,	MVRCLoss=2.448952,	
Rank[  3]Epoch[6] Batch [9100]	Speed: 28.22 samples/s ETA: 0 d 21 h 36 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.289 O: 1.806 M: 0.007	Train-MLMAcc=0.627169,	MVRCAccuracy=0.673594,	MLMLossWVC=1.796600,	MVRCLoss=2.448889,	
Rank[  2]Epoch[6] Batch [9100]	Speed: 28.22 samples/s ETA: 0 d 21 h 36 m	Data: 1.756 Tran: 0.007 F: 0.150 B: 0.293 O: 0.053 M: 0.006	Train-MLMAcc=0.627169,	MVRCAccuracy=0.673594,	MLMLossWVC=1.796600,	MVRCLoss=2.448889,	
Rank[  1]Epoch[6] Batch [9100]	Speed: 28.22 samples/s ETA: 0 d 21 h 36 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.799 M: 0.005	Train-MLMAcc=0.627169,	MVRCAccuracy=0.673594,	MLMLossWVC=1.796600,	MVRCLoss=2.448889,	
Rank[  0]Epoch[6] Batch [9100]	Speed: 28.22 samples/s ETA: 0 d 21 h 36 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.803 M: 0.007	Train-MLMAcc=0.627169,	MVRCAccuracy=0.673594,	MLMLossWVC=1.796600,	MVRCLoss=2.448889,	
Rank[  0]Epoch[6] Batch [9200]	Speed: 27.75 samples/s ETA: 0 d 21 h 54 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.839 M: 0.009	Train-MLMAcc=0.627156,	MVRCAccuracy=0.673580,	MLMLossWVC=1.796728,	MVRCLoss=2.448866,	
Rank[  3]Epoch[6] Batch [9200]	Speed: 27.75 samples/s ETA: 0 d 21 h 54 m	Data: 0.505 Tran: 0.007 F: 0.153 B: 0.291 O: 1.340 M: 0.008	Train-MLMAcc=0.627156,	MVRCAccuracy=0.673580,	MLMLossWVC=1.796728,	MVRCLoss=2.448866,	
Rank[  2]Epoch[6] Batch [9200]	Speed: 27.75 samples/s ETA: 0 d 21 h 54 m	Data: 1.471 Tran: 0.012 F: 0.172 B: 0.296 O: 0.346 M: 0.009	Train-MLMAcc=0.627156,	MVRCAccuracy=0.673580,	MLMLossWVC=1.796728,	MVRCLoss=2.448866,	
Rank[  1]Epoch[6] Batch [9200]	Speed: 27.75 samples/s ETA: 0 d 21 h 54 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.300 O: 1.831 M: 0.008	Train-MLMAcc=0.627156,	MVRCAccuracy=0.673580,	MLMLossWVC=1.796728,	MVRCLoss=2.448866,	
Rank[  1]Epoch[6] Batch [9300]	Speed: 27.42 samples/s ETA: 0 d 22 h  6 m	Data: 0.009 Tran: 0.008 F: 0.154 B: 0.306 O: 1.846 M: 0.009	Train-MLMAcc=0.627101,	MVRCAccuracy=0.673595,	MLMLossWVC=1.797017,	MVRCLoss=2.448854,	
Rank[  2]Epoch[6] Batch [9300]	Speed: 27.42 samples/s ETA: 0 d 22 h  6 m	Data: 1.670 Tran: 0.008 F: 0.167 B: 0.307 O: 0.171 M: 0.009	Train-MLMAcc=0.627101,	MVRCAccuracy=0.673595,	MLMLossWVC=1.797017,	MVRCLoss=2.448854,	
Rank[  0]Epoch[6] Batch [9300]	Speed: 27.42 samples/s ETA: 0 d 22 h  6 m	Data: 0.014 Tran: 0.007 F: 0.154 B: 0.298 O: 1.850 M: 0.007	Train-MLMAcc=0.627101,	MVRCAccuracy=0.673595,	MLMLossWVC=1.797017,	MVRCLoss=2.448854,	
Rank[  3]Epoch[6] Batch [9300]	Speed: 27.42 samples/s ETA: 0 d 22 h  6 m	Data: 0.993 Tran: 0.008 F: 0.155 B: 0.293 O: 0.873 M: 0.009	Train-MLMAcc=0.627101,	MVRCAccuracy=0.673595,	MLMLossWVC=1.797017,	MVRCLoss=2.448854,	
Rank[  0]Epoch[6] Batch [9400]	Speed: 27.82 samples/s ETA: 0 d 21 h 43 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.291 O: 1.839 M: 0.006	Train-MLMAcc=0.627178,	MVRCAccuracy=0.673596,	MLMLossWVC=1.796717,	MVRCLoss=2.448778,	
Rank[  1]Epoch[6] Batch [9400]	Speed: 27.82 samples/s ETA: 0 d 21 h 43 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.299 O: 1.829 M: 0.006	Train-MLMAcc=0.627178,	MVRCAccuracy=0.673596,	MLMLossWVC=1.796717,	MVRCLoss=2.448778,	
Rank[  2]Epoch[6] Batch [9400]	Speed: 27.82 samples/s ETA: 0 d 21 h 43 m	Data: 1.084 Tran: 0.007 F: 0.151 B: 0.294 O: 0.758 M: 0.006	Train-MLMAcc=0.627178,	MVRCAccuracy=0.673596,	MLMLossWVC=1.796717,	MVRCLoss=2.448778,	
Rank[  3]Epoch[6] Batch [9400]	Speed: 27.82 samples/s ETA: 0 d 21 h 43 m	Data: 1.765 Tran: 0.007 F: 0.151 B: 0.291 O: 0.080 M: 0.005	Train-MLMAcc=0.627178,	MVRCAccuracy=0.673596,	MLMLossWVC=1.796717,	MVRCLoss=2.448778,	
Rank[  1]Epoch[6] Batch [9500]	Speed: 27.85 samples/s ETA: 0 d 21 h 38 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.298 O: 1.829 M: 0.007	Train-MLMAcc=0.627195,	MVRCAccuracy=0.673595,	MLMLossWVC=1.796607,	MVRCLoss=2.448797,	
Rank[  0]Epoch[6] Batch [9500]	Speed: 27.85 samples/s ETA: 0 d 21 h 38 m	Data: 0.027 Tran: 0.007 F: 0.149 B: 0.291 O: 1.816 M: 0.007	Train-MLMAcc=0.627195,	MVRCAccuracy=0.673595,	MLMLossWVC=1.796607,	MVRCLoss=2.448797,	
Rank[  3]Epoch[6] Batch [9500]	Speed: 27.85 samples/s ETA: 0 d 21 h 38 m	Data: 1.679 Tran: 0.007 F: 0.150 B: 0.291 O: 0.163 M: 0.006	Train-MLMAcc=0.627195,	MVRCAccuracy=0.673595,	MLMLossWVC=1.796607,	MVRCLoss=2.448797,	
Rank[  2]Epoch[6] Batch [9500]	Speed: 27.85 samples/s ETA: 0 d 21 h 38 m	Data: 0.751 Tran: 0.007 F: 0.150 B: 0.292 O: 1.091 M: 0.006	Train-MLMAcc=0.627195,	MVRCAccuracy=0.673595,	MLMLossWVC=1.796607,	MVRCLoss=2.448797,	
Rank[  1]Epoch[6] Batch [9600]	Speed: 28.05 samples/s ETA: 0 d 21 h 25 m	Data: 0.086 Tran: 0.007 F: 0.149 B: 0.297 O: 1.735 M: 0.007	Train-MLMAcc=0.627220,	MVRCAccuracy=0.673610,	MLMLossWVC=1.796456,	MVRCLoss=2.448730,	
Rank[  2]Epoch[6] Batch [9600]	Speed: 28.05 samples/s ETA: 0 d 21 h 25 m	Data: 0.229 Tran: 0.007 F: 0.150 B: 0.295 O: 1.591 M: 0.008	Train-MLMAcc=0.627220,	MVRCAccuracy=0.673610,	MLMLossWVC=1.796456,	MVRCLoss=2.448730,	
Rank[  0]Epoch[6] Batch [9600]	Speed: 28.05 samples/s ETA: 0 d 21 h 25 m	Data: 0.108 Tran: 0.007 F: 0.149 B: 0.291 O: 1.719 M: 0.007	Train-MLMAcc=0.627220,	MVRCAccuracy=0.673610,	MLMLossWVC=1.796456,	MVRCLoss=2.448730,	
Rank[  3]Epoch[6] Batch [9600]	Speed: 28.05 samples/s ETA: 0 d 21 h 25 m	Data: 1.618 Tran: 0.007 F: 0.150 B: 0.291 O: 0.209 M: 0.006	Train-MLMAcc=0.627220,	MVRCAccuracy=0.673610,	MLMLossWVC=1.796456,	MVRCLoss=2.448730,	
Rank[  1]Epoch[6] Batch [9700]	Speed: 27.98 samples/s ETA: 0 d 21 h 24 m	Data: 0.022 Tran: 0.007 F: 0.150 B: 0.298 O: 1.804 M: 0.006	Train-MLMAcc=0.627174,	MVRCAccuracy=0.673638,	MLMLossWVC=1.796585,	MVRCLoss=2.448732,	
Rank[  0]Epoch[6] Batch [9700]	Speed: 27.98 samples/s ETA: 0 d 21 h 24 m	Data: 0.147 Tran: 0.007 F: 0.150 B: 0.293 O: 1.684 M: 0.006	Train-MLMAcc=0.627174,	MVRCAccuracy=0.673638,	MLMLossWVC=1.796585,	MVRCLoss=2.448732,	
Rank[  3]Epoch[6] Batch [9700]	Speed: 27.98 samples/s ETA: 0 d 21 h 24 m	Data: 1.151 Tran: 0.007 F: 0.149 B: 0.290 O: 0.684 M: 0.006	Train-MLMAcc=0.627174,	MVRCAccuracy=0.673638,	MLMLossWVC=1.796585,	MVRCLoss=2.448732,	
Rank[  2]Epoch[6] Batch [9700]	Speed: 27.98 samples/s ETA: 0 d 21 h 24 m	Data: 0.496 Tran: 0.007 F: 0.150 B: 0.295 O: 1.333 M: 0.007	Train-MLMAcc=0.627174,	MVRCAccuracy=0.673638,	MLMLossWVC=1.796585,	MVRCLoss=2.448732,	
Rank[  1]Epoch[6] Batch [9800]	Speed: 27.84 samples/s ETA: 0 d 21 h 27 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.830 M: 0.006	Train-MLMAcc=0.627240,	MVRCAccuracy=0.673649,	MLMLossWVC=1.796306,	MVRCLoss=2.448725,	
Rank[  3]Epoch[6] Batch [9800]	Speed: 27.84 samples/s ETA: 0 d 21 h 27 m	Data: 1.634 Tran: 0.007 F: 0.150 B: 0.290 O: 0.212 M: 0.006	Train-MLMAcc=0.627240,	MVRCAccuracy=0.673649,	MLMLossWVC=1.796306,	MVRCLoss=2.448725,	
Rank[  2]Epoch[6] Batch [9800]	Speed: 27.84 samples/s ETA: 0 d 21 h 27 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.833 M: 0.006	Train-MLMAcc=0.627240,	MVRCAccuracy=0.673649,	MLMLossWVC=1.796306,	MVRCLoss=2.448725,	
Rank[  0]Epoch[6] Batch [9800]	Speed: 27.84 samples/s ETA: 0 d 21 h 27 m	Data: 0.163 Tran: 0.007 F: 0.149 B: 0.290 O: 1.684 M: 0.006	Train-MLMAcc=0.627240,	MVRCAccuracy=0.673649,	MLMLossWVC=1.796306,	MVRCLoss=2.448725,	
Rank[  1]Epoch[6] Batch [9900]	Speed: 28.14 samples/s ETA: 0 d 21 h  9 m	Data: 0.066 Tran: 0.007 F: 0.149 B: 0.297 O: 1.749 M: 0.006	Train-MLMAcc=0.627240,	MVRCAccuracy=0.673654,	MLMLossWVC=1.796409,	MVRCLoss=2.448755,	
Rank[  0]Epoch[6] Batch [9900]	Speed: 28.14 samples/s ETA: 0 d 21 h  9 m	Data: 0.022 Tran: 0.007 F: 0.150 B: 0.292 O: 1.797 M: 0.006	Train-MLMAcc=0.627240,	MVRCAccuracy=0.673654,	MLMLossWVC=1.796409,	MVRCLoss=2.448755,	
Rank[  2]Epoch[6] Batch [9900]	Speed: 28.14 samples/s ETA: 0 d 21 h  9 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.293 O: 1.810 M: 0.007	Train-MLMAcc=0.627240,	MVRCAccuracy=0.673654,	MLMLossWVC=1.796409,	MVRCLoss=2.448755,	
Rank[  3]Epoch[6] Batch [9900]	Speed: 28.14 samples/s ETA: 0 d 21 h  9 m	Data: 1.699 Tran: 0.008 F: 0.150 B: 0.290 O: 0.120 M: 0.006	Train-MLMAcc=0.627240,	MVRCAccuracy=0.673654,	MLMLossWVC=1.796409,	MVRCLoss=2.448755,	
Rank[  2]Epoch[6] Batch [10000]	Speed: 28.13 samples/s ETA: 0 d 21 h  6 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.294 O: 1.810 M: 0.006	Train-MLMAcc=0.627237,	MVRCAccuracy=0.673704,	MLMLossWVC=1.796367,	MVRCLoss=2.448686,	
Rank[  0]Epoch[6] Batch [10000]	Speed: 28.13 samples/s ETA: 0 d 21 h  6 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.808 M: 0.011	Train-MLMAcc=0.627237,	MVRCAccuracy=0.673704,	MLMLossWVC=1.796367,	MVRCLoss=2.448686,	
Rank[  3]Epoch[6] Batch [10000]	Speed: 28.13 samples/s ETA: 0 d 21 h  6 m	Data: 1.714 Tran: 0.007 F: 0.150 B: 0.289 O: 0.106 M: 0.009	Train-MLMAcc=0.627237,	MVRCAccuracy=0.673704,	MLMLossWVC=1.796367,	MVRCLoss=2.448686,	
Rank[  1]Epoch[6] Batch [10000]	Speed: 28.13 samples/s ETA: 0 d 21 h  6 m	Data: 0.055 Tran: 0.007 F: 0.149 B: 0.297 O: 1.757 M: 0.009	Train-MLMAcc=0.627237,	MVRCAccuracy=0.673704,	MLMLossWVC=1.796367,	MVRCLoss=2.448686,	
Rank[  0]Epoch[6] Batch [10100]	Speed: 27.84 samples/s ETA: 0 d 21 h 16 m	Data: 0.021 Tran: 0.007 F: 0.151 B: 0.293 O: 1.818 M: 0.008	Train-MLMAcc=0.627275,	MVRCAccuracy=0.673716,	MLMLossWVC=1.796084,	MVRCLoss=2.448670,	
Rank[  1]Epoch[6] Batch [10100]	Speed: 27.84 samples/s ETA: 0 d 21 h 16 m	Data: 0.172 Tran: 0.007 F: 0.150 B: 0.296 O: 1.665 M: 0.009	Train-MLMAcc=0.627275,	MVRCAccuracy=0.673716,	MLMLossWVC=1.796084,	MVRCLoss=2.448670,	
Rank[  2]Epoch[6] Batch [10100]	Speed: 27.84 samples/s ETA: 0 d 21 h 16 m	Data: 0.244 Tran: 0.007 F: 0.150 B: 0.294 O: 1.595 M: 0.008	Train-MLMAcc=0.627275,	MVRCAccuracy=0.673716,	MLMLossWVC=1.796084,	MVRCLoss=2.448670,	
Rank[  3]Epoch[6] Batch [10100]	Speed: 27.84 samples/s ETA: 0 d 21 h 16 m	Data: 1.340 Tran: 0.010 F: 0.175 B: 0.298 O: 0.466 M: 0.009	Train-MLMAcc=0.627275,	MVRCAccuracy=0.673716,	MLMLossWVC=1.796084,	MVRCLoss=2.448670,	
Rank[  2]Epoch[6] Batch [10200]	Speed: 27.37 samples/s ETA: 0 d 21 h 34 m	Data: 1.503 Tran: 0.007 F: 0.159 B: 0.296 O: 0.362 M: 0.009	Train-MLMAcc=0.627274,	MVRCAccuracy=0.673723,	MLMLossWVC=1.796214,	MVRCLoss=2.448623,	
Rank[  3]Epoch[6] Batch [10200]	Speed: 27.37 samples/s ETA: 0 d 21 h 34 m	Data: 0.408 Tran: 0.008 F: 0.175 B: 0.307 O: 1.430 M: 0.009	Train-MLMAcc=0.627274,	MVRCAccuracy=0.673723,	MLMLossWVC=1.796214,	MVRCLoss=2.448623,	
Rank[  1]Epoch[6] Batch [10200]	Speed: 27.37 samples/s ETA: 0 d 21 h 34 m	Data: 0.502 Tran: 0.007 F: 0.169 B: 0.317 O: 1.333 M: 0.008	Train-MLMAcc=0.627274,	MVRCAccuracy=0.673723,	MLMLossWVC=1.796214,	MVRCLoss=2.448623,	
Rank[  0]Epoch[6] Batch [10200]	Speed: 27.37 samples/s ETA: 0 d 21 h 34 m	Data: 0.167 Tran: 0.007 F: 0.155 B: 0.297 O: 1.704 M: 0.007	Train-MLMAcc=0.627274,	MVRCAccuracy=0.673723,	MLMLossWVC=1.796214,	MVRCLoss=2.448623,	
Rank[  1]Epoch[6] Batch [10300]	Speed: 28.01 samples/s ETA: 0 d 21 h  0 m	Data: 1.403 Tran: 0.007 F: 0.150 B: 0.297 O: 0.419 M: 0.007	Train-MLMAcc=0.627318,	MVRCAccuracy=0.673744,	MLMLossWVC=1.796077,	MVRCLoss=2.448574,	
Rank[  0]Epoch[6] Batch [10300]	Speed: 28.01 samples/s ETA: 0 d 21 h  0 m	Data: 0.263 Tran: 0.007 F: 0.150 B: 0.292 O: 1.566 M: 0.007	Train-MLMAcc=0.627318,	MVRCAccuracy=0.673744,	MLMLossWVC=1.796077,	MVRCLoss=2.448574,	
Rank[  2]Epoch[6] Batch [10300]	Speed: 28.01 samples/s ETA: 0 d 21 h  0 m	Data: 1.425 Tran: 0.007 F: 0.150 B: 0.293 O: 0.401 M: 0.007	Train-MLMAcc=0.627318,	MVRCAccuracy=0.673744,	MLMLossWVC=1.796077,	MVRCLoss=2.448574,	
Rank[  3]Epoch[6] Batch [10300]	Speed: 28.01 samples/s ETA: 0 d 21 h  0 m	Data: 0.144 Tran: 0.007 F: 0.150 B: 0.291 O: 1.686 M: 0.006	Train-MLMAcc=0.627318,	MVRCAccuracy=0.673744,	MLMLossWVC=1.796077,	MVRCLoss=2.448574,	
Rank[  0]Epoch[6] Batch [10400]	Speed: 27.51 samples/s ETA: 0 d 21 h 19 m	Data: 0.397 Tran: 0.007 F: 0.150 B: 0.291 O: 1.474 M: 0.008	Train-MLMAcc=0.627320,	MVRCAccuracy=0.673761,	MLMLossWVC=1.796137,	MVRCLoss=2.448540,	
Rank[  3]Epoch[6] Batch [10400]	Speed: 27.51 samples/s ETA: 0 d 21 h 19 m	Data: 0.055 Tran: 0.007 F: 0.149 B: 0.289 O: 1.819 M: 0.006	Train-MLMAcc=0.627320,	MVRCAccuracy=0.673761,	MLMLossWVC=1.796137,	MVRCLoss=2.448540,	
Rank[  1]Epoch[6] Batch [10400]	Speed: 27.51 samples/s ETA: 0 d 21 h 19 m	Data: 0.700 Tran: 0.007 F: 0.150 B: 0.298 O: 1.163 M: 0.007	Train-MLMAcc=0.627320,	MVRCAccuracy=0.673761,	MLMLossWVC=1.796137,	MVRCLoss=2.448540,	
Rank[  2]Epoch[6] Batch [10400]	Speed: 27.51 samples/s ETA: 0 d 21 h 19 m	Data: 1.376 Tran: 0.007 F: 0.150 B: 0.293 O: 0.491 M: 0.009	Train-MLMAcc=0.627320,	MVRCAccuracy=0.673761,	MLMLossWVC=1.796137,	MVRCLoss=2.448540,	
Rank[  1]Epoch[6] Batch [10500]	Speed: 27.82 samples/s ETA: 0 d 21 h  1 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.831 M: 0.006	Train-MLMAcc=0.627323,	MVRCAccuracy=0.673788,	MLMLossWVC=1.796214,	MVRCLoss=2.448496,	
Rank[  3]Epoch[6] Batch [10500]	Speed: 27.82 samples/s ETA: 0 d 21 h  1 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.290 O: 1.840 M: 0.007	Train-MLMAcc=0.627323,	MVRCAccuracy=0.673788,	MLMLossWVC=1.796214,	MVRCLoss=2.448496,	
Rank[  0]Epoch[6] Batch [10500]	Speed: 27.82 samples/s ETA: 0 d 21 h  1 m	Data: 1.003 Tran: 0.006 F: 0.150 B: 0.290 O: 0.844 M: 0.006	Train-MLMAcc=0.627323,	MVRCAccuracy=0.673788,	MLMLossWVC=1.796214,	MVRCLoss=2.448496,	
Rank[  2]Epoch[6] Batch [10500]	Speed: 27.82 samples/s ETA: 0 d 21 h  1 m	Data: 0.796 Tran: 0.007 F: 0.150 B: 0.293 O: 1.047 M: 0.007	Train-MLMAcc=0.627323,	MVRCAccuracy=0.673788,	MLMLossWVC=1.796214,	MVRCLoss=2.448496,	
Rank[  1]Epoch[6] Batch [10600]	Speed: 27.86 samples/s ETA: 0 d 20 h 56 m	Data: 0.041 Tran: 0.007 F: 0.150 B: 0.298 O: 1.793 M: 0.008	Train-MLMAcc=0.627316,	MVRCAccuracy=0.673828,	MLMLossWVC=1.796187,	MVRCLoss=2.448465,	
Rank[  2]Epoch[6] Batch [10600]	Speed: 27.86 samples/s ETA: 0 d 20 h 56 m	Data: 0.139 Tran: 0.007 F: 0.149 B: 0.293 O: 1.700 M: 0.007	Train-MLMAcc=0.627316,	MVRCAccuracy=0.673828,	MLMLossWVC=1.796187,	MVRCLoss=2.448465,	
Rank[  0]Epoch[6] Batch [10600]	Speed: 27.86 samples/s ETA: 0 d 20 h 56 m	Data: 1.639 Tran: 0.006 F: 0.151 B: 0.293 O: 0.202 M: 0.006	Train-MLMAcc=0.627316,	MVRCAccuracy=0.673828,	MLMLossWVC=1.796187,	MVRCLoss=2.448465,	
Rank[  3]Epoch[6] Batch [10600]	Speed: 27.86 samples/s ETA: 0 d 20 h 56 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.835 M: 0.006	Train-MLMAcc=0.627316,	MVRCAccuracy=0.673828,	MLMLossWVC=1.796187,	MVRCLoss=2.448465,	
Rank[  3]Epoch[6] Batch [10700]	Speed: 27.74 samples/s ETA: 0 d 20 h 57 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.846 M: 0.005	Train-MLMAcc=0.627283,	MVRCAccuracy=0.673831,	MLMLossWVC=1.796439,	MVRCLoss=2.448467,	
Rank[  0]Epoch[6] Batch [10700]	Speed: 27.74 samples/s ETA: 0 d 20 h 57 m	Data: 1.806 Tran: 0.006 F: 0.150 B: 0.291 O: 0.048 M: 0.006	Train-MLMAcc=0.627283,	MVRCAccuracy=0.673831,	MLMLossWVC=1.796439,	MVRCLoss=2.448467,	
Rank[  1]Epoch[6] Batch [10700]	Speed: 27.74 samples/s ETA: 0 d 20 h 57 m	Data: 0.011 Tran: 0.007 F: 0.149 B: 0.296 O: 1.838 M: 0.006	Train-MLMAcc=0.627283,	MVRCAccuracy=0.673831,	MLMLossWVC=1.796439,	MVRCLoss=2.448467,	
Rank[  2]Epoch[6] Batch [10700]	Speed: 27.74 samples/s ETA: 0 d 20 h 57 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.845 M: 0.005	Train-MLMAcc=0.627283,	MVRCAccuracy=0.673831,	MLMLossWVC=1.796439,	MVRCLoss=2.448467,	
Rank[  0]Epoch[6] Batch [10800]	Speed: 28.04 samples/s ETA: 0 d 20 h 40 m	Data: 1.753 Tran: 0.006 F: 0.151 B: 0.293 O: 0.070 M: 0.007	Train-MLMAcc=0.627299,	MVRCAccuracy=0.673845,	MLMLossWVC=1.796273,	MVRCLoss=2.448413,	
Rank[  3]Epoch[6] Batch [10800]	Speed: 28.04 samples/s ETA: 0 d 20 h 40 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.290 O: 1.820 M: 0.006	Train-MLMAcc=0.627299,	MVRCAccuracy=0.673845,	MLMLossWVC=1.796273,	MVRCLoss=2.448413,	
Rank[  1]Epoch[6] Batch [10800]	Speed: 28.04 samples/s ETA: 0 d 20 h 40 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.298 O: 1.811 M: 0.006	Train-MLMAcc=0.627299,	MVRCAccuracy=0.673845,	MLMLossWVC=1.796273,	MVRCLoss=2.448413,	
Rank[  2]Epoch[6] Batch [10800]	Speed: 28.04 samples/s ETA: 0 d 20 h 40 m	Data: 0.025 Tran: 0.008 F: 0.150 B: 0.294 O: 1.798 M: 0.006	Train-MLMAcc=0.627299,	MVRCAccuracy=0.673845,	MLMLossWVC=1.796273,	MVRCLoss=2.448413,	
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
New Best Val MLMAcc: 0.6052337288856506, Epoch: 6
New Best Val MLMAcc: 0.6052337288856506, Epoch: 6
New Best Val MLMAcc: 0.6052337288856506, Epoch: 6
New Best Val MLMAcc: 0.6052337288856506, Epoch: 6
Epoch[6] 	Val-MLMAcc=0.605234,	MVRCAccuracy=0.698870,	MLMLossWVC=1.924453,	MVRCLoss=2.456105,	
Epoch[6] 	Val-MLMAcc=0.605234,	MVRCAccuracy=0.698870,	MLMLossWVC=1.924453,	MVRCLoss=2.456105,	
Epoch[6] 	Val-MLMAcc=0.605234,	MVRCAccuracy=0.698870,	MLMLossWVC=1.924453,	MVRCLoss=2.456105,	
Best Val MLMAcc: 0.6052337288856506, Epoch: 6
PROGRESS: 70.00%
Best Val MLMAcc: 0.6052337288856506, Epoch: 6
Best Val MLMAcc: 0.6052337288856506, Epoch: 6
PROGRESS: 70.00%
Epoch[6] 	Val-MLMAcc=0.605234,	MVRCAccuracy=0.698870,	MLMLossWVC=1.924453,	MVRCLoss=2.456105,	
Best Val MLMAcc: 0.6052337288856506, Epoch: 6
PROGRESS: 70.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Save new best model to /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-best.model.
PROGRESS: 70.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Rank[  1]Epoch[7] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.602871,	MVRCAccuracy=0.687318,	MLMLossWVC=2.005262,	MVRCLoss=2.431429,	
Rank[  2]Epoch[7] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.602871,	MVRCAccuracy=0.687318,	MLMLossWVC=2.005262,	MVRCLoss=2.431429,	
Rank[  0]Epoch[7] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.602871,	MVRCAccuracy=0.687318,	MLMLossWVC=2.005262,	MVRCLoss=2.431429,	
Rank[  3]Epoch[7] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.602871,	MVRCAccuracy=0.687318,	MLMLossWVC=2.005262,	MVRCLoss=2.431429,	
Rank[  1]Epoch[7] Batch [100]	Speed: 24.23 samples/s ETA: 0 d 23 h 48 m	Data: 0.422 Tran: 0.013 F: 0.280 B: 0.530 O: 2.966 M: 0.026	Train-MLMAcc=0.634575,	MVRCAccuracy=0.672719,	MLMLossWVC=1.744896,	MVRCLoss=2.442004,	
Rank[  2]Epoch[7] Batch [100]	Speed: 24.23 samples/s ETA: 0 d 23 h 48 m	Data: 0.474 Tran: 0.011 F: 0.279 B: 0.529 O: 2.915 M: 0.028	Train-MLMAcc=0.634575,	MVRCAccuracy=0.672719,	MLMLossWVC=1.744896,	MVRCLoss=2.442004,	
Rank[  3]Epoch[7] Batch [100]	Speed: 24.23 samples/s ETA: 0 d 23 h 48 m	Data: 0.415 Tran: 0.013 F: 0.280 B: 0.516 O: 2.986 M: 0.026	Train-MLMAcc=0.634575,	MVRCAccuracy=0.672719,	MLMLossWVC=1.744896,	MVRCLoss=2.442004,	
Rank[  0]Epoch[7] Batch [100]	Speed: 24.23 samples/s ETA: 0 d 23 h 48 m	Data: 2.929 Tran: 0.015 F: 0.348 B: 0.571 O: 0.163 M: 0.027	Train-MLMAcc=0.634575,	MVRCAccuracy=0.672719,	MLMLossWVC=1.744896,	MVRCLoss=2.442004,	
Rank[  3]Epoch[7] Batch [200]	Speed: 22.23 samples/s ETA: 1 d  1 h 52 m	Data: 0.027 Tran: 0.009 F: 0.234 B: 0.420 O: 2.145 M: 0.034	Train-MLMAcc=0.632756,	MVRCAccuracy=0.672248,	MLMLossWVC=1.763258,	MVRCLoss=2.444588,	
Rank[  2]Epoch[7] Batch [200]	Speed: 22.23 samples/s ETA: 1 d  1 h 52 m	Data: 0.027 Tran: 0.009 F: 0.235 B: 0.422 O: 2.143 M: 0.033	Train-MLMAcc=0.632756,	MVRCAccuracy=0.672248,	MLMLossWVC=1.763258,	MVRCLoss=2.444588,	
Rank[  1]Epoch[7] Batch [200]	Speed: 22.23 samples/s ETA: 1 d  1 h 52 m	Data: 0.028 Tran: 0.009 F: 0.235 B: 0.425 O: 2.139 M: 0.034	Train-MLMAcc=0.632756,	MVRCAccuracy=0.672248,	MLMLossWVC=1.763258,	MVRCLoss=2.444588,	
Rank[  0]Epoch[7] Batch [200]	Speed: 22.23 samples/s ETA: 1 d  1 h 52 m	Data: 1.916 Tran: 0.026 F: 0.353 B: 0.448 O: 0.096 M: 0.031	Train-MLMAcc=0.632756,	MVRCAccuracy=0.672248,	MLMLossWVC=1.763258,	MVRCLoss=2.444588,	
Rank[  2]Epoch[7] Batch [300]	Speed: 24.57 samples/s ETA: 0 d 23 h 20 m	Data: 0.015 Tran: 0.012 F: 0.206 B: 0.373 O: 1.975 M: 0.019	Train-MLMAcc=0.633083,	MVRCAccuracy=0.673424,	MLMLossWVC=1.761047,	MVRCLoss=2.442177,	
Rank[  3]Epoch[7] Batch [300]	Speed: 24.57 samples/s ETA: 0 d 23 h 20 m	Data: 0.019 Tran: 0.010 F: 0.204 B: 0.369 O: 1.979 M: 0.019	Train-MLMAcc=0.633083,	MVRCAccuracy=0.673424,	MLMLossWVC=1.761047,	MVRCLoss=2.442177,	
Rank[  1]Epoch[7] Batch [300]	Speed: 24.57 samples/s ETA: 0 d 23 h 20 m	Data: 0.025 Tran: 0.011 F: 0.206 B: 0.378 O: 1.961 M: 0.019	Train-MLMAcc=0.633083,	MVRCAccuracy=0.673424,	MLMLossWVC=1.761047,	MVRCLoss=2.442177,	
Rank[  0]Epoch[7] Batch [300]	Speed: 24.57 samples/s ETA: 0 d 23 h 20 m	Data: 1.837 Tran: 0.012 F: 0.270 B: 0.388 O: 0.075 M: 0.019	Train-MLMAcc=0.633083,	MVRCAccuracy=0.673424,	MLMLossWVC=1.761047,	MVRCLoss=2.442177,	
Rank[  1]Epoch[7] Batch [400]	Speed: 27.56 samples/s ETA: 0 d 20 h 44 m	Data: 0.010 Tran: 0.008 F: 0.171 B: 0.307 O: 1.817 M: 0.008	Train-MLMAcc=0.633444,	MVRCAccuracy=0.674249,	MLMLossWVC=1.756747,	MVRCLoss=2.441753,	
Rank[  3]Epoch[7] Batch [400]	Speed: 27.56 samples/s ETA: 0 d 20 h 44 m	Data: 0.008 Tran: 0.007 F: 0.169 B: 0.297 O: 1.829 M: 0.010	Train-MLMAcc=0.633444,	MVRCAccuracy=0.674249,	MLMLossWVC=1.756747,	MVRCLoss=2.441753,	
Rank[  0]Epoch[7] Batch [400]	Speed: 27.56 samples/s ETA: 0 d 20 h 44 m	Data: 1.779 Tran: 0.007 F: 0.171 B: 0.301 O: 0.056 M: 0.008	Train-MLMAcc=0.633444,	MVRCAccuracy=0.674249,	MLMLossWVC=1.756747,	MVRCLoss=2.441753,	
Rank[  2]Epoch[7] Batch [400]	Speed: 27.56 samples/s ETA: 0 d 20 h 44 m	Data: 0.008 Tran: 0.008 F: 0.170 B: 0.301 O: 1.825 M: 0.009	Train-MLMAcc=0.633444,	MVRCAccuracy=0.674249,	MLMLossWVC=1.756747,	MVRCLoss=2.441753,	
Rank[  3]Epoch[7] Batch [500]	Speed: 26.92 samples/s ETA: 0 d 21 h  9 m	Data: 0.008 Tran: 0.007 F: 0.159 B: 0.306 O: 1.877 M: 0.014	Train-MLMAcc=0.632254,	MVRCAccuracy=0.674329,	MLMLossWVC=1.763450,	MVRCLoss=2.442749,	
Rank[  0]Epoch[7] Batch [500]	Speed: 26.92 samples/s ETA: 0 d 21 h  9 m	Data: 1.808 Tran: 0.010 F: 0.174 B: 0.307 O: 0.060 M: 0.014	Train-MLMAcc=0.632254,	MVRCAccuracy=0.674329,	MLMLossWVC=1.763450,	MVRCLoss=2.442749,	
Rank[  2]Epoch[7] Batch [500]	Speed: 26.92 samples/s ETA: 0 d 21 h  9 m	Data: 0.010 Tran: 0.007 F: 0.157 B: 0.308 O: 1.877 M: 0.014	Train-MLMAcc=0.632254,	MVRCAccuracy=0.674329,	MLMLossWVC=1.763450,	MVRCLoss=2.442749,	
Rank[  1]Epoch[7] Batch [500]	Speed: 26.92 samples/s ETA: 0 d 21 h  9 m	Data: 0.009 Tran: 0.008 F: 0.159 B: 0.311 O: 1.872 M: 0.014	Train-MLMAcc=0.632254,	MVRCAccuracy=0.674329,	MLMLossWVC=1.763450,	MVRCLoss=2.442749,	
Rank[  1]Epoch[7] Batch [600]	Speed: 28.00 samples/s ETA: 0 d 20 h 17 m	Data: 0.047 Tran: 0.007 F: 0.150 B: 0.297 O: 1.776 M: 0.008	Train-MLMAcc=0.632236,	MVRCAccuracy=0.674424,	MLMLossWVC=1.765079,	MVRCLoss=2.443019,	
Rank[  0]Epoch[7] Batch [600]	Speed: 28.00 samples/s ETA: 0 d 20 h 17 m	Data: 1.773 Tran: 0.007 F: 0.150 B: 0.291 O: 0.056 M: 0.009	Train-MLMAcc=0.632236,	MVRCAccuracy=0.674424,	MLMLossWVC=1.765079,	MVRCLoss=2.443019,	
Rank[  2]Epoch[7] Batch [600]	Speed: 28.00 samples/s ETA: 0 d 20 h 17 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.821 M: 0.008	Train-MLMAcc=0.632236,	MVRCAccuracy=0.674424,	MLMLossWVC=1.765079,	MVRCLoss=2.443019,	
Rank[  3]Epoch[7] Batch [600]	Speed: 28.00 samples/s ETA: 0 d 20 h 17 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.291 O: 1.823 M: 0.006	Train-MLMAcc=0.632236,	MVRCAccuracy=0.674424,	MLMLossWVC=1.765079,	MVRCLoss=2.443019,	
Rank[  3]Epoch[7] Batch [700]	Speed: 27.13 samples/s ETA: 0 d 20 h 52 m	Data: 0.566 Tran: 0.007 F: 0.156 B: 0.299 O: 1.318 M: 0.011	Train-MLMAcc=0.631796,	MVRCAccuracy=0.674781,	MLMLossWVC=1.767033,	MVRCLoss=2.443069,	
Rank[  1]Epoch[7] Batch [700]	Speed: 27.13 samples/s ETA: 0 d 20 h 52 m	Data: 0.027 Tran: 0.007 F: 0.155 B: 0.306 O: 1.850 M: 0.011	Train-MLMAcc=0.631796,	MVRCAccuracy=0.674781,	MLMLossWVC=1.767033,	MVRCLoss=2.443069,	
Rank[  2]Epoch[7] Batch [700]	Speed: 27.13 samples/s ETA: 0 d 20 h 52 m	Data: 0.018 Tran: 0.007 F: 0.156 B: 0.305 O: 1.861 M: 0.010	Train-MLMAcc=0.631796,	MVRCAccuracy=0.674781,	MLMLossWVC=1.767033,	MVRCLoss=2.443069,	
Rank[  0]Epoch[7] Batch [700]	Speed: 27.13 samples/s ETA: 0 d 20 h 52 m	Data: 1.528 Tran: 0.007 F: 0.175 B: 0.335 O: 0.301 M: 0.010	Train-MLMAcc=0.631796,	MVRCAccuracy=0.674781,	MLMLossWVC=1.767033,	MVRCLoss=2.443069,	
Rank[  3]Epoch[7] Batch [800]	Speed: 28.31 samples/s ETA: 0 d 19 h 56 m	Data: 0.705 Tran: 0.007 F: 0.150 B: 0.292 O: 1.099 M: 0.007	Train-MLMAcc=0.631671,	MVRCAccuracy=0.674755,	MLMLossWVC=1.768652,	MVRCLoss=2.443297,	
Rank[  2]Epoch[7] Batch [800]	Speed: 28.31 samples/s ETA: 0 d 19 h 56 m	Data: 0.014 Tran: 0.007 F: 0.149 B: 0.293 O: 1.791 M: 0.006	Train-MLMAcc=0.631671,	MVRCAccuracy=0.674755,	MLMLossWVC=1.768652,	MVRCLoss=2.443297,	
Rank[  0]Epoch[7] Batch [800]	Speed: 28.31 samples/s ETA: 0 d 19 h 56 m	Data: 1.737 Tran: 0.007 F: 0.150 B: 0.291 O: 0.068 M: 0.007	Train-MLMAcc=0.631671,	MVRCAccuracy=0.674755,	MLMLossWVC=1.768652,	MVRCLoss=2.443297,	
Rank[  1]Epoch[7] Batch [800]	Speed: 28.31 samples/s ETA: 0 d 19 h 56 m	Data: 0.032 Tran: 0.007 F: 0.149 B: 0.296 O: 1.769 M: 0.006	Train-MLMAcc=0.631671,	MVRCAccuracy=0.674755,	MLMLossWVC=1.768652,	MVRCLoss=2.443297,	
Rank[  3]Epoch[7] Batch [900]	Speed: 27.89 samples/s ETA: 0 d 20 h 10 m	Data: 0.311 Tran: 0.007 F: 0.150 B: 0.292 O: 1.529 M: 0.005	Train-MLMAcc=0.631511,	MVRCAccuracy=0.674846,	MLMLossWVC=1.768311,	MVRCLoss=2.443638,	
Rank[  2]Epoch[7] Batch [900]	Speed: 27.89 samples/s ETA: 0 d 20 h 10 m	Data: 0.051 Tran: 0.007 F: 0.150 B: 0.294 O: 1.786 M: 0.005	Train-MLMAcc=0.631511,	MVRCAccuracy=0.674846,	MLMLossWVC=1.768311,	MVRCLoss=2.443638,	
Rank[  0]Epoch[7] Batch [900]	Speed: 27.89 samples/s ETA: 0 d 20 h 10 m	Data: 0.659 Tran: 0.007 F: 0.150 B: 0.291 O: 1.182 M: 0.005	Train-MLMAcc=0.631511,	MVRCAccuracy=0.674846,	MLMLossWVC=1.768311,	MVRCLoss=2.443638,	
Rank[  1]Epoch[7] Batch [900]	Speed: 27.89 samples/s ETA: 0 d 20 h 10 m	Data: 1.487 Tran: 0.007 F: 0.151 B: 0.300 O: 0.343 M: 0.005	Train-MLMAcc=0.631511,	MVRCAccuracy=0.674846,	MLMLossWVC=1.768311,	MVRCLoss=2.443638,	
Rank[  3]Epoch[7] Batch [1000]	Speed: 27.93 samples/s ETA: 0 d 20 h  4 m	Data: 0.067 Tran: 0.007 F: 0.149 B: 0.289 O: 1.770 M: 0.008	Train-MLMAcc=0.632022,	MVRCAccuracy=0.675154,	MLMLossWVC=1.766687,	MVRCLoss=2.443516,	
Rank[  1]Epoch[7] Batch [1000]	Speed: 27.93 samples/s ETA: 0 d 20 h  4 m	Data: 1.781 Tran: 0.007 F: 0.150 B: 0.298 O: 0.047 M: 0.008	Train-MLMAcc=0.632022,	MVRCAccuracy=0.675154,	MLMLossWVC=1.766687,	MVRCLoss=2.443516,	
Rank[  2]Epoch[7] Batch [1000]	Speed: 27.93 samples/s ETA: 0 d 20 h  4 m	Data: 0.182 Tran: 0.007 F: 0.150 B: 0.293 O: 1.653 M: 0.006	Train-MLMAcc=0.632022,	MVRCAccuracy=0.675154,	MLMLossWVC=1.766687,	MVRCLoss=2.443516,	
Rank[  0]Epoch[7] Batch [1000]	Speed: 27.93 samples/s ETA: 0 d 20 h  4 m	Data: 0.013 Tran: 0.007 F: 0.149 B: 0.289 O: 1.826 M: 0.007	Train-MLMAcc=0.632022,	MVRCAccuracy=0.675154,	MLMLossWVC=1.766687,	MVRCLoss=2.443516,	
Rank[  0]Epoch[7] Batch [1100]	Speed: 27.84 samples/s ETA: 0 d 20 h  4 m	Data: 0.014 Tran: 0.007 F: 0.150 B: 0.292 O: 1.828 M: 0.007	Train-MLMAcc=0.631756,	MVRCAccuracy=0.675199,	MLMLossWVC=1.766831,	MVRCLoss=2.443339,	
Rank[  2]Epoch[7] Batch [1100]	Speed: 27.84 samples/s ETA: 0 d 20 h  4 m	Data: 0.420 Tran: 0.012 F: 0.171 B: 0.298 O: 1.387 M: 0.008	Train-MLMAcc=0.631756,	MVRCAccuracy=0.675199,	MLMLossWVC=1.766831,	MVRCLoss=2.443339,	
Rank[  3]Epoch[7] Batch [1100]	Speed: 27.84 samples/s ETA: 0 d 20 h  4 m	Data: 0.870 Tran: 0.007 F: 0.152 B: 0.293 O: 0.966 M: 0.008	Train-MLMAcc=0.631756,	MVRCAccuracy=0.675199,	MLMLossWVC=1.766831,	MVRCLoss=2.443339,	
Rank[  1]Epoch[7] Batch [1100]	Speed: 27.84 samples/s ETA: 0 d 20 h  4 m	Data: 1.584 Tran: 0.007 F: 0.152 B: 0.301 O: 0.244 M: 0.009	Train-MLMAcc=0.631756,	MVRCAccuracy=0.675199,	MLMLossWVC=1.766831,	MVRCLoss=2.443339,	
Rank[  0]Epoch[7] Batch [1200]	Speed: 27.19 samples/s ETA: 0 d 20 h 29 m	Data: 0.021 Tran: 0.007 F: 0.152 B: 0.291 O: 1.872 M: 0.009	Train-MLMAcc=0.631257,	MVRCAccuracy=0.675292,	MLMLossWVC=1.768571,	MVRCLoss=2.443514,	
Rank[  3]Epoch[7] Batch [1200]	Speed: 27.19 samples/s ETA: 0 d 20 h 29 m	Data: 1.564 Tran: 0.007 F: 0.161 B: 0.294 O: 0.317 M: 0.009	Train-MLMAcc=0.631257,	MVRCAccuracy=0.675292,	MLMLossWVC=1.768571,	MVRCLoss=2.443514,	
Rank[  2]Epoch[7] Batch [1200]	Speed: 27.19 samples/s ETA: 0 d 20 h 29 m	Data: 0.048 Tran: 0.007 F: 0.150 B: 0.294 O: 1.843 M: 0.010	Train-MLMAcc=0.631257,	MVRCAccuracy=0.675292,	MLMLossWVC=1.768571,	MVRCLoss=2.443514,	
Rank[  1]Epoch[7] Batch [1200]	Speed: 27.19 samples/s ETA: 0 d 20 h 29 m	Data: 1.040 Tran: 0.008 F: 0.153 B: 0.315 O: 0.828 M: 0.009	Train-MLMAcc=0.631257,	MVRCAccuracy=0.675292,	MLMLossWVC=1.768571,	MVRCLoss=2.443514,	
Rank[  2]Epoch[7] Batch [1300]	Speed: 27.80 samples/s ETA: 0 d 19 h 59 m	Data: 0.009 Tran: 0.007 F: 0.157 B: 0.304 O: 1.816 M: 0.007	Train-MLMAcc=0.631325,	MVRCAccuracy=0.675405,	MLMLossWVC=1.769107,	MVRCLoss=2.443252,	
Rank[  0]Epoch[7] Batch [1300]	Speed: 27.80 samples/s ETA: 0 d 19 h 59 m	Data: 0.009 Tran: 0.007 F: 0.157 B: 0.298 O: 1.822 M: 0.008	Train-MLMAcc=0.631325,	MVRCAccuracy=0.675405,	MLMLossWVC=1.769107,	MVRCLoss=2.443252,	
Rank[  3]Epoch[7] Batch [1300]	Speed: 27.80 samples/s ETA: 0 d 19 h 59 m	Data: 1.760 Tran: 0.008 F: 0.163 B: 0.300 O: 0.065 M: 0.007	Train-MLMAcc=0.631325,	MVRCAccuracy=0.675405,	MLMLossWVC=1.769107,	MVRCLoss=2.443252,	
Rank[  1]Epoch[7] Batch [1300]	Speed: 27.80 samples/s ETA: 0 d 19 h 59 m	Data: 0.836 Tran: 0.009 F: 0.173 B: 0.310 O: 0.964 M: 0.008	Train-MLMAcc=0.631325,	MVRCAccuracy=0.675405,	MLMLossWVC=1.769107,	MVRCLoss=2.443252,	
Rank[  2]Epoch[7] Batch [1400]	Speed: 27.62 samples/s ETA: 0 d 20 h  2 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.332 O: 1.812 M: 0.008	Train-MLMAcc=0.631266,	MVRCAccuracy=0.675537,	MLMLossWVC=1.768809,	MVRCLoss=2.442958,	
Rank[  3]Epoch[7] Batch [1400]	Speed: 27.62 samples/s ETA: 0 d 20 h  2 m	Data: 1.668 Tran: 0.008 F: 0.172 B: 0.297 O: 0.163 M: 0.007	Train-MLMAcc=0.631266,	MVRCAccuracy=0.675537,	MLMLossWVC=1.768809,	MVRCLoss=2.442958,	
Rank[  1]Epoch[7] Batch [1400]	Speed: 27.62 samples/s ETA: 0 d 20 h  2 m	Data: 1.148 Tran: 0.007 F: 0.160 B: 0.302 O: 0.691 M: 0.008	Train-MLMAcc=0.631266,	MVRCAccuracy=0.675537,	MLMLossWVC=1.768809,	MVRCLoss=2.442958,	
Rank[  0]Epoch[7] Batch [1400]	Speed: 27.62 samples/s ETA: 0 d 20 h  2 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.331 O: 1.811 M: 0.008	Train-MLMAcc=0.631266,	MVRCAccuracy=0.675537,	MLMLossWVC=1.768809,	MVRCLoss=2.442958,	
Rank[  0]Epoch[7] Batch [1500]	Speed: 27.54 samples/s ETA: 0 d 20 h  2 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.857 M: 0.009	Train-MLMAcc=0.631347,	MVRCAccuracy=0.675617,	MLMLossWVC=1.768600,	MVRCLoss=2.442847,	
Rank[  2]Epoch[7] Batch [1500]	Speed: 27.54 samples/s ETA: 0 d 20 h  2 m	Data: 0.134 Tran: 0.007 F: 0.150 B: 0.294 O: 1.730 M: 0.008	Train-MLMAcc=0.631347,	MVRCAccuracy=0.675617,	MLMLossWVC=1.768600,	MVRCLoss=2.442847,	
Rank[  3]Epoch[7] Batch [1500]	Speed: 27.54 samples/s ETA: 0 d 20 h  2 m	Data: 1.641 Tran: 0.008 F: 0.166 B: 0.301 O: 0.199 M: 0.008	Train-MLMAcc=0.631347,	MVRCAccuracy=0.675617,	MLMLossWVC=1.768600,	MVRCLoss=2.442847,	
Rank[  1]Epoch[7] Batch [1500]	Speed: 27.54 samples/s ETA: 0 d 20 h  2 m	Data: 1.035 Tran: 0.008 F: 0.170 B: 0.311 O: 0.789 M: 0.009	Train-MLMAcc=0.631347,	MVRCAccuracy=0.675617,	MLMLossWVC=1.768600,	MVRCLoss=2.442847,	
Rank[  3]Epoch[7] Batch [1600]	Speed: 27.65 samples/s ETA: 0 d 19 h 54 m	Data: 1.566 Tran: 0.007 F: 0.166 B: 0.311 O: 0.255 M: 0.008	Train-MLMAcc=0.631530,	MVRCAccuracy=0.675552,	MLMLossWVC=1.768356,	MVRCLoss=2.442785,	
Rank[  1]Epoch[7] Batch [1600]	Speed: 27.65 samples/s ETA: 0 d 19 h 54 m	Data: 1.181 Tran: 0.008 F: 0.163 B: 0.310 O: 0.642 M: 0.009	Train-MLMAcc=0.631530,	MVRCAccuracy=0.675552,	MLMLossWVC=1.768356,	MVRCLoss=2.442785,	
Rank[  2]Epoch[7] Batch [1600]	Speed: 27.65 samples/s ETA: 0 d 19 h 54 m	Data: 0.142 Tran: 0.006 F: 0.156 B: 0.299 O: 1.702 M: 0.008	Train-MLMAcc=0.631530,	MVRCAccuracy=0.675552,	MLMLossWVC=1.768356,	MVRCLoss=2.442785,	
Rank[  0]Epoch[7] Batch [1600]	Speed: 27.65 samples/s ETA: 0 d 19 h 54 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.305 O: 1.833 M: 0.007	Train-MLMAcc=0.631530,	MVRCAccuracy=0.675552,	MLMLossWVC=1.768356,	MVRCLoss=2.442785,	
Rank[  1]Epoch[7] Batch [1700]	Speed: 27.36 samples/s ETA: 0 d 20 h  3 m	Data: 1.339 Tran: 0.010 F: 0.175 B: 0.321 O: 0.485 M: 0.008	Train-MLMAcc=0.631064,	MVRCAccuracy=0.675711,	MLMLossWVC=1.769803,	MVRCLoss=2.442729,	
Rank[  3]Epoch[7] Batch [1700]	Speed: 27.36 samples/s ETA: 0 d 20 h  3 m	Data: 0.908 Tran: 0.007 F: 0.181 B: 0.293 O: 0.941 M: 0.008	Train-MLMAcc=0.631064,	MVRCAccuracy=0.675711,	MLMLossWVC=1.769803,	MVRCLoss=2.442729,	
Rank[  2]Epoch[7] Batch [1700]	Speed: 27.36 samples/s ETA: 0 d 20 h  3 m	Data: 0.008 Tran: 0.007 F: 0.162 B: 0.296 O: 1.859 M: 0.006	Train-MLMAcc=0.631064,	MVRCAccuracy=0.675711,	MLMLossWVC=1.769803,	MVRCLoss=2.442729,	
Rank[  0]Epoch[7] Batch [1700]	Speed: 27.36 samples/s ETA: 0 d 20 h  3 m	Data: 0.009 Tran: 0.007 F: 0.161 B: 0.294 O: 1.858 M: 0.008	Train-MLMAcc=0.631064,	MVRCAccuracy=0.675711,	MLMLossWVC=1.769803,	MVRCLoss=2.442729,	
Rank[  0]Epoch[7] Batch [1800]	Speed: 27.71 samples/s ETA: 0 d 19 h 44 m	Data: 0.102 Tran: 0.007 F: 0.150 B: 0.301 O: 1.741 M: 0.008	Train-MLMAcc=0.631174,	MVRCAccuracy=0.675663,	MLMLossWVC=1.770413,	MVRCLoss=2.443136,	
Rank[  2]Epoch[7] Batch [1800]	Speed: 27.71 samples/s ETA: 0 d 19 h 44 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.303 O: 1.832 M: 0.008	Train-MLMAcc=0.631174,	MVRCAccuracy=0.675663,	MLMLossWVC=1.770413,	MVRCLoss=2.443136,	
Rank[  1]Epoch[7] Batch [1800]	Speed: 27.71 samples/s ETA: 0 d 19 h 44 m	Data: 0.928 Tran: 0.012 F: 0.195 B: 0.315 O: 0.851 M: 0.008	Train-MLMAcc=0.631174,	MVRCAccuracy=0.675663,	MLMLossWVC=1.770413,	MVRCLoss=2.443136,	
Rank[  3]Epoch[7] Batch [1800]	Speed: 27.71 samples/s ETA: 0 d 19 h 44 m	Data: 0.820 Tran: 0.007 F: 0.152 B: 0.301 O: 1.023 M: 0.006	Train-MLMAcc=0.631174,	MVRCAccuracy=0.675663,	MLMLossWVC=1.770413,	MVRCLoss=2.443136,	
Rank[  1]Epoch[7] Batch [1900]	Speed: 27.16 samples/s ETA: 0 d 20 h  3 m	Data: 0.541 Tran: 0.007 F: 0.167 B: 0.304 O: 1.327 M: 0.008	Train-MLMAcc=0.631357,	MVRCAccuracy=0.675722,	MLMLossWVC=1.770041,	MVRCLoss=2.442820,	
Rank[  0]Epoch[7] Batch [1900]	Speed: 27.16 samples/s ETA: 0 d 20 h  3 m	Data: 0.605 Tran: 0.008 F: 0.157 B: 0.292 O: 1.285 M: 0.008	Train-MLMAcc=0.631357,	MVRCAccuracy=0.675722,	MLMLossWVC=1.770041,	MVRCLoss=2.442820,	
Rank[  3]Epoch[7] Batch [1900]	Speed: 27.16 samples/s ETA: 0 d 20 h  3 m	Data: 1.289 Tran: 0.007 F: 0.167 B: 0.295 O: 0.588 M: 0.008	Train-MLMAcc=0.631357,	MVRCAccuracy=0.675722,	MLMLossWVC=1.770041,	MVRCLoss=2.442820,	
Rank[  2]Epoch[7] Batch [1900]	Speed: 27.16 samples/s ETA: 0 d 20 h  3 m	Data: 0.053 Tran: 0.007 F: 0.167 B: 0.301 O: 1.820 M: 0.008	Train-MLMAcc=0.631357,	MVRCAccuracy=0.675722,	MLMLossWVC=1.770041,	MVRCLoss=2.442820,	
Rank[  3]Epoch[7] Batch [2000]	Speed: 27.92 samples/s ETA: 0 d 19 h 27 m	Data: 0.562 Tran: 0.007 F: 0.155 B: 0.292 O: 1.264 M: 0.007	Train-MLMAcc=0.631141,	MVRCAccuracy=0.675827,	MLMLossWVC=1.771582,	MVRCLoss=2.442894,	
Rank[  2]Epoch[7] Batch [2000]	Speed: 27.92 samples/s ETA: 0 d 19 h 27 m	Data: 0.007 Tran: 0.007 F: 0.152 B: 0.297 O: 1.817 M: 0.007	Train-MLMAcc=0.631141,	MVRCAccuracy=0.675827,	MLMLossWVC=1.771582,	MVRCLoss=2.442894,	
Rank[  1]Epoch[7] Batch [2000]	Speed: 27.92 samples/s ETA: 0 d 19 h 27 m	Data: 0.805 Tran: 0.009 F: 0.161 B: 0.303 O: 1.003 M: 0.007	Train-MLMAcc=0.631141,	MVRCAccuracy=0.675827,	MLMLossWVC=1.771582,	MVRCLoss=2.442894,	
Rank[  0]Epoch[7] Batch [2000]	Speed: 27.92 samples/s ETA: 0 d 19 h 27 m	Data: 0.767 Tran: 0.008 F: 0.163 B: 0.301 O: 1.042 M: 0.007	Train-MLMAcc=0.631141,	MVRCAccuracy=0.675827,	MLMLossWVC=1.771582,	MVRCLoss=2.442894,	
Rank[  1]Epoch[7] Batch [2100]	Speed: 27.40 samples/s ETA: 0 d 19 h 45 m	Data: 0.959 Tran: 0.008 F: 0.195 B: 0.312 O: 0.849 M: 0.010	Train-MLMAcc=0.631347,	MVRCAccuracy=0.675856,	MLMLossWVC=1.770831,	MVRCLoss=2.442851,	
Rank[  3]Epoch[7] Batch [2100]	Speed: 27.40 samples/s ETA: 0 d 19 h 45 m	Data: 0.767 Tran: 0.008 F: 0.170 B: 0.295 O: 1.084 M: 0.010	Train-MLMAcc=0.631347,	MVRCAccuracy=0.675856,	MLMLossWVC=1.770831,	MVRCLoss=2.442851,	
Rank[  0]Epoch[7] Batch [2100]	Speed: 27.40 samples/s ETA: 0 d 19 h 45 m	Data: 0.305 Tran: 0.009 F: 0.191 B: 0.307 O: 1.509 M: 0.011	Train-MLMAcc=0.631347,	MVRCAccuracy=0.675856,	MLMLossWVC=1.770831,	MVRCLoss=2.442851,	
Rank[  2]Epoch[7] Batch [2100]	Speed: 27.40 samples/s ETA: 0 d 19 h 45 m	Data: 0.009 Tran: 0.008 F: 0.191 B: 0.309 O: 1.807 M: 0.010	Train-MLMAcc=0.631347,	MVRCAccuracy=0.675856,	MLMLossWVC=1.770831,	MVRCLoss=2.442851,	
Rank[  1]Epoch[7] Batch [2200]	Speed: 27.74 samples/s ETA: 0 d 19 h 27 m	Data: 0.765 Tran: 0.008 F: 0.162 B: 0.328 O: 1.034 M: 0.008	Train-MLMAcc=0.631351,	MVRCAccuracy=0.675963,	MLMLossWVC=1.771071,	MVRCLoss=2.442711,	
Rank[  2]Epoch[7] Batch [2200]	Speed: 27.74 samples/s ETA: 0 d 19 h 27 m	Data: 0.012 Tran: 0.007 F: 0.156 B: 0.295 O: 1.826 M: 0.009	Train-MLMAcc=0.631351,	MVRCAccuracy=0.675963,	MLMLossWVC=1.771071,	MVRCLoss=2.442711,	
Rank[  0]Epoch[7] Batch [2200]	Speed: 27.74 samples/s ETA: 0 d 19 h 27 m	Data: 0.147 Tran: 0.007 F: 0.154 B: 0.290 O: 1.700 M: 0.007	Train-MLMAcc=0.631351,	MVRCAccuracy=0.675963,	MLMLossWVC=1.771071,	MVRCLoss=2.442711,	
Rank[  3]Epoch[7] Batch [2200]	Speed: 27.74 samples/s ETA: 0 d 19 h 27 m	Data: 0.988 Tran: 0.007 F: 0.158 B: 0.292 O: 0.853 M: 0.007	Train-MLMAcc=0.631351,	MVRCAccuracy=0.675963,	MLMLossWVC=1.771071,	MVRCLoss=2.442711,	
Rank[  0]Epoch[7] Batch [2300]	Speed: 28.14 samples/s ETA: 0 d 19 h  6 m	Data: 0.304 Tran: 0.007 F: 0.157 B: 0.315 O: 1.479 M: 0.012	Train-MLMAcc=0.631512,	MVRCAccuracy=0.675973,	MLMLossWVC=1.769268,	MVRCLoss=2.442708,	
Rank[  3]Epoch[7] Batch [2300]	Speed: 28.14 samples/s ETA: 0 d 19 h  6 m	Data: 0.489 Tran: 0.007 F: 0.157 B: 0.317 O: 1.290 M: 0.013	Train-MLMAcc=0.631512,	MVRCAccuracy=0.675973,	MLMLossWVC=1.769268,	MVRCLoss=2.442708,	
Rank[  2]Epoch[7] Batch [2300]	Speed: 28.14 samples/s ETA: 0 d 19 h  6 m	Data: 0.273 Tran: 0.007 F: 0.155 B: 0.296 O: 1.529 M: 0.012	Train-MLMAcc=0.631512,	MVRCAccuracy=0.675973,	MLMLossWVC=1.769268,	MVRCLoss=2.442708,	
Rank[  1]Epoch[7] Batch [2300]	Speed: 28.14 samples/s ETA: 0 d 19 h  6 m	Data: 0.952 Tran: 0.007 F: 0.155 B: 0.300 O: 0.846 M: 0.012	Train-MLMAcc=0.631512,	MVRCAccuracy=0.675973,	MLMLossWVC=1.769268,	MVRCLoss=2.442708,	
Rank[  3]Epoch[7] Batch [2400]	Speed: 27.61 samples/s ETA: 0 d 19 h 24 m	Data: 0.023 Tran: 0.007 F: 0.149 B: 0.294 O: 1.836 M: 0.007	Train-MLMAcc=0.631520,	MVRCAccuracy=0.675971,	MLMLossWVC=1.769093,	MVRCLoss=2.442580,	
Rank[  2]Epoch[7] Batch [2400]	Speed: 27.61 samples/s ETA: 0 d 19 h 24 m	Data: 0.040 Tran: 0.007 F: 0.168 B: 0.298 O: 1.797 M: 0.006	Train-MLMAcc=0.631520,	MVRCAccuracy=0.675971,	MLMLossWVC=1.769093,	MVRCLoss=2.442580,	
Rank[  0]Epoch[7] Batch [2400]	Speed: 27.61 samples/s ETA: 0 d 19 h 24 m	Data: 0.080 Tran: 0.007 F: 0.149 B: 0.294 O: 1.780 M: 0.007	Train-MLMAcc=0.631520,	MVRCAccuracy=0.675971,	MLMLossWVC=1.769093,	MVRCLoss=2.442580,	
Rank[  1]Epoch[7] Batch [2400]	Speed: 27.61 samples/s ETA: 0 d 19 h 24 m	Data: 1.661 Tran: 0.007 F: 0.158 B: 0.306 O: 0.178 M: 0.006	Train-MLMAcc=0.631520,	MVRCAccuracy=0.675971,	MLMLossWVC=1.769093,	MVRCLoss=2.442580,	
Rank[  1]Epoch[7] Batch [2500]	Speed: 27.28 samples/s ETA: 0 d 19 h 35 m	Data: 1.300 Tran: 0.009 F: 0.171 B: 0.331 O: 0.523 M: 0.011	Train-MLMAcc=0.631398,	MVRCAccuracy=0.676000,	MLMLossWVC=1.769552,	MVRCLoss=2.442648,	
Rank[  3]Epoch[7] Batch [2500]	Speed: 27.28 samples/s ETA: 0 d 19 h 35 m	Data: 0.014 Tran: 0.007 F: 0.167 B: 0.290 O: 1.856 M: 0.011	Train-MLMAcc=0.631398,	MVRCAccuracy=0.676000,	MLMLossWVC=1.769552,	MVRCLoss=2.442648,	
Rank[  0]Epoch[7] Batch [2500]	Speed: 27.28 samples/s ETA: 0 d 19 h 35 m	Data: 0.016 Tran: 0.007 F: 0.161 B: 0.292 O: 1.858 M: 0.011	Train-MLMAcc=0.631398,	MVRCAccuracy=0.676000,	MLMLossWVC=1.769552,	MVRCLoss=2.442648,	
Rank[  2]Epoch[7] Batch [2500]	Speed: 27.28 samples/s ETA: 0 d 19 h 35 m	Data: 0.444 Tran: 0.011 F: 0.180 B: 0.304 O: 1.395 M: 0.010	Train-MLMAcc=0.631398,	MVRCAccuracy=0.676000,	MLMLossWVC=1.769552,	MVRCLoss=2.442648,	
Rank[  3]Epoch[7] Batch [2600]	Speed: 28.04 samples/s ETA: 0 d 18 h 59 m	Data: 0.012 Tran: 0.007 F: 0.161 B: 0.292 O: 1.801 M: 0.009	Train-MLMAcc=0.631381,	MVRCAccuracy=0.676014,	MLMLossWVC=1.769540,	MVRCLoss=2.442614,	
Rank[  1]Epoch[7] Batch [2600]	Speed: 28.04 samples/s ETA: 0 d 18 h 59 m	Data: 1.186 Tran: 0.007 F: 0.169 B: 0.306 O: 0.606 M: 0.008	Train-MLMAcc=0.631381,	MVRCAccuracy=0.676014,	MLMLossWVC=1.769540,	MVRCLoss=2.442614,	
Rank[  2]Epoch[7] Batch [2600]	Speed: 28.04 samples/s ETA: 0 d 18 h 59 m	Data: 0.552 Tran: 0.008 F: 0.169 B: 0.304 O: 1.240 M: 0.008	Train-MLMAcc=0.631381,	MVRCAccuracy=0.676014,	MLMLossWVC=1.769540,	MVRCLoss=2.442614,	
Rank[  0]Epoch[7] Batch [2600]	Speed: 28.04 samples/s ETA: 0 d 18 h 59 m	Data: 0.009 Tran: 0.007 F: 0.162 B: 0.294 O: 1.800 M: 0.009	Train-MLMAcc=0.631381,	MVRCAccuracy=0.676014,	MLMLossWVC=1.769540,	MVRCLoss=2.442614,	
Rank[  1]Epoch[7] Batch [2700]	Speed: 27.51 samples/s ETA: 0 d 19 h 17 m	Data: 1.669 Tran: 0.007 F: 0.171 B: 0.309 O: 0.163 M: 0.006	Train-MLMAcc=0.631367,	MVRCAccuracy=0.676014,	MLMLossWVC=1.769990,	MVRCLoss=2.442818,	
Rank[  3]Epoch[7] Batch [2700]	Speed: 27.51 samples/s ETA: 0 d 19 h 17 m	Data: 0.025 Tran: 0.007 F: 0.152 B: 0.295 O: 1.840 M: 0.007	Train-MLMAcc=0.631367,	MVRCAccuracy=0.676014,	MLMLossWVC=1.769990,	MVRCLoss=2.442818,	
Rank[  2]Epoch[7] Batch [2700]	Speed: 27.51 samples/s ETA: 0 d 19 h 17 m	Data: 0.125 Tran: 0.007 F: 0.151 B: 0.298 O: 1.738 M: 0.006	Train-MLMAcc=0.631367,	MVRCAccuracy=0.676014,	MLMLossWVC=1.769990,	MVRCLoss=2.442818,	
Rank[  0]Epoch[7] Batch [2700]	Speed: 27.51 samples/s ETA: 0 d 19 h 17 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.297 O: 1.855 M: 0.007	Train-MLMAcc=0.631367,	MVRCAccuracy=0.676014,	MLMLossWVC=1.769990,	MVRCLoss=2.442818,	
Rank[  1]Epoch[7] Batch [2800]	Speed: 27.72 samples/s ETA: 0 d 19 h  4 m	Data: 1.753 Tran: 0.007 F: 0.168 B: 0.318 O: 0.052 M: 0.010	Train-MLMAcc=0.631340,	MVRCAccuracy=0.676061,	MLMLossWVC=1.770361,	MVRCLoss=2.442729,	
Rank[  3]Epoch[7] Batch [2800]	Speed: 27.72 samples/s ETA: 0 d 19 h  4 m	Data: 0.008 Tran: 0.007 F: 0.157 B: 0.292 O: 1.833 M: 0.010	Train-MLMAcc=0.631340,	MVRCAccuracy=0.676061,	MLMLossWVC=1.770361,	MVRCLoss=2.442729,	
Rank[  2]Epoch[7] Batch [2800]	Speed: 27.72 samples/s ETA: 0 d 19 h  4 m	Data: 0.009 Tran: 0.008 F: 0.157 B: 0.297 O: 1.829 M: 0.008	Train-MLMAcc=0.631340,	MVRCAccuracy=0.676061,	MLMLossWVC=1.770361,	MVRCLoss=2.442729,	
Rank[  0]Epoch[7] Batch [2800]	Speed: 27.72 samples/s ETA: 0 d 19 h  4 m	Data: 0.008 Tran: 0.007 F: 0.158 B: 0.294 O: 1.831 M: 0.009	Train-MLMAcc=0.631340,	MVRCAccuracy=0.676061,	MLMLossWVC=1.770361,	MVRCLoss=2.442729,	
Rank[  3]Epoch[7] Batch [2900]	Speed: 27.62 samples/s ETA: 0 d 19 h  5 m	Data: 0.008 Tran: 0.007 F: 0.155 B: 0.292 O: 1.844 M: 0.009	Train-MLMAcc=0.631281,	MVRCAccuracy=0.676097,	MLMLossWVC=1.770958,	MVRCLoss=2.442612,	
Rank[  1]Epoch[7] Batch [2900]	Speed: 27.62 samples/s ETA: 0 d 19 h  5 m	Data: 1.725 Tran: 0.014 F: 0.201 B: 0.308 O: 0.058 M: 0.010	Train-MLMAcc=0.631281,	MVRCAccuracy=0.676097,	MLMLossWVC=1.770958,	MVRCLoss=2.442612,	
Rank[  0]Epoch[7] Batch [2900]	Speed: 27.62 samples/s ETA: 0 d 19 h  5 m	Data: 0.009 Tran: 0.007 F: 0.156 B: 0.295 O: 1.839 M: 0.009	Train-MLMAcc=0.631281,	MVRCAccuracy=0.676097,	MLMLossWVC=1.770958,	MVRCLoss=2.442612,	
Rank[  2]Epoch[7] Batch [2900]	Speed: 27.62 samples/s ETA: 0 d 19 h  5 m	Data: 0.008 Tran: 0.007 F: 0.157 B: 0.295 O: 1.841 M: 0.008	Train-MLMAcc=0.631281,	MVRCAccuracy=0.676097,	MLMLossWVC=1.770958,	MVRCLoss=2.442612,	
Rank[  2]Epoch[7] Batch [3000]	Speed: 27.41 samples/s ETA: 0 d 19 h  9 m	Data: 0.189 Tran: 0.007 F: 0.158 B: 0.298 O: 1.674 M: 0.006	Train-MLMAcc=0.631486,	MVRCAccuracy=0.676111,	MLMLossWVC=1.770044,	MVRCLoss=2.442626,	
Rank[  3]Epoch[7] Batch [3000]	Speed: 27.41 samples/s ETA: 0 d 19 h  9 m	Data: 0.008 Tran: 0.007 F: 0.158 B: 0.297 O: 1.855 M: 0.008	Train-MLMAcc=0.631486,	MVRCAccuracy=0.676111,	MLMLossWVC=1.770044,	MVRCLoss=2.442626,	
Rank[  0]Epoch[7] Batch [3000]	Speed: 27.41 samples/s ETA: 0 d 19 h  9 m	Data: 0.011 Tran: 0.007 F: 0.157 B: 0.297 O: 1.851 M: 0.008	Train-MLMAcc=0.631486,	MVRCAccuracy=0.676111,	MLMLossWVC=1.770044,	MVRCLoss=2.442626,	
Rank[  1]Epoch[7] Batch [3000]	Speed: 27.41 samples/s ETA: 0 d 19 h  9 m	Data: 1.594 Tran: 0.011 F: 0.173 B: 0.307 O: 0.240 M: 0.008	Train-MLMAcc=0.631486,	MVRCAccuracy=0.676111,	MLMLossWVC=1.770044,	MVRCLoss=2.442626,	
Rank[  0]Epoch[7] Batch [3100]	Speed: 27.90 samples/s ETA: 0 d 18 h 46 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.830 M: 0.007	Train-MLMAcc=0.631490,	MVRCAccuracy=0.676184,	MLMLossWVC=1.769896,	MVRCLoss=2.442885,	
Rank[  1]Epoch[7] Batch [3100]	Speed: 27.90 samples/s ETA: 0 d 18 h 46 m	Data: 1.508 Tran: 0.007 F: 0.154 B: 0.299 O: 0.318 M: 0.007	Train-MLMAcc=0.631490,	MVRCAccuracy=0.676184,	MLMLossWVC=1.769896,	MVRCLoss=2.442885,	
Rank[  2]Epoch[7] Batch [3100]	Speed: 27.90 samples/s ETA: 0 d 18 h 46 m	Data: 0.278 Tran: 0.008 F: 0.162 B: 0.294 O: 1.545 M: 0.006	Train-MLMAcc=0.631490,	MVRCAccuracy=0.676184,	MLMLossWVC=1.769896,	MVRCLoss=2.442885,	
Rank[  3]Epoch[7] Batch [3100]	Speed: 27.90 samples/s ETA: 0 d 18 h 46 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.289 O: 1.832 M: 0.007	Train-MLMAcc=0.631490,	MVRCAccuracy=0.676184,	MLMLossWVC=1.769896,	MVRCLoss=2.442885,	
Rank[  0]Epoch[7] Batch [3200]	Speed: 27.90 samples/s ETA: 0 d 18 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.828 M: 0.007	Train-MLMAcc=0.631378,	MVRCAccuracy=0.676154,	MLMLossWVC=1.770583,	MVRCLoss=2.442841,	
Rank[  1]Epoch[7] Batch [3200]	Speed: 27.90 samples/s ETA: 0 d 18 h 42 m	Data: 1.760 Tran: 0.007 F: 0.162 B: 0.296 O: 0.059 M: 0.008	Train-MLMAcc=0.631378,	MVRCAccuracy=0.676154,	MLMLossWVC=1.770583,	MVRCLoss=2.442841,	
Rank[  3]Epoch[7] Batch [3200]	Speed: 27.90 samples/s ETA: 0 d 18 h 42 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.288 O: 1.831 M: 0.009	Train-MLMAcc=0.631378,	MVRCAccuracy=0.676154,	MLMLossWVC=1.770583,	MVRCLoss=2.442841,	
Rank[  2]Epoch[7] Batch [3200]	Speed: 27.90 samples/s ETA: 0 d 18 h 42 m	Data: 0.014 Tran: 0.007 F: 0.150 B: 0.293 O: 1.822 M: 0.007	Train-MLMAcc=0.631378,	MVRCAccuracy=0.676154,	MLMLossWVC=1.770583,	MVRCLoss=2.442841,	
Rank[  2]Epoch[7] Batch [3300]	Speed: 28.30 samples/s ETA: 0 d 18 h 22 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.294 O: 1.795 M: 0.008	Train-MLMAcc=0.631263,	MVRCAccuracy=0.676136,	MLMLossWVC=1.770982,	MVRCLoss=2.442955,	
Rank[  0]Epoch[7] Batch [3300]	Speed: 28.30 samples/s ETA: 0 d 18 h 22 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.797 M: 0.008	Train-MLMAcc=0.631263,	MVRCAccuracy=0.676136,	MLMLossWVC=1.770982,	MVRCLoss=2.442955,	
Rank[  1]Epoch[7] Batch [3300]	Speed: 28.30 samples/s ETA: 0 d 18 h 22 m	Data: 1.748 Tran: 0.007 F: 0.151 B: 0.298 O: 0.050 M: 0.007	Train-MLMAcc=0.631263,	MVRCAccuracy=0.676136,	MLMLossWVC=1.770982,	MVRCLoss=2.442955,	
Rank[  3]Epoch[7] Batch [3300]	Speed: 28.30 samples/s ETA: 0 d 18 h 22 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.798 M: 0.007	Train-MLMAcc=0.631263,	MVRCAccuracy=0.676136,	MLMLossWVC=1.770982,	MVRCLoss=2.442955,	
Rank[  2]Epoch[7] Batch [3400]	Speed: 28.17 samples/s ETA: 0 d 18 h 23 m	Data: 0.173 Tran: 0.007 F: 0.151 B: 0.295 O: 1.638 M: 0.007	Train-MLMAcc=0.631060,	MVRCAccuracy=0.676147,	MLMLossWVC=1.771597,	MVRCLoss=2.442941,	
Rank[  1]Epoch[7] Batch [3400]	Speed: 28.17 samples/s ETA: 0 d 18 h 23 m	Data: 1.593 Tran: 0.007 F: 0.151 B: 0.299 O: 0.214 M: 0.007	Train-MLMAcc=0.631060,	MVRCAccuracy=0.676147,	MLMLossWVC=1.771597,	MVRCLoss=2.442941,	
Rank[  0]Epoch[7] Batch [3400]	Speed: 28.17 samples/s ETA: 0 d 18 h 23 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.293 O: 1.805 M: 0.007	Train-MLMAcc=0.631060,	MVRCAccuracy=0.676147,	MLMLossWVC=1.771597,	MVRCLoss=2.442941,	
Rank[  3]Epoch[7] Batch [3400]	Speed: 28.17 samples/s ETA: 0 d 18 h 23 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.290 O: 1.811 M: 0.006	Train-MLMAcc=0.631060,	MVRCAccuracy=0.676147,	MLMLossWVC=1.771597,	MVRCLoss=2.442941,	
Rank[  0]Epoch[7] Batch [3500]	Speed: 27.99 samples/s ETA: 0 d 18 h 27 m	Data: 0.215 Tran: 0.007 F: 0.149 B: 0.291 O: 1.617 M: 0.006	Train-MLMAcc=0.631125,	MVRCAccuracy=0.676166,	MLMLossWVC=1.771355,	MVRCLoss=2.442914,	
Rank[  2]Epoch[7] Batch [3500]	Speed: 27.99 samples/s ETA: 0 d 18 h 27 m	Data: 0.563 Tran: 0.007 F: 0.149 B: 0.293 O: 1.268 M: 0.006	Train-MLMAcc=0.631125,	MVRCAccuracy=0.676166,	MLMLossWVC=1.771355,	MVRCLoss=2.442914,	
Rank[  1]Epoch[7] Batch [3500]	Speed: 27.99 samples/s ETA: 0 d 18 h 27 m	Data: 1.163 Tran: 0.007 F: 0.151 B: 0.298 O: 0.662 M: 0.006	Train-MLMAcc=0.631125,	MVRCAccuracy=0.676166,	MLMLossWVC=1.771355,	MVRCLoss=2.442914,	
Rank[  3]Epoch[7] Batch [3500]	Speed: 27.99 samples/s ETA: 0 d 18 h 27 m	Data: 0.070 Tran: 0.007 F: 0.150 B: 0.292 O: 1.760 M: 0.006	Train-MLMAcc=0.631125,	MVRCAccuracy=0.676166,	MLMLossWVC=1.771355,	MVRCLoss=2.442914,	
Rank[  0]Epoch[7] Batch [3600]	Speed: 28.02 samples/s ETA: 0 d 18 h 22 m	Data: 0.499 Tran: 0.007 F: 0.150 B: 0.292 O: 1.329 M: 0.006	Train-MLMAcc=0.631188,	MVRCAccuracy=0.676249,	MLMLossWVC=1.770990,	MVRCLoss=2.442692,	
Rank[  1]Epoch[7] Batch [3600]	Speed: 28.02 samples/s ETA: 0 d 18 h 22 m	Data: 0.127 Tran: 0.007 F: 0.150 B: 0.298 O: 1.694 M: 0.005	Train-MLMAcc=0.631188,	MVRCAccuracy=0.676249,	MLMLossWVC=1.770990,	MVRCLoss=2.442692,	
Rank[  3]Epoch[7] Batch [3600]	Speed: 28.02 samples/s ETA: 0 d 18 h 22 m	Data: 0.023 Tran: 0.008 F: 0.149 B: 0.290 O: 1.807 M: 0.006	Train-MLMAcc=0.631188,	MVRCAccuracy=0.676249,	MLMLossWVC=1.770990,	MVRCLoss=2.442692,	
Rank[  2]Epoch[7] Batch [3600]	Speed: 28.02 samples/s ETA: 0 d 18 h 22 m	Data: 1.642 Tran: 0.007 F: 0.151 B: 0.294 O: 0.183 M: 0.007	Train-MLMAcc=0.631188,	MVRCAccuracy=0.676249,	MLMLossWVC=1.770990,	MVRCLoss=2.442692,	
Rank[  0]Epoch[7] Batch [3700]	Speed: 28.15 samples/s ETA: 0 d 18 h 13 m	Data: 0.185 Tran: 0.007 F: 0.150 B: 0.292 O: 1.631 M: 0.009	Train-MLMAcc=0.631168,	MVRCAccuracy=0.676281,	MLMLossWVC=1.771236,	MVRCLoss=2.442674,	
Rank[  1]Epoch[7] Batch [3700]	Speed: 28.15 samples/s ETA: 0 d 18 h 13 m	Data: 0.291 Tran: 0.007 F: 0.149 B: 0.295 O: 1.522 M: 0.008	Train-MLMAcc=0.631168,	MVRCAccuracy=0.676281,	MLMLossWVC=1.771236,	MVRCLoss=2.442674,	
Rank[  2]Epoch[7] Batch [3700]	Speed: 28.15 samples/s ETA: 0 d 18 h 13 m	Data: 1.474 Tran: 0.007 F: 0.151 B: 0.296 O: 0.340 M: 0.005	Train-MLMAcc=0.631168,	MVRCAccuracy=0.676281,	MLMLossWVC=1.771236,	MVRCLoss=2.442674,	
Rank[  3]Epoch[7] Batch [3700]	Speed: 28.15 samples/s ETA: 0 d 18 h 13 m	Data: 0.041 Tran: 0.007 F: 0.149 B: 0.289 O: 1.778 M: 0.009	Train-MLMAcc=0.631168,	MVRCAccuracy=0.676281,	MLMLossWVC=1.771236,	MVRCLoss=2.442674,	
Rank[  0]Epoch[7] Batch [3800]	Speed: 25.21 samples/s ETA: 0 d 20 h 16 m	Data: 0.971 Tran: 0.007 F: 0.171 B: 0.334 O: 1.042 M: 0.011	Train-MLMAcc=0.631134,	MVRCAccuracy=0.676246,	MLMLossWVC=1.771583,	MVRCLoss=2.442670,	
Rank[  3]Epoch[7] Batch [3800]	Speed: 25.21 samples/s ETA: 0 d 20 h 16 m	Data: 0.931 Tran: 0.012 F: 0.222 B: 0.319 O: 1.041 M: 0.011	Train-MLMAcc=0.631134,	MVRCAccuracy=0.676246,	MLMLossWVC=1.771583,	MVRCLoss=2.442670,	
Rank[  2]Epoch[7] Batch [3800]	Speed: 25.21 samples/s ETA: 0 d 20 h 16 m	Data: 1.049 Tran: 0.008 F: 0.177 B: 0.332 O: 0.959 M: 0.011	Train-MLMAcc=0.631134,	MVRCAccuracy=0.676246,	MLMLossWVC=1.771583,	MVRCLoss=2.442670,	
Rank[  1]Epoch[7] Batch [3800]	Speed: 25.21 samples/s ETA: 0 d 20 h 16 m	Data: 0.236 Tran: 0.007 F: 0.173 B: 0.336 O: 1.774 M: 0.011	Train-MLMAcc=0.631134,	MVRCAccuracy=0.676246,	MLMLossWVC=1.771583,	MVRCLoss=2.442670,	
Rank[  1]Epoch[7] Batch [3900]	Speed: 27.34 samples/s ETA: 0 d 18 h 37 m	Data: 0.009 Tran: 0.007 F: 0.157 B: 0.315 O: 1.838 M: 0.012	Train-MLMAcc=0.631020,	MVRCAccuracy=0.676253,	MLMLossWVC=1.772508,	MVRCLoss=2.442576,	
Rank[  2]Epoch[7] Batch [3900]	Speed: 27.34 samples/s ETA: 0 d 18 h 37 m	Data: 0.758 Tran: 0.007 F: 0.161 B: 0.313 O: 1.086 M: 0.012	Train-MLMAcc=0.631020,	MVRCAccuracy=0.676253,	MLMLossWVC=1.772508,	MVRCLoss=2.442576,	
Rank[  3]Epoch[7] Batch [3900]	Speed: 27.34 samples/s ETA: 0 d 18 h 37 m	Data: 0.936 Tran: 0.008 F: 0.175 B: 0.307 O: 0.900 M: 0.012	Train-MLMAcc=0.631020,	MVRCAccuracy=0.676253,	MLMLossWVC=1.772508,	MVRCLoss=2.442576,	
Rank[  0]Epoch[7] Batch [3900]	Speed: 27.34 samples/s ETA: 0 d 18 h 37 m	Data: 1.218 Tran: 0.007 F: 0.164 B: 0.319 O: 0.617 M: 0.012	Train-MLMAcc=0.631020,	MVRCAccuracy=0.676253,	MLMLossWVC=1.772508,	MVRCLoss=2.442576,	
Rank[  2]Epoch[7] Batch [4000]	Speed: 25.60 samples/s ETA: 0 d 19 h 49 m	Data: 0.450 Tran: 0.009 F: 0.209 B: 0.334 O: 1.486 M: 0.011	Train-MLMAcc=0.631005,	MVRCAccuracy=0.676203,	MLMLossWVC=1.772520,	MVRCLoss=2.442698,	
Rank[  0]Epoch[7] Batch [4000]	Speed: 25.60 samples/s ETA: 0 d 19 h 49 m	Data: 1.206 Tran: 0.010 F: 0.198 B: 0.316 O: 0.757 M: 0.011	Train-MLMAcc=0.631005,	MVRCAccuracy=0.676203,	MLMLossWVC=1.772520,	MVRCLoss=2.442698,	
Rank[  3]Epoch[7] Batch [4000]	Speed: 25.60 samples/s ETA: 0 d 19 h 49 m	Data: 0.785 Tran: 0.009 F: 0.176 B: 0.316 O: 1.203 M: 0.010	Train-MLMAcc=0.631005,	MVRCAccuracy=0.676203,	MLMLossWVC=1.772520,	MVRCLoss=2.442698,	
Rank[  1]Epoch[7] Batch [4000]	Speed: 25.60 samples/s ETA: 0 d 19 h 49 m	Data: 0.013 Tran: 0.007 F: 0.170 B: 0.317 O: 1.980 M: 0.011	Train-MLMAcc=0.631005,	MVRCAccuracy=0.676203,	MLMLossWVC=1.772520,	MVRCLoss=2.442698,	
Rank[  2]Epoch[7] Batch [4100]	Speed: 27.94 samples/s ETA: 0 d 18 h  6 m	Data: 0.783 Tran: 0.007 F: 0.151 B: 0.295 O: 1.047 M: 0.008	Train-MLMAcc=0.630985,	MVRCAccuracy=0.676228,	MLMLossWVC=1.772841,	MVRCLoss=2.442712,	
Rank[  1]Epoch[7] Batch [4100]	Speed: 27.94 samples/s ETA: 0 d 18 h  6 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.298 O: 1.820 M: 0.009	Train-MLMAcc=0.630985,	MVRCAccuracy=0.676228,	MLMLossWVC=1.772841,	MVRCLoss=2.442712,	
Rank[  0]Epoch[7] Batch [4100]	Speed: 27.94 samples/s ETA: 0 d 18 h  6 m	Data: 0.585 Tran: 0.007 F: 0.151 B: 0.292 O: 1.249 M: 0.006	Train-MLMAcc=0.630985,	MVRCAccuracy=0.676228,	MLMLossWVC=1.772841,	MVRCLoss=2.442712,	
Rank[  3]Epoch[7] Batch [4100]	Speed: 27.94 samples/s ETA: 0 d 18 h  6 m	Data: 1.157 Tran: 0.007 F: 0.150 B: 0.291 O: 0.678 M: 0.008	Train-MLMAcc=0.630985,	MVRCAccuracy=0.676228,	MLMLossWVC=1.772841,	MVRCLoss=2.442712,	
Rank[  2]Epoch[7] Batch [4200]	Speed: 23.32 samples/s ETA: 0 d 21 h 36 m	Data: 1.164 Tran: 0.016 F: 0.228 B: 0.376 O: 0.933 M: 0.024	Train-MLMAcc=0.630876,	MVRCAccuracy=0.676268,	MLMLossWVC=1.773391,	MVRCLoss=2.442533,	
Rank[  3]Epoch[7] Batch [4200]	Speed: 23.32 samples/s ETA: 0 d 21 h 36 m	Data: 0.694 Tran: 0.009 F: 0.199 B: 0.363 O: 1.451 M: 0.025	Train-MLMAcc=0.630876,	MVRCAccuracy=0.676268,	MLMLossWVC=1.773391,	MVRCLoss=2.442533,	
Rank[  0]Epoch[7] Batch [4200]	Speed: 23.32 samples/s ETA: 0 d 21 h 36 m	Data: 1.464 Tran: 0.009 F: 0.252 B: 0.387 O: 0.604 M: 0.024	Train-MLMAcc=0.630876,	MVRCAccuracy=0.676268,	MLMLossWVC=1.773391,	MVRCLoss=2.442533,	
Rank[  1]Epoch[7] Batch [4200]	Speed: 23.32 samples/s ETA: 0 d 21 h 36 m	Data: 0.014 Tran: 0.007 F: 0.187 B: 0.373 O: 2.135 M: 0.024	Train-MLMAcc=0.630876,	MVRCAccuracy=0.676268,	MLMLossWVC=1.773391,	MVRCLoss=2.442533,	
Rank[  0]Epoch[7] Batch [4300]	Speed: 24.55 samples/s ETA: 0 d 20 h 27 m	Data: 0.941 Tran: 0.008 F: 0.209 B: 0.382 O: 1.040 M: 0.023	Train-MLMAcc=0.630848,	MVRCAccuracy=0.676273,	MLMLossWVC=1.773391,	MVRCLoss=2.442534,	
Rank[  1]Epoch[7] Batch [4300]	Speed: 24.55 samples/s ETA: 0 d 20 h 27 m	Data: 0.016 Tran: 0.007 F: 0.187 B: 0.363 O: 2.008 M: 0.022	Train-MLMAcc=0.630848,	MVRCAccuracy=0.676273,	MLMLossWVC=1.773391,	MVRCLoss=2.442534,	
Rank[  3]Epoch[7] Batch [4300]	Speed: 24.55 samples/s ETA: 0 d 20 h 27 m	Data: 1.434 Tran: 0.009 F: 0.225 B: 0.394 O: 0.518 M: 0.023	Train-MLMAcc=0.630848,	MVRCAccuracy=0.676273,	MLMLossWVC=1.773391,	MVRCLoss=2.442534,	
Rank[  2]Epoch[7] Batch [4300]	Speed: 24.55 samples/s ETA: 0 d 20 h 27 m	Data: 1.290 Tran: 0.008 F: 0.215 B: 0.377 O: 0.693 M: 0.021	Train-MLMAcc=0.630848,	MVRCAccuracy=0.676273,	MLMLossWVC=1.773391,	MVRCLoss=2.442534,	
Rank[  0]Epoch[7] Batch [4400]	Speed: 22.14 samples/s ETA: 0 d 22 h 36 m	Data: 1.696 Tran: 0.012 F: 0.275 B: 0.445 O: 0.407 M: 0.044	Train-MLMAcc=0.630866,	MVRCAccuracy=0.676236,	MLMLossWVC=1.773551,	MVRCLoss=2.442524,	
Rank[  1]Epoch[7] Batch [4400]	Speed: 22.14 samples/s ETA: 0 d 22 h 36 m	Data: 0.019 Tran: 0.009 F: 0.237 B: 0.454 O: 2.117 M: 0.044	Train-MLMAcc=0.630866,	MVRCAccuracy=0.676236,	MLMLossWVC=1.773551,	MVRCLoss=2.442524,	
Rank[  3]Epoch[7] Batch [4400]	Speed: 22.14 samples/s ETA: 0 d 22 h 36 m	Data: 1.419 Tran: 0.009 F: 0.261 B: 0.417 O: 0.728 M: 0.044	Train-MLMAcc=0.630866,	MVRCAccuracy=0.676236,	MLMLossWVC=1.773551,	MVRCLoss=2.442524,	
Rank[  2]Epoch[7] Batch [4400]	Speed: 22.14 samples/s ETA: 0 d 22 h 36 m	Data: 1.593 Tran: 0.012 F: 0.252 B: 0.455 O: 0.524 M: 0.044	Train-MLMAcc=0.630866,	MVRCAccuracy=0.676236,	MLMLossWVC=1.773551,	MVRCLoss=2.442524,	
Rank[  3]Epoch[7] Batch [4500]	Speed: 22.33 samples/s ETA: 0 d 22 h 19 m	Data: 0.900 Tran: 0.012 F: 0.259 B: 0.430 O: 1.229 M: 0.030	Train-MLMAcc=0.630841,	MVRCAccuracy=0.676247,	MLMLossWVC=1.773368,	MVRCLoss=2.442635,	
Rank[  1]Epoch[7] Batch [4500]	Speed: 22.33 samples/s ETA: 0 d 22 h 19 m	Data: 0.023 Tran: 0.010 F: 0.249 B: 0.444 O: 2.104 M: 0.030	Train-MLMAcc=0.630841,	MVRCAccuracy=0.676247,	MLMLossWVC=1.773368,	MVRCLoss=2.442635,	
Rank[  2]Epoch[7] Batch [4500]	Speed: 22.33 samples/s ETA: 0 d 22 h 19 m	Data: 1.077 Tran: 0.015 F: 0.251 B: 0.428 O: 1.059 M: 0.031	Train-MLMAcc=0.630841,	MVRCAccuracy=0.676247,	MLMLossWVC=1.773368,	MVRCLoss=2.442635,	
Rank[  0]Epoch[7] Batch [4500]	Speed: 22.33 samples/s ETA: 0 d 22 h 19 m	Data: 1.979 Tran: 0.017 F: 0.290 B: 0.457 O: 0.086 M: 0.030	Train-MLMAcc=0.630841,	MVRCAccuracy=0.676247,	MLMLossWVC=1.773368,	MVRCLoss=2.442635,	
Rank[  3]Epoch[7] Batch [4600]	Speed: 27.74 samples/s ETA: 0 d 17 h 54 m	Data: 1.048 Tran: 0.007 F: 0.162 B: 0.302 O: 0.778 M: 0.008	Train-MLMAcc=0.630849,	MVRCAccuracy=0.676258,	MLMLossWVC=1.773501,	MVRCLoss=2.442569,	
Rank[  0]Epoch[7] Batch [4600]	Speed: 27.74 samples/s ETA: 0 d 17 h 54 m	Data: 1.774 Tran: 0.007 F: 0.160 B: 0.299 O: 0.059 M: 0.007	Train-MLMAcc=0.630849,	MVRCAccuracy=0.676258,	MLMLossWVC=1.773501,	MVRCLoss=2.442569,	
Rank[  2]Epoch[7] Batch [4600]	Speed: 27.74 samples/s ETA: 0 d 17 h 54 m	Data: 0.746 Tran: 0.007 F: 0.159 B: 0.299 O: 1.087 M: 0.008	Train-MLMAcc=0.630849,	MVRCAccuracy=0.676258,	MLMLossWVC=1.773501,	MVRCLoss=2.442569,	
Rank[  1]Epoch[7] Batch [4600]	Speed: 27.74 samples/s ETA: 0 d 17 h 54 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.304 O: 1.825 M: 0.008	Train-MLMAcc=0.630849,	MVRCAccuracy=0.676258,	MLMLossWVC=1.773501,	MVRCLoss=2.442569,	
Rank[  0]Epoch[7] Batch [4700]	Speed: 27.71 samples/s ETA: 0 d 17 h 52 m	Data: 1.769 Tran: 0.007 F: 0.155 B: 0.293 O: 0.079 M: 0.006	Train-MLMAcc=0.630905,	MVRCAccuracy=0.676292,	MLMLossWVC=1.773029,	MVRCLoss=2.442592,	
Rank[  3]Epoch[7] Batch [4700]	Speed: 27.71 samples/s ETA: 0 d 17 h 52 m	Data: 0.594 Tran: 0.008 F: 0.157 B: 0.297 O: 1.244 M: 0.008	Train-MLMAcc=0.630905,	MVRCAccuracy=0.676292,	MLMLossWVC=1.773029,	MVRCLoss=2.442592,	
Rank[  2]Epoch[7] Batch [4700]	Speed: 27.71 samples/s ETA: 0 d 17 h 52 m	Data: 0.327 Tran: 0.007 F: 0.151 B: 0.295 O: 1.521 M: 0.008	Train-MLMAcc=0.630905,	MVRCAccuracy=0.676292,	MLMLossWVC=1.773029,	MVRCLoss=2.442592,	
Rank[  1]Epoch[7] Batch [4700]	Speed: 27.71 samples/s ETA: 0 d 17 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.839 M: 0.007	Train-MLMAcc=0.630905,	MVRCAccuracy=0.676292,	MLMLossWVC=1.773029,	MVRCLoss=2.442592,	
Rank[  1]Epoch[7] Batch [4800]	Speed: 28.26 samples/s ETA: 0 d 17 h 27 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.300 O: 1.791 M: 0.008	Train-MLMAcc=0.631012,	MVRCAccuracy=0.676344,	MLMLossWVC=1.772722,	MVRCLoss=2.442536,	
Rank[  2]Epoch[7] Batch [4800]	Speed: 28.26 samples/s ETA: 0 d 17 h 27 m	Data: 0.444 Tran: 0.008 F: 0.151 B: 0.295 O: 1.359 M: 0.009	Train-MLMAcc=0.631012,	MVRCAccuracy=0.676344,	MLMLossWVC=1.772722,	MVRCLoss=2.442536,	
Rank[  3]Epoch[7] Batch [4800]	Speed: 28.26 samples/s ETA: 0 d 17 h 27 m	Data: 0.081 Tran: 0.008 F: 0.149 B: 0.289 O: 1.730 M: 0.007	Train-MLMAcc=0.631012,	MVRCAccuracy=0.676344,	MLMLossWVC=1.772722,	MVRCLoss=2.442536,	
Rank[  0]Epoch[7] Batch [4800]	Speed: 28.26 samples/s ETA: 0 d 17 h 27 m	Data: 1.701 Tran: 0.007 F: 0.150 B: 0.291 O: 0.106 M: 0.010	Train-MLMAcc=0.631012,	MVRCAccuracy=0.676344,	MLMLossWVC=1.772722,	MVRCLoss=2.442536,	
Rank[  3]Epoch[7] Batch [4900]	Speed: 27.92 samples/s ETA: 0 d 17 h 36 m	Data: 0.534 Tran: 0.008 F: 0.149 B: 0.290 O: 1.301 M: 0.009	Train-MLMAcc=0.631009,	MVRCAccuracy=0.676363,	MLMLossWVC=1.772824,	MVRCLoss=2.442558,	
Rank[  2]Epoch[7] Batch [4900]	Speed: 27.92 samples/s ETA: 0 d 17 h 36 m	Data: 0.095 Tran: 0.007 F: 0.150 B: 0.295 O: 1.735 M: 0.008	Train-MLMAcc=0.631009,	MVRCAccuracy=0.676363,	MLMLossWVC=1.772824,	MVRCLoss=2.442558,	
Rank[  0]Epoch[7] Batch [4900]	Speed: 27.92 samples/s ETA: 0 d 17 h 36 m	Data: 1.764 Tran: 0.007 F: 0.150 B: 0.291 O: 0.070 M: 0.009	Train-MLMAcc=0.631009,	MVRCAccuracy=0.676363,	MLMLossWVC=1.772824,	MVRCLoss=2.442558,	
Rank[  1]Epoch[7] Batch [4900]	Speed: 27.92 samples/s ETA: 0 d 17 h 36 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.821 M: 0.008	Train-MLMAcc=0.631009,	MVRCAccuracy=0.676363,	MLMLossWVC=1.772824,	MVRCLoss=2.442558,	
Rank[  3]Epoch[7] Batch [5000]	Speed: 28.19 samples/s ETA: 0 d 17 h 22 m	Data: 1.112 Tran: 0.007 F: 0.150 B: 0.289 O: 0.705 M: 0.007	Train-MLMAcc=0.631047,	MVRCAccuracy=0.676345,	MLMLossWVC=1.772528,	MVRCLoss=2.442611,	
Rank[  1]Epoch[7] Batch [5000]	Speed: 28.19 samples/s ETA: 0 d 17 h 22 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.799 M: 0.007	Train-MLMAcc=0.631047,	MVRCAccuracy=0.676345,	MLMLossWVC=1.772528,	MVRCLoss=2.442611,	
Rank[  0]Epoch[7] Batch [5000]	Speed: 28.19 samples/s ETA: 0 d 17 h 22 m	Data: 1.452 Tran: 0.007 F: 0.151 B: 0.293 O: 0.361 M: 0.006	Train-MLMAcc=0.631047,	MVRCAccuracy=0.676345,	MLMLossWVC=1.772528,	MVRCLoss=2.442611,	
Rank[  2]Epoch[7] Batch [5000]	Speed: 28.19 samples/s ETA: 0 d 17 h 22 m	Data: 0.079 Tran: 0.007 F: 0.149 B: 0.292 O: 1.736 M: 0.007	Train-MLMAcc=0.631047,	MVRCAccuracy=0.676345,	MLMLossWVC=1.772528,	MVRCLoss=2.442611,	
Rank[  2]Epoch[7] Batch [5100]	Speed: 23.49 samples/s ETA: 0 d 20 h 46 m	Data: 0.181 Tran: 0.009 F: 0.221 B: 0.406 O: 1.879 M: 0.025	Train-MLMAcc=0.631049,	MVRCAccuracy=0.676338,	MLMLossWVC=1.772345,	MVRCLoss=2.442636,	
Rank[  1]Epoch[7] Batch [5100]	Speed: 23.49 samples/s ETA: 0 d 20 h 46 m	Data: 0.021 Tran: 0.011 F: 0.218 B: 0.413 O: 2.027 M: 0.030	Train-MLMAcc=0.631049,	MVRCAccuracy=0.676338,	MLMLossWVC=1.772345,	MVRCLoss=2.442636,	
Rank[  0]Epoch[7] Batch [5100]	Speed: 23.49 samples/s ETA: 0 d 20 h 46 m	Data: 1.649 Tran: 0.014 F: 0.281 B: 0.417 O: 0.332 M: 0.028	Train-MLMAcc=0.631049,	MVRCAccuracy=0.676338,	MLMLossWVC=1.772345,	MVRCLoss=2.442636,	
Rank[  3]Epoch[7] Batch [5100]	Speed: 23.49 samples/s ETA: 0 d 20 h 46 m	Data: 1.205 Tran: 0.012 F: 0.246 B: 0.409 O: 0.819 M: 0.030	Train-MLMAcc=0.631049,	MVRCAccuracy=0.676338,	MLMLossWVC=1.772345,	MVRCLoss=2.442636,	
Rank[  1]Epoch[7] Batch [5200]	Speed: 23.53 samples/s ETA: 0 d 20 h 39 m	Data: 0.015 Tran: 0.007 F: 0.222 B: 0.404 O: 2.040 M: 0.026	Train-MLMAcc=0.631053,	MVRCAccuracy=0.676341,	MLMLossWVC=1.772462,	MVRCLoss=2.442720,	
Rank[  3]Epoch[7] Batch [5200]	Speed: 23.53 samples/s ETA: 0 d 20 h 39 m	Data: 1.602 Tran: 0.008 F: 0.226 B: 0.401 O: 0.452 M: 0.026	Train-MLMAcc=0.631053,	MVRCAccuracy=0.676341,	MLMLossWVC=1.772462,	MVRCLoss=2.442720,	
Rank[  0]Epoch[7] Batch [5200]	Speed: 23.53 samples/s ETA: 0 d 20 h 39 m	Data: 1.926 Tran: 0.010 F: 0.243 B: 0.412 O: 0.098 M: 0.026	Train-MLMAcc=0.631053,	MVRCAccuracy=0.676341,	MLMLossWVC=1.772462,	MVRCLoss=2.442720,	
Rank[  2]Epoch[7] Batch [5200]	Speed: 23.53 samples/s ETA: 0 d 20 h 39 m	Data: 0.030 Tran: 0.007 F: 0.216 B: 0.401 O: 2.034 M: 0.027	Train-MLMAcc=0.631053,	MVRCAccuracy=0.676341,	MLMLossWVC=1.772462,	MVRCLoss=2.442720,	
Rank[  2]Epoch[7] Batch [5300]	Speed: 27.94 samples/s ETA: 0 d 17 h 20 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.293 O: 1.824 M: 0.007	Train-MLMAcc=0.631086,	MVRCAccuracy=0.676349,	MLMLossWVC=1.772474,	MVRCLoss=2.442884,	
Rank[  1]Epoch[7] Batch [5300]	Speed: 27.94 samples/s ETA: 0 d 17 h 20 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.819 M: 0.007	Train-MLMAcc=0.631086,	MVRCAccuracy=0.676349,	MLMLossWVC=1.772474,	MVRCLoss=2.442884,	
Rank[  3]Epoch[7] Batch [5300]	Speed: 27.94 samples/s ETA: 0 d 17 h 20 m	Data: 1.380 Tran: 0.007 F: 0.150 B: 0.289 O: 0.456 M: 0.007	Train-MLMAcc=0.631086,	MVRCAccuracy=0.676349,	MLMLossWVC=1.772474,	MVRCLoss=2.442884,	
Rank[  0]Epoch[7] Batch [5300]	Speed: 27.94 samples/s ETA: 0 d 17 h 20 m	Data: 1.611 Tran: 0.007 F: 0.150 B: 0.290 O: 0.226 M: 0.006	Train-MLMAcc=0.631086,	MVRCAccuracy=0.676349,	MLMLossWVC=1.772474,	MVRCLoss=2.442884,	
Rank[  1]Epoch[7] Batch [5400]	Speed: 28.16 samples/s ETA: 0 d 17 h  8 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.805 M: 0.005	Train-MLMAcc=0.630978,	MVRCAccuracy=0.676333,	MLMLossWVC=1.772567,	MVRCLoss=2.442840,	
Rank[  0]Epoch[7] Batch [5400]	Speed: 28.16 samples/s ETA: 0 d 17 h  8 m	Data: 1.760 Tran: 0.007 F: 0.151 B: 0.293 O: 0.054 M: 0.007	Train-MLMAcc=0.630978,	MVRCAccuracy=0.676333,	MLMLossWVC=1.772567,	MVRCLoss=2.442840,	
Rank[  3]Epoch[7] Batch [5400]	Speed: 28.16 samples/s ETA: 0 d 17 h  8 m	Data: 0.886 Tran: 0.007 F: 0.150 B: 0.289 O: 0.931 M: 0.008	Train-MLMAcc=0.630978,	MVRCAccuracy=0.676333,	MLMLossWVC=1.772567,	MVRCLoss=2.442840,	
Rank[  2]Epoch[7] Batch [5400]	Speed: 28.16 samples/s ETA: 0 d 17 h  8 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.805 M: 0.008	Train-MLMAcc=0.630978,	MVRCAccuracy=0.676333,	MLMLossWVC=1.772567,	MVRCLoss=2.442840,	
Rank[  1]Epoch[7] Batch [5500]	Speed: 28.15 samples/s ETA: 0 d 17 h  4 m	Data: 0.008 Tran: 0.007 F: 0.165 B: 0.306 O: 1.780 M: 0.006	Train-MLMAcc=0.630998,	MVRCAccuracy=0.676324,	MLMLossWVC=1.772251,	MVRCLoss=2.442855,	
Rank[  3]Epoch[7] Batch [5500]	Speed: 28.15 samples/s ETA: 0 d 17 h  4 m	Data: 0.470 Tran: 0.007 F: 0.152 B: 0.289 O: 1.347 M: 0.007	Train-MLMAcc=0.630998,	MVRCAccuracy=0.676324,	MLMLossWVC=1.772251,	MVRCLoss=2.442855,	
Rank[  0]Epoch[7] Batch [5500]	Speed: 28.15 samples/s ETA: 0 d 17 h  4 m	Data: 1.726 Tran: 0.013 F: 0.173 B: 0.294 O: 0.061 M: 0.006	Train-MLMAcc=0.630998,	MVRCAccuracy=0.676324,	MLMLossWVC=1.772251,	MVRCLoss=2.442855,	
Rank[  2]Epoch[7] Batch [5500]	Speed: 28.15 samples/s ETA: 0 d 17 h  4 m	Data: 0.008 Tran: 0.007 F: 0.166 B: 0.302 O: 1.784 M: 0.006	Train-MLMAcc=0.630998,	MVRCAccuracy=0.676324,	MLMLossWVC=1.772251,	MVRCLoss=2.442855,	
Rank[  1]Epoch[7] Batch [5600]	Speed: 27.55 samples/s ETA: 0 d 17 h 23 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.854 M: 0.009	Train-MLMAcc=0.631066,	MVRCAccuracy=0.676341,	MLMLossWVC=1.771680,	MVRCLoss=2.442850,	
Rank[  3]Epoch[7] Batch [5600]	Speed: 27.55 samples/s ETA: 0 d 17 h 23 m	Data: 0.754 Tran: 0.007 F: 0.151 B: 0.290 O: 1.114 M: 0.006	Train-MLMAcc=0.631066,	MVRCAccuracy=0.676341,	MLMLossWVC=1.771680,	MVRCLoss=2.442850,	
Rank[  0]Epoch[7] Batch [5600]	Speed: 27.55 samples/s ETA: 0 d 17 h 23 m	Data: 1.809 Tran: 0.007 F: 0.150 B: 0.292 O: 0.054 M: 0.010	Train-MLMAcc=0.631066,	MVRCAccuracy=0.676341,	MLMLossWVC=1.771680,	MVRCLoss=2.442850,	
Rank[  2]Epoch[7] Batch [5600]	Speed: 27.55 samples/s ETA: 0 d 17 h 23 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.856 M: 0.009	Train-MLMAcc=0.631066,	MVRCAccuracy=0.676341,	MLMLossWVC=1.771680,	MVRCLoss=2.442850,	
Rank[  2]Epoch[7] Batch [5700]	Speed: 28.30 samples/s ETA: 0 d 16 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.795 M: 0.008	Train-MLMAcc=0.631091,	MVRCAccuracy=0.676335,	MLMLossWVC=1.771349,	MVRCLoss=2.442809,	
Rank[  0]Epoch[7] Batch [5700]	Speed: 28.30 samples/s ETA: 0 d 16 h 52 m	Data: 1.715 Tran: 0.007 F: 0.150 B: 0.290 O: 0.087 M: 0.011	Train-MLMAcc=0.631091,	MVRCAccuracy=0.676335,	MLMLossWVC=1.771349,	MVRCLoss=2.442809,	
Rank[  1]Epoch[7] Batch [5700]	Speed: 28.30 samples/s ETA: 0 d 16 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.787 M: 0.010	Train-MLMAcc=0.631091,	MVRCAccuracy=0.676335,	MLMLossWVC=1.771349,	MVRCLoss=2.442809,	
Rank[  3]Epoch[7] Batch [5700]	Speed: 28.30 samples/s ETA: 0 d 16 h 52 m	Data: 0.592 Tran: 0.007 F: 0.151 B: 0.291 O: 1.212 M: 0.009	Train-MLMAcc=0.631091,	MVRCAccuracy=0.676335,	MLMLossWVC=1.771349,	MVRCLoss=2.442809,	
Rank[  2]Epoch[7] Batch [5800]	Speed: 28.04 samples/s ETA: 0 d 16 h 57 m	Data: 0.053 Tran: 0.007 F: 0.149 B: 0.292 O: 1.774 M: 0.007	Train-MLMAcc=0.631073,	MVRCAccuracy=0.676349,	MLMLossWVC=1.771302,	MVRCLoss=2.442811,	
Rank[  1]Epoch[7] Batch [5800]	Speed: 28.04 samples/s ETA: 0 d 16 h 57 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.812 M: 0.007	Train-MLMAcc=0.631073,	MVRCAccuracy=0.676349,	MLMLossWVC=1.771302,	MVRCLoss=2.442811,	
Rank[  3]Epoch[7] Batch [5800]	Speed: 28.04 samples/s ETA: 0 d 16 h 57 m	Data: 0.436 Tran: 0.007 F: 0.150 B: 0.292 O: 1.391 M: 0.006	Train-MLMAcc=0.631073,	MVRCAccuracy=0.676349,	MLMLossWVC=1.771302,	MVRCLoss=2.442811,	
Rank[  0]Epoch[7] Batch [5800]	Speed: 28.04 samples/s ETA: 0 d 16 h 57 m	Data: 1.650 Tran: 0.007 F: 0.150 B: 0.292 O: 0.177 M: 0.006	Train-MLMAcc=0.631073,	MVRCAccuracy=0.676349,	MLMLossWVC=1.771302,	MVRCLoss=2.442811,	
Rank[  2]Epoch[7] Batch [5900]	Speed: 26.28 samples/s ETA: 0 d 18 h  1 m	Data: 0.192 Tran: 0.007 F: 0.175 B: 0.334 O: 1.712 M: 0.013	Train-MLMAcc=0.630989,	MVRCAccuracy=0.676329,	MLMLossWVC=1.771618,	MVRCLoss=2.442742,	
Rank[  0]Epoch[7] Batch [5900]	Speed: 26.28 samples/s ETA: 0 d 18 h  1 m	Data: 1.248 Tran: 0.008 F: 0.194 B: 0.347 O: 0.624 M: 0.011	Train-MLMAcc=0.630989,	MVRCAccuracy=0.676329,	MLMLossWVC=1.771618,	MVRCLoss=2.442742,	
Rank[  1]Epoch[7] Batch [5900]	Speed: 26.28 samples/s ETA: 0 d 18 h  1 m	Data: 0.012 Tran: 0.007 F: 0.171 B: 0.339 O: 1.890 M: 0.014	Train-MLMAcc=0.630989,	MVRCAccuracy=0.676329,	MLMLossWVC=1.771618,	MVRCLoss=2.442742,	
Rank[  3]Epoch[7] Batch [5900]	Speed: 26.28 samples/s ETA: 0 d 18 h  1 m	Data: 0.585 Tran: 0.007 F: 0.178 B: 0.329 O: 1.319 M: 0.014	Train-MLMAcc=0.630989,	MVRCAccuracy=0.676329,	MLMLossWVC=1.771618,	MVRCLoss=2.442742,	
Rank[  2]Epoch[7] Batch [6000]	Speed: 27.75 samples/s ETA: 0 d 17 h  0 m	Data: 0.329 Tran: 0.007 F: 0.150 B: 0.294 O: 1.517 M: 0.008	Train-MLMAcc=0.630974,	MVRCAccuracy=0.676340,	MLMLossWVC=1.771948,	MVRCLoss=2.442612,	
Rank[  1]Epoch[7] Batch [6000]	Speed: 27.75 samples/s ETA: 0 d 17 h  0 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.835 M: 0.008	Train-MLMAcc=0.630974,	MVRCAccuracy=0.676340,	MLMLossWVC=1.771948,	MVRCLoss=2.442612,	
Rank[  0]Epoch[7] Batch [6000]	Speed: 27.75 samples/s ETA: 0 d 17 h  0 m	Data: 1.253 Tran: 0.006 F: 0.150 B: 0.291 O: 0.597 M: 0.008	Train-MLMAcc=0.630974,	MVRCAccuracy=0.676340,	MLMLossWVC=1.771948,	MVRCLoss=2.442612,	
Rank[  3]Epoch[7] Batch [6000]	Speed: 27.75 samples/s ETA: 0 d 17 h  0 m	Data: 0.531 Tran: 0.007 F: 0.150 B: 0.290 O: 1.321 M: 0.007	Train-MLMAcc=0.630974,	MVRCAccuracy=0.676340,	MLMLossWVC=1.771948,	MVRCLoss=2.442612,	
Rank[  0]Epoch[7] Batch [6100]	Speed: 28.28 samples/s ETA: 0 d 16 h 37 m	Data: 0.875 Tran: 0.007 F: 0.151 B: 0.293 O: 0.929 M: 0.008	Train-MLMAcc=0.631081,	MVRCAccuracy=0.676410,	MLMLossWVC=1.771457,	MVRCLoss=2.442490,	
Rank[  1]Epoch[7] Batch [6100]	Speed: 28.28 samples/s ETA: 0 d 16 h 37 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.792 M: 0.007	Train-MLMAcc=0.631081,	MVRCAccuracy=0.676410,	MLMLossWVC=1.771457,	MVRCLoss=2.442490,	
Rank[  3]Epoch[7] Batch [6100]	Speed: 28.28 samples/s ETA: 0 d 16 h 37 m	Data: 0.914 Tran: 0.007 F: 0.150 B: 0.289 O: 0.894 M: 0.008	Train-MLMAcc=0.631081,	MVRCAccuracy=0.676410,	MLMLossWVC=1.771457,	MVRCLoss=2.442490,	
Rank[  2]Epoch[7] Batch [6100]	Speed: 28.28 samples/s ETA: 0 d 16 h 37 m	Data: 0.490 Tran: 0.007 F: 0.149 B: 0.292 O: 1.317 M: 0.008	Train-MLMAcc=0.631081,	MVRCAccuracy=0.676410,	MLMLossWVC=1.771457,	MVRCLoss=2.442490,	
Rank[  3]Epoch[7] Batch [6200]	Speed: 27.90 samples/s ETA: 0 d 16 h 47 m	Data: 1.192 Tran: 0.007 F: 0.150 B: 0.290 O: 0.647 M: 0.007	Train-MLMAcc=0.631013,	MVRCAccuracy=0.676399,	MLMLossWVC=1.771626,	MVRCLoss=2.442574,	
Rank[  1]Epoch[7] Batch [6200]	Speed: 27.90 samples/s ETA: 0 d 16 h 47 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.824 M: 0.006	Train-MLMAcc=0.631013,	MVRCAccuracy=0.676399,	MLMLossWVC=1.771626,	MVRCLoss=2.442574,	
Rank[  0]Epoch[7] Batch [6200]	Speed: 27.90 samples/s ETA: 0 d 16 h 47 m	Data: 0.145 Tran: 0.007 F: 0.151 B: 0.293 O: 1.693 M: 0.006	Train-MLMAcc=0.631013,	MVRCAccuracy=0.676399,	MLMLossWVC=1.771626,	MVRCLoss=2.442574,	
Rank[  2]Epoch[7] Batch [6200]	Speed: 27.90 samples/s ETA: 0 d 16 h 47 m	Data: 1.640 Tran: 0.007 F: 0.150 B: 0.292 O: 0.197 M: 0.007	Train-MLMAcc=0.631013,	MVRCAccuracy=0.676399,	MLMLossWVC=1.771626,	MVRCLoss=2.442574,	
Rank[  2]Epoch[7] Batch [6300]	Speed: 28.19 samples/s ETA: 0 d 16 h 33 m	Data: 1.279 Tran: 0.007 F: 0.150 B: 0.292 O: 0.533 M: 0.008	Train-MLMAcc=0.630988,	MVRCAccuracy=0.676415,	MLMLossWVC=1.771962,	MVRCLoss=2.442661,	
Rank[  0]Epoch[7] Batch [6300]	Speed: 28.19 samples/s ETA: 0 d 16 h 33 m	Data: 0.028 Tran: 0.007 F: 0.150 B: 0.291 O: 1.786 M: 0.007	Train-MLMAcc=0.630988,	MVRCAccuracy=0.676415,	MLMLossWVC=1.771962,	MVRCLoss=2.442661,	
Rank[  1]Epoch[7] Batch [6300]	Speed: 28.19 samples/s ETA: 0 d 16 h 33 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.797 M: 0.008	Train-MLMAcc=0.630988,	MVRCAccuracy=0.676415,	MLMLossWVC=1.771962,	MVRCLoss=2.442661,	
Rank[  3]Epoch[7] Batch [6300]	Speed: 28.19 samples/s ETA: 0 d 16 h 33 m	Data: 1.703 Tran: 0.007 F: 0.149 B: 0.288 O: 0.112 M: 0.009	Train-MLMAcc=0.630988,	MVRCAccuracy=0.676415,	MLMLossWVC=1.771962,	MVRCLoss=2.442661,	
Rank[  3]Epoch[7] Batch [6400]	Speed: 27.95 samples/s ETA: 0 d 16 h 37 m	Data: 1.519 Tran: 0.007 F: 0.150 B: 0.290 O: 0.314 M: 0.008	Train-MLMAcc=0.630953,	MVRCAccuracy=0.676384,	MLMLossWVC=1.772067,	MVRCLoss=2.442610,	
Rank[  0]Epoch[7] Batch [6400]	Speed: 27.95 samples/s ETA: 0 d 16 h 37 m	Data: 0.011 Tran: 0.007 F: 0.149 B: 0.292 O: 1.821 M: 0.009	Train-MLMAcc=0.630953,	MVRCAccuracy=0.676384,	MLMLossWVC=1.772067,	MVRCLoss=2.442610,	
Rank[  1]Epoch[7] Batch [6400]	Speed: 27.95 samples/s ETA: 0 d 16 h 37 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.296 O: 1.821 M: 0.008	Train-MLMAcc=0.630953,	MVRCAccuracy=0.676384,	MLMLossWVC=1.772067,	MVRCLoss=2.442610,	
Rank[  2]Epoch[7] Batch [6400]	Speed: 27.95 samples/s ETA: 0 d 16 h 37 m	Data: 1.697 Tran: 0.007 F: 0.151 B: 0.294 O: 0.130 M: 0.008	Train-MLMAcc=0.630953,	MVRCAccuracy=0.676384,	MLMLossWVC=1.772067,	MVRCLoss=2.442610,	
Rank[  1]Epoch[7] Batch [6500]	Speed: 28.11 samples/s ETA: 0 d 16 h 28 m	Data: 0.007 Tran: 0.007 F: 0.177 B: 0.306 O: 1.772 M: 0.006	Train-MLMAcc=0.630998,	MVRCAccuracy=0.676404,	MLMLossWVC=1.771592,	MVRCLoss=2.442614,	
Rank[  3]Epoch[7] Batch [6500]	Speed: 28.11 samples/s ETA: 0 d 16 h 28 m	Data: 0.872 Tran: 0.007 F: 0.174 B: 0.298 O: 0.916 M: 0.009	Train-MLMAcc=0.630998,	MVRCAccuracy=0.676404,	MLMLossWVC=1.771592,	MVRCLoss=2.442614,	
Rank[  0]Epoch[7] Batch [6500]	Speed: 28.11 samples/s ETA: 0 d 16 h 28 m	Data: 0.011 Tran: 0.007 F: 0.174 B: 0.301 O: 1.775 M: 0.008	Train-MLMAcc=0.630998,	MVRCAccuracy=0.676404,	MLMLossWVC=1.771592,	MVRCLoss=2.442614,	
Rank[  2]Epoch[7] Batch [6500]	Speed: 28.11 samples/s ETA: 0 d 16 h 28 m	Data: 1.717 Tran: 0.007 F: 0.175 B: 0.302 O: 0.066 M: 0.008	Train-MLMAcc=0.630998,	MVRCAccuracy=0.676404,	MLMLossWVC=1.771592,	MVRCLoss=2.442614,	
Rank[  2]Epoch[7] Batch [6600]	Speed: 27.34 samples/s ETA: 0 d 16 h 52 m	Data: 1.408 Tran: 0.007 F: 0.175 B: 0.314 O: 0.426 M: 0.009	Train-MLMAcc=0.630949,	MVRCAccuracy=0.676416,	MLMLossWVC=1.771813,	MVRCLoss=2.442562,	
Rank[  1]Epoch[7] Batch [6600]	Speed: 27.34 samples/s ETA: 0 d 16 h 52 m	Data: 0.009 Tran: 0.008 F: 0.168 B: 0.310 O: 1.838 M: 0.007	Train-MLMAcc=0.630949,	MVRCAccuracy=0.676416,	MLMLossWVC=1.771813,	MVRCLoss=2.442562,	
Rank[  3]Epoch[7] Batch [6600]	Speed: 27.34 samples/s ETA: 0 d 16 h 52 m	Data: 1.506 Tran: 0.007 F: 0.169 B: 0.301 O: 0.347 M: 0.009	Train-MLMAcc=0.630949,	MVRCAccuracy=0.676416,	MLMLossWVC=1.771813,	MVRCLoss=2.442562,	
Rank[  0]Epoch[7] Batch [6600]	Speed: 27.34 samples/s ETA: 0 d 16 h 52 m	Data: 0.010 Tran: 0.008 F: 0.166 B: 0.305 O: 1.842 M: 0.009	Train-MLMAcc=0.630949,	MVRCAccuracy=0.676416,	MLMLossWVC=1.771813,	MVRCLoss=2.442562,	
Rank[  1]Epoch[7] Batch [6700]	Speed: 27.91 samples/s ETA: 0 d 16 h 28 m	Data: 0.018 Tran: 0.007 F: 0.180 B: 0.311 O: 1.758 M: 0.016	Train-MLMAcc=0.631047,	MVRCAccuracy=0.676392,	MLMLossWVC=1.771165,	MVRCLoss=2.442516,	
Rank[  3]Epoch[7] Batch [6700]	Speed: 27.91 samples/s ETA: 0 d 16 h 28 m	Data: 1.698 Tran: 0.010 F: 0.180 B: 0.300 O: 0.086 M: 0.016	Train-MLMAcc=0.631047,	MVRCAccuracy=0.676392,	MLMLossWVC=1.771165,	MVRCLoss=2.442516,	
Rank[  2]Epoch[7] Batch [6700]	Speed: 27.91 samples/s ETA: 0 d 16 h 28 m	Data: 0.714 Tran: 0.007 F: 0.177 B: 0.306 O: 1.070 M: 0.017	Train-MLMAcc=0.631047,	MVRCAccuracy=0.676392,	MLMLossWVC=1.771165,	MVRCLoss=2.442516,	
Rank[  0]Epoch[7] Batch [6700]	Speed: 27.91 samples/s ETA: 0 d 16 h 28 m	Data: 0.019 Tran: 0.007 F: 0.177 B: 0.306 O: 1.765 M: 0.016	Train-MLMAcc=0.631047,	MVRCAccuracy=0.676392,	MLMLossWVC=1.771165,	MVRCLoss=2.442516,	
Rank[  0]Epoch[7] Batch [6800]	Speed: 27.57 samples/s ETA: 0 d 16 h 36 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.856 M: 0.006	Train-MLMAcc=0.631076,	MVRCAccuracy=0.676391,	MLMLossWVC=1.771041,	MVRCLoss=2.442567,	
Rank[  2]Epoch[7] Batch [6800]	Speed: 27.57 samples/s ETA: 0 d 16 h 36 m	Data: 0.261 Tran: 0.007 F: 0.150 B: 0.296 O: 1.600 M: 0.006	Train-MLMAcc=0.631076,	MVRCAccuracy=0.676391,	MLMLossWVC=1.771041,	MVRCLoss=2.442567,	
Rank[  3]Epoch[7] Batch [6800]	Speed: 27.57 samples/s ETA: 0 d 16 h 36 m	Data: 1.766 Tran: 0.008 F: 0.176 B: 0.302 O: 0.062 M: 0.006	Train-MLMAcc=0.631076,	MVRCAccuracy=0.676391,	MLMLossWVC=1.771041,	MVRCLoss=2.442567,	
Rank[  1]Epoch[7] Batch [6800]	Speed: 27.57 samples/s ETA: 0 d 16 h 36 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.855 M: 0.006	Train-MLMAcc=0.631076,	MVRCAccuracy=0.676391,	MLMLossWVC=1.771041,	MVRCLoss=2.442567,	
Rank[  1]Epoch[7] Batch [6900]	Speed: 28.31 samples/s ETA: 0 d 16 h  6 m	Data: 0.008 Tran: 0.008 F: 0.157 B: 0.316 O: 1.760 M: 0.009	Train-MLMAcc=0.631103,	MVRCAccuracy=0.676383,	MLMLossWVC=1.770871,	MVRCLoss=2.442626,	
Rank[  2]Epoch[7] Batch [6900]	Speed: 28.31 samples/s ETA: 0 d 16 h  6 m	Data: 0.574 Tran: 0.008 F: 0.157 B: 0.310 O: 1.199 M: 0.010	Train-MLMAcc=0.631103,	MVRCAccuracy=0.676383,	MLMLossWVC=1.770871,	MVRCLoss=2.442626,	
Rank[  3]Epoch[7] Batch [6900]	Speed: 28.31 samples/s ETA: 0 d 16 h  6 m	Data: 1.714 Tran: 0.008 F: 0.158 B: 0.308 O: 0.061 M: 0.009	Train-MLMAcc=0.631103,	MVRCAccuracy=0.676383,	MLMLossWVC=1.770871,	MVRCLoss=2.442626,	
Rank[  0]Epoch[7] Batch [6900]	Speed: 28.31 samples/s ETA: 0 d 16 h  6 m	Data: 0.009 Tran: 0.008 F: 0.156 B: 0.310 O: 1.766 M: 0.011	Train-MLMAcc=0.631103,	MVRCAccuracy=0.676383,	MLMLossWVC=1.770871,	MVRCLoss=2.442626,	
Rank[  2]Epoch[7] Batch [7000]	Speed: 27.52 samples/s ETA: 0 d 16 h 30 m	Data: 1.772 Tran: 0.007 F: 0.164 B: 0.303 O: 0.068 M: 0.009	Train-MLMAcc=0.631172,	MVRCAccuracy=0.676392,	MLMLossWVC=1.770337,	MVRCLoss=2.442567,	
Rank[  0]Epoch[7] Batch [7000]	Speed: 27.52 samples/s ETA: 0 d 16 h 30 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.295 O: 1.850 M: 0.009	Train-MLMAcc=0.631172,	MVRCAccuracy=0.676392,	MLMLossWVC=1.770337,	MVRCLoss=2.442567,	
Rank[  1]Epoch[7] Batch [7000]	Speed: 27.52 samples/s ETA: 0 d 16 h 30 m	Data: 0.008 Tran: 0.007 F: 0.155 B: 0.303 O: 1.840 M: 0.009	Train-MLMAcc=0.631172,	MVRCAccuracy=0.676392,	MLMLossWVC=1.770337,	MVRCLoss=2.442567,	
Rank[  3]Epoch[7] Batch [7000]	Speed: 27.52 samples/s ETA: 0 d 16 h 30 m	Data: 1.646 Tran: 0.009 F: 0.172 B: 0.298 O: 0.187 M: 0.011	Train-MLMAcc=0.631172,	MVRCAccuracy=0.676392,	MLMLossWVC=1.770337,	MVRCLoss=2.442567,	
Rank[  3]Epoch[7] Batch [7100]	Speed: 27.52 samples/s ETA: 0 d 16 h 26 m	Data: 1.196 Tran: 0.009 F: 0.169 B: 0.297 O: 0.645 M: 0.008	Train-MLMAcc=0.631129,	MVRCAccuracy=0.676406,	MLMLossWVC=1.770496,	MVRCLoss=2.442572,	
Rank[  1]Epoch[7] Batch [7100]	Speed: 27.52 samples/s ETA: 0 d 16 h 26 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.301 O: 1.848 M: 0.008	Train-MLMAcc=0.631129,	MVRCAccuracy=0.676406,	MLMLossWVC=1.770496,	MVRCLoss=2.442572,	
Rank[  2]Epoch[7] Batch [7100]	Speed: 27.52 samples/s ETA: 0 d 16 h 26 m	Data: 1.773 Tran: 0.010 F: 0.168 B: 0.303 O: 0.061 M: 0.009	Train-MLMAcc=0.631129,	MVRCAccuracy=0.676406,	MLMLossWVC=1.770496,	MVRCLoss=2.442572,	
Rank[  0]Epoch[7] Batch [7100]	Speed: 27.52 samples/s ETA: 0 d 16 h 26 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.297 O: 1.852 M: 0.007	Train-MLMAcc=0.631129,	MVRCAccuracy=0.676406,	MLMLossWVC=1.770496,	MVRCLoss=2.442572,	
Rank[  1]Epoch[7] Batch [7200]	Speed: 28.05 samples/s ETA: 0 d 16 h  4 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.301 O: 1.799 M: 0.011	Train-MLMAcc=0.631123,	MVRCAccuracy=0.676438,	MLMLossWVC=1.770689,	MVRCLoss=2.442445,	
Rank[  0]Epoch[7] Batch [7200]	Speed: 28.05 samples/s ETA: 0 d 16 h  4 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.296 O: 1.804 M: 0.012	Train-MLMAcc=0.631123,	MVRCAccuracy=0.676438,	MLMLossWVC=1.770689,	MVRCLoss=2.442445,	
Rank[  2]Epoch[7] Batch [7200]	Speed: 28.05 samples/s ETA: 0 d 16 h  4 m	Data: 1.487 Tran: 0.008 F: 0.171 B: 0.298 O: 0.303 M: 0.012	Train-MLMAcc=0.631123,	MVRCAccuracy=0.676438,	MLMLossWVC=1.770689,	MVRCLoss=2.442445,	
Rank[  3]Epoch[7] Batch [7200]	Speed: 28.05 samples/s ETA: 0 d 16 h  4 m	Data: 0.598 Tran: 0.007 F: 0.154 B: 0.291 O: 1.219 M: 0.010	Train-MLMAcc=0.631123,	MVRCAccuracy=0.676438,	MLMLossWVC=1.770689,	MVRCLoss=2.442445,	
Rank[  2]Epoch[7] Batch [7300]	Speed: 27.87 samples/s ETA: 0 d 16 h  6 m	Data: 1.634 Tran: 0.008 F: 0.168 B: 0.295 O: 0.183 M: 0.007	Train-MLMAcc=0.631187,	MVRCAccuracy=0.676458,	MLMLossWVC=1.770553,	MVRCLoss=2.442393,	
Rank[  1]Epoch[7] Batch [7300]	Speed: 27.87 samples/s ETA: 0 d 16 h  6 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.824 M: 0.008	Train-MLMAcc=0.631187,	MVRCAccuracy=0.676458,	MLMLossWVC=1.770553,	MVRCLoss=2.442393,	
Rank[  3]Epoch[7] Batch [7300]	Speed: 27.87 samples/s ETA: 0 d 16 h  6 m	Data: 0.681 Tran: 0.007 F: 0.154 B: 0.293 O: 1.154 M: 0.007	Train-MLMAcc=0.631187,	MVRCAccuracy=0.676458,	MLMLossWVC=1.770553,	MVRCLoss=2.442393,	
Rank[  0]Epoch[7] Batch [7300]	Speed: 27.87 samples/s ETA: 0 d 16 h  6 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.292 O: 1.833 M: 0.006	Train-MLMAcc=0.631187,	MVRCAccuracy=0.676458,	MLMLossWVC=1.770553,	MVRCLoss=2.442393,	
Rank[  1]Epoch[7] Batch [7400]	Speed: 27.96 samples/s ETA: 0 d 15 h 59 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.305 O: 1.809 M: 0.008	Train-MLMAcc=0.631181,	MVRCAccuracy=0.676464,	MLMLossWVC=1.770428,	MVRCLoss=2.442391,	
Rank[  3]Epoch[7] Batch [7400]	Speed: 27.96 samples/s ETA: 0 d 15 h 59 m	Data: 1.239 Tran: 0.006 F: 0.154 B: 0.297 O: 0.583 M: 0.009	Train-MLMAcc=0.631181,	MVRCAccuracy=0.676464,	MLMLossWVC=1.770428,	MVRCLoss=2.442391,	
Rank[  2]Epoch[7] Batch [7400]	Speed: 27.96 samples/s ETA: 0 d 15 h 59 m	Data: 1.501 Tran: 0.008 F: 0.168 B: 0.306 O: 0.297 M: 0.008	Train-MLMAcc=0.631181,	MVRCAccuracy=0.676464,	MLMLossWVC=1.770428,	MVRCLoss=2.442391,	
Rank[  0]Epoch[7] Batch [7400]	Speed: 27.96 samples/s ETA: 0 d 15 h 59 m	Data: 0.083 Tran: 0.007 F: 0.151 B: 0.300 O: 1.738 M: 0.009	Train-MLMAcc=0.631181,	MVRCAccuracy=0.676464,	MLMLossWVC=1.770428,	MVRCLoss=2.442391,	
Rank[  2]Epoch[7] Batch [7500]	Speed: 27.45 samples/s ETA: 0 d 16 h 13 m	Data: 0.933 Tran: 0.008 F: 0.188 B: 0.298 O: 0.893 M: 0.009	Train-MLMAcc=0.631188,	MVRCAccuracy=0.676498,	MLMLossWVC=1.770243,	MVRCLoss=2.442310,	
Rank[  1]Epoch[7] Batch [7500]	Speed: 27.45 samples/s ETA: 0 d 16 h 13 m	Data: 0.058 Tran: 0.007 F: 0.163 B: 0.311 O: 1.784 M: 0.008	Train-MLMAcc=0.631188,	MVRCAccuracy=0.676498,	MLMLossWVC=1.770243,	MVRCLoss=2.442310,	
Rank[  0]Epoch[7] Batch [7500]	Speed: 27.45 samples/s ETA: 0 d 16 h 13 m	Data: 0.021 Tran: 0.007 F: 0.162 B: 0.306 O: 1.825 M: 0.009	Train-MLMAcc=0.631188,	MVRCAccuracy=0.676498,	MLMLossWVC=1.770243,	MVRCLoss=2.442310,	
Rank[  3]Epoch[7] Batch [7500]	Speed: 27.45 samples/s ETA: 0 d 16 h 13 m	Data: 1.528 Tran: 0.007 F: 0.154 B: 0.297 O: 0.335 M: 0.010	Train-MLMAcc=0.631188,	MVRCAccuracy=0.676498,	MLMLossWVC=1.770243,	MVRCLoss=2.442310,	
Rank[  1]Epoch[7] Batch [7600]	Speed: 27.30 samples/s ETA: 0 d 16 h 14 m	Data: 0.412 Tran: 0.009 F: 0.166 B: 0.309 O: 1.428 M: 0.017	Train-MLMAcc=0.631224,	MVRCAccuracy=0.676524,	MLMLossWVC=1.770151,	MVRCLoss=2.442271,	
Rank[  3]Epoch[7] Batch [7600]	Speed: 27.30 samples/s ETA: 0 d 16 h 14 m	Data: 0.811 Tran: 0.007 F: 0.157 B: 0.310 O: 1.041 M: 0.014	Train-MLMAcc=0.631224,	MVRCAccuracy=0.676524,	MLMLossWVC=1.770151,	MVRCLoss=2.442271,	
Rank[  2]Epoch[7] Batch [7600]	Speed: 27.30 samples/s ETA: 0 d 16 h 14 m	Data: 1.275 Tran: 0.007 F: 0.173 B: 0.310 O: 0.558 M: 0.017	Train-MLMAcc=0.631224,	MVRCAccuracy=0.676524,	MLMLossWVC=1.770151,	MVRCLoss=2.442271,	
Rank[  0]Epoch[7] Batch [7600]	Speed: 27.30 samples/s ETA: 0 d 16 h 14 m	Data: 0.009 Tran: 0.009 F: 0.163 B: 0.300 O: 1.842 M: 0.018	Train-MLMAcc=0.631224,	MVRCAccuracy=0.676524,	MLMLossWVC=1.770151,	MVRCLoss=2.442271,	
Rank[  1]Epoch[7] Batch [7700]	Speed: 27.88 samples/s ETA: 0 d 15 h 50 m	Data: 0.609 Tran: 0.008 F: 0.154 B: 0.306 O: 1.206 M: 0.009	Train-MLMAcc=0.631269,	MVRCAccuracy=0.676546,	MLMLossWVC=1.769964,	MVRCLoss=2.442232,	
Rank[  3]Epoch[7] Batch [7700]	Speed: 27.88 samples/s ETA: 0 d 15 h 50 m	Data: 0.798 Tran: 0.007 F: 0.152 B: 0.294 O: 1.032 M: 0.007	Train-MLMAcc=0.631269,	MVRCAccuracy=0.676546,	MLMLossWVC=1.769964,	MVRCLoss=2.442232,	
Rank[  2]Epoch[7] Batch [7700]	Speed: 27.88 samples/s ETA: 0 d 15 h 50 m	Data: 1.463 Tran: 0.007 F: 0.152 B: 0.300 O: 0.361 M: 0.009	Train-MLMAcc=0.631269,	MVRCAccuracy=0.676546,	MLMLossWVC=1.769964,	MVRCLoss=2.442232,	
Rank[  0]Epoch[7] Batch [7700]	Speed: 27.88 samples/s ETA: 0 d 15 h 50 m	Data: 0.008 Tran: 0.007 F: 0.158 B: 0.295 O: 1.815 M: 0.008	Train-MLMAcc=0.631269,	MVRCAccuracy=0.676546,	MLMLossWVC=1.769964,	MVRCLoss=2.442232,	
Rank[  1]Epoch[7] Batch [7800]	Speed: 27.67 samples/s ETA: 0 d 15 h 54 m	Data: 0.237 Tran: 0.007 F: 0.157 B: 0.300 O: 1.600 M: 0.010	Train-MLMAcc=0.631269,	MVRCAccuracy=0.676544,	MLMLossWVC=1.769966,	MVRCLoss=2.442122,	
Rank[  0]Epoch[7] Batch [7800]	Speed: 27.67 samples/s ETA: 0 d 15 h 54 m	Data: 0.009 Tran: 0.007 F: 0.157 B: 0.295 O: 1.834 M: 0.010	Train-MLMAcc=0.631269,	MVRCAccuracy=0.676544,	MLMLossWVC=1.769966,	MVRCLoss=2.442122,	
Rank[  3]Epoch[7] Batch [7800]	Speed: 27.67 samples/s ETA: 0 d 15 h 54 m	Data: 1.148 Tran: 0.010 F: 0.166 B: 0.294 O: 0.684 M: 0.010	Train-MLMAcc=0.631269,	MVRCAccuracy=0.676544,	MLMLossWVC=1.769966,	MVRCLoss=2.442122,	
Rank[  2]Epoch[7] Batch [7800]	Speed: 27.67 samples/s ETA: 0 d 15 h 54 m	Data: 1.325 Tran: 0.007 F: 0.168 B: 0.301 O: 0.501 M: 0.010	Train-MLMAcc=0.631269,	MVRCAccuracy=0.676544,	MLMLossWVC=1.769966,	MVRCLoss=2.442122,	
Rank[  3]Epoch[7] Batch [7900]	Speed: 27.22 samples/s ETA: 0 d 16 h  5 m	Data: 1.265 Tran: 0.007 F: 0.169 B: 0.300 O: 0.599 M: 0.009	Train-MLMAcc=0.631333,	MVRCAccuracy=0.676568,	MLMLossWVC=1.769795,	MVRCLoss=2.442115,	
Rank[  2]Epoch[7] Batch [7900]	Speed: 27.22 samples/s ETA: 0 d 16 h  5 m	Data: 1.366 Tran: 0.007 F: 0.183 B: 0.311 O: 0.473 M: 0.010	Train-MLMAcc=0.631333,	MVRCAccuracy=0.676568,	MLMLossWVC=1.769795,	MVRCLoss=2.442115,	
Rank[  1]Epoch[7] Batch [7900]	Speed: 27.22 samples/s ETA: 0 d 16 h  5 m	Data: 1.263 Tran: 0.017 F: 0.187 B: 0.314 O: 0.560 M: 0.009	Train-MLMAcc=0.631333,	MVRCAccuracy=0.676568,	MLMLossWVC=1.769795,	MVRCLoss=2.442115,	
Rank[  0]Epoch[7] Batch [7900]	Speed: 27.22 samples/s ETA: 0 d 16 h  5 m	Data: 0.008 Tran: 0.007 F: 0.155 B: 0.299 O: 1.871 M: 0.009	Train-MLMAcc=0.631333,	MVRCAccuracy=0.676568,	MLMLossWVC=1.769795,	MVRCLoss=2.442115,	
Rank[  1]Epoch[7] Batch [8000]	Speed: 27.23 samples/s ETA: 0 d 16 h  1 m	Data: 0.957 Tran: 0.008 F: 0.160 B: 0.310 O: 0.903 M: 0.011	Train-MLMAcc=0.631341,	MVRCAccuracy=0.676578,	MLMLossWVC=1.769893,	MVRCLoss=2.442070,	
Rank[  0]Epoch[7] Batch [8000]	Speed: 27.23 samples/s ETA: 0 d 16 h  1 m	Data: 0.008 Tran: 0.007 F: 0.154 B: 0.302 O: 1.868 M: 0.009	Train-MLMAcc=0.631341,	MVRCAccuracy=0.676578,	MLMLossWVC=1.769893,	MVRCLoss=2.442070,	
Rank[  3]Epoch[7] Batch [8000]	Speed: 27.23 samples/s ETA: 0 d 16 h  1 m	Data: 0.445 Tran: 0.007 F: 0.155 B: 0.300 O: 1.429 M: 0.012	Train-MLMAcc=0.631341,	MVRCAccuracy=0.676578,	MLMLossWVC=1.769893,	MVRCLoss=2.442070,	
Rank[  2]Epoch[7] Batch [8000]	Speed: 27.23 samples/s ETA: 0 d 16 h  1 m	Data: 1.553 Tran: 0.010 F: 0.178 B: 0.307 O: 0.288 M: 0.012	Train-MLMAcc=0.631341,	MVRCAccuracy=0.676578,	MLMLossWVC=1.769893,	MVRCLoss=2.442070,	
Rank[  1]Epoch[7] Batch [8100]	Speed: 27.54 samples/s ETA: 0 d 15 h 46 m	Data: 0.649 Tran: 0.008 F: 0.155 B: 0.303 O: 1.199 M: 0.009	Train-MLMAcc=0.631387,	MVRCAccuracy=0.676596,	MLMLossWVC=1.769572,	MVRCLoss=2.442072,	
Rank[  0]Epoch[7] Batch [8100]	Speed: 27.54 samples/s ETA: 0 d 15 h 46 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.297 O: 1.849 M: 0.008	Train-MLMAcc=0.631387,	MVRCAccuracy=0.676596,	MLMLossWVC=1.769572,	MVRCLoss=2.442072,	
Rank[  3]Epoch[7] Batch [8100]	Speed: 27.54 samples/s ETA: 0 d 15 h 46 m	Data: 0.511 Tran: 0.009 F: 0.170 B: 0.298 O: 1.327 M: 0.008	Train-MLMAcc=0.631387,	MVRCAccuracy=0.676596,	MLMLossWVC=1.769572,	MVRCLoss=2.442072,	
Rank[  2]Epoch[7] Batch [8100]	Speed: 27.54 samples/s ETA: 0 d 15 h 46 m	Data: 1.450 Tran: 0.009 F: 0.178 B: 0.309 O: 0.369 M: 0.008	Train-MLMAcc=0.631387,	MVRCAccuracy=0.676596,	MLMLossWVC=1.769572,	MVRCLoss=2.442072,	
Rank[  2]Epoch[7] Batch [8200]	Speed: 27.90 samples/s ETA: 0 d 15 h 31 m	Data: 1.740 Tran: 0.008 F: 0.177 B: 0.299 O: 0.060 M: 0.007	Train-MLMAcc=0.631405,	MVRCAccuracy=0.676614,	MLMLossWVC=1.769464,	MVRCLoss=2.442013,	
Rank[  3]Epoch[7] Batch [8200]	Speed: 27.90 samples/s ETA: 0 d 15 h 31 m	Data: 0.481 Tran: 0.007 F: 0.157 B: 0.293 O: 1.347 M: 0.006	Train-MLMAcc=0.631405,	MVRCAccuracy=0.676614,	MLMLossWVC=1.769464,	MVRCLoss=2.442013,	
Rank[  0]Epoch[7] Batch [8200]	Speed: 27.90 samples/s ETA: 0 d 15 h 31 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.294 O: 1.824 M: 0.006	Train-MLMAcc=0.631405,	MVRCAccuracy=0.676614,	MLMLossWVC=1.769464,	MVRCLoss=2.442013,	
Rank[  1]Epoch[7] Batch [8200]	Speed: 27.90 samples/s ETA: 0 d 15 h 31 m	Data: 0.066 Tran: 0.007 F: 0.154 B: 0.304 O: 1.754 M: 0.007	Train-MLMAcc=0.631405,	MVRCAccuracy=0.676614,	MLMLossWVC=1.769464,	MVRCLoss=2.442013,	
Rank[  3]Epoch[7] Batch [8300]	Speed: 27.49 samples/s ETA: 0 d 15 h 41 m	Data: 0.068 Tran: 0.007 F: 0.153 B: 0.290 O: 1.799 M: 0.009	Train-MLMAcc=0.631387,	MVRCAccuracy=0.676620,	MLMLossWVC=1.769501,	MVRCLoss=2.441965,	
Rank[  2]Epoch[7] Batch [8300]	Speed: 27.49 samples/s ETA: 0 d 15 h 41 m	Data: 1.749 Tran: 0.010 F: 0.188 B: 0.305 O: 0.062 M: 0.010	Train-MLMAcc=0.631387,	MVRCAccuracy=0.676620,	MLMLossWVC=1.769501,	MVRCLoss=2.441965,	
Rank[  1]Epoch[7] Batch [8300]	Speed: 27.49 samples/s ETA: 0 d 15 h 41 m	Data: 0.049 Tran: 0.007 F: 0.154 B: 0.299 O: 1.808 M: 0.008	Train-MLMAcc=0.631387,	MVRCAccuracy=0.676620,	MLMLossWVC=1.769501,	MVRCLoss=2.441965,	
Rank[  0]Epoch[7] Batch [8300]	Speed: 27.49 samples/s ETA: 0 d 15 h 41 m	Data: 0.008 Tran: 0.007 F: 0.154 B: 0.292 O: 1.858 M: 0.007	Train-MLMAcc=0.631387,	MVRCAccuracy=0.676620,	MLMLossWVC=1.769501,	MVRCLoss=2.441965,	
Rank[  0]Epoch[7] Batch [8400]	Speed: 27.76 samples/s ETA: 0 d 15 h 28 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.838 M: 0.009	Train-MLMAcc=0.631450,	MVRCAccuracy=0.676609,	MLMLossWVC=1.769107,	MVRCLoss=2.441979,	
Rank[  2]Epoch[7] Batch [8400]	Speed: 27.76 samples/s ETA: 0 d 15 h 28 m	Data: 1.551 Tran: 0.008 F: 0.170 B: 0.305 O: 0.263 M: 0.007	Train-MLMAcc=0.631450,	MVRCAccuracy=0.676609,	MLMLossWVC=1.769107,	MVRCLoss=2.441979,	
Rank[  1]Epoch[7] Batch [8400]	Speed: 27.76 samples/s ETA: 0 d 15 h 28 m	Data: 0.017 Tran: 0.007 F: 0.150 B: 0.298 O: 1.823 M: 0.009	Train-MLMAcc=0.631450,	MVRCAccuracy=0.676609,	MLMLossWVC=1.769107,	MVRCLoss=2.441979,	
Rank[  3]Epoch[7] Batch [8400]	Speed: 27.76 samples/s ETA: 0 d 15 h 28 m	Data: 0.219 Tran: 0.006 F: 0.150 B: 0.290 O: 1.630 M: 0.008	Train-MLMAcc=0.631450,	MVRCAccuracy=0.676609,	MLMLossWVC=1.769107,	MVRCLoss=2.441979,	
Rank[  1]Epoch[7] Batch [8500]	Speed: 27.63 samples/s ETA: 0 d 15 h 28 m	Data: 0.008 Tran: 0.008 F: 0.157 B: 0.302 O: 1.830 M: 0.010	Train-MLMAcc=0.631441,	MVRCAccuracy=0.676638,	MLMLossWVC=1.769189,	MVRCLoss=2.442014,	
Rank[  3]Epoch[7] Batch [8500]	Speed: 27.63 samples/s ETA: 0 d 15 h 28 m	Data: 0.095 Tran: 0.008 F: 0.167 B: 0.297 O: 1.739 M: 0.009	Train-MLMAcc=0.631441,	MVRCAccuracy=0.676638,	MLMLossWVC=1.769189,	MVRCLoss=2.442014,	
Rank[  2]Epoch[7] Batch [8500]	Speed: 27.63 samples/s ETA: 0 d 15 h 28 m	Data: 1.666 Tran: 0.009 F: 0.176 B: 0.301 O: 0.152 M: 0.010	Train-MLMAcc=0.631441,	MVRCAccuracy=0.676638,	MLMLossWVC=1.769189,	MVRCLoss=2.442014,	
Rank[  0]Epoch[7] Batch [8500]	Speed: 27.63 samples/s ETA: 0 d 15 h 28 m	Data: 0.008 Tran: 0.007 F: 0.158 B: 0.297 O: 1.834 M: 0.009	Train-MLMAcc=0.631441,	MVRCAccuracy=0.676638,	MLMLossWVC=1.769189,	MVRCLoss=2.442014,	
Rank[  1]Epoch[7] Batch [8600]	Speed: 27.76 samples/s ETA: 0 d 15 h 20 m	Data: 0.009 Tran: 0.007 F: 0.160 B: 0.299 O: 1.820 M: 0.010	Train-MLMAcc=0.631502,	MVRCAccuracy=0.676650,	MLMLossWVC=1.768904,	MVRCLoss=2.441933,	
Rank[  3]Epoch[7] Batch [8600]	Speed: 27.76 samples/s ETA: 0 d 15 h 20 m	Data: 0.682 Tran: 0.009 F: 0.179 B: 0.306 O: 1.118 M: 0.010	Train-MLMAcc=0.631502,	MVRCAccuracy=0.676650,	MLMLossWVC=1.768904,	MVRCLoss=2.441933,	
Rank[  2]Epoch[7] Batch [8600]	Speed: 27.76 samples/s ETA: 0 d 15 h 20 m	Data: 1.054 Tran: 0.007 F: 0.164 B: 0.296 O: 0.773 M: 0.010	Train-MLMAcc=0.631502,	MVRCAccuracy=0.676650,	MLMLossWVC=1.768904,	MVRCLoss=2.441933,	
Rank[  0]Epoch[7] Batch [8600]	Speed: 27.76 samples/s ETA: 0 d 15 h 20 m	Data: 0.008 Tran: 0.007 F: 0.159 B: 0.292 O: 1.828 M: 0.010	Train-MLMAcc=0.631502,	MVRCAccuracy=0.676650,	MLMLossWVC=1.768904,	MVRCLoss=2.441933,	
Rank[  1]Epoch[7] Batch [8700]	Speed: 27.84 samples/s ETA: 0 d 15 h 14 m	Data: 0.015 Tran: 0.007 F: 0.150 B: 0.298 O: 1.819 M: 0.009	Train-MLMAcc=0.631463,	MVRCAccuracy=0.676678,	MLMLossWVC=1.769033,	MVRCLoss=2.441871,	
Rank[  0]Epoch[7] Batch [8700]	Speed: 27.84 samples/s ETA: 0 d 15 h 14 m	Data: 0.012 Tran: 0.007 F: 0.151 B: 0.293 O: 1.826 M: 0.008	Train-MLMAcc=0.631463,	MVRCAccuracy=0.676678,	MLMLossWVC=1.769033,	MVRCLoss=2.441871,	
Rank[  2]Epoch[7] Batch [8700]	Speed: 27.84 samples/s ETA: 0 d 15 h 14 m	Data: 0.592 Tran: 0.007 F: 0.152 B: 0.298 O: 1.240 M: 0.009	Train-MLMAcc=0.631463,	MVRCAccuracy=0.676678,	MLMLossWVC=1.769033,	MVRCLoss=2.441871,	
Rank[  3]Epoch[7] Batch [8700]	Speed: 27.84 samples/s ETA: 0 d 15 h 14 m	Data: 1.165 Tran: 0.009 F: 0.191 B: 0.299 O: 0.625 M: 0.008	Train-MLMAcc=0.631463,	MVRCAccuracy=0.676678,	MLMLossWVC=1.769033,	MVRCLoss=2.441871,	
Rank[  2]Epoch[7] Batch [8800]	Speed: 27.87 samples/s ETA: 0 d 15 h  9 m	Data: 0.542 Tran: 0.007 F: 0.151 B: 0.297 O: 1.290 M: 0.007	Train-MLMAcc=0.631536,	MVRCAccuracy=0.676709,	MLMLossWVC=1.768694,	MVRCLoss=2.441888,	
Rank[  1]Epoch[7] Batch [8800]	Speed: 27.87 samples/s ETA: 0 d 15 h  9 m	Data: 0.032 Tran: 0.007 F: 0.150 B: 0.300 O: 1.799 M: 0.006	Train-MLMAcc=0.631536,	MVRCAccuracy=0.676709,	MLMLossWVC=1.768694,	MVRCLoss=2.441888,	
Rank[  0]Epoch[7] Batch [8800]	Speed: 27.87 samples/s ETA: 0 d 15 h  9 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.829 M: 0.006	Train-MLMAcc=0.631536,	MVRCAccuracy=0.676709,	MLMLossWVC=1.768694,	MVRCLoss=2.441888,	
Rank[  3]Epoch[7] Batch [8800]	Speed: 27.87 samples/s ETA: 0 d 15 h  9 m	Data: 1.368 Tran: 0.007 F: 0.171 B: 0.303 O: 0.438 M: 0.006	Train-MLMAcc=0.631536,	MVRCAccuracy=0.676709,	MLMLossWVC=1.768694,	MVRCLoss=2.441888,	
Rank[  1]Epoch[7] Batch [8900]	Speed: 27.61 samples/s ETA: 0 d 15 h 13 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.311 O: 1.831 M: 0.009	Train-MLMAcc=0.631517,	MVRCAccuracy=0.676736,	MLMLossWVC=1.768758,	MVRCLoss=2.441843,	
Rank[  3]Epoch[7] Batch [8900]	Speed: 27.61 samples/s ETA: 0 d 15 h 13 m	Data: 1.698 Tran: 0.007 F: 0.177 B: 0.303 O: 0.120 M: 0.010	Train-MLMAcc=0.631517,	MVRCAccuracy=0.676736,	MLMLossWVC=1.768758,	MVRCLoss=2.441843,	
Rank[  2]Epoch[7] Batch [8900]	Speed: 27.61 samples/s ETA: 0 d 15 h 13 m	Data: 0.076 Tran: 0.007 F: 0.150 B: 0.307 O: 1.766 M: 0.011	Train-MLMAcc=0.631517,	MVRCAccuracy=0.676736,	MLMLossWVC=1.768758,	MVRCLoss=2.441843,	
Rank[  0]Epoch[7] Batch [8900]	Speed: 27.61 samples/s ETA: 0 d 15 h 13 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.306 O: 1.834 M: 0.011	Train-MLMAcc=0.631517,	MVRCAccuracy=0.676736,	MLMLossWVC=1.768758,	MVRCLoss=2.441843,	
Rank[  0]Epoch[7] Batch [9000]	Speed: 28.28 samples/s ETA: 0 d 14 h 48 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.299 O: 1.787 M: 0.009	Train-MLMAcc=0.631484,	MVRCAccuracy=0.676756,	MLMLossWVC=1.768901,	MVRCLoss=2.441889,	
Rank[  2]Epoch[7] Batch [9000]	Speed: 28.28 samples/s ETA: 0 d 14 h 48 m	Data: 0.029 Tran: 0.007 F: 0.153 B: 0.300 O: 1.764 M: 0.009	Train-MLMAcc=0.631484,	MVRCAccuracy=0.676756,	MLMLossWVC=1.768901,	MVRCLoss=2.441889,	
Rank[  3]Epoch[7] Batch [9000]	Speed: 28.28 samples/s ETA: 0 d 14 h 48 m	Data: 1.681 Tran: 0.010 F: 0.183 B: 0.305 O: 0.075 M: 0.009	Train-MLMAcc=0.631484,	MVRCAccuracy=0.676756,	MLMLossWVC=1.768901,	MVRCLoss=2.441889,	
Rank[  1]Epoch[7] Batch [9000]	Speed: 28.28 samples/s ETA: 0 d 14 h 48 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.306 O: 1.779 M: 0.009	Train-MLMAcc=0.631484,	MVRCAccuracy=0.676756,	MLMLossWVC=1.768901,	MVRCLoss=2.441889,	
Rank[  2]Epoch[7] Batch [9100]	Speed: 27.45 samples/s ETA: 0 d 15 h 11 m	Data: 0.178 Tran: 0.007 F: 0.150 B: 0.303 O: 1.683 M: 0.009	Train-MLMAcc=0.631487,	MVRCAccuracy=0.676768,	MLMLossWVC=1.768825,	MVRCLoss=2.441850,	
Rank[  1]Epoch[7] Batch [9100]	Speed: 27.45 samples/s ETA: 0 d 15 h 11 m	Data: 0.373 Tran: 0.007 F: 0.152 B: 0.302 O: 1.486 M: 0.009	Train-MLMAcc=0.631487,	MVRCAccuracy=0.676768,	MLMLossWVC=1.768825,	MVRCLoss=2.441850,	
Rank[  3]Epoch[7] Batch [9100]	Speed: 27.45 samples/s ETA: 0 d 15 h 11 m	Data: 1.512 Tran: 0.007 F: 0.165 B: 0.302 O: 0.335 M: 0.009	Train-MLMAcc=0.631487,	MVRCAccuracy=0.676768,	MLMLossWVC=1.768825,	MVRCLoss=2.441850,	
Rank[  0]Epoch[7] Batch [9100]	Speed: 27.45 samples/s ETA: 0 d 15 h 11 m	Data: 0.171 Tran: 0.007 F: 0.151 B: 0.294 O: 1.700 M: 0.008	Train-MLMAcc=0.631487,	MVRCAccuracy=0.676768,	MLMLossWVC=1.768825,	MVRCLoss=2.441850,	
Rank[  1]Epoch[7] Batch [9200]	Speed: 26.37 samples/s ETA: 0 d 15 h 44 m	Data: 0.744 Tran: 0.009 F: 0.184 B: 0.327 O: 1.147 M: 0.012	Train-MLMAcc=0.631507,	MVRCAccuracy=0.676808,	MLMLossWVC=1.768746,	MVRCLoss=2.441793,	
Rank[  0]Epoch[7] Batch [9200]	Speed: 26.37 samples/s ETA: 0 d 15 h 44 m	Data: 0.641 Tran: 0.007 F: 0.177 B: 0.322 O: 1.264 M: 0.012	Train-MLMAcc=0.631507,	MVRCAccuracy=0.676808,	MLMLossWVC=1.768746,	MVRCLoss=2.441793,	
Rank[  3]Epoch[7] Batch [9200]	Speed: 26.37 samples/s ETA: 0 d 15 h 44 m	Data: 1.629 Tran: 0.007 F: 0.184 B: 0.322 O: 0.268 M: 0.012	Train-MLMAcc=0.631507,	MVRCAccuracy=0.676808,	MLMLossWVC=1.768746,	MVRCLoss=2.441793,	
Rank[  2]Epoch[7] Batch [9200]	Speed: 26.37 samples/s ETA: 0 d 15 h 44 m	Data: 0.211 Tran: 0.008 F: 0.184 B: 0.326 O: 1.682 M: 0.012	Train-MLMAcc=0.631507,	MVRCAccuracy=0.676808,	MLMLossWVC=1.768746,	MVRCLoss=2.441793,	
Rank[  0]Epoch[7] Batch [9300]	Speed: 21.76 samples/s ETA: 0 d 19 h  0 m	Data: 0.837 Tran: 0.011 F: 0.274 B: 0.427 O: 1.343 M: 0.040	Train-MLMAcc=0.631501,	MVRCAccuracy=0.676827,	MLMLossWVC=1.768772,	MVRCLoss=2.441738,	
Rank[  3]Epoch[7] Batch [9300]	Speed: 21.76 samples/s ETA: 0 d 19 h  0 m	Data: 1.328 Tran: 0.015 F: 0.319 B: 0.449 O: 0.780 M: 0.041	Train-MLMAcc=0.631501,	MVRCAccuracy=0.676827,	MLMLossWVC=1.768772,	MVRCLoss=2.441738,	
Rank[  2]Epoch[7] Batch [9300]	Speed: 21.76 samples/s ETA: 0 d 19 h  0 m	Data: 0.331 Tran: 0.012 F: 0.261 B: 0.420 O: 1.868 M: 0.040	Train-MLMAcc=0.631501,	MVRCAccuracy=0.676827,	MLMLossWVC=1.768772,	MVRCLoss=2.441738,	
Rank[  1]Epoch[7] Batch [9300]	Speed: 21.76 samples/s ETA: 0 d 19 h  0 m	Data: 0.136 Tran: 0.011 F: 0.264 B: 0.425 O: 2.058 M: 0.039	Train-MLMAcc=0.631501,	MVRCAccuracy=0.676827,	MLMLossWVC=1.768772,	MVRCLoss=2.441738,	
Rank[  2]Epoch[7] Batch [9400]	Speed: 22.34 samples/s ETA: 0 d 18 h 25 m	Data: 0.406 Tran: 0.010 F: 0.242 B: 0.438 O: 1.737 M: 0.029	Train-MLMAcc=0.631552,	MVRCAccuracy=0.676841,	MLMLossWVC=1.768531,	MVRCLoss=2.441722,	
Rank[  3]Epoch[7] Batch [9400]	Speed: 22.34 samples/s ETA: 0 d 18 h 25 m	Data: 1.942 Tran: 0.013 F: 0.276 B: 0.437 O: 0.165 M: 0.028	Train-MLMAcc=0.631552,	MVRCAccuracy=0.676841,	MLMLossWVC=1.768531,	MVRCLoss=2.441722,	
Rank[  0]Epoch[7] Batch [9400]	Speed: 22.34 samples/s ETA: 0 d 18 h 25 m	Data: 0.083 Tran: 0.007 F: 0.218 B: 0.416 O: 2.109 M: 0.028	Train-MLMAcc=0.631552,	MVRCAccuracy=0.676841,	MLMLossWVC=1.768531,	MVRCLoss=2.441722,	
Rank[  1]Epoch[7] Batch [9400]	Speed: 22.34 samples/s ETA: 0 d 18 h 25 m	Data: 0.017 Tran: 0.007 F: 0.210 B: 0.415 O: 2.183 M: 0.028	Train-MLMAcc=0.631552,	MVRCAccuracy=0.676841,	MLMLossWVC=1.768531,	MVRCLoss=2.441722,	
Rank[  0]Epoch[7] Batch [9500]	Speed: 23.96 samples/s ETA: 0 d 17 h  6 m	Data: 0.025 Tran: 0.008 F: 0.188 B: 0.346 O: 2.086 M: 0.014	Train-MLMAcc=0.631562,	MVRCAccuracy=0.676841,	MLMLossWVC=1.768416,	MVRCLoss=2.441773,	
Rank[  2]Epoch[7] Batch [9500]	Speed: 23.96 samples/s ETA: 0 d 17 h  6 m	Data: 0.013 Tran: 0.008 F: 0.187 B: 0.345 O: 2.101 M: 0.014	Train-MLMAcc=0.631562,	MVRCAccuracy=0.676841,	MLMLossWVC=1.768416,	MVRCLoss=2.441773,	
Rank[  1]Epoch[7] Batch [9500]	Speed: 23.96 samples/s ETA: 0 d 17 h  6 m	Data: 0.012 Tran: 0.008 F: 0.187 B: 0.349 O: 2.097 M: 0.014	Train-MLMAcc=0.631562,	MVRCAccuracy=0.676841,	MLMLossWVC=1.768416,	MVRCLoss=2.441773,	
Rank[  3]Epoch[7] Batch [9500]	Speed: 23.96 samples/s ETA: 0 d 17 h  6 m	Data: 1.978 Tran: 0.009 F: 0.231 B: 0.348 O: 0.086 M: 0.014	Train-MLMAcc=0.631562,	MVRCAccuracy=0.676841,	MLMLossWVC=1.768416,	MVRCLoss=2.441773,	
Rank[  2]Epoch[7] Batch [9600]	Speed: 28.32 samples/s ETA: 0 d 14 h 24 m	Data: 0.014 Tran: 0.007 F: 0.149 B: 0.291 O: 1.791 M: 0.007	Train-MLMAcc=0.631546,	MVRCAccuracy=0.676842,	MLMLossWVC=1.768332,	MVRCLoss=2.441702,	
Rank[  0]Epoch[7] Batch [9600]	Speed: 28.32 samples/s ETA: 0 d 14 h 24 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.795 M: 0.005	Train-MLMAcc=0.631546,	MVRCAccuracy=0.676842,	MLMLossWVC=1.768332,	MVRCLoss=2.441702,	
Rank[  3]Epoch[7] Batch [9600]	Speed: 28.32 samples/s ETA: 0 d 14 h 24 m	Data: 1.568 Tran: 0.007 F: 0.162 B: 0.301 O: 0.214 M: 0.007	Train-MLMAcc=0.631546,	MVRCAccuracy=0.676842,	MLMLossWVC=1.768332,	MVRCLoss=2.441702,	
Rank[  1]Epoch[7] Batch [9600]	Speed: 28.32 samples/s ETA: 0 d 14 h 24 m	Data: 0.192 Tran: 0.007 F: 0.151 B: 0.302 O: 1.600 M: 0.007	Train-MLMAcc=0.631546,	MVRCAccuracy=0.676842,	MLMLossWVC=1.768332,	MVRCLoss=2.441702,	
Rank[  3]Epoch[7] Batch [9700]	Speed: 26.95 samples/s ETA: 0 d 15 h  4 m	Data: 0.423 Tran: 0.007 F: 0.155 B: 0.303 O: 1.477 M: 0.009	Train-MLMAcc=0.631549,	MVRCAccuracy=0.676851,	MLMLossWVC=1.768370,	MVRCLoss=2.441699,	
Rank[  0]Epoch[7] Batch [9700]	Speed: 26.95 samples/s ETA: 0 d 15 h  4 m	Data: 0.009 Tran: 0.007 F: 0.162 B: 0.308 O: 1.878 M: 0.009	Train-MLMAcc=0.631549,	MVRCAccuracy=0.676851,	MLMLossWVC=1.768370,	MVRCLoss=2.441699,	
Rank[  1]Epoch[7] Batch [9700]	Speed: 26.95 samples/s ETA: 0 d 15 h  4 m	Data: 1.353 Tran: 0.011 F: 0.193 B: 0.346 O: 0.460 M: 0.010	Train-MLMAcc=0.631549,	MVRCAccuracy=0.676851,	MLMLossWVC=1.768370,	MVRCLoss=2.441699,	
Rank[  2]Epoch[7] Batch [9700]	Speed: 26.95 samples/s ETA: 0 d 15 h  4 m	Data: 0.017 Tran: 0.007 F: 0.161 B: 0.311 O: 1.868 M: 0.008	Train-MLMAcc=0.631549,	MVRCAccuracy=0.676851,	MLMLossWVC=1.768370,	MVRCLoss=2.441699,	
Rank[  2]Epoch[7] Batch [9800]	Speed: 25.12 samples/s ETA: 0 d 16 h  6 m	Data: 0.146 Tran: 0.007 F: 0.168 B: 0.321 O: 1.887 M: 0.012	Train-MLMAcc=0.631563,	MVRCAccuracy=0.676847,	MLMLossWVC=1.768350,	MVRCLoss=2.441751,	
Rank[  0]Epoch[7] Batch [9800]	Speed: 25.12 samples/s ETA: 0 d 16 h  6 m	Data: 0.012 Tran: 0.008 F: 0.168 B: 0.321 O: 2.021 M: 0.013	Train-MLMAcc=0.631563,	MVRCAccuracy=0.676847,	MLMLossWVC=1.768350,	MVRCLoss=2.441751,	
Rank[  1]Epoch[7] Batch [9800]	Speed: 25.12 samples/s ETA: 0 d 16 h  6 m	Data: 1.864 Tran: 0.012 F: 0.213 B: 0.349 O: 0.091 M: 0.013	Train-MLMAcc=0.631563,	MVRCAccuracy=0.676847,	MLMLossWVC=1.768350,	MVRCLoss=2.441751,	
Rank[  3]Epoch[7] Batch [9800]	Speed: 25.12 samples/s ETA: 0 d 16 h  6 m	Data: 0.152 Tran: 0.007 F: 0.173 B: 0.312 O: 1.885 M: 0.012	Train-MLMAcc=0.631563,	MVRCAccuracy=0.676847,	MLMLossWVC=1.768350,	MVRCLoss=2.441751,	
Rank[  1]Epoch[7] Batch [9900]	Speed: 27.99 samples/s ETA: 0 d 14 h 23 m	Data: 1.759 Tran: 0.007 F: 0.161 B: 0.300 O: 0.051 M: 0.009	Train-MLMAcc=0.631546,	MVRCAccuracy=0.676842,	MLMLossWVC=1.768310,	MVRCLoss=2.441695,	
Rank[  2]Epoch[7] Batch [9900]	Speed: 27.99 samples/s ETA: 0 d 14 h 23 m	Data: 0.008 Tran: 0.007 F: 0.167 B: 0.305 O: 1.791 M: 0.007	Train-MLMAcc=0.631546,	MVRCAccuracy=0.676842,	MLMLossWVC=1.768310,	MVRCLoss=2.441695,	
Rank[  0]Epoch[7] Batch [9900]	Speed: 27.99 samples/s ETA: 0 d 14 h 23 m	Data: 0.008 Tran: 0.007 F: 0.167 B: 0.305 O: 1.790 M: 0.008	Train-MLMAcc=0.631546,	MVRCAccuracy=0.676842,	MLMLossWVC=1.768310,	MVRCLoss=2.441695,	
Rank[  3]Epoch[7] Batch [9900]	Speed: 27.99 samples/s ETA: 0 d 14 h 23 m	Data: 0.144 Tran: 0.007 F: 0.166 B: 0.301 O: 1.659 M: 0.009	Train-MLMAcc=0.631546,	MVRCAccuracy=0.676842,	MLMLossWVC=1.768310,	MVRCLoss=2.441695,	
Rank[  2]Epoch[7] Batch [10000]	Speed: 27.82 samples/s ETA: 0 d 14 h 24 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.830 M: 0.009	Train-MLMAcc=0.631559,	MVRCAccuracy=0.676840,	MLMLossWVC=1.768274,	MVRCLoss=2.441672,	
Rank[  0]Epoch[7] Batch [10000]	Speed: 27.82 samples/s ETA: 0 d 14 h 24 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.293 O: 1.830 M: 0.009	Train-MLMAcc=0.631559,	MVRCAccuracy=0.676840,	MLMLossWVC=1.768274,	MVRCLoss=2.441672,	
Rank[  1]Epoch[7] Batch [10000]	Speed: 27.82 samples/s ETA: 0 d 14 h 24 m	Data: 1.736 Tran: 0.007 F: 0.176 B: 0.315 O: 0.054 M: 0.009	Train-MLMAcc=0.631559,	MVRCAccuracy=0.676840,	MLMLossWVC=1.768274,	MVRCLoss=2.441672,	
Rank[  3]Epoch[7] Batch [10000]	Speed: 27.82 samples/s ETA: 0 d 14 h 24 m	Data: 0.628 Tran: 0.007 F: 0.150 B: 0.308 O: 1.196 M: 0.009	Train-MLMAcc=0.631559,	MVRCAccuracy=0.676840,	MLMLossWVC=1.768274,	MVRCLoss=2.441672,	
Rank[  1]Epoch[7] Batch [10100]	Speed: 27.74 samples/s ETA: 0 d 14 h 23 m	Data: 1.685 Tran: 0.018 F: 0.188 B: 0.304 O: 0.101 M: 0.008	Train-MLMAcc=0.631521,	MVRCAccuracy=0.676851,	MLMLossWVC=1.768439,	MVRCLoss=2.441639,	
Rank[  3]Epoch[7] Batch [10100]	Speed: 27.74 samples/s ETA: 0 d 14 h 23 m	Data: 0.707 Tran: 0.012 F: 0.159 B: 0.291 O: 1.128 M: 0.009	Train-MLMAcc=0.631521,	MVRCAccuracy=0.676851,	MLMLossWVC=1.768439,	MVRCLoss=2.441639,	
Rank[  2]Epoch[7] Batch [10100]	Speed: 27.74 samples/s ETA: 0 d 14 h 23 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.840 M: 0.008	Train-MLMAcc=0.631521,	MVRCAccuracy=0.676851,	MLMLossWVC=1.768439,	MVRCLoss=2.441639,	
Rank[  0]Epoch[7] Batch [10100]	Speed: 27.74 samples/s ETA: 0 d 14 h 23 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.844 M: 0.006	Train-MLMAcc=0.631521,	MVRCAccuracy=0.676851,	MLMLossWVC=1.768439,	MVRCLoss=2.441639,	
Rank[  2]Epoch[7] Batch [10200]	Speed: 27.50 samples/s ETA: 0 d 14 h 26 m	Data: 0.008 Tran: 0.007 F: 0.155 B: 0.309 O: 1.838 M: 0.009	Train-MLMAcc=0.631524,	MVRCAccuracy=0.676861,	MLMLossWVC=1.768296,	MVRCLoss=2.441594,	
Rank[  1]Epoch[7] Batch [10200]	Speed: 27.50 samples/s ETA: 0 d 14 h 26 m	Data: 1.774 Tran: 0.007 F: 0.164 B: 0.321 O: 0.050 M: 0.009	Train-MLMAcc=0.631524,	MVRCAccuracy=0.676861,	MLMLossWVC=1.768296,	MVRCLoss=2.441594,	
Rank[  3]Epoch[7] Batch [10200]	Speed: 27.50 samples/s ETA: 0 d 14 h 26 m	Data: 0.140 Tran: 0.008 F: 0.156 B: 0.307 O: 1.708 M: 0.008	Train-MLMAcc=0.631524,	MVRCAccuracy=0.676861,	MLMLossWVC=1.768296,	MVRCLoss=2.441594,	
Rank[  0]Epoch[7] Batch [10200]	Speed: 27.50 samples/s ETA: 0 d 14 h 26 m	Data: 0.009 Tran: 0.007 F: 0.154 B: 0.308 O: 1.840 M: 0.008	Train-MLMAcc=0.631524,	MVRCAccuracy=0.676861,	MLMLossWVC=1.768296,	MVRCLoss=2.441594,	
Rank[  3]Epoch[7] Batch [10300]	Speed: 27.59 samples/s ETA: 0 d 14 h 20 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.294 O: 1.850 M: 0.009	Train-MLMAcc=0.631539,	MVRCAccuracy=0.676866,	MLMLossWVC=1.768060,	MVRCLoss=2.441636,	
Rank[  0]Epoch[7] Batch [10300]	Speed: 27.59 samples/s ETA: 0 d 14 h 20 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.846 M: 0.008	Train-MLMAcc=0.631539,	MVRCAccuracy=0.676866,	MLMLossWVC=1.768060,	MVRCLoss=2.441636,	
Rank[  2]Epoch[7] Batch [10300]	Speed: 27.59 samples/s ETA: 0 d 14 h 20 m	Data: 0.012 Tran: 0.007 F: 0.149 B: 0.296 O: 1.844 M: 0.009	Train-MLMAcc=0.631539,	MVRCAccuracy=0.676866,	MLMLossWVC=1.768060,	MVRCLoss=2.441636,	
Rank[  1]Epoch[7] Batch [10300]	Speed: 27.59 samples/s ETA: 0 d 14 h 20 m	Data: 1.771 Tran: 0.008 F: 0.167 B: 0.306 O: 0.057 M: 0.008	Train-MLMAcc=0.631539,	MVRCAccuracy=0.676866,	MLMLossWVC=1.768060,	MVRCLoss=2.441636,	
Rank[  0]Epoch[7] Batch [10400]	Speed: 28.21 samples/s ETA: 0 d 13 h 57 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.796 M: 0.008	Train-MLMAcc=0.631496,	MVRCAccuracy=0.676879,	MLMLossWVC=1.768200,	MVRCLoss=2.441605,	
Rank[  2]Epoch[7] Batch [10400]	Speed: 28.21 samples/s ETA: 0 d 13 h 57 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.795 M: 0.009	Train-MLMAcc=0.631496,	MVRCAccuracy=0.676879,	MLMLossWVC=1.768200,	MVRCLoss=2.441605,	
Rank[  1]Epoch[7] Batch [10400]	Speed: 28.21 samples/s ETA: 0 d 13 h 57 m	Data: 1.707 Tran: 0.008 F: 0.179 B: 0.314 O: 0.052 M: 0.007	Train-MLMAcc=0.631496,	MVRCAccuracy=0.676879,	MLMLossWVC=1.768200,	MVRCLoss=2.441605,	
Rank[  3]Epoch[7] Batch [10400]	Speed: 28.21 samples/s ETA: 0 d 13 h 57 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.799 M: 0.007	Train-MLMAcc=0.631496,	MVRCAccuracy=0.676879,	MLMLossWVC=1.768200,	MVRCLoss=2.441605,	
Rank[  0]Epoch[7] Batch [10500]	Speed: 26.53 samples/s ETA: 0 d 14 h 46 m	Data: 0.012 Tran: 0.007 F: 0.194 B: 0.336 O: 1.847 M: 0.013	Train-MLMAcc=0.631469,	MVRCAccuracy=0.676921,	MLMLossWVC=1.768111,	MVRCLoss=2.441589,	
Rank[  2]Epoch[7] Batch [10500]	Speed: 26.53 samples/s ETA: 0 d 14 h 46 m	Data: 0.012 Tran: 0.009 F: 0.196 B: 0.337 O: 1.843 M: 0.013	Train-MLMAcc=0.631469,	MVRCAccuracy=0.676921,	MLMLossWVC=1.768111,	MVRCLoss=2.441589,	
Rank[  3]Epoch[7] Batch [10500]	Speed: 26.53 samples/s ETA: 0 d 14 h 46 m	Data: 0.012 Tran: 0.007 F: 0.194 B: 0.330 O: 1.853 M: 0.013	Train-MLMAcc=0.631469,	MVRCAccuracy=0.676921,	MLMLossWVC=1.768111,	MVRCLoss=2.441589,	
Rank[  1]Epoch[7] Batch [10500]	Speed: 26.53 samples/s ETA: 0 d 14 h 46 m	Data: 1.751 Tran: 0.012 F: 0.216 B: 0.350 O: 0.066 M: 0.014	Train-MLMAcc=0.631469,	MVRCAccuracy=0.676921,	MLMLossWVC=1.768111,	MVRCLoss=2.441589,	
Rank[  0]Epoch[7] Batch [10600]	Speed: 22.72 samples/s ETA: 0 d 17 h 10 m	Data: 0.536 Tran: 0.009 F: 0.252 B: 0.431 O: 1.558 M: 0.024	Train-MLMAcc=0.631475,	MVRCAccuracy=0.676933,	MLMLossWVC=1.768098,	MVRCLoss=2.441550,	
Rank[  2]Epoch[7] Batch [10600]	Speed: 22.72 samples/s ETA: 0 d 17 h 10 m	Data: 0.573 Tran: 0.010 F: 0.249 B: 0.431 O: 1.525 M: 0.024	Train-MLMAcc=0.631475,	MVRCAccuracy=0.676933,	MLMLossWVC=1.768098,	MVRCLoss=2.441550,	
Rank[  3]Epoch[7] Batch [10600]	Speed: 22.72 samples/s ETA: 0 d 17 h 10 m	Data: 0.223 Tran: 0.008 F: 0.244 B: 0.439 O: 1.872 M: 0.024	Train-MLMAcc=0.631475,	MVRCAccuracy=0.676933,	MLMLossWVC=1.768098,	MVRCLoss=2.441550,	
Rank[  1]Epoch[7] Batch [10600]	Speed: 22.72 samples/s ETA: 0 d 17 h 10 m	Data: 1.804 Tran: 0.018 F: 0.313 B: 0.433 O: 0.219 M: 0.024	Train-MLMAcc=0.631475,	MVRCAccuracy=0.676933,	MLMLossWVC=1.768098,	MVRCLoss=2.441550,	
Rank[  1]Epoch[7] Batch [10700]	Speed: 24.03 samples/s ETA: 0 d 16 h  9 m	Data: 1.214 Tran: 0.013 F: 0.253 B: 0.369 O: 0.780 M: 0.030	Train-MLMAcc=0.631484,	MVRCAccuracy=0.676958,	MLMLossWVC=1.768001,	MVRCLoss=2.441498,	
Rank[  2]Epoch[7] Batch [10700]	Speed: 24.03 samples/s ETA: 0 d 16 h  9 m	Data: 0.543 Tran: 0.010 F: 0.201 B: 0.358 O: 1.519 M: 0.027	Train-MLMAcc=0.631484,	MVRCAccuracy=0.676958,	MLMLossWVC=1.768001,	MVRCLoss=2.441498,	
Rank[  3]Epoch[7] Batch [10700]	Speed: 24.03 samples/s ETA: 0 d 16 h  9 m	Data: 0.035 Tran: 0.007 F: 0.187 B: 0.348 O: 2.051 M: 0.030	Train-MLMAcc=0.631484,	MVRCAccuracy=0.676958,	MLMLossWVC=1.768001,	MVRCLoss=2.441498,	
Rank[  0]Epoch[7] Batch [10700]	Speed: 24.03 samples/s ETA: 0 d 16 h  9 m	Data: 0.985 Tran: 0.011 F: 0.221 B: 0.371 O: 1.041 M: 0.030	Train-MLMAcc=0.631484,	MVRCAccuracy=0.676958,	MLMLossWVC=1.768001,	MVRCLoss=2.441498,	
Rank[  0]Epoch[7] Batch [10800]	Speed: 27.94 samples/s ETA: 0 d 13 h 50 m	Data: 0.386 Tran: 0.007 F: 0.152 B: 0.295 O: 1.444 M: 0.006	Train-MLMAcc=0.631535,	MVRCAccuracy=0.676969,	MLMLossWVC=1.767818,	MVRCLoss=2.441468,	
Rank[  3]Epoch[7] Batch [10800]	Speed: 27.94 samples/s ETA: 0 d 13 h 50 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.824 M: 0.007	Train-MLMAcc=0.631535,	MVRCAccuracy=0.676969,	MLMLossWVC=1.767818,	MVRCLoss=2.441468,	
Rank[  1]Epoch[7] Batch [10800]	Speed: 27.94 samples/s ETA: 0 d 13 h 50 m	Data: 0.828 Tran: 0.007 F: 0.163 B: 0.304 O: 0.982 M: 0.007	Train-MLMAcc=0.631535,	MVRCAccuracy=0.676969,	MLMLossWVC=1.767818,	MVRCLoss=2.441468,	
Rank[  2]Epoch[7] Batch [10800]	Speed: 27.94 samples/s ETA: 0 d 13 h 50 m	Data: 1.137 Tran: 0.007 F: 0.158 B: 0.299 O: 0.681 M: 0.008	Train-MLMAcc=0.631535,	MVRCAccuracy=0.676969,	MLMLossWVC=1.767818,	MVRCLoss=2.441468,	
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Epoch[7] 	Val-MLMAcc=0.602253,	MVRCAccuracy=0.695467,	MLMLossWVC=1.942971,	MVRCLoss=2.457370,	
Epoch[7] 	Val-MLMAcc=0.602253,	MVRCAccuracy=0.695467,	MLMLossWVC=1.942971,	MVRCLoss=2.457370,	
Epoch[7] 	Val-MLMAcc=0.602253,	MVRCAccuracy=0.695467,	MLMLossWVC=1.942971,	MVRCLoss=2.457370,	
Epoch[7] 	Val-MLMAcc=0.602253,	MVRCAccuracy=0.695467,	MLMLossWVC=1.942971,	MVRCLoss=2.457370,	
Best Val MLMAcc: 0.6052337288856506, Epoch: 6
Best Val MLMAcc: 0.6052337288856506, Epoch: 6
PROGRESS: 80.00%
Best Val MLMAcc: 0.6052337288856506, Epoch: 6
PROGRESS: 80.00%
Best Val MLMAcc: 0.6052337288856506, Epoch: 6
PROGRESS: 80.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
PROGRESS: 80.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Rank[  0]Epoch[8] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.623288,	MVRCAccuracy=0.683161,	MLMLossWVC=1.996130,	MVRCLoss=2.378218,	
Rank[  1]Epoch[8] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.623288,	MVRCAccuracy=0.683161,	MLMLossWVC=1.996130,	MVRCLoss=2.378218,	
Rank[  2]Epoch[8] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.623288,	MVRCAccuracy=0.683161,	MLMLossWVC=1.996130,	MVRCLoss=2.378218,	
Rank[  3]Epoch[8] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.623288,	MVRCAccuracy=0.683161,	MLMLossWVC=1.996130,	MVRCLoss=2.378218,	
Rank[  3]Epoch[8] Batch [100]	Speed: 26.48 samples/s ETA: 0 d 14 h 30 m	Data: 0.392 Tran: 0.011 F: 0.240 B: 0.454 O: 2.896 M: 0.019	Train-MLMAcc=0.638088,	MVRCAccuracy=0.678110,	MLMLossWVC=1.737711,	MVRCLoss=2.440233,	
Rank[  0]Epoch[8] Batch [100]	Speed: 26.48 samples/s ETA: 0 d 14 h 30 m	Data: 2.268 Tran: 0.012 F: 0.270 B: 0.486 O: 0.864 M: 0.020	Train-MLMAcc=0.638088,	MVRCAccuracy=0.678110,	MLMLossWVC=1.737711,	MVRCLoss=2.440233,	
Rank[  1]Epoch[8] Batch [100]	Speed: 26.48 samples/s ETA: 0 d 14 h 30 m	Data: 0.930 Tran: 0.014 F: 0.258 B: 0.469 O: 2.324 M: 0.017	Train-MLMAcc=0.638088,	MVRCAccuracy=0.678110,	MLMLossWVC=1.737711,	MVRCLoss=2.440233,	
Rank[  2]Epoch[8] Batch [100]	Speed: 26.48 samples/s ETA: 0 d 14 h 30 m	Data: 0.905 Tran: 0.011 F: 0.240 B: 0.459 O: 2.378 M: 0.020	Train-MLMAcc=0.638088,	MVRCAccuracy=0.678110,	MLMLossWVC=1.737711,	MVRCLoss=2.440233,	
Rank[  0]Epoch[8] Batch [200]	Speed: 28.02 samples/s ETA: 0 d 13 h 38 m	Data: 1.770 Tran: 0.007 F: 0.153 B: 0.291 O: 0.056 M: 0.006	Train-MLMAcc=0.638987,	MVRCAccuracy=0.678916,	MLMLossWVC=1.725382,	MVRCLoss=2.438319,	
Rank[  2]Epoch[8] Batch [200]	Speed: 28.02 samples/s ETA: 0 d 13 h 38 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.291 O: 1.820 M: 0.007	Train-MLMAcc=0.638987,	MVRCAccuracy=0.678916,	MLMLossWVC=1.725382,	MVRCLoss=2.438319,	
Rank[  1]Epoch[8] Batch [200]	Speed: 28.02 samples/s ETA: 0 d 13 h 38 m	Data: 0.018 Tran: 0.008 F: 0.151 B: 0.299 O: 1.802 M: 0.006	Train-MLMAcc=0.638987,	MVRCAccuracy=0.678916,	MLMLossWVC=1.725382,	MVRCLoss=2.438319,	
Rank[  3]Epoch[8] Batch [200]	Speed: 28.02 samples/s ETA: 0 d 13 h 38 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.290 O: 1.820 M: 0.007	Train-MLMAcc=0.638987,	MVRCAccuracy=0.678916,	MLMLossWVC=1.725382,	MVRCLoss=2.438319,	
Rank[  0]Epoch[8] Batch [300]	Speed: 28.09 samples/s ETA: 0 d 13 h 32 m	Data: 1.413 Tran: 0.007 F: 0.150 B: 0.292 O: 0.408 M: 0.008	Train-MLMAcc=0.637004,	MVRCAccuracy=0.679546,	MLMLossWVC=1.731387,	MVRCLoss=2.436616,	
Rank[  2]Epoch[8] Batch [300]	Speed: 28.09 samples/s ETA: 0 d 13 h 32 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 1.811 M: 0.008	Train-MLMAcc=0.637004,	MVRCAccuracy=0.679546,	MLMLossWVC=1.731387,	MVRCLoss=2.436616,	
Rank[  1]Epoch[8] Batch [300]	Speed: 28.09 samples/s ETA: 0 d 13 h 32 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.809 M: 0.007	Train-MLMAcc=0.637004,	MVRCAccuracy=0.679546,	MLMLossWVC=1.731387,	MVRCLoss=2.436616,	
Rank[  3]Epoch[8] Batch [300]	Speed: 28.09 samples/s ETA: 0 d 13 h 32 m	Data: 0.362 Tran: 0.007 F: 0.150 B: 0.291 O: 1.459 M: 0.008	Train-MLMAcc=0.637004,	MVRCAccuracy=0.679546,	MLMLossWVC=1.731387,	MVRCLoss=2.436616,	
Rank[  0]Epoch[8] Batch [400]	Speed: 27.74 samples/s ETA: 0 d 13 h 38 m	Data: 1.328 Tran: 0.007 F: 0.152 B: 0.294 O: 0.517 M: 0.008	Train-MLMAcc=0.635773,	MVRCAccuracy=0.679749,	MLMLossWVC=1.737008,	MVRCLoss=2.437188,	
Rank[  1]Epoch[8] Batch [400]	Speed: 27.74 samples/s ETA: 0 d 13 h 38 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.833 M: 0.010	Train-MLMAcc=0.635773,	MVRCAccuracy=0.679749,	MLMLossWVC=1.737008,	MVRCLoss=2.437188,	
Rank[  2]Epoch[8] Batch [400]	Speed: 27.74 samples/s ETA: 0 d 13 h 38 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.294 O: 1.838 M: 0.008	Train-MLMAcc=0.635773,	MVRCAccuracy=0.679749,	MLMLossWVC=1.737008,	MVRCLoss=2.437188,	
Rank[  3]Epoch[8] Batch [400]	Speed: 27.74 samples/s ETA: 0 d 13 h 38 m	Data: 0.471 Tran: 0.007 F: 0.151 B: 0.291 O: 1.378 M: 0.008	Train-MLMAcc=0.635773,	MVRCAccuracy=0.679749,	MLMLossWVC=1.737008,	MVRCLoss=2.437188,	
Rank[  2]Epoch[8] Batch [500]	Speed: 28.22 samples/s ETA: 0 d 13 h 21 m	Data: 0.011 Tran: 0.007 F: 0.151 B: 0.293 O: 1.796 M: 0.007	Train-MLMAcc=0.635878,	MVRCAccuracy=0.679209,	MLMLossWVC=1.738782,	MVRCLoss=2.438139,	
Rank[  0]Epoch[8] Batch [500]	Speed: 28.22 samples/s ETA: 0 d 13 h 21 m	Data: 1.098 Tran: 0.007 F: 0.157 B: 0.292 O: 0.706 M: 0.007	Train-MLMAcc=0.635878,	MVRCAccuracy=0.679209,	MLMLossWVC=1.738782,	MVRCLoss=2.438139,	
Rank[  1]Epoch[8] Batch [500]	Speed: 28.22 samples/s ETA: 0 d 13 h 21 m	Data: 0.011 Tran: 0.007 F: 0.152 B: 0.300 O: 1.789 M: 0.007	Train-MLMAcc=0.635878,	MVRCAccuracy=0.679209,	MLMLossWVC=1.738782,	MVRCLoss=2.438139,	
Rank[  3]Epoch[8] Batch [500]	Speed: 28.22 samples/s ETA: 0 d 13 h 21 m	Data: 0.624 Tran: 0.008 F: 0.156 B: 0.322 O: 1.150 M: 0.006	Train-MLMAcc=0.635878,	MVRCAccuracy=0.679209,	MLMLossWVC=1.738782,	MVRCLoss=2.438139,	
Rank[  0]Epoch[8] Batch [600]	Speed: 28.41 samples/s ETA: 0 d 13 h 12 m	Data: 0.232 Tran: 0.007 F: 0.149 B: 0.291 O: 1.564 M: 0.008	Train-MLMAcc=0.635870,	MVRCAccuracy=0.678747,	MLMLossWVC=1.742112,	MVRCLoss=2.437549,	
Rank[  1]Epoch[8] Batch [600]	Speed: 28.41 samples/s ETA: 0 d 13 h 12 m	Data: 0.075 Tran: 0.007 F: 0.149 B: 0.297 O: 1.716 M: 0.007	Train-MLMAcc=0.635870,	MVRCAccuracy=0.678747,	MLMLossWVC=1.742112,	MVRCLoss=2.437549,	
Rank[  3]Epoch[8] Batch [600]	Speed: 28.41 samples/s ETA: 0 d 13 h 12 m	Data: 1.649 Tran: 0.007 F: 0.151 B: 0.291 O: 0.145 M: 0.008	Train-MLMAcc=0.635870,	MVRCAccuracy=0.678747,	MLMLossWVC=1.742112,	MVRCLoss=2.437549,	
Rank[  2]Epoch[8] Batch [600]	Speed: 28.41 samples/s ETA: 0 d 13 h 12 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.786 M: 0.008	Train-MLMAcc=0.635870,	MVRCAccuracy=0.678747,	MLMLossWVC=1.742112,	MVRCLoss=2.437549,	
Rank[  1]Epoch[8] Batch [700]	Speed: 27.97 samples/s ETA: 0 d 13 h 20 m	Data: 0.023 Tran: 0.007 F: 0.150 B: 0.297 O: 1.804 M: 0.006	Train-MLMAcc=0.634851,	MVRCAccuracy=0.678503,	MLMLossWVC=1.743991,	MVRCLoss=2.437891,	
Rank[  0]Epoch[8] Batch [700]	Speed: 27.97 samples/s ETA: 0 d 13 h 20 m	Data: 0.185 Tran: 0.007 F: 0.150 B: 0.292 O: 1.646 M: 0.008	Train-MLMAcc=0.634851,	MVRCAccuracy=0.678503,	MLMLossWVC=1.743991,	MVRCLoss=2.437891,	
Rank[  2]Epoch[8] Batch [700]	Speed: 27.97 samples/s ETA: 0 d 13 h 20 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.821 M: 0.008	Train-MLMAcc=0.634851,	MVRCAccuracy=0.678503,	MLMLossWVC=1.743991,	MVRCLoss=2.437891,	
Rank[  3]Epoch[8] Batch [700]	Speed: 27.97 samples/s ETA: 0 d 13 h 20 m	Data: 1.599 Tran: 0.006 F: 0.151 B: 0.291 O: 0.231 M: 0.008	Train-MLMAcc=0.634851,	MVRCAccuracy=0.678503,	MLMLossWVC=1.743991,	MVRCLoss=2.437891,	
Rank[  0]Epoch[8] Batch [800]	Speed: 27.93 samples/s ETA: 0 d 13 h 18 m	Data: 0.046 Tran: 0.007 F: 0.150 B: 0.291 O: 1.789 M: 0.008	Train-MLMAcc=0.634186,	MVRCAccuracy=0.678596,	MLMLossWVC=1.746877,	MVRCLoss=2.436613,	
Rank[  2]Epoch[8] Batch [800]	Speed: 27.93 samples/s ETA: 0 d 13 h 18 m	Data: 0.007 Tran: 0.008 F: 0.150 B: 0.293 O: 1.825 M: 0.008	Train-MLMAcc=0.634186,	MVRCAccuracy=0.678596,	MLMLossWVC=1.746877,	MVRCLoss=2.436613,	
Rank[  3]Epoch[8] Batch [800]	Speed: 27.93 samples/s ETA: 0 d 13 h 18 m	Data: 1.741 Tran: 0.007 F: 0.150 B: 0.289 O: 0.096 M: 0.009	Train-MLMAcc=0.634186,	MVRCAccuracy=0.678596,	MLMLossWVC=1.746877,	MVRCLoss=2.436613,	
Rank[  1]Epoch[8] Batch [800]	Speed: 27.93 samples/s ETA: 0 d 13 h 18 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.819 M: 0.009	Train-MLMAcc=0.634186,	MVRCAccuracy=0.678596,	MLMLossWVC=1.746877,	MVRCLoss=2.436613,	
Rank[  2]Epoch[8] Batch [900]	Speed: 27.95 samples/s ETA: 0 d 13 h 13 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.293 O: 1.822 M: 0.009	Train-MLMAcc=0.633689,	MVRCAccuracy=0.678605,	MLMLossWVC=1.750391,	MVRCLoss=2.437018,	
Rank[  0]Epoch[8] Batch [900]	Speed: 27.95 samples/s ETA: 0 d 13 h 13 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.826 M: 0.007	Train-MLMAcc=0.633689,	MVRCAccuracy=0.678605,	MLMLossWVC=1.750391,	MVRCLoss=2.437018,	
Rank[  1]Epoch[8] Batch [900]	Speed: 27.95 samples/s ETA: 0 d 13 h 13 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.819 M: 0.008	Train-MLMAcc=0.633689,	MVRCAccuracy=0.678605,	MLMLossWVC=1.750391,	MVRCLoss=2.437018,	
Rank[  3]Epoch[8] Batch [900]	Speed: 27.95 samples/s ETA: 0 d 13 h 13 m	Data: 1.775 Tran: 0.007 F: 0.151 B: 0.290 O: 0.057 M: 0.009	Train-MLMAcc=0.633689,	MVRCAccuracy=0.678605,	MLMLossWVC=1.750391,	MVRCLoss=2.437018,	
Rank[  0]Epoch[8] Batch [1000]	Speed: 27.24 samples/s ETA: 0 d 13 h 30 m	Data: 0.008 Tran: 0.007 F: 0.166 B: 0.328 O: 1.830 M: 0.009	Train-MLMAcc=0.634074,	MVRCAccuracy=0.678801,	MLMLossWVC=1.748933,	MVRCLoss=2.436784,	
Rank[  2]Epoch[8] Batch [1000]	Speed: 27.24 samples/s ETA: 0 d 13 h 30 m	Data: 0.013 Tran: 0.008 F: 0.161 B: 0.328 O: 1.829 M: 0.010	Train-MLMAcc=0.634074,	MVRCAccuracy=0.678801,	MLMLossWVC=1.748933,	MVRCLoss=2.436784,	
Rank[  1]Epoch[8] Batch [1000]	Speed: 27.24 samples/s ETA: 0 d 13 h 30 m	Data: 0.013 Tran: 0.007 F: 0.161 B: 0.332 O: 1.825 M: 0.010	Train-MLMAcc=0.634074,	MVRCAccuracy=0.678801,	MLMLossWVC=1.748933,	MVRCLoss=2.436784,	
Rank[  3]Epoch[8] Batch [1000]	Speed: 27.24 samples/s ETA: 0 d 13 h 30 m	Data: 1.758 Tran: 0.007 F: 0.177 B: 0.321 O: 0.076 M: 0.009	Train-MLMAcc=0.634074,	MVRCAccuracy=0.678801,	MLMLossWVC=1.748933,	MVRCLoss=2.436784,	
Rank[  3]Epoch[8] Batch [1100]	Speed: 26.89 samples/s ETA: 0 d 13 h 37 m	Data: 1.656 Tran: 0.009 F: 0.193 B: 0.318 O: 0.189 M: 0.013	Train-MLMAcc=0.633827,	MVRCAccuracy=0.678781,	MLMLossWVC=1.750726,	MVRCLoss=2.436865,	
Rank[  1]Epoch[8] Batch [1100]	Speed: 26.89 samples/s ETA: 0 d 13 h 37 m	Data: 0.015 Tran: 0.007 F: 0.157 B: 0.317 O: 1.868 M: 0.014	Train-MLMAcc=0.633827,	MVRCAccuracy=0.678781,	MLMLossWVC=1.750726,	MVRCLoss=2.436865,	
Rank[  2]Epoch[8] Batch [1100]	Speed: 26.89 samples/s ETA: 0 d 13 h 37 m	Data: 0.085 Tran: 0.008 F: 0.155 B: 0.309 O: 1.806 M: 0.013	Train-MLMAcc=0.633827,	MVRCAccuracy=0.678781,	MLMLossWVC=1.750726,	MVRCLoss=2.436865,	
Rank[  0]Epoch[8] Batch [1100]	Speed: 26.89 samples/s ETA: 0 d 13 h 37 m	Data: 0.071 Tran: 0.008 F: 0.158 B: 0.308 O: 1.819 M: 0.014	Train-MLMAcc=0.633827,	MVRCAccuracy=0.678781,	MLMLossWVC=1.750726,	MVRCLoss=2.436865,	
Rank[  0]Epoch[8] Batch [1200]	Speed: 26.92 samples/s ETA: 0 d 13 h 32 m	Data: 0.071 Tran: 0.007 F: 0.151 B: 0.294 O: 1.847 M: 0.008	Train-MLMAcc=0.633627,	MVRCAccuracy=0.678845,	MLMLossWVC=1.751276,	MVRCLoss=2.436534,	
Rank[  1]Epoch[8] Batch [1200]	Speed: 26.92 samples/s ETA: 0 d 13 h 32 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.907 M: 0.008	Train-MLMAcc=0.633627,	MVRCAccuracy=0.678845,	MLMLossWVC=1.751276,	MVRCLoss=2.436534,	
Rank[  3]Epoch[8] Batch [1200]	Speed: 26.92 samples/s ETA: 0 d 13 h 32 m	Data: 1.817 Tran: 0.006 F: 0.151 B: 0.291 O: 0.103 M: 0.008	Train-MLMAcc=0.633627,	MVRCAccuracy=0.678845,	MLMLossWVC=1.751276,	MVRCLoss=2.436534,	
Rank[  2]Epoch[8] Batch [1200]	Speed: 26.92 samples/s ETA: 0 d 13 h 32 m	Data: 0.383 Tran: 0.007 F: 0.149 B: 0.292 O: 1.537 M: 0.009	Train-MLMAcc=0.633627,	MVRCAccuracy=0.678845,	MLMLossWVC=1.751276,	MVRCLoss=2.436534,	
Rank[  2]Epoch[8] Batch [1300]	Speed: 26.61 samples/s ETA: 0 d 13 h 37 m	Data: 1.113 Tran: 0.009 F: 0.179 B: 0.303 O: 0.791 M: 0.009	Train-MLMAcc=0.633621,	MVRCAccuracy=0.679088,	MLMLossWVC=1.751977,	MVRCLoss=2.436826,	
Rank[  3]Epoch[8] Batch [1300]	Speed: 26.61 samples/s ETA: 0 d 13 h 37 m	Data: 1.803 Tran: 0.007 F: 0.170 B: 0.301 O: 0.117 M: 0.007	Train-MLMAcc=0.633621,	MVRCAccuracy=0.679088,	MLMLossWVC=1.751977,	MVRCLoss=2.436826,	
Rank[  1]Epoch[8] Batch [1300]	Speed: 26.61 samples/s ETA: 0 d 13 h 37 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.932 M: 0.009	Train-MLMAcc=0.633621,	MVRCAccuracy=0.679088,	MLMLossWVC=1.751977,	MVRCLoss=2.436826,	
Rank[  0]Epoch[8] Batch [1300]	Speed: 26.61 samples/s ETA: 0 d 13 h 37 m	Data: 0.009 Tran: 0.007 F: 0.149 B: 0.292 O: 1.940 M: 0.008	Train-MLMAcc=0.633621,	MVRCAccuracy=0.679088,	MLMLossWVC=1.751977,	MVRCLoss=2.436826,	
Rank[  1]Epoch[8] Batch [1400]	Speed: 27.26 samples/s ETA: 0 d 13 h 14 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.300 O: 1.872 M: 0.009	Train-MLMAcc=0.633839,	MVRCAccuracy=0.679035,	MLMLossWVC=1.750763,	MVRCLoss=2.436859,	
Rank[  0]Epoch[8] Batch [1400]	Speed: 27.26 samples/s ETA: 0 d 13 h 14 m	Data: 0.023 Tran: 0.007 F: 0.150 B: 0.293 O: 1.865 M: 0.009	Train-MLMAcc=0.633839,	MVRCAccuracy=0.679035,	MLMLossWVC=1.750763,	MVRCLoss=2.436859,	
Rank[  2]Epoch[8] Batch [1400]	Speed: 27.26 samples/s ETA: 0 d 13 h 14 m	Data: 0.809 Tran: 0.007 F: 0.150 B: 0.293 O: 1.080 M: 0.008	Train-MLMAcc=0.633839,	MVRCAccuracy=0.679035,	MLMLossWVC=1.750763,	MVRCLoss=2.436859,	
Rank[  3]Epoch[8] Batch [1400]	Speed: 27.26 samples/s ETA: 0 d 13 h 14 m	Data: 1.746 Tran: 0.007 F: 0.150 B: 0.291 O: 0.144 M: 0.010	Train-MLMAcc=0.633839,	MVRCAccuracy=0.679035,	MLMLossWVC=1.750763,	MVRCLoss=2.436859,	
Rank[  2]Epoch[8] Batch [1500]	Speed: 25.99 samples/s ETA: 0 d 13 h 49 m	Data: 0.043 Tran: 0.008 F: 0.160 B: 0.304 O: 1.930 M: 0.016	Train-MLMAcc=0.633771,	MVRCAccuracy=0.678953,	MLMLossWVC=1.750854,	MVRCLoss=2.437552,	
Rank[  0]Epoch[8] Batch [1500]	Speed: 25.99 samples/s ETA: 0 d 13 h 49 m	Data: 0.009 Tran: 0.008 F: 0.161 B: 0.303 O: 1.967 M: 0.013	Train-MLMAcc=0.633771,	MVRCAccuracy=0.678953,	MLMLossWVC=1.750854,	MVRCLoss=2.437552,	
Rank[  3]Epoch[8] Batch [1500]	Speed: 25.99 samples/s ETA: 0 d 13 h 49 m	Data: 1.860 Tran: 0.012 F: 0.196 B: 0.312 O: 0.065 M: 0.015	Train-MLMAcc=0.633771,	MVRCAccuracy=0.678953,	MLMLossWVC=1.750854,	MVRCLoss=2.437552,	
Rank[  1]Epoch[8] Batch [1500]	Speed: 25.99 samples/s ETA: 0 d 13 h 49 m	Data: 0.010 Tran: 0.008 F: 0.160 B: 0.309 O: 1.960 M: 0.013	Train-MLMAcc=0.633771,	MVRCAccuracy=0.678953,	MLMLossWVC=1.750854,	MVRCLoss=2.437552,	
Rank[  3]Epoch[8] Batch [1600]	Speed: 26.09 samples/s ETA: 0 d 13 h 41 m	Data: 1.896 Tran: 0.008 F: 0.180 B: 0.301 O: 0.059 M: 0.008	Train-MLMAcc=0.633822,	MVRCAccuracy=0.678875,	MLMLossWVC=1.751616,	MVRCLoss=2.437012,	
Rank[  2]Epoch[8] Batch [1600]	Speed: 26.09 samples/s ETA: 0 d 13 h 41 m	Data: 0.009 Tran: 0.007 F: 0.157 B: 0.297 O: 1.973 M: 0.009	Train-MLMAcc=0.633822,	MVRCAccuracy=0.678875,	MLMLossWVC=1.751616,	MVRCLoss=2.437012,	
Rank[  0]Epoch[8] Batch [1600]	Speed: 26.09 samples/s ETA: 0 d 13 h 41 m	Data: 0.009 Tran: 0.007 F: 0.156 B: 0.292 O: 1.978 M: 0.009	Train-MLMAcc=0.633822,	MVRCAccuracy=0.678875,	MLMLossWVC=1.751616,	MVRCLoss=2.437012,	
Rank[  1]Epoch[8] Batch [1600]	Speed: 26.09 samples/s ETA: 0 d 13 h 41 m	Data: 0.008 Tran: 0.008 F: 0.157 B: 0.302 O: 1.969 M: 0.008	Train-MLMAcc=0.633822,	MVRCAccuracy=0.678875,	MLMLossWVC=1.751616,	MVRCLoss=2.437012,	
Rank[  0]Epoch[8] Batch [1700]	Speed: 27.13 samples/s ETA: 0 d 13 h  6 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.892 M: 0.009	Train-MLMAcc=0.634078,	MVRCAccuracy=0.679043,	MLMLossWVC=1.750804,	MVRCLoss=2.436826,	
Rank[  3]Epoch[8] Batch [1700]	Speed: 27.13 samples/s ETA: 0 d 13 h  6 m	Data: 1.844 Tran: 0.007 F: 0.150 B: 0.288 O: 0.061 M: 0.009	Train-MLMAcc=0.634078,	MVRCAccuracy=0.679043,	MLMLossWVC=1.750804,	MVRCLoss=2.436826,	
Rank[  2]Epoch[8] Batch [1700]	Speed: 27.13 samples/s ETA: 0 d 13 h  6 m	Data: 0.010 Tran: 0.007 F: 0.150 B: 0.293 O: 1.891 M: 0.007	Train-MLMAcc=0.634078,	MVRCAccuracy=0.679043,	MLMLossWVC=1.750804,	MVRCLoss=2.436826,	
Rank[  1]Epoch[8] Batch [1700]	Speed: 27.13 samples/s ETA: 0 d 13 h  6 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.886 M: 0.009	Train-MLMAcc=0.634078,	MVRCAccuracy=0.679043,	MLMLossWVC=1.750804,	MVRCLoss=2.436826,	
Rank[  0]Epoch[8] Batch [1800]	Speed: 28.09 samples/s ETA: 0 d 12 h 35 m	Data: 0.053 Tran: 0.007 F: 0.150 B: 0.292 O: 1.768 M: 0.007	Train-MLMAcc=0.634218,	MVRCAccuracy=0.679099,	MLMLossWVC=1.750860,	MVRCLoss=2.436918,	
Rank[  3]Epoch[8] Batch [1800]	Speed: 28.09 samples/s ETA: 0 d 12 h 35 m	Data: 1.406 Tran: 0.007 F: 0.150 B: 0.290 O: 0.418 M: 0.007	Train-MLMAcc=0.634218,	MVRCAccuracy=0.679099,	MLMLossWVC=1.750860,	MVRCLoss=2.436918,	
Rank[  2]Epoch[8] Batch [1800]	Speed: 28.09 samples/s ETA: 0 d 12 h 35 m	Data: 0.510 Tran: 0.007 F: 0.150 B: 0.292 O: 1.311 M: 0.007	Train-MLMAcc=0.634218,	MVRCAccuracy=0.679099,	MLMLossWVC=1.750860,	MVRCLoss=2.436918,	
Rank[  1]Epoch[8] Batch [1800]	Speed: 28.09 samples/s ETA: 0 d 12 h 35 m	Data: 0.007 Tran: 0.008 F: 0.150 B: 0.298 O: 1.808 M: 0.006	Train-MLMAcc=0.634218,	MVRCAccuracy=0.679099,	MLMLossWVC=1.750860,	MVRCLoss=2.436918,	
Rank[  1]Epoch[8] Batch [1900]	Speed: 27.99 samples/s ETA: 0 d 12 h 34 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.296 O: 1.817 M: 0.008	Train-MLMAcc=0.634010,	MVRCAccuracy=0.679061,	MLMLossWVC=1.751907,	MVRCLoss=2.437216,	
Rank[  0]Epoch[8] Batch [1900]	Speed: 27.99 samples/s ETA: 0 d 12 h 34 m	Data: 0.013 Tran: 0.007 F: 0.150 B: 0.293 O: 1.814 M: 0.009	Train-MLMAcc=0.634010,	MVRCAccuracy=0.679061,	MLMLossWVC=1.751907,	MVRCLoss=2.437216,	
Rank[  3]Epoch[8] Batch [1900]	Speed: 27.99 samples/s ETA: 0 d 12 h 34 m	Data: 0.910 Tran: 0.007 F: 0.151 B: 0.292 O: 0.918 M: 0.007	Train-MLMAcc=0.634010,	MVRCAccuracy=0.679061,	MLMLossWVC=1.751907,	MVRCLoss=2.437216,	
Rank[  2]Epoch[8] Batch [1900]	Speed: 27.99 samples/s ETA: 0 d 12 h 34 m	Data: 1.499 Tran: 0.007 F: 0.150 B: 0.292 O: 0.330 M: 0.008	Train-MLMAcc=0.634010,	MVRCAccuracy=0.679061,	MLMLossWVC=1.751907,	MVRCLoss=2.437216,	
Rank[  2]Epoch[8] Batch [2000]	Speed: 26.53 samples/s ETA: 0 d 13 h 12 m	Data: 1.583 Tran: 0.008 F: 0.174 B: 0.316 O: 0.314 M: 0.011	Train-MLMAcc=0.633954,	MVRCAccuracy=0.678944,	MLMLossWVC=1.752620,	MVRCLoss=2.437507,	
Rank[  1]Epoch[8] Batch [2000]	Speed: 26.53 samples/s ETA: 0 d 13 h 12 m	Data: 0.010 Tran: 0.007 F: 0.164 B: 0.312 O: 1.905 M: 0.010	Train-MLMAcc=0.633954,	MVRCAccuracy=0.678944,	MLMLossWVC=1.752620,	MVRCLoss=2.437507,	
Rank[  0]Epoch[8] Batch [2000]	Speed: 26.53 samples/s ETA: 0 d 13 h 12 m	Data: 0.070 Tran: 0.007 F: 0.163 B: 0.305 O: 1.851 M: 0.010	Train-MLMAcc=0.633954,	MVRCAccuracy=0.678944,	MLMLossWVC=1.752620,	MVRCLoss=2.437507,	
Rank[  3]Epoch[8] Batch [2000]	Speed: 26.53 samples/s ETA: 0 d 13 h 12 m	Data: 1.717 Tran: 0.013 F: 0.185 B: 0.310 O: 0.171 M: 0.011	Train-MLMAcc=0.633954,	MVRCAccuracy=0.678944,	MLMLossWVC=1.752620,	MVRCLoss=2.437507,	
Rank[  3]Epoch[8] Batch [2100]	Speed: 27.82 samples/s ETA: 0 d 12 h 31 m	Data: 1.794 Tran: 0.007 F: 0.150 B: 0.291 O: 0.051 M: 0.007	Train-MLMAcc=0.633790,	MVRCAccuracy=0.679038,	MLMLossWVC=1.753420,	MVRCLoss=2.437779,	
Rank[  1]Epoch[8] Batch [2100]	Speed: 27.82 samples/s ETA: 0 d 12 h 31 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.832 M: 0.007	Train-MLMAcc=0.633790,	MVRCAccuracy=0.679038,	MLMLossWVC=1.753420,	MVRCLoss=2.437779,	
Rank[  0]Epoch[8] Batch [2100]	Speed: 27.82 samples/s ETA: 0 d 12 h 31 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.835 M: 0.007	Train-MLMAcc=0.633790,	MVRCAccuracy=0.679038,	MLMLossWVC=1.753420,	MVRCLoss=2.437779,	
Rank[  2]Epoch[8] Batch [2100]	Speed: 27.82 samples/s ETA: 0 d 12 h 31 m	Data: 1.005 Tran: 0.007 F: 0.150 B: 0.293 O: 0.838 M: 0.007	Train-MLMAcc=0.633790,	MVRCAccuracy=0.679038,	MLMLossWVC=1.753420,	MVRCLoss=2.437779,	
Rank[  2]Epoch[8] Batch [2200]	Speed: 28.45 samples/s ETA: 0 d 12 h 11 m	Data: 1.118 Tran: 0.007 F: 0.151 B: 0.295 O: 0.669 M: 0.008	Train-MLMAcc=0.633639,	MVRCAccuracy=0.679125,	MLMLossWVC=1.754557,	MVRCLoss=2.438089,	
Rank[  0]Epoch[8] Batch [2200]	Speed: 28.45 samples/s ETA: 0 d 12 h 11 m	Data: 0.021 Tran: 0.007 F: 0.150 B: 0.292 O: 1.771 M: 0.007	Train-MLMAcc=0.633639,	MVRCAccuracy=0.679125,	MLMLossWVC=1.754557,	MVRCLoss=2.438089,	
Rank[  1]Epoch[8] Batch [2200]	Speed: 28.45 samples/s ETA: 0 d 12 h 11 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.780 M: 0.008	Train-MLMAcc=0.633639,	MVRCAccuracy=0.679125,	MLMLossWVC=1.754557,	MVRCLoss=2.438089,	
Rank[  3]Epoch[8] Batch [2200]	Speed: 28.45 samples/s ETA: 0 d 12 h 11 m	Data: 1.601 Tran: 0.006 F: 0.150 B: 0.290 O: 0.192 M: 0.008	Train-MLMAcc=0.633639,	MVRCAccuracy=0.679125,	MLMLossWVC=1.754557,	MVRCLoss=2.438089,	
Rank[  1]Epoch[8] Batch [2300]	Speed: 26.47 samples/s ETA: 0 d 13 h  1 m	Data: 0.013 Tran: 0.009 F: 0.169 B: 0.308 O: 1.897 M: 0.015	Train-MLMAcc=0.633587,	MVRCAccuracy=0.679101,	MLMLossWVC=1.754860,	MVRCLoss=2.438174,	
Rank[  0]Epoch[8] Batch [2300]	Speed: 26.47 samples/s ETA: 0 d 13 h  1 m	Data: 0.229 Tran: 0.009 F: 0.170 B: 0.307 O: 1.680 M: 0.016	Train-MLMAcc=0.633587,	MVRCAccuracy=0.679101,	MLMLossWVC=1.754860,	MVRCLoss=2.438174,	
Rank[  2]Epoch[8] Batch [2300]	Speed: 26.47 samples/s ETA: 0 d 13 h  1 m	Data: 1.258 Tran: 0.009 F: 0.170 B: 0.328 O: 0.631 M: 0.014	Train-MLMAcc=0.633587,	MVRCAccuracy=0.679101,	MLMLossWVC=1.754860,	MVRCLoss=2.438174,	
Rank[  3]Epoch[8] Batch [2300]	Speed: 26.47 samples/s ETA: 0 d 13 h  1 m	Data: 1.668 Tran: 0.008 F: 0.194 B: 0.304 O: 0.222 M: 0.016	Train-MLMAcc=0.633587,	MVRCAccuracy=0.679101,	MLMLossWVC=1.754860,	MVRCLoss=2.438174,	
Rank[  1]Epoch[8] Batch [2400]	Speed: 26.58 samples/s ETA: 0 d 12 h 54 m	Data: 0.012 Tran: 0.012 F: 0.166 B: 0.320 O: 1.882 M: 0.015	Train-MLMAcc=0.633584,	MVRCAccuracy=0.679053,	MLMLossWVC=1.755408,	MVRCLoss=2.438233,	
Rank[  0]Epoch[8] Batch [2400]	Speed: 26.58 samples/s ETA: 0 d 12 h 54 m	Data: 0.354 Tran: 0.007 F: 0.190 B: 0.326 O: 1.514 M: 0.015	Train-MLMAcc=0.633584,	MVRCAccuracy=0.679053,	MLMLossWVC=1.755408,	MVRCLoss=2.438233,	
Rank[  2]Epoch[8] Batch [2400]	Speed: 26.58 samples/s ETA: 0 d 12 h 54 m	Data: 0.792 Tran: 0.009 F: 0.181 B: 0.323 O: 1.087 M: 0.015	Train-MLMAcc=0.633584,	MVRCAccuracy=0.679053,	MLMLossWVC=1.755408,	MVRCLoss=2.438233,	
Rank[  3]Epoch[8] Batch [2400]	Speed: 26.58 samples/s ETA: 0 d 12 h 54 m	Data: 1.602 Tran: 0.008 F: 0.191 B: 0.329 O: 0.261 M: 0.015	Train-MLMAcc=0.633584,	MVRCAccuracy=0.679053,	MLMLossWVC=1.755408,	MVRCLoss=2.438233,	
Rank[  3]Epoch[8] Batch [2500]	Speed: 27.78 samples/s ETA: 0 d 12 h 17 m	Data: 1.640 Tran: 0.006 F: 0.150 B: 0.290 O: 0.209 M: 0.007	Train-MLMAcc=0.633745,	MVRCAccuracy=0.679013,	MLMLossWVC=1.754488,	MVRCLoss=2.438246,	
Rank[  0]Epoch[8] Batch [2500]	Speed: 27.78 samples/s ETA: 0 d 12 h 17 m	Data: 0.142 Tran: 0.007 F: 0.150 B: 0.292 O: 1.704 M: 0.008	Train-MLMAcc=0.633745,	MVRCAccuracy=0.679013,	MLMLossWVC=1.754488,	MVRCLoss=2.438246,	
Rank[  1]Epoch[8] Batch [2500]	Speed: 27.78 samples/s ETA: 0 d 12 h 17 m	Data: 0.050 Tran: 0.007 F: 0.149 B: 0.296 O: 1.793 M: 0.008	Train-MLMAcc=0.633745,	MVRCAccuracy=0.679013,	MLMLossWVC=1.754488,	MVRCLoss=2.438246,	
Rank[  2]Epoch[8] Batch [2500]	Speed: 27.78 samples/s ETA: 0 d 12 h 17 m	Data: 0.127 Tran: 0.007 F: 0.150 B: 0.294 O: 1.720 M: 0.005	Train-MLMAcc=0.633745,	MVRCAccuracy=0.679013,	MLMLossWVC=1.754488,	MVRCLoss=2.438246,	
Rank[  3]Epoch[8] Batch [2600]	Speed: 25.99 samples/s ETA: 0 d 13 h  3 m	Data: 1.809 Tran: 0.008 F: 0.204 B: 0.320 O: 0.105 M: 0.012	Train-MLMAcc=0.633706,	MVRCAccuracy=0.678909,	MLMLossWVC=1.754172,	MVRCLoss=2.438433,	
Rank[  2]Epoch[8] Batch [2600]	Speed: 25.99 samples/s ETA: 0 d 13 h  3 m	Data: 0.010 Tran: 0.007 F: 0.169 B: 0.315 O: 1.946 M: 0.012	Train-MLMAcc=0.633706,	MVRCAccuracy=0.678909,	MLMLossWVC=1.754172,	MVRCLoss=2.438433,	
Rank[  0]Epoch[8] Batch [2600]	Speed: 25.99 samples/s ETA: 0 d 13 h  3 m	Data: 0.010 Tran: 0.007 F: 0.170 B: 0.313 O: 1.948 M: 0.011	Train-MLMAcc=0.633706,	MVRCAccuracy=0.678909,	MLMLossWVC=1.754172,	MVRCLoss=2.438433,	
Rank[  1]Epoch[8] Batch [2600]	Speed: 25.99 samples/s ETA: 0 d 13 h  3 m	Data: 0.086 Tran: 0.007 F: 0.169 B: 0.316 O: 1.868 M: 0.012	Train-MLMAcc=0.633706,	MVRCAccuracy=0.678909,	MLMLossWVC=1.754172,	MVRCLoss=2.438433,	
Rank[  1]Epoch[8] Batch [2700]	Speed: 27.24 samples/s ETA: 0 d 12 h 24 m	Data: 0.028 Tran: 0.007 F: 0.161 B: 0.307 O: 1.836 M: 0.008	Train-MLMAcc=0.633607,	MVRCAccuracy=0.678949,	MLMLossWVC=1.754551,	MVRCLoss=2.438546,	
Rank[  3]Epoch[8] Batch [2700]	Speed: 27.24 samples/s ETA: 0 d 12 h 24 m	Data: 1.747 Tran: 0.007 F: 0.163 B: 0.300 O: 0.122 M: 0.009	Train-MLMAcc=0.633607,	MVRCAccuracy=0.678949,	MLMLossWVC=1.754551,	MVRCLoss=2.438546,	
Rank[  2]Epoch[8] Batch [2700]	Speed: 27.24 samples/s ETA: 0 d 12 h 24 m	Data: 0.013 Tran: 0.007 F: 0.161 B: 0.304 O: 1.857 M: 0.007	Train-MLMAcc=0.633607,	MVRCAccuracy=0.678949,	MLMLossWVC=1.754551,	MVRCLoss=2.438546,	
Rank[  0]Epoch[8] Batch [2700]	Speed: 27.24 samples/s ETA: 0 d 12 h 24 m	Data: 0.065 Tran: 0.007 F: 0.160 B: 0.301 O: 1.808 M: 0.008	Train-MLMAcc=0.633607,	MVRCAccuracy=0.678949,	MLMLossWVC=1.754551,	MVRCLoss=2.438546,	
Rank[  3]Epoch[8] Batch [2800]	Speed: 27.20 samples/s ETA: 0 d 12 h 21 m	Data: 1.811 Tran: 0.007 F: 0.171 B: 0.296 O: 0.059 M: 0.008	Train-MLMAcc=0.633710,	MVRCAccuracy=0.679051,	MLMLossWVC=1.754243,	MVRCLoss=2.438133,	
Rank[  2]Epoch[8] Batch [2800]	Speed: 27.20 samples/s ETA: 0 d 12 h 21 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.885 M: 0.007	Train-MLMAcc=0.633710,	MVRCAccuracy=0.679051,	MLMLossWVC=1.754243,	MVRCLoss=2.438133,	
Rank[  0]Epoch[8] Batch [2800]	Speed: 27.20 samples/s ETA: 0 d 12 h 21 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.292 O: 1.886 M: 0.007	Train-MLMAcc=0.633710,	MVRCAccuracy=0.679051,	MLMLossWVC=1.754243,	MVRCLoss=2.438133,	
Rank[  1]Epoch[8] Batch [2800]	Speed: 27.20 samples/s ETA: 0 d 12 h 21 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.880 M: 0.009	Train-MLMAcc=0.633710,	MVRCAccuracy=0.679051,	MLMLossWVC=1.754243,	MVRCLoss=2.438133,	
Rank[  0]Epoch[8] Batch [2900]	Speed: 27.54 samples/s ETA: 0 d 12 h  8 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.856 M: 0.006	Train-MLMAcc=0.633841,	MVRCAccuracy=0.679016,	MLMLossWVC=1.753773,	MVRCLoss=2.438163,	
Rank[  2]Epoch[8] Batch [2900]	Speed: 27.54 samples/s ETA: 0 d 12 h  8 m	Data: 0.009 Tran: 0.008 F: 0.153 B: 0.296 O: 1.852 M: 0.006	Train-MLMAcc=0.633841,	MVRCAccuracy=0.679016,	MLMLossWVC=1.753773,	MVRCLoss=2.438163,	
Rank[  1]Epoch[8] Batch [2900]	Speed: 27.54 samples/s ETA: 0 d 12 h  8 m	Data: 0.009 Tran: 0.008 F: 0.149 B: 0.299 O: 1.852 M: 0.007	Train-MLMAcc=0.633841,	MVRCAccuracy=0.679016,	MLMLossWVC=1.753773,	MVRCLoss=2.438163,	
Rank[  3]Epoch[8] Batch [2900]	Speed: 27.54 samples/s ETA: 0 d 12 h  8 m	Data: 1.778 Tran: 0.008 F: 0.169 B: 0.303 O: 0.058 M: 0.007	Train-MLMAcc=0.633841,	MVRCAccuracy=0.679016,	MLMLossWVC=1.753773,	MVRCLoss=2.438163,	
Rank[  3]Epoch[8] Batch [3000]	Speed: 28.15 samples/s ETA: 0 d 11 h 48 m	Data: 1.643 Tran: 0.006 F: 0.150 B: 0.290 O: 0.173 M: 0.009	Train-MLMAcc=0.633762,	MVRCAccuracy=0.679071,	MLMLossWVC=1.753497,	MVRCLoss=2.438177,	
Rank[  2]Epoch[8] Batch [3000]	Speed: 28.15 samples/s ETA: 0 d 11 h 48 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.806 M: 0.007	Train-MLMAcc=0.633762,	MVRCAccuracy=0.679071,	MLMLossWVC=1.753497,	MVRCLoss=2.438177,	
Rank[  1]Epoch[8] Batch [3000]	Speed: 28.15 samples/s ETA: 0 d 11 h 48 m	Data: 0.033 Tran: 0.007 F: 0.149 B: 0.296 O: 1.778 M: 0.008	Train-MLMAcc=0.633762,	MVRCAccuracy=0.679071,	MLMLossWVC=1.753497,	MVRCLoss=2.438177,	
Rank[  0]Epoch[8] Batch [3000]	Speed: 28.15 samples/s ETA: 0 d 11 h 48 m	Data: 0.103 Tran: 0.007 F: 0.150 B: 0.291 O: 1.715 M: 0.008	Train-MLMAcc=0.633762,	MVRCAccuracy=0.679071,	MLMLossWVC=1.753497,	MVRCLoss=2.438177,	
Rank[  2]Epoch[8] Batch [3100]	Speed: 27.91 samples/s ETA: 0 d 11 h 51 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.826 M: 0.007	Train-MLMAcc=0.633892,	MVRCAccuracy=0.679053,	MLMLossWVC=1.752467,	MVRCLoss=2.438307,	
Rank[  0]Epoch[8] Batch [3100]	Speed: 27.91 samples/s ETA: 0 d 11 h 51 m	Data: 0.392 Tran: 0.007 F: 0.150 B: 0.291 O: 1.447 M: 0.007	Train-MLMAcc=0.633892,	MVRCAccuracy=0.679053,	MLMLossWVC=1.752467,	MVRCLoss=2.438307,	
Rank[  1]Epoch[8] Batch [3100]	Speed: 27.91 samples/s ETA: 0 d 11 h 51 m	Data: 0.014 Tran: 0.007 F: 0.150 B: 0.298 O: 1.817 M: 0.007	Train-MLMAcc=0.633892,	MVRCAccuracy=0.679053,	MLMLossWVC=1.752467,	MVRCLoss=2.438307,	
Rank[  3]Epoch[8] Batch [3100]	Speed: 27.91 samples/s ETA: 0 d 11 h 51 m	Data: 1.494 Tran: 0.006 F: 0.150 B: 0.289 O: 0.345 M: 0.008	Train-MLMAcc=0.633892,	MVRCAccuracy=0.679053,	MLMLossWVC=1.752467,	MVRCLoss=2.438307,	
Rank[  1]Epoch[8] Batch [3200]	Speed: 28.49 samples/s ETA: 0 d 11 h 32 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.775 M: 0.008	Train-MLMAcc=0.633908,	MVRCAccuracy=0.679073,	MLMLossWVC=1.752536,	MVRCLoss=2.438128,	
Rank[  0]Epoch[8] Batch [3200]	Speed: 28.49 samples/s ETA: 0 d 11 h 32 m	Data: 0.170 Tran: 0.007 F: 0.151 B: 0.293 O: 1.616 M: 0.009	Train-MLMAcc=0.633908,	MVRCAccuracy=0.679073,	MLMLossWVC=1.752536,	MVRCLoss=2.438128,	
Rank[  2]Epoch[8] Batch [3200]	Speed: 28.49 samples/s ETA: 0 d 11 h 32 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.293 O: 1.780 M: 0.009	Train-MLMAcc=0.633908,	MVRCAccuracy=0.679073,	MLMLossWVC=1.752536,	MVRCLoss=2.438128,	
Rank[  3]Epoch[8] Batch [3200]	Speed: 28.49 samples/s ETA: 0 d 11 h 32 m	Data: 1.601 Tran: 0.006 F: 0.150 B: 0.291 O: 0.187 M: 0.009	Train-MLMAcc=0.633908,	MVRCAccuracy=0.679073,	MLMLossWVC=1.752536,	MVRCLoss=2.438128,	
Rank[  2]Epoch[8] Batch [3300]	Speed: 27.90 samples/s ETA: 0 d 11 h 43 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.293 O: 1.827 M: 0.010	Train-MLMAcc=0.633878,	MVRCAccuracy=0.679107,	MLMLossWVC=1.752385,	MVRCLoss=2.438063,	
Rank[  1]Epoch[8] Batch [3300]	Speed: 27.90 samples/s ETA: 0 d 11 h 43 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.820 M: 0.009	Train-MLMAcc=0.633878,	MVRCAccuracy=0.679107,	MLMLossWVC=1.752385,	MVRCLoss=2.438063,	
Rank[  3]Epoch[8] Batch [3300]	Speed: 27.90 samples/s ETA: 0 d 11 h 43 m	Data: 1.788 Tran: 0.006 F: 0.150 B: 0.292 O: 0.047 M: 0.009	Train-MLMAcc=0.633878,	MVRCAccuracy=0.679107,	MLMLossWVC=1.752385,	MVRCLoss=2.438063,	
Rank[  0]Epoch[8] Batch [3300]	Speed: 27.90 samples/s ETA: 0 d 11 h 43 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.292 O: 1.829 M: 0.007	Train-MLMAcc=0.633878,	MVRCAccuracy=0.679107,	MLMLossWVC=1.752385,	MVRCLoss=2.438063,	
Rank[  1]Epoch[8] Batch [3400]	Speed: 25.58 samples/s ETA: 0 d 12 h 43 m	Data: 0.011 Tran: 0.007 F: 0.166 B: 0.334 O: 1.970 M: 0.012	Train-MLMAcc=0.633877,	MVRCAccuracy=0.679134,	MLMLossWVC=1.752491,	MVRCLoss=2.438107,	
Rank[  0]Epoch[8] Batch [3400]	Speed: 25.58 samples/s ETA: 0 d 12 h 43 m	Data: 0.012 Tran: 0.007 F: 0.166 B: 0.324 O: 1.979 M: 0.012	Train-MLMAcc=0.633877,	MVRCAccuracy=0.679134,	MLMLossWVC=1.752491,	MVRCLoss=2.438107,	
Rank[  2]Epoch[8] Batch [3400]	Speed: 25.58 samples/s ETA: 0 d 12 h 43 m	Data: 0.011 Tran: 0.007 F: 0.165 B: 0.327 O: 1.978 M: 0.011	Train-MLMAcc=0.633877,	MVRCAccuracy=0.679134,	MLMLossWVC=1.752491,	MVRCLoss=2.438107,	
Rank[  3]Epoch[8] Batch [3400]	Speed: 25.58 samples/s ETA: 0 d 12 h 43 m	Data: 1.844 Tran: 0.016 F: 0.211 B: 0.348 O: 0.068 M: 0.012	Train-MLMAcc=0.633877,	MVRCAccuracy=0.679134,	MLMLossWVC=1.752491,	MVRCLoss=2.438107,	
Rank[  3]Epoch[8] Batch [3500]	Speed: 27.62 samples/s ETA: 0 d 11 h 42 m	Data: 1.754 Tran: 0.008 F: 0.174 B: 0.307 O: 0.064 M: 0.008	Train-MLMAcc=0.633960,	MVRCAccuracy=0.679128,	MLMLossWVC=1.752253,	MVRCLoss=2.438073,	
Rank[  2]Epoch[8] Batch [3500]	Speed: 27.62 samples/s ETA: 0 d 11 h 42 m	Data: 0.008 Tran: 0.008 F: 0.153 B: 0.297 O: 1.841 M: 0.008	Train-MLMAcc=0.633960,	MVRCAccuracy=0.679128,	MLMLossWVC=1.752253,	MVRCLoss=2.438073,	
Rank[  0]Epoch[8] Batch [3500]	Speed: 27.62 samples/s ETA: 0 d 11 h 42 m	Data: 0.009 Tran: 0.008 F: 0.154 B: 0.298 O: 1.841 M: 0.008	Train-MLMAcc=0.633960,	MVRCAccuracy=0.679128,	MLMLossWVC=1.752253,	MVRCLoss=2.438073,	
Rank[  1]Epoch[8] Batch [3500]	Speed: 27.62 samples/s ETA: 0 d 11 h 42 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.302 O: 1.836 M: 0.009	Train-MLMAcc=0.633960,	MVRCAccuracy=0.679128,	MLMLossWVC=1.752253,	MVRCLoss=2.438073,	
Rank[  3]Epoch[8] Batch [3600]	Speed: 26.16 samples/s ETA: 0 d 12 h 17 m	Data: 1.831 Tran: 0.008 F: 0.187 B: 0.331 O: 0.078 M: 0.010	Train-MLMAcc=0.633912,	MVRCAccuracy=0.679153,	MLMLossWVC=1.752265,	MVRCLoss=2.438176,	
Rank[  1]Epoch[8] Batch [3600]	Speed: 26.16 samples/s ETA: 0 d 12 h 17 m	Data: 0.010 Tran: 0.008 F: 0.169 B: 0.327 O: 1.920 M: 0.011	Train-MLMAcc=0.633912,	MVRCAccuracy=0.679153,	MLMLossWVC=1.752265,	MVRCLoss=2.438176,	
Rank[  0]Epoch[8] Batch [3600]	Speed: 26.16 samples/s ETA: 0 d 12 h 17 m	Data: 0.010 Tran: 0.007 F: 0.169 B: 0.328 O: 1.919 M: 0.011	Train-MLMAcc=0.633912,	MVRCAccuracy=0.679153,	MLMLossWVC=1.752265,	MVRCLoss=2.438176,	
Rank[  2]Epoch[8] Batch [3600]	Speed: 26.16 samples/s ETA: 0 d 12 h 17 m	Data: 0.010 Tran: 0.008 F: 0.169 B: 0.324 O: 1.925 M: 0.010	Train-MLMAcc=0.633912,	MVRCAccuracy=0.679153,	MLMLossWVC=1.752265,	MVRCLoss=2.438176,	
Rank[  3]Epoch[8] Batch [3700]	Speed: 28.23 samples/s ETA: 0 d 11 h 20 m	Data: 1.755 Tran: 0.007 F: 0.150 B: 0.290 O: 0.057 M: 0.007	Train-MLMAcc=0.633883,	MVRCAccuracy=0.679145,	MLMLossWVC=1.752451,	MVRCLoss=2.438317,	
Rank[  2]Epoch[8] Batch [3700]	Speed: 28.23 samples/s ETA: 0 d 11 h 20 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.804 M: 0.005	Train-MLMAcc=0.633883,	MVRCAccuracy=0.679145,	MLMLossWVC=1.752451,	MVRCLoss=2.438317,	
Rank[  1]Epoch[8] Batch [3700]	Speed: 28.23 samples/s ETA: 0 d 11 h 20 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.298 O: 1.795 M: 0.007	Train-MLMAcc=0.633883,	MVRCAccuracy=0.679145,	MLMLossWVC=1.752451,	MVRCLoss=2.438317,	
Rank[  0]Epoch[8] Batch [3700]	Speed: 28.23 samples/s ETA: 0 d 11 h 20 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.290 O: 1.805 M: 0.008	Train-MLMAcc=0.633883,	MVRCAccuracy=0.679145,	MLMLossWVC=1.752451,	MVRCLoss=2.438317,	
Rank[  3]Epoch[8] Batch [3800]	Speed: 28.30 samples/s ETA: 0 d 11 h 14 m	Data: 1.726 Tran: 0.007 F: 0.151 B: 0.292 O: 0.077 M: 0.007	Train-MLMAcc=0.633892,	MVRCAccuracy=0.679104,	MLMLossWVC=1.752438,	MVRCLoss=2.438252,	
Rank[  2]Epoch[8] Batch [3800]	Speed: 28.30 samples/s ETA: 0 d 11 h 14 m	Data: 0.038 Tran: 0.007 F: 0.149 B: 0.292 O: 1.766 M: 0.009	Train-MLMAcc=0.633892,	MVRCAccuracy=0.679104,	MLMLossWVC=1.752438,	MVRCLoss=2.438252,	
Rank[  0]Epoch[8] Batch [3800]	Speed: 28.30 samples/s ETA: 0 d 11 h 14 m	Data: 0.009 Tran: 0.008 F: 0.151 B: 0.293 O: 1.795 M: 0.006	Train-MLMAcc=0.633892,	MVRCAccuracy=0.679104,	MLMLossWVC=1.752438,	MVRCLoss=2.438252,	
Rank[  1]Epoch[8] Batch [3800]	Speed: 28.30 samples/s ETA: 0 d 11 h 14 m	Data: 0.019 Tran: 0.007 F: 0.151 B: 0.300 O: 1.774 M: 0.009	Train-MLMAcc=0.633892,	MVRCAccuracy=0.679104,	MLMLossWVC=1.752438,	MVRCLoss=2.438252,	
Rank[  0]Epoch[8] Batch [3900]	Speed: 27.04 samples/s ETA: 0 d 11 h 42 m	Data: 0.009 Tran: 0.007 F: 0.153 B: 0.299 O: 1.888 M: 0.009	Train-MLMAcc=0.633877,	MVRCAccuracy=0.679100,	MLMLossWVC=1.753025,	MVRCLoss=2.438335,	
Rank[  1]Epoch[8] Batch [3900]	Speed: 27.04 samples/s ETA: 0 d 11 h 42 m	Data: 0.253 Tran: 0.013 F: 0.172 B: 0.310 O: 1.608 M: 0.009	Train-MLMAcc=0.633877,	MVRCAccuracy=0.679100,	MLMLossWVC=1.753025,	MVRCLoss=2.438335,	
Rank[  2]Epoch[8] Batch [3900]	Speed: 27.04 samples/s ETA: 0 d 11 h 42 m	Data: 0.468 Tran: 0.007 F: 0.160 B: 0.304 O: 1.417 M: 0.009	Train-MLMAcc=0.633877,	MVRCAccuracy=0.679100,	MLMLossWVC=1.753025,	MVRCLoss=2.438335,	
Rank[  3]Epoch[8] Batch [3900]	Speed: 27.04 samples/s ETA: 0 d 11 h 42 m	Data: 1.687 Tran: 0.014 F: 0.185 B: 0.303 O: 0.168 M: 0.008	Train-MLMAcc=0.633877,	MVRCAccuracy=0.679100,	MLMLossWVC=1.753025,	MVRCLoss=2.438335,	
Rank[  3]Epoch[8] Batch [4000]	Speed: 27.52 samples/s ETA: 0 d 11 h 26 m	Data: 1.679 Tran: 0.011 F: 0.167 B: 0.294 O: 0.167 M: 0.007	Train-MLMAcc=0.633885,	MVRCAccuracy=0.679100,	MLMLossWVC=1.753210,	MVRCLoss=2.438371,	
Rank[  1]Epoch[8] Batch [4000]	Speed: 27.52 samples/s ETA: 0 d 11 h 26 m	Data: 0.206 Tran: 0.007 F: 0.150 B: 0.297 O: 1.656 M: 0.008	Train-MLMAcc=0.633885,	MVRCAccuracy=0.679100,	MLMLossWVC=1.753210,	MVRCLoss=2.438371,	
Rank[  2]Epoch[8] Batch [4000]	Speed: 27.52 samples/s ETA: 0 d 11 h 26 m	Data: 0.503 Tran: 0.007 F: 0.150 B: 0.296 O: 1.360 M: 0.009	Train-MLMAcc=0.633885,	MVRCAccuracy=0.679100,	MLMLossWVC=1.753210,	MVRCLoss=2.438371,	
Rank[  0]Epoch[8] Batch [4000]	Speed: 27.52 samples/s ETA: 0 d 11 h 26 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.857 M: 0.009	Train-MLMAcc=0.633885,	MVRCAccuracy=0.679100,	MLMLossWVC=1.753210,	MVRCLoss=2.438371,	
Rank[  0]Epoch[8] Batch [4100]	Speed: 27.34 samples/s ETA: 0 d 11 h 26 m	Data: 0.009 Tran: 0.007 F: 0.152 B: 0.302 O: 1.862 M: 0.006	Train-MLMAcc=0.634002,	MVRCAccuracy=0.679141,	MLMLossWVC=1.752527,	MVRCLoss=2.438285,	
Rank[  2]Epoch[8] Batch [4100]	Speed: 27.34 samples/s ETA: 0 d 11 h 26 m	Data: 0.799 Tran: 0.007 F: 0.156 B: 0.309 O: 1.062 M: 0.006	Train-MLMAcc=0.634002,	MVRCAccuracy=0.679141,	MLMLossWVC=1.752527,	MVRCLoss=2.438285,	
Rank[  3]Epoch[8] Batch [4100]	Speed: 27.34 samples/s ETA: 0 d 11 h 26 m	Data: 1.781 Tran: 0.009 F: 0.176 B: 0.310 O: 0.056 M: 0.006	Train-MLMAcc=0.634002,	MVRCAccuracy=0.679141,	MLMLossWVC=1.752527,	MVRCLoss=2.438285,	
Rank[  1]Epoch[8] Batch [4100]	Speed: 27.34 samples/s ETA: 0 d 11 h 26 m	Data: 0.009 Tran: 0.007 F: 0.151 B: 0.308 O: 1.858 M: 0.006	Train-MLMAcc=0.634002,	MVRCAccuracy=0.679141,	MLMLossWVC=1.752527,	MVRCLoss=2.438285,	
Rank[  2]Epoch[8] Batch [4200]	Speed: 27.34 samples/s ETA: 0 d 11 h 22 m	Data: 0.070 Tran: 0.008 F: 0.149 B: 0.293 O: 1.812 M: 0.008	Train-MLMAcc=0.633919,	MVRCAccuracy=0.679190,	MLMLossWVC=1.752890,	MVRCLoss=2.438057,	
Rank[  0]Epoch[8] Batch [4200]	Speed: 27.34 samples/s ETA: 0 d 11 h 22 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.878 M: 0.006	Train-MLMAcc=0.633919,	MVRCAccuracy=0.679190,	MLMLossWVC=1.752890,	MVRCLoss=2.438057,	
Rank[  3]Epoch[8] Batch [4200]	Speed: 27.34 samples/s ETA: 0 d 11 h 22 m	Data: 1.798 Tran: 0.007 F: 0.151 B: 0.291 O: 0.087 M: 0.007	Train-MLMAcc=0.633919,	MVRCAccuracy=0.679190,	MLMLossWVC=1.752890,	MVRCLoss=2.438057,	
Rank[  1]Epoch[8] Batch [4200]	Speed: 27.34 samples/s ETA: 0 d 11 h 22 m	Data: 0.099 Tran: 0.007 F: 0.150 B: 0.299 O: 1.776 M: 0.008	Train-MLMAcc=0.633919,	MVRCAccuracy=0.679190,	MLMLossWVC=1.752890,	MVRCLoss=2.438057,	
Rank[  3]Epoch[8] Batch [4300]	Speed: 26.38 samples/s ETA: 0 d 11 h 43 m	Data: 1.839 Tran: 0.011 F: 0.190 B: 0.311 O: 0.061 M: 0.011	Train-MLMAcc=0.633856,	MVRCAccuracy=0.679168,	MLMLossWVC=1.753145,	MVRCLoss=2.438108,	
Rank[  2]Epoch[8] Batch [4300]	Speed: 26.38 samples/s ETA: 0 d 11 h 43 m	Data: 0.009 Tran: 0.007 F: 0.157 B: 0.300 O: 1.940 M: 0.010	Train-MLMAcc=0.633856,	MVRCAccuracy=0.679168,	MLMLossWVC=1.753145,	MVRCLoss=2.438108,	
Rank[  0]Epoch[8] Batch [4300]	Speed: 26.38 samples/s ETA: 0 d 11 h 43 m	Data: 0.010 Tran: 0.007 F: 0.156 B: 0.298 O: 1.942 M: 0.011	Train-MLMAcc=0.633856,	MVRCAccuracy=0.679168,	MLMLossWVC=1.753145,	MVRCLoss=2.438108,	
Rank[  1]Epoch[8] Batch [4300]	Speed: 26.38 samples/s ETA: 0 d 11 h 43 m	Data: 0.009 Tran: 0.007 F: 0.156 B: 0.302 O: 1.937 M: 0.012	Train-MLMAcc=0.633856,	MVRCAccuracy=0.679168,	MLMLossWVC=1.753145,	MVRCLoss=2.438108,	
Rank[  1]Epoch[8] Batch [4400]	Speed: 28.05 samples/s ETA: 0 d 10 h 58 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.299 O: 1.810 M: 0.007	Train-MLMAcc=0.633922,	MVRCAccuracy=0.679199,	MLMLossWVC=1.753045,	MVRCLoss=2.438060,	
Rank[  2]Epoch[8] Batch [4400]	Speed: 28.05 samples/s ETA: 0 d 10 h 58 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.293 O: 1.817 M: 0.005	Train-MLMAcc=0.633922,	MVRCAccuracy=0.679199,	MLMLossWVC=1.753045,	MVRCLoss=2.438060,	
Rank[  0]Epoch[8] Batch [4400]	Speed: 28.05 samples/s ETA: 0 d 10 h 58 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.816 M: 0.007	Train-MLMAcc=0.633922,	MVRCAccuracy=0.679199,	MLMLossWVC=1.753045,	MVRCLoss=2.438060,	
Rank[  3]Epoch[8] Batch [4400]	Speed: 28.05 samples/s ETA: 0 d 10 h 58 m	Data: 1.772 Tran: 0.007 F: 0.151 B: 0.291 O: 0.053 M: 0.007	Train-MLMAcc=0.633922,	MVRCAccuracy=0.679199,	MLMLossWVC=1.753045,	MVRCLoss=2.438060,	
Rank[  2]Epoch[8] Batch [4500]	Speed: 27.63 samples/s ETA: 0 d 11 h  4 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.850 M: 0.009	Train-MLMAcc=0.633903,	MVRCAccuracy=0.679232,	MLMLossWVC=1.753153,	MVRCLoss=2.438061,	
Rank[  1]Epoch[8] Batch [4500]	Speed: 27.63 samples/s ETA: 0 d 11 h  4 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.299 O: 1.845 M: 0.007	Train-MLMAcc=0.633903,	MVRCAccuracy=0.679232,	MLMLossWVC=1.753153,	MVRCLoss=2.438061,	
Rank[  0]Epoch[8] Batch [4500]	Speed: 27.63 samples/s ETA: 0 d 11 h  4 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.290 O: 1.853 M: 0.008	Train-MLMAcc=0.633903,	MVRCAccuracy=0.679232,	MLMLossWVC=1.753153,	MVRCLoss=2.438061,	
Rank[  3]Epoch[8] Batch [4500]	Speed: 27.63 samples/s ETA: 0 d 11 h  4 m	Data: 1.802 Tran: 0.007 F: 0.151 B: 0.290 O: 0.057 M: 0.010	Train-MLMAcc=0.633903,	MVRCAccuracy=0.679232,	MLMLossWVC=1.753153,	MVRCLoss=2.438061,	
Rank[  3]Epoch[8] Batch [4600]	Speed: 27.09 samples/s ETA: 0 d 11 h 13 m	Data: 1.788 Tran: 0.010 F: 0.180 B: 0.315 O: 0.061 M: 0.008	Train-MLMAcc=0.633958,	MVRCAccuracy=0.679247,	MLMLossWVC=1.752888,	MVRCLoss=2.438013,	
Rank[  1]Epoch[8] Batch [4600]	Speed: 27.09 samples/s ETA: 0 d 11 h 13 m	Data: 0.009 Tran: 0.007 F: 0.156 B: 0.304 O: 1.878 M: 0.007	Train-MLMAcc=0.633958,	MVRCAccuracy=0.679247,	MLMLossWVC=1.752888,	MVRCLoss=2.438013,	
Rank[  0]Epoch[8] Batch [4600]	Speed: 27.09 samples/s ETA: 0 d 11 h 13 m	Data: 0.009 Tran: 0.007 F: 0.155 B: 0.298 O: 1.884 M: 0.009	Train-MLMAcc=0.633958,	MVRCAccuracy=0.679247,	MLMLossWVC=1.752888,	MVRCLoss=2.438013,	
Rank[  2]Epoch[8] Batch [4600]	Speed: 27.09 samples/s ETA: 0 d 11 h 13 m	Data: 0.009 Tran: 0.007 F: 0.155 B: 0.297 O: 1.885 M: 0.008	Train-MLMAcc=0.633958,	MVRCAccuracy=0.679247,	MLMLossWVC=1.752888,	MVRCLoss=2.438013,	
Rank[  0]Epoch[8] Batch [4700]	Speed: 27.59 samples/s ETA: 0 d 10 h 57 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.854 M: 0.009	Train-MLMAcc=0.633973,	MVRCAccuracy=0.679265,	MLMLossWVC=1.752876,	MVRCLoss=2.437960,	
Rank[  2]Epoch[8] Batch [4700]	Speed: 27.59 samples/s ETA: 0 d 10 h 57 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.855 M: 0.009	Train-MLMAcc=0.633973,	MVRCAccuracy=0.679265,	MLMLossWVC=1.752876,	MVRCLoss=2.437960,	
Rank[  3]Epoch[8] Batch [4700]	Speed: 27.59 samples/s ETA: 0 d 10 h 57 m	Data: 1.807 Tran: 0.007 F: 0.151 B: 0.290 O: 0.058 M: 0.007	Train-MLMAcc=0.633973,	MVRCAccuracy=0.679265,	MLMLossWVC=1.752876,	MVRCLoss=2.437960,	
Rank[  1]Epoch[8] Batch [4700]	Speed: 27.59 samples/s ETA: 0 d 10 h 57 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.299 O: 1.847 M: 0.007	Train-MLMAcc=0.633973,	MVRCAccuracy=0.679265,	MLMLossWVC=1.752876,	MVRCLoss=2.437960,	
Rank[  0]Epoch[8] Batch [4800]	Speed: 27.86 samples/s ETA: 0 d 10 h 47 m	Data: 0.025 Tran: 0.007 F: 0.150 B: 0.291 O: 1.816 M: 0.008	Train-MLMAcc=0.634053,	MVRCAccuracy=0.679256,	MLMLossWVC=1.752291,	MVRCLoss=2.437899,	
Rank[  2]Epoch[8] Batch [4800]	Speed: 27.86 samples/s ETA: 0 d 10 h 47 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.292 O: 1.830 M: 0.010	Train-MLMAcc=0.634053,	MVRCAccuracy=0.679256,	MLMLossWVC=1.752291,	MVRCLoss=2.437899,	
Rank[  1]Epoch[8] Batch [4800]	Speed: 27.86 samples/s ETA: 0 d 10 h 47 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.825 M: 0.008	Train-MLMAcc=0.634053,	MVRCAccuracy=0.679256,	MLMLossWVC=1.752291,	MVRCLoss=2.437899,	
Rank[  3]Epoch[8] Batch [4800]	Speed: 27.86 samples/s ETA: 0 d 10 h 47 m	Data: 1.784 Tran: 0.007 F: 0.151 B: 0.290 O: 0.056 M: 0.008	Train-MLMAcc=0.634053,	MVRCAccuracy=0.679256,	MLMLossWVC=1.752291,	MVRCLoss=2.437899,	
Rank[  0]Epoch[8] Batch [4900]	Speed: 27.34 samples/s ETA: 0 d 10 h 55 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.874 M: 0.007	Train-MLMAcc=0.634149,	MVRCAccuracy=0.679248,	MLMLossWVC=1.752062,	MVRCLoss=2.437926,	
Rank[  3]Epoch[8] Batch [4900]	Speed: 27.34 samples/s ETA: 0 d 10 h 55 m	Data: 1.799 Tran: 0.008 F: 0.172 B: 0.297 O: 0.057 M: 0.006	Train-MLMAcc=0.634149,	MVRCAccuracy=0.679248,	MLMLossWVC=1.752062,	MVRCLoss=2.437926,	
Rank[  2]Epoch[8] Batch [4900]	Speed: 27.34 samples/s ETA: 0 d 10 h 55 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.875 M: 0.006	Train-MLMAcc=0.634149,	MVRCAccuracy=0.679248,	MLMLossWVC=1.752062,	MVRCLoss=2.437926,	
Rank[  1]Epoch[8] Batch [4900]	Speed: 27.34 samples/s ETA: 0 d 10 h 55 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.301 O: 1.868 M: 0.006	Train-MLMAcc=0.634149,	MVRCAccuracy=0.679248,	MLMLossWVC=1.752062,	MVRCLoss=2.437926,	
Rank[  1]Epoch[8] Batch [5000]	Speed: 25.90 samples/s ETA: 0 d 11 h 27 m	Data: 0.042 Tran: 0.007 F: 0.160 B: 0.323 O: 1.924 M: 0.012	Train-MLMAcc=0.634183,	MVRCAccuracy=0.679243,	MLMLossWVC=1.751978,	MVRCLoss=2.437998,	
Rank[  2]Epoch[8] Batch [5000]	Speed: 25.90 samples/s ETA: 0 d 11 h 27 m	Data: 0.040 Tran: 0.007 F: 0.160 B: 0.314 O: 1.937 M: 0.011	Train-MLMAcc=0.634183,	MVRCAccuracy=0.679243,	MLMLossWVC=1.751978,	MVRCLoss=2.437998,	
Rank[  3]Epoch[8] Batch [5000]	Speed: 25.90 samples/s ETA: 0 d 11 h 27 m	Data: 1.490 Tran: 0.012 F: 0.212 B: 0.328 O: 0.416 M: 0.011	Train-MLMAcc=0.634183,	MVRCAccuracy=0.679243,	MLMLossWVC=1.751978,	MVRCLoss=2.437998,	
Rank[  0]Epoch[8] Batch [5000]	Speed: 25.90 samples/s ETA: 0 d 11 h 27 m	Data: 0.351 Tran: 0.007 F: 0.166 B: 0.318 O: 1.616 M: 0.011	Train-MLMAcc=0.634183,	MVRCAccuracy=0.679243,	MLMLossWVC=1.751978,	MVRCLoss=2.437998,	
Rank[  3]Epoch[8] Batch [5100]	Speed: 25.08 samples/s ETA: 0 d 11 h 46 m	Data: 1.849 Tran: 0.012 F: 0.199 B: 0.312 O: 0.161 M: 0.015	Train-MLMAcc=0.634294,	MVRCAccuracy=0.679287,	MLMLossWVC=1.751277,	MVRCLoss=2.438025,	
Rank[  0]Epoch[8] Batch [5100]	Speed: 25.08 samples/s ETA: 0 d 11 h 46 m	Data: 0.114 Tran: 0.007 F: 0.158 B: 0.306 O: 1.950 M: 0.013	Train-MLMAcc=0.634294,	MVRCAccuracy=0.679287,	MLMLossWVC=1.751277,	MVRCLoss=2.438025,	
Rank[  2]Epoch[8] Batch [5100]	Speed: 25.08 samples/s ETA: 0 d 11 h 46 m	Data: 0.014 Tran: 0.007 F: 0.157 B: 0.307 O: 2.048 M: 0.015	Train-MLMAcc=0.634294,	MVRCAccuracy=0.679287,	MLMLossWVC=1.751277,	MVRCLoss=2.438025,	
Rank[  1]Epoch[8] Batch [5100]	Speed: 25.08 samples/s ETA: 0 d 11 h 46 m	Data: 0.014 Tran: 0.007 F: 0.157 B: 0.309 O: 2.047 M: 0.014	Train-MLMAcc=0.634294,	MVRCAccuracy=0.679287,	MLMLossWVC=1.751277,	MVRCLoss=2.438025,	
Rank[  2]Epoch[8] Batch [5200]	Speed: 27.26 samples/s ETA: 0 d 10 h 45 m	Data: 0.017 Tran: 0.008 F: 0.156 B: 0.295 O: 1.865 M: 0.006	Train-MLMAcc=0.634329,	MVRCAccuracy=0.679350,	MLMLossWVC=1.750995,	MVRCLoss=2.437939,	
Rank[  0]Epoch[8] Batch [5200]	Speed: 27.26 samples/s ETA: 0 d 10 h 45 m	Data: 0.009 Tran: 0.007 F: 0.156 B: 0.295 O: 1.873 M: 0.006	Train-MLMAcc=0.634329,	MVRCAccuracy=0.679350,	MLMLossWVC=1.750995,	MVRCLoss=2.437939,	
Rank[  3]Epoch[8] Batch [5200]	Speed: 27.26 samples/s ETA: 0 d 10 h 45 m	Data: 1.822 Tran: 0.008 F: 0.161 B: 0.295 O: 0.054 M: 0.007	Train-MLMAcc=0.634329,	MVRCAccuracy=0.679350,	MLMLossWVC=1.750995,	MVRCLoss=2.437939,	
Rank[  1]Epoch[8] Batch [5200]	Speed: 27.26 samples/s ETA: 0 d 10 h 45 m	Data: 0.009 Tran: 0.008 F: 0.156 B: 0.300 O: 1.867 M: 0.006	Train-MLMAcc=0.634329,	MVRCAccuracy=0.679350,	MLMLossWVC=1.750995,	MVRCLoss=2.437939,	
Rank[  3]Epoch[8] Batch [5300]	Speed: 25.62 samples/s ETA: 0 d 11 h 22 m	Data: 1.818 Tran: 0.014 F: 0.221 B: 0.352 O: 0.075 M: 0.015	Train-MLMAcc=0.634342,	MVRCAccuracy=0.679353,	MLMLossWVC=1.750746,	MVRCLoss=2.437937,	
Rank[  0]Epoch[8] Batch [5300]	Speed: 25.62 samples/s ETA: 0 d 11 h 22 m	Data: 0.013 Tran: 0.008 F: 0.176 B: 0.341 O: 1.942 M: 0.015	Train-MLMAcc=0.634342,	MVRCAccuracy=0.679353,	MLMLossWVC=1.750746,	MVRCLoss=2.437937,	
Rank[  2]Epoch[8] Batch [5300]	Speed: 25.62 samples/s ETA: 0 d 11 h 22 m	Data: 0.013 Tran: 0.008 F: 0.176 B: 0.341 O: 1.942 M: 0.015	Train-MLMAcc=0.634342,	MVRCAccuracy=0.679353,	MLMLossWVC=1.750746,	MVRCLoss=2.437937,	
Rank[  1]Epoch[8] Batch [5300]	Speed: 25.62 samples/s ETA: 0 d 11 h 22 m	Data: 0.013 Tran: 0.008 F: 0.176 B: 0.346 O: 1.938 M: 0.014	Train-MLMAcc=0.634342,	MVRCAccuracy=0.679353,	MLMLossWVC=1.750746,	MVRCLoss=2.437937,	
Rank[  2]Epoch[8] Batch [5400]	Speed: 27.74 samples/s ETA: 0 d 10 h 26 m	Data: 0.022 Tran: 0.007 F: 0.150 B: 0.293 O: 1.826 M: 0.009	Train-MLMAcc=0.634358,	MVRCAccuracy=0.679403,	MLMLossWVC=1.750744,	MVRCLoss=2.437907,	
Rank[  1]Epoch[8] Batch [5400]	Speed: 27.74 samples/s ETA: 0 d 10 h 26 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.300 O: 1.834 M: 0.006	Train-MLMAcc=0.634358,	MVRCAccuracy=0.679403,	MLMLossWVC=1.750744,	MVRCLoss=2.437907,	
Rank[  0]Epoch[8] Batch [5400]	Speed: 27.74 samples/s ETA: 0 d 10 h 26 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.291 O: 1.842 M: 0.008	Train-MLMAcc=0.634358,	MVRCAccuracy=0.679403,	MLMLossWVC=1.750744,	MVRCLoss=2.437907,	
Rank[  3]Epoch[8] Batch [5400]	Speed: 27.74 samples/s ETA: 0 d 10 h 26 m	Data: 1.793 Tran: 0.007 F: 0.151 B: 0.291 O: 0.057 M: 0.008	Train-MLMAcc=0.634358,	MVRCAccuracy=0.679403,	MLMLossWVC=1.750744,	MVRCLoss=2.437907,	
Rank[  0]Epoch[8] Batch [5500]	Speed: 26.03 samples/s ETA: 0 d 11 h  4 m	Data: 0.009 Tran: 0.008 F: 0.170 B: 0.313 O: 1.937 M: 0.019	Train-MLMAcc=0.634427,	MVRCAccuracy=0.679398,	MLMLossWVC=1.750448,	MVRCLoss=2.437846,	
Rank[  2]Epoch[8] Batch [5500]	Speed: 26.03 samples/s ETA: 0 d 11 h  4 m	Data: 0.012 Tran: 0.007 F: 0.168 B: 0.314 O: 1.938 M: 0.018	Train-MLMAcc=0.634427,	MVRCAccuracy=0.679398,	MLMLossWVC=1.750448,	MVRCLoss=2.437846,	
Rank[  3]Epoch[8] Batch [5500]	Speed: 26.03 samples/s ETA: 0 d 11 h  4 m	Data: 1.816 Tran: 0.009 F: 0.207 B: 0.337 O: 0.069 M: 0.020	Train-MLMAcc=0.634427,	MVRCAccuracy=0.679398,	MLMLossWVC=1.750448,	MVRCLoss=2.437846,	
Rank[  1]Epoch[8] Batch [5500]	Speed: 26.03 samples/s ETA: 0 d 11 h  4 m	Data: 0.009 Tran: 0.007 F: 0.172 B: 0.330 O: 1.923 M: 0.016	Train-MLMAcc=0.634427,	MVRCAccuracy=0.679398,	MLMLossWVC=1.750448,	MVRCLoss=2.437846,	
Rank[  3]Epoch[8] Batch [5600]	Speed: 27.52 samples/s ETA: 0 d 10 h 24 m	Data: 1.761 Tran: 0.008 F: 0.176 B: 0.311 O: 0.057 M: 0.011	Train-MLMAcc=0.634431,	MVRCAccuracy=0.679442,	MLMLossWVC=1.750512,	MVRCLoss=2.437744,	
Rank[  2]Epoch[8] Batch [5600]	Speed: 27.52 samples/s ETA: 0 d 10 h 24 m	Data: 0.016 Tran: 0.007 F: 0.151 B: 0.292 O: 1.847 M: 0.011	Train-MLMAcc=0.634431,	MVRCAccuracy=0.679442,	MLMLossWVC=1.750512,	MVRCLoss=2.437744,	
Rank[  0]Epoch[8] Batch [5600]	Speed: 27.52 samples/s ETA: 0 d 10 h 24 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.294 O: 1.852 M: 0.011	Train-MLMAcc=0.634431,	MVRCAccuracy=0.679442,	MLMLossWVC=1.750512,	MVRCLoss=2.437744,	
Rank[  1]Epoch[8] Batch [5600]	Speed: 27.52 samples/s ETA: 0 d 10 h 24 m	Data: 0.008 Tran: 0.008 F: 0.153 B: 0.302 O: 1.846 M: 0.009	Train-MLMAcc=0.634431,	MVRCAccuracy=0.679442,	MLMLossWVC=1.750512,	MVRCLoss=2.437744,	
Rank[  1]Epoch[8] Batch [5700]	Speed: 27.33 samples/s ETA: 0 d 10 h 24 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.298 O: 1.869 M: 0.009	Train-MLMAcc=0.634431,	MVRCAccuracy=0.679467,	MLMLossWVC=1.750431,	MVRCLoss=2.437752,	
Rank[  3]Epoch[8] Batch [5700]	Speed: 27.33 samples/s ETA: 0 d 10 h 24 m	Data: 1.832 Tran: 0.007 F: 0.150 B: 0.289 O: 0.054 M: 0.009	Train-MLMAcc=0.634431,	MVRCAccuracy=0.679467,	MLMLossWVC=1.750431,	MVRCLoss=2.437752,	
Rank[  0]Epoch[8] Batch [5700]	Speed: 27.33 samples/s ETA: 0 d 10 h 24 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.874 M: 0.009	Train-MLMAcc=0.634431,	MVRCAccuracy=0.679467,	MLMLossWVC=1.750431,	MVRCLoss=2.437752,	
Rank[  2]Epoch[8] Batch [5700]	Speed: 27.33 samples/s ETA: 0 d 10 h 24 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.293 O: 1.876 M: 0.006	Train-MLMAcc=0.634431,	MVRCAccuracy=0.679467,	MLMLossWVC=1.750431,	MVRCLoss=2.437752,	
Rank[  2]Epoch[8] Batch [5800]	Speed: 25.12 samples/s ETA: 0 d 11 h 15 m	Data: 0.011 Tran: 0.008 F: 0.163 B: 0.313 O: 2.036 M: 0.014	Train-MLMAcc=0.634444,	MVRCAccuracy=0.679516,	MLMLossWVC=1.750347,	MVRCLoss=2.437703,	
Rank[  3]Epoch[8] Batch [5800]	Speed: 25.12 samples/s ETA: 0 d 11 h 15 m	Data: 1.852 Tran: 0.013 F: 0.219 B: 0.337 O: 0.111 M: 0.012	Train-MLMAcc=0.634444,	MVRCAccuracy=0.679516,	MLMLossWVC=1.750347,	MVRCLoss=2.437703,	
Rank[  0]Epoch[8] Batch [5800]	Speed: 25.12 samples/s ETA: 0 d 11 h 15 m	Data: 0.045 Tran: 0.008 F: 0.167 B: 0.311 O: 2.001 M: 0.012	Train-MLMAcc=0.634444,	MVRCAccuracy=0.679516,	MLMLossWVC=1.750347,	MVRCLoss=2.437703,	
Rank[  1]Epoch[8] Batch [5800]	Speed: 25.12 samples/s ETA: 0 d 11 h 15 m	Data: 0.054 Tran: 0.008 F: 0.163 B: 0.319 O: 1.988 M: 0.013	Train-MLMAcc=0.634444,	MVRCAccuracy=0.679516,	MLMLossWVC=1.750347,	MVRCLoss=2.437703,	
Rank[  0]Epoch[8] Batch [5900]	Speed: 28.16 samples/s ETA: 0 d  9 h 58 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.294 O: 1.806 M: 0.007	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679506,	MLMLossWVC=1.750486,	MVRCLoss=2.437711,	
Rank[  2]Epoch[8] Batch [5900]	Speed: 28.16 samples/s ETA: 0 d  9 h 58 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.806 M: 0.007	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679506,	MLMLossWVC=1.750486,	MVRCLoss=2.437711,	
Rank[  3]Epoch[8] Batch [5900]	Speed: 28.16 samples/s ETA: 0 d  9 h 58 m	Data: 1.765 Tran: 0.006 F: 0.151 B: 0.291 O: 0.052 M: 0.007	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679506,	MLMLossWVC=1.750486,	MVRCLoss=2.437711,	
Rank[  1]Epoch[8] Batch [5900]	Speed: 28.16 samples/s ETA: 0 d  9 h 58 m	Data: 0.029 Tran: 0.007 F: 0.150 B: 0.299 O: 1.779 M: 0.007	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679506,	MLMLossWVC=1.750486,	MVRCLoss=2.437711,	
Rank[  3]Epoch[8] Batch [6000]	Speed: 27.96 samples/s ETA: 0 d  9 h 58 m	Data: 1.714 Tran: 0.007 F: 0.175 B: 0.301 O: 0.078 M: 0.012	Train-MLMAcc=0.634502,	MVRCAccuracy=0.679510,	MLMLossWVC=1.750093,	MVRCLoss=2.437663,	
Rank[  1]Epoch[8] Batch [6000]	Speed: 27.96 samples/s ETA: 0 d  9 h 58 m	Data: 0.319 Tran: 0.007 F: 0.152 B: 0.302 O: 1.495 M: 0.011	Train-MLMAcc=0.634502,	MVRCAccuracy=0.679510,	MLMLossWVC=1.750093,	MVRCLoss=2.437663,	
Rank[  2]Epoch[8] Batch [6000]	Speed: 27.96 samples/s ETA: 0 d  9 h 58 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.814 M: 0.010	Train-MLMAcc=0.634502,	MVRCAccuracy=0.679510,	MLMLossWVC=1.750093,	MVRCLoss=2.437663,	
Rank[  0]Epoch[8] Batch [6000]	Speed: 27.96 samples/s ETA: 0 d  9 h 58 m	Data: 0.033 Tran: 0.007 F: 0.151 B: 0.296 O: 1.790 M: 0.011	Train-MLMAcc=0.634502,	MVRCAccuracy=0.679510,	MLMLossWVC=1.750093,	MVRCLoss=2.437663,	
Rank[  0]Epoch[8] Batch [6100]	Speed: 27.37 samples/s ETA: 0 d 10 h  8 m	Data: 0.176 Tran: 0.007 F: 0.151 B: 0.294 O: 1.703 M: 0.007	Train-MLMAcc=0.634523,	MVRCAccuracy=0.679540,	MLMLossWVC=1.750047,	MVRCLoss=2.437716,	
Rank[  1]Epoch[8] Batch [6100]	Speed: 27.37 samples/s ETA: 0 d 10 h  8 m	Data: 0.094 Tran: 0.007 F: 0.150 B: 0.299 O: 1.780 M: 0.007	Train-MLMAcc=0.634523,	MVRCAccuracy=0.679540,	MLMLossWVC=1.750047,	MVRCLoss=2.437716,	
Rank[  2]Epoch[8] Batch [6100]	Speed: 27.37 samples/s ETA: 0 d 10 h  8 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.293 O: 1.874 M: 0.007	Train-MLMAcc=0.634523,	MVRCAccuracy=0.679540,	MLMLossWVC=1.750047,	MVRCLoss=2.437716,	
Rank[  3]Epoch[8] Batch [6100]	Speed: 27.37 samples/s ETA: 0 d 10 h  8 m	Data: 1.665 Tran: 0.007 F: 0.150 B: 0.290 O: 0.219 M: 0.007	Train-MLMAcc=0.634523,	MVRCAccuracy=0.679540,	MLMLossWVC=1.750047,	MVRCLoss=2.437716,	
Rank[  0]Epoch[8] Batch [6200]	Speed: 28.19 samples/s ETA: 0 d  9 h 46 m	Data: 0.277 Tran: 0.007 F: 0.150 B: 0.290 O: 1.538 M: 0.007	Train-MLMAcc=0.634575,	MVRCAccuracy=0.679533,	MLMLossWVC=1.749766,	MVRCLoss=2.437574,	
Rank[  3]Epoch[8] Batch [6200]	Speed: 28.19 samples/s ETA: 0 d  9 h 46 m	Data: 1.492 Tran: 0.007 F: 0.150 B: 0.290 O: 0.323 M: 0.007	Train-MLMAcc=0.634575,	MVRCAccuracy=0.679533,	MLMLossWVC=1.749766,	MVRCLoss=2.437574,	
Rank[  2]Epoch[8] Batch [6200]	Speed: 28.19 samples/s ETA: 0 d  9 h 46 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.292 O: 1.806 M: 0.007	Train-MLMAcc=0.634575,	MVRCAccuracy=0.679533,	MLMLossWVC=1.749766,	MVRCLoss=2.437574,	
Rank[  1]Epoch[8] Batch [6200]	Speed: 28.19 samples/s ETA: 0 d  9 h 46 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.298 O: 1.801 M: 0.006	Train-MLMAcc=0.634575,	MVRCAccuracy=0.679533,	MLMLossWVC=1.749766,	MVRCLoss=2.437574,	
Rank[  0]Epoch[8] Batch [6300]	Speed: 27.73 samples/s ETA: 0 d  9 h 52 m	Data: 0.301 Tran: 0.007 F: 0.150 B: 0.291 O: 1.550 M: 0.008	Train-MLMAcc=0.634506,	MVRCAccuracy=0.679510,	MLMLossWVC=1.750213,	MVRCLoss=2.437538,	
Rank[  3]Epoch[8] Batch [6300]	Speed: 27.73 samples/s ETA: 0 d  9 h 52 m	Data: 1.507 Tran: 0.007 F: 0.150 B: 0.291 O: 0.343 M: 0.009	Train-MLMAcc=0.634506,	MVRCAccuracy=0.679510,	MLMLossWVC=1.750213,	MVRCLoss=2.437538,	
Rank[  2]Epoch[8] Batch [6300]	Speed: 27.73 samples/s ETA: 0 d  9 h 52 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.292 O: 1.842 M: 0.009	Train-MLMAcc=0.634506,	MVRCAccuracy=0.679510,	MLMLossWVC=1.750213,	MVRCLoss=2.437538,	
Rank[  1]Epoch[8] Batch [6300]	Speed: 27.73 samples/s ETA: 0 d  9 h 52 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.297 O: 1.838 M: 0.008	Train-MLMAcc=0.634506,	MVRCAccuracy=0.679510,	MLMLossWVC=1.750213,	MVRCLoss=2.437538,	
Rank[  0]Epoch[8] Batch [6400]	Speed: 27.97 samples/s ETA: 0 d  9 h 43 m	Data: 0.108 Tran: 0.007 F: 0.150 B: 0.291 O: 1.726 M: 0.005	Train-MLMAcc=0.634565,	MVRCAccuracy=0.679487,	MLMLossWVC=1.749917,	MVRCLoss=2.437452,	
Rank[  1]Epoch[8] Batch [6400]	Speed: 27.97 samples/s ETA: 0 d  9 h 43 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 1.819 M: 0.007	Train-MLMAcc=0.634565,	MVRCAccuracy=0.679487,	MLMLossWVC=1.749917,	MVRCLoss=2.437452,	
Rank[  2]Epoch[8] Batch [6400]	Speed: 27.97 samples/s ETA: 0 d  9 h 43 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.293 O: 1.824 M: 0.007	Train-MLMAcc=0.634565,	MVRCAccuracy=0.679487,	MLMLossWVC=1.749917,	MVRCLoss=2.437452,	
Rank[  3]Epoch[8] Batch [6400]	Speed: 27.97 samples/s ETA: 0 d  9 h 43 m	Data: 1.679 Tran: 0.007 F: 0.150 B: 0.290 O: 0.154 M: 0.007	Train-MLMAcc=0.634565,	MVRCAccuracy=0.679487,	MLMLossWVC=1.749917,	MVRCLoss=2.437452,	
Rank[  0]Epoch[8] Batch [6500]	Speed: 26.91 samples/s ETA: 0 d 10 h  2 m	Data: 0.095 Tran: 0.007 F: 0.161 B: 0.310 O: 1.790 M: 0.013	Train-MLMAcc=0.634509,	MVRCAccuracy=0.679506,	MLMLossWVC=1.750236,	MVRCLoss=2.437430,	
Rank[  1]Epoch[8] Batch [6500]	Speed: 26.91 samples/s ETA: 0 d 10 h  2 m	Data: 0.153 Tran: 0.007 F: 0.160 B: 0.313 O: 1.731 M: 0.012	Train-MLMAcc=0.634509,	MVRCAccuracy=0.679506,	MLMLossWVC=1.750236,	MVRCLoss=2.437430,	
Rank[  2]Epoch[8] Batch [6500]	Speed: 26.91 samples/s ETA: 0 d 10 h  2 m	Data: 0.046 Tran: 0.007 F: 0.161 B: 0.309 O: 1.841 M: 0.012	Train-MLMAcc=0.634509,	MVRCAccuracy=0.679506,	MLMLossWVC=1.750236,	MVRCLoss=2.437430,	
Rank[  3]Epoch[8] Batch [6500]	Speed: 26.91 samples/s ETA: 0 d 10 h  2 m	Data: 1.590 Tran: 0.012 F: 0.201 B: 0.325 O: 0.237 M: 0.011	Train-MLMAcc=0.634509,	MVRCAccuracy=0.679506,	MLMLossWVC=1.750236,	MVRCLoss=2.437430,	
Rank[  3]Epoch[8] Batch [6600]	Speed: 26.32 samples/s ETA: 0 d 10 h 12 m	Data: 1.813 Tran: 0.010 F: 0.200 B: 0.317 O: 0.082 M: 0.008	Train-MLMAcc=0.634458,	MVRCAccuracy=0.679515,	MLMLossWVC=1.750464,	MVRCLoss=2.437410,	
Rank[  0]Epoch[8] Batch [6600]	Speed: 26.32 samples/s ETA: 0 d 10 h 12 m	Data: 0.012 Tran: 0.009 F: 0.164 B: 0.309 O: 1.928 M: 0.009	Train-MLMAcc=0.634458,	MVRCAccuracy=0.679515,	MLMLossWVC=1.750464,	MVRCLoss=2.437410,	
Rank[  1]Epoch[8] Batch [6600]	Speed: 26.32 samples/s ETA: 0 d 10 h 12 m	Data: 0.301 Tran: 0.009 F: 0.163 B: 0.332 O: 1.617 M: 0.008	Train-MLMAcc=0.634458,	MVRCAccuracy=0.679515,	MLMLossWVC=1.750464,	MVRCLoss=2.437410,	
Rank[  2]Epoch[8] Batch [6600]	Speed: 26.32 samples/s ETA: 0 d 10 h 12 m	Data: 0.217 Tran: 0.010 F: 0.162 B: 0.312 O: 1.721 M: 0.009	Train-MLMAcc=0.634458,	MVRCAccuracy=0.679515,	MLMLossWVC=1.750464,	MVRCLoss=2.437410,	
Rank[  1]Epoch[8] Batch [6700]	Speed: 26.51 samples/s ETA: 0 d 10 h  3 m	Data: 0.419 Tran: 0.008 F: 0.163 B: 0.311 O: 1.505 M: 0.007	Train-MLMAcc=0.634553,	MVRCAccuracy=0.679510,	MLMLossWVC=1.749939,	MVRCLoss=2.437375,	
Rank[  2]Epoch[8] Batch [6700]	Speed: 26.51 samples/s ETA: 0 d 10 h  3 m	Data: 1.307 Tran: 0.009 F: 0.187 B: 0.316 O: 0.584 M: 0.009	Train-MLMAcc=0.634553,	MVRCAccuracy=0.679510,	MLMLossWVC=1.749939,	MVRCLoss=2.437375,	
Rank[  0]Epoch[8] Batch [6700]	Speed: 26.51 samples/s ETA: 0 d 10 h  3 m	Data: 0.481 Tran: 0.008 F: 0.166 B: 0.309 O: 1.439 M: 0.008	Train-MLMAcc=0.634553,	MVRCAccuracy=0.679510,	MLMLossWVC=1.749939,	MVRCLoss=2.437375,	
Rank[  3]Epoch[8] Batch [6700]	Speed: 26.51 samples/s ETA: 0 d 10 h  3 m	Data: 1.792 Tran: 0.010 F: 0.178 B: 0.311 O: 0.111 M: 0.009	Train-MLMAcc=0.634553,	MVRCAccuracy=0.679510,	MLMLossWVC=1.749939,	MVRCLoss=2.437375,	
Rank[  0]Epoch[8] Batch [6800]	Speed: 26.38 samples/s ETA: 0 d 10 h  2 m	Data: 0.061 Tran: 0.007 F: 0.167 B: 0.320 O: 1.858 M: 0.012	Train-MLMAcc=0.634479,	MVRCAccuracy=0.679528,	MLMLossWVC=1.750264,	MVRCLoss=2.437337,	
Rank[  1]Epoch[8] Batch [6800]	Speed: 26.38 samples/s ETA: 0 d 10 h  2 m	Data: 0.140 Tran: 0.007 F: 0.167 B: 0.322 O: 1.774 M: 0.014	Train-MLMAcc=0.634479,	MVRCAccuracy=0.679528,	MLMLossWVC=1.750264,	MVRCLoss=2.437337,	
Rank[  3]Epoch[8] Batch [6800]	Speed: 26.38 samples/s ETA: 0 d 10 h  2 m	Data: 1.821 Tran: 0.008 F: 0.180 B: 0.332 O: 0.068 M: 0.016	Train-MLMAcc=0.634479,	MVRCAccuracy=0.679528,	MLMLossWVC=1.750264,	MVRCLoss=2.437337,	
Rank[  2]Epoch[8] Batch [6800]	Speed: 26.38 samples/s ETA: 0 d 10 h  2 m	Data: 0.601 Tran: 0.008 F: 0.169 B: 0.328 O: 1.303 M: 0.016	Train-MLMAcc=0.634479,	MVRCAccuracy=0.679528,	MLMLossWVC=1.750264,	MVRCLoss=2.437337,	
Rank[  0]Epoch[8] Batch [6900]	Speed: 27.37 samples/s ETA: 0 d  9 h 36 m	Data: 0.009 Tran: 0.007 F: 0.154 B: 0.295 O: 1.864 M: 0.008	Train-MLMAcc=0.634445,	MVRCAccuracy=0.679532,	MLMLossWVC=1.750527,	MVRCLoss=2.437397,	
Rank[  3]Epoch[8] Batch [6900]	Speed: 27.37 samples/s ETA: 0 d  9 h 36 m	Data: 1.772 Tran: 0.009 F: 0.178 B: 0.302 O: 0.068 M: 0.008	Train-MLMAcc=0.634445,	MVRCAccuracy=0.679532,	MLMLossWVC=1.750527,	MVRCLoss=2.437397,	
Rank[  2]Epoch[8] Batch [6900]	Speed: 27.37 samples/s ETA: 0 d  9 h 36 m	Data: 0.584 Tran: 0.007 F: 0.156 B: 0.298 O: 1.285 M: 0.008	Train-MLMAcc=0.634445,	MVRCAccuracy=0.679532,	MLMLossWVC=1.750527,	MVRCLoss=2.437397,	
Rank[  1]Epoch[8] Batch [6900]	Speed: 27.37 samples/s ETA: 0 d  9 h 36 m	Data: 0.047 Tran: 0.007 F: 0.155 B: 0.301 O: 1.818 M: 0.009	Train-MLMAcc=0.634445,	MVRCAccuracy=0.679532,	MLMLossWVC=1.750527,	MVRCLoss=2.437397,	
Rank[  0]Epoch[8] Batch [7000]	Speed: 26.28 samples/s ETA: 0 d  9 h 56 m	Data: 0.019 Tran: 0.009 F: 0.173 B: 0.323 O: 1.898 M: 0.010	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679550,	MLMLossWVC=1.750608,	MVRCLoss=2.437463,	
Rank[  3]Epoch[8] Batch [7000]	Speed: 26.28 samples/s ETA: 0 d  9 h 56 m	Data: 1.838 Tran: 0.010 F: 0.183 B: 0.315 O: 0.077 M: 0.011	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679550,	MLMLossWVC=1.750608,	MVRCLoss=2.437463,	
Rank[  1]Epoch[8] Batch [7000]	Speed: 26.28 samples/s ETA: 0 d  9 h 56 m	Data: 0.182 Tran: 0.010 F: 0.179 B: 0.344 O: 1.706 M: 0.011	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679550,	MLMLossWVC=1.750608,	MVRCLoss=2.437463,	
Rank[  2]Epoch[8] Batch [7000]	Speed: 26.28 samples/s ETA: 0 d  9 h 56 m	Data: 0.176 Tran: 0.011 F: 0.180 B: 0.327 O: 1.728 M: 0.011	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679550,	MLMLossWVC=1.750608,	MVRCLoss=2.437463,	
Rank[  3]Epoch[8] Batch [7100]	Speed: 26.58 samples/s ETA: 0 d  9 h 46 m	Data: 1.824 Tran: 0.011 F: 0.178 B: 0.316 O: 0.065 M: 0.012	Train-MLMAcc=0.634541,	MVRCAccuracy=0.679543,	MLMLossWVC=1.750302,	MVRCLoss=2.437433,	
Rank[  0]Epoch[8] Batch [7100]	Speed: 26.58 samples/s ETA: 0 d  9 h 46 m	Data: 0.011 Tran: 0.007 F: 0.162 B: 0.339 O: 1.876 M: 0.010	Train-MLMAcc=0.634541,	MVRCAccuracy=0.679543,	MLMLossWVC=1.750302,	MVRCLoss=2.437433,	
Rank[  2]Epoch[8] Batch [7100]	Speed: 26.58 samples/s ETA: 0 d  9 h 46 m	Data: 0.300 Tran: 0.008 F: 0.167 B: 0.329 O: 1.591 M: 0.011	Train-MLMAcc=0.634541,	MVRCAccuracy=0.679543,	MLMLossWVC=1.750302,	MVRCLoss=2.437433,	
Rank[  1]Epoch[8] Batch [7100]	Speed: 26.58 samples/s ETA: 0 d  9 h 46 m	Data: 0.172 Tran: 0.008 F: 0.161 B: 0.341 O: 1.713 M: 0.010	Train-MLMAcc=0.634541,	MVRCAccuracy=0.679543,	MLMLossWVC=1.750302,	MVRCLoss=2.437433,	
Rank[  1]Epoch[8] Batch [7200]	Speed: 25.76 samples/s ETA: 0 d 10 h  0 m	Data: 0.024 Tran: 0.008 F: 0.165 B: 0.324 O: 1.952 M: 0.010	Train-MLMAcc=0.634524,	MVRCAccuracy=0.679521,	MLMLossWVC=1.750362,	MVRCLoss=2.437413,	
Rank[  2]Epoch[8] Batch [7200]	Speed: 25.76 samples/s ETA: 0 d 10 h  0 m	Data: 0.012 Tran: 0.008 F: 0.164 B: 0.319 O: 1.971 M: 0.010	Train-MLMAcc=0.634524,	MVRCAccuracy=0.679521,	MLMLossWVC=1.750362,	MVRCLoss=2.437413,	
Rank[  3]Epoch[8] Batch [7200]	Speed: 25.76 samples/s ETA: 0 d 10 h  0 m	Data: 1.909 Tran: 0.009 F: 0.178 B: 0.312 O: 0.066 M: 0.010	Train-MLMAcc=0.634524,	MVRCAccuracy=0.679521,	MLMLossWVC=1.750362,	MVRCLoss=2.437413,	
Rank[  0]Epoch[8] Batch [7200]	Speed: 25.76 samples/s ETA: 0 d 10 h  0 m	Data: 0.010 Tran: 0.007 F: 0.163 B: 0.322 O: 1.975 M: 0.007	Train-MLMAcc=0.634524,	MVRCAccuracy=0.679521,	MLMLossWVC=1.750362,	MVRCLoss=2.437413,	
Rank[  3]Epoch[8] Batch [7300]	Speed: 28.22 samples/s ETA: 0 d  9 h  4 m	Data: 1.754 Tran: 0.007 F: 0.150 B: 0.290 O: 0.058 M: 0.008	Train-MLMAcc=0.634508,	MVRCAccuracy=0.679531,	MLMLossWVC=1.750434,	MVRCLoss=2.437393,	
Rank[  1]Epoch[8] Batch [7300]	Speed: 28.22 samples/s ETA: 0 d  9 h  4 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.299 O: 1.794 M: 0.008	Train-MLMAcc=0.634508,	MVRCAccuracy=0.679531,	MLMLossWVC=1.750434,	MVRCLoss=2.437393,	
Rank[  2]Epoch[8] Batch [7300]	Speed: 28.22 samples/s ETA: 0 d  9 h  4 m	Data: 0.013 Tran: 0.008 F: 0.149 B: 0.291 O: 1.799 M: 0.008	Train-MLMAcc=0.634508,	MVRCAccuracy=0.679531,	MLMLossWVC=1.750434,	MVRCLoss=2.437393,	
Rank[  0]Epoch[8] Batch [7300]	Speed: 28.22 samples/s ETA: 0 d  9 h  4 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.292 O: 1.804 M: 0.007	Train-MLMAcc=0.634508,	MVRCAccuracy=0.679531,	MLMLossWVC=1.750434,	MVRCLoss=2.437393,	
Rank[  3]Epoch[8] Batch [7400]	Speed: 26.22 samples/s ETA: 0 d  9 h 41 m	Data: 1.820 Tran: 0.011 F: 0.179 B: 0.338 O: 0.076 M: 0.014	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679533,	MLMLossWVC=1.750545,	MVRCLoss=2.437386,	
Rank[  2]Epoch[8] Batch [7400]	Speed: 26.22 samples/s ETA: 0 d  9 h 41 m	Data: 0.024 Tran: 0.007 F: 0.178 B: 0.345 O: 1.870 M: 0.015	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679533,	MLMLossWVC=1.750545,	MVRCLoss=2.437386,	
Rank[  0]Epoch[8] Batch [7400]	Speed: 26.22 samples/s ETA: 0 d  9 h 41 m	Data: 0.015 Tran: 0.007 F: 0.178 B: 0.345 O: 1.878 M: 0.015	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679533,	MLMLossWVC=1.750545,	MVRCLoss=2.437386,	
Rank[  1]Epoch[8] Batch [7400]	Speed: 26.22 samples/s ETA: 0 d  9 h 41 m	Data: 0.015 Tran: 0.007 F: 0.178 B: 0.347 O: 1.876 M: 0.015	Train-MLMAcc=0.634462,	MVRCAccuracy=0.679533,	MLMLossWVC=1.750545,	MVRCLoss=2.437386,	
Rank[  2]Epoch[8] Batch [7500]	Speed: 27.16 samples/s ETA: 0 d  9 h 17 m	Data: 0.068 Tran: 0.007 F: 0.155 B: 0.302 O: 1.813 M: 0.010	Train-MLMAcc=0.634463,	MVRCAccuracy=0.679536,	MLMLossWVC=1.750538,	MVRCLoss=2.437404,	
Rank[  3]Epoch[8] Batch [7500]	Speed: 27.16 samples/s ETA: 0 d  9 h 17 m	Data: 1.785 Tran: 0.008 F: 0.177 B: 0.315 O: 0.059 M: 0.011	Train-MLMAcc=0.634463,	MVRCAccuracy=0.679536,	MLMLossWVC=1.750538,	MVRCLoss=2.437404,	
Rank[  0]Epoch[8] Batch [7500]	Speed: 27.16 samples/s ETA: 0 d  9 h 17 m	Data: 0.009 Tran: 0.007 F: 0.155 B: 0.304 O: 1.868 M: 0.010	Train-MLMAcc=0.634463,	MVRCAccuracy=0.679536,	MLMLossWVC=1.750538,	MVRCLoss=2.437404,	
Rank[  1]Epoch[8] Batch [7500]	Speed: 27.16 samples/s ETA: 0 d  9 h 17 m	Data: 0.010 Tran: 0.007 F: 0.154 B: 0.306 O: 1.870 M: 0.008	Train-MLMAcc=0.634463,	MVRCAccuracy=0.679536,	MLMLossWVC=1.750538,	MVRCLoss=2.437404,	
Rank[  2]Epoch[8] Batch [7600]	Speed: 27.92 samples/s ETA: 0 d  8 h 58 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.827 M: 0.008	Train-MLMAcc=0.634486,	MVRCAccuracy=0.679557,	MLMLossWVC=1.750581,	MVRCLoss=2.437363,	
Rank[  3]Epoch[8] Batch [7600]	Speed: 27.92 samples/s ETA: 0 d  8 h 58 m	Data: 1.767 Tran: 0.007 F: 0.151 B: 0.290 O: 0.072 M: 0.006	Train-MLMAcc=0.634486,	MVRCAccuracy=0.679557,	MLMLossWVC=1.750581,	MVRCLoss=2.437363,	
Rank[  0]Epoch[8] Batch [7600]	Speed: 27.92 samples/s ETA: 0 d  8 h 58 m	Data: 0.022 Tran: 0.007 F: 0.150 B: 0.293 O: 1.811 M: 0.008	Train-MLMAcc=0.634486,	MVRCAccuracy=0.679557,	MLMLossWVC=1.750581,	MVRCLoss=2.437363,	
Rank[  1]Epoch[8] Batch [7600]	Speed: 27.92 samples/s ETA: 0 d  8 h 58 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.300 O: 1.820 M: 0.007	Train-MLMAcc=0.634486,	MVRCAccuracy=0.679557,	MLMLossWVC=1.750581,	MVRCLoss=2.437363,	
Rank[  3]Epoch[8] Batch [7700]	Speed: 28.04 samples/s ETA: 0 d  8 h 52 m	Data: 1.583 Tran: 0.007 F: 0.149 B: 0.289 O: 0.246 M: 0.007	Train-MLMAcc=0.634527,	MVRCAccuracy=0.679536,	MLMLossWVC=1.750519,	MVRCLoss=2.437373,	
Rank[  2]Epoch[8] Batch [7700]	Speed: 28.04 samples/s ETA: 0 d  8 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.817 M: 0.006	Train-MLMAcc=0.634527,	MVRCAccuracy=0.679536,	MLMLossWVC=1.750519,	MVRCLoss=2.437373,	
Rank[  1]Epoch[8] Batch [7700]	Speed: 28.04 samples/s ETA: 0 d  8 h 52 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.299 O: 1.811 M: 0.007	Train-MLMAcc=0.634527,	MVRCAccuracy=0.679536,	MLMLossWVC=1.750519,	MVRCLoss=2.437373,	
Rank[  0]Epoch[8] Batch [7700]	Speed: 28.04 samples/s ETA: 0 d  8 h 52 m	Data: 0.205 Tran: 0.006 F: 0.150 B: 0.292 O: 1.622 M: 0.006	Train-MLMAcc=0.634527,	MVRCAccuracy=0.679536,	MLMLossWVC=1.750519,	MVRCLoss=2.437373,	
Rank[  0]Epoch[8] Batch [7800]	Speed: 26.17 samples/s ETA: 0 d  9 h 26 m	Data: 0.091 Tran: 0.007 F: 0.161 B: 0.356 O: 1.820 M: 0.009	Train-MLMAcc=0.634493,	MVRCAccuracy=0.679563,	MLMLossWVC=1.750556,	MVRCLoss=2.437367,	
Rank[  1]Epoch[8] Batch [7800]	Speed: 26.17 samples/s ETA: 0 d  9 h 26 m	Data: 0.011 Tran: 0.007 F: 0.161 B: 0.363 O: 1.892 M: 0.010	Train-MLMAcc=0.634493,	MVRCAccuracy=0.679563,	MLMLossWVC=1.750556,	MVRCLoss=2.437367,	
Rank[  3]Epoch[8] Batch [7800]	Speed: 26.17 samples/s ETA: 0 d  9 h 26 m	Data: 1.750 Tran: 0.008 F: 0.208 B: 0.322 O: 0.146 M: 0.010	Train-MLMAcc=0.634493,	MVRCAccuracy=0.679563,	MLMLossWVC=1.750556,	MVRCLoss=2.437367,	
Rank[  2]Epoch[8] Batch [7800]	Speed: 26.17 samples/s ETA: 0 d  9 h 26 m	Data: 0.009 Tran: 0.007 F: 0.162 B: 0.359 O: 1.896 M: 0.010	Train-MLMAcc=0.634493,	MVRCAccuracy=0.679563,	MLMLossWVC=1.750556,	MVRCLoss=2.437367,	
Rank[  3]Epoch[8] Batch [7900]	Speed: 28.20 samples/s ETA: 0 d  8 h 42 m	Data: 1.518 Tran: 0.007 F: 0.151 B: 0.292 O: 0.294 M: 0.008	Train-MLMAcc=0.634510,	MVRCAccuracy=0.679555,	MLMLossWVC=1.750344,	MVRCLoss=2.437399,	
Rank[  0]Epoch[8] Batch [7900]	Speed: 28.20 samples/s ETA: 0 d  8 h 42 m	Data: 0.251 Tran: 0.007 F: 0.150 B: 0.293 O: 1.560 M: 0.008	Train-MLMAcc=0.634510,	MVRCAccuracy=0.679555,	MLMLossWVC=1.750344,	MVRCLoss=2.437399,	
Rank[  2]Epoch[8] Batch [7900]	Speed: 28.20 samples/s ETA: 0 d  8 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.806 M: 0.006	Train-MLMAcc=0.634510,	MVRCAccuracy=0.679555,	MLMLossWVC=1.750344,	MVRCLoss=2.437399,	
Rank[  1]Epoch[8] Batch [7900]	Speed: 28.20 samples/s ETA: 0 d  8 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.798 M: 0.007	Train-MLMAcc=0.634510,	MVRCAccuracy=0.679555,	MLMLossWVC=1.750344,	MVRCLoss=2.437399,	
Rank[  0]Epoch[8] Batch [8000]	Speed: 26.87 samples/s ETA: 0 d  9 h  3 m	Data: 1.110 Tran: 0.007 F: 0.159 B: 0.307 O: 0.786 M: 0.010	Train-MLMAcc=0.634518,	MVRCAccuracy=0.679566,	MLMLossWVC=1.750382,	MVRCLoss=2.437392,	
Rank[  2]Epoch[8] Batch [8000]	Speed: 26.87 samples/s ETA: 0 d  9 h  3 m	Data: 0.038 Tran: 0.007 F: 0.157 B: 0.307 O: 1.859 M: 0.012	Train-MLMAcc=0.634518,	MVRCAccuracy=0.679566,	MLMLossWVC=1.750382,	MVRCLoss=2.437392,	
Rank[  1]Epoch[8] Batch [8000]	Speed: 26.87 samples/s ETA: 0 d  9 h  3 m	Data: 0.087 Tran: 0.007 F: 0.159 B: 0.311 O: 1.805 M: 0.011	Train-MLMAcc=0.634518,	MVRCAccuracy=0.679566,	MLMLossWVC=1.750382,	MVRCLoss=2.437392,	
Rank[  3]Epoch[8] Batch [8000]	Speed: 26.87 samples/s ETA: 0 d  9 h  3 m	Data: 0.826 Tran: 0.010 F: 0.185 B: 0.318 O: 1.032 M: 0.010	Train-MLMAcc=0.634518,	MVRCAccuracy=0.679566,	MLMLossWVC=1.750382,	MVRCLoss=2.437392,	
Rank[  0]Epoch[8] Batch [8100]	Speed: 27.86 samples/s ETA: 0 d  8 h 40 m	Data: 0.422 Tran: 0.007 F: 0.150 B: 0.292 O: 1.419 M: 0.005	Train-MLMAcc=0.634540,	MVRCAccuracy=0.679571,	MLMLossWVC=1.750301,	MVRCLoss=2.437297,	
Rank[  3]Epoch[8] Batch [8100]	Speed: 27.86 samples/s ETA: 0 d  8 h 40 m	Data: 1.378 Tran: 0.007 F: 0.149 B: 0.288 O: 0.469 M: 0.006	Train-MLMAcc=0.634540,	MVRCAccuracy=0.679571,	MLMLossWVC=1.750301,	MVRCLoss=2.437297,	
Rank[  2]Epoch[8] Batch [8100]	Speed: 27.86 samples/s ETA: 0 d  8 h 40 m	Data: 0.015 Tran: 0.008 F: 0.149 B: 0.293 O: 1.826 M: 0.006	Train-MLMAcc=0.634540,	MVRCAccuracy=0.679571,	MLMLossWVC=1.750301,	MVRCLoss=2.437297,	
Rank[  1]Epoch[8] Batch [8100]	Speed: 27.86 samples/s ETA: 0 d  8 h 40 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 1.829 M: 0.006	Train-MLMAcc=0.634540,	MVRCAccuracy=0.679571,	MLMLossWVC=1.750301,	MVRCLoss=2.437297,	
Rank[  1]Epoch[8] Batch [8200]	Speed: 27.11 samples/s ETA: 0 d  8 h 51 m	Data: 0.009 Tran: 0.007 F: 0.160 B: 0.302 O: 1.872 M: 0.010	Train-MLMAcc=0.634536,	MVRCAccuracy=0.679563,	MLMLossWVC=1.750391,	MVRCLoss=2.437316,	
Rank[  2]Epoch[8] Batch [8200]	Speed: 27.11 samples/s ETA: 0 d  8 h 51 m	Data: 0.010 Tran: 0.007 F: 0.159 B: 0.299 O: 1.874 M: 0.011	Train-MLMAcc=0.634536,	MVRCAccuracy=0.679563,	MLMLossWVC=1.750391,	MVRCLoss=2.437316,	
Rank[  0]Epoch[8] Batch [8200]	Speed: 27.11 samples/s ETA: 0 d  8 h 51 m	Data: 0.538 Tran: 0.007 F: 0.158 B: 0.300 O: 1.346 M: 0.010	Train-MLMAcc=0.634536,	MVRCAccuracy=0.679563,	MLMLossWVC=1.750391,	MVRCLoss=2.437316,	
Rank[  3]Epoch[8] Batch [8200]	Speed: 27.11 samples/s ETA: 0 d  8 h 51 m	Data: 1.280 Tran: 0.007 F: 0.165 B: 0.313 O: 0.583 M: 0.011	Train-MLMAcc=0.634536,	MVRCAccuracy=0.679563,	MLMLossWVC=1.750391,	MVRCLoss=2.437316,	
Rank[  3]Epoch[8] Batch [8300]	Speed: 27.31 samples/s ETA: 0 d  8 h 43 m	Data: 0.979 Tran: 0.009 F: 0.180 B: 0.313 O: 0.849 M: 0.011	Train-MLMAcc=0.634579,	MVRCAccuracy=0.679552,	MLMLossWVC=1.750288,	MVRCLoss=2.437333,	
Rank[  0]Epoch[8] Batch [8300]	Speed: 27.31 samples/s ETA: 0 d  8 h 43 m	Data: 0.798 Tran: 0.007 F: 0.159 B: 0.308 O: 1.059 M: 0.011	Train-MLMAcc=0.634579,	MVRCAccuracy=0.679552,	MLMLossWVC=1.750288,	MVRCLoss=2.437333,	
Rank[  2]Epoch[8] Batch [8300]	Speed: 27.31 samples/s ETA: 0 d  8 h 43 m	Data: 0.009 Tran: 0.007 F: 0.157 B: 0.306 O: 1.851 M: 0.012	Train-MLMAcc=0.634579,	MVRCAccuracy=0.679552,	MLMLossWVC=1.750288,	MVRCLoss=2.437333,	
Rank[  1]Epoch[8] Batch [8300]	Speed: 27.31 samples/s ETA: 0 d  8 h 43 m	Data: 0.360 Tran: 0.007 F: 0.159 B: 0.314 O: 1.494 M: 0.008	Train-MLMAcc=0.634579,	MVRCAccuracy=0.679552,	MLMLossWVC=1.750288,	MVRCLoss=2.437333,	
Rank[  1]Epoch[8] Batch [8400]	Speed: 27.83 samples/s ETA: 0 d  8 h 29 m	Data: 0.242 Tran: 0.007 F: 0.150 B: 0.297 O: 1.596 M: 0.007	Train-MLMAcc=0.634545,	MVRCAccuracy=0.679562,	MLMLossWVC=1.750539,	MVRCLoss=2.437278,	
Rank[  0]Epoch[8] Batch [8400]	Speed: 27.83 samples/s ETA: 0 d  8 h 29 m	Data: 0.099 Tran: 0.007 F: 0.150 B: 0.292 O: 1.745 M: 0.007	Train-MLMAcc=0.634545,	MVRCAccuracy=0.679562,	MLMLossWVC=1.750539,	MVRCLoss=2.437278,	
Rank[  2]Epoch[8] Batch [8400]	Speed: 27.83 samples/s ETA: 0 d  8 h 29 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 1.833 M: 0.007	Train-MLMAcc=0.634545,	MVRCAccuracy=0.679562,	MLMLossWVC=1.750539,	MVRCLoss=2.437278,	
Rank[  3]Epoch[8] Batch [8400]	Speed: 27.83 samples/s ETA: 0 d  8 h 29 m	Data: 1.522 Tran: 0.007 F: 0.151 B: 0.292 O: 0.321 M: 0.006	Train-MLMAcc=0.634545,	MVRCAccuracy=0.679562,	MLMLossWVC=1.750539,	MVRCLoss=2.437278,	
Rank[  2]Epoch[8] Batch [8500]	Speed: 26.73 samples/s ETA: 0 d  8 h 46 m	Data: 0.010 Tran: 0.007 F: 0.160 B: 0.319 O: 1.882 M: 0.013	Train-MLMAcc=0.634570,	MVRCAccuracy=0.679552,	MLMLossWVC=1.750486,	MVRCLoss=2.437321,	
Rank[  3]Epoch[8] Batch [8500]	Speed: 26.73 samples/s ETA: 0 d  8 h 46 m	Data: 1.283 Tran: 0.010 F: 0.190 B: 0.323 O: 0.574 M: 0.012	Train-MLMAcc=0.634570,	MVRCAccuracy=0.679552,	MLMLossWVC=1.750486,	MVRCLoss=2.437321,	
Rank[  1]Epoch[8] Batch [8500]	Speed: 26.73 samples/s ETA: 0 d  8 h 46 m	Data: 0.435 Tran: 0.007 F: 0.167 B: 0.322 O: 1.449 M: 0.013	Train-MLMAcc=0.634570,	MVRCAccuracy=0.679552,	MLMLossWVC=1.750486,	MVRCLoss=2.437321,	
Rank[  0]Epoch[8] Batch [8500]	Speed: 26.73 samples/s ETA: 0 d  8 h 46 m	Data: 0.076 Tran: 0.007 F: 0.164 B: 0.317 O: 1.816 M: 0.012	Train-MLMAcc=0.634570,	MVRCAccuracy=0.679552,	MLMLossWVC=1.750486,	MVRCLoss=2.437321,	
Rank[  1]Epoch[8] Batch [8600]	Speed: 27.76 samples/s ETA: 0 d  8 h 23 m	Data: 0.298 Tran: 0.007 F: 0.150 B: 0.299 O: 1.542 M: 0.008	Train-MLMAcc=0.634561,	MVRCAccuracy=0.679569,	MLMLossWVC=1.750406,	MVRCLoss=2.437280,	
Rank[  2]Epoch[8] Batch [8600]	Speed: 27.76 samples/s ETA: 0 d  8 h 23 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.837 M: 0.007	Train-MLMAcc=0.634561,	MVRCAccuracy=0.679569,	MLMLossWVC=1.750406,	MVRCLoss=2.437280,	
Rank[  0]Epoch[8] Batch [8600]	Speed: 27.76 samples/s ETA: 0 d  8 h 23 m	Data: 0.578 Tran: 0.007 F: 0.150 B: 0.293 O: 1.270 M: 0.007	Train-MLMAcc=0.634561,	MVRCAccuracy=0.679569,	MLMLossWVC=1.750406,	MVRCLoss=2.437280,	
Rank[  3]Epoch[8] Batch [8600]	Speed: 27.76 samples/s ETA: 0 d  8 h 23 m	Data: 0.933 Tran: 0.006 F: 0.149 B: 0.290 O: 0.918 M: 0.008	Train-MLMAcc=0.634561,	MVRCAccuracy=0.679569,	MLMLossWVC=1.750406,	MVRCLoss=2.437280,	
Rank[  2]Epoch[8] Batch [8700]	Speed: 25.34 samples/s ETA: 0 d  9 h  7 m	Data: 0.011 Tran: 0.008 F: 0.174 B: 0.379 O: 1.939 M: 0.012	Train-MLMAcc=0.634540,	MVRCAccuracy=0.679595,	MLMLossWVC=1.750327,	MVRCLoss=2.437288,	
Rank[  1]Epoch[8] Batch [8700]	Speed: 25.34 samples/s ETA: 0 d  9 h  7 m	Data: 0.366 Tran: 0.009 F: 0.181 B: 0.377 O: 1.579 M: 0.012	Train-MLMAcc=0.634540,	MVRCAccuracy=0.679595,	MLMLossWVC=1.750327,	MVRCLoss=2.437288,	
Rank[  3]Epoch[8] Batch [8700]	Speed: 25.34 samples/s ETA: 0 d  9 h  7 m	Data: 1.526 Tran: 0.009 F: 0.207 B: 0.345 O: 0.425 M: 0.011	Train-MLMAcc=0.634540,	MVRCAccuracy=0.679595,	MLMLossWVC=1.750327,	MVRCLoss=2.437288,	
Rank[  0]Epoch[8] Batch [8700]	Speed: 25.34 samples/s ETA: 0 d  9 h  7 m	Data: 0.012 Tran: 0.010 F: 0.172 B: 0.378 O: 1.940 M: 0.011	Train-MLMAcc=0.634540,	MVRCAccuracy=0.679595,	MLMLossWVC=1.750327,	MVRCLoss=2.437288,	
Rank[  3]Epoch[8] Batch [8800]	Speed: 27.29 samples/s ETA: 0 d  8 h 24 m	Data: 1.797 Tran: 0.009 F: 0.172 B: 0.297 O: 0.062 M: 0.008	Train-MLMAcc=0.634501,	MVRCAccuracy=0.679580,	MLMLossWVC=1.750381,	MVRCLoss=2.437266,	
Rank[  0]Epoch[8] Batch [8800]	Speed: 27.29 samples/s ETA: 0 d  8 h 24 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.291 O: 1.880 M: 0.007	Train-MLMAcc=0.634501,	MVRCAccuracy=0.679580,	MLMLossWVC=1.750381,	MVRCLoss=2.437266,	
Rank[  1]Epoch[8] Batch [8800]	Speed: 27.29 samples/s ETA: 0 d  8 h 24 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.296 O: 1.874 M: 0.008	Train-MLMAcc=0.634501,	MVRCAccuracy=0.679580,	MLMLossWVC=1.750381,	MVRCLoss=2.437266,	
Rank[  2]Epoch[8] Batch [8800]	Speed: 27.29 samples/s ETA: 0 d  8 h 24 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.293 O: 1.878 M: 0.007	Train-MLMAcc=0.634501,	MVRCAccuracy=0.679580,	MLMLossWVC=1.750381,	MVRCLoss=2.437266,	
Rank[  2]Epoch[8] Batch [8900]	Speed: 25.83 samples/s ETA: 0 d  8 h 48 m	Data: 0.011 Tran: 0.007 F: 0.164 B: 0.307 O: 1.976 M: 0.010	Train-MLMAcc=0.634529,	MVRCAccuracy=0.679574,	MLMLossWVC=1.750418,	MVRCLoss=2.437282,	
Rank[  0]Epoch[8] Batch [8900]	Speed: 25.83 samples/s ETA: 0 d  8 h 48 m	Data: 0.012 Tran: 0.007 F: 0.162 B: 0.310 O: 1.974 M: 0.010	Train-MLMAcc=0.634529,	MVRCAccuracy=0.679574,	MLMLossWVC=1.750418,	MVRCLoss=2.437282,	
Rank[  1]Epoch[8] Batch [8900]	Speed: 25.83 samples/s ETA: 0 d  8 h 48 m	Data: 0.012 Tran: 0.008 F: 0.163 B: 0.313 O: 1.969 M: 0.010	Train-MLMAcc=0.634529,	MVRCAccuracy=0.679574,	MLMLossWVC=1.750418,	MVRCLoss=2.437282,	
Rank[  3]Epoch[8] Batch [8900]	Speed: 25.83 samples/s ETA: 0 d  8 h 48 m	Data: 1.871 Tran: 0.009 F: 0.194 B: 0.324 O: 0.068 M: 0.010	Train-MLMAcc=0.634529,	MVRCAccuracy=0.679574,	MLMLossWVC=1.750418,	MVRCLoss=2.437282,	
Rank[  1]Epoch[8] Batch [9000]	Speed: 26.20 samples/s ETA: 0 d  8 h 37 m	Data: 0.097 Tran: 0.009 F: 0.186 B: 0.336 O: 1.793 M: 0.017	Train-MLMAcc=0.634526,	MVRCAccuracy=0.679575,	MLMLossWVC=1.750439,	MVRCLoss=2.437298,	
Rank[  0]Epoch[8] Batch [9000]	Speed: 26.20 samples/s ETA: 0 d  8 h 37 m	Data: 0.012 Tran: 0.009 F: 0.179 B: 0.320 O: 1.903 M: 0.015	Train-MLMAcc=0.634526,	MVRCAccuracy=0.679575,	MLMLossWVC=1.750439,	MVRCLoss=2.437298,	
Rank[  3]Epoch[8] Batch [9000]	Speed: 26.20 samples/s ETA: 0 d  8 h 37 m	Data: 1.694 Tran: 0.010 F: 0.209 B: 0.330 O: 0.178 M: 0.016	Train-MLMAcc=0.634526,	MVRCAccuracy=0.679575,	MLMLossWVC=1.750439,	MVRCLoss=2.437298,	
Rank[  2]Epoch[8] Batch [9000]	Speed: 26.20 samples/s ETA: 0 d  8 h 37 m	Data: 0.014 Tran: 0.009 F: 0.178 B: 0.324 O: 1.897 M: 0.017	Train-MLMAcc=0.634526,	MVRCAccuracy=0.679575,	MLMLossWVC=1.750439,	MVRCLoss=2.437298,	
Rank[  1]Epoch[8] Batch [9100]	Speed: 27.31 samples/s ETA: 0 d  8 h 12 m	Data: 0.158 Tran: 0.007 F: 0.153 B: 0.305 O: 1.710 M: 0.008	Train-MLMAcc=0.634566,	MVRCAccuracy=0.679597,	MLMLossWVC=1.750156,	MVRCLoss=2.437305,	
Rank[  3]Epoch[8] Batch [9100]	Speed: 27.31 samples/s ETA: 0 d  8 h 12 m	Data: 1.655 Tran: 0.007 F: 0.157 B: 0.298 O: 0.217 M: 0.009	Train-MLMAcc=0.634566,	MVRCAccuracy=0.679597,	MLMLossWVC=1.750156,	MVRCLoss=2.437305,	
Rank[  2]Epoch[8] Batch [9100]	Speed: 27.31 samples/s ETA: 0 d  8 h 12 m	Data: 0.017 Tran: 0.007 F: 0.153 B: 0.299 O: 1.858 M: 0.009	Train-MLMAcc=0.634566,	MVRCAccuracy=0.679597,	MLMLossWVC=1.750156,	MVRCLoss=2.437305,	
Rank[  0]Epoch[8] Batch [9100]	Speed: 27.31 samples/s ETA: 0 d  8 h 12 m	Data: 0.011 Tran: 0.007 F: 0.154 B: 0.297 O: 1.866 M: 0.007	Train-MLMAcc=0.634566,	MVRCAccuracy=0.679597,	MLMLossWVC=1.750156,	MVRCLoss=2.437305,	
Rank[  1]Epoch[8] Batch [9200]	Speed: 27.09 samples/s ETA: 0 d  8 h 12 m	Data: 0.009 Tran: 0.007 F: 0.154 B: 0.306 O: 1.873 M: 0.011	Train-MLMAcc=0.634594,	MVRCAccuracy=0.679624,	MLMLossWVC=1.750104,	MVRCLoss=2.437245,	
Rank[  2]Epoch[8] Batch [9200]	Speed: 27.09 samples/s ETA: 0 d  8 h 12 m	Data: 0.152 Tran: 0.007 F: 0.155 B: 0.303 O: 1.734 M: 0.010	Train-MLMAcc=0.634594,	MVRCAccuracy=0.679624,	MLMLossWVC=1.750104,	MVRCLoss=2.437245,	
Rank[  3]Epoch[8] Batch [9200]	Speed: 27.09 samples/s ETA: 0 d  8 h 12 m	Data: 1.632 Tran: 0.014 F: 0.184 B: 0.316 O: 0.205 M: 0.010	Train-MLMAcc=0.634594,	MVRCAccuracy=0.679624,	MLMLossWVC=1.750104,	MVRCLoss=2.437245,	
Rank[  0]Epoch[8] Batch [9200]	Speed: 27.09 samples/s ETA: 0 d  8 h 12 m	Data: 0.010 Tran: 0.007 F: 0.153 B: 0.299 O: 1.883 M: 0.008	Train-MLMAcc=0.634594,	MVRCAccuracy=0.679624,	MLMLossWVC=1.750104,	MVRCLoss=2.437245,	
Rank[  0]Epoch[8] Batch [9300]	Speed: 26.61 samples/s ETA: 0 d  8 h 17 m	Data: 0.309 Tran: 0.007 F: 0.168 B: 0.311 O: 1.601 M: 0.008	Train-MLMAcc=0.634613,	MVRCAccuracy=0.679624,	MLMLossWVC=1.750014,	MVRCLoss=2.437159,	
Rank[  2]Epoch[8] Batch [9300]	Speed: 26.61 samples/s ETA: 0 d  8 h 17 m	Data: 0.102 Tran: 0.007 F: 0.169 B: 0.314 O: 1.803 M: 0.009	Train-MLMAcc=0.634613,	MVRCAccuracy=0.679624,	MLMLossWVC=1.750014,	MVRCLoss=2.437159,	
Rank[  1]Epoch[8] Batch [9300]	Speed: 26.61 samples/s ETA: 0 d  8 h 17 m	Data: 0.018 Tran: 0.008 F: 0.166 B: 0.315 O: 1.887 M: 0.009	Train-MLMAcc=0.634613,	MVRCAccuracy=0.679624,	MLMLossWVC=1.750014,	MVRCLoss=2.437159,	
Rank[  3]Epoch[8] Batch [9300]	Speed: 26.61 samples/s ETA: 0 d  8 h 17 m	Data: 1.497 Tran: 0.008 F: 0.175 B: 0.321 O: 0.394 M: 0.009	Train-MLMAcc=0.634613,	MVRCAccuracy=0.679624,	MLMLossWVC=1.750014,	MVRCLoss=2.437159,	
Rank[  0]Epoch[8] Batch [9400]	Speed: 25.81 samples/s ETA: 0 d  8 h 28 m	Data: 0.150 Tran: 0.008 F: 0.165 B: 0.330 O: 1.811 M: 0.014	Train-MLMAcc=0.634617,	MVRCAccuracy=0.679602,	MLMLossWVC=1.749934,	MVRCLoss=2.437121,	
Rank[  1]Epoch[8] Batch [9400]	Speed: 25.81 samples/s ETA: 0 d  8 h 28 m	Data: 0.012 Tran: 0.007 F: 0.164 B: 0.338 O: 1.945 M: 0.012	Train-MLMAcc=0.634617,	MVRCAccuracy=0.679602,	MLMLossWVC=1.749934,	MVRCLoss=2.437121,	
Rank[  3]Epoch[8] Batch [9400]	Speed: 25.81 samples/s ETA: 0 d  8 h 28 m	Data: 1.533 Tran: 0.008 F: 0.213 B: 0.344 O: 0.364 M: 0.014	Train-MLMAcc=0.634617,	MVRCAccuracy=0.679602,	MLMLossWVC=1.749934,	MVRCLoss=2.437121,	
Rank[  2]Epoch[8] Batch [9400]	Speed: 25.81 samples/s ETA: 0 d  8 h 28 m	Data: 0.167 Tran: 0.008 F: 0.165 B: 0.329 O: 1.794 M: 0.015	Train-MLMAcc=0.634617,	MVRCAccuracy=0.679602,	MLMLossWVC=1.749934,	MVRCLoss=2.437121,	
Rank[  0]Epoch[8] Batch [9500]	Speed: 27.42 samples/s ETA: 0 d  7 h 54 m	Data: 0.903 Tran: 0.007 F: 0.152 B: 0.296 O: 0.967 M: 0.009	Train-MLMAcc=0.634628,	MVRCAccuracy=0.679576,	MLMLossWVC=1.749845,	MVRCLoss=2.437169,	
Rank[  2]Epoch[8] Batch [9500]	Speed: 27.42 samples/s ETA: 0 d  7 h 54 m	Data: 0.015 Tran: 0.008 F: 0.151 B: 0.297 O: 1.855 M: 0.008	Train-MLMAcc=0.634628,	MVRCAccuracy=0.679576,	MLMLossWVC=1.749845,	MVRCLoss=2.437169,	
Rank[  3]Epoch[8] Batch [9500]	Speed: 27.42 samples/s ETA: 0 d  7 h 54 m	Data: 0.914 Tran: 0.007 F: 0.152 B: 0.294 O: 0.959 M: 0.008	Train-MLMAcc=0.634628,	MVRCAccuracy=0.679576,	MLMLossWVC=1.749845,	MVRCLoss=2.437169,	
Rank[  1]Epoch[8] Batch [9500]	Speed: 27.42 samples/s ETA: 0 d  7 h 54 m	Data: 0.008 Tran: 0.008 F: 0.151 B: 0.299 O: 1.861 M: 0.007	Train-MLMAcc=0.634628,	MVRCAccuracy=0.679576,	MLMLossWVC=1.749845,	MVRCLoss=2.437169,	
Rank[  2]Epoch[8] Batch [9600]	Speed: 28.33 samples/s ETA: 0 d  7 h 35 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.294 O: 1.794 M: 0.006	Train-MLMAcc=0.634624,	MVRCAccuracy=0.679599,	MLMLossWVC=1.749874,	MVRCLoss=2.437185,	
Rank[  0]Epoch[8] Batch [9600]	Speed: 28.33 samples/s ETA: 0 d  7 h 35 m	Data: 0.764 Tran: 0.007 F: 0.151 B: 0.294 O: 1.034 M: 0.008	Train-MLMAcc=0.634624,	MVRCAccuracy=0.679599,	MLMLossWVC=1.749874,	MVRCLoss=2.437185,	
Rank[  3]Epoch[8] Batch [9600]	Speed: 28.33 samples/s ETA: 0 d  7 h 35 m	Data: 0.994 Tran: 0.007 F: 0.150 B: 0.290 O: 0.810 M: 0.007	Train-MLMAcc=0.634624,	MVRCAccuracy=0.679599,	MLMLossWVC=1.749874,	MVRCLoss=2.437185,	
Rank[  1]Epoch[8] Batch [9600]	Speed: 28.33 samples/s ETA: 0 d  7 h 35 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.298 O: 1.787 M: 0.008	Train-MLMAcc=0.634624,	MVRCAccuracy=0.679599,	MLMLossWVC=1.749874,	MVRCLoss=2.437185,	
Rank[  2]Epoch[8] Batch [9700]	Speed: 25.99 samples/s ETA: 0 d  8 h 12 m	Data: 0.010 Tran: 0.007 F: 0.165 B: 0.306 O: 1.959 M: 0.011	Train-MLMAcc=0.634606,	MVRCAccuracy=0.679578,	MLMLossWVC=1.749964,	MVRCLoss=2.437184,	
Rank[  3]Epoch[8] Batch [9700]	Speed: 25.99 samples/s ETA: 0 d  8 h 12 m	Data: 1.385 Tran: 0.012 F: 0.216 B: 0.318 O: 0.517 M: 0.012	Train-MLMAcc=0.634606,	MVRCAccuracy=0.679578,	MLMLossWVC=1.749964,	MVRCLoss=2.437184,	
Rank[  0]Epoch[8] Batch [9700]	Speed: 25.99 samples/s ETA: 0 d  8 h 12 m	Data: 0.443 Tran: 0.007 F: 0.175 B: 0.318 O: 1.504 M: 0.012	Train-MLMAcc=0.634606,	MVRCAccuracy=0.679578,	MLMLossWVC=1.749964,	MVRCLoss=2.437184,	
Rank[  1]Epoch[8] Batch [9700]	Speed: 25.99 samples/s ETA: 0 d  8 h 12 m	Data: 0.012 Tran: 0.007 F: 0.164 B: 0.308 O: 1.957 M: 0.011	Train-MLMAcc=0.634606,	MVRCAccuracy=0.679578,	MLMLossWVC=1.749964,	MVRCLoss=2.437184,	
Rank[  2]Epoch[8] Batch [9800]	Speed: 28.09 samples/s ETA: 0 d  7 h 31 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.294 O: 1.811 M: 0.008	Train-MLMAcc=0.634599,	MVRCAccuracy=0.679588,	MLMLossWVC=1.750119,	MVRCLoss=2.437175,	
Rank[  3]Epoch[8] Batch [9800]	Speed: 28.09 samples/s ETA: 0 d  7 h 31 m	Data: 1.654 Tran: 0.007 F: 0.150 B: 0.290 O: 0.169 M: 0.007	Train-MLMAcc=0.634599,	MVRCAccuracy=0.679588,	MLMLossWVC=1.750119,	MVRCLoss=2.437175,	
Rank[  0]Epoch[8] Batch [9800]	Speed: 28.09 samples/s ETA: 0 d  7 h 31 m	Data: 0.124 Tran: 0.007 F: 0.151 B: 0.293 O: 1.694 M: 0.008	Train-MLMAcc=0.634599,	MVRCAccuracy=0.679588,	MLMLossWVC=1.750119,	MVRCLoss=2.437175,	
Rank[  1]Epoch[8] Batch [9800]	Speed: 28.09 samples/s ETA: 0 d  7 h 31 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.298 O: 1.805 M: 0.008	Train-MLMAcc=0.634599,	MVRCAccuracy=0.679588,	MLMLossWVC=1.750119,	MVRCLoss=2.437175,	
Rank[  2]Epoch[8] Batch [9900]	Speed: 25.57 samples/s ETA: 0 d  8 h 12 m	Data: 0.016 Tran: 0.008 F: 0.161 B: 0.314 O: 1.990 M: 0.013	Train-MLMAcc=0.634622,	MVRCAccuracy=0.679599,	MLMLossWVC=1.749794,	MVRCLoss=2.437157,	
Rank[  1]Epoch[8] Batch [9900]	Speed: 25.57 samples/s ETA: 0 d  8 h 12 m	Data: 0.016 Tran: 0.008 F: 0.160 B: 0.317 O: 1.986 M: 0.014	Train-MLMAcc=0.634622,	MVRCAccuracy=0.679599,	MLMLossWVC=1.749794,	MVRCLoss=2.437157,	
Rank[  3]Epoch[8] Batch [9900]	Speed: 25.57 samples/s ETA: 0 d  8 h 12 m	Data: 1.843 Tran: 0.013 F: 0.229 B: 0.331 O: 0.071 M: 0.013	Train-MLMAcc=0.634622,	MVRCAccuracy=0.679599,	MLMLossWVC=1.749794,	MVRCLoss=2.437157,	
Rank[  0]Epoch[8] Batch [9900]	Speed: 25.57 samples/s ETA: 0 d  8 h 12 m	Data: 0.021 Tran: 0.008 F: 0.161 B: 0.311 O: 1.986 M: 0.013	Train-MLMAcc=0.634622,	MVRCAccuracy=0.679599,	MLMLossWVC=1.749794,	MVRCLoss=2.437157,	
Rank[  1]Epoch[8] Batch [10000]	Speed: 27.31 samples/s ETA: 0 d  7 h 36 m	Data: 0.010 Tran: 0.007 F: 0.154 B: 0.304 O: 1.860 M: 0.007	Train-MLMAcc=0.634632,	MVRCAccuracy=0.679607,	MLMLossWVC=1.749787,	MVRCLoss=2.437171,	
Rank[  2]Epoch[8] Batch [10000]	Speed: 27.31 samples/s ETA: 0 d  7 h 36 m	Data: 0.058 Tran: 0.007 F: 0.152 B: 0.297 O: 1.820 M: 0.008	Train-MLMAcc=0.634632,	MVRCAccuracy=0.679607,	MLMLossWVC=1.749787,	MVRCLoss=2.437171,	
Rank[  3]Epoch[8] Batch [10000]	Speed: 27.31 samples/s ETA: 0 d  7 h 36 m	Data: 1.754 Tran: 0.008 F: 0.188 B: 0.308 O: 0.076 M: 0.008	Train-MLMAcc=0.634632,	MVRCAccuracy=0.679607,	MLMLossWVC=1.749787,	MVRCLoss=2.437171,	
Rank[  0]Epoch[8] Batch [10000]	Speed: 27.31 samples/s ETA: 0 d  7 h 36 m	Data: 0.029 Tran: 0.007 F: 0.153 B: 0.298 O: 1.847 M: 0.008	Train-MLMAcc=0.634632,	MVRCAccuracy=0.679607,	MLMLossWVC=1.749787,	MVRCLoss=2.437171,	
Rank[  1]Epoch[8] Batch [10100]	Speed: 26.41 samples/s ETA: 0 d  7 h 48 m	Data: 0.010 Tran: 0.007 F: 0.165 B: 0.312 O: 1.915 M: 0.014	Train-MLMAcc=0.634645,	MVRCAccuracy=0.679583,	MLMLossWVC=1.749607,	MVRCLoss=2.437140,	
Rank[  0]Epoch[8] Batch [10100]	Speed: 26.41 samples/s ETA: 0 d  7 h 48 m	Data: 0.302 Tran: 0.007 F: 0.182 B: 0.312 O: 1.605 M: 0.014	Train-MLMAcc=0.634645,	MVRCAccuracy=0.679583,	MLMLossWVC=1.749607,	MVRCLoss=2.437140,	
Rank[  2]Epoch[8] Batch [10100]	Speed: 26.41 samples/s ETA: 0 d  7 h 48 m	Data: 0.009 Tran: 0.007 F: 0.167 B: 0.315 O: 1.910 M: 0.014	Train-MLMAcc=0.634645,	MVRCAccuracy=0.679583,	MLMLossWVC=1.749607,	MVRCLoss=2.437140,	
Rank[  3]Epoch[8] Batch [10100]	Speed: 26.41 samples/s ETA: 0 d  7 h 48 m	Data: 1.747 Tran: 0.008 F: 0.181 B: 0.326 O: 0.148 M: 0.012	Train-MLMAcc=0.634645,	MVRCAccuracy=0.679583,	MLMLossWVC=1.749607,	MVRCLoss=2.437140,	
Rank[  3]Epoch[8] Batch [10200]	Speed: 26.73 samples/s ETA: 0 d  7 h 38 m	Data: 1.796 Tran: 0.008 F: 0.187 B: 0.326 O: 0.068 M: 0.008	Train-MLMAcc=0.634682,	MVRCAccuracy=0.679583,	MLMLossWVC=1.749399,	MVRCLoss=2.437106,	
Rank[  1]Epoch[8] Batch [10200]	Speed: 26.73 samples/s ETA: 0 d  7 h 38 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.302 O: 1.913 M: 0.009	Train-MLMAcc=0.634682,	MVRCAccuracy=0.679583,	MLMLossWVC=1.749399,	MVRCLoss=2.437106,	
Rank[  0]Epoch[8] Batch [10200]	Speed: 26.73 samples/s ETA: 0 d  7 h 38 m	Data: 0.050 Tran: 0.007 F: 0.154 B: 0.297 O: 1.876 M: 0.009	Train-MLMAcc=0.634682,	MVRCAccuracy=0.679583,	MLMLossWVC=1.749399,	MVRCLoss=2.437106,	
Rank[  2]Epoch[8] Batch [10200]	Speed: 26.73 samples/s ETA: 0 d  7 h 38 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.297 O: 1.919 M: 0.009	Train-MLMAcc=0.634682,	MVRCAccuracy=0.679583,	MLMLossWVC=1.749399,	MVRCLoss=2.437106,	
Rank[  3]Epoch[8] Batch [10300]	Speed: 27.60 samples/s ETA: 0 d  7 h 20 m	Data: 1.809 Tran: 0.007 F: 0.151 B: 0.290 O: 0.056 M: 0.006	Train-MLMAcc=0.634737,	MVRCAccuracy=0.679584,	MLMLossWVC=1.749200,	MVRCLoss=2.437089,	
Rank[  2]Epoch[8] Batch [10300]	Speed: 27.60 samples/s ETA: 0 d  7 h 20 m	Data: 0.029 Tran: 0.007 F: 0.150 B: 0.294 O: 1.831 M: 0.005	Train-MLMAcc=0.634737,	MVRCAccuracy=0.679584,	MLMLossWVC=1.749200,	MVRCLoss=2.437089,	
Rank[  1]Epoch[8] Batch [10300]	Speed: 27.60 samples/s ETA: 0 d  7 h 20 m	Data: 0.007 Tran: 0.008 F: 0.150 B: 0.299 O: 1.848 M: 0.006	Train-MLMAcc=0.634737,	MVRCAccuracy=0.679584,	MLMLossWVC=1.749200,	MVRCLoss=2.437089,	
Rank[  0]Epoch[8] Batch [10300]	Speed: 27.60 samples/s ETA: 0 d  7 h 20 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.856 M: 0.006	Train-MLMAcc=0.634737,	MVRCAccuracy=0.679584,	MLMLossWVC=1.749200,	MVRCLoss=2.437089,	
Rank[  3]Epoch[8] Batch [10400]	Speed: 28.06 samples/s ETA: 0 d  7 h  9 m	Data: 1.729 Tran: 0.009 F: 0.169 B: 0.299 O: 0.066 M: 0.008	Train-MLMAcc=0.634699,	MVRCAccuracy=0.679567,	MLMLossWVC=1.749359,	MVRCLoss=2.437185,	
Rank[  2]Epoch[8] Batch [10400]	Speed: 28.06 samples/s ETA: 0 d  7 h  9 m	Data: 0.015 Tran: 0.007 F: 0.149 B: 0.291 O: 1.810 M: 0.008	Train-MLMAcc=0.634699,	MVRCAccuracy=0.679567,	MLMLossWVC=1.749359,	MVRCLoss=2.437185,	
Rank[  1]Epoch[8] Batch [10400]	Speed: 28.06 samples/s ETA: 0 d  7 h  9 m	Data: 0.008 Tran: 0.008 F: 0.151 B: 0.299 O: 1.809 M: 0.006	Train-MLMAcc=0.634699,	MVRCAccuracy=0.679567,	MLMLossWVC=1.749359,	MVRCLoss=2.437185,	
Rank[  0]Epoch[8] Batch [10400]	Speed: 28.06 samples/s ETA: 0 d  7 h  9 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.291 O: 1.816 M: 0.008	Train-MLMAcc=0.634699,	MVRCAccuracy=0.679567,	MLMLossWVC=1.749359,	MVRCLoss=2.437185,	
Rank[  2]Epoch[8] Batch [10500]	Speed: 28.11 samples/s ETA: 0 d  7 h  5 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.294 O: 1.811 M: 0.006	Train-MLMAcc=0.634667,	MVRCAccuracy=0.679567,	MLMLossWVC=1.749426,	MVRCLoss=2.437165,	
Rank[  3]Epoch[8] Batch [10500]	Speed: 28.11 samples/s ETA: 0 d  7 h  5 m	Data: 1.770 Tran: 0.007 F: 0.150 B: 0.290 O: 0.053 M: 0.006	Train-MLMAcc=0.634667,	MVRCAccuracy=0.679567,	MLMLossWVC=1.749426,	MVRCLoss=2.437165,	
Rank[  1]Epoch[8] Batch [10500]	Speed: 28.11 samples/s ETA: 0 d  7 h  5 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.811 M: 0.006	Train-MLMAcc=0.634667,	MVRCAccuracy=0.679567,	MLMLossWVC=1.749426,	MVRCLoss=2.437165,	
Rank[  0]Epoch[8] Batch [10500]	Speed: 28.11 samples/s ETA: 0 d  7 h  5 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.813 M: 0.006	Train-MLMAcc=0.634667,	MVRCAccuracy=0.679567,	MLMLossWVC=1.749426,	MVRCLoss=2.437165,	
Rank[  1]Epoch[8] Batch [10600]	Speed: 27.12 samples/s ETA: 0 d  7 h 16 m	Data: 0.008 Tran: 0.008 F: 0.156 B: 0.299 O: 1.879 M: 0.010	Train-MLMAcc=0.634671,	MVRCAccuracy=0.679564,	MLMLossWVC=1.749453,	MVRCLoss=2.437201,	
Rank[  2]Epoch[8] Batch [10600]	Speed: 27.12 samples/s ETA: 0 d  7 h 16 m	Data: 0.012 Tran: 0.009 F: 0.154 B: 0.295 O: 1.880 M: 0.009	Train-MLMAcc=0.634671,	MVRCAccuracy=0.679564,	MLMLossWVC=1.749453,	MVRCLoss=2.437201,	
Rank[  3]Epoch[8] Batch [10600]	Speed: 27.12 samples/s ETA: 0 d  7 h 16 m	Data: 1.807 Tran: 0.008 F: 0.173 B: 0.297 O: 0.065 M: 0.009	Train-MLMAcc=0.634671,	MVRCAccuracy=0.679564,	MLMLossWVC=1.749453,	MVRCLoss=2.437201,	
Rank[  0]Epoch[8] Batch [10600]	Speed: 27.12 samples/s ETA: 0 d  7 h 16 m	Data: 0.008 Tran: 0.009 F: 0.154 B: 0.293 O: 1.885 M: 0.009	Train-MLMAcc=0.634671,	MVRCAccuracy=0.679564,	MLMLossWVC=1.749453,	MVRCLoss=2.437201,	
Rank[  2]Epoch[8] Batch [10700]	Speed: 28.23 samples/s ETA: 0 d  6 h 55 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.803 M: 0.006	Train-MLMAcc=0.634695,	MVRCAccuracy=0.679572,	MLMLossWVC=1.749378,	MVRCLoss=2.437244,	
Rank[  3]Epoch[8] Batch [10700]	Speed: 28.23 samples/s ETA: 0 d  6 h 55 m	Data: 1.757 Tran: 0.007 F: 0.149 B: 0.287 O: 0.061 M: 0.006	Train-MLMAcc=0.634695,	MVRCAccuracy=0.679572,	MLMLossWVC=1.749378,	MVRCLoss=2.437244,	
Rank[  0]Epoch[8] Batch [10700]	Speed: 28.23 samples/s ETA: 0 d  6 h 55 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.294 O: 1.799 M: 0.006	Train-MLMAcc=0.634695,	MVRCAccuracy=0.679572,	MLMLossWVC=1.749378,	MVRCLoss=2.437244,	
Rank[  1]Epoch[8] Batch [10700]	Speed: 28.23 samples/s ETA: 0 d  6 h 55 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.299 O: 1.794 M: 0.007	Train-MLMAcc=0.634695,	MVRCAccuracy=0.679572,	MLMLossWVC=1.749378,	MVRCLoss=2.437244,	
Rank[  1]Epoch[8] Batch [10800]	Speed: 28.26 samples/s ETA: 0 d  6 h 51 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.797 M: 0.007	Train-MLMAcc=0.634707,	MVRCAccuracy=0.679587,	MLMLossWVC=1.749455,	MVRCLoss=2.437246,	
Rank[  3]Epoch[8] Batch [10800]	Speed: 28.26 samples/s ETA: 0 d  6 h 51 m	Data: 1.753 Tran: 0.007 F: 0.150 B: 0.289 O: 0.057 M: 0.008	Train-MLMAcc=0.634707,	MVRCAccuracy=0.679587,	MLMLossWVC=1.749455,	MVRCLoss=2.437246,	
Rank[  0]Epoch[8] Batch [10800]	Speed: 28.26 samples/s ETA: 0 d  6 h 51 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.292 O: 1.801 M: 0.008	Train-MLMAcc=0.634707,	MVRCAccuracy=0.679587,	MLMLossWVC=1.749455,	MVRCLoss=2.437246,	
Rank[  2]Epoch[8] Batch [10800]	Speed: 28.26 samples/s ETA: 0 d  6 h 51 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.294 O: 1.798 M: 0.007	Train-MLMAcc=0.634707,	MVRCAccuracy=0.679587,	MLMLossWVC=1.749455,	MVRCLoss=2.437246,	
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
New Best Val MLMAcc: 0.6077878475189209, Epoch: 8
New Best Val MLMAcc: 0.6077878475189209, Epoch: 8
New Best Val MLMAcc: 0.6077878475189209, Epoch: 8
New Best Val MLMAcc: 0.6077878475189209, Epoch: 8
Epoch[8] 	Val-MLMAcc=0.607788,	MVRCAccuracy=0.700743,	MLMLossWVC=1.900855,	MVRCLoss=2.446323,	
Epoch[8] 	Val-MLMAcc=0.607788,	MVRCAccuracy=0.700743,	MLMLossWVC=1.900855,	MVRCLoss=2.446323,	
Epoch[8] 	Val-MLMAcc=0.607788,	MVRCAccuracy=0.700743,	MLMLossWVC=1.900855,	MVRCLoss=2.446323,	
Best Val MLMAcc: 0.6077878475189209, Epoch: 8
PROGRESS: 90.00%
Best Val MLMAcc: 0.6077878475189209, Epoch: 8
Best Val MLMAcc: 0.6077878475189209, Epoch: 8
PROGRESS: 90.00%
Epoch[8] 	Val-MLMAcc=0.607788,	MVRCAccuracy=0.700743,	MLMLossWVC=1.900855,	MVRCLoss=2.446323,	
Best Val MLMAcc: 0.6077878475189209, Epoch: 8
PROGRESS: 90.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Save new best model to /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-best.model.
PROGRESS: 90.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Rank[  0]Epoch[9] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.598972,	MVRCAccuracy=0.673557,	MLMLossWVC=1.999421,	MVRCLoss=2.418871,	
Rank[  2]Epoch[9] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.598972,	MVRCAccuracy=0.673557,	MLMLossWVC=1.999421,	MVRCLoss=2.418871,	
Rank[  3]Epoch[9] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.598972,	MVRCAccuracy=0.673557,	MLMLossWVC=1.999421,	MVRCLoss=2.418871,	
Rank[  1]Epoch[9] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.598972,	MVRCAccuracy=0.673557,	MLMLossWVC=1.999421,	MVRCLoss=2.418871,	
Rank[  3]Epoch[9] Batch [100]	Speed: 28.65 samples/s ETA: 0 d  6 h 40 m	Data: 1.221 Tran: 0.012 F: 0.227 B: 0.437 O: 1.919 M: 0.009	Train-MLMAcc=0.642492,	MVRCAccuracy=0.679412,	MLMLossWVC=1.691610,	MVRCLoss=2.435395,	
Rank[  2]Epoch[9] Batch [100]	Speed: 28.65 samples/s ETA: 0 d  6 h 40 m	Data: 0.399 Tran: 0.011 F: 0.225 B: 0.439 O: 2.741 M: 0.009	Train-MLMAcc=0.642492,	MVRCAccuracy=0.679412,	MLMLossWVC=1.691610,	MVRCLoss=2.435395,	
Rank[  0]Epoch[9] Batch [100]	Speed: 28.65 samples/s ETA: 0 d  6 h 40 m	Data: 2.069 Tran: 0.010 F: 0.226 B: 0.438 O: 0.896 M: 0.009	Train-MLMAcc=0.642492,	MVRCAccuracy=0.679412,	MLMLossWVC=1.691610,	MVRCLoss=2.435395,	
Rank[  1]Epoch[9] Batch [100]	Speed: 28.65 samples/s ETA: 0 d  6 h 40 m	Data: 0.406 Tran: 0.012 F: 0.226 B: 0.446 O: 2.726 M: 0.009	Train-MLMAcc=0.642492,	MVRCAccuracy=0.679412,	MLMLossWVC=1.691610,	MVRCLoss=2.435395,	
Rank[  0]Epoch[9] Batch [200]	Speed: 28.04 samples/s ETA: 0 d  6 h 45 m	Data: 1.773 Tran: 0.007 F: 0.150 B: 0.292 O: 0.052 M: 0.007	Train-MLMAcc=0.640279,	MVRCAccuracy=0.679118,	MLMLossWVC=1.705612,	MVRCLoss=2.434024,	
Rank[  2]Epoch[9] Batch [200]	Speed: 28.04 samples/s ETA: 0 d  6 h 45 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.294 O: 1.816 M: 0.006	Train-MLMAcc=0.640279,	MVRCAccuracy=0.679118,	MLMLossWVC=1.705612,	MVRCLoss=2.434024,	
Rank[  3]Epoch[9] Batch [200]	Speed: 28.04 samples/s ETA: 0 d  6 h 45 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.289 O: 1.823 M: 0.006	Train-MLMAcc=0.640279,	MVRCAccuracy=0.679118,	MLMLossWVC=1.705612,	MVRCLoss=2.434024,	
Rank[  1]Epoch[9] Batch [200]	Speed: 28.04 samples/s ETA: 0 d  6 h 45 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.295 O: 1.816 M: 0.007	Train-MLMAcc=0.640279,	MVRCAccuracy=0.679118,	MLMLossWVC=1.705612,	MVRCLoss=2.434024,	
Rank[  0]Epoch[9] Batch [300]	Speed: 27.80 samples/s ETA: 0 d  6 h 44 m	Data: 1.793 Tran: 0.007 F: 0.150 B: 0.292 O: 0.054 M: 0.006	Train-MLMAcc=0.640036,	MVRCAccuracy=0.679701,	MLMLossWVC=1.714478,	MVRCLoss=2.434460,	
Rank[  1]Epoch[9] Batch [300]	Speed: 27.80 samples/s ETA: 0 d  6 h 44 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.299 O: 1.830 M: 0.006	Train-MLMAcc=0.640036,	MVRCAccuracy=0.679701,	MLMLossWVC=1.714478,	MVRCLoss=2.434460,	
Rank[  3]Epoch[9] Batch [300]	Speed: 27.80 samples/s ETA: 0 d  6 h 44 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.841 M: 0.006	Train-MLMAcc=0.640036,	MVRCAccuracy=0.679701,	MLMLossWVC=1.714478,	MVRCLoss=2.434460,	
Rank[  2]Epoch[9] Batch [300]	Speed: 27.80 samples/s ETA: 0 d  6 h 44 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.289 O: 1.843 M: 0.006	Train-MLMAcc=0.640036,	MVRCAccuracy=0.679701,	MLMLossWVC=1.714478,	MVRCLoss=2.434460,	
Rank[  1]Epoch[9] Batch [400]	Speed: 28.02 samples/s ETA: 0 d  6 h 37 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.295 O: 1.816 M: 0.007	Train-MLMAcc=0.638181,	MVRCAccuracy=0.679404,	MLMLossWVC=1.723263,	MVRCLoss=2.435058,	
Rank[  2]Epoch[9] Batch [400]	Speed: 28.02 samples/s ETA: 0 d  6 h 37 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.293 O: 1.818 M: 0.007	Train-MLMAcc=0.638181,	MVRCAccuracy=0.679404,	MLMLossWVC=1.723263,	MVRCLoss=2.435058,	
Rank[  0]Epoch[9] Batch [400]	Speed: 28.02 samples/s ETA: 0 d  6 h 37 m	Data: 1.770 Tran: 0.007 F: 0.150 B: 0.292 O: 0.055 M: 0.008	Train-MLMAcc=0.638181,	MVRCAccuracy=0.679404,	MLMLossWVC=1.723263,	MVRCLoss=2.435058,	
Rank[  3]Epoch[9] Batch [400]	Speed: 28.02 samples/s ETA: 0 d  6 h 37 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.289 O: 1.822 M: 0.008	Train-MLMAcc=0.638181,	MVRCAccuracy=0.679404,	MLMLossWVC=1.723263,	MVRCLoss=2.435058,	
Rank[  3]Epoch[9] Batch [500]	Speed: 27.54 samples/s ETA: 0 d  6 h 40 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.862 M: 0.006	Train-MLMAcc=0.636794,	MVRCAccuracy=0.678960,	MLMLossWVC=1.728798,	MVRCLoss=2.434566,	
Rank[  2]Epoch[9] Batch [500]	Speed: 27.54 samples/s ETA: 0 d  6 h 40 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.293 O: 1.858 M: 0.006	Train-MLMAcc=0.636794,	MVRCAccuracy=0.678960,	MLMLossWVC=1.728798,	MVRCLoss=2.434566,	
Rank[  1]Epoch[9] Batch [500]	Speed: 27.54 samples/s ETA: 0 d  6 h 40 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.296 O: 1.856 M: 0.005	Train-MLMAcc=0.636794,	MVRCAccuracy=0.678960,	MLMLossWVC=1.728798,	MVRCLoss=2.434566,	
Rank[  0]Epoch[9] Batch [500]	Speed: 27.54 samples/s ETA: 0 d  6 h 40 m	Data: 1.813 Tran: 0.007 F: 0.151 B: 0.291 O: 0.056 M: 0.005	Train-MLMAcc=0.636794,	MVRCAccuracy=0.678960,	MLMLossWVC=1.728798,	MVRCLoss=2.434566,	
Rank[  0]Epoch[9] Batch [600]	Speed: 28.09 samples/s ETA: 0 d  6 h 29 m	Data: 1.767 Tran: 0.007 F: 0.151 B: 0.293 O: 0.053 M: 0.006	Train-MLMAcc=0.635632,	MVRCAccuracy=0.679417,	MLMLossWVC=1.735391,	MVRCLoss=2.434488,	
Rank[  3]Epoch[9] Batch [600]	Speed: 28.09 samples/s ETA: 0 d  6 h 29 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.290 O: 1.817 M: 0.006	Train-MLMAcc=0.635632,	MVRCAccuracy=0.679417,	MLMLossWVC=1.735391,	MVRCLoss=2.434488,	
Rank[  2]Epoch[9] Batch [600]	Speed: 28.09 samples/s ETA: 0 d  6 h 29 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.814 M: 0.007	Train-MLMAcc=0.635632,	MVRCAccuracy=0.679417,	MLMLossWVC=1.735391,	MVRCLoss=2.434488,	
Rank[  1]Epoch[9] Batch [600]	Speed: 28.09 samples/s ETA: 0 d  6 h 29 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.298 O: 1.807 M: 0.006	Train-MLMAcc=0.635632,	MVRCAccuracy=0.679417,	MLMLossWVC=1.735391,	MVRCLoss=2.434488,	
Rank[  0]Epoch[9] Batch [700]	Speed: 27.88 samples/s ETA: 0 d  6 h 28 m	Data: 1.786 Tran: 0.007 F: 0.150 B: 0.291 O: 0.054 M: 0.007	Train-MLMAcc=0.635616,	MVRCAccuracy=0.679883,	MLMLossWVC=1.735590,	MVRCLoss=2.434818,	
Rank[  2]Epoch[9] Batch [700]	Speed: 27.88 samples/s ETA: 0 d  6 h 28 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.292 O: 1.832 M: 0.007	Train-MLMAcc=0.635616,	MVRCAccuracy=0.679883,	MLMLossWVC=1.735590,	MVRCLoss=2.434818,	
Rank[  1]Epoch[9] Batch [700]	Speed: 27.88 samples/s ETA: 0 d  6 h 28 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.826 M: 0.006	Train-MLMAcc=0.635616,	MVRCAccuracy=0.679883,	MLMLossWVC=1.735590,	MVRCLoss=2.434818,	
Rank[  3]Epoch[9] Batch [700]	Speed: 27.88 samples/s ETA: 0 d  6 h 28 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.291 O: 1.832 M: 0.007	Train-MLMAcc=0.635616,	MVRCAccuracy=0.679883,	MLMLossWVC=1.735590,	MVRCLoss=2.434818,	
Rank[  2]Epoch[9] Batch [800]	Speed: 28.12 samples/s ETA: 0 d  6 h 21 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.810 M: 0.006	Train-MLMAcc=0.635623,	MVRCAccuracy=0.680449,	MLMLossWVC=1.736591,	MVRCLoss=2.434180,	
Rank[  0]Epoch[9] Batch [800]	Speed: 28.12 samples/s ETA: 0 d  6 h 21 m	Data: 1.766 Tran: 0.007 F: 0.151 B: 0.292 O: 0.053 M: 0.006	Train-MLMAcc=0.635623,	MVRCAccuracy=0.680449,	MLMLossWVC=1.736591,	MVRCLoss=2.434180,	
Rank[  1]Epoch[9] Batch [800]	Speed: 28.12 samples/s ETA: 0 d  6 h 21 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.297 O: 1.807 M: 0.006	Train-MLMAcc=0.635623,	MVRCAccuracy=0.680449,	MLMLossWVC=1.736591,	MVRCLoss=2.434180,	
Rank[  3]Epoch[9] Batch [800]	Speed: 28.12 samples/s ETA: 0 d  6 h 21 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.288 O: 1.818 M: 0.006	Train-MLMAcc=0.635623,	MVRCAccuracy=0.680449,	MLMLossWVC=1.736591,	MVRCLoss=2.434180,	
Rank[  3]Epoch[9] Batch [900]	Speed: 27.75 samples/s ETA: 0 d  6 h 22 m	Data: 0.018 Tran: 0.007 F: 0.149 B: 0.289 O: 1.835 M: 0.008	Train-MLMAcc=0.636175,	MVRCAccuracy=0.680303,	MLMLossWVC=1.734608,	MVRCLoss=2.434540,	
Rank[  0]Epoch[9] Batch [900]	Speed: 27.75 samples/s ETA: 0 d  6 h 22 m	Data: 1.783 Tran: 0.007 F: 0.151 B: 0.293 O: 0.063 M: 0.007	Train-MLMAcc=0.636175,	MVRCAccuracy=0.680303,	MLMLossWVC=1.734608,	MVRCLoss=2.434540,	
Rank[  1]Epoch[9] Batch [900]	Speed: 27.75 samples/s ETA: 0 d  6 h 22 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.297 O: 1.837 M: 0.005	Train-MLMAcc=0.636175,	MVRCAccuracy=0.680303,	MLMLossWVC=1.734608,	MVRCLoss=2.434540,	
Rank[  2]Epoch[9] Batch [900]	Speed: 27.75 samples/s ETA: 0 d  6 h 22 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.293 O: 1.839 M: 0.008	Train-MLMAcc=0.636175,	MVRCAccuracy=0.680303,	MLMLossWVC=1.734608,	MVRCLoss=2.434540,	
Rank[  3]Epoch[9] Batch [1000]	Speed: 27.80 samples/s ETA: 0 d  6 h 17 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.840 M: 0.007	Train-MLMAcc=0.636185,	MVRCAccuracy=0.680470,	MLMLossWVC=1.733366,	MVRCLoss=2.433986,	
Rank[  1]Epoch[9] Batch [1000]	Speed: 27.80 samples/s ETA: 0 d  6 h 17 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.296 O: 1.833 M: 0.007	Train-MLMAcc=0.636185,	MVRCAccuracy=0.680470,	MLMLossWVC=1.733366,	MVRCLoss=2.433986,	
Rank[  0]Epoch[9] Batch [1000]	Speed: 27.80 samples/s ETA: 0 d  6 h 17 m	Data: 1.789 Tran: 0.007 F: 0.151 B: 0.292 O: 0.055 M: 0.007	Train-MLMAcc=0.636185,	MVRCAccuracy=0.680470,	MLMLossWVC=1.733366,	MVRCLoss=2.433986,	
Rank[  2]Epoch[9] Batch [1000]	Speed: 27.80 samples/s ETA: 0 d  6 h 17 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.293 O: 1.835 M: 0.008	Train-MLMAcc=0.636185,	MVRCAccuracy=0.680470,	MLMLossWVC=1.733366,	MVRCLoss=2.433986,	
Rank[  3]Epoch[9] Batch [1100]	Speed: 27.59 samples/s ETA: 0 d  6 h 16 m	Data: 0.446 Tran: 0.007 F: 0.150 B: 0.291 O: 1.417 M: 0.008	Train-MLMAcc=0.636543,	MVRCAccuracy=0.680417,	MLMLossWVC=1.732478,	MVRCLoss=2.433594,	
Rank[  0]Epoch[9] Batch [1100]	Speed: 27.59 samples/s ETA: 0 d  6 h 16 m	Data: 1.798 Tran: 0.007 F: 0.150 B: 0.291 O: 0.066 M: 0.006	Train-MLMAcc=0.636543,	MVRCAccuracy=0.680417,	MLMLossWVC=1.732478,	MVRCLoss=2.433594,	
Rank[  1]Epoch[9] Batch [1100]	Speed: 27.59 samples/s ETA: 0 d  6 h 16 m	Data: 0.043 Tran: 0.007 F: 0.150 B: 0.298 O: 1.813 M: 0.006	Train-MLMAcc=0.636543,	MVRCAccuracy=0.680417,	MLMLossWVC=1.732478,	MVRCLoss=2.433594,	
Rank[  2]Epoch[9] Batch [1100]	Speed: 27.59 samples/s ETA: 0 d  6 h 16 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.294 O: 1.852 M: 0.007	Train-MLMAcc=0.636543,	MVRCAccuracy=0.680417,	MLMLossWVC=1.732478,	MVRCLoss=2.433594,	
Rank[  2]Epoch[9] Batch [1200]	Speed: 27.81 samples/s ETA: 0 d  6 h 10 m	Data: 0.013 Tran: 0.007 F: 0.149 B: 0.294 O: 1.830 M: 0.008	Train-MLMAcc=0.636375,	MVRCAccuracy=0.680350,	MLMLossWVC=1.733441,	MVRCLoss=2.433606,	
Rank[  3]Epoch[9] Batch [1200]	Speed: 27.81 samples/s ETA: 0 d  6 h 10 m	Data: 1.041 Tran: 0.007 F: 0.150 B: 0.291 O: 0.804 M: 0.007	Train-MLMAcc=0.636375,	MVRCAccuracy=0.680350,	MLMLossWVC=1.733441,	MVRCLoss=2.433606,	
Rank[  1]Epoch[9] Batch [1200]	Speed: 27.81 samples/s ETA: 0 d  6 h 10 m	Data: 0.022 Tran: 0.007 F: 0.150 B: 0.298 O: 1.816 M: 0.008	Train-MLMAcc=0.636375,	MVRCAccuracy=0.680350,	MLMLossWVC=1.733441,	MVRCLoss=2.433606,	
Rank[  0]Epoch[9] Batch [1200]	Speed: 27.81 samples/s ETA: 0 d  6 h 10 m	Data: 1.777 Tran: 0.007 F: 0.151 B: 0.292 O: 0.068 M: 0.007	Train-MLMAcc=0.636375,	MVRCAccuracy=0.680350,	MLMLossWVC=1.733441,	MVRCLoss=2.433606,	
Rank[  2]Epoch[9] Batch [1300]	Speed: 27.77 samples/s ETA: 0 d  6 h  6 m	Data: 0.014 Tran: 0.008 F: 0.149 B: 0.291 O: 1.835 M: 0.007	Train-MLMAcc=0.636163,	MVRCAccuracy=0.680327,	MLMLossWVC=1.734646,	MVRCLoss=2.434062,	
Rank[  3]Epoch[9] Batch [1300]	Speed: 27.77 samples/s ETA: 0 d  6 h  6 m	Data: 0.392 Tran: 0.007 F: 0.150 B: 0.289 O: 1.461 M: 0.006	Train-MLMAcc=0.636163,	MVRCAccuracy=0.680327,	MLMLossWVC=1.734646,	MVRCLoss=2.434062,	
Rank[  0]Epoch[9] Batch [1300]	Speed: 27.77 samples/s ETA: 0 d  6 h  6 m	Data: 1.785 Tran: 0.007 F: 0.151 B: 0.293 O: 0.060 M: 0.007	Train-MLMAcc=0.636163,	MVRCAccuracy=0.680327,	MLMLossWVC=1.734646,	MVRCLoss=2.434062,	
Rank[  1]Epoch[9] Batch [1300]	Speed: 27.77 samples/s ETA: 0 d  6 h  6 m	Data: 0.019 Tran: 0.008 F: 0.150 B: 0.299 O: 1.821 M: 0.008	Train-MLMAcc=0.636163,	MVRCAccuracy=0.680327,	MLMLossWVC=1.734646,	MVRCLoss=2.434062,	
Rank[  1]Epoch[9] Batch [1400]	Speed: 27.51 samples/s ETA: 0 d  6 h  6 m	Data: 0.030 Tran: 0.007 F: 0.150 B: 0.298 O: 1.831 M: 0.009	Train-MLMAcc=0.636272,	MVRCAccuracy=0.680266,	MLMLossWVC=1.735474,	MVRCLoss=2.434458,	
Rank[  0]Epoch[9] Batch [1400]	Speed: 27.51 samples/s ETA: 0 d  6 h  6 m	Data: 1.326 Tran: 0.009 F: 0.166 B: 0.295 O: 0.520 M: 0.008	Train-MLMAcc=0.636272,	MVRCAccuracy=0.680266,	MLMLossWVC=1.735474,	MVRCLoss=2.434458,	
Rank[  2]Epoch[9] Batch [1400]	Speed: 27.51 samples/s ETA: 0 d  6 h  6 m	Data: 0.443 Tran: 0.007 F: 0.151 B: 0.296 O: 1.420 M: 0.008	Train-MLMAcc=0.636272,	MVRCAccuracy=0.680266,	MLMLossWVC=1.735474,	MVRCLoss=2.434458,	
Rank[  3]Epoch[9] Batch [1400]	Speed: 27.51 samples/s ETA: 0 d  6 h  6 m	Data: 0.020 Tran: 0.007 F: 0.150 B: 0.292 O: 1.848 M: 0.008	Train-MLMAcc=0.636272,	MVRCAccuracy=0.680266,	MLMLossWVC=1.735474,	MVRCLoss=2.434458,	
Rank[  3]Epoch[9] Batch [1500]	Speed: 27.80 samples/s ETA: 0 d  5 h 58 m	Data: 0.030 Tran: 0.007 F: 0.150 B: 0.291 O: 1.816 M: 0.007	Train-MLMAcc=0.636422,	MVRCAccuracy=0.680440,	MLMLossWVC=1.734341,	MVRCLoss=2.434632,	
Rank[  1]Epoch[9] Batch [1500]	Speed: 27.80 samples/s ETA: 0 d  5 h 58 m	Data: 0.624 Tran: 0.007 F: 0.150 B: 0.299 O: 1.213 M: 0.008	Train-MLMAcc=0.636422,	MVRCAccuracy=0.680440,	MLMLossWVC=1.734341,	MVRCLoss=2.434632,	
Rank[  0]Epoch[9] Batch [1500]	Speed: 27.80 samples/s ETA: 0 d  5 h 58 m	Data: 1.156 Tran: 0.007 F: 0.151 B: 0.290 O: 0.689 M: 0.008	Train-MLMAcc=0.636422,	MVRCAccuracy=0.680440,	MLMLossWVC=1.734341,	MVRCLoss=2.434632,	
Rank[  2]Epoch[9] Batch [1500]	Speed: 27.80 samples/s ETA: 0 d  5 h 58 m	Data: 0.020 Tran: 0.007 F: 0.150 B: 0.296 O: 1.822 M: 0.006	Train-MLMAcc=0.636422,	MVRCAccuracy=0.680440,	MLMLossWVC=1.734341,	MVRCLoss=2.434632,	
Rank[  0]Epoch[9] Batch [1600]	Speed: 27.71 samples/s ETA: 0 d  5 h 56 m	Data: 1.086 Tran: 0.007 F: 0.156 B: 0.295 O: 0.757 M: 0.009	Train-MLMAcc=0.636628,	MVRCAccuracy=0.680439,	MLMLossWVC=1.733905,	MVRCLoss=2.434426,	
Rank[  3]Epoch[9] Batch [1600]	Speed: 27.71 samples/s ETA: 0 d  5 h 56 m	Data: 0.013 Tran: 0.007 F: 0.150 B: 0.291 O: 1.839 M: 0.009	Train-MLMAcc=0.636628,	MVRCAccuracy=0.680439,	MLMLossWVC=1.733905,	MVRCLoss=2.434426,	
Rank[  1]Epoch[9] Batch [1600]	Speed: 27.71 samples/s ETA: 0 d  5 h 56 m	Data: 0.706 Tran: 0.007 F: 0.157 B: 0.300 O: 1.131 M: 0.009	Train-MLMAcc=0.636628,	MVRCAccuracy=0.680439,	MLMLossWVC=1.733905,	MVRCLoss=2.434426,	
Rank[  2]Epoch[9] Batch [1600]	Speed: 27.71 samples/s ETA: 0 d  5 h 56 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.837 M: 0.010	Train-MLMAcc=0.636628,	MVRCAccuracy=0.680439,	MLMLossWVC=1.733905,	MVRCLoss=2.434426,	
Rank[  3]Epoch[9] Batch [1700]	Speed: 27.71 samples/s ETA: 0 d  5 h 52 m	Data: 0.013 Tran: 0.007 F: 0.155 B: 0.291 O: 1.834 M: 0.008	Train-MLMAcc=0.636662,	MVRCAccuracy=0.680416,	MLMLossWVC=1.733676,	MVRCLoss=2.434845,	
Rank[  2]Epoch[9] Batch [1700]	Speed: 27.71 samples/s ETA: 0 d  5 h 52 m	Data: 0.139 Tran: 0.007 F: 0.156 B: 0.295 O: 1.704 M: 0.007	Train-MLMAcc=0.636662,	MVRCAccuracy=0.680416,	MLMLossWVC=1.733676,	MVRCLoss=2.434845,	
Rank[  1]Epoch[9] Batch [1700]	Speed: 27.71 samples/s ETA: 0 d  5 h 52 m	Data: 0.640 Tran: 0.007 F: 0.159 B: 0.299 O: 1.196 M: 0.008	Train-MLMAcc=0.636662,	MVRCAccuracy=0.680416,	MLMLossWVC=1.733676,	MVRCLoss=2.434845,	
Rank[  0]Epoch[9] Batch [1700]	Speed: 27.71 samples/s ETA: 0 d  5 h 52 m	Data: 1.135 Tran: 0.007 F: 0.176 B: 0.294 O: 0.690 M: 0.007	Train-MLMAcc=0.636662,	MVRCAccuracy=0.680416,	MLMLossWVC=1.733676,	MVRCLoss=2.434845,	
Rank[  0]Epoch[9] Batch [1800]	Speed: 27.71 samples/s ETA: 0 d  5 h 48 m	Data: 0.984 Tran: 0.006 F: 0.151 B: 0.292 O: 0.868 M: 0.007	Train-MLMAcc=0.636709,	MVRCAccuracy=0.680408,	MLMLossWVC=1.733905,	MVRCLoss=2.435242,	
Rank[  1]Epoch[9] Batch [1800]	Speed: 27.71 samples/s ETA: 0 d  5 h 48 m	Data: 0.910 Tran: 0.006 F: 0.155 B: 0.299 O: 0.931 M: 0.008	Train-MLMAcc=0.636709,	MVRCAccuracy=0.680408,	MLMLossWVC=1.733905,	MVRCLoss=2.435242,	
Rank[  3]Epoch[9] Batch [1800]	Speed: 27.71 samples/s ETA: 0 d  5 h 48 m	Data: 0.009 Tran: 0.007 F: 0.150 B: 0.290 O: 1.845 M: 0.008	Train-MLMAcc=0.636709,	MVRCAccuracy=0.680408,	MLMLossWVC=1.733905,	MVRCLoss=2.435242,	
Rank[  2]Epoch[9] Batch [1800]	Speed: 27.71 samples/s ETA: 0 d  5 h 48 m	Data: 0.181 Tran: 0.007 F: 0.149 B: 0.294 O: 1.669 M: 0.009	Train-MLMAcc=0.636709,	MVRCAccuracy=0.680408,	MLMLossWVC=1.733905,	MVRCLoss=2.435242,	
Rank[  1]Epoch[9] Batch [1900]	Speed: 27.46 samples/s ETA: 0 d  5 h 47 m	Data: 0.536 Tran: 0.007 F: 0.154 B: 0.297 O: 1.327 M: 0.009	Train-MLMAcc=0.636549,	MVRCAccuracy=0.680364,	MLMLossWVC=1.734775,	MVRCLoss=2.435298,	
Rank[  2]Epoch[9] Batch [1900]	Speed: 27.46 samples/s ETA: 0 d  5 h 47 m	Data: 0.138 Tran: 0.007 F: 0.151 B: 0.297 O: 1.729 M: 0.008	Train-MLMAcc=0.636549,	MVRCAccuracy=0.680364,	MLMLossWVC=1.734775,	MVRCLoss=2.435298,	
Rank[  3]Epoch[9] Batch [1900]	Speed: 27.46 samples/s ETA: 0 d  5 h 47 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.864 M: 0.007	Train-MLMAcc=0.636549,	MVRCAccuracy=0.680364,	MLMLossWVC=1.734775,	MVRCLoss=2.435298,	
Rank[  0]Epoch[9] Batch [1900]	Speed: 27.46 samples/s ETA: 0 d  5 h 47 m	Data: 1.181 Tran: 0.007 F: 0.152 B: 0.292 O: 0.690 M: 0.007	Train-MLMAcc=0.636549,	MVRCAccuracy=0.680364,	MLMLossWVC=1.734775,	MVRCLoss=2.435298,	
Rank[  3]Epoch[9] Batch [2000]	Speed: 27.84 samples/s ETA: 0 d  5 h 39 m	Data: 0.083 Tran: 0.007 F: 0.150 B: 0.291 O: 1.756 M: 0.011	Train-MLMAcc=0.636564,	MVRCAccuracy=0.680429,	MLMLossWVC=1.734111,	MVRCLoss=2.434988,	
Rank[  1]Epoch[9] Batch [2000]	Speed: 27.84 samples/s ETA: 0 d  5 h 39 m	Data: 0.573 Tran: 0.007 F: 0.152 B: 0.298 O: 1.259 M: 0.010	Train-MLMAcc=0.636564,	MVRCAccuracy=0.680429,	MLMLossWVC=1.734111,	MVRCLoss=2.434988,	
Rank[  2]Epoch[9] Batch [2000]	Speed: 27.84 samples/s ETA: 0 d  5 h 39 m	Data: 0.200 Tran: 0.007 F: 0.149 B: 0.291 O: 1.643 M: 0.008	Train-MLMAcc=0.636564,	MVRCAccuracy=0.680429,	MLMLossWVC=1.734111,	MVRCLoss=2.434988,	
Rank[  0]Epoch[9] Batch [2000]	Speed: 27.84 samples/s ETA: 0 d  5 h 39 m	Data: 1.113 Tran: 0.008 F: 0.165 B: 0.301 O: 0.700 M: 0.011	Train-MLMAcc=0.636564,	MVRCAccuracy=0.680429,	MLMLossWVC=1.734111,	MVRCLoss=2.434988,	
Rank[  0]Epoch[9] Batch [2100]	Speed: 27.26 samples/s ETA: 0 d  5 h 42 m	Data: 0.885 Tran: 0.007 F: 0.164 B: 0.298 O: 0.983 M: 0.008	Train-MLMAcc=0.636668,	MVRCAccuracy=0.680479,	MLMLossWVC=1.733495,	MVRCLoss=2.434911,	
Rank[  3]Epoch[9] Batch [2100]	Speed: 27.26 samples/s ETA: 0 d  5 h 42 m	Data: 0.621 Tran: 0.009 F: 0.177 B: 0.293 O: 1.235 M: 0.010	Train-MLMAcc=0.636668,	MVRCAccuracy=0.680479,	MLMLossWVC=1.733495,	MVRCLoss=2.434911,	
Rank[  1]Epoch[9] Batch [2100]	Speed: 27.26 samples/s ETA: 0 d  5 h 42 m	Data: 0.870 Tran: 0.008 F: 0.167 B: 0.305 O: 0.987 M: 0.008	Train-MLMAcc=0.636668,	MVRCAccuracy=0.680479,	MLMLossWVC=1.733495,	MVRCLoss=2.434911,	
Rank[  2]Epoch[9] Batch [2100]	Speed: 27.26 samples/s ETA: 0 d  5 h 42 m	Data: 0.598 Tran: 0.010 F: 0.180 B: 0.298 O: 1.251 M: 0.010	Train-MLMAcc=0.636668,	MVRCAccuracy=0.680479,	MLMLossWVC=1.733495,	MVRCLoss=2.434911,	
Rank[  2]Epoch[9] Batch [2200]	Speed: 27.48 samples/s ETA: 0 d  5 h 35 m	Data: 0.139 Tran: 0.007 F: 0.150 B: 0.293 O: 1.731 M: 0.006	Train-MLMAcc=0.636553,	MVRCAccuracy=0.680483,	MLMLossWVC=1.734245,	MVRCLoss=2.434789,	
Rank[  3]Epoch[9] Batch [2200]	Speed: 27.48 samples/s ETA: 0 d  5 h 35 m	Data: 0.918 Tran: 0.007 F: 0.175 B: 0.304 O: 0.916 M: 0.006	Train-MLMAcc=0.636553,	MVRCAccuracy=0.680483,	MLMLossWVC=1.734245,	MVRCLoss=2.434789,	
Rank[  0]Epoch[9] Batch [2200]	Speed: 27.48 samples/s ETA: 0 d  5 h 35 m	Data: 0.868 Tran: 0.007 F: 0.154 B: 0.295 O: 0.997 M: 0.006	Train-MLMAcc=0.636553,	MVRCAccuracy=0.680483,	MLMLossWVC=1.734245,	MVRCLoss=2.434789,	
Rank[  1]Epoch[9] Batch [2200]	Speed: 27.48 samples/s ETA: 0 d  5 h 35 m	Data: 0.208 Tran: 0.007 F: 0.151 B: 0.298 O: 1.657 M: 0.006	Train-MLMAcc=0.636553,	MVRCAccuracy=0.680483,	MLMLossWVC=1.734245,	MVRCLoss=2.434789,	
Rank[  0]Epoch[9] Batch [2300]	Speed: 26.74 samples/s ETA: 0 d  5 h 41 m	Data: 0.733 Tran: 0.007 F: 0.152 B: 0.293 O: 1.197 M: 0.010	Train-MLMAcc=0.636478,	MVRCAccuracy=0.680552,	MLMLossWVC=1.735339,	MVRCLoss=2.434684,	
Rank[  2]Epoch[9] Batch [2300]	Speed: 26.74 samples/s ETA: 0 d  5 h 41 m	Data: 0.200 Tran: 0.007 F: 0.151 B: 0.295 O: 1.731 M: 0.008	Train-MLMAcc=0.636478,	MVRCAccuracy=0.680552,	MLMLossWVC=1.735339,	MVRCLoss=2.434684,	
Rank[  3]Epoch[9] Batch [2300]	Speed: 26.74 samples/s ETA: 0 d  5 h 41 m	Data: 1.129 Tran: 0.008 F: 0.168 B: 0.298 O: 0.781 M: 0.008	Train-MLMAcc=0.636478,	MVRCAccuracy=0.680552,	MLMLossWVC=1.735339,	MVRCLoss=2.434684,	
Rank[  1]Epoch[9] Batch [2300]	Speed: 26.74 samples/s ETA: 0 d  5 h 41 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.299 O: 1.917 M: 0.010	Train-MLMAcc=0.636478,	MVRCAccuracy=0.680552,	MLMLossWVC=1.735339,	MVRCLoss=2.434684,	
Rank[  0]Epoch[9] Batch [2400]	Speed: 26.19 samples/s ETA: 0 d  5 h 44 m	Data: 0.189 Tran: 0.007 F: 0.166 B: 0.313 O: 1.755 M: 0.011	Train-MLMAcc=0.636573,	MVRCAccuracy=0.680583,	MLMLossWVC=1.735334,	MVRCLoss=2.434924,	
Rank[  3]Epoch[9] Batch [2400]	Speed: 26.19 samples/s ETA: 0 d  5 h 44 m	Data: 1.671 Tran: 0.009 F: 0.189 B: 0.313 O: 0.249 M: 0.011	Train-MLMAcc=0.636573,	MVRCAccuracy=0.680583,	MLMLossWVC=1.735334,	MVRCLoss=2.434924,	
Rank[  1]Epoch[9] Batch [2400]	Speed: 26.19 samples/s ETA: 0 d  5 h 44 m	Data: 0.009 Tran: 0.007 F: 0.164 B: 0.310 O: 1.938 M: 0.012	Train-MLMAcc=0.636573,	MVRCAccuracy=0.680583,	MLMLossWVC=1.735334,	MVRCLoss=2.434924,	
Rank[  2]Epoch[9] Batch [2400]	Speed: 26.19 samples/s ETA: 0 d  5 h 44 m	Data: 0.199 Tran: 0.007 F: 0.166 B: 0.306 O: 1.751 M: 0.012	Train-MLMAcc=0.636573,	MVRCAccuracy=0.680583,	MLMLossWVC=1.735334,	MVRCLoss=2.434924,	
Rank[  0]Epoch[9] Batch [2500]	Speed: 23.15 samples/s ETA: 0 d  6 h 24 m	Data: 0.012 Tran: 0.007 F: 0.221 B: 0.392 O: 2.103 M: 0.026	Train-MLMAcc=0.636370,	MVRCAccuracy=0.680578,	MLMLossWVC=1.736111,	MVRCLoss=2.434823,	
Rank[  2]Epoch[9] Batch [2500]	Speed: 23.15 samples/s ETA: 0 d  6 h 24 m	Data: 0.104 Tran: 0.008 F: 0.220 B: 0.391 O: 2.013 M: 0.026	Train-MLMAcc=0.636370,	MVRCAccuracy=0.680578,	MLMLossWVC=1.736111,	MVRCLoss=2.434823,	
Rank[  1]Epoch[9] Batch [2500]	Speed: 23.15 samples/s ETA: 0 d  6 h 24 m	Data: 0.022 Tran: 0.008 F: 0.210 B: 0.393 O: 2.105 M: 0.024	Train-MLMAcc=0.636370,	MVRCAccuracy=0.680578,	MLMLossWVC=1.736111,	MVRCLoss=2.434823,	
Rank[  3]Epoch[9] Batch [2500]	Speed: 23.15 samples/s ETA: 0 d  6 h 24 m	Data: 1.982 Tran: 0.011 F: 0.251 B: 0.395 O: 0.098 M: 0.024	Train-MLMAcc=0.636370,	MVRCAccuracy=0.680578,	MLMLossWVC=1.736111,	MVRCLoss=2.434823,	
Rank[  2]Epoch[9] Batch [2600]	Speed: 27.50 samples/s ETA: 0 d  5 h 20 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.295 O: 1.857 M: 0.007	Train-MLMAcc=0.636383,	MVRCAccuracy=0.680451,	MLMLossWVC=1.736005,	MVRCLoss=2.435032,	
Rank[  0]Epoch[9] Batch [2600]	Speed: 27.50 samples/s ETA: 0 d  5 h 20 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.295 O: 1.856 M: 0.008	Train-MLMAcc=0.636383,	MVRCAccuracy=0.680451,	MLMLossWVC=1.736005,	MVRCLoss=2.435032,	
Rank[  3]Epoch[9] Batch [2600]	Speed: 27.50 samples/s ETA: 0 d  5 h 20 m	Data: 1.766 Tran: 0.008 F: 0.179 B: 0.297 O: 0.068 M: 0.008	Train-MLMAcc=0.636383,	MVRCAccuracy=0.680451,	MLMLossWVC=1.736005,	MVRCLoss=2.435032,	
Rank[  1]Epoch[9] Batch [2600]	Speed: 27.50 samples/s ETA: 0 d  5 h 20 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.300 O: 1.852 M: 0.007	Train-MLMAcc=0.636383,	MVRCAccuracy=0.680451,	MLMLossWVC=1.736005,	MVRCLoss=2.435032,	
Rank[  0]Epoch[9] Batch [2700]	Speed: 28.08 samples/s ETA: 0 d  5 h  9 m	Data: 0.010 Tran: 0.007 F: 0.151 B: 0.300 O: 1.801 M: 0.009	Train-MLMAcc=0.636349,	MVRCAccuracy=0.680488,	MLMLossWVC=1.736241,	MVRCLoss=2.435042,	
Rank[  1]Epoch[9] Batch [2700]	Speed: 28.08 samples/s ETA: 0 d  5 h  9 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.308 O: 1.791 M: 0.010	Train-MLMAcc=0.636349,	MVRCAccuracy=0.680488,	MLMLossWVC=1.736241,	MVRCLoss=2.435042,	
Rank[  2]Epoch[9] Batch [2700]	Speed: 28.08 samples/s ETA: 0 d  5 h  9 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.304 O: 1.797 M: 0.009	Train-MLMAcc=0.636349,	MVRCAccuracy=0.680488,	MLMLossWVC=1.736241,	MVRCLoss=2.435042,	
Rank[  3]Epoch[9] Batch [2700]	Speed: 28.08 samples/s ETA: 0 d  5 h  9 m	Data: 1.709 Tran: 0.008 F: 0.183 B: 0.307 O: 0.061 M: 0.009	Train-MLMAcc=0.636349,	MVRCAccuracy=0.680488,	MLMLossWVC=1.736241,	MVRCLoss=2.435042,	
Rank[  2]Epoch[9] Batch [2800]	Speed: 27.51 samples/s ETA: 0 d  5 h 12 m	Data: 0.062 Tran: 0.007 F: 0.152 B: 0.306 O: 1.785 M: 0.013	Train-MLMAcc=0.636454,	MVRCAccuracy=0.680499,	MLMLossWVC=1.735631,	MVRCLoss=2.434926,	
Rank[  0]Epoch[9] Batch [2800]	Speed: 27.51 samples/s ETA: 0 d  5 h 12 m	Data: 0.022 Tran: 0.007 F: 0.151 B: 0.303 O: 1.830 M: 0.011	Train-MLMAcc=0.636454,	MVRCAccuracy=0.680499,	MLMLossWVC=1.735631,	MVRCLoss=2.434926,	
Rank[  3]Epoch[9] Batch [2800]	Speed: 27.51 samples/s ETA: 0 d  5 h 12 m	Data: 1.576 Tran: 0.008 F: 0.171 B: 0.310 O: 0.248 M: 0.011	Train-MLMAcc=0.636454,	MVRCAccuracy=0.680499,	MLMLossWVC=1.735631,	MVRCLoss=2.434926,	
Rank[  1]Epoch[9] Batch [2800]	Speed: 27.51 samples/s ETA: 0 d  5 h 12 m	Data: 0.304 Tran: 0.007 F: 0.155 B: 0.311 O: 1.539 M: 0.009	Train-MLMAcc=0.636454,	MVRCAccuracy=0.680499,	MLMLossWVC=1.735631,	MVRCLoss=2.434926,	
Rank[  2]Epoch[9] Batch [2900]	Speed: 25.62 samples/s ETA: 0 d  5 h 31 m	Data: 0.214 Tran: 0.010 F: 0.162 B: 0.296 O: 1.804 M: 0.010	Train-MLMAcc=0.636476,	MVRCAccuracy=0.680517,	MLMLossWVC=1.735499,	MVRCLoss=2.434884,	
Rank[  3]Epoch[9] Batch [2900]	Speed: 25.62 samples/s ETA: 0 d  5 h 31 m	Data: 1.771 Tran: 0.012 F: 0.184 B: 0.311 O: 0.207 M: 0.011	Train-MLMAcc=0.636476,	MVRCAccuracy=0.680517,	MLMLossWVC=1.735499,	MVRCLoss=2.434884,	
Rank[  0]Epoch[9] Batch [2900]	Speed: 25.62 samples/s ETA: 0 d  5 h 31 m	Data: 0.097 Tran: 0.007 F: 0.152 B: 0.292 O: 1.938 M: 0.010	Train-MLMAcc=0.636476,	MVRCAccuracy=0.680517,	MLMLossWVC=1.735499,	MVRCLoss=2.434884,	
Rank[  1]Epoch[9] Batch [2900]	Speed: 25.62 samples/s ETA: 0 d  5 h 31 m	Data: 0.351 Tran: 0.007 F: 0.151 B: 0.301 O: 1.676 M: 0.010	Train-MLMAcc=0.636476,	MVRCAccuracy=0.680517,	MLMLossWVC=1.735499,	MVRCLoss=2.434884,	
Rank[  3]Epoch[9] Batch [3000]	Speed: 27.69 samples/s ETA: 0 d  5 h  2 m	Data: 1.753 Tran: 0.010 F: 0.174 B: 0.298 O: 0.066 M: 0.009	Train-MLMAcc=0.636596,	MVRCAccuracy=0.680559,	MLMLossWVC=1.734867,	MVRCLoss=2.434734,	
Rank[  1]Epoch[9] Batch [3000]	Speed: 27.69 samples/s ETA: 0 d  5 h  2 m	Data: 0.010 Tran: 0.007 F: 0.150 B: 0.298 O: 1.835 M: 0.008	Train-MLMAcc=0.636596,	MVRCAccuracy=0.680559,	MLMLossWVC=1.734867,	MVRCLoss=2.434734,	
Rank[  2]Epoch[9] Batch [3000]	Speed: 27.69 samples/s ETA: 0 d  5 h  2 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.844 M: 0.009	Train-MLMAcc=0.636596,	MVRCAccuracy=0.680559,	MLMLossWVC=1.734867,	MVRCLoss=2.434734,	
Rank[  0]Epoch[9] Batch [3000]	Speed: 27.69 samples/s ETA: 0 d  5 h  2 m	Data: 0.015 Tran: 0.007 F: 0.151 B: 0.292 O: 1.840 M: 0.005	Train-MLMAcc=0.636596,	MVRCAccuracy=0.680559,	MLMLossWVC=1.734867,	MVRCLoss=2.434734,	
Rank[  1]Epoch[9] Batch [3100]	Speed: 27.64 samples/s ETA: 0 d  4 h 59 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.847 M: 0.005	Train-MLMAcc=0.636714,	MVRCAccuracy=0.680535,	MLMLossWVC=1.734714,	MVRCLoss=2.434599,	
Rank[  2]Epoch[9] Batch [3100]	Speed: 27.64 samples/s ETA: 0 d  4 h 59 m	Data: 0.127 Tran: 0.009 F: 0.155 B: 0.291 O: 1.722 M: 0.009	Train-MLMAcc=0.636714,	MVRCAccuracy=0.680535,	MLMLossWVC=1.734714,	MVRCLoss=2.434599,	
Rank[  0]Epoch[9] Batch [3100]	Speed: 27.64 samples/s ETA: 0 d  4 h 59 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.847 M: 0.009	Train-MLMAcc=0.636714,	MVRCAccuracy=0.680535,	MLMLossWVC=1.734714,	MVRCLoss=2.434599,	
Rank[  3]Epoch[9] Batch [3100]	Speed: 27.64 samples/s ETA: 0 d  4 h 59 m	Data: 1.647 Tran: 0.008 F: 0.169 B: 0.296 O: 0.183 M: 0.009	Train-MLMAcc=0.636714,	MVRCAccuracy=0.680535,	MLMLossWVC=1.734714,	MVRCLoss=2.434599,	
Rank[  1]Epoch[9] Batch [3200]	Speed: 27.35 samples/s ETA: 0 d  4 h 58 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.865 M: 0.008	Train-MLMAcc=0.636703,	MVRCAccuracy=0.680576,	MLMLossWVC=1.734817,	MVRCLoss=2.434505,	
Rank[  0]Epoch[9] Batch [3200]	Speed: 27.35 samples/s ETA: 0 d  4 h 58 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.295 O: 1.866 M: 0.008	Train-MLMAcc=0.636703,	MVRCAccuracy=0.680576,	MLMLossWVC=1.734817,	MVRCLoss=2.434505,	
Rank[  2]Epoch[9] Batch [3200]	Speed: 27.35 samples/s ETA: 0 d  4 h 58 m	Data: 1.306 Tran: 0.008 F: 0.155 B: 0.309 O: 0.553 M: 0.007	Train-MLMAcc=0.636703,	MVRCAccuracy=0.680576,	MLMLossWVC=1.734817,	MVRCLoss=2.434505,	
Rank[  3]Epoch[9] Batch [3200]	Speed: 27.35 samples/s ETA: 0 d  4 h 58 m	Data: 0.500 Tran: 0.007 F: 0.154 B: 0.297 O: 1.371 M: 0.009	Train-MLMAcc=0.636703,	MVRCAccuracy=0.680576,	MLMLossWVC=1.734817,	MVRCLoss=2.434505,	
Rank[  2]Epoch[9] Batch [3300]	Speed: 27.36 samples/s ETA: 0 d  4 h 54 m	Data: 1.604 Tran: 0.010 F: 0.180 B: 0.299 O: 0.237 M: 0.008	Train-MLMAcc=0.636906,	MVRCAccuracy=0.680564,	MLMLossWVC=1.733482,	MVRCLoss=2.434530,	
Rank[  3]Epoch[9] Batch [3300]	Speed: 27.36 samples/s ETA: 0 d  4 h 54 m	Data: 0.184 Tran: 0.007 F: 0.150 B: 0.290 O: 1.696 M: 0.010	Train-MLMAcc=0.636906,	MVRCAccuracy=0.680564,	MLMLossWVC=1.733482,	MVRCLoss=2.434530,	
Rank[  1]Epoch[9] Batch [3300]	Speed: 27.36 samples/s ETA: 0 d  4 h 54 m	Data: 0.158 Tran: 0.007 F: 0.150 B: 0.298 O: 1.716 M: 0.009	Train-MLMAcc=0.636906,	MVRCAccuracy=0.680564,	MLMLossWVC=1.733482,	MVRCLoss=2.434530,	
Rank[  0]Epoch[9] Batch [3300]	Speed: 27.36 samples/s ETA: 0 d  4 h 54 m	Data: 0.430 Tran: 0.008 F: 0.166 B: 0.298 O: 1.426 M: 0.009	Train-MLMAcc=0.636906,	MVRCAccuracy=0.680564,	MLMLossWVC=1.733482,	MVRCLoss=2.434530,	
Rank[  3]Epoch[9] Batch [3400]	Speed: 27.61 samples/s ETA: 0 d  4 h 47 m	Data: 0.070 Tran: 0.007 F: 0.151 B: 0.295 O: 1.785 M: 0.008	Train-MLMAcc=0.636948,	MVRCAccuracy=0.680537,	MLMLossWVC=1.733414,	MVRCLoss=2.434438,	
Rank[  2]Epoch[9] Batch [3400]	Speed: 27.61 samples/s ETA: 0 d  4 h 47 m	Data: 1.194 Tran: 0.006 F: 0.165 B: 0.309 O: 0.633 M: 0.008	Train-MLMAcc=0.636948,	MVRCAccuracy=0.680537,	MLMLossWVC=1.733414,	MVRCLoss=2.434438,	
Rank[  1]Epoch[9] Batch [3400]	Speed: 27.61 samples/s ETA: 0 d  4 h 47 m	Data: 0.015 Tran: 0.007 F: 0.151 B: 0.303 O: 1.832 M: 0.009	Train-MLMAcc=0.636948,	MVRCAccuracy=0.680537,	MLMLossWVC=1.733414,	MVRCLoss=2.434438,	
Rank[  0]Epoch[9] Batch [3400]	Speed: 27.61 samples/s ETA: 0 d  4 h 47 m	Data: 1.213 Tran: 0.007 F: 0.159 B: 0.296 O: 0.632 M: 0.009	Train-MLMAcc=0.636948,	MVRCAccuracy=0.680537,	MLMLossWVC=1.733414,	MVRCLoss=2.434438,	
Rank[  0]Epoch[9] Batch [3500]	Speed: 27.64 samples/s ETA: 0 d  4 h 43 m	Data: 0.863 Tran: 0.007 F: 0.153 B: 0.294 O: 0.989 M: 0.008	Train-MLMAcc=0.636970,	MVRCAccuracy=0.680477,	MLMLossWVC=1.733195,	MVRCLoss=2.434271,	
Rank[  1]Epoch[9] Batch [3500]	Speed: 27.64 samples/s ETA: 0 d  4 h 43 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.844 M: 0.006	Train-MLMAcc=0.636970,	MVRCAccuracy=0.680477,	MLMLossWVC=1.733195,	MVRCLoss=2.434271,	
Rank[  2]Epoch[9] Batch [3500]	Speed: 27.64 samples/s ETA: 0 d  4 h 43 m	Data: 1.447 Tran: 0.008 F: 0.171 B: 0.303 O: 0.379 M: 0.007	Train-MLMAcc=0.636970,	MVRCAccuracy=0.680477,	MLMLossWVC=1.733195,	MVRCLoss=2.434271,	
Rank[  3]Epoch[9] Batch [3500]	Speed: 27.64 samples/s ETA: 0 d  4 h 43 m	Data: 0.082 Tran: 0.007 F: 0.150 B: 0.291 O: 1.776 M: 0.008	Train-MLMAcc=0.636970,	MVRCAccuracy=0.680477,	MLMLossWVC=1.733195,	MVRCLoss=2.434271,	
Rank[  2]Epoch[9] Batch [3600]	Speed: 27.13 samples/s ETA: 0 d  4 h 45 m	Data: 1.540 Tran: 0.008 F: 0.159 B: 0.294 O: 0.350 M: 0.007	Train-MLMAcc=0.636970,	MVRCAccuracy=0.680537,	MLMLossWVC=1.733691,	MVRCLoss=2.434113,	
Rank[  0]Epoch[9] Batch [3600]	Speed: 27.13 samples/s ETA: 0 d  4 h 45 m	Data: 0.978 Tran: 0.008 F: 0.183 B: 0.301 O: 0.881 M: 0.008	Train-MLMAcc=0.636970,	MVRCAccuracy=0.680537,	MLMLossWVC=1.733691,	MVRCLoss=2.434113,	
Rank[  3]Epoch[9] Batch [3600]	Speed: 27.13 samples/s ETA: 0 d  4 h 45 m	Data: 0.015 Tran: 0.007 F: 0.158 B: 0.299 O: 1.872 M: 0.007	Train-MLMAcc=0.636970,	MVRCAccuracy=0.680537,	MLMLossWVC=1.733691,	MVRCLoss=2.434113,	
Rank[  1]Epoch[9] Batch [3600]	Speed: 27.13 samples/s ETA: 0 d  4 h 45 m	Data: 0.008 Tran: 0.007 F: 0.161 B: 0.305 O: 1.871 M: 0.007	Train-MLMAcc=0.636970,	MVRCAccuracy=0.680537,	MLMLossWVC=1.733691,	MVRCLoss=2.434113,	
Rank[  2]Epoch[9] Batch [3700]	Speed: 27.48 samples/s ETA: 0 d  4 h 37 m	Data: 1.448 Tran: 0.007 F: 0.163 B: 0.300 O: 0.401 M: 0.008	Train-MLMAcc=0.637000,	MVRCAccuracy=0.680505,	MLMLossWVC=1.734029,	MVRCLoss=2.434036,	
Rank[  3]Epoch[9] Batch [3700]	Speed: 27.48 samples/s ETA: 0 d  4 h 37 m	Data: 0.010 Tran: 0.007 F: 0.151 B: 0.290 O: 1.862 M: 0.007	Train-MLMAcc=0.637000,	MVRCAccuracy=0.680505,	MLMLossWVC=1.734029,	MVRCLoss=2.434036,	
Rank[  1]Epoch[9] Batch [3700]	Speed: 27.48 samples/s ETA: 0 d  4 h 37 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.297 O: 1.854 M: 0.009	Train-MLMAcc=0.637000,	MVRCAccuracy=0.680505,	MLMLossWVC=1.734029,	MVRCLoss=2.434036,	
Rank[  0]Epoch[9] Batch [3700]	Speed: 27.48 samples/s ETA: 0 d  4 h 37 m	Data: 0.847 Tran: 0.007 F: 0.157 B: 0.294 O: 1.015 M: 0.008	Train-MLMAcc=0.637000,	MVRCAccuracy=0.680505,	MLMLossWVC=1.734029,	MVRCLoss=2.434036,	
Rank[  3]Epoch[9] Batch [3800]	Speed: 27.37 samples/s ETA: 0 d  4 h 34 m	Data: 0.010 Tran: 0.007 F: 0.153 B: 0.295 O: 1.860 M: 0.010	Train-MLMAcc=0.636967,	MVRCAccuracy=0.680505,	MLMLossWVC=1.734191,	MVRCLoss=2.434049,	
Rank[  0]Epoch[9] Batch [3800]	Speed: 27.37 samples/s ETA: 0 d  4 h 34 m	Data: 0.293 Tran: 0.007 F: 0.157 B: 0.297 O: 1.573 M: 0.009	Train-MLMAcc=0.636967,	MVRCAccuracy=0.680505,	MLMLossWVC=1.734191,	MVRCLoss=2.434049,	
Rank[  2]Epoch[9] Batch [3800]	Speed: 27.37 samples/s ETA: 0 d  4 h 34 m	Data: 1.717 Tran: 0.007 F: 0.171 B: 0.305 O: 0.126 M: 0.010	Train-MLMAcc=0.636967,	MVRCAccuracy=0.680505,	MLMLossWVC=1.734191,	MVRCLoss=2.434049,	
Rank[  1]Epoch[9] Batch [3800]	Speed: 27.37 samples/s ETA: 0 d  4 h 34 m	Data: 0.009 Tran: 0.007 F: 0.155 B: 0.301 O: 1.855 M: 0.009	Train-MLMAcc=0.636967,	MVRCAccuracy=0.680505,	MLMLossWVC=1.734191,	MVRCLoss=2.434049,	
Rank[  0]Epoch[9] Batch [3900]	Speed: 27.52 samples/s ETA: 0 d  4 h 29 m	Data: 0.063 Tran: 0.007 F: 0.160 B: 0.293 O: 1.791 M: 0.010	Train-MLMAcc=0.637004,	MVRCAccuracy=0.680503,	MLMLossWVC=1.734131,	MVRCLoss=2.434107,	
Rank[  1]Epoch[9] Batch [3900]	Speed: 27.52 samples/s ETA: 0 d  4 h 29 m	Data: 0.008 Tran: 0.007 F: 0.159 B: 0.299 O: 1.842 M: 0.009	Train-MLMAcc=0.637004,	MVRCAccuracy=0.680503,	MLMLossWVC=1.734131,	MVRCLoss=2.434107,	
Rank[  2]Epoch[9] Batch [3900]	Speed: 27.52 samples/s ETA: 0 d  4 h 29 m	Data: 1.740 Tran: 0.007 F: 0.157 B: 0.302 O: 0.107 M: 0.011	Train-MLMAcc=0.637004,	MVRCAccuracy=0.680503,	MLMLossWVC=1.734131,	MVRCLoss=2.434107,	
Rank[  3]Epoch[9] Batch [3900]	Speed: 27.52 samples/s ETA: 0 d  4 h 29 m	Data: 0.008 Tran: 0.007 F: 0.159 B: 0.292 O: 1.848 M: 0.010	Train-MLMAcc=0.637004,	MVRCAccuracy=0.680503,	MLMLossWVC=1.734131,	MVRCLoss=2.434107,	
Rank[  1]Epoch[9] Batch [4000]	Speed: 25.38 samples/s ETA: 0 d  4 h 47 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.301 O: 2.045 M: 0.008	Train-MLMAcc=0.637048,	MVRCAccuracy=0.680548,	MLMLossWVC=1.733835,	MVRCLoss=2.434078,	
Rank[  3]Epoch[9] Batch [4000]	Speed: 25.38 samples/s ETA: 0 d  4 h 47 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.292 O: 2.055 M: 0.008	Train-MLMAcc=0.637048,	MVRCAccuracy=0.680548,	MLMLossWVC=1.733835,	MVRCLoss=2.434078,	
Rank[  2]Epoch[9] Batch [4000]	Speed: 25.38 samples/s ETA: 0 d  4 h 47 m	Data: 1.660 Tran: 0.014 F: 0.175 B: 0.308 O: 0.356 M: 0.009	Train-MLMAcc=0.637048,	MVRCAccuracy=0.680548,	MLMLossWVC=1.733835,	MVRCLoss=2.434078,	
Rank[  0]Epoch[9] Batch [4000]	Speed: 25.38 samples/s ETA: 0 d  4 h 47 m	Data: 0.679 Tran: 0.007 F: 0.152 B: 0.296 O: 1.379 M: 0.008	Train-MLMAcc=0.637048,	MVRCAccuracy=0.680548,	MLMLossWVC=1.733835,	MVRCLoss=2.434078,	
Rank[  3]Epoch[9] Batch [4100]	Speed: 27.66 samples/s ETA: 0 d  4 h 20 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.291 O: 1.849 M: 0.006	Train-MLMAcc=0.636952,	MVRCAccuracy=0.680574,	MLMLossWVC=1.734545,	MVRCLoss=2.434101,	
Rank[  1]Epoch[9] Batch [4100]	Speed: 27.66 samples/s ETA: 0 d  4 h 20 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.300 O: 1.839 M: 0.007	Train-MLMAcc=0.636952,	MVRCAccuracy=0.680574,	MLMLossWVC=1.734545,	MVRCLoss=2.434101,	
Rank[  0]Epoch[9] Batch [4100]	Speed: 27.66 samples/s ETA: 0 d  4 h 20 m	Data: 1.278 Tran: 0.009 F: 0.172 B: 0.298 O: 0.550 M: 0.006	Train-MLMAcc=0.636952,	MVRCAccuracy=0.680574,	MLMLossWVC=1.734545,	MVRCLoss=2.434101,	
Rank[  2]Epoch[9] Batch [4100]	Speed: 27.66 samples/s ETA: 0 d  4 h 20 m	Data: 0.533 Tran: 0.007 F: 0.151 B: 0.295 O: 1.321 M: 0.006	Train-MLMAcc=0.636952,	MVRCAccuracy=0.680574,	MLMLossWVC=1.734545,	MVRCLoss=2.434101,	
