Namespace(cfg='cfgs/pretrain/base_prec_withouttextonly_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/', slurm=False)
Namespace(cfg='cfgs/pretrain/base_prec_withouttextonly_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/', slurm=False)
Namespace(cfg='cfgs/pretrain/base_prec_withouttextonly_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/', slurm=False)
Namespace(cfg='cfgs/pretrain/base_prec_withouttextonly_4x16G_fp32.yaml', cudnn_off=False, dist=True, do_test=False, log_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/tensorboard_logs', model_dir='/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/', slurm=False)
{'CHECKPOINT_FREQUENT': 1,
 {'CHECKPOINT_FREQUENT': 1,
 {'CHECKPOINT_FREQUENT': 1,
 {'CHECKPOINT_FREQUENT': 1,
 'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'ANSWER_VOCAB_FILE': '',
             'ANSWER_VOCAB_SIZE': 3129,
             'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'APPEND_INDEX': False,
             'BASIC_ALIGN': False,
             'ANSWER_VOCAB_FILE': '',
             'CACHE_MODE': False,
             'ANSWER_VOCAB_SIZE': 3129,
             'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'DATASET': 'conceptual_captions',
             'APPEND_INDEX': False,
             'ANSWER_VOCAB_FILE': '',
             'BASIC_ALIGN': False,
             'ANSWER_VOCAB_SIZE': 3129,
             'CACHE_MODE': False,
             'APPEND_INDEX': False,
             'DATASET': 'conceptual_captions',
             'BASIC_ALIGN': False,
             'CACHE_MODE': False,
             'DATASET': 'conceptual_captions',
             'DATASET': {'ADD_IMAGE_AS_A_BOX': True,
             'ANSWER_VOCAB_FILE': '',
             'ANSWER_VOCAB_SIZE': 3129,
             'APPEND_INDEX': False,
             'BASIC_ALIGN': False,
             'CACHE_MODE': False,
             'DATASET': 'conceptual_captions',
             'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/conceptual_captions/vl-bert/',
             'IGNORE_DB_CACHE': False,
             'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/conceptual_captions/vl-bert/',
             'LABEL_INDEX_IN_BATCH': -1,
             'MASK_SIZE': 14,
             'IGNORE_DB_CACHE': False,
             'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/conceptual_captions/vl-bert/',
             'MIN_SEQ_LEN': 0,
             'LABEL_INDEX_IN_BATCH': -1,
             'ONLY_USE_RELEVANT_DETS': True,
             'MASK_SIZE': 14,
             'IGNORE_DB_CACHE': False,
             'QA2R_AUG': False,
             'MIN_SEQ_LEN': 0,
             'LABEL_INDEX_IN_BATCH': -1,
             'QA2R_NOQ': False,
             'ONLY_USE_RELEVANT_DETS': True,
             'MASK_SIZE': 14,
             'ROOT_PATH': './',
             'QA2R_AUG': False,
             'MIN_SEQ_LEN': 0,
             'SEQ_LEN': 64,
             'QA2R_NOQ': False,
             'ONLY_USE_RELEVANT_DETS': True,
             'TASK': 'Q2AR',
             'ROOT_PATH': './',
             'QA2R_AUG': False,
             'TEST_ANNOTATION_FILE': '',
             'SEQ_LEN': 64,
             'QA2R_NOQ': False,
             'DATASET_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/data/conceptual_captions/vl-bert/',
             'TEST_IMAGE_SET': 'val',
             'TASK': 'Q2AR',
             'ROOT_PATH': './',
             'TRAIN_ANNOTATION_FILE': '',
             'TEST_ANNOTATION_FILE': '',
             'IGNORE_DB_CACHE': False,
             'SEQ_LEN': 64,
             'TRAIN_IMAGE_SET': 'train',
             'TEST_IMAGE_SET': 'val',
             'LABEL_INDEX_IN_BATCH': -1,
             'TASK': 'Q2AR',
             'VAL_ANNOTATION_FILE': '',
             'TRAIN_ANNOTATION_FILE': '',
             'MASK_SIZE': 14,
             'TEST_ANNOTATION_FILE': '',
             'VAL_IMAGE_SET': 'val',
             'TRAIN_IMAGE_SET': 'train',
             'MIN_SEQ_LEN': 0,
             'TEST_IMAGE_SET': 'val',
             'VAL_ANNOTATION_FILE': '',
             'ZIP_MODE': False},
 'ONLY_USE_RELEVANT_DETS': True,
             'TRAIN_ANNOTATION_FILE': '',
             'VAL_IMAGE_SET': 'val',
             'GPUS': '0,1,2,3',
 'QA2R_AUG': False,
             'TRAIN_IMAGE_SET': 'train',
             'LOG_FREQUENT': 100,
 'ZIP_MODE': False},
 'QA2R_NOQ': False,
             'VAL_ANNOTATION_FILE': '',
             'MODEL_PREFIX': 'vl-bert_base_res101_pretrain',
 'GPUS': '0,1,2,3',
 'ROOT_PATH': './',
             'VAL_IMAGE_SET': 'val',
             'MODULE': 'ResNetVLBERTForPretraining',
 'LOG_FREQUENT': 100,
 'SEQ_LEN': 64,
             'ZIP_MODE': False},
 'MODEL_PREFIX': 'vl-bert_base_res101_pretrain',
 'TASK': 'Q2AR',
             'GPUS': '0,1,2,3',
 'MODULE': 'ResNetVLBERTForPretraining',
 'TEST_ANNOTATION_FILE': '',
             'LOG_FREQUENT': 100,
 'TEST_IMAGE_SET': 'val',
             'MODEL_PREFIX': 'vl-bert_base_res101_pretrain',
 'TRAIN_ANNOTATION_FILE': '',
             'MODULE': 'ResNetVLBERTForPretraining',
 'TRAIN_IMAGE_SET': 'train',
             'VAL_ANNOTATION_FILE': '',
             'VAL_IMAGE_SET': 'val',
             'ZIP_MODE': False},
 'GPUS': '0,1,2,3',
 'LOG_FREQUENT': 100,
 'MODEL_PREFIX': 'vl-bert_base_res101_pretrain',
 'MODULE': 'ResNetVLBERTForPretraining',
 'NETWORK': {'ANS_LOSS_WEIGHT': 1.0,
             'BERT_ALIGN_ANSWER': True,
             'BERT_ALIGN_QUESTION': True,
             'BERT_FROZEN': False,
             'NETWORK': {'ANS_LOSS_WEIGHT': 1.0,
             'NETWORK': {'ANS_LOSS_WEIGHT': 1.0,
             'BERT_ALIGN_ANSWER': True,
             'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'BERT_ALIGN_QUESTION': True,
             'BERT_ALIGN_ANSWER': True,
             'BERT_PRETRAINED': '',
             'BERT_FROZEN': False,
             'BERT_ALIGN_QUESTION': True,
             'BERT_PRETRAINED_EPOCH': 0,
             'BERT_FROZEN': False,
             'BERT_USE_LAYER': -2,
             'BERT_WITH_MLM_LOSS': False,
             'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'BERT_WITH_NSP_LOSS': False,
             'BERT_PRETRAINED': '',
             'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'BLIND': False,
             'BERT_PRETRAINED_EPOCH': 0,
             'BERT_PRETRAINED': '',
             'CLASSIFIER_DROPOUT': 0.1,
             'NETWORK': {'ANS_LOSS_WEIGHT': 1.0,
             'BERT_USE_LAYER': -2,
             'BERT_PRETRAINED_EPOCH': 0,
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'BERT_WITH_MLM_LOSS': False,
             'BERT_ALIGN_ANSWER': True,
             'BERT_USE_LAYER': -2,
             'CLASSIFIER_SIGMOID': False,
             'BERT_WITH_NSP_LOSS': False,
             'BERT_ALIGN_QUESTION': True,
             'BERT_WITH_MLM_LOSS': False,
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'BLIND': False,
             'BERT_FROZEN': False,
             'BERT_WITH_NSP_LOSS': False,
             'CLASSIFIER_TYPE': '2fc',
             'CLASSIFIER_DROPOUT': 0.1,
             'BLIND': False,
             'CNN_LOSS_WEIGHT': 1.0,
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'CLASSIFIER_DROPOUT': 0.1,
             'ENABLE_CNN_REG_LOSS': False,
             'CLASSIFIER_SIGMOID': False,
             'BERT_MODEL_NAME': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/pretrained_models/bert-base-uncased',
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'BERT_PRETRAINED': '',
             'CLASSIFIER_SIGMOID': False,
             'IMAGE_C5_DILATED': True,
             'CLASSIFIER_TYPE': '2fc',
             'BERT_PRETRAINED_EPOCH': 0,
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'CNN_LOSS_WEIGHT': 1.0,
             'BERT_USE_LAYER': -2,
             'CLASSIFIER_TYPE': '2fc',
             'IMAGE_FINAL_DIM': 768,
             'ENABLE_CNN_REG_LOSS': False,
             'BERT_WITH_MLM_LOSS': False,
             'CNN_LOSS_WEIGHT': 1.0,
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'BERT_WITH_NSP_LOSS': False,
             'ENABLE_CNN_REG_LOSS': False,
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'IMAGE_C5_DILATED': True,
             'BLIND': False,
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'IMAGE_FROZEN_BN': True,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'CLASSIFIER_DROPOUT': 0.1,
             'IMAGE_C5_DILATED': True,
             'IMAGE_NUM_LAYERS': 101,
             'IMAGE_FINAL_DIM': 768,
             'CLASSIFIER_HIDDEN_SIZE': 1024,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'IMAGE_PRETRAINED': '',
             'CLASSIFIER_SIGMOID': False,
             'IMAGE_FINAL_DIM': 768,
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'IMAGE_PRETRAINED_EPOCH': 0,
             'CLASSIFIER_SIGMOID_LOSS_POSITIVE_WEIGHT': 1.0,
             'IMAGE_FROZEN_BN': True,
             'IMAGE_SEMANTIC': False,
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'CLASSIFIER_TYPE': '2fc',
             'IMAGE_NUM_LAYERS': 101,
             'IMAGE_STRIDE_IN_1x1': True,
             'IMAGE_FROZEN_BN': True,
             'CNN_LOSS_WEIGHT': 1.0,
             'IMAGE_PRETRAINED': '',
             'MASK_RAW_PIXELS': True,
             'IMAGE_NUM_LAYERS': 101,
             'ENABLE_CNN_REG_LOSS': False,
             'IMAGE_PRETRAINED_EPOCH': 0,
             'MLM_LOSS_NORM_IN_BATCH_FIRST': False,
             'IMAGE_PRETRAINED': '',
             'FOR_MASK_VL_MODELING_PRETRAIN': False,
             'IMAGE_SEMANTIC': False,
             'MVRC_LOSS_NORM_IN_BATCH_FIRST': False,
             'IMAGE_PRETRAINED_EPOCH': 0,
             'IMAGE_C5_DILATED': True,
             'IMAGE_STRIDE_IN_1x1': True,
             'NO_GROUNDING': False,
             'IMAGE_SEMANTIC': False,
             'IMAGE_FEAT_PRECOMPUTED': True,
             'MASK_RAW_PIXELS': True,
             'NO_OBJ_ATTENTION': False,
             'IMAGE_STRIDE_IN_1x1': True,
             'IMAGE_FINAL_DIM': 768,
             'MLM_LOSS_NORM_IN_BATCH_FIRST': False,
             'OUTPUT_CONV5': False,
             'MASK_RAW_PIXELS': True,
             'MVRC_LOSS_NORM_IN_BATCH_FIRST': False,
             'PARTIAL_PRETRAIN': '',
             'IMAGE_FROZEN_BACKBONE_STAGES': [1, 2],
             'MLM_LOSS_NORM_IN_BATCH_FIRST': False,
             'NO_GROUNDING': False,
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': [],
             'IMAGE_FROZEN_BN': True,
             'MVRC_LOSS_NORM_IN_BATCH_FIRST': False,
             'NO_OBJ_ATTENTION': False,
             'IMAGE_NUM_LAYERS': 101,
             'NO_GROUNDING': False,
             'OUTPUT_CONV5': False,
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'IMAGE_PRETRAINED': '',
             'NO_OBJ_ATTENTION': False,
             'PARTIAL_PRETRAIN': '',
             'IMAGE_PRETRAINED_EPOCH': 0,
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'OUTPUT_CONV5': False,
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': [],
             'IMAGE_SEMANTIC': False,
             'PARTIAL_PRETRAIN': '',
             'IMAGE_STRIDE_IN_1x1': True,
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': [],
             'MASK_RAW_PIXELS': True,
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'MLM_LOSS_NORM_IN_BATCH_FIRST': False,
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'MVRC_LOSS_NORM_IN_BATCH_FIRST': False,
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'NO_GROUNDING': False,
             'NO_OBJ_ATTENTION': False,
             'OUTPUT_CONV5': False,
             'PARTIAL_PRETRAIN': '',
             'PARTIAL_PRETRAIN_PREFIX_CHANGES': [],
             'PIXEL_MEANS': [102.9801, 115.9465, 122.7717],
             'PIXEL_STDS': [1.0, 1.0, 1.0],
             'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'from_scratch': False,
                        'hidden_act': 'gelu',
                        'hidden_dropout_prob': 0.1,
                        'hidden_size': 768,
                        'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'initializer_range': 0.02,
                        'from_scratch': False,
                        'input_size': 1280,
                        'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'hidden_act': 'gelu',
                        'input_transform_type': 1,
                        'from_scratch': False,
                        'hidden_dropout_prob': 0.1,
                        'intermediate_size': 3072,
                        'hidden_act': 'gelu',
                        'hidden_size': 768,
                        'max_position_embeddings': 512,
                        'hidden_dropout_prob': 0.1,
                        'initializer_range': 0.02,
                        'num_attention_heads': 12,
                        'hidden_size': 768,
                        'input_size': 1280,
                        'num_hidden_layers': 12,
                        'initializer_range': 0.02,
                        'input_transform_type': 1,
                        'obj_pos_id_relative': True,
                        'input_size': 1280,
                        'intermediate_size': 3072,
                        'object_word_embed_mode': 2,
                        'input_transform_type': 1,
                        'VLBERT': {'attention_probs_dropout_prob': 0.1,
                        'max_position_embeddings': 512,
                        'pos_embedding_frozen': False,
                        'intermediate_size': 3072,
                        'from_scratch': False,
                        'position_padding_idx': -1,
                        'num_attention_heads': 12,
                        'max_position_embeddings': 512,
                        'hidden_act': 'gelu',
                        'type_vocab_size': 3,
                        'num_hidden_layers': 12,
                        'num_attention_heads': 12,
                        'hidden_dropout_prob': 0.1,
                        'visual_ln': True,
                        'obj_pos_id_relative': True,
                        'num_hidden_layers': 12,
                        'hidden_size': 768,
                        'visual_region_classes': 1601,
                        'object_word_embed_mode': 2,
                        'obj_pos_id_relative': True,
                        'initializer_range': 0.02,
                        'visual_scale_object_init': 0.0,
                        'pos_embedding_frozen': False,
                        'object_word_embed_mode': 2,
                        'input_size': 1280,
                        'visual_scale_text_init': 0.0,
                        'position_padding_idx': -1,
                        'pos_embedding_frozen': False,
                        'input_transform_type': 1,
                        'visual_size': 768,
                        'type_vocab_size': 3,
                        'position_padding_idx': -1,
                        'intermediate_size': 3072,
                        'vocab_size': 30522,
                        'visual_ln': True,
                        'type_vocab_size': 3,
                        'max_position_embeddings': 512,
                        'with_pooler': False,
                        'visual_region_classes': 1601,
                        'visual_ln': True,
                        'num_attention_heads': 12,
                        'visual_scale_object_init': 0.0,
                        'word_embedding_frozen': False},
             'visual_region_classes': 1601,
                        'num_hidden_layers': 12,
                        'visual_scale_text_init': 0.0,
                        'WITH_MLM_LOSS': True,
             'visual_scale_object_init': 0.0,
                        'obj_pos_id_relative': True,
                        'visual_size': 768,
                        'WITH_MVRC_LOSS': True,
             'visual_scale_text_init': 0.0,
                        'object_word_embed_mode': 2,
                        'vocab_size': 30522,
                        'visual_size': 768,
                        'WITH_REL_LOSS': False},
 'pos_embedding_frozen': False,
                        'with_pooler': False,
                        'vocab_size': 30522,
                        'NUM_WORKERS_PER_GPU': 4,
 'position_padding_idx': -1,
                        'with_pooler': False,
                        'word_embedding_frozen': False},
             'type_vocab_size': 3,
                        'WITH_MLM_LOSS': True,
             'word_embedding_frozen': False},
             'visual_ln': True,
                        'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert',
 'WITH_MVRC_LOSS': True,
             'WITH_MLM_LOSS': True,
             'visual_region_classes': 1601,
                        'RNG_SEED': 12345,
 'WITH_MVRC_LOSS': True,
             'WITH_REL_LOSS': False},
 'visual_scale_object_init': 0.0,
                        'NUM_WORKERS_PER_GPU': 4,
 'WITH_REL_LOSS': False},
 'visual_scale_text_init': 0.0,
                        'SCALES': [600, 1000],
 'NUM_WORKERS_PER_GPU': 4,
 'visual_size': 768,
                        'vocab_size': 30522,
                        'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert',
 'with_pooler': False,
                        'RNG_SEED': 12345,
 'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert',
 'word_embedding_frozen': False},
             'RNG_SEED': 12345,
 'SCALES': [600, 1000],
 'WITH_MLM_LOSS': True,
             'TEST': {'BATCH_IMAGES': 64,
          'WITH_MVRC_LOSS': True,
             'SCALES': [600, 1000],
 'FLIP_PROB': 0,
          'WITH_REL_LOSS': False},
 'SHUFFLE': False,
          'NUM_WORKERS_PER_GPU': 4,
 'TEST_EPOCH': 0},
 'TEST': {'BATCH_IMAGES': 64,
          'OUTPUT_PATH': '/gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert',
 'FLIP_PROB': 0,
          'TEST': {'BATCH_IMAGES': 64,
          'RNG_SEED': 12345,
 'SHUFFLE': False,
          'FLIP_PROB': 0,
          'SHUFFLE': False,
          'TEST_EPOCH': 0},
 'SCALES': [600, 1000],
 'TEST_EPOCH': 0},
 'TEST': {'BATCH_IMAGES': 64,
          'FLIP_PROB': 0,
          'SHUFFLE': False,
          'TEST_EPOCH': 0},
 'TRAIN': {'ASPECT_GROUPING': False,
           'AUTO_RESUME': True,
           'BATCH_IMAGES': 64,
           'BEGIN_EPOCH': 0,
           'CLIP_GRAD_NORM': 10,
           'END_EPOCH': 10,
           'TRAIN': {'ASPECT_GROUPING': False,
           'FLIP_PROB': 0.5,
           'TRAIN': {'ASPECT_GROUPING': False,
           'AUTO_RESUME': True,
           'FP16': False,
           'AUTO_RESUME': True,
           'BATCH_IMAGES': 64,
           'FP16_LOSS_SCALE': 128.0,
           'BATCH_IMAGES': 64,
           'BEGIN_EPOCH': 0,
           'GRAD_ACCUMULATE_STEPS': 1,
           'BEGIN_EPOCH': 0,
           'CLIP_GRAD_NORM': 10,
           'CLIP_GRAD_NORM': 10,
           'END_EPOCH': 10,
           'END_EPOCH': 10,
           'FLIP_PROB': 0.5,
           'FLIP_PROB': 0.5,
           'FP16': False,
           'LOSS_LOGGERS': [('mlm_loss', 'MLMLossWVC'),
                            'FP16': False,
           'FP16_LOSS_SCALE': 128.0,
           'TRAIN': {'ASPECT_GROUPING': False,
           'FP16_LOSS_SCALE': 128.0,
           ('mvrc_loss', 'MVRCLoss')],
           'GRAD_ACCUMULATE_STEPS': 1,
           'AUTO_RESUME': True,
           'GRAD_ACCUMULATE_STEPS': 1,
           'LR': 1e-07,
           'BATCH_IMAGES': 64,
           'LR_FACTOR': 0.1,
           'BEGIN_EPOCH': 0,
           'LR_MULT': [],
           'CLIP_GRAD_NORM': 10,
           'LR_SCHEDULE': 'triangle',
           'LOSS_LOGGERS': [('mlm_loss', 'MLMLossWVC'),
                            'END_EPOCH': 10,
           'LOSS_LOGGERS': [('mlm_loss', 'MLMLossWVC'),
                            'LR_STEP': [],
           'FLIP_PROB': 0.5,
           ('mvrc_loss', 'MVRCLoss')],
           'MOMENTUM': 0.9,
           ('mvrc_loss', 'MVRCLoss')],
           'FP16': False,
           'OPTIMIZER': 'AdamW',
           'LR': 1e-07,
           'LR': 1e-07,
           'FP16_LOSS_SCALE': 128.0,
           'RESUME': False,
           'LR_FACTOR': 0.1,
           'LR_FACTOR': 0.1,
           'GRAD_ACCUMULATE_STEPS': 1,
           'SHUFFLE': True,
           'LR_MULT': [],
           'LR_MULT': [],
           'WARMUP': True,
           'LR_SCHEDULE': 'triangle',
           'LR_SCHEDULE': 'triangle',
           'WARMUP_FACTOR': 0.0,
           'LR_STEP': [],
           'LR_STEP': [],
           'WARMUP_METHOD': 'linear',
           'MOMENTUM': 0.9,
           'MOMENTUM': 0.9,
           'WARMUP_STEPS': 8000,
           'OPTIMIZER': 'AdamW',
           'LOSS_LOGGERS': [('mlm_loss', 'MLMLossWVC'),
                            'OPTIMIZER': 'AdamW',
           'WD': 0.0001},
 'RESUME': False,
           'RESUME': False,
           ('mvrc_loss', 'MVRCLoss')],
           'SHUFFLE': True,
           'SHUFFLE': True,
           'LR': 1e-07,
           'WARMUP': True,
           'WARMUP': True,
           'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'WARMUP_FACTOR': 0.0,
           'LR_FACTOR': 0.1,
           'WARMUP_FACTOR': 0.0,
           'WARMUP_METHOD': 'linear',
           'VAL_FREQUENT': 1}
'LR_MULT': [],
           'WARMUP_METHOD': 'linear',
           'WARMUP_STEPS': 8000,
           'LR_SCHEDULE': 'triangle',
           'WARMUP_STEPS': 8000,
           'WD': 0.0001},
 'LR_STEP': [],
           'WD': 0.0001},
 'MOMENTUM': 0.9,
           'OPTIMIZER': 'AdamW',
           'RESUME': False,
           'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'SHUFFLE': True,
           'VAL_FREQUENT': 1}
'WARMUP': True,
           'VAL_FREQUENT': 1}
'WARMUP_FACTOR': 0.0,
           'WARMUP_METHOD': 'linear',
           'WARMUP_STEPS': 8000,
           'WD': 0.0001},
 'VAL': {'BATCH_IMAGES': 64, 'FLIP_PROB': 0, 'SHUFFLE': False},
 'VAL_FREQUENT': 1}
Warnings: Unexpected keys: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
Warnings: Unexpected keys: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
Warnings: Unexpected keys: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
Warnings: Unexpected keys: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias'].
native distributed, size: 4, rank: 2, local rank: 2
native distributed, size: 4, rank: 3, local rank: 3
native distributed, size: 4, rank: 1, local rank: 1
native distributed, size: 4, rank: 0, local rank: 0
>> Trainable Parameters:
---------------------------------------------------------------------------------------------------------------
|Name                                                         |Dtype            |Shape           |#Params     |
---------------------------------------------------------------------------------------------------------------
|image_feature_extractor.obj_downsample.1.weight              |torch.float32    |(768, 4096)     |3145728     |
---------------------------------------------------------------------------------------------------------------
|image_feature_extractor.obj_downsample.1.bias                |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|object_linguistic_embeddings.weight                          |torch.float32    |(1, 768)        |768         |
---------------------------------------------------------------------------------------------------------------
|object_mask_visual_embedding.weight                          |torch.float32    |(1, 2048)       |2048        |
---------------------------------------------------------------------------------------------------------------
|object_mask_word_embedding.weight                            |torch.float32    |(1, 768)        |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.word_embeddings.weight                                |torch.float32    |(30522, 768)    |23440896    |
---------------------------------------------------------------------------------------------------------------
|vlbert.end_embedding.weight                                  |torch.float32    |(1, 768)        |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.position_embeddings.weight                            |torch.float32    |(512, 768)      |393216      |
---------------------------------------------------------------------------------------------------------------
|vlbert.token_type_embeddings.weight                          |torch.float32    |(3, 768)        |2304        |
---------------------------------------------------------------------------------------------------------------
|vlbert.embedding_LayerNorm.weight                            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.embedding_LayerNorm.bias                              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_text.weight                                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_text.bias                                   |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_object.weight                               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.visual_ln_object.bias                                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.0.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.1.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.2.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.3.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.4.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.5.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.6.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.7.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.8.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.query.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.query.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.key.weight             |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.key.bias               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.value.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.self.value.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.dense.weight         |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.dense.bias           |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.LayerNorm.weight     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.attention.output.LayerNorm.bias       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.intermediate.dense.weight             |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.intermediate.dense.bias               |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.dense.weight                   |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.dense.bias                     |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.LayerNorm.weight               |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.9.output.LayerNorm.bias                 |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.query.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.query.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.key.weight            |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.key.bias              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.value.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.self.value.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.dense.weight        |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.dense.bias          |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.LayerNorm.weight    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.attention.output.LayerNorm.bias      |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.intermediate.dense.weight            |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.intermediate.dense.bias              |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.dense.bias                    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.LayerNorm.weight              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.10.output.LayerNorm.bias                |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.query.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.query.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.key.weight            |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.key.bias              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.value.weight          |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.self.value.bias            |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.dense.weight        |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.dense.bias          |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.LayerNorm.weight    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.attention.output.LayerNorm.bias      |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.intermediate.dense.weight            |torch.float32    |(3072, 768)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.intermediate.dense.bias              |torch.float32    |(3072,)         |3072        |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.dense.weight                  |torch.float32    |(768, 3072)     |2359296     |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.dense.bias                    |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.LayerNorm.weight              |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.encoder.layer.11.output.LayerNorm.bias                |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.mlm_head.predictions.bias                             |torch.float32    |(30522,)        |30522       |
---------------------------------------------------------------------------------------------------------------
|vlbert.mlm_head.predictions.transform.dense.weight           |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.mlm_head.predictions.transform.dense.bias             |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.mlm_head.predictions.transform.LayerNorm.weight       |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.mlm_head.predictions.transform.LayerNorm.bias         |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.mvrc_head.transform.dense.weight                      |torch.float32    |(768, 768)      |589824      |
---------------------------------------------------------------------------------------------------------------
|vlbert.mvrc_head.transform.dense.bias                        |torch.float32    |(768,)          |768         |
---------------------------------------------------------------------------------------------------------------
|vlbert.mvrc_head.region_cls_pred.weight                      |torch.float32    |(1601, 768)     |1229568     |
---------------------------------------------------------------------------------------------------------------
|vlbert.mvrc_head.region_cls_pred.bias                        |torch.float32    |(1601,)         |1601        |
---------------------------------------------------------------------------------------------------------------
>> # TrainableParams:       	114.49	M
>> # NonTrainableParams:    	0.00	M
>> # TotalParams:           	114.49	M
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
mask_raw_pixels:  True
Best Val MLMAcc: 0.5815196633338928, Epoch: 2
Auto continue training from /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-0002.model
PROGRESS: 30.00%
PROGRESS: 30.00%
PROGRESS: 30.00%
PROGRESS: 30.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Rank[  2]Epoch[3] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.621749,	MVRCAccuracy=0.638528,	MLMLossWVC=1.825388,	MVRCLoss=2.595793,	
Rank[  0]Epoch[3] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.621749,	MVRCAccuracy=0.638528,	MLMLossWVC=1.825388,	MVRCLoss=2.595793,	
Rank[  3]Epoch[3] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.621749,	MVRCAccuracy=0.638528,	MLMLossWVC=1.825388,	MVRCLoss=2.595793,	
Rank[  1]Epoch[3] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.621749,	MVRCAccuracy=0.638528,	MLMLossWVC=1.825388,	MVRCLoss=2.595793,	
Rank[  0]Epoch[3] Batch [100]	Speed: 27.49 samples/s ETA: 2 d  1 h  3 m	Data: 2.169 Tran: 0.007 F: 0.154 B: 0.296 O: 0.111 M: 0.011	Train-MLMAcc=0.602319,	MVRCAccuracy=0.646338,	MLMLossWVC=1.953626,	MVRCLoss=2.508663,	
Rank[  3]Epoch[3] Batch [100]	Speed: 27.49 samples/s ETA: 2 d  1 h  3 m	Data: 1.994 Tran: 0.007 F: 0.156 B: 0.300 O: 0.281 M: 0.009	Train-MLMAcc=0.602319,	MVRCAccuracy=0.646338,	MLMLossWVC=1.953626,	MVRCLoss=2.508663,	
Rank[  2]Epoch[3] Batch [100]	Speed: 27.49 samples/s ETA: 2 d  1 h  3 m	Data: 1.584 Tran: 0.007 F: 0.158 B: 0.296 O: 0.694 M: 0.010	Train-MLMAcc=0.602319,	MVRCAccuracy=0.646338,	MLMLossWVC=1.953626,	MVRCLoss=2.508663,	
Rank[  1]Epoch[3] Batch [100]	Speed: 27.49 samples/s ETA: 2 d  1 h  3 m	Data: 1.563 Tran: 0.007 F: 0.160 B: 0.299 O: 0.708 M: 0.010	Train-MLMAcc=0.602319,	MVRCAccuracy=0.646338,	MLMLossWVC=1.953626,	MVRCLoss=2.508663,	
Rank[  2]Epoch[3] Batch [200]	Speed: 27.70 samples/s ETA: 2 d  0 h 37 m	Data: 0.527 Tran: 0.007 F: 0.152 B: 0.298 O: 1.320 M: 0.007	Train-MLMAcc=0.602120,	MVRCAccuracy=0.646959,	MLMLossWVC=1.954730,	MVRCLoss=2.510180,	
Rank[  0]Epoch[3] Batch [200]	Speed: 27.70 samples/s ETA: 2 d  0 h 37 m	Data: 1.568 Tran: 0.007 F: 0.151 B: 0.294 O: 0.281 M: 0.009	Train-MLMAcc=0.602120,	MVRCAccuracy=0.646959,	MLMLossWVC=1.954730,	MVRCLoss=2.510180,	
Rank[  3]Epoch[3] Batch [200]	Speed: 27.70 samples/s ETA: 2 d  0 h 37 m	Data: 1.777 Tran: 0.007 F: 0.150 B: 0.295 O: 0.070 M: 0.011	Train-MLMAcc=0.602120,	MVRCAccuracy=0.646959,	MLMLossWVC=1.954730,	MVRCLoss=2.510180,	
Rank[  1]Epoch[3] Batch [200]	Speed: 27.70 samples/s ETA: 2 d  0 h 37 m	Data: 0.260 Tran: 0.007 F: 0.150 B: 0.294 O: 1.590 M: 0.009	Train-MLMAcc=0.602120,	MVRCAccuracy=0.646959,	MLMLossWVC=1.954730,	MVRCLoss=2.510180,	
Rank[  0]Epoch[3] Batch [300]	Speed: 27.73 samples/s ETA: 2 d  0 h 30 m	Data: 1.125 Tran: 0.007 F: 0.151 B: 0.293 O: 0.723 M: 0.009	Train-MLMAcc=0.602329,	MVRCAccuracy=0.647508,	MLMLossWVC=1.961767,	MVRCLoss=2.507480,	
Rank[  2]Epoch[3] Batch [300]	Speed: 27.73 samples/s ETA: 2 d  0 h 30 m	Data: 0.258 Tran: 0.006 F: 0.150 B: 0.296 O: 1.583 M: 0.013	Train-MLMAcc=0.602329,	MVRCAccuracy=0.647508,	MLMLossWVC=1.961767,	MVRCLoss=2.507480,	
Rank[  3]Epoch[3] Batch [300]	Speed: 27.73 samples/s ETA: 2 d  0 h 30 m	Data: 1.769 Tran: 0.006 F: 0.151 B: 0.297 O: 0.072 M: 0.011	Train-MLMAcc=0.602329,	MVRCAccuracy=0.647508,	MLMLossWVC=1.961767,	MVRCLoss=2.507480,	
Rank[  1]Epoch[3] Batch [300]	Speed: 27.73 samples/s ETA: 2 d  0 h 30 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.296 O: 1.838 M: 0.009	Train-MLMAcc=0.602329,	MVRCAccuracy=0.647508,	MLMLossWVC=1.961767,	MVRCLoss=2.507480,	
Rank[  0]Epoch[3] Batch [400]	Speed: 27.85 samples/s ETA: 2 d  0 h 14 m	Data: 0.318 Tran: 0.007 F: 0.150 B: 0.292 O: 1.523 M: 0.007	Train-MLMAcc=0.601984,	MVRCAccuracy=0.647820,	MLMLossWVC=1.959093,	MVRCLoss=2.506146,	
Rank[  1]Epoch[3] Batch [400]	Speed: 27.85 samples/s ETA: 2 d  0 h 14 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.833 M: 0.007	Train-MLMAcc=0.601984,	MVRCAccuracy=0.647820,	MLMLossWVC=1.959093,	MVRCLoss=2.506146,	
Rank[  2]Epoch[3] Batch [400]	Speed: 27.85 samples/s ETA: 2 d  0 h 14 m	Data: 0.123 Tran: 0.007 F: 0.150 B: 0.294 O: 1.718 M: 0.006	Train-MLMAcc=0.601984,	MVRCAccuracy=0.647820,	MLMLossWVC=1.959093,	MVRCLoss=2.506146,	
Rank[  3]Epoch[3] Batch [400]	Speed: 27.85 samples/s ETA: 2 d  0 h 14 m	Data: 1.789 Tran: 0.006 F: 0.150 B: 0.296 O: 0.049 M: 0.008	Train-MLMAcc=0.601984,	MVRCAccuracy=0.647820,	MLMLossWVC=1.959093,	MVRCLoss=2.506146,	
Rank[  0]Epoch[3] Batch [500]	Speed: 27.63 samples/s ETA: 2 d  0 h 32 m	Data: 0.060 Tran: 0.007 F: 0.150 B: 0.292 O: 1.801 M: 0.005	Train-MLMAcc=0.602968,	MVRCAccuracy=0.647607,	MLMLossWVC=1.957744,	MVRCLoss=2.506133,	
Rank[  1]Epoch[3] Batch [500]	Speed: 27.63 samples/s ETA: 2 d  0 h 32 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.296 O: 1.850 M: 0.005	Train-MLMAcc=0.602968,	MVRCAccuracy=0.647607,	MLMLossWVC=1.957744,	MVRCLoss=2.506133,	
Rank[  3]Epoch[3] Batch [500]	Speed: 27.63 samples/s ETA: 2 d  0 h 32 m	Data: 1.806 Tran: 0.006 F: 0.151 B: 0.297 O: 0.049 M: 0.006	Train-MLMAcc=0.602968,	MVRCAccuracy=0.647607,	MLMLossWVC=1.957744,	MVRCLoss=2.506133,	
Rank[  2]Epoch[3] Batch [500]	Speed: 27.63 samples/s ETA: 2 d  0 h 32 m	Data: 0.012 Tran: 0.006 F: 0.150 B: 0.296 O: 1.845 M: 0.006	Train-MLMAcc=0.602968,	MVRCAccuracy=0.647607,	MLMLossWVC=1.957744,	MVRCLoss=2.506133,	
Rank[  2]Epoch[3] Batch [600]	Speed: 27.90 samples/s ETA: 2 d  0 h  0 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.823 M: 0.008	Train-MLMAcc=0.603264,	MVRCAccuracy=0.647716,	MLMLossWVC=1.958599,	MVRCLoss=2.505418,	
Rank[  3]Epoch[3] Batch [600]	Speed: 27.90 samples/s ETA: 2 d  0 h  0 m	Data: 1.779 Tran: 0.006 F: 0.152 B: 0.298 O: 0.049 M: 0.010	Train-MLMAcc=0.603264,	MVRCAccuracy=0.647716,	MLMLossWVC=1.958599,	MVRCLoss=2.505418,	
Rank[  0]Epoch[3] Batch [600]	Speed: 27.90 samples/s ETA: 2 d  0 h  0 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.827 M: 0.008	Train-MLMAcc=0.603264,	MVRCAccuracy=0.647716,	MLMLossWVC=1.958599,	MVRCLoss=2.505418,	
Rank[  1]Epoch[3] Batch [600]	Speed: 27.90 samples/s ETA: 2 d  0 h  0 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.295 O: 1.826 M: 0.007	Train-MLMAcc=0.603264,	MVRCAccuracy=0.647716,	MLMLossWVC=1.958599,	MVRCLoss=2.505418,	
Rank[  3]Epoch[3] Batch [700]	Speed: 27.86 samples/s ETA: 2 d  0 h  1 m	Data: 1.406 Tran: 0.006 F: 0.150 B: 0.296 O: 0.425 M: 0.012	Train-MLMAcc=0.603359,	MVRCAccuracy=0.647763,	MLMLossWVC=1.956158,	MVRCLoss=2.504975,	
Rank[  0]Epoch[3] Batch [700]	Speed: 27.86 samples/s ETA: 2 d  0 h  1 m	Data: 0.070 Tran: 0.007 F: 0.150 B: 0.292 O: 1.769 M: 0.009	Train-MLMAcc=0.603359,	MVRCAccuracy=0.647763,	MLMLossWVC=1.956158,	MVRCLoss=2.504975,	
Rank[  2]Epoch[3] Batch [700]	Speed: 27.86 samples/s ETA: 2 d  0 h  1 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.829 M: 0.007	Train-MLMAcc=0.603359,	MVRCAccuracy=0.647763,	MLMLossWVC=1.956158,	MVRCLoss=2.504975,	
Rank[  1]Epoch[3] Batch [700]	Speed: 27.86 samples/s ETA: 2 d  0 h  1 m	Data: 0.359 Tran: 0.006 F: 0.150 B: 0.295 O: 1.473 M: 0.011	Train-MLMAcc=0.603359,	MVRCAccuracy=0.647763,	MLMLossWVC=1.956158,	MVRCLoss=2.504975,	
Rank[  3]Epoch[3] Batch [800]	Speed: 27.89 samples/s ETA: 1 d 23 h 54 m	Data: 1.353 Tran: 0.006 F: 0.150 B: 0.297 O: 0.481 M: 0.006	Train-MLMAcc=0.603572,	MVRCAccuracy=0.647739,	MLMLossWVC=1.955138,	MVRCLoss=2.505442,	
Rank[  1]Epoch[3] Batch [800]	Speed: 27.89 samples/s ETA: 1 d 23 h 54 m	Data: 0.420 Tran: 0.007 F: 0.150 B: 0.296 O: 1.414 M: 0.007	Train-MLMAcc=0.603572,	MVRCAccuracy=0.647739,	MLMLossWVC=1.955138,	MVRCLoss=2.505442,	
Rank[  0]Epoch[3] Batch [800]	Speed: 27.89 samples/s ETA: 1 d 23 h 54 m	Data: 0.028 Tran: 0.007 F: 0.149 B: 0.293 O: 1.810 M: 0.005	Train-MLMAcc=0.603572,	MVRCAccuracy=0.647739,	MLMLossWVC=1.955138,	MVRCLoss=2.505442,	
Rank[  2]Epoch[3] Batch [800]	Speed: 27.89 samples/s ETA: 1 d 23 h 54 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.828 M: 0.008	Train-MLMAcc=0.603572,	MVRCAccuracy=0.647739,	MLMLossWVC=1.955138,	MVRCLoss=2.505442,	
Rank[  2]Epoch[3] Batch [900]	Speed: 28.02 samples/s ETA: 1 d 23 h 37 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.299 O: 1.812 M: 0.008	Train-MLMAcc=0.603801,	MVRCAccuracy=0.647786,	MLMLossWVC=1.954323,	MVRCLoss=2.505570,	
Rank[  3]Epoch[3] Batch [900]	Speed: 28.02 samples/s ETA: 1 d 23 h 37 m	Data: 0.405 Tran: 0.006 F: 0.150 B: 0.298 O: 1.412 M: 0.011	Train-MLMAcc=0.603801,	MVRCAccuracy=0.647786,	MLMLossWVC=1.954323,	MVRCLoss=2.505570,	
Rank[  0]Epoch[3] Batch [900]	Speed: 28.02 samples/s ETA: 1 d 23 h 37 m	Data: 0.115 Tran: 0.007 F: 0.150 B: 0.292 O: 1.708 M: 0.012	Train-MLMAcc=0.603801,	MVRCAccuracy=0.647786,	MLMLossWVC=1.954323,	MVRCLoss=2.505570,	
Rank[  1]Epoch[3] Batch [900]	Speed: 28.02 samples/s ETA: 1 d 23 h 37 m	Data: 1.370 Tran: 0.007 F: 0.152 B: 0.296 O: 0.450 M: 0.009	Train-MLMAcc=0.603801,	MVRCAccuracy=0.647786,	MLMLossWVC=1.954323,	MVRCLoss=2.505570,	
Rank[  2]Epoch[3] Batch [1000]	Speed: 28.00 samples/s ETA: 1 d 23 h 35 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.816 M: 0.009	Train-MLMAcc=0.604007,	MVRCAccuracy=0.647875,	MLMLossWVC=1.952282,	MVRCLoss=2.505123,	
Rank[  0]Epoch[3] Batch [1000]	Speed: 28.00 samples/s ETA: 1 d 23 h 35 m	Data: 0.018 Tran: 0.007 F: 0.149 B: 0.291 O: 1.810 M: 0.009	Train-MLMAcc=0.604007,	MVRCAccuracy=0.647875,	MLMLossWVC=1.952282,	MVRCLoss=2.505123,	
Rank[  3]Epoch[3] Batch [1000]	Speed: 28.00 samples/s ETA: 1 d 23 h 35 m	Data: 0.331 Tran: 0.006 F: 0.150 B: 0.296 O: 1.493 M: 0.009	Train-MLMAcc=0.604007,	MVRCAccuracy=0.647875,	MLMLossWVC=1.952282,	MVRCLoss=2.505123,	
Rank[  1]Epoch[3] Batch [1000]	Speed: 28.00 samples/s ETA: 1 d 23 h 35 m	Data: 1.448 Tran: 0.006 F: 0.151 B: 0.295 O: 0.378 M: 0.006	Train-MLMAcc=0.604007,	MVRCAccuracy=0.647875,	MLMLossWVC=1.952282,	MVRCLoss=2.505123,	
Rank[  1]Epoch[3] Batch [1100]	Speed: 28.05 samples/s ETA: 1 d 23 h 26 m	Data: 1.330 Tran: 0.006 F: 0.151 B: 0.296 O: 0.489 M: 0.008	Train-MLMAcc=0.603926,	MVRCAccuracy=0.648108,	MLMLossWVC=1.953493,	MVRCLoss=2.505270,	
Rank[  0]Epoch[3] Batch [1100]	Speed: 28.05 samples/s ETA: 1 d 23 h 26 m	Data: 0.093 Tran: 0.007 F: 0.150 B: 0.292 O: 1.732 M: 0.008	Train-MLMAcc=0.603926,	MVRCAccuracy=0.648108,	MLMLossWVC=1.953493,	MVRCLoss=2.505270,	
Rank[  3]Epoch[3] Batch [1100]	Speed: 28.05 samples/s ETA: 1 d 23 h 26 m	Data: 0.444 Tran: 0.006 F: 0.151 B: 0.299 O: 1.372 M: 0.008	Train-MLMAcc=0.603926,	MVRCAccuracy=0.648108,	MLMLossWVC=1.953493,	MVRCLoss=2.505270,	
Rank[  2]Epoch[3] Batch [1100]	Speed: 28.05 samples/s ETA: 1 d 23 h 26 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.810 M: 0.008	Train-MLMAcc=0.603926,	MVRCAccuracy=0.648108,	MLMLossWVC=1.953493,	MVRCLoss=2.505270,	
Rank[  1]Epoch[3] Batch [1200]	Speed: 27.52 samples/s ETA: 2 d  0 h 17 m	Data: 1.474 Tran: 0.006 F: 0.151 B: 0.295 O: 0.392 M: 0.006	Train-MLMAcc=0.603624,	MVRCAccuracy=0.648190,	MLMLossWVC=1.955062,	MVRCLoss=2.504846,	
Rank[  0]Epoch[3] Batch [1200]	Speed: 27.52 samples/s ETA: 2 d  0 h 17 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.292 O: 1.862 M: 0.007	Train-MLMAcc=0.603624,	MVRCAccuracy=0.648190,	MLMLossWVC=1.955062,	MVRCLoss=2.504846,	
Rank[  3]Epoch[3] Batch [1200]	Speed: 27.52 samples/s ETA: 2 d  0 h 17 m	Data: 0.347 Tran: 0.006 F: 0.150 B: 0.296 O: 1.519 M: 0.007	Train-MLMAcc=0.603624,	MVRCAccuracy=0.648190,	MLMLossWVC=1.955062,	MVRCLoss=2.504846,	
Rank[  2]Epoch[3] Batch [1200]	Speed: 27.52 samples/s ETA: 2 d  0 h 17 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.856 M: 0.007	Train-MLMAcc=0.603624,	MVRCAccuracy=0.648190,	MLMLossWVC=1.955062,	MVRCLoss=2.504846,	
Rank[  0]Epoch[3] Batch [1300]	Speed: 26.67 samples/s ETA: 2 d  1 h 45 m	Data: 0.010 Tran: 0.007 F: 0.155 B: 0.300 O: 1.915 M: 0.010	Train-MLMAcc=0.603453,	MVRCAccuracy=0.648367,	MLMLossWVC=1.956562,	MVRCLoss=2.504253,	
Rank[  1]Epoch[3] Batch [1300]	Speed: 26.67 samples/s ETA: 2 d  1 h 45 m	Data: 1.655 Tran: 0.013 F: 0.192 B: 0.315 O: 0.213 M: 0.012	Train-MLMAcc=0.603453,	MVRCAccuracy=0.648367,	MLMLossWVC=1.956562,	MVRCLoss=2.504253,	
Rank[  2]Epoch[3] Batch [1300]	Speed: 26.67 samples/s ETA: 2 d  1 h 45 m	Data: 0.008 Tran: 0.007 F: 0.157 B: 0.302 O: 1.911 M: 0.013	Train-MLMAcc=0.603453,	MVRCAccuracy=0.648367,	MLMLossWVC=1.956562,	MVRCLoss=2.504253,	
Rank[  3]Epoch[3] Batch [1300]	Speed: 26.67 samples/s ETA: 2 d  1 h 45 m	Data: 0.162 Tran: 0.007 F: 0.156 B: 0.306 O: 1.753 M: 0.014	Train-MLMAcc=0.603453,	MVRCAccuracy=0.648367,	MLMLossWVC=1.956562,	MVRCLoss=2.504253,	
Rank[  0]Epoch[3] Batch [1400]	Speed: 27.52 samples/s ETA: 2 d  0 h  9 m	Data: 0.172 Tran: 0.007 F: 0.149 B: 0.292 O: 1.698 M: 0.006	Train-MLMAcc=0.603325,	MVRCAccuracy=0.648310,	MLMLossWVC=1.957117,	MVRCLoss=2.504408,	
Rank[  2]Epoch[3] Batch [1400]	Speed: 27.52 samples/s ETA: 2 d  0 h  9 m	Data: 0.094 Tran: 0.007 F: 0.149 B: 0.295 O: 1.774 M: 0.006	Train-MLMAcc=0.603325,	MVRCAccuracy=0.648310,	MLMLossWVC=1.957117,	MVRCLoss=2.504408,	
Rank[  3]Epoch[3] Batch [1400]	Speed: 27.52 samples/s ETA: 2 d  0 h  9 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.857 M: 0.006	Train-MLMAcc=0.603325,	MVRCAccuracy=0.648310,	MLMLossWVC=1.957117,	MVRCLoss=2.504408,	
Rank[  1]Epoch[3] Batch [1400]	Speed: 27.52 samples/s ETA: 2 d  0 h  9 m	Data: 1.566 Tran: 0.006 F: 0.150 B: 0.294 O: 0.303 M: 0.005	Train-MLMAcc=0.603325,	MVRCAccuracy=0.648310,	MLMLossWVC=1.957117,	MVRCLoss=2.504408,	
Rank[  0]Epoch[3] Batch [1500]	Speed: 27.63 samples/s ETA: 1 d 23 h 54 m	Data: 0.948 Tran: 0.007 F: 0.150 B: 0.293 O: 0.909 M: 0.008	Train-MLMAcc=0.603709,	MVRCAccuracy=0.648404,	MLMLossWVC=1.955090,	MVRCLoss=2.504339,	
Rank[  3]Epoch[3] Batch [1500]	Speed: 27.63 samples/s ETA: 1 d 23 h 54 m	Data: 0.071 Tran: 0.007 F: 0.150 B: 0.297 O: 1.783 M: 0.008	Train-MLMAcc=0.603709,	MVRCAccuracy=0.648404,	MLMLossWVC=1.955090,	MVRCLoss=2.504339,	
Rank[  1]Epoch[3] Batch [1500]	Speed: 27.63 samples/s ETA: 1 d 23 h 54 m	Data: 0.800 Tran: 0.006 F: 0.151 B: 0.295 O: 1.057 M: 0.006	Train-MLMAcc=0.603709,	MVRCAccuracy=0.648404,	MLMLossWVC=1.955090,	MVRCLoss=2.504339,	
Rank[  2]Epoch[3] Batch [1500]	Speed: 27.63 samples/s ETA: 1 d 23 h 54 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.847 M: 0.008	Train-MLMAcc=0.603709,	MVRCAccuracy=0.648404,	MLMLossWVC=1.955090,	MVRCLoss=2.504339,	
Rank[  0]Epoch[3] Batch [1600]	Speed: 27.14 samples/s ETA: 2 d  0 h 42 m	Data: 0.781 Tran: 0.010 F: 0.173 B: 0.297 O: 1.090 M: 0.006	Train-MLMAcc=0.603748,	MVRCAccuracy=0.648332,	MLMLossWVC=1.955166,	MVRCLoss=2.503939,	
Rank[  1]Epoch[3] Batch [1600]	Speed: 27.14 samples/s ETA: 2 d  0 h 42 m	Data: 1.035 Tran: 0.006 F: 0.151 B: 0.294 O: 0.861 M: 0.010	Train-MLMAcc=0.603748,	MVRCAccuracy=0.648332,	MLMLossWVC=1.955166,	MVRCLoss=2.503939,	
Rank[  2]Epoch[3] Batch [1600]	Speed: 27.14 samples/s ETA: 2 d  0 h 42 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.888 M: 0.010	Train-MLMAcc=0.603748,	MVRCAccuracy=0.648332,	MLMLossWVC=1.955166,	MVRCLoss=2.503939,	
Rank[  3]Epoch[3] Batch [1600]	Speed: 27.14 samples/s ETA: 2 d  0 h 42 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.299 O: 1.883 M: 0.011	Train-MLMAcc=0.603748,	MVRCAccuracy=0.648332,	MLMLossWVC=1.955166,	MVRCLoss=2.503939,	
Rank[  1]Epoch[3] Batch [1700]	Speed: 28.10 samples/s ETA: 1 d 22 h 59 m	Data: 1.523 Tran: 0.007 F: 0.166 B: 0.301 O: 0.272 M: 0.008	Train-MLMAcc=0.603787,	MVRCAccuracy=0.648497,	MLMLossWVC=1.954383,	MVRCLoss=2.503879,	
Rank[  0]Epoch[3] Batch [1700]	Speed: 28.10 samples/s ETA: 1 d 22 h 59 m	Data: 0.219 Tran: 0.007 F: 0.163 B: 0.297 O: 1.582 M: 0.008	Train-MLMAcc=0.603787,	MVRCAccuracy=0.648497,	MLMLossWVC=1.954383,	MVRCLoss=2.503879,	
Rank[  2]Epoch[3] Batch [1700]	Speed: 28.10 samples/s ETA: 1 d 22 h 59 m	Data: 0.008 Tran: 0.008 F: 0.160 B: 0.299 O: 1.796 M: 0.007	Train-MLMAcc=0.603787,	MVRCAccuracy=0.648497,	MLMLossWVC=1.954383,	MVRCLoss=2.503879,	
Rank[  3]Epoch[3] Batch [1700]	Speed: 28.10 samples/s ETA: 1 d 22 h 59 m	Data: 0.009 Tran: 0.007 F: 0.159 B: 0.300 O: 1.793 M: 0.009	Train-MLMAcc=0.603787,	MVRCAccuracy=0.648497,	MLMLossWVC=1.954383,	MVRCLoss=2.503879,	
Rank[  0]Epoch[3] Batch [1800]	Speed: 27.63 samples/s ETA: 1 d 23 h 42 m	Data: 0.361 Tran: 0.007 F: 0.150 B: 0.292 O: 1.494 M: 0.012	Train-MLMAcc=0.603986,	MVRCAccuracy=0.648525,	MLMLossWVC=1.953890,	MVRCLoss=2.503437,	
Rank[  1]Epoch[3] Batch [1800]	Speed: 27.63 samples/s ETA: 1 d 23 h 42 m	Data: 1.446 Tran: 0.007 F: 0.151 B: 0.294 O: 0.407 M: 0.010	Train-MLMAcc=0.603986,	MVRCAccuracy=0.648525,	MLMLossWVC=1.953890,	MVRCLoss=2.503437,	
Rank[  2]Epoch[3] Batch [1800]	Speed: 27.63 samples/s ETA: 1 d 23 h 42 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.296 O: 1.848 M: 0.007	Train-MLMAcc=0.603986,	MVRCAccuracy=0.648525,	MLMLossWVC=1.953890,	MVRCLoss=2.503437,	
Rank[  3]Epoch[3] Batch [1800]	Speed: 27.63 samples/s ETA: 1 d 23 h 42 m	Data: 0.007 Tran: 0.006 F: 0.150 B: 0.297 O: 1.842 M: 0.013	Train-MLMAcc=0.603986,	MVRCAccuracy=0.648525,	MLMLossWVC=1.953890,	MVRCLoss=2.503437,	
Rank[  2]Epoch[3] Batch [1900]	Speed: 27.77 samples/s ETA: 1 d 23 h 24 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.838 M: 0.005	Train-MLMAcc=0.603962,	MVRCAccuracy=0.648585,	MLMLossWVC=1.953960,	MVRCLoss=2.503229,	
Rank[  0]Epoch[3] Batch [1900]	Speed: 27.77 samples/s ETA: 1 d 23 h 24 m	Data: 1.118 Tran: 0.007 F: 0.149 B: 0.293 O: 0.731 M: 0.006	Train-MLMAcc=0.603962,	MVRCAccuracy=0.648585,	MLMLossWVC=1.953960,	MVRCLoss=2.503229,	
Rank[  3]Epoch[3] Batch [1900]	Speed: 27.77 samples/s ETA: 1 d 23 h 24 m	Data: 0.007 Tran: 0.006 F: 0.150 B: 0.297 O: 1.837 M: 0.007	Train-MLMAcc=0.603962,	MVRCAccuracy=0.648585,	MLMLossWVC=1.953960,	MVRCLoss=2.503229,	
Rank[  1]Epoch[3] Batch [1900]	Speed: 27.77 samples/s ETA: 1 d 23 h 24 m	Data: 0.685 Tran: 0.007 F: 0.150 B: 0.294 O: 1.162 M: 0.007	Train-MLMAcc=0.603962,	MVRCAccuracy=0.648585,	MLMLossWVC=1.953960,	MVRCLoss=2.503229,	
Rank[  2]Epoch[3] Batch [2000]	Speed: 27.98 samples/s ETA: 1 d 22 h 59 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.817 M: 0.008	Train-MLMAcc=0.604006,	MVRCAccuracy=0.648650,	MLMLossWVC=1.953488,	MVRCLoss=2.503038,	
Rank[  0]Epoch[3] Batch [2000]	Speed: 27.98 samples/s ETA: 1 d 22 h 59 m	Data: 1.285 Tran: 0.007 F: 0.151 B: 0.293 O: 0.544 M: 0.007	Train-MLMAcc=0.604006,	MVRCAccuracy=0.648650,	MLMLossWVC=1.953488,	MVRCLoss=2.503038,	
Rank[  1]Epoch[3] Batch [2000]	Speed: 27.98 samples/s ETA: 1 d 22 h 59 m	Data: 0.494 Tran: 0.007 F: 0.152 B: 0.297 O: 1.331 M: 0.005	Train-MLMAcc=0.604006,	MVRCAccuracy=0.648650,	MLMLossWVC=1.953488,	MVRCLoss=2.503038,	
Rank[  3]Epoch[3] Batch [2000]	Speed: 27.98 samples/s ETA: 1 d 22 h 59 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.817 M: 0.008	Train-MLMAcc=0.604006,	MVRCAccuracy=0.648650,	MLMLossWVC=1.953488,	MVRCLoss=2.503038,	
Rank[  2]Epoch[3] Batch [2100]	Speed: 27.50 samples/s ETA: 1 d 23 h 44 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.859 M: 0.009	Train-MLMAcc=0.603886,	MVRCAccuracy=0.648751,	MLMLossWVC=1.953466,	MVRCLoss=2.503032,	
Rank[  0]Epoch[3] Batch [2100]	Speed: 27.50 samples/s ETA: 1 d 23 h 44 m	Data: 1.287 Tran: 0.007 F: 0.151 B: 0.294 O: 0.577 M: 0.010	Train-MLMAcc=0.603886,	MVRCAccuracy=0.648751,	MLMLossWVC=1.953466,	MVRCLoss=2.503032,	
Rank[  3]Epoch[3] Batch [2100]	Speed: 27.50 samples/s ETA: 1 d 23 h 44 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.299 O: 1.854 M: 0.007	Train-MLMAcc=0.603886,	MVRCAccuracy=0.648751,	MLMLossWVC=1.953466,	MVRCLoss=2.503032,	
Rank[  1]Epoch[3] Batch [2100]	Speed: 27.50 samples/s ETA: 1 d 23 h 44 m	Data: 0.530 Tran: 0.007 F: 0.151 B: 0.295 O: 1.334 M: 0.010	Train-MLMAcc=0.603886,	MVRCAccuracy=0.648751,	MLMLossWVC=1.953466,	MVRCLoss=2.503032,	
Rank[  2]Epoch[3] Batch [2200]	Speed: 28.24 samples/s ETA: 1 d 22 h 25 m	Data: 0.008 Tran: 0.006 F: 0.149 B: 0.295 O: 1.800 M: 0.008	Train-MLMAcc=0.603806,	MVRCAccuracy=0.648829,	MLMLossWVC=1.954446,	MVRCLoss=2.502981,	
Rank[  0]Epoch[3] Batch [2200]	Speed: 28.24 samples/s ETA: 1 d 22 h 25 m	Data: 1.753 Tran: 0.006 F: 0.150 B: 0.291 O: 0.058 M: 0.007	Train-MLMAcc=0.603806,	MVRCAccuracy=0.648829,	MLMLossWVC=1.954446,	MVRCLoss=2.502981,	
Rank[  3]Epoch[3] Batch [2200]	Speed: 28.24 samples/s ETA: 1 d 22 h 25 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.797 M: 0.008	Train-MLMAcc=0.603806,	MVRCAccuracy=0.648829,	MLMLossWVC=1.954446,	MVRCLoss=2.502981,	
Rank[  1]Epoch[3] Batch [2200]	Speed: 28.24 samples/s ETA: 1 d 22 h 25 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.297 O: 1.798 M: 0.006	Train-MLMAcc=0.603806,	MVRCAccuracy=0.648829,	MLMLossWVC=1.954446,	MVRCLoss=2.502981,	
Rank[  0]Epoch[3] Batch [2300]	Speed: 28.69 samples/s ETA: 1 d 21 h 38 m	Data: 1.418 Tran: 0.006 F: 0.150 B: 0.292 O: 0.354 M: 0.008	Train-MLMAcc=0.604007,	MVRCAccuracy=0.648849,	MLMLossWVC=1.953341,	MVRCLoss=2.502674,	
Rank[  3]Epoch[3] Batch [2300]	Speed: 28.69 samples/s ETA: 1 d 21 h 38 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.759 M: 0.007	Train-MLMAcc=0.604007,	MVRCAccuracy=0.648849,	MLMLossWVC=1.953341,	MVRCLoss=2.502674,	
Rank[  1]Epoch[3] Batch [2300]	Speed: 28.69 samples/s ETA: 1 d 21 h 38 m	Data: 0.353 Tran: 0.007 F: 0.151 B: 0.295 O: 1.414 M: 0.010	Train-MLMAcc=0.604007,	MVRCAccuracy=0.648849,	MLMLossWVC=1.953341,	MVRCLoss=2.502674,	
Rank[  2]Epoch[3] Batch [2300]	Speed: 28.69 samples/s ETA: 1 d 21 h 38 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.759 M: 0.009	Train-MLMAcc=0.604007,	MVRCAccuracy=0.648849,	MLMLossWVC=1.953341,	MVRCLoss=2.502674,	
Rank[  2]Epoch[3] Batch [2400]	Speed: 28.13 samples/s ETA: 1 d 22 h 28 m	Data: 0.093 Tran: 0.007 F: 0.151 B: 0.299 O: 1.716 M: 0.008	Train-MLMAcc=0.604085,	MVRCAccuracy=0.648905,	MLMLossWVC=1.951656,	MVRCLoss=2.502776,	
Rank[  0]Epoch[3] Batch [2400]	Speed: 28.13 samples/s ETA: 1 d 22 h 28 m	Data: 1.440 Tran: 0.006 F: 0.150 B: 0.294 O: 0.376 M: 0.008	Train-MLMAcc=0.604085,	MVRCAccuracy=0.648905,	MLMLossWVC=1.951656,	MVRCLoss=2.502776,	
Rank[  1]Epoch[3] Batch [2400]	Speed: 28.13 samples/s ETA: 1 d 22 h 28 m	Data: 0.962 Tran: 0.007 F: 0.150 B: 0.296 O: 0.850 M: 0.008	Train-MLMAcc=0.604085,	MVRCAccuracy=0.648905,	MLMLossWVC=1.951656,	MVRCLoss=2.502776,	
Rank[  3]Epoch[3] Batch [2400]	Speed: 28.13 samples/s ETA: 1 d 22 h 28 m	Data: 0.148 Tran: 0.007 F: 0.149 B: 0.296 O: 1.667 M: 0.007	Train-MLMAcc=0.604085,	MVRCAccuracy=0.648905,	MLMLossWVC=1.951656,	MVRCLoss=2.502776,	
Rank[  0]Epoch[3] Batch [2500]	Speed: 28.01 samples/s ETA: 1 d 22 h 37 m	Data: 1.772 Tran: 0.007 F: 0.150 B: 0.291 O: 0.053 M: 0.011	Train-MLMAcc=0.603985,	MVRCAccuracy=0.649013,	MLMLossWVC=1.952116,	MVRCLoss=2.502341,	
Rank[  2]Epoch[3] Batch [2500]	Speed: 28.01 samples/s ETA: 1 d 22 h 37 m	Data: 0.007 Tran: 0.006 F: 0.149 B: 0.296 O: 1.814 M: 0.011	Train-MLMAcc=0.603985,	MVRCAccuracy=0.649013,	MLMLossWVC=1.952116,	MVRCLoss=2.502341,	
Rank[  1]Epoch[3] Batch [2500]	Speed: 28.01 samples/s ETA: 1 d 22 h 37 m	Data: 0.478 Tran: 0.007 F: 0.151 B: 0.295 O: 1.346 M: 0.006	Train-MLMAcc=0.603985,	MVRCAccuracy=0.649013,	MLMLossWVC=1.952116,	MVRCLoss=2.502341,	
Rank[  3]Epoch[3] Batch [2500]	Speed: 28.01 samples/s ETA: 1 d 22 h 37 m	Data: 0.053 Tran: 0.007 F: 0.150 B: 0.297 O: 1.765 M: 0.011	Train-MLMAcc=0.603985,	MVRCAccuracy=0.649013,	MLMLossWVC=1.952116,	MVRCLoss=2.502341,	
Rank[  0]Epoch[3] Batch [2600]	Speed: 28.01 samples/s ETA: 1 d 22 h 33 m	Data: 1.777 Tran: 0.006 F: 0.151 B: 0.292 O: 0.053 M: 0.005	Train-MLMAcc=0.603806,	MVRCAccuracy=0.649120,	MLMLossWVC=1.952988,	MVRCLoss=2.502014,	
Rank[  3]Epoch[3] Batch [2600]	Speed: 28.01 samples/s ETA: 1 d 22 h 33 m	Data: 0.204 Tran: 0.006 F: 0.149 B: 0.296 O: 1.618 M: 0.010	Train-MLMAcc=0.603806,	MVRCAccuracy=0.649120,	MLMLossWVC=1.952988,	MVRCLoss=2.502014,	
Rank[  1]Epoch[3] Batch [2600]	Speed: 28.01 samples/s ETA: 1 d 22 h 33 m	Data: 0.146 Tran: 0.007 F: 0.150 B: 0.297 O: 1.675 M: 0.009	Train-MLMAcc=0.603806,	MVRCAccuracy=0.649120,	MLMLossWVC=1.952988,	MVRCLoss=2.502014,	
Rank[  2]Epoch[3] Batch [2600]	Speed: 28.01 samples/s ETA: 1 d 22 h 33 m	Data: 0.007 Tran: 0.006 F: 0.148 B: 0.295 O: 1.818 M: 0.009	Train-MLMAcc=0.603806,	MVRCAccuracy=0.649120,	MLMLossWVC=1.952988,	MVRCLoss=2.502014,	
Rank[  1]Epoch[3] Batch [2700]	Speed: 27.98 samples/s ETA: 1 d 22 h 33 m	Data: 0.161 Tran: 0.006 F: 0.150 B: 0.298 O: 1.665 M: 0.008	Train-MLMAcc=0.603845,	MVRCAccuracy=0.649117,	MLMLossWVC=1.952684,	MVRCLoss=2.502148,	
Rank[  0]Epoch[3] Batch [2700]	Speed: 27.98 samples/s ETA: 1 d 22 h 33 m	Data: 1.700 Tran: 0.006 F: 0.151 B: 0.292 O: 0.134 M: 0.005	Train-MLMAcc=0.603845,	MVRCAccuracy=0.649117,	MLMLossWVC=1.952684,	MVRCLoss=2.502148,	
Rank[  2]Epoch[3] Batch [2700]	Speed: 27.98 samples/s ETA: 1 d 22 h 33 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.299 O: 1.814 M: 0.009	Train-MLMAcc=0.603845,	MVRCAccuracy=0.649117,	MLMLossWVC=1.952684,	MVRCLoss=2.502148,	
Rank[  3]Epoch[3] Batch [2700]	Speed: 27.98 samples/s ETA: 1 d 22 h 33 m	Data: 0.404 Tran: 0.006 F: 0.150 B: 0.297 O: 1.419 M: 0.010	Train-MLMAcc=0.603845,	MVRCAccuracy=0.649117,	MLMLossWVC=1.952684,	MVRCLoss=2.502148,	
Rank[  3]Epoch[3] Batch [2800]	Speed: 27.80 samples/s ETA: 1 d 22 h 47 m	Data: 0.080 Tran: 0.007 F: 0.150 B: 0.298 O: 1.756 M: 0.011	Train-MLMAcc=0.603932,	MVRCAccuracy=0.649143,	MLMLossWVC=1.952512,	MVRCLoss=2.502195,	
Rank[  0]Epoch[3] Batch [2800]	Speed: 27.80 samples/s ETA: 1 d 22 h 47 m	Data: 1.405 Tran: 0.006 F: 0.150 B: 0.293 O: 0.438 M: 0.009	Train-MLMAcc=0.603932,	MVRCAccuracy=0.649143,	MLMLossWVC=1.952512,	MVRCLoss=2.502195,	
Rank[  2]Epoch[3] Batch [2800]	Speed: 27.80 samples/s ETA: 1 d 22 h 47 m	Data: 0.007 Tran: 0.007 F: 0.152 B: 0.299 O: 1.831 M: 0.005	Train-MLMAcc=0.603932,	MVRCAccuracy=0.649143,	MLMLossWVC=1.952512,	MVRCLoss=2.502195,	
Rank[  1]Epoch[3] Batch [2800]	Speed: 27.80 samples/s ETA: 1 d 22 h 47 m	Data: 0.477 Tran: 0.006 F: 0.151 B: 0.298 O: 1.360 M: 0.010	Train-MLMAcc=0.603932,	MVRCAccuracy=0.649143,	MLMLossWVC=1.952512,	MVRCLoss=2.502195,	
Rank[  2]Epoch[3] Batch [2900]	Speed: 27.52 samples/s ETA: 1 d 23 h 12 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.856 M: 0.009	Train-MLMAcc=0.603762,	MVRCAccuracy=0.649207,	MLMLossWVC=1.953376,	MVRCLoss=2.501878,	
Rank[  0]Epoch[3] Batch [2900]	Speed: 27.52 samples/s ETA: 1 d 23 h 12 m	Data: 0.607 Tran: 0.006 F: 0.149 B: 0.291 O: 1.260 M: 0.012	Train-MLMAcc=0.603762,	MVRCAccuracy=0.649207,	MLMLossWVC=1.953376,	MVRCLoss=2.501878,	
Rank[  1]Epoch[3] Batch [2900]	Speed: 27.52 samples/s ETA: 1 d 23 h 12 m	Data: 1.224 Tran: 0.006 F: 0.150 B: 0.295 O: 0.638 M: 0.012	Train-MLMAcc=0.603762,	MVRCAccuracy=0.649207,	MLMLossWVC=1.953376,	MVRCLoss=2.501878,	
Rank[  3]Epoch[3] Batch [2900]	Speed: 27.52 samples/s ETA: 1 d 23 h 12 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.853 M: 0.009	Train-MLMAcc=0.603762,	MVRCAccuracy=0.649207,	MLMLossWVC=1.953376,	MVRCLoss=2.501878,	
Rank[  0]Epoch[3] Batch [3000]	Speed: 27.92 samples/s ETA: 1 d 22 h 27 m	Data: 0.726 Tran: 0.006 F: 0.149 B: 0.292 O: 1.108 M: 0.010	Train-MLMAcc=0.603729,	MVRCAccuracy=0.649351,	MLMLossWVC=1.953322,	MVRCLoss=2.501641,	
Rank[  1]Epoch[3] Batch [3000]	Speed: 27.92 samples/s ETA: 1 d 22 h 27 m	Data: 1.224 Tran: 0.006 F: 0.151 B: 0.296 O: 0.604 M: 0.010	Train-MLMAcc=0.603729,	MVRCAccuracy=0.649351,	MLMLossWVC=1.953322,	MVRCLoss=2.501641,	
Rank[  2]Epoch[3] Batch [3000]	Speed: 27.92 samples/s ETA: 1 d 22 h 27 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.824 M: 0.005	Train-MLMAcc=0.603729,	MVRCAccuracy=0.649351,	MLMLossWVC=1.953322,	MVRCLoss=2.501641,	
Rank[  3]Epoch[3] Batch [3000]	Speed: 27.92 samples/s ETA: 1 d 22 h 27 m	Data: 0.012 Tran: 0.007 F: 0.150 B: 0.296 O: 1.816 M: 0.010	Train-MLMAcc=0.603729,	MVRCAccuracy=0.649351,	MLMLossWVC=1.953322,	MVRCLoss=2.501641,	
Rank[  2]Epoch[3] Batch [3100]	Speed: 27.63 samples/s ETA: 1 d 22 h 52 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.847 M: 0.005	Train-MLMAcc=0.603699,	MVRCAccuracy=0.649394,	MLMLossWVC=1.953931,	MVRCLoss=2.501586,	
Rank[  0]Epoch[3] Batch [3100]	Speed: 27.63 samples/s ETA: 1 d 22 h 52 m	Data: 1.733 Tran: 0.007 F: 0.150 B: 0.294 O: 0.122 M: 0.010	Train-MLMAcc=0.603699,	MVRCAccuracy=0.649394,	MLMLossWVC=1.953931,	MVRCLoss=2.501586,	
Rank[  1]Epoch[3] Batch [3100]	Speed: 27.63 samples/s ETA: 1 d 22 h 52 m	Data: 0.082 Tran: 0.006 F: 0.150 B: 0.296 O: 1.772 M: 0.009	Train-MLMAcc=0.603699,	MVRCAccuracy=0.649394,	MLMLossWVC=1.953931,	MVRCLoss=2.501586,	
Rank[  3]Epoch[3] Batch [3100]	Speed: 27.63 samples/s ETA: 1 d 22 h 52 m	Data: 0.290 Tran: 0.007 F: 0.150 B: 0.295 O: 1.563 M: 0.010	Train-MLMAcc=0.603699,	MVRCAccuracy=0.649394,	MLMLossWVC=1.953931,	MVRCLoss=2.501586,	
Rank[  2]Epoch[3] Batch [3200]	Speed: 28.04 samples/s ETA: 1 d 22 h  7 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.296 O: 1.813 M: 0.009	Train-MLMAcc=0.603730,	MVRCAccuracy=0.649468,	MLMLossWVC=1.953800,	MVRCLoss=2.501492,	
Rank[  1]Epoch[3] Batch [3200]	Speed: 28.04 samples/s ETA: 1 d 22 h  7 m	Data: 0.072 Tran: 0.006 F: 0.150 B: 0.296 O: 1.753 M: 0.005	Train-MLMAcc=0.603730,	MVRCAccuracy=0.649468,	MLMLossWVC=1.953800,	MVRCLoss=2.501492,	
Rank[  0]Epoch[3] Batch [3200]	Speed: 28.04 samples/s ETA: 1 d 22 h  7 m	Data: 1.709 Tran: 0.007 F: 0.150 B: 0.293 O: 0.114 M: 0.008	Train-MLMAcc=0.603730,	MVRCAccuracy=0.649468,	MLMLossWVC=1.953800,	MVRCLoss=2.501492,	
Rank[  3]Epoch[3] Batch [3200]	Speed: 28.04 samples/s ETA: 1 d 22 h  7 m	Data: 0.117 Tran: 0.007 F: 0.149 B: 0.295 O: 1.705 M: 0.009	Train-MLMAcc=0.603730,	MVRCAccuracy=0.649468,	MLMLossWVC=1.953800,	MVRCLoss=2.501492,	
Rank[  2]Epoch[3] Batch [3300]	Speed: 27.75 samples/s ETA: 1 d 22 h 32 m	Data: 0.008 Tran: 0.006 F: 0.150 B: 0.296 O: 1.841 M: 0.005	Train-MLMAcc=0.603778,	MVRCAccuracy=0.649522,	MLMLossWVC=1.953312,	MVRCLoss=2.501416,	
Rank[  1]Epoch[3] Batch [3300]	Speed: 27.75 samples/s ETA: 1 d 22 h 32 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.293 O: 1.842 M: 0.007	Train-MLMAcc=0.603778,	MVRCAccuracy=0.649522,	MLMLossWVC=1.953312,	MVRCLoss=2.501416,	
Rank[  0]Epoch[3] Batch [3300]	Speed: 27.75 samples/s ETA: 1 d 22 h 32 m	Data: 1.798 Tran: 0.007 F: 0.149 B: 0.290 O: 0.054 M: 0.007	Train-MLMAcc=0.603778,	MVRCAccuracy=0.649522,	MLMLossWVC=1.953312,	MVRCLoss=2.501416,	
Rank[  3]Epoch[3] Batch [3300]	Speed: 27.75 samples/s ETA: 1 d 22 h 32 m	Data: 0.697 Tran: 0.006 F: 0.151 B: 0.298 O: 1.144 M: 0.008	Train-MLMAcc=0.603778,	MVRCAccuracy=0.649522,	MLMLossWVC=1.953312,	MVRCLoss=2.501416,	
Rank[  2]Epoch[3] Batch [3400]	Speed: 27.58 samples/s ETA: 1 d 22 h 46 m	Data: 0.008 Tran: 0.007 F: 0.163 B: 0.315 O: 1.821 M: 0.006	Train-MLMAcc=0.604044,	MVRCAccuracy=0.649580,	MLMLossWVC=1.951941,	MVRCLoss=2.501204,	
Rank[  1]Epoch[3] Batch [3400]	Speed: 27.58 samples/s ETA: 1 d 22 h 46 m	Data: 0.196 Tran: 0.007 F: 0.164 B: 0.315 O: 1.631 M: 0.006	Train-MLMAcc=0.604044,	MVRCAccuracy=0.649580,	MLMLossWVC=1.951941,	MVRCLoss=2.501204,	
Rank[  3]Epoch[3] Batch [3400]	Speed: 27.58 samples/s ETA: 1 d 22 h 46 m	Data: 0.144 Tran: 0.007 F: 0.164 B: 0.316 O: 1.683 M: 0.005	Train-MLMAcc=0.604044,	MVRCAccuracy=0.649580,	MLMLossWVC=1.951941,	MVRCLoss=2.501204,	
Rank[  0]Epoch[3] Batch [3400]	Speed: 27.58 samples/s ETA: 1 d 22 h 46 m	Data: 1.797 Tran: 0.007 F: 0.158 B: 0.293 O: 0.058 M: 0.007	Train-MLMAcc=0.604044,	MVRCAccuracy=0.649580,	MLMLossWVC=1.951941,	MVRCLoss=2.501204,	
Rank[  1]Epoch[3] Batch [3500]	Speed: 27.34 samples/s ETA: 1 d 23 h  6 m	Data: 0.957 Tran: 0.007 F: 0.151 B: 0.295 O: 0.921 M: 0.008	Train-MLMAcc=0.603989,	MVRCAccuracy=0.649688,	MLMLossWVC=1.952384,	MVRCLoss=2.500878,	
Rank[  2]Epoch[3] Batch [3500]	Speed: 27.34 samples/s ETA: 1 d 23 h  6 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.867 M: 0.011	Train-MLMAcc=0.603989,	MVRCAccuracy=0.649688,	MLMLossWVC=1.952384,	MVRCLoss=2.500878,	
Rank[  3]Epoch[3] Batch [3500]	Speed: 27.34 samples/s ETA: 1 d 23 h  6 m	Data: 0.153 Tran: 0.007 F: 0.150 B: 0.298 O: 1.722 M: 0.010	Train-MLMAcc=0.603989,	MVRCAccuracy=0.649688,	MLMLossWVC=1.952384,	MVRCLoss=2.500878,	
Rank[  0]Epoch[3] Batch [3500]	Speed: 27.34 samples/s ETA: 1 d 23 h  6 m	Data: 1.712 Tran: 0.007 F: 0.151 B: 0.293 O: 0.166 M: 0.011	Train-MLMAcc=0.603989,	MVRCAccuracy=0.649688,	MLMLossWVC=1.952384,	MVRCLoss=2.500878,	
Rank[  2]Epoch[3] Batch [3600]	Speed: 27.76 samples/s ETA: 1 d 22 h 20 m	Data: 0.432 Tran: 0.006 F: 0.150 B: 0.297 O: 1.410 M: 0.009	Train-MLMAcc=0.604027,	MVRCAccuracy=0.649677,	MLMLossWVC=1.952512,	MVRCLoss=2.500463,	
Rank[  1]Epoch[3] Batch [3600]	Speed: 27.76 samples/s ETA: 1 d 22 h 20 m	Data: 1.210 Tran: 0.007 F: 0.151 B: 0.297 O: 0.630 M: 0.009	Train-MLMAcc=0.604027,	MVRCAccuracy=0.649677,	MLMLossWVC=1.952512,	MVRCLoss=2.500463,	
Rank[  0]Epoch[3] Batch [3600]	Speed: 27.76 samples/s ETA: 1 d 22 h 20 m	Data: 0.877 Tran: 0.007 F: 0.150 B: 0.294 O: 0.969 M: 0.007	Train-MLMAcc=0.604027,	MVRCAccuracy=0.649677,	MLMLossWVC=1.952512,	MVRCLoss=2.500463,	
Rank[  3]Epoch[3] Batch [3600]	Speed: 27.76 samples/s ETA: 1 d 22 h 20 m	Data: 0.543 Tran: 0.006 F: 0.150 B: 0.295 O: 1.302 M: 0.008	Train-MLMAcc=0.604027,	MVRCAccuracy=0.649677,	MLMLossWVC=1.952512,	MVRCLoss=2.500463,	
Rank[  0]Epoch[3] Batch [3700]	Speed: 27.65 samples/s ETA: 1 d 22 h 27 m	Data: 0.351 Tran: 0.007 F: 0.149 B: 0.293 O: 1.505 M: 0.009	Train-MLMAcc=0.604101,	MVRCAccuracy=0.649786,	MLMLossWVC=1.952121,	MVRCLoss=2.500233,	
Rank[  1]Epoch[3] Batch [3700]	Speed: 27.65 samples/s ETA: 1 d 22 h 27 m	Data: 0.179 Tran: 0.007 F: 0.150 B: 0.295 O: 1.675 M: 0.008	Train-MLMAcc=0.604101,	MVRCAccuracy=0.649786,	MLMLossWVC=1.952121,	MVRCLoss=2.500233,	
Rank[  2]Epoch[3] Batch [3700]	Speed: 27.65 samples/s ETA: 1 d 22 h 27 m	Data: 1.445 Tran: 0.007 F: 0.150 B: 0.295 O: 0.408 M: 0.009	Train-MLMAcc=0.604101,	MVRCAccuracy=0.649786,	MLMLossWVC=1.952121,	MVRCLoss=2.500233,	
Rank[  3]Epoch[3] Batch [3700]	Speed: 27.65 samples/s ETA: 1 d 22 h 27 m	Data: 0.833 Tran: 0.007 F: 0.152 B: 0.301 O: 1.014 M: 0.008	Train-MLMAcc=0.604101,	MVRCAccuracy=0.649786,	MLMLossWVC=1.952121,	MVRCLoss=2.500233,	
Rank[  0]Epoch[3] Batch [3800]	Speed: 27.87 samples/s ETA: 1 d 22 h  1 m	Data: 0.109 Tran: 0.007 F: 0.149 B: 0.292 O: 1.730 M: 0.008	Train-MLMAcc=0.604277,	MVRCAccuracy=0.649837,	MLMLossWVC=1.950738,	MVRCLoss=2.500140,	
Rank[  1]Epoch[3] Batch [3800]	Speed: 27.87 samples/s ETA: 1 d 22 h  1 m	Data: 0.589 Tran: 0.007 F: 0.150 B: 0.294 O: 1.250 M: 0.007	Train-MLMAcc=0.604277,	MVRCAccuracy=0.649837,	MLMLossWVC=1.950738,	MVRCLoss=2.500140,	
Rank[  3]Epoch[3] Batch [3800]	Speed: 27.87 samples/s ETA: 1 d 22 h  1 m	Data: 1.397 Tran: 0.007 F: 0.151 B: 0.299 O: 0.437 M: 0.005	Train-MLMAcc=0.604277,	MVRCAccuracy=0.649837,	MLMLossWVC=1.950738,	MVRCLoss=2.500140,	
Rank[  2]Epoch[3] Batch [3800]	Speed: 27.87 samples/s ETA: 1 d 22 h  1 m	Data: 1.050 Tran: 0.007 F: 0.150 B: 0.295 O: 0.787 M: 0.007	Train-MLMAcc=0.604277,	MVRCAccuracy=0.649837,	MLMLossWVC=1.950738,	MVRCLoss=2.500140,	
Rank[  0]Epoch[3] Batch [3900]	Speed: 27.36 samples/s ETA: 1 d 22 h 49 m	Data: 0.129 Tran: 0.007 F: 0.150 B: 0.294 O: 1.749 M: 0.009	Train-MLMAcc=0.604359,	MVRCAccuracy=0.649877,	MLMLossWVC=1.950438,	MVRCLoss=2.500062,	
Rank[  1]Epoch[3] Batch [3900]	Speed: 27.36 samples/s ETA: 1 d 22 h 49 m	Data: 0.706 Tran: 0.007 F: 0.151 B: 0.297 O: 1.169 M: 0.007	Train-MLMAcc=0.604359,	MVRCAccuracy=0.649877,	MLMLossWVC=1.950438,	MVRCLoss=2.500062,	
Rank[  3]Epoch[3] Batch [3900]	Speed: 27.36 samples/s ETA: 1 d 22 h 49 m	Data: 1.201 Tran: 0.007 F: 0.151 B: 0.297 O: 0.674 M: 0.009	Train-MLMAcc=0.604359,	MVRCAccuracy=0.649877,	MLMLossWVC=1.950438,	MVRCLoss=2.500062,	
Rank[  2]Epoch[3] Batch [3900]	Speed: 27.36 samples/s ETA: 1 d 22 h 49 m	Data: 0.625 Tran: 0.007 F: 0.151 B: 0.298 O: 1.251 M: 0.006	Train-MLMAcc=0.604359,	MVRCAccuracy=0.649877,	MLMLossWVC=1.950438,	MVRCLoss=2.500062,	
Rank[  0]Epoch[3] Batch [4000]	Speed: 27.86 samples/s ETA: 1 d 21 h 55 m	Data: 0.769 Tran: 0.007 F: 0.150 B: 0.293 O: 1.070 M: 0.007	Train-MLMAcc=0.604313,	MVRCAccuracy=0.649980,	MLMLossWVC=1.950438,	MVRCLoss=2.499889,	
Rank[  1]Epoch[3] Batch [4000]	Speed: 27.86 samples/s ETA: 1 d 21 h 55 m	Data: 0.562 Tran: 0.007 F: 0.150 B: 0.294 O: 1.277 M: 0.007	Train-MLMAcc=0.604313,	MVRCAccuracy=0.649980,	MLMLossWVC=1.950438,	MVRCLoss=2.499889,	
Rank[  2]Epoch[3] Batch [4000]	Speed: 27.86 samples/s ETA: 1 d 21 h 55 m	Data: 0.082 Tran: 0.007 F: 0.150 B: 0.298 O: 1.752 M: 0.007	Train-MLMAcc=0.604313,	MVRCAccuracy=0.649980,	MLMLossWVC=1.950438,	MVRCLoss=2.499889,	
Rank[  3]Epoch[3] Batch [4000]	Speed: 27.86 samples/s ETA: 1 d 21 h 55 m	Data: 0.661 Tran: 0.007 F: 0.150 B: 0.298 O: 1.174 M: 0.008	Train-MLMAcc=0.604313,	MVRCAccuracy=0.649980,	MLMLossWVC=1.950438,	MVRCLoss=2.499889,	
Rank[  0]Epoch[3] Batch [4100]	Speed: 27.85 samples/s ETA: 1 d 21 h 52 m	Data: 0.388 Tran: 0.007 F: 0.150 B: 0.292 O: 1.453 M: 0.008	Train-MLMAcc=0.604254,	MVRCAccuracy=0.650023,	MLMLossWVC=1.950864,	MVRCLoss=2.499773,	
Rank[  2]Epoch[3] Batch [4100]	Speed: 27.85 samples/s ETA: 1 d 21 h 52 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.829 M: 0.008	Train-MLMAcc=0.604254,	MVRCAccuracy=0.650023,	MLMLossWVC=1.950864,	MVRCLoss=2.499773,	
Rank[  1]Epoch[3] Batch [4100]	Speed: 27.85 samples/s ETA: 1 d 21 h 52 m	Data: 1.777 Tran: 0.007 F: 0.151 B: 0.294 O: 0.061 M: 0.008	Train-MLMAcc=0.604254,	MVRCAccuracy=0.650023,	MLMLossWVC=1.950864,	MVRCLoss=2.499773,	
Rank[  3]Epoch[3] Batch [4100]	Speed: 27.85 samples/s ETA: 1 d 21 h 52 m	Data: 0.236 Tran: 0.007 F: 0.150 B: 0.296 O: 1.601 M: 0.008	Train-MLMAcc=0.604254,	MVRCAccuracy=0.650023,	MLMLossWVC=1.950864,	MVRCLoss=2.499773,	
Rank[  0]Epoch[3] Batch [4200]	Speed: 27.65 samples/s ETA: 1 d 22 h  8 m	Data: 0.173 Tran: 0.007 F: 0.149 B: 0.291 O: 1.688 M: 0.006	Train-MLMAcc=0.604343,	MVRCAccuracy=0.650073,	MLMLossWVC=1.950530,	MVRCLoss=2.499856,	
Rank[  2]Epoch[3] Batch [4200]	Speed: 27.65 samples/s ETA: 1 d 22 h  8 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.849 M: 0.006	Train-MLMAcc=0.604343,	MVRCAccuracy=0.650073,	MLMLossWVC=1.950530,	MVRCLoss=2.499856,	
Rank[  1]Epoch[3] Batch [4200]	Speed: 27.65 samples/s ETA: 1 d 22 h  8 m	Data: 1.805 Tran: 0.007 F: 0.151 B: 0.294 O: 0.050 M: 0.007	Train-MLMAcc=0.604343,	MVRCAccuracy=0.650073,	MLMLossWVC=1.950530,	MVRCLoss=2.499856,	
Rank[  3]Epoch[3] Batch [4200]	Speed: 27.65 samples/s ETA: 1 d 22 h  8 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.295 O: 1.849 M: 0.007	Train-MLMAcc=0.604343,	MVRCAccuracy=0.650073,	MLMLossWVC=1.950530,	MVRCLoss=2.499856,	
Rank[  2]Epoch[3] Batch [4300]	Speed: 27.83 samples/s ETA: 1 d 21 h 46 m	Data: 0.007 Tran: 0.006 F: 0.149 B: 0.295 O: 1.836 M: 0.005	Train-MLMAcc=0.604387,	MVRCAccuracy=0.650105,	MLMLossWVC=1.950519,	MVRCLoss=2.499864,	
Rank[  1]Epoch[3] Batch [4300]	Speed: 27.83 samples/s ETA: 1 d 21 h 46 m	Data: 1.789 Tran: 0.007 F: 0.151 B: 0.293 O: 0.054 M: 0.005	Train-MLMAcc=0.604387,	MVRCAccuracy=0.650105,	MLMLossWVC=1.950519,	MVRCLoss=2.499864,	
Rank[  0]Epoch[3] Batch [4300]	Speed: 27.83 samples/s ETA: 1 d 21 h 46 m	Data: 0.460 Tran: 0.007 F: 0.150 B: 0.293 O: 1.384 M: 0.005	Train-MLMAcc=0.604387,	MVRCAccuracy=0.650105,	MLMLossWVC=1.950519,	MVRCLoss=2.499864,	
Rank[  3]Epoch[3] Batch [4300]	Speed: 27.83 samples/s ETA: 1 d 21 h 46 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.295 O: 1.835 M: 0.005	Train-MLMAcc=0.604387,	MVRCAccuracy=0.650105,	MLMLossWVC=1.950519,	MVRCLoss=2.499864,	
Rank[  1]Epoch[3] Batch [4400]	Speed: 27.53 samples/s ETA: 1 d 22 h 12 m	Data: 1.448 Tran: 0.007 F: 0.151 B: 0.295 O: 0.418 M: 0.005	Train-MLMAcc=0.604412,	MVRCAccuracy=0.650154,	MLMLossWVC=1.950518,	MVRCLoss=2.499664,	
Rank[  2]Epoch[3] Batch [4400]	Speed: 27.53 samples/s ETA: 1 d 22 h 12 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.858 M: 0.005	Train-MLMAcc=0.604412,	MVRCAccuracy=0.650154,	MLMLossWVC=1.950518,	MVRCLoss=2.499664,	
Rank[  3]Epoch[3] Batch [4400]	Speed: 27.53 samples/s ETA: 1 d 22 h 12 m	Data: 0.232 Tran: 0.007 F: 0.149 B: 0.295 O: 1.636 M: 0.006	Train-MLMAcc=0.604412,	MVRCAccuracy=0.650154,	MLMLossWVC=1.950518,	MVRCLoss=2.499664,	
Rank[  0]Epoch[3] Batch [4400]	Speed: 27.53 samples/s ETA: 1 d 22 h 12 m	Data: 1.212 Tran: 0.007 F: 0.150 B: 0.293 O: 0.658 M: 0.005	Train-MLMAcc=0.604412,	MVRCAccuracy=0.650154,	MLMLossWVC=1.950518,	MVRCLoss=2.499664,	
Rank[  0]Epoch[3] Batch [4500]	Speed: 27.78 samples/s ETA: 1 d 21 h 43 m	Data: 1.257 Tran: 0.007 F: 0.150 B: 0.292 O: 0.589 M: 0.007	Train-MLMAcc=0.604416,	MVRCAccuracy=0.650187,	MLMLossWVC=1.950399,	MVRCLoss=2.499501,	
Rank[  3]Epoch[3] Batch [4500]	Speed: 27.78 samples/s ETA: 1 d 21 h 43 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.837 M: 0.006	Train-MLMAcc=0.604416,	MVRCAccuracy=0.650187,	MLMLossWVC=1.950399,	MVRCLoss=2.499501,	
Rank[  1]Epoch[3] Batch [4500]	Speed: 27.78 samples/s ETA: 1 d 21 h 43 m	Data: 1.782 Tran: 0.007 F: 0.151 B: 0.294 O: 0.060 M: 0.007	Train-MLMAcc=0.604416,	MVRCAccuracy=0.650187,	MLMLossWVC=1.950399,	MVRCLoss=2.499501,	
Rank[  2]Epoch[3] Batch [4500]	Speed: 27.78 samples/s ETA: 1 d 21 h 43 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.295 O: 1.836 M: 0.007	Train-MLMAcc=0.604416,	MVRCAccuracy=0.650187,	MLMLossWVC=1.950399,	MVRCLoss=2.499501,	
Rank[  2]Epoch[3] Batch [4600]	Speed: 27.89 samples/s ETA: 1 d 21 h 29 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.825 M: 0.007	Train-MLMAcc=0.604403,	MVRCAccuracy=0.650247,	MLMLossWVC=1.950116,	MVRCLoss=2.499369,	
Rank[  0]Epoch[3] Batch [4600]	Speed: 27.89 samples/s ETA: 1 d 21 h 29 m	Data: 1.438 Tran: 0.007 F: 0.150 B: 0.292 O: 0.400 M: 0.007	Train-MLMAcc=0.604403,	MVRCAccuracy=0.650247,	MLMLossWVC=1.950116,	MVRCLoss=2.499369,	
Rank[  3]Epoch[3] Batch [4600]	Speed: 27.89 samples/s ETA: 1 d 21 h 29 m	Data: 0.016 Tran: 0.007 F: 0.150 B: 0.298 O: 1.816 M: 0.006	Train-MLMAcc=0.604403,	MVRCAccuracy=0.650247,	MLMLossWVC=1.950116,	MVRCLoss=2.499369,	
Rank[  1]Epoch[3] Batch [4600]	Speed: 27.89 samples/s ETA: 1 d 21 h 29 m	Data: 1.495 Tran: 0.007 F: 0.150 B: 0.292 O: 0.343 M: 0.007	Train-MLMAcc=0.604403,	MVRCAccuracy=0.650247,	MLMLossWVC=1.950116,	MVRCLoss=2.499369,	
Rank[  1]Epoch[3] Batch [4700]	Speed: 27.63 samples/s ETA: 1 d 21 h 51 m	Data: 0.921 Tran: 0.007 F: 0.151 B: 0.297 O: 0.930 M: 0.010	Train-MLMAcc=0.604431,	MVRCAccuracy=0.650275,	MLMLossWVC=1.950009,	MVRCLoss=2.499348,	
Rank[  3]Epoch[3] Batch [4700]	Speed: 27.63 samples/s ETA: 1 d 21 h 51 m	Data: 0.022 Tran: 0.007 F: 0.149 B: 0.298 O: 1.830 M: 0.010	Train-MLMAcc=0.604431,	MVRCAccuracy=0.650275,	MLMLossWVC=1.950009,	MVRCLoss=2.499348,	
Rank[  0]Epoch[3] Batch [4700]	Speed: 27.63 samples/s ETA: 1 d 21 h 51 m	Data: 1.267 Tran: 0.006 F: 0.152 B: 0.295 O: 0.589 M: 0.006	Train-MLMAcc=0.604431,	MVRCAccuracy=0.650275,	MLMLossWVC=1.950009,	MVRCLoss=2.499348,	
Rank[  2]Epoch[3] Batch [4700]	Speed: 27.63 samples/s ETA: 1 d 21 h 51 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.848 M: 0.006	Train-MLMAcc=0.604431,	MVRCAccuracy=0.650275,	MLMLossWVC=1.950009,	MVRCLoss=2.499348,	
Rank[  3]Epoch[3] Batch [4800]	Speed: 27.75 samples/s ETA: 1 d 21 h 34 m	Data: 0.015 Tran: 0.007 F: 0.151 B: 0.300 O: 1.824 M: 0.008	Train-MLMAcc=0.604516,	MVRCAccuracy=0.650344,	MLMLossWVC=1.949677,	MVRCLoss=2.499094,	
Rank[  2]Epoch[3] Batch [4800]	Speed: 27.75 samples/s ETA: 1 d 21 h 34 m	Data: 0.023 Tran: 0.007 F: 0.155 B: 0.300 O: 1.812 M: 0.007	Train-MLMAcc=0.604516,	MVRCAccuracy=0.650344,	MLMLossWVC=1.949677,	MVRCLoss=2.499094,	
Rank[  1]Epoch[3] Batch [4800]	Speed: 27.75 samples/s ETA: 1 d 21 h 34 m	Data: 0.641 Tran: 0.007 F: 0.156 B: 0.294 O: 1.199 M: 0.007	Train-MLMAcc=0.604516,	MVRCAccuracy=0.650344,	MLMLossWVC=1.949677,	MVRCLoss=2.499094,	
Rank[  0]Epoch[3] Batch [4800]	Speed: 27.75 samples/s ETA: 1 d 21 h 34 m	Data: 1.190 Tran: 0.007 F: 0.179 B: 0.305 O: 0.617 M: 0.007	Train-MLMAcc=0.604516,	MVRCAccuracy=0.650344,	MLMLossWVC=1.949677,	MVRCLoss=2.499094,	
Rank[  0]Epoch[3] Batch [4900]	Speed: 27.58 samples/s ETA: 1 d 21 h 48 m	Data: 1.301 Tran: 0.007 F: 0.149 B: 0.291 O: 0.566 M: 0.006	Train-MLMAcc=0.604490,	MVRCAccuracy=0.650392,	MLMLossWVC=1.949416,	MVRCLoss=2.498971,	
Rank[  1]Epoch[3] Batch [4900]	Speed: 27.58 samples/s ETA: 1 d 21 h 48 m	Data: 0.295 Tran: 0.007 F: 0.151 B: 0.296 O: 1.565 M: 0.007	Train-MLMAcc=0.604490,	MVRCAccuracy=0.650392,	MLMLossWVC=1.949416,	MVRCLoss=2.498971,	
Rank[  3]Epoch[3] Batch [4900]	Speed: 27.58 samples/s ETA: 1 d 21 h 48 m	Data: 0.013 Tran: 0.007 F: 0.150 B: 0.299 O: 1.843 M: 0.007	Train-MLMAcc=0.604490,	MVRCAccuracy=0.650392,	MLMLossWVC=1.949416,	MVRCLoss=2.498971,	
Rank[  2]Epoch[3] Batch [4900]	Speed: 27.58 samples/s ETA: 1 d 21 h 48 m	Data: 0.960 Tran: 0.007 F: 0.150 B: 0.295 O: 0.902 M: 0.006	Train-MLMAcc=0.604490,	MVRCAccuracy=0.650392,	MLMLossWVC=1.949416,	MVRCLoss=2.498971,	
Rank[  0]Epoch[3] Batch [5000]	Speed: 27.69 samples/s ETA: 1 d 21 h 33 m	Data: 0.276 Tran: 0.007 F: 0.149 B: 0.291 O: 1.577 M: 0.012	Train-MLMAcc=0.604614,	MVRCAccuracy=0.650467,	MLMLossWVC=1.948882,	MVRCLoss=2.498821,	
Rank[  1]Epoch[3] Batch [5000]	Speed: 27.69 samples/s ETA: 1 d 21 h 33 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.296 O: 1.841 M: 0.009	Train-MLMAcc=0.604614,	MVRCAccuracy=0.650467,	MLMLossWVC=1.948882,	MVRCLoss=2.498821,	
Rank[  2]Epoch[3] Batch [5000]	Speed: 27.69 samples/s ETA: 1 d 21 h 33 m	Data: 1.504 Tran: 0.007 F: 0.151 B: 0.298 O: 0.340 M: 0.011	Train-MLMAcc=0.604614,	MVRCAccuracy=0.650467,	MLMLossWVC=1.948882,	MVRCLoss=2.498821,	
Rank[  3]Epoch[3] Batch [5000]	Speed: 27.69 samples/s ETA: 1 d 21 h 33 m	Data: 0.039 Tran: 0.007 F: 0.151 B: 0.299 O: 1.803 M: 0.012	Train-MLMAcc=0.604614,	MVRCAccuracy=0.650467,	MLMLossWVC=1.948882,	MVRCLoss=2.498821,	
Rank[  1]Epoch[3] Batch [5100]	Speed: 27.71 samples/s ETA: 1 d 21 h 27 m	Data: 0.008 Tran: 0.008 F: 0.151 B: 0.296 O: 1.840 M: 0.006	Train-MLMAcc=0.604626,	MVRCAccuracy=0.650470,	MLMLossWVC=1.948710,	MVRCLoss=2.498752,	
Rank[  3]Epoch[3] Batch [5100]	Speed: 27.71 samples/s ETA: 1 d 21 h 27 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.295 O: 1.843 M: 0.006	Train-MLMAcc=0.604626,	MVRCAccuracy=0.650470,	MLMLossWVC=1.948710,	MVRCLoss=2.498752,	
Rank[  0]Epoch[3] Batch [5100]	Speed: 27.71 samples/s ETA: 1 d 21 h 27 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.290 O: 1.847 M: 0.007	Train-MLMAcc=0.604626,	MVRCAccuracy=0.650470,	MLMLossWVC=1.948710,	MVRCLoss=2.498752,	
Rank[  2]Epoch[3] Batch [5100]	Speed: 27.71 samples/s ETA: 1 d 21 h 27 m	Data: 1.797 Tran: 0.007 F: 0.151 B: 0.297 O: 0.052 M: 0.006	Train-MLMAcc=0.604626,	MVRCAccuracy=0.650470,	MLMLossWVC=1.948710,	MVRCLoss=2.498752,	
Rank[  0]Epoch[3] Batch [5200]	Speed: 27.69 samples/s ETA: 1 d 21 h 25 m	Data: 0.326 Tran: 0.007 F: 0.150 B: 0.292 O: 1.529 M: 0.007	Train-MLMAcc=0.604678,	MVRCAccuracy=0.650558,	MLMLossWVC=1.948517,	MVRCLoss=2.498499,	
Rank[  3]Epoch[3] Batch [5200]	Speed: 27.69 samples/s ETA: 1 d 21 h 25 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.297 O: 1.841 M: 0.006	Train-MLMAcc=0.604678,	MVRCAccuracy=0.650558,	MLMLossWVC=1.948517,	MVRCLoss=2.498499,	
Rank[  2]Epoch[3] Batch [5200]	Speed: 27.69 samples/s ETA: 1 d 21 h 25 m	Data: 1.481 Tran: 0.007 F: 0.151 B: 0.298 O: 0.365 M: 0.007	Train-MLMAcc=0.604678,	MVRCAccuracy=0.650558,	MLMLossWVC=1.948517,	MVRCLoss=2.498499,	
Rank[  1]Epoch[3] Batch [5200]	Speed: 27.69 samples/s ETA: 1 d 21 h 25 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.294 O: 1.844 M: 0.006	Train-MLMAcc=0.604678,	MVRCAccuracy=0.650558,	MLMLossWVC=1.948517,	MVRCLoss=2.498499,	
Rank[  3]Epoch[3] Batch [5300]	Speed: 27.99 samples/s ETA: 1 d 20 h 52 m	Data: 0.065 Tran: 0.007 F: 0.150 B: 0.297 O: 1.759 M: 0.007	Train-MLMAcc=0.604762,	MVRCAccuracy=0.650639,	MLMLossWVC=1.948004,	MVRCLoss=2.498219,	
Rank[  1]Epoch[3] Batch [5300]	Speed: 27.99 samples/s ETA: 1 d 20 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.817 M: 0.009	Train-MLMAcc=0.604762,	MVRCAccuracy=0.650639,	MLMLossWVC=1.948004,	MVRCLoss=2.498219,	
Rank[  2]Epoch[3] Batch [5300]	Speed: 27.99 samples/s ETA: 1 d 20 h 52 m	Data: 1.573 Tran: 0.007 F: 0.150 B: 0.296 O: 0.252 M: 0.008	Train-MLMAcc=0.604762,	MVRCAccuracy=0.650639,	MLMLossWVC=1.948004,	MVRCLoss=2.498219,	
Rank[  0]Epoch[3] Batch [5300]	Speed: 27.99 samples/s ETA: 1 d 20 h 52 m	Data: 0.169 Tran: 0.007 F: 0.150 B: 0.293 O: 1.659 M: 0.007	Train-MLMAcc=0.604762,	MVRCAccuracy=0.650639,	MLMLossWVC=1.948004,	MVRCLoss=2.498219,	
Rank[  2]Epoch[3] Batch [5400]	Speed: 27.90 samples/s ETA: 1 d 20 h 57 m	Data: 1.455 Tran: 0.007 F: 0.151 B: 0.298 O: 0.377 M: 0.006	Train-MLMAcc=0.604753,	MVRCAccuracy=0.650746,	MLMLossWVC=1.948107,	MVRCLoss=2.497996,	
Rank[  0]Epoch[3] Batch [5400]	Speed: 27.90 samples/s ETA: 1 d 20 h 57 m	Data: 0.130 Tran: 0.007 F: 0.149 B: 0.292 O: 1.708 M: 0.006	Train-MLMAcc=0.604753,	MVRCAccuracy=0.650746,	MLMLossWVC=1.948107,	MVRCLoss=2.497996,	
Rank[  1]Epoch[3] Batch [5400]	Speed: 27.90 samples/s ETA: 1 d 20 h 57 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.826 M: 0.007	Train-MLMAcc=0.604753,	MVRCAccuracy=0.650746,	MLMLossWVC=1.948107,	MVRCLoss=2.497996,	
Rank[  3]Epoch[3] Batch [5400]	Speed: 27.90 samples/s ETA: 1 d 20 h 57 m	Data: 0.221 Tran: 0.007 F: 0.150 B: 0.298 O: 1.611 M: 0.005	Train-MLMAcc=0.604753,	MVRCAccuracy=0.650746,	MLMLossWVC=1.948107,	MVRCLoss=2.497996,	
Rank[  2]Epoch[3] Batch [5500]	Speed: 27.88 samples/s ETA: 1 d 20 h 55 m	Data: 0.224 Tran: 0.007 F: 0.151 B: 0.299 O: 1.606 M: 0.008	Train-MLMAcc=0.604732,	MVRCAccuracy=0.650834,	MLMLossWVC=1.948314,	MVRCLoss=2.497612,	
Rank[  0]Epoch[3] Batch [5500]	Speed: 27.88 samples/s ETA: 1 d 20 h 55 m	Data: 1.136 Tran: 0.007 F: 0.150 B: 0.293 O: 0.702 M: 0.006	Train-MLMAcc=0.604732,	MVRCAccuracy=0.650834,	MLMLossWVC=1.948314,	MVRCLoss=2.497612,	
Rank[  1]Epoch[3] Batch [5500]	Speed: 27.88 samples/s ETA: 1 d 20 h 55 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.295 O: 1.829 M: 0.008	Train-MLMAcc=0.604732,	MVRCAccuracy=0.650834,	MLMLossWVC=1.948314,	MVRCLoss=2.497612,	
Rank[  3]Epoch[3] Batch [5500]	Speed: 27.88 samples/s ETA: 1 d 20 h 55 m	Data: 0.580 Tran: 0.007 F: 0.150 B: 0.296 O: 1.254 M: 0.008	Train-MLMAcc=0.604732,	MVRCAccuracy=0.650834,	MLMLossWVC=1.948314,	MVRCLoss=2.497612,	
Rank[  0]Epoch[3] Batch [5600]	Speed: 28.06 samples/s ETA: 1 d 20 h 34 m	Data: 1.429 Tran: 0.007 F: 0.151 B: 0.294 O: 0.393 M: 0.007	Train-MLMAcc=0.604806,	MVRCAccuracy=0.650866,	MLMLossWVC=1.947935,	MVRCLoss=2.497508,	
Rank[  1]Epoch[3] Batch [5600]	Speed: 28.06 samples/s ETA: 1 d 20 h 34 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.814 M: 0.007	Train-MLMAcc=0.604806,	MVRCAccuracy=0.650866,	MLMLossWVC=1.947935,	MVRCLoss=2.497508,	
Rank[  3]Epoch[3] Batch [5600]	Speed: 28.06 samples/s ETA: 1 d 20 h 34 m	Data: 0.367 Tran: 0.007 F: 0.151 B: 0.298 O: 1.450 M: 0.008	Train-MLMAcc=0.604806,	MVRCAccuracy=0.650866,	MLMLossWVC=1.947935,	MVRCLoss=2.497508,	
Rank[  2]Epoch[3] Batch [5600]	Speed: 28.06 samples/s ETA: 1 d 20 h 34 m	Data: 0.149 Tran: 0.006 F: 0.150 B: 0.298 O: 1.669 M: 0.008	Train-MLMAcc=0.604806,	MVRCAccuracy=0.650866,	MLMLossWVC=1.947935,	MVRCLoss=2.497508,	
Rank[  3]Epoch[3] Batch [5700]	Speed: 27.91 samples/s ETA: 1 d 20 h 45 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.822 M: 0.008	Train-MLMAcc=0.604852,	MVRCAccuracy=0.650925,	MLMLossWVC=1.947726,	MVRCLoss=2.497268,	
Rank[  0]Epoch[3] Batch [5700]	Speed: 27.91 samples/s ETA: 1 d 20 h 45 m	Data: 1.757 Tran: 0.007 F: 0.151 B: 0.293 O: 0.078 M: 0.006	Train-MLMAcc=0.604852,	MVRCAccuracy=0.650925,	MLMLossWVC=1.947726,	MVRCLoss=2.497268,	
Rank[  1]Epoch[3] Batch [5700]	Speed: 27.91 samples/s ETA: 1 d 20 h 45 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.825 M: 0.008	Train-MLMAcc=0.604852,	MVRCAccuracy=0.650925,	MLMLossWVC=1.947726,	MVRCLoss=2.497268,	
Rank[  2]Epoch[3] Batch [5700]	Speed: 27.91 samples/s ETA: 1 d 20 h 45 m	Data: 0.032 Tran: 0.007 F: 0.149 B: 0.296 O: 1.801 M: 0.007	Train-MLMAcc=0.604852,	MVRCAccuracy=0.650925,	MLMLossWVC=1.947726,	MVRCLoss=2.497268,	
Rank[  1]Epoch[3] Batch [5800]	Speed: 26.31 samples/s ETA: 1 d 23 h 24 m	Data: 0.010 Tran: 0.007 F: 0.162 B: 0.313 O: 1.927 M: 0.012	Train-MLMAcc=0.604877,	MVRCAccuracy=0.650971,	MLMLossWVC=1.947569,	MVRCLoss=2.497028,	
Rank[  2]Epoch[3] Batch [5800]	Speed: 26.31 samples/s ETA: 1 d 23 h 24 m	Data: 0.279 Tran: 0.006 F: 0.161 B: 0.315 O: 1.656 M: 0.012	Train-MLMAcc=0.604877,	MVRCAccuracy=0.650971,	MLMLossWVC=1.947569,	MVRCLoss=2.497028,	
Rank[  3]Epoch[3] Batch [5800]	Speed: 26.31 samples/s ETA: 1 d 23 h 24 m	Data: 0.010 Tran: 0.007 F: 0.160 B: 0.314 O: 1.927 M: 0.012	Train-MLMAcc=0.604877,	MVRCAccuracy=0.650971,	MLMLossWVC=1.947569,	MVRCLoss=2.497028,	
Rank[  0]Epoch[3] Batch [5800]	Speed: 26.31 samples/s ETA: 1 d 23 h 24 m	Data: 1.560 Tran: 0.011 F: 0.189 B: 0.322 O: 0.337 M: 0.010	Train-MLMAcc=0.604877,	MVRCAccuracy=0.650971,	MLMLossWVC=1.947569,	MVRCLoss=2.497028,	
Rank[  0]Epoch[3] Batch [5900]	Speed: 25.64 samples/s ETA: 2 d  0 h 34 m	Data: 1.849 Tran: 0.011 F: 0.197 B: 0.341 O: 0.076 M: 0.020	Train-MLMAcc=0.604851,	MVRCAccuracy=0.651078,	MLMLossWVC=1.947532,	MVRCLoss=2.496977,	
Rank[  2]Epoch[3] Batch [5900]	Speed: 25.64 samples/s ETA: 2 d  0 h 34 m	Data: 0.010 Tran: 0.008 F: 0.177 B: 0.332 O: 1.947 M: 0.020	Train-MLMAcc=0.604851,	MVRCAccuracy=0.651078,	MLMLossWVC=1.947532,	MVRCLoss=2.496977,	
Rank[  3]Epoch[3] Batch [5900]	Speed: 25.64 samples/s ETA: 2 d  0 h 34 m	Data: 0.010 Tran: 0.008 F: 0.177 B: 0.343 O: 1.937 M: 0.019	Train-MLMAcc=0.604851,	MVRCAccuracy=0.651078,	MLMLossWVC=1.947532,	MVRCLoss=2.496977,	
Rank[  1]Epoch[3] Batch [5900]	Speed: 25.64 samples/s ETA: 2 d  0 h 34 m	Data: 0.011 Tran: 0.007 F: 0.177 B: 0.339 O: 1.940 M: 0.020	Train-MLMAcc=0.604851,	MVRCAccuracy=0.651078,	MLMLossWVC=1.947532,	MVRCLoss=2.496977,	
Rank[  3]Epoch[3] Batch [6000]	Speed: 26.12 samples/s ETA: 1 d 23 h 36 m	Data: 0.115 Tran: 0.008 F: 0.166 B: 0.315 O: 1.834 M: 0.011	Train-MLMAcc=0.604838,	MVRCAccuracy=0.651156,	MLMLossWVC=1.947559,	MVRCLoss=2.496911,	
Rank[  2]Epoch[3] Batch [6000]	Speed: 26.12 samples/s ETA: 1 d 23 h 36 m	Data: 0.010 Tran: 0.009 F: 0.167 B: 0.317 O: 1.937 M: 0.009	Train-MLMAcc=0.604838,	MVRCAccuracy=0.651156,	MLMLossWVC=1.947559,	MVRCLoss=2.496911,	
Rank[  1]Epoch[3] Batch [6000]	Speed: 26.12 samples/s ETA: 1 d 23 h 36 m	Data: 0.011 Tran: 0.008 F: 0.167 B: 0.316 O: 1.938 M: 0.009	Train-MLMAcc=0.604838,	MVRCAccuracy=0.651156,	MLMLossWVC=1.947559,	MVRCLoss=2.496911,	
Rank[  0]Epoch[3] Batch [6000]	Speed: 26.12 samples/s ETA: 1 d 23 h 36 m	Data: 1.781 Tran: 0.007 F: 0.171 B: 0.314 O: 0.164 M: 0.012	Train-MLMAcc=0.604838,	MVRCAccuracy=0.651156,	MLMLossWVC=1.947559,	MVRCLoss=2.496911,	
Rank[  3]Epoch[3] Batch [6100]	Speed: 25.97 samples/s ETA: 1 d 23 h 49 m	Data: 0.541 Tran: 0.008 F: 0.180 B: 0.335 O: 1.388 M: 0.010	Train-MLMAcc=0.604917,	MVRCAccuracy=0.651192,	MLMLossWVC=1.946828,	MVRCLoss=2.496686,	
Rank[  2]Epoch[3] Batch [6100]	Speed: 25.97 samples/s ETA: 1 d 23 h 49 m	Data: 0.011 Tran: 0.008 F: 0.172 B: 0.323 O: 1.939 M: 0.009	Train-MLMAcc=0.604917,	MVRCAccuracy=0.651192,	MLMLossWVC=1.946828,	MVRCLoss=2.496686,	
Rank[  1]Epoch[3] Batch [6100]	Speed: 25.97 samples/s ETA: 1 d 23 h 49 m	Data: 0.011 Tran: 0.008 F: 0.173 B: 0.328 O: 1.932 M: 0.011	Train-MLMAcc=0.604917,	MVRCAccuracy=0.651192,	MLMLossWVC=1.946828,	MVRCLoss=2.496686,	
Rank[  0]Epoch[3] Batch [6100]	Speed: 25.97 samples/s ETA: 1 d 23 h 49 m	Data: 1.303 Tran: 0.010 F: 0.211 B: 0.323 O: 0.606 M: 0.010	Train-MLMAcc=0.604917,	MVRCAccuracy=0.651192,	MLMLossWVC=1.946828,	MVRCLoss=2.496686,	
Rank[  1]Epoch[3] Batch [6200]	Speed: 28.06 samples/s ETA: 1 d 20 h 11 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.811 M: 0.007	Train-MLMAcc=0.605031,	MVRCAccuracy=0.651262,	MLMLossWVC=1.946304,	MVRCLoss=2.496568,	
Rank[  0]Epoch[3] Batch [6200]	Speed: 28.06 samples/s ETA: 1 d 20 h 11 m	Data: 1.665 Tran: 0.006 F: 0.150 B: 0.293 O: 0.157 M: 0.008	Train-MLMAcc=0.605031,	MVRCAccuracy=0.651262,	MLMLossWVC=1.946304,	MVRCLoss=2.496568,	
Rank[  3]Epoch[3] Batch [6200]	Speed: 28.06 samples/s ETA: 1 d 20 h 11 m	Data: 0.280 Tran: 0.007 F: 0.150 B: 0.297 O: 1.539 M: 0.007	Train-MLMAcc=0.605031,	MVRCAccuracy=0.651262,	MLMLossWVC=1.946304,	MVRCLoss=2.496568,	
Rank[  2]Epoch[3] Batch [6200]	Speed: 28.06 samples/s ETA: 1 d 20 h 11 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.811 M: 0.007	Train-MLMAcc=0.605031,	MVRCAccuracy=0.651262,	MLMLossWVC=1.946304,	MVRCLoss=2.496568,	
Rank[  0]Epoch[3] Batch [6300]	Speed: 27.76 samples/s ETA: 1 d 20 h 36 m	Data: 1.101 Tran: 0.006 F: 0.150 B: 0.294 O: 0.748 M: 0.005	Train-MLMAcc=0.605112,	MVRCAccuracy=0.651302,	MLMLossWVC=1.945810,	MVRCLoss=2.496418,	
Rank[  1]Epoch[3] Batch [6300]	Speed: 27.76 samples/s ETA: 1 d 20 h 36 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.837 M: 0.007	Train-MLMAcc=0.605112,	MVRCAccuracy=0.651302,	MLMLossWVC=1.945810,	MVRCLoss=2.496418,	
Rank[  3]Epoch[3] Batch [6300]	Speed: 27.76 samples/s ETA: 1 d 20 h 36 m	Data: 0.706 Tran: 0.007 F: 0.151 B: 0.299 O: 1.136 M: 0.006	Train-MLMAcc=0.605112,	MVRCAccuracy=0.651302,	MLMLossWVC=1.945810,	MVRCLoss=2.496418,	
Rank[  2]Epoch[3] Batch [6300]	Speed: 27.76 samples/s ETA: 1 d 20 h 36 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.836 M: 0.005	Train-MLMAcc=0.605112,	MVRCAccuracy=0.651302,	MLMLossWVC=1.945810,	MVRCLoss=2.496418,	
Rank[  3]Epoch[3] Batch [6400]	Speed: 27.51 samples/s ETA: 1 d 20 h 56 m	Data: 1.539 Tran: 0.011 F: 0.177 B: 0.306 O: 0.282 M: 0.011	Train-MLMAcc=0.605090,	MVRCAccuracy=0.651388,	MLMLossWVC=1.945787,	MVRCLoss=2.496299,	
Rank[  0]Epoch[3] Batch [6400]	Speed: 27.51 samples/s ETA: 1 d 20 h 56 m	Data: 0.231 Tran: 0.007 F: 0.152 B: 0.299 O: 1.626 M: 0.011	Train-MLMAcc=0.605090,	MVRCAccuracy=0.651388,	MLMLossWVC=1.945787,	MVRCLoss=2.496299,	
Rank[  1]Epoch[3] Batch [6400]	Speed: 27.51 samples/s ETA: 1 d 20 h 56 m	Data: 0.009 Tran: 0.007 F: 0.153 B: 0.302 O: 1.845 M: 0.010	Train-MLMAcc=0.605090,	MVRCAccuracy=0.651388,	MLMLossWVC=1.945787,	MVRCLoss=2.496299,	
Rank[  2]Epoch[3] Batch [6400]	Speed: 27.51 samples/s ETA: 1 d 20 h 56 m	Data: 0.009 Tran: 0.007 F: 0.153 B: 0.305 O: 1.845 M: 0.007	Train-MLMAcc=0.605090,	MVRCAccuracy=0.651388,	MLMLossWVC=1.945787,	MVRCLoss=2.496299,	
Rank[  1]Epoch[3] Batch [6500]	Speed: 27.73 samples/s ETA: 1 d 20 h 32 m	Data: 0.016 Tran: 0.007 F: 0.150 B: 0.296 O: 1.828 M: 0.010	Train-MLMAcc=0.605177,	MVRCAccuracy=0.651412,	MLMLossWVC=1.945454,	MVRCLoss=2.496236,	
Rank[  0]Epoch[3] Batch [6500]	Speed: 27.73 samples/s ETA: 1 d 20 h 32 m	Data: 0.904 Tran: 0.006 F: 0.149 B: 0.293 O: 0.945 M: 0.010	Train-MLMAcc=0.605177,	MVRCAccuracy=0.651412,	MLMLossWVC=1.945454,	MVRCLoss=2.496236,	
Rank[  3]Epoch[3] Batch [6500]	Speed: 27.73 samples/s ETA: 1 d 20 h 32 m	Data: 1.389 Tran: 0.007 F: 0.152 B: 0.298 O: 0.455 M: 0.007	Train-MLMAcc=0.605177,	MVRCAccuracy=0.651412,	MLMLossWVC=1.945454,	MVRCLoss=2.496236,	
Rank[  2]Epoch[3] Batch [6500]	Speed: 27.73 samples/s ETA: 1 d 20 h 32 m	Data: 0.020 Tran: 0.007 F: 0.149 B: 0.296 O: 1.827 M: 0.009	Train-MLMAcc=0.605177,	MVRCAccuracy=0.651412,	MLMLossWVC=1.945454,	MVRCLoss=2.496236,	
Rank[  0]Epoch[3] Batch [6600]	Speed: 27.58 samples/s ETA: 1 d 20 h 42 m	Data: 1.303 Tran: 0.007 F: 0.149 B: 0.291 O: 0.563 M: 0.008	Train-MLMAcc=0.605164,	MVRCAccuracy=0.651500,	MLMLossWVC=1.945328,	MVRCLoss=2.496040,	
Rank[  1]Epoch[3] Batch [6600]	Speed: 27.58 samples/s ETA: 1 d 20 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.852 M: 0.007	Train-MLMAcc=0.605164,	MVRCAccuracy=0.651500,	MLMLossWVC=1.945328,	MVRCLoss=2.496040,	
Rank[  3]Epoch[3] Batch [6600]	Speed: 27.58 samples/s ETA: 1 d 20 h 42 m	Data: 1.429 Tran: 0.007 F: 0.150 B: 0.296 O: 0.432 M: 0.006	Train-MLMAcc=0.605164,	MVRCAccuracy=0.651500,	MLMLossWVC=1.945328,	MVRCLoss=2.496040,	
Rank[  2]Epoch[3] Batch [6600]	Speed: 27.58 samples/s ETA: 1 d 20 h 42 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.854 M: 0.006	Train-MLMAcc=0.605164,	MVRCAccuracy=0.651500,	MLMLossWVC=1.945328,	MVRCLoss=2.496040,	
Rank[  1]Epoch[3] Batch [6700]	Speed: 27.46 samples/s ETA: 1 d 20 h 50 m	Data: 0.012 Tran: 0.007 F: 0.162 B: 0.309 O: 1.831 M: 0.009	Train-MLMAcc=0.605242,	MVRCAccuracy=0.651547,	MLMLossWVC=1.944753,	MVRCLoss=2.495946,	
Rank[  3]Epoch[3] Batch [6700]	Speed: 27.46 samples/s ETA: 1 d 20 h 50 m	Data: 1.731 Tran: 0.008 F: 0.152 B: 0.310 O: 0.118 M: 0.010	Train-MLMAcc=0.605242,	MVRCAccuracy=0.651547,	MLMLossWVC=1.944753,	MVRCLoss=2.495946,	
Rank[  2]Epoch[3] Batch [6700]	Speed: 27.46 samples/s ETA: 1 d 20 h 50 m	Data: 0.008 Tran: 0.007 F: 0.167 B: 0.301 O: 1.838 M: 0.010	Train-MLMAcc=0.605242,	MVRCAccuracy=0.651547,	MLMLossWVC=1.944753,	MVRCLoss=2.495946,	
Rank[  0]Epoch[3] Batch [6700]	Speed: 27.46 samples/s ETA: 1 d 20 h 50 m	Data: 0.866 Tran: 0.007 F: 0.152 B: 0.301 O: 0.993 M: 0.010	Train-MLMAcc=0.605242,	MVRCAccuracy=0.651547,	MLMLossWVC=1.944753,	MVRCLoss=2.495946,	
Rank[  1]Epoch[3] Batch [6800]	Speed: 28.10 samples/s ETA: 1 d 19 h 45 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.295 O: 1.807 M: 0.009	Train-MLMAcc=0.605228,	MVRCAccuracy=0.651633,	MLMLossWVC=1.944809,	MVRCLoss=2.495867,	
Rank[  2]Epoch[3] Batch [6800]	Speed: 28.10 samples/s ETA: 1 d 19 h 45 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.810 M: 0.006	Train-MLMAcc=0.605228,	MVRCAccuracy=0.651633,	MLMLossWVC=1.944809,	MVRCLoss=2.495867,	
Rank[  0]Epoch[3] Batch [6800]	Speed: 28.10 samples/s ETA: 1 d 19 h 45 m	Data: 0.784 Tran: 0.007 F: 0.150 B: 0.293 O: 1.033 M: 0.010	Train-MLMAcc=0.605228,	MVRCAccuracy=0.651633,	MLMLossWVC=1.944809,	MVRCLoss=2.495867,	
Rank[  3]Epoch[3] Batch [6800]	Speed: 28.10 samples/s ETA: 1 d 19 h 45 m	Data: 1.761 Tran: 0.008 F: 0.151 B: 0.296 O: 0.051 M: 0.010	Train-MLMAcc=0.605228,	MVRCAccuracy=0.651633,	MLMLossWVC=1.944809,	MVRCLoss=2.495867,	
Rank[  0]Epoch[3] Batch [6900]	Speed: 27.87 samples/s ETA: 1 d 20 h  3 m	Data: 1.117 Tran: 0.007 F: 0.151 B: 0.294 O: 0.717 M: 0.010	Train-MLMAcc=0.605294,	MVRCAccuracy=0.651710,	MLMLossWVC=1.944405,	MVRCLoss=2.495751,	
Rank[  3]Epoch[3] Batch [6900]	Speed: 27.87 samples/s ETA: 1 d 20 h  3 m	Data: 1.708 Tran: 0.007 F: 0.150 B: 0.295 O: 0.126 M: 0.009	Train-MLMAcc=0.605294,	MVRCAccuracy=0.651710,	MLMLossWVC=1.944405,	MVRCLoss=2.495751,	
Rank[  1]Epoch[3] Batch [6900]	Speed: 27.87 samples/s ETA: 1 d 20 h  3 m	Data: 0.055 Tran: 0.007 F: 0.150 B: 0.296 O: 1.779 M: 0.008	Train-MLMAcc=0.605294,	MVRCAccuracy=0.651710,	MLMLossWVC=1.944405,	MVRCLoss=2.495751,	
Rank[  2]Epoch[3] Batch [6900]	Speed: 27.87 samples/s ETA: 1 d 20 h  3 m	Data: 0.356 Tran: 0.007 F: 0.151 B: 0.299 O: 1.478 M: 0.005	Train-MLMAcc=0.605294,	MVRCAccuracy=0.651710,	MLMLossWVC=1.944405,	MVRCLoss=2.495751,	
Rank[  2]Epoch[3] Batch [7000]	Speed: 27.36 samples/s ETA: 1 d 20 h 47 m	Data: 0.197 Tran: 0.007 F: 0.150 B: 0.298 O: 1.681 M: 0.006	Train-MLMAcc=0.605364,	MVRCAccuracy=0.651781,	MLMLossWVC=1.944112,	MVRCLoss=2.495610,	
Rank[  3]Epoch[3] Batch [7000]	Speed: 27.36 samples/s ETA: 1 d 20 h 47 m	Data: 1.413 Tran: 0.006 F: 0.150 B: 0.298 O: 0.464 M: 0.007	Train-MLMAcc=0.605364,	MVRCAccuracy=0.651781,	MLMLossWVC=1.944112,	MVRCLoss=2.495610,	
Rank[  1]Epoch[3] Batch [7000]	Speed: 27.36 samples/s ETA: 1 d 20 h 47 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.870 M: 0.007	Train-MLMAcc=0.605364,	MVRCAccuracy=0.651781,	MLMLossWVC=1.944112,	MVRCLoss=2.495610,	
Rank[  0]Epoch[3] Batch [7000]	Speed: 27.36 samples/s ETA: 1 d 20 h 47 m	Data: 1.510 Tran: 0.006 F: 0.151 B: 0.294 O: 0.371 M: 0.006	Train-MLMAcc=0.605364,	MVRCAccuracy=0.651781,	MLMLossWVC=1.944112,	MVRCLoss=2.495610,	
Rank[  0]Epoch[3] Batch [7100]	Speed: 27.18 samples/s ETA: 1 d 21 h  2 m	Data: 0.757 Tran: 0.007 F: 0.150 B: 0.292 O: 1.141 M: 0.007	Train-MLMAcc=0.605364,	MVRCAccuracy=0.651815,	MLMLossWVC=1.943933,	MVRCLoss=2.495508,	
Rank[  2]Epoch[3] Batch [7100]	Speed: 27.18 samples/s ETA: 1 d 21 h  2 m	Data: 0.112 Tran: 0.007 F: 0.150 B: 0.298 O: 1.780 M: 0.008	Train-MLMAcc=0.605364,	MVRCAccuracy=0.651815,	MLMLossWVC=1.943933,	MVRCLoss=2.495508,	
Rank[  1]Epoch[3] Batch [7100]	Speed: 27.18 samples/s ETA: 1 d 21 h  2 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.887 M: 0.007	Train-MLMAcc=0.605364,	MVRCAccuracy=0.651815,	MLMLossWVC=1.943933,	MVRCLoss=2.495508,	
Rank[  3]Epoch[3] Batch [7100]	Speed: 27.18 samples/s ETA: 1 d 21 h  2 m	Data: 1.685 Tran: 0.007 F: 0.151 B: 0.300 O: 0.205 M: 0.006	Train-MLMAcc=0.605364,	MVRCAccuracy=0.651815,	MLMLossWVC=1.943933,	MVRCLoss=2.495508,	
Rank[  0]Epoch[3] Batch [7200]	Speed: 27.30 samples/s ETA: 1 d 20 h 46 m	Data: 0.299 Tran: 0.007 F: 0.149 B: 0.290 O: 1.588 M: 0.009	Train-MLMAcc=0.605440,	MVRCAccuracy=0.651862,	MLMLossWVC=1.943613,	MVRCLoss=2.495291,	
Rank[  3]Epoch[3] Batch [7200]	Speed: 27.30 samples/s ETA: 1 d 20 h 46 m	Data: 1.777 Tran: 0.007 F: 0.150 B: 0.298 O: 0.102 M: 0.010	Train-MLMAcc=0.605440,	MVRCAccuracy=0.651862,	MLMLossWVC=1.943613,	MVRCLoss=2.495291,	
Rank[  2]Epoch[3] Batch [7200]	Speed: 27.30 samples/s ETA: 1 d 20 h 46 m	Data: 0.009 Tran: 0.007 F: 0.150 B: 0.296 O: 1.874 M: 0.008	Train-MLMAcc=0.605440,	MVRCAccuracy=0.651862,	MLMLossWVC=1.943613,	MVRCLoss=2.495291,	
Rank[  1]Epoch[3] Batch [7200]	Speed: 27.30 samples/s ETA: 1 d 20 h 46 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.877 M: 0.008	Train-MLMAcc=0.605440,	MVRCAccuracy=0.651862,	MLMLossWVC=1.943613,	MVRCLoss=2.495291,	
Rank[  2]Epoch[3] Batch [7300]	Speed: 27.41 samples/s ETA: 1 d 20 h 31 m	Data: 0.033 Tran: 0.006 F: 0.149 B: 0.296 O: 1.842 M: 0.007	Train-MLMAcc=0.605460,	MVRCAccuracy=0.651896,	MLMLossWVC=1.943216,	MVRCLoss=2.495125,	
Rank[  0]Epoch[3] Batch [7300]	Speed: 27.41 samples/s ETA: 1 d 20 h 31 m	Data: 0.152 Tran: 0.007 F: 0.150 B: 0.293 O: 1.726 M: 0.007	Train-MLMAcc=0.605460,	MVRCAccuracy=0.651896,	MLMLossWVC=1.943216,	MVRCLoss=2.495125,	
Rank[  1]Epoch[3] Batch [7300]	Speed: 27.41 samples/s ETA: 1 d 20 h 31 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.295 O: 1.867 M: 0.008	Train-MLMAcc=0.605460,	MVRCAccuracy=0.651896,	MLMLossWVC=1.943216,	MVRCLoss=2.495125,	
Rank[  3]Epoch[3] Batch [7300]	Speed: 27.41 samples/s ETA: 1 d 20 h 31 m	Data: 1.799 Tran: 0.006 F: 0.151 B: 0.299 O: 0.072 M: 0.008	Train-MLMAcc=0.605460,	MVRCAccuracy=0.651896,	MLMLossWVC=1.943216,	MVRCLoss=2.495125,	
Rank[  2]Epoch[3] Batch [7400]	Speed: 27.80 samples/s ETA: 1 d 19 h 50 m	Data: 0.007 Tran: 0.006 F: 0.150 B: 0.298 O: 1.831 M: 0.009	Train-MLMAcc=0.605449,	MVRCAccuracy=0.651954,	MLMLossWVC=1.943264,	MVRCLoss=2.495004,	
Rank[  3]Epoch[3] Batch [7400]	Speed: 27.80 samples/s ETA: 1 d 19 h 50 m	Data: 1.792 Tran: 0.007 F: 0.150 B: 0.296 O: 0.051 M: 0.005	Train-MLMAcc=0.605449,	MVRCAccuracy=0.651954,	MLMLossWVC=1.943264,	MVRCLoss=2.495004,	
Rank[  0]Epoch[3] Batch [7400]	Speed: 27.80 samples/s ETA: 1 d 19 h 50 m	Data: 0.137 Tran: 0.007 F: 0.149 B: 0.292 O: 1.708 M: 0.009	Train-MLMAcc=0.605449,	MVRCAccuracy=0.651954,	MLMLossWVC=1.943264,	MVRCLoss=2.495004,	
Rank[  1]Epoch[3] Batch [7400]	Speed: 27.80 samples/s ETA: 1 d 19 h 50 m	Data: 0.007 Tran: 0.006 F: 0.151 B: 0.297 O: 1.834 M: 0.007	Train-MLMAcc=0.605449,	MVRCAccuracy=0.651954,	MLMLossWVC=1.943264,	MVRCLoss=2.495004,	
Rank[  1]Epoch[3] Batch [7500]	Speed: 27.55 samples/s ETA: 1 d 20 h 10 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.294 O: 1.858 M: 0.006	Train-MLMAcc=0.605567,	MVRCAccuracy=0.652004,	MLMLossWVC=1.942664,	MVRCLoss=2.494893,	
Rank[  3]Epoch[3] Batch [7500]	Speed: 27.55 samples/s ETA: 1 d 20 h 10 m	Data: 1.811 Tran: 0.007 F: 0.151 B: 0.298 O: 0.049 M: 0.006	Train-MLMAcc=0.605567,	MVRCAccuracy=0.652004,	MLMLossWVC=1.942664,	MVRCLoss=2.494893,	
Rank[  0]Epoch[3] Batch [7500]	Speed: 27.55 samples/s ETA: 1 d 20 h 10 m	Data: 0.009 Tran: 0.007 F: 0.150 B: 0.293 O: 1.855 M: 0.007	Train-MLMAcc=0.605567,	MVRCAccuracy=0.652004,	MLMLossWVC=1.942664,	MVRCLoss=2.494893,	
Rank[  2]Epoch[3] Batch [7500]	Speed: 27.55 samples/s ETA: 1 d 20 h 10 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.851 M: 0.008	Train-MLMAcc=0.605567,	MVRCAccuracy=0.652004,	MLMLossWVC=1.942664,	MVRCLoss=2.494893,	
Rank[  1]Epoch[3] Batch [7600]	Speed: 27.87 samples/s ETA: 1 d 19 h 36 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.294 O: 1.827 M: 0.009	Train-MLMAcc=0.605566,	MVRCAccuracy=0.652050,	MLMLossWVC=1.942559,	MVRCLoss=2.494843,	
Rank[  2]Epoch[3] Batch [7600]	Speed: 27.87 samples/s ETA: 1 d 19 h 36 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.827 M: 0.007	Train-MLMAcc=0.605566,	MVRCAccuracy=0.652050,	MLMLossWVC=1.942559,	MVRCLoss=2.494843,	
Rank[  3]Epoch[3] Batch [7600]	Speed: 27.87 samples/s ETA: 1 d 19 h 36 m	Data: 1.605 Tran: 0.007 F: 0.151 B: 0.297 O: 0.227 M: 0.008	Train-MLMAcc=0.605566,	MVRCAccuracy=0.652050,	MLMLossWVC=1.942559,	MVRCLoss=2.494843,	
Rank[  0]Epoch[3] Batch [7600]	Speed: 27.87 samples/s ETA: 1 d 19 h 36 m	Data: 0.189 Tran: 0.007 F: 0.150 B: 0.293 O: 1.650 M: 0.008	Train-MLMAcc=0.605566,	MVRCAccuracy=0.652050,	MLMLossWVC=1.942559,	MVRCLoss=2.494843,	
Rank[  0]Epoch[3] Batch [7700]	Speed: 27.85 samples/s ETA: 1 d 19 h 34 m	Data: 1.350 Tran: 0.006 F: 0.150 B: 0.293 O: 0.490 M: 0.008	Train-MLMAcc=0.605546,	MVRCAccuracy=0.652092,	MLMLossWVC=1.942593,	MVRCLoss=2.494757,	
Rank[  3]Epoch[3] Batch [7700]	Speed: 27.85 samples/s ETA: 1 d 19 h 34 m	Data: 1.056 Tran: 0.007 F: 0.150 B: 0.295 O: 0.781 M: 0.008	Train-MLMAcc=0.605546,	MVRCAccuracy=0.652092,	MLMLossWVC=1.942593,	MVRCLoss=2.494757,	
Rank[  1]Epoch[3] Batch [7700]	Speed: 27.85 samples/s ETA: 1 d 19 h 34 m	Data: 0.123 Tran: 0.007 F: 0.150 B: 0.295 O: 1.715 M: 0.008	Train-MLMAcc=0.605546,	MVRCAccuracy=0.652092,	MLMLossWVC=1.942593,	MVRCLoss=2.494757,	
Rank[  2]Epoch[3] Batch [7700]	Speed: 27.85 samples/s ETA: 1 d 19 h 34 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.830 M: 0.007	Train-MLMAcc=0.605546,	MVRCAccuracy=0.652092,	MLMLossWVC=1.942593,	MVRCLoss=2.494757,	
Rank[  2]Epoch[3] Batch [7800]	Speed: 27.56 samples/s ETA: 1 d 19 h 58 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.855 M: 0.007	Train-MLMAcc=0.605619,	MVRCAccuracy=0.652127,	MLMLossWVC=1.942391,	MVRCLoss=2.494699,	
Rank[  1]Epoch[3] Batch [7800]	Speed: 27.56 samples/s ETA: 1 d 19 h 58 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.295 O: 1.853 M: 0.008	Train-MLMAcc=0.605619,	MVRCAccuracy=0.652127,	MLMLossWVC=1.942391,	MVRCLoss=2.494699,	
Rank[  0]Epoch[3] Batch [7800]	Speed: 27.56 samples/s ETA: 1 d 19 h 58 m	Data: 1.798 Tran: 0.006 F: 0.150 B: 0.291 O: 0.065 M: 0.012	Train-MLMAcc=0.605619,	MVRCAccuracy=0.652127,	MLMLossWVC=1.942391,	MVRCLoss=2.494699,	
Rank[  3]Epoch[3] Batch [7800]	Speed: 27.56 samples/s ETA: 1 d 19 h 58 m	Data: 0.827 Tran: 0.007 F: 0.150 B: 0.296 O: 1.031 M: 0.011	Train-MLMAcc=0.605619,	MVRCAccuracy=0.652127,	MLMLossWVC=1.942391,	MVRCLoss=2.494699,	
Rank[  1]Epoch[3] Batch [7900]	Speed: 23.91 samples/s ETA: 2 d  2 h 35 m	Data: 0.017 Tran: 0.008 F: 0.195 B: 0.386 O: 2.049 M: 0.019	Train-MLMAcc=0.605633,	MVRCAccuracy=0.652187,	MLMLossWVC=1.942302,	MVRCLoss=2.494478,	
Rank[  2]Epoch[3] Batch [7900]	Speed: 23.91 samples/s ETA: 2 d  2 h 35 m	Data: 0.017 Tran: 0.008 F: 0.192 B: 0.391 O: 2.047 M: 0.018	Train-MLMAcc=0.605633,	MVRCAccuracy=0.652187,	MLMLossWVC=1.942302,	MVRCLoss=2.494478,	
Rank[  3]Epoch[3] Batch [7900]	Speed: 23.91 samples/s ETA: 2 d  2 h 35 m	Data: 1.323 Tran: 0.013 F: 0.253 B: 0.386 O: 0.679 M: 0.018	Train-MLMAcc=0.605633,	MVRCAccuracy=0.652187,	MLMLossWVC=1.942302,	MVRCLoss=2.494478,	
Rank[  0]Epoch[3] Batch [7900]	Speed: 23.91 samples/s ETA: 2 d  2 h 35 m	Data: 0.823 Tran: 0.010 F: 0.210 B: 0.389 O: 1.224 M: 0.018	Train-MLMAcc=0.605633,	MVRCAccuracy=0.652187,	MLMLossWVC=1.942302,	MVRCLoss=2.494478,	
Rank[  3]Epoch[3] Batch [8000]	Speed: 27.91 samples/s ETA: 1 d 19 h 16 m	Data: 0.848 Tran: 0.007 F: 0.151 B: 0.297 O: 0.985 M: 0.005	Train-MLMAcc=0.605631,	MVRCAccuracy=0.652255,	MLMLossWVC=1.942254,	MVRCLoss=2.494387,	
Rank[  0]Epoch[3] Batch [8000]	Speed: 27.91 samples/s ETA: 1 d 19 h 16 m	Data: 0.943 Tran: 0.007 F: 0.149 B: 0.291 O: 0.896 M: 0.006	Train-MLMAcc=0.605631,	MVRCAccuracy=0.652255,	MLMLossWVC=1.942254,	MVRCLoss=2.494387,	
Rank[  1]Epoch[3] Batch [8000]	Speed: 27.91 samples/s ETA: 1 d 19 h 16 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.826 M: 0.006	Train-MLMAcc=0.605631,	MVRCAccuracy=0.652255,	MLMLossWVC=1.942254,	MVRCLoss=2.494387,	
Rank[  2]Epoch[3] Batch [8000]	Speed: 27.91 samples/s ETA: 1 d 19 h 16 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.827 M: 0.005	Train-MLMAcc=0.605631,	MVRCAccuracy=0.652255,	MLMLossWVC=1.942254,	MVRCLoss=2.494387,	
Rank[  0]Epoch[3] Batch [8100]	Speed: 27.35 samples/s ETA: 1 d 20 h  6 m	Data: 0.614 Tran: 0.007 F: 0.151 B: 0.294 O: 1.263 M: 0.010	Train-MLMAcc=0.605623,	MVRCAccuracy=0.652317,	MLMLossWVC=1.942285,	MVRCLoss=2.494264,	
Rank[  1]Epoch[3] Batch [8100]	Speed: 27.35 samples/s ETA: 1 d 20 h  6 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.870 M: 0.007	Train-MLMAcc=0.605623,	MVRCAccuracy=0.652317,	MLMLossWVC=1.942285,	MVRCLoss=2.494264,	
Rank[  3]Epoch[3] Batch [8100]	Speed: 27.35 samples/s ETA: 1 d 20 h  6 m	Data: 1.219 Tran: 0.007 F: 0.151 B: 0.297 O: 0.656 M: 0.010	Train-MLMAcc=0.605623,	MVRCAccuracy=0.652317,	MLMLossWVC=1.942285,	MVRCLoss=2.494264,	
Rank[  2]Epoch[3] Batch [8100]	Speed: 27.35 samples/s ETA: 1 d 20 h  6 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.865 M: 0.011	Train-MLMAcc=0.605623,	MVRCAccuracy=0.652317,	MLMLossWVC=1.942285,	MVRCLoss=2.494264,	
Rank[  1]Epoch[3] Batch [8200]	Speed: 27.67 samples/s ETA: 1 d 19 h 32 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.843 M: 0.008	Train-MLMAcc=0.605645,	MVRCAccuracy=0.652363,	MLMLossWVC=1.942148,	MVRCLoss=2.494184,	
Rank[  2]Epoch[3] Batch [8200]	Speed: 27.67 samples/s ETA: 1 d 19 h 32 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.298 O: 1.844 M: 0.005	Train-MLMAcc=0.605645,	MVRCAccuracy=0.652363,	MLMLossWVC=1.942148,	MVRCLoss=2.494184,	
Rank[  0]Epoch[3] Batch [8200]	Speed: 27.67 samples/s ETA: 1 d 19 h 32 m	Data: 0.606 Tran: 0.007 F: 0.150 B: 0.294 O: 1.248 M: 0.009	Train-MLMAcc=0.605645,	MVRCAccuracy=0.652363,	MLMLossWVC=1.942148,	MVRCLoss=2.494184,	
Rank[  3]Epoch[3] Batch [8200]	Speed: 27.67 samples/s ETA: 1 d 19 h 32 m	Data: 1.207 Tran: 0.007 F: 0.150 B: 0.298 O: 0.643 M: 0.008	Train-MLMAcc=0.605645,	MVRCAccuracy=0.652363,	MLMLossWVC=1.942148,	MVRCLoss=2.494184,	
Rank[  0]Epoch[3] Batch [8300]	Speed: 27.40 samples/s ETA: 1 d 19 h 54 m	Data: 0.805 Tran: 0.007 F: 0.150 B: 0.294 O: 1.074 M: 0.005	Train-MLMAcc=0.605672,	MVRCAccuracy=0.652411,	MLMLossWVC=1.941947,	MVRCLoss=2.494082,	
Rank[  3]Epoch[3] Batch [8300]	Speed: 27.40 samples/s ETA: 1 d 19 h 54 m	Data: 1.031 Tran: 0.007 F: 0.150 B: 0.295 O: 0.846 M: 0.006	Train-MLMAcc=0.605672,	MVRCAccuracy=0.652411,	MLMLossWVC=1.941947,	MVRCLoss=2.494082,	
Rank[  2]Epoch[3] Batch [8300]	Speed: 27.40 samples/s ETA: 1 d 19 h 54 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.869 M: 0.005	Train-MLMAcc=0.605672,	MVRCAccuracy=0.652411,	MLMLossWVC=1.941947,	MVRCLoss=2.494082,	
Rank[  1]Epoch[3] Batch [8300]	Speed: 27.40 samples/s ETA: 1 d 19 h 54 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.869 M: 0.005	Train-MLMAcc=0.605672,	MVRCAccuracy=0.652411,	MLMLossWVC=1.941947,	MVRCLoss=2.494082,	
Rank[  1]Epoch[3] Batch [8400]	Speed: 27.93 samples/s ETA: 1 d 19 h  0 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.295 O: 1.823 M: 0.008	Train-MLMAcc=0.605721,	MVRCAccuracy=0.652476,	MLMLossWVC=1.941875,	MVRCLoss=2.493909,	
Rank[  2]Epoch[3] Batch [8400]	Speed: 27.93 samples/s ETA: 1 d 19 h  0 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.299 O: 1.819 M: 0.007	Train-MLMAcc=0.605721,	MVRCAccuracy=0.652476,	MLMLossWVC=1.941875,	MVRCLoss=2.493909,	
Rank[  3]Epoch[3] Batch [8400]	Speed: 27.93 samples/s ETA: 1 d 19 h  0 m	Data: 0.619 Tran: 0.008 F: 0.150 B: 0.296 O: 1.211 M: 0.007	Train-MLMAcc=0.605721,	MVRCAccuracy=0.652476,	MLMLossWVC=1.941875,	MVRCLoss=2.493909,	
Rank[  0]Epoch[3] Batch [8400]	Speed: 27.93 samples/s ETA: 1 d 19 h  0 m	Data: 1.167 Tran: 0.007 F: 0.151 B: 0.293 O: 0.666 M: 0.006	Train-MLMAcc=0.605721,	MVRCAccuracy=0.652476,	MLMLossWVC=1.941875,	MVRCLoss=2.493909,	
Rank[  0]Epoch[3] Batch [8500]	Speed: 27.21 samples/s ETA: 1 d 20 h  3 m	Data: 1.813 Tran: 0.006 F: 0.151 B: 0.293 O: 0.082 M: 0.006	Train-MLMAcc=0.605749,	MVRCAccuracy=0.652533,	MLMLossWVC=1.941700,	MVRCLoss=2.493771,	
Rank[  1]Epoch[3] Batch [8500]	Speed: 27.21 samples/s ETA: 1 d 20 h  3 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.879 M: 0.009	Train-MLMAcc=0.605749,	MVRCAccuracy=0.652533,	MLMLossWVC=1.941700,	MVRCLoss=2.493771,	
Rank[  3]Epoch[3] Batch [8500]	Speed: 27.21 samples/s ETA: 1 d 20 h  3 m	Data: 0.197 Tran: 0.007 F: 0.150 B: 0.296 O: 1.693 M: 0.007	Train-MLMAcc=0.605749,	MVRCAccuracy=0.652533,	MLMLossWVC=1.941700,	MVRCLoss=2.493771,	
Rank[  2]Epoch[3] Batch [8500]	Speed: 27.21 samples/s ETA: 1 d 20 h  3 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.883 M: 0.007	Train-MLMAcc=0.605749,	MVRCAccuracy=0.652533,	MLMLossWVC=1.941700,	MVRCLoss=2.493771,	
Rank[  3]Epoch[3] Batch [8600]	Speed: 28.32 samples/s ETA: 1 d 18 h 17 m	Data: 0.916 Tran: 0.006 F: 0.150 B: 0.297 O: 0.882 M: 0.009	Train-MLMAcc=0.605814,	MVRCAccuracy=0.652583,	MLMLossWVC=1.941343,	MVRCLoss=2.493681,	
Rank[  1]Epoch[3] Batch [8600]	Speed: 28.32 samples/s ETA: 1 d 18 h 17 m	Data: 0.463 Tran: 0.007 F: 0.150 B: 0.298 O: 1.332 M: 0.008	Train-MLMAcc=0.605814,	MVRCAccuracy=0.652583,	MLMLossWVC=1.941343,	MVRCLoss=2.493681,	
Rank[  2]Epoch[3] Batch [8600]	Speed: 28.32 samples/s ETA: 1 d 18 h 17 m	Data: 0.281 Tran: 0.007 F: 0.150 B: 0.297 O: 1.517 M: 0.007	Train-MLMAcc=0.605814,	MVRCAccuracy=0.652583,	MLMLossWVC=1.941343,	MVRCLoss=2.493681,	
Rank[  0]Epoch[3] Batch [8600]	Speed: 28.32 samples/s ETA: 1 d 18 h 17 m	Data: 1.554 Tran: 0.009 F: 0.177 B: 0.299 O: 0.213 M: 0.008	Train-MLMAcc=0.605814,	MVRCAccuracy=0.652583,	MLMLossWVC=1.941343,	MVRCLoss=2.493681,	
Rank[  3]Epoch[3] Batch [8700]	Speed: 26.89 samples/s ETA: 1 d 20 h 27 m	Data: 0.537 Tran: 0.006 F: 0.160 B: 0.314 O: 1.352 M: 0.009	Train-MLMAcc=0.605880,	MVRCAccuracy=0.652650,	MLMLossWVC=1.940955,	MVRCLoss=2.493497,	
Rank[  1]Epoch[3] Batch [8700]	Speed: 26.89 samples/s ETA: 1 d 20 h 27 m	Data: 0.069 Tran: 0.007 F: 0.161 B: 0.315 O: 1.818 M: 0.009	Train-MLMAcc=0.605880,	MVRCAccuracy=0.652650,	MLMLossWVC=1.940955,	MVRCLoss=2.493497,	
Rank[  2]Epoch[3] Batch [8700]	Speed: 26.89 samples/s ETA: 1 d 20 h 27 m	Data: 0.028 Tran: 0.007 F: 0.161 B: 0.315 O: 1.859 M: 0.009	Train-MLMAcc=0.605880,	MVRCAccuracy=0.652650,	MLMLossWVC=1.940955,	MVRCLoss=2.493497,	
Rank[  0]Epoch[3] Batch [8700]	Speed: 26.89 samples/s ETA: 1 d 20 h 27 m	Data: 1.762 Tran: 0.007 F: 0.167 B: 0.305 O: 0.129 M: 0.009	Train-MLMAcc=0.605880,	MVRCAccuracy=0.652650,	MLMLossWVC=1.940955,	MVRCLoss=2.493497,	
Rank[  2]Epoch[3] Batch [8800]	Speed: 26.57 samples/s ETA: 1 d 20 h 56 m	Data: 0.009 Tran: 0.008 F: 0.166 B: 0.312 O: 1.900 M: 0.011	Train-MLMAcc=0.605921,	MVRCAccuracy=0.652710,	MLMLossWVC=1.940638,	MVRCLoss=2.493450,	
Rank[  3]Epoch[3] Batch [8800]	Speed: 26.57 samples/s ETA: 1 d 20 h 56 m	Data: 1.385 Tran: 0.009 F: 0.197 B: 0.327 O: 0.474 M: 0.014	Train-MLMAcc=0.605921,	MVRCAccuracy=0.652710,	MLMLossWVC=1.940638,	MVRCLoss=2.493450,	
Rank[  1]Epoch[3] Batch [8800]	Speed: 26.57 samples/s ETA: 1 d 20 h 56 m	Data: 0.009 Tran: 0.007 F: 0.166 B: 0.314 O: 1.896 M: 0.015	Train-MLMAcc=0.605921,	MVRCAccuracy=0.652710,	MLMLossWVC=1.940638,	MVRCLoss=2.493450,	
Rank[  0]Epoch[3] Batch [8800]	Speed: 26.57 samples/s ETA: 1 d 20 h 56 m	Data: 1.348 Tran: 0.007 F: 0.168 B: 0.312 O: 0.557 M: 0.015	Train-MLMAcc=0.605921,	MVRCAccuracy=0.652710,	MLMLossWVC=1.940638,	MVRCLoss=2.493450,	
Rank[  2]Epoch[3] Batch [8900]	Speed: 25.45 samples/s ETA: 1 d 22 h 50 m	Data: 0.015 Tran: 0.007 F: 0.188 B: 0.333 O: 1.957 M: 0.011	Train-MLMAcc=0.606010,	MVRCAccuracy=0.652753,	MLMLossWVC=1.940146,	MVRCLoss=2.493274,	
Rank[  3]Epoch[3] Batch [8900]	Speed: 25.45 samples/s ETA: 1 d 22 h 50 m	Data: 1.696 Tran: 0.008 F: 0.206 B: 0.342 O: 0.245 M: 0.016	Train-MLMAcc=0.606010,	MVRCAccuracy=0.652753,	MLMLossWVC=1.940146,	MVRCLoss=2.493274,	
Rank[  1]Epoch[3] Batch [8900]	Speed: 25.45 samples/s ETA: 1 d 22 h 50 m	Data: 0.019 Tran: 0.008 F: 0.183 B: 0.335 O: 1.951 M: 0.016	Train-MLMAcc=0.606010,	MVRCAccuracy=0.652753,	MLMLossWVC=1.940146,	MVRCLoss=2.493274,	
Rank[  0]Epoch[3] Batch [8900]	Speed: 25.45 samples/s ETA: 1 d 22 h 50 m	Data: 1.280 Tran: 0.008 F: 0.213 B: 0.340 O: 0.655 M: 0.016	Train-MLMAcc=0.606010,	MVRCAccuracy=0.652753,	MLMLossWVC=1.940146,	MVRCLoss=2.493274,	
Rank[  0]Epoch[3] Batch [9000]	Speed: 27.82 samples/s ETA: 1 d 18 h 46 m	Data: 1.247 Tran: 0.006 F: 0.150 B: 0.294 O: 0.591 M: 0.011	Train-MLMAcc=0.606014,	MVRCAccuracy=0.652796,	MLMLossWVC=1.939985,	MVRCLoss=2.493263,	
Rank[  1]Epoch[3] Batch [9000]	Speed: 27.82 samples/s ETA: 1 d 18 h 46 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.829 M: 0.010	Train-MLMAcc=0.606014,	MVRCAccuracy=0.652796,	MLMLossWVC=1.939985,	MVRCLoss=2.493263,	
Rank[  3]Epoch[3] Batch [9000]	Speed: 27.82 samples/s ETA: 1 d 18 h 46 m	Data: 1.339 Tran: 0.007 F: 0.149 B: 0.294 O: 0.499 M: 0.011	Train-MLMAcc=0.606014,	MVRCAccuracy=0.652796,	MLMLossWVC=1.939985,	MVRCLoss=2.493263,	
Rank[  2]Epoch[3] Batch [9000]	Speed: 27.82 samples/s ETA: 1 d 18 h 46 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.828 M: 0.008	Train-MLMAcc=0.606014,	MVRCAccuracy=0.652796,	MLMLossWVC=1.939985,	MVRCLoss=2.493263,	
Rank[  2]Epoch[3] Batch [9100]	Speed: 25.66 samples/s ETA: 1 d 22 h 19 m	Data: 0.011 Tran: 0.007 F: 0.170 B: 0.318 O: 1.974 M: 0.012	Train-MLMAcc=0.606133,	MVRCAccuracy=0.652857,	MLMLossWVC=1.939286,	MVRCLoss=2.493214,	
Rank[  3]Epoch[3] Batch [9100]	Speed: 25.66 samples/s ETA: 1 d 22 h 19 m	Data: 1.737 Tran: 0.010 F: 0.211 B: 0.326 O: 0.195 M: 0.013	Train-MLMAcc=0.606133,	MVRCAccuracy=0.652857,	MLMLossWVC=1.939286,	MVRCLoss=2.493214,	
Rank[  0]Epoch[3] Batch [9100]	Speed: 25.66 samples/s ETA: 1 d 22 h 19 m	Data: 0.576 Tran: 0.007 F: 0.167 B: 0.317 O: 1.411 M: 0.015	Train-MLMAcc=0.606133,	MVRCAccuracy=0.652857,	MLMLossWVC=1.939286,	MVRCLoss=2.493214,	
Rank[  1]Epoch[3] Batch [9100]	Speed: 25.66 samples/s ETA: 1 d 22 h 19 m	Data: 0.011 Tran: 0.007 F: 0.171 B: 0.316 O: 1.975 M: 0.013	Train-MLMAcc=0.606133,	MVRCAccuracy=0.652857,	MLMLossWVC=1.939286,	MVRCLoss=2.493214,	
Rank[  2]Epoch[3] Batch [9200]	Speed: 27.13 samples/s ETA: 1 d 19 h 45 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.311 O: 1.871 M: 0.009	Train-MLMAcc=0.606126,	MVRCAccuracy=0.652926,	MLMLossWVC=1.939124,	MVRCLoss=2.493144,	
Rank[  3]Epoch[3] Batch [9200]	Speed: 27.13 samples/s ETA: 1 d 19 h 45 m	Data: 1.805 Tran: 0.008 F: 0.174 B: 0.307 O: 0.057 M: 0.009	Train-MLMAcc=0.606126,	MVRCAccuracy=0.652926,	MLMLossWVC=1.939124,	MVRCLoss=2.493144,	
Rank[  1]Epoch[3] Batch [9200]	Speed: 27.13 samples/s ETA: 1 d 19 h 45 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.310 O: 1.872 M: 0.010	Train-MLMAcc=0.606126,	MVRCAccuracy=0.652926,	MLMLossWVC=1.939124,	MVRCLoss=2.493144,	
Rank[  0]Epoch[3] Batch [9200]	Speed: 27.13 samples/s ETA: 1 d 19 h 45 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.307 O: 1.877 M: 0.007	Train-MLMAcc=0.606126,	MVRCAccuracy=0.652926,	MLMLossWVC=1.939124,	MVRCLoss=2.493144,	
Rank[  2]Epoch[3] Batch [9300]	Speed: 27.46 samples/s ETA: 1 d 19 h  9 m	Data: 0.137 Tran: 0.009 F: 0.157 B: 0.304 O: 1.716 M: 0.008	Train-MLMAcc=0.606139,	MVRCAccuracy=0.652957,	MLMLossWVC=1.938897,	MVRCLoss=2.493122,	
Rank[  1]Epoch[3] Batch [9300]	Speed: 27.46 samples/s ETA: 1 d 19 h  9 m	Data: 0.008 Tran: 0.007 F: 0.164 B: 0.304 O: 1.837 M: 0.008	Train-MLMAcc=0.606139,	MVRCAccuracy=0.652957,	MLMLossWVC=1.938897,	MVRCLoss=2.493122,	
Rank[  3]Epoch[3] Batch [9300]	Speed: 27.46 samples/s ETA: 1 d 19 h  9 m	Data: 1.538 Tran: 0.007 F: 0.168 B: 0.304 O: 0.306 M: 0.006	Train-MLMAcc=0.606139,	MVRCAccuracy=0.652957,	MLMLossWVC=1.938897,	MVRCLoss=2.493122,	
Rank[  0]Epoch[3] Batch [9300]	Speed: 27.46 samples/s ETA: 1 d 19 h  9 m	Data: 0.118 Tran: 0.007 F: 0.164 B: 0.316 O: 1.717 M: 0.008	Train-MLMAcc=0.606139,	MVRCAccuracy=0.652957,	MLMLossWVC=1.938897,	MVRCLoss=2.493122,	
Rank[  2]Epoch[3] Batch [9400]	Speed: 27.74 samples/s ETA: 1 d 18 h 39 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.839 M: 0.006	Train-MLMAcc=0.606160,	MVRCAccuracy=0.653019,	MLMLossWVC=1.938479,	MVRCLoss=2.492977,	
Rank[  1]Epoch[3] Batch [9400]	Speed: 27.74 samples/s ETA: 1 d 18 h 39 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.295 O: 1.840 M: 0.006	Train-MLMAcc=0.606160,	MVRCAccuracy=0.653019,	MLMLossWVC=1.938479,	MVRCLoss=2.492977,	
Rank[  3]Epoch[3] Batch [9400]	Speed: 27.74 samples/s ETA: 1 d 18 h 39 m	Data: 1.728 Tran: 0.007 F: 0.150 B: 0.296 O: 0.118 M: 0.007	Train-MLMAcc=0.606160,	MVRCAccuracy=0.653019,	MLMLossWVC=1.938479,	MVRCLoss=2.492977,	
Rank[  0]Epoch[3] Batch [9400]	Speed: 27.74 samples/s ETA: 1 d 18 h 39 m	Data: 0.074 Tran: 0.007 F: 0.149 B: 0.292 O: 1.778 M: 0.008	Train-MLMAcc=0.606160,	MVRCAccuracy=0.653019,	MLMLossWVC=1.938479,	MVRCLoss=2.492977,	
Rank[  1]Epoch[3] Batch [9500]	Speed: 27.70 samples/s ETA: 1 d 18 h 39 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.839 M: 0.010	Train-MLMAcc=0.606197,	MVRCAccuracy=0.653061,	MLMLossWVC=1.938190,	MVRCLoss=2.492836,	
Rank[  0]Epoch[3] Batch [9500]	Speed: 27.70 samples/s ETA: 1 d 18 h 39 m	Data: 0.428 Tran: 0.007 F: 0.150 B: 0.293 O: 1.422 M: 0.009	Train-MLMAcc=0.606197,	MVRCAccuracy=0.653061,	MLMLossWVC=1.938190,	MVRCLoss=2.492836,	
Rank[  3]Epoch[3] Batch [9500]	Speed: 27.70 samples/s ETA: 1 d 18 h 39 m	Data: 1.375 Tran: 0.006 F: 0.150 B: 0.296 O: 0.473 M: 0.009	Train-MLMAcc=0.606197,	MVRCAccuracy=0.653061,	MLMLossWVC=1.938190,	MVRCLoss=2.492836,	
Rank[  2]Epoch[3] Batch [9500]	Speed: 27.70 samples/s ETA: 1 d 18 h 39 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.299 O: 1.839 M: 0.006	Train-MLMAcc=0.606197,	MVRCAccuracy=0.653061,	MLMLossWVC=1.938190,	MVRCLoss=2.492836,	
Rank[  3]Epoch[3] Batch [9600]	Speed: 26.71 samples/s ETA: 1 d 20 h  9 m	Data: 0.261 Tran: 0.007 F: 0.163 B: 0.339 O: 1.616 M: 0.007	Train-MLMAcc=0.606224,	MVRCAccuracy=0.653089,	MLMLossWVC=1.937937,	MVRCLoss=2.492777,	
Rank[  1]Epoch[3] Batch [9600]	Speed: 26.71 samples/s ETA: 1 d 20 h  9 m	Data: 0.010 Tran: 0.007 F: 0.162 B: 0.331 O: 1.873 M: 0.010	Train-MLMAcc=0.606224,	MVRCAccuracy=0.653089,	MLMLossWVC=1.937937,	MVRCLoss=2.492777,	
Rank[  2]Epoch[3] Batch [9600]	Speed: 26.71 samples/s ETA: 1 d 20 h  9 m	Data: 0.009 Tran: 0.007 F: 0.162 B: 0.336 O: 1.869 M: 0.010	Train-MLMAcc=0.606224,	MVRCAccuracy=0.653089,	MLMLossWVC=1.937937,	MVRCLoss=2.492777,	
Rank[  0]Epoch[3] Batch [9600]	Speed: 26.71 samples/s ETA: 1 d 20 h  9 m	Data: 1.548 Tran: 0.007 F: 0.178 B: 0.334 O: 0.316 M: 0.011	Train-MLMAcc=0.606224,	MVRCAccuracy=0.653089,	MLMLossWVC=1.937937,	MVRCLoss=2.492777,	
Rank[  0]Epoch[3] Batch [9700]	Speed: 27.82 samples/s ETA: 1 d 18 h 20 m	Data: 1.785 Tran: 0.006 F: 0.149 B: 0.291 O: 0.058 M: 0.010	Train-MLMAcc=0.606256,	MVRCAccuracy=0.653138,	MLMLossWVC=1.937720,	MVRCLoss=2.492623,	
Rank[  1]Epoch[3] Batch [9700]	Speed: 27.82 samples/s ETA: 1 d 18 h 20 m	Data: 0.042 Tran: 0.007 F: 0.151 B: 0.295 O: 1.798 M: 0.006	Train-MLMAcc=0.606256,	MVRCAccuracy=0.653138,	MLMLossWVC=1.937720,	MVRCLoss=2.492623,	
Rank[  2]Epoch[3] Batch [9700]	Speed: 27.82 samples/s ETA: 1 d 18 h 20 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.831 M: 0.008	Train-MLMAcc=0.606256,	MVRCAccuracy=0.653138,	MLMLossWVC=1.937720,	MVRCLoss=2.492623,	
Rank[  3]Epoch[3] Batch [9700]	Speed: 27.82 samples/s ETA: 1 d 18 h 20 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.829 M: 0.010	Train-MLMAcc=0.606256,	MVRCAccuracy=0.653138,	MLMLossWVC=1.937720,	MVRCLoss=2.492623,	
Rank[  2]Epoch[3] Batch [9800]	Speed: 26.53 samples/s ETA: 1 d 20 h 19 m	Data: 0.011 Tran: 0.007 F: 0.150 B: 0.297 O: 1.939 M: 0.007	Train-MLMAcc=0.606306,	MVRCAccuracy=0.653195,	MLMLossWVC=1.937395,	MVRCLoss=2.492457,	
Rank[  3]Epoch[3] Batch [9800]	Speed: 26.53 samples/s ETA: 1 d 20 h 19 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.946 M: 0.006	Train-MLMAcc=0.606306,	MVRCAccuracy=0.653195,	MLMLossWVC=1.937395,	MVRCLoss=2.492457,	
Rank[  1]Epoch[3] Batch [9800]	Speed: 26.53 samples/s ETA: 1 d 20 h 19 m	Data: 0.024 Tran: 0.007 F: 0.150 B: 0.295 O: 1.928 M: 0.008	Train-MLMAcc=0.606306,	MVRCAccuracy=0.653195,	MLMLossWVC=1.937395,	MVRCLoss=2.492457,	
Rank[  0]Epoch[3] Batch [9800]	Speed: 26.53 samples/s ETA: 1 d 20 h 19 m	Data: 1.894 Tran: 0.006 F: 0.151 B: 0.294 O: 0.059 M: 0.009	Train-MLMAcc=0.606306,	MVRCAccuracy=0.653195,	MLMLossWVC=1.937395,	MVRCLoss=2.492457,	
Rank[  0]Epoch[3] Batch [9900]	Speed: 26.40 samples/s ETA: 1 d 20 h 29 m	Data: 1.898 Tran: 0.006 F: 0.150 B: 0.291 O: 0.068 M: 0.010	Train-MLMAcc=0.606373,	MVRCAccuracy=0.653245,	MLMLossWVC=1.936955,	MVRCLoss=2.492303,	
Rank[  1]Epoch[3] Batch [9900]	Speed: 26.40 samples/s ETA: 1 d 20 h 29 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.294 O: 1.956 M: 0.010	Train-MLMAcc=0.606373,	MVRCAccuracy=0.653245,	MLMLossWVC=1.936955,	MVRCLoss=2.492303,	
Rank[  3]Epoch[3] Batch [9900]	Speed: 26.40 samples/s ETA: 1 d 20 h 29 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.954 M: 0.006	Train-MLMAcc=0.606373,	MVRCAccuracy=0.653245,	MLMLossWVC=1.936955,	MVRCLoss=2.492303,	
Rank[  2]Epoch[3] Batch [9900]	Speed: 26.40 samples/s ETA: 1 d 20 h 29 m	Data: 0.017 Tran: 0.007 F: 0.149 B: 0.295 O: 1.945 M: 0.010	Train-MLMAcc=0.606373,	MVRCAccuracy=0.653245,	MLMLossWVC=1.936955,	MVRCLoss=2.492303,	
Rank[  0]Epoch[3] Batch [10000]	Speed: 27.70 samples/s ETA: 1 d 18 h 19 m	Data: 1.716 Tran: 0.007 F: 0.150 B: 0.292 O: 0.135 M: 0.008	Train-MLMAcc=0.606414,	MVRCAccuracy=0.653295,	MLMLossWVC=1.936694,	MVRCLoss=2.492214,	
Rank[  3]Epoch[3] Batch [10000]	Speed: 27.70 samples/s ETA: 1 d 18 h 19 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.841 M: 0.005	Train-MLMAcc=0.606414,	MVRCAccuracy=0.653295,	MLMLossWVC=1.936694,	MVRCLoss=2.492214,	
Rank[  2]Epoch[3] Batch [10000]	Speed: 27.70 samples/s ETA: 1 d 18 h 19 m	Data: 0.088 Tran: 0.007 F: 0.149 B: 0.293 O: 1.765 M: 0.007	Train-MLMAcc=0.606414,	MVRCAccuracy=0.653295,	MLMLossWVC=1.936694,	MVRCLoss=2.492214,	
Rank[  1]Epoch[3] Batch [10000]	Speed: 27.70 samples/s ETA: 1 d 18 h 19 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.841 M: 0.008	Train-MLMAcc=0.606414,	MVRCAccuracy=0.653295,	MLMLossWVC=1.936694,	MVRCLoss=2.492214,	
Rank[  2]Epoch[3] Batch [10100]	Speed: 27.12 samples/s ETA: 1 d 19 h 10 m	Data: 0.013 Tran: 0.007 F: 0.151 B: 0.298 O: 1.883 M: 0.007	Train-MLMAcc=0.606462,	MVRCAccuracy=0.653321,	MLMLossWVC=1.936486,	MVRCLoss=2.492184,	
Rank[  0]Epoch[3] Batch [10100]	Speed: 27.12 samples/s ETA: 1 d 19 h 10 m	Data: 1.840 Tran: 0.008 F: 0.151 B: 0.294 O: 0.058 M: 0.008	Train-MLMAcc=0.606462,	MVRCAccuracy=0.653321,	MLMLossWVC=1.936486,	MVRCLoss=2.492184,	
Rank[  1]Epoch[3] Batch [10100]	Speed: 27.12 samples/s ETA: 1 d 19 h 10 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.293 O: 1.894 M: 0.008	Train-MLMAcc=0.606462,	MVRCAccuracy=0.653321,	MLMLossWVC=1.936486,	MVRCLoss=2.492184,	
Rank[  3]Epoch[3] Batch [10100]	Speed: 27.12 samples/s ETA: 1 d 19 h 10 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.890 M: 0.007	Train-MLMAcc=0.606462,	MVRCAccuracy=0.653321,	MLMLossWVC=1.936486,	MVRCLoss=2.492184,	
Rank[  2]Epoch[3] Batch [10200]	Speed: 27.56 samples/s ETA: 1 d 18 h 25 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.295 O: 1.857 M: 0.006	Train-MLMAcc=0.606568,	MVRCAccuracy=0.653363,	MLMLossWVC=1.935961,	MVRCLoss=2.492045,	
Rank[  3]Epoch[3] Batch [10200]	Speed: 27.56 samples/s ETA: 1 d 18 h 25 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.853 M: 0.006	Train-MLMAcc=0.606568,	MVRCAccuracy=0.653363,	MLMLossWVC=1.935961,	MVRCLoss=2.492045,	
Rank[  0]Epoch[3] Batch [10200]	Speed: 27.56 samples/s ETA: 1 d 18 h 25 m	Data: 1.812 Tran: 0.007 F: 0.150 B: 0.292 O: 0.054 M: 0.006	Train-MLMAcc=0.606568,	MVRCAccuracy=0.653363,	MLMLossWVC=1.935961,	MVRCLoss=2.492045,	
Rank[  1]Epoch[3] Batch [10200]	Speed: 27.56 samples/s ETA: 1 d 18 h 25 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.857 M: 0.006	Train-MLMAcc=0.606568,	MVRCAccuracy=0.653363,	MLMLossWVC=1.935961,	MVRCLoss=2.492045,	
Rank[  1]Epoch[3] Batch [10300]	Speed: 27.81 samples/s ETA: 1 d 17 h 58 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.835 M: 0.008	Train-MLMAcc=0.606606,	MVRCAccuracy=0.653413,	MLMLossWVC=1.935612,	MVRCLoss=2.491988,	
Rank[  3]Epoch[3] Batch [10300]	Speed: 27.81 samples/s ETA: 1 d 17 h 58 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.833 M: 0.006	Train-MLMAcc=0.606606,	MVRCAccuracy=0.653413,	MLMLossWVC=1.935612,	MVRCLoss=2.491988,	
Rank[  2]Epoch[3] Batch [10300]	Speed: 27.81 samples/s ETA: 1 d 17 h 58 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 1.836 M: 0.006	Train-MLMAcc=0.606606,	MVRCAccuracy=0.653413,	MLMLossWVC=1.935612,	MVRCLoss=2.491988,	
Rank[  0]Epoch[3] Batch [10300]	Speed: 27.81 samples/s ETA: 1 d 17 h 58 m	Data: 1.790 Tran: 0.007 F: 0.150 B: 0.290 O: 0.058 M: 0.006	Train-MLMAcc=0.606606,	MVRCAccuracy=0.653413,	MLMLossWVC=1.935612,	MVRCLoss=2.491988,	
Rank[  3]Epoch[3] Batch [10400]	Speed: 27.72 samples/s ETA: 1 d 18 h  2 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.835 M: 0.011	Train-MLMAcc=0.606631,	MVRCAccuracy=0.653449,	MLMLossWVC=1.935275,	MVRCLoss=2.491981,	
Rank[  0]Epoch[3] Batch [10400]	Speed: 27.72 samples/s ETA: 1 d 18 h  2 m	Data: 1.790 Tran: 0.007 F: 0.150 B: 0.292 O: 0.058 M: 0.010	Train-MLMAcc=0.606631,	MVRCAccuracy=0.653449,	MLMLossWVC=1.935275,	MVRCLoss=2.491981,	
Rank[  2]Epoch[3] Batch [10400]	Speed: 27.72 samples/s ETA: 1 d 18 h  2 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.839 M: 0.006	Train-MLMAcc=0.606631,	MVRCAccuracy=0.653449,	MLMLossWVC=1.935275,	MVRCLoss=2.491981,	
Rank[  1]Epoch[3] Batch [10400]	Speed: 27.72 samples/s ETA: 1 d 18 h  2 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.840 M: 0.010	Train-MLMAcc=0.606631,	MVRCAccuracy=0.653449,	MLMLossWVC=1.935275,	MVRCLoss=2.491981,	
Rank[  1]Epoch[3] Batch [10500]	Speed: 27.57 samples/s ETA: 1 d 18 h 12 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.854 M: 0.007	Train-MLMAcc=0.606658,	MVRCAccuracy=0.653501,	MLMLossWVC=1.935108,	MVRCLoss=2.491879,	
Rank[  2]Epoch[3] Batch [10500]	Speed: 27.57 samples/s ETA: 1 d 18 h 12 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.855 M: 0.006	Train-MLMAcc=0.606658,	MVRCAccuracy=0.653501,	MLMLossWVC=1.935108,	MVRCLoss=2.491879,	
Rank[  3]Epoch[3] Batch [10500]	Speed: 27.57 samples/s ETA: 1 d 18 h 12 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.852 M: 0.006	Train-MLMAcc=0.606658,	MVRCAccuracy=0.653501,	MLMLossWVC=1.935108,	MVRCLoss=2.491879,	
Rank[  0]Epoch[3] Batch [10500]	Speed: 27.57 samples/s ETA: 1 d 18 h 12 m	Data: 1.809 Tran: 0.007 F: 0.151 B: 0.293 O: 0.056 M: 0.004	Train-MLMAcc=0.606658,	MVRCAccuracy=0.653501,	MLMLossWVC=1.935108,	MVRCLoss=2.491879,	
Rank[  3]Epoch[3] Batch [10600]	Speed: 26.85 samples/s ETA: 1 d 19 h 16 m	Data: 0.030 Tran: 0.007 F: 0.156 B: 0.309 O: 1.869 M: 0.010	Train-MLMAcc=0.606683,	MVRCAccuracy=0.653551,	MLMLossWVC=1.934906,	MVRCLoss=2.491715,	
Rank[  0]Epoch[3] Batch [10600]	Speed: 26.85 samples/s ETA: 1 d 19 h 16 m	Data: 1.708 Tran: 0.011 F: 0.182 B: 0.304 O: 0.167 M: 0.009	Train-MLMAcc=0.606683,	MVRCAccuracy=0.653551,	MLMLossWVC=1.934906,	MVRCLoss=2.491715,	
Rank[  1]Epoch[3] Batch [10600]	Speed: 26.85 samples/s ETA: 1 d 19 h 16 m	Data: 0.218 Tran: 0.007 F: 0.156 B: 0.305 O: 1.688 M: 0.009	Train-MLMAcc=0.606683,	MVRCAccuracy=0.653551,	MLMLossWVC=1.934906,	MVRCLoss=2.491715,	
Rank[  2]Epoch[3] Batch [10600]	Speed: 26.85 samples/s ETA: 1 d 19 h 16 m	Data: 0.135 Tran: 0.007 F: 0.156 B: 0.304 O: 1.770 M: 0.010	Train-MLMAcc=0.606683,	MVRCAccuracy=0.653551,	MLMLossWVC=1.934906,	MVRCLoss=2.491715,	
Rank[  3]Epoch[3] Batch [10700]	Speed: 26.84 samples/s ETA: 1 d 19 h 13 m	Data: 0.055 Tran: 0.007 F: 0.162 B: 0.299 O: 1.843 M: 0.017	Train-MLMAcc=0.606710,	MVRCAccuracy=0.653578,	MLMLossWVC=1.934878,	MVRCLoss=2.491682,	
Rank[  1]Epoch[3] Batch [10700]	Speed: 26.84 samples/s ETA: 1 d 19 h 13 m	Data: 0.677 Tran: 0.007 F: 0.158 B: 0.294 O: 1.229 M: 0.018	Train-MLMAcc=0.606710,	MVRCAccuracy=0.653578,	MLMLossWVC=1.934878,	MVRCLoss=2.491682,	
Rank[  0]Epoch[3] Batch [10700]	Speed: 26.84 samples/s ETA: 1 d 19 h 13 m	Data: 1.843 Tran: 0.007 F: 0.158 B: 0.296 O: 0.061 M: 0.017	Train-MLMAcc=0.606710,	MVRCAccuracy=0.653578,	MLMLossWVC=1.934878,	MVRCLoss=2.491682,	
Rank[  2]Epoch[3] Batch [10700]	Speed: 26.84 samples/s ETA: 1 d 19 h 13 m	Data: 0.008 Tran: 0.007 F: 0.155 B: 0.317 O: 1.882 M: 0.013	Train-MLMAcc=0.606710,	MVRCAccuracy=0.653578,	MLMLossWVC=1.934878,	MVRCLoss=2.491682,	
Rank[  2]Epoch[3] Batch [10800]	Speed: 26.11 samples/s ETA: 1 d 20 h 21 m	Data: 0.010 Tran: 0.007 F: 0.166 B: 0.351 O: 1.896 M: 0.018	Train-MLMAcc=0.606742,	MVRCAccuracy=0.653623,	MLMLossWVC=1.934675,	MVRCLoss=2.491650,	
Rank[  3]Epoch[3] Batch [10800]	Speed: 26.11 samples/s ETA: 1 d 20 h 21 m	Data: 0.018 Tran: 0.007 F: 0.165 B: 0.352 O: 1.888 M: 0.018	Train-MLMAcc=0.606742,	MVRCAccuracy=0.653623,	MLMLossWVC=1.934675,	MVRCLoss=2.491650,	
Rank[  0]Epoch[3] Batch [10800]	Speed: 26.11 samples/s ETA: 1 d 20 h 21 m	Data: 1.839 Tran: 0.008 F: 0.184 B: 0.328 O: 0.067 M: 0.021	Train-MLMAcc=0.606742,	MVRCAccuracy=0.653623,	MLMLossWVC=1.934675,	MVRCLoss=2.491650,	
Rank[  1]Epoch[3] Batch [10800]	Speed: 26.11 samples/s ETA: 1 d 20 h 21 m	Data: 0.113 Tran: 0.007 F: 0.165 B: 0.347 O: 1.793 M: 0.023	Train-MLMAcc=0.606742,	MVRCAccuracy=0.653623,	MLMLossWVC=1.934675,	MVRCLoss=2.491650,	
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
New Best Val MLMAcc: 0.5892488956451416, Epoch: 3
New Best Val MLMAcc: 0.5892488956451416, Epoch: 3
New Best Val MLMAcc: 0.5892488956451416, Epoch: 3
New Best Val MLMAcc: 0.5892488956451416, Epoch: 3
Epoch[3] 	Val-MLMAcc=0.589249,	MVRCAccuracy=0.679217,	MLMLossWVC=2.018944,	MVRCLoss=2.490228,	
Epoch[3] 	Val-MLMAcc=0.589249,	MVRCAccuracy=0.679217,	MLMLossWVC=2.018944,	MVRCLoss=2.490228,	
Epoch[3] 	Val-MLMAcc=0.589249,	MVRCAccuracy=0.679217,	MLMLossWVC=2.018944,	MVRCLoss=2.490228,	
Epoch[3] 	Val-MLMAcc=0.589249,	MVRCAccuracy=0.679217,	MLMLossWVC=2.018944,	MVRCLoss=2.490228,	
Best Val MLMAcc: 0.5892488956451416, Epoch: 3
PROGRESS: 40.00%
Best Val MLMAcc: 0.5892488956451416, Epoch: 3
Best Val MLMAcc: 0.5892488956451416, Epoch: 3
PROGRESS: 40.00%
Best Val MLMAcc: 0.5892488956451416, Epoch: 3
PROGRESS: 40.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Save new best model to /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-best.model.
PROGRESS: 40.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Rank[  0]Epoch[4] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.576271,	MVRCAccuracy=0.690110,	MLMLossWVC=2.155807,	MVRCLoss=2.479343,	
Rank[  1]Epoch[4] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.576271,	MVRCAccuracy=0.690110,	MLMLossWVC=2.155807,	MVRCLoss=2.479343,	
Rank[  3]Epoch[4] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.576271,	MVRCAccuracy=0.690110,	MLMLossWVC=2.155807,	MVRCLoss=2.479343,	
Rank[  2]Epoch[4] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.576271,	MVRCAccuracy=0.690110,	MLMLossWVC=2.155807,	MVRCLoss=2.479343,	
Rank[  0]Epoch[4] Batch [100]	Speed: 27.89 samples/s ETA: 1 d 17 h 25 m	Data: 2.927 Tran: 0.010 F: 0.227 B: 0.438 O: 0.085 M: 0.012	Train-MLMAcc=0.609950,	MVRCAccuracy=0.658082,	MLMLossWVC=1.897598,	MVRCLoss=2.483167,	
Rank[  3]Epoch[4] Batch [100]	Speed: 27.89 samples/s ETA: 1 d 17 h 25 m	Data: 0.436 Tran: 0.011 F: 0.226 B: 0.444 O: 2.749 M: 0.011	Train-MLMAcc=0.609950,	MVRCAccuracy=0.658082,	MLMLossWVC=1.897598,	MVRCLoss=2.483167,	
Rank[  1]Epoch[4] Batch [100]	Speed: 27.89 samples/s ETA: 1 d 17 h 25 m	Data: 0.418 Tran: 0.011 F: 0.227 B: 0.443 O: 2.765 M: 0.012	Train-MLMAcc=0.609950,	MVRCAccuracy=0.658082,	MLMLossWVC=1.897598,	MVRCLoss=2.483167,	
Rank[  2]Epoch[4] Batch [100]	Speed: 27.89 samples/s ETA: 1 d 17 h 25 m	Data: 0.368 Tran: 0.011 F: 0.227 B: 0.446 O: 2.816 M: 0.008	Train-MLMAcc=0.609950,	MVRCAccuracy=0.658082,	MLMLossWVC=1.897598,	MVRCLoss=2.483167,	
Rank[  0]Epoch[4] Batch [200]	Speed: 27.75 samples/s ETA: 1 d 17 h 34 m	Data: 1.794 Tran: 0.006 F: 0.150 B: 0.291 O: 0.053 M: 0.011	Train-MLMAcc=0.612183,	MVRCAccuracy=0.658234,	MLMLossWVC=1.886485,	MVRCLoss=2.481700,	
Rank[  1]Epoch[4] Batch [200]	Speed: 27.75 samples/s ETA: 1 d 17 h 34 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.835 M: 0.011	Train-MLMAcc=0.612183,	MVRCAccuracy=0.658234,	MLMLossWVC=1.886485,	MVRCLoss=2.481700,	
Rank[  3]Epoch[4] Batch [200]	Speed: 27.75 samples/s ETA: 1 d 17 h 34 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.835 M: 0.008	Train-MLMAcc=0.612183,	MVRCAccuracy=0.658234,	MLMLossWVC=1.886485,	MVRCLoss=2.481700,	
Rank[  2]Epoch[4] Batch [200]	Speed: 27.75 samples/s ETA: 1 d 17 h 34 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.839 M: 0.007	Train-MLMAcc=0.612183,	MVRCAccuracy=0.658234,	MLMLossWVC=1.886485,	MVRCLoss=2.481700,	
Rank[  0]Epoch[4] Batch [300]	Speed: 28.00 samples/s ETA: 1 d 17 h  8 m	Data: 1.527 Tran: 0.006 F: 0.149 B: 0.292 O: 0.301 M: 0.009	Train-MLMAcc=0.612621,	MVRCAccuracy=0.658120,	MLMLossWVC=1.890576,	MVRCLoss=2.482126,	
Rank[  3]Epoch[4] Batch [300]	Speed: 28.00 samples/s ETA: 1 d 17 h  8 m	Data: 0.046 Tran: 0.007 F: 0.150 B: 0.296 O: 1.781 M: 0.005	Train-MLMAcc=0.612621,	MVRCAccuracy=0.658120,	MLMLossWVC=1.890576,	MVRCLoss=2.482126,	
Rank[  2]Epoch[4] Batch [300]	Speed: 28.00 samples/s ETA: 1 d 17 h  8 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.818 M: 0.008	Train-MLMAcc=0.612621,	MVRCAccuracy=0.658120,	MLMLossWVC=1.890576,	MVRCLoss=2.482126,	
Rank[  1]Epoch[4] Batch [300]	Speed: 28.00 samples/s ETA: 1 d 17 h  8 m	Data: 0.319 Tran: 0.007 F: 0.150 B: 0.295 O: 1.506 M: 0.008	Train-MLMAcc=0.612621,	MVRCAccuracy=0.658120,	MLMLossWVC=1.890576,	MVRCLoss=2.482126,	
Rank[  3]Epoch[4] Batch [400]	Speed: 27.29 samples/s ETA: 1 d 18 h  9 m	Data: 0.378 Tran: 0.007 F: 0.150 B: 0.297 O: 1.507 M: 0.006	Train-MLMAcc=0.613759,	MVRCAccuracy=0.658465,	MLMLossWVC=1.887780,	MVRCLoss=2.481369,	
Rank[  2]Epoch[4] Batch [400]	Speed: 27.29 samples/s ETA: 1 d 18 h  9 m	Data: 0.014 Tran: 0.007 F: 0.150 B: 0.296 O: 1.872 M: 0.005	Train-MLMAcc=0.613759,	MVRCAccuracy=0.658465,	MLMLossWVC=1.887780,	MVRCLoss=2.481369,	
Rank[  1]Epoch[4] Batch [400]	Speed: 27.29 samples/s ETA: 1 d 18 h  9 m	Data: 0.859 Tran: 0.007 F: 0.150 B: 0.296 O: 1.026 M: 0.007	Train-MLMAcc=0.613759,	MVRCAccuracy=0.658465,	MLMLossWVC=1.887780,	MVRCLoss=2.481369,	
Rank[  0]Epoch[4] Batch [400]	Speed: 27.29 samples/s ETA: 1 d 18 h  9 m	Data: 1.639 Tran: 0.006 F: 0.150 B: 0.292 O: 0.250 M: 0.007	Train-MLMAcc=0.613759,	MVRCAccuracy=0.658465,	MLMLossWVC=1.887780,	MVRCLoss=2.481369,	
Rank[  3]Epoch[4] Batch [500]	Speed: 27.58 samples/s ETA: 1 d 17 h 38 m	Data: 0.009 Tran: 0.007 F: 0.149 B: 0.298 O: 1.849 M: 0.008	Train-MLMAcc=0.613812,	MVRCAccuracy=0.658603,	MLMLossWVC=1.888302,	MVRCLoss=2.481210,	
Rank[  0]Epoch[4] Batch [500]	Speed: 27.58 samples/s ETA: 1 d 17 h 38 m	Data: 1.808 Tran: 0.006 F: 0.150 B: 0.291 O: 0.057 M: 0.007	Train-MLMAcc=0.613812,	MVRCAccuracy=0.658603,	MLMLossWVC=1.888302,	MVRCLoss=2.481210,	
Rank[  1]Epoch[4] Batch [500]	Speed: 27.58 samples/s ETA: 1 d 17 h 38 m	Data: 0.069 Tran: 0.007 F: 0.150 B: 0.295 O: 1.794 M: 0.005	Train-MLMAcc=0.613812,	MVRCAccuracy=0.658603,	MLMLossWVC=1.888302,	MVRCLoss=2.481210,	
Rank[  2]Epoch[4] Batch [500]	Speed: 27.58 samples/s ETA: 1 d 17 h 38 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.853 M: 0.007	Train-MLMAcc=0.613812,	MVRCAccuracy=0.658603,	MLMLossWVC=1.888302,	MVRCLoss=2.481210,	
Rank[  1]Epoch[4] Batch [600]	Speed: 27.50 samples/s ETA: 1 d 17 h 41 m	Data: 0.050 Tran: 0.007 F: 0.149 B: 0.292 O: 1.821 M: 0.007	Train-MLMAcc=0.613362,	MVRCAccuracy=0.659019,	MLMLossWVC=1.890763,	MVRCLoss=2.480348,	
Rank[  3]Epoch[4] Batch [600]	Speed: 27.50 samples/s ETA: 1 d 17 h 41 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.295 O: 1.862 M: 0.006	Train-MLMAcc=0.613362,	MVRCAccuracy=0.659019,	MLMLossWVC=1.890763,	MVRCLoss=2.480348,	
Rank[  0]Epoch[4] Batch [600]	Speed: 27.50 samples/s ETA: 1 d 17 h 41 m	Data: 1.815 Tran: 0.007 F: 0.151 B: 0.294 O: 0.053 M: 0.006	Train-MLMAcc=0.613362,	MVRCAccuracy=0.659019,	MLMLossWVC=1.890763,	MVRCLoss=2.480348,	
Rank[  2]Epoch[4] Batch [600]	Speed: 27.50 samples/s ETA: 1 d 17 h 41 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.299 O: 1.856 M: 0.005	Train-MLMAcc=0.613362,	MVRCAccuracy=0.659019,	MLMLossWVC=1.890763,	MVRCLoss=2.480348,	
Rank[  3]Epoch[4] Batch [700]	Speed: 27.45 samples/s ETA: 1 d 17 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.864 M: 0.006	Train-MLMAcc=0.613625,	MVRCAccuracy=0.659572,	MLMLossWVC=1.890437,	MVRCLoss=2.479049,	
Rank[  0]Epoch[4] Batch [700]	Speed: 27.45 samples/s ETA: 1 d 17 h 42 m	Data: 1.818 Tran: 0.007 F: 0.150 B: 0.291 O: 0.056 M: 0.008	Train-MLMAcc=0.613625,	MVRCAccuracy=0.659572,	MLMLossWVC=1.890437,	MVRCLoss=2.479049,	
Rank[  1]Epoch[4] Batch [700]	Speed: 27.45 samples/s ETA: 1 d 17 h 42 m	Data: 0.080 Tran: 0.007 F: 0.151 B: 0.295 O: 1.791 M: 0.006	Train-MLMAcc=0.613625,	MVRCAccuracy=0.659572,	MLMLossWVC=1.890437,	MVRCLoss=2.479049,	
Rank[  2]Epoch[4] Batch [700]	Speed: 27.45 samples/s ETA: 1 d 17 h 42 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.863 M: 0.008	Train-MLMAcc=0.613625,	MVRCAccuracy=0.659572,	MLMLossWVC=1.890437,	MVRCLoss=2.479049,	
Rank[  3]Epoch[4] Batch [800]	Speed: 27.71 samples/s ETA: 1 d 17 h 15 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.840 M: 0.007	Train-MLMAcc=0.614185,	MVRCAccuracy=0.659693,	MLMLossWVC=1.889218,	MVRCLoss=2.478621,	
Rank[  0]Epoch[4] Batch [800]	Speed: 27.71 samples/s ETA: 1 d 17 h 15 m	Data: 1.796 Tran: 0.007 F: 0.150 B: 0.291 O: 0.057 M: 0.009	Train-MLMAcc=0.614185,	MVRCAccuracy=0.659693,	MLMLossWVC=1.889218,	MVRCLoss=2.478621,	
Rank[  2]Epoch[4] Batch [800]	Speed: 27.71 samples/s ETA: 1 d 17 h 15 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.841 M: 0.008	Train-MLMAcc=0.614185,	MVRCAccuracy=0.659693,	MLMLossWVC=1.889218,	MVRCLoss=2.478621,	
Rank[  1]Epoch[4] Batch [800]	Speed: 27.71 samples/s ETA: 1 d 17 h 15 m	Data: 0.014 Tran: 0.007 F: 0.150 B: 0.294 O: 1.837 M: 0.007	Train-MLMAcc=0.614185,	MVRCAccuracy=0.659693,	MLMLossWVC=1.889218,	MVRCLoss=2.478621,	
Rank[  3]Epoch[4] Batch [900]	Speed: 27.56 samples/s ETA: 1 d 17 h 25 m	Data: 0.064 Tran: 0.007 F: 0.150 B: 0.297 O: 1.799 M: 0.006	Train-MLMAcc=0.613771,	MVRCAccuracy=0.659912,	MLMLossWVC=1.891396,	MVRCLoss=2.477886,	
Rank[  0]Epoch[4] Batch [900]	Speed: 27.56 samples/s ETA: 1 d 17 h 25 m	Data: 1.786 Tran: 0.006 F: 0.151 B: 0.292 O: 0.079 M: 0.007	Train-MLMAcc=0.613771,	MVRCAccuracy=0.659912,	MLMLossWVC=1.891396,	MVRCLoss=2.477886,	
Rank[  2]Epoch[4] Batch [900]	Speed: 27.56 samples/s ETA: 1 d 17 h 25 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.856 M: 0.006	Train-MLMAcc=0.613771,	MVRCAccuracy=0.659912,	MLMLossWVC=1.891396,	MVRCLoss=2.477886,	
Rank[  1]Epoch[4] Batch [900]	Speed: 27.56 samples/s ETA: 1 d 17 h 25 m	Data: 0.042 Tran: 0.006 F: 0.150 B: 0.294 O: 1.822 M: 0.007	Train-MLMAcc=0.613771,	MVRCAccuracy=0.659912,	MLMLossWVC=1.891396,	MVRCLoss=2.477886,	
Rank[  0]Epoch[4] Batch [1000]	Speed: 27.64 samples/s ETA: 1 d 17 h 13 m	Data: 1.801 Tran: 0.007 F: 0.151 B: 0.293 O: 0.055 M: 0.008	Train-MLMAcc=0.613313,	MVRCAccuracy=0.659941,	MLMLossWVC=1.893786,	MVRCLoss=2.477881,	
Rank[  2]Epoch[4] Batch [1000]	Speed: 27.64 samples/s ETA: 1 d 17 h 13 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.850 M: 0.006	Train-MLMAcc=0.613313,	MVRCAccuracy=0.659941,	MLMLossWVC=1.893786,	MVRCLoss=2.477881,	
Rank[  3]Epoch[4] Batch [1000]	Speed: 27.64 samples/s ETA: 1 d 17 h 13 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.847 M: 0.006	Train-MLMAcc=0.613313,	MVRCAccuracy=0.659941,	MLMLossWVC=1.893786,	MVRCLoss=2.477881,	
Rank[  1]Epoch[4] Batch [1000]	Speed: 27.64 samples/s ETA: 1 d 17 h 13 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.847 M: 0.008	Train-MLMAcc=0.613313,	MVRCAccuracy=0.659941,	MLMLossWVC=1.893786,	MVRCLoss=2.477881,	
Rank[  3]Epoch[4] Batch [1100]	Speed: 27.11 samples/s ETA: 1 d 17 h 58 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 1.891 M: 0.008	Train-MLMAcc=0.613827,	MVRCAccuracy=0.660022,	MLMLossWVC=1.892012,	MVRCLoss=2.477458,	
Rank[  0]Epoch[4] Batch [1100]	Speed: 27.11 samples/s ETA: 1 d 17 h 58 m	Data: 1.246 Tran: 0.007 F: 0.150 B: 0.292 O: 0.656 M: 0.009	Train-MLMAcc=0.613827,	MVRCAccuracy=0.660022,	MLMLossWVC=1.892012,	MVRCLoss=2.477458,	
Rank[  1]Epoch[4] Batch [1100]	Speed: 27.11 samples/s ETA: 1 d 17 h 58 m	Data: 0.609 Tran: 0.007 F: 0.152 B: 0.297 O: 1.288 M: 0.007	Train-MLMAcc=0.613827,	MVRCAccuracy=0.660022,	MLMLossWVC=1.892012,	MVRCLoss=2.477458,	
Rank[  2]Epoch[4] Batch [1100]	Speed: 27.11 samples/s ETA: 1 d 17 h 58 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.296 O: 1.891 M: 0.010	Train-MLMAcc=0.613827,	MVRCAccuracy=0.660022,	MLMLossWVC=1.892012,	MVRCLoss=2.477458,	
Rank[  3]Epoch[4] Batch [1200]	Speed: 26.89 samples/s ETA: 1 d 18 h 15 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.910 M: 0.010	Train-MLMAcc=0.613744,	MVRCAccuracy=0.659996,	MLMLossWVC=1.892973,	MVRCLoss=2.477357,	
Rank[  0]Epoch[4] Batch [1200]	Speed: 26.89 samples/s ETA: 1 d 18 h 15 m	Data: 0.455 Tran: 0.007 F: 0.150 B: 0.292 O: 1.465 M: 0.010	Train-MLMAcc=0.613744,	MVRCAccuracy=0.659996,	MLMLossWVC=1.892973,	MVRCLoss=2.477357,	
Rank[  1]Epoch[4] Batch [1200]	Speed: 26.89 samples/s ETA: 1 d 18 h 15 m	Data: 1.420 Tran: 0.006 F: 0.150 B: 0.293 O: 0.500 M: 0.010	Train-MLMAcc=0.613744,	MVRCAccuracy=0.659996,	MLMLossWVC=1.892973,	MVRCLoss=2.477357,	
Rank[  2]Epoch[4] Batch [1200]	Speed: 26.89 samples/s ETA: 1 d 18 h 15 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.911 M: 0.005	Train-MLMAcc=0.613744,	MVRCAccuracy=0.659996,	MLMLossWVC=1.892973,	MVRCLoss=2.477357,	
Rank[  0]Epoch[4] Batch [1300]	Speed: 27.63 samples/s ETA: 1 d 17 h  3 m	Data: 0.027 Tran: 0.007 F: 0.150 B: 0.292 O: 1.831 M: 0.010	Train-MLMAcc=0.613889,	MVRCAccuracy=0.659889,	MLMLossWVC=1.892466,	MVRCLoss=2.477289,	
Rank[  2]Epoch[4] Batch [1300]	Speed: 27.63 samples/s ETA: 1 d 17 h  3 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.844 M: 0.009	Train-MLMAcc=0.613889,	MVRCAccuracy=0.659889,	MLMLossWVC=1.892466,	MVRCLoss=2.477289,	
Rank[  1]Epoch[4] Batch [1300]	Speed: 27.63 samples/s ETA: 1 d 17 h  3 m	Data: 1.782 Tran: 0.007 F: 0.150 B: 0.291 O: 0.076 M: 0.010	Train-MLMAcc=0.613889,	MVRCAccuracy=0.659889,	MLMLossWVC=1.892466,	MVRCLoss=2.477289,	
Rank[  3]Epoch[4] Batch [1300]	Speed: 27.63 samples/s ETA: 1 d 17 h  3 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.847 M: 0.005	Train-MLMAcc=0.613889,	MVRCAccuracy=0.659889,	MLMLossWVC=1.892466,	MVRCLoss=2.477289,	
Rank[  2]Epoch[4] Batch [1400]	Speed: 27.80 samples/s ETA: 1 d 16 h 44 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.297 O: 1.830 M: 0.008	Train-MLMAcc=0.613702,	MVRCAccuracy=0.659669,	MLMLossWVC=1.893580,	MVRCLoss=2.476639,	
Rank[  0]Epoch[4] Batch [1400]	Speed: 27.80 samples/s ETA: 1 d 16 h 44 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.293 O: 1.838 M: 0.006	Train-MLMAcc=0.613702,	MVRCAccuracy=0.659669,	MLMLossWVC=1.893580,	MVRCLoss=2.476639,	
Rank[  3]Epoch[4] Batch [1400]	Speed: 27.80 samples/s ETA: 1 d 16 h 44 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.833 M: 0.008	Train-MLMAcc=0.613702,	MVRCAccuracy=0.659669,	MLMLossWVC=1.893580,	MVRCLoss=2.476639,	
Rank[  1]Epoch[4] Batch [1400]	Speed: 27.80 samples/s ETA: 1 d 16 h 44 m	Data: 1.788 Tran: 0.007 F: 0.151 B: 0.293 O: 0.054 M: 0.007	Train-MLMAcc=0.613702,	MVRCAccuracy=0.659669,	MLMLossWVC=1.893580,	MVRCLoss=2.476639,	
Rank[  0]Epoch[4] Batch [1500]	Speed: 27.86 samples/s ETA: 1 d 16 h 35 m	Data: 0.022 Tran: 0.007 F: 0.149 B: 0.292 O: 1.820 M: 0.006	Train-MLMAcc=0.613890,	MVRCAccuracy=0.659794,	MLMLossWVC=1.892273,	MVRCLoss=2.476599,	
Rank[  3]Epoch[4] Batch [1500]	Speed: 27.86 samples/s ETA: 1 d 16 h 35 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.830 M: 0.006	Train-MLMAcc=0.613890,	MVRCAccuracy=0.659794,	MLMLossWVC=1.892273,	MVRCLoss=2.476599,	
Rank[  2]Epoch[4] Batch [1500]	Speed: 27.86 samples/s ETA: 1 d 16 h 35 m	Data: 0.008 Tran: 0.008 F: 0.149 B: 0.297 O: 1.829 M: 0.006	Train-MLMAcc=0.613890,	MVRCAccuracy=0.659794,	MLMLossWVC=1.892273,	MVRCLoss=2.476599,	
Rank[  1]Epoch[4] Batch [1500]	Speed: 27.86 samples/s ETA: 1 d 16 h 35 m	Data: 1.789 Tran: 0.007 F: 0.150 B: 0.292 O: 0.052 M: 0.006	Train-MLMAcc=0.613890,	MVRCAccuracy=0.659794,	MLMLossWVC=1.892273,	MVRCLoss=2.476599,	
Rank[  0]Epoch[4] Batch [1600]	Speed: 27.32 samples/s ETA: 1 d 17 h 19 m	Data: 0.107 Tran: 0.007 F: 0.149 B: 0.291 O: 1.777 M: 0.010	Train-MLMAcc=0.613853,	MVRCAccuracy=0.659981,	MLMLossWVC=1.892109,	MVRCLoss=2.476520,	
Rank[  1]Epoch[4] Batch [1600]	Speed: 27.32 samples/s ETA: 1 d 17 h 19 m	Data: 1.826 Tran: 0.007 F: 0.151 B: 0.293 O: 0.056 M: 0.009	Train-MLMAcc=0.613853,	MVRCAccuracy=0.659981,	MLMLossWVC=1.892109,	MVRCLoss=2.476520,	
Rank[  2]Epoch[4] Batch [1600]	Speed: 27.32 samples/s ETA: 1 d 17 h 19 m	Data: 0.008 Tran: 0.008 F: 0.151 B: 0.298 O: 1.869 M: 0.008	Train-MLMAcc=0.613853,	MVRCAccuracy=0.659981,	MLMLossWVC=1.892109,	MVRCLoss=2.476520,	
Rank[  3]Epoch[4] Batch [1600]	Speed: 27.32 samples/s ETA: 1 d 17 h 19 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.869 M: 0.011	Train-MLMAcc=0.613853,	MVRCAccuracy=0.659981,	MLMLossWVC=1.892109,	MVRCLoss=2.476520,	
Rank[  0]Epoch[4] Batch [1700]	Speed: 27.99 samples/s ETA: 1 d 16 h 16 m	Data: 0.012 Tran: 0.007 F: 0.150 B: 0.291 O: 1.820 M: 0.006	Train-MLMAcc=0.613862,	MVRCAccuracy=0.660137,	MLMLossWVC=1.891888,	MVRCLoss=2.475986,	
Rank[  1]Epoch[4] Batch [1700]	Speed: 27.99 samples/s ETA: 1 d 16 h 16 m	Data: 1.774 Tran: 0.007 F: 0.151 B: 0.293 O: 0.054 M: 0.007	Train-MLMAcc=0.613862,	MVRCAccuracy=0.660137,	MLMLossWVC=1.891888,	MVRCLoss=2.475986,	
Rank[  3]Epoch[4] Batch [1700]	Speed: 27.99 samples/s ETA: 1 d 16 h 16 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.818 M: 0.005	Train-MLMAcc=0.613862,	MVRCAccuracy=0.660137,	MLMLossWVC=1.891888,	MVRCLoss=2.475986,	
Rank[  2]Epoch[4] Batch [1700]	Speed: 27.99 samples/s ETA: 1 d 16 h 16 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.818 M: 0.007	Train-MLMAcc=0.613862,	MVRCAccuracy=0.660137,	MLMLossWVC=1.891888,	MVRCLoss=2.475986,	
Rank[  1]Epoch[4] Batch [1800]	Speed: 28.12 samples/s ETA: 1 d 16 h  1 m	Data: 1.588 Tran: 0.006 F: 0.151 B: 0.295 O: 0.226 M: 0.010	Train-MLMAcc=0.613959,	MVRCAccuracy=0.660175,	MLMLossWVC=1.890743,	MVRCLoss=2.475834,	
Rank[  0]Epoch[4] Batch [1800]	Speed: 28.12 samples/s ETA: 1 d 16 h  1 m	Data: 0.228 Tran: 0.007 F: 0.149 B: 0.293 O: 1.589 M: 0.010	Train-MLMAcc=0.613959,	MVRCAccuracy=0.660175,	MLMLossWVC=1.890743,	MVRCLoss=2.475834,	
Rank[  3]Epoch[4] Batch [1800]	Speed: 28.12 samples/s ETA: 1 d 16 h  1 m	Data: 0.195 Tran: 0.007 F: 0.149 B: 0.296 O: 1.620 M: 0.009	Train-MLMAcc=0.613959,	MVRCAccuracy=0.660175,	MLMLossWVC=1.890743,	MVRCLoss=2.475834,	
Rank[  2]Epoch[4] Batch [1800]	Speed: 28.12 samples/s ETA: 1 d 16 h  1 m	Data: 0.075 Tran: 0.007 F: 0.151 B: 0.299 O: 1.737 M: 0.006	Train-MLMAcc=0.613959,	MVRCAccuracy=0.660175,	MLMLossWVC=1.890743,	MVRCLoss=2.475834,	
Rank[  3]Epoch[4] Batch [1900]	Speed: 27.00 samples/s ETA: 1 d 17 h 36 m	Data: 0.607 Tran: 0.008 F: 0.157 B: 0.301 O: 1.289 M: 0.008	Train-MLMAcc=0.613951,	MVRCAccuracy=0.660117,	MLMLossWVC=1.889909,	MVRCLoss=2.475725,	
Rank[  2]Epoch[4] Batch [1900]	Speed: 27.00 samples/s ETA: 1 d 17 h 36 m	Data: 0.055 Tran: 0.009 F: 0.157 B: 0.299 O: 1.844 M: 0.006	Train-MLMAcc=0.613951,	MVRCAccuracy=0.660117,	MLMLossWVC=1.889909,	MVRCLoss=2.475725,	
Rank[  0]Epoch[4] Batch [1900]	Speed: 27.00 samples/s ETA: 1 d 17 h 36 m	Data: 0.410 Tran: 0.007 F: 0.153 B: 0.293 O: 1.500 M: 0.007	Train-MLMAcc=0.613951,	MVRCAccuracy=0.660117,	MLMLossWVC=1.889909,	MVRCLoss=2.475725,	
Rank[  1]Epoch[4] Batch [1900]	Speed: 27.00 samples/s ETA: 1 d 17 h 36 m	Data: 1.511 Tran: 0.008 F: 0.157 B: 0.320 O: 0.366 M: 0.008	Train-MLMAcc=0.613951,	MVRCAccuracy=0.660117,	MLMLossWVC=1.889909,	MVRCLoss=2.475725,	
Rank[  0]Epoch[4] Batch [2000]	Speed: 27.76 samples/s ETA: 1 d 16 h 24 m	Data: 0.009 Tran: 0.007 F: 0.149 B: 0.291 O: 1.842 M: 0.006	Train-MLMAcc=0.614171,	MVRCAccuracy=0.660119,	MLMLossWVC=1.888695,	MVRCLoss=2.476062,	
Rank[  2]Epoch[4] Batch [2000]	Speed: 27.76 samples/s ETA: 1 d 16 h 24 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.298 O: 1.837 M: 0.004	Train-MLMAcc=0.614171,	MVRCAccuracy=0.660119,	MLMLossWVC=1.888695,	MVRCLoss=2.476062,	
Rank[  3]Epoch[4] Batch [2000]	Speed: 27.76 samples/s ETA: 1 d 16 h 24 m	Data: 0.859 Tran: 0.006 F: 0.150 B: 0.298 O: 0.987 M: 0.005	Train-MLMAcc=0.614171,	MVRCAccuracy=0.660119,	MLMLossWVC=1.888695,	MVRCLoss=2.476062,	
Rank[  1]Epoch[4] Batch [2000]	Speed: 27.76 samples/s ETA: 1 d 16 h 24 m	Data: 1.050 Tran: 0.007 F: 0.151 B: 0.296 O: 0.795 M: 0.005	Train-MLMAcc=0.614171,	MVRCAccuracy=0.660119,	MLMLossWVC=1.888695,	MVRCLoss=2.476062,	
Rank[  0]Epoch[4] Batch [2100]	Speed: 27.40 samples/s ETA: 1 d 16 h 52 m	Data: 0.076 Tran: 0.007 F: 0.149 B: 0.291 O: 1.804 M: 0.008	Train-MLMAcc=0.614154,	MVRCAccuracy=0.660170,	MLMLossWVC=1.888821,	MVRCLoss=2.475911,	
Rank[  1]Epoch[4] Batch [2100]	Speed: 27.40 samples/s ETA: 1 d 16 h 52 m	Data: 1.431 Tran: 0.007 F: 0.151 B: 0.297 O: 0.441 M: 0.007	Train-MLMAcc=0.614154,	MVRCAccuracy=0.660170,	MLMLossWVC=1.888821,	MVRCLoss=2.475911,	
Rank[  3]Epoch[4] Batch [2100]	Speed: 27.40 samples/s ETA: 1 d 16 h 52 m	Data: 0.434 Tran: 0.007 F: 0.150 B: 0.297 O: 1.441 M: 0.006	Train-MLMAcc=0.614154,	MVRCAccuracy=0.660170,	MLMLossWVC=1.888821,	MVRCLoss=2.475911,	
Rank[  2]Epoch[4] Batch [2100]	Speed: 27.40 samples/s ETA: 1 d 16 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.864 M: 0.007	Train-MLMAcc=0.614154,	MVRCAccuracy=0.660170,	MLMLossWVC=1.888821,	MVRCLoss=2.475911,	
Rank[  0]Epoch[4] Batch [2200]	Speed: 27.62 samples/s ETA: 1 d 16 h 29 m	Data: 0.010 Tran: 0.007 F: 0.149 B: 0.292 O: 1.850 M: 0.008	Train-MLMAcc=0.614426,	MVRCAccuracy=0.660237,	MLMLossWVC=1.887556,	MVRCLoss=2.475680,	
Rank[  2]Epoch[4] Batch [2200]	Speed: 27.62 samples/s ETA: 1 d 16 h 29 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.852 M: 0.006	Train-MLMAcc=0.614426,	MVRCAccuracy=0.660237,	MLMLossWVC=1.887556,	MVRCLoss=2.475680,	
Rank[  3]Epoch[4] Batch [2200]	Speed: 27.62 samples/s ETA: 1 d 16 h 29 m	Data: 0.391 Tran: 0.007 F: 0.150 B: 0.297 O: 1.465 M: 0.006	Train-MLMAcc=0.614426,	MVRCAccuracy=0.660237,	MLMLossWVC=1.887556,	MVRCLoss=2.475680,	
Rank[  1]Epoch[4] Batch [2200]	Speed: 27.62 samples/s ETA: 1 d 16 h 29 m	Data: 1.437 Tran: 0.007 F: 0.151 B: 0.296 O: 0.418 M: 0.007	Train-MLMAcc=0.614426,	MVRCAccuracy=0.660237,	MLMLossWVC=1.887556,	MVRCLoss=2.475680,	
Rank[  3]Epoch[4] Batch [2300]	Speed: 27.49 samples/s ETA: 1 d 16 h 37 m	Data: 0.012 Tran: 0.007 F: 0.149 B: 0.294 O: 1.857 M: 0.007	Train-MLMAcc=0.614431,	MVRCAccuracy=0.660151,	MLMLossWVC=1.887564,	MVRCLoss=2.475611,	
Rank[  0]Epoch[4] Batch [2300]	Speed: 27.49 samples/s ETA: 1 d 16 h 37 m	Data: 0.025 Tran: 0.007 F: 0.150 B: 0.293 O: 1.845 M: 0.007	Train-MLMAcc=0.614431,	MVRCAccuracy=0.660151,	MLMLossWVC=1.887564,	MVRCLoss=2.475611,	
Rank[  2]Epoch[4] Batch [2300]	Speed: 27.49 samples/s ETA: 1 d 16 h 37 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 1.862 M: 0.008	Train-MLMAcc=0.614431,	MVRCAccuracy=0.660151,	MLMLossWVC=1.887564,	MVRCLoss=2.475611,	
Rank[  1]Epoch[4] Batch [2300]	Speed: 27.49 samples/s ETA: 1 d 16 h 37 m	Data: 1.810 Tran: 0.008 F: 0.151 B: 0.292 O: 0.060 M: 0.007	Train-MLMAcc=0.614431,	MVRCAccuracy=0.660151,	MLMLossWVC=1.887564,	MVRCLoss=2.475611,	
Rank[  1]Epoch[4] Batch [2400]	Speed: 27.60 samples/s ETA: 1 d 16 h 23 m	Data: 1.575 Tran: 0.007 F: 0.151 B: 0.294 O: 0.284 M: 0.006	Train-MLMAcc=0.614597,	MVRCAccuracy=0.660096,	MLMLossWVC=1.886468,	MVRCLoss=2.475516,	
Rank[  0]Epoch[4] Batch [2400]	Speed: 27.60 samples/s ETA: 1 d 16 h 23 m	Data: 0.223 Tran: 0.007 F: 0.150 B: 0.292 O: 1.638 M: 0.009	Train-MLMAcc=0.614597,	MVRCAccuracy=0.660096,	MLMLossWVC=1.886468,	MVRCLoss=2.475516,	
Rank[  3]Epoch[4] Batch [2400]	Speed: 27.60 samples/s ETA: 1 d 16 h 23 m	Data: 0.304 Tran: 0.007 F: 0.150 B: 0.296 O: 1.553 M: 0.008	Train-MLMAcc=0.614597,	MVRCAccuracy=0.660096,	MLMLossWVC=1.886468,	MVRCLoss=2.475516,	
Rank[  2]Epoch[4] Batch [2400]	Speed: 27.60 samples/s ETA: 1 d 16 h 23 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.849 M: 0.007	Train-MLMAcc=0.614597,	MVRCAccuracy=0.660096,	MLMLossWVC=1.886468,	MVRCLoss=2.475516,	
Rank[  2]Epoch[4] Batch [2500]	Speed: 27.28 samples/s ETA: 1 d 16 h 48 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.872 M: 0.012	Train-MLMAcc=0.614582,	MVRCAccuracy=0.660173,	MLMLossWVC=1.886230,	MVRCLoss=2.475485,	
Rank[  3]Epoch[4] Batch [2500]	Speed: 27.28 samples/s ETA: 1 d 16 h 48 m	Data: 0.038 Tran: 0.007 F: 0.149 B: 0.295 O: 1.845 M: 0.011	Train-MLMAcc=0.614582,	MVRCAccuracy=0.660173,	MLMLossWVC=1.886230,	MVRCLoss=2.475485,	
Rank[  1]Epoch[4] Batch [2500]	Speed: 27.28 samples/s ETA: 1 d 16 h 48 m	Data: 1.814 Tran: 0.007 F: 0.152 B: 0.293 O: 0.071 M: 0.008	Train-MLMAcc=0.614582,	MVRCAccuracy=0.660173,	MLMLossWVC=1.886230,	MVRCLoss=2.475485,	
Rank[  0]Epoch[4] Batch [2500]	Speed: 27.28 samples/s ETA: 1 d 16 h 48 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.877 M: 0.012	Train-MLMAcc=0.614582,	MVRCAccuracy=0.660173,	MLMLossWVC=1.886230,	MVRCLoss=2.475485,	
Rank[  2]Epoch[4] Batch [2600]	Speed: 26.86 samples/s ETA: 1 d 17 h 22 m	Data: 0.008 Tran: 0.007 F: 0.148 B: 0.294 O: 1.917 M: 0.007	Train-MLMAcc=0.614495,	MVRCAccuracy=0.660139,	MLMLossWVC=1.886596,	MVRCLoss=2.475654,	
Rank[  3]Epoch[4] Batch [2600]	Speed: 26.86 samples/s ETA: 1 d 17 h 22 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.914 M: 0.005	Train-MLMAcc=0.614495,	MVRCAccuracy=0.660139,	MLMLossWVC=1.886596,	MVRCLoss=2.475654,	
Rank[  1]Epoch[4] Batch [2600]	Speed: 26.86 samples/s ETA: 1 d 17 h 22 m	Data: 1.870 Tran: 0.007 F: 0.150 B: 0.292 O: 0.057 M: 0.006	Train-MLMAcc=0.614495,	MVRCAccuracy=0.660139,	MLMLossWVC=1.886596,	MVRCLoss=2.475654,	
Rank[  0]Epoch[4] Batch [2600]	Speed: 26.86 samples/s ETA: 1 d 17 h 22 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.921 M: 0.006	Train-MLMAcc=0.614495,	MVRCAccuracy=0.660139,	MLMLossWVC=1.886596,	MVRCLoss=2.475654,	
Rank[  1]Epoch[4] Batch [2700]	Speed: 28.00 samples/s ETA: 1 d 15 h 37 m	Data: 1.771 Tran: 0.007 F: 0.151 B: 0.294 O: 0.054 M: 0.008	Train-MLMAcc=0.614550,	MVRCAccuracy=0.660227,	MLMLossWVC=1.886615,	MVRCLoss=2.475561,	
Rank[  0]Epoch[4] Batch [2700]	Speed: 28.00 samples/s ETA: 1 d 15 h 37 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.825 M: 0.006	Train-MLMAcc=0.614550,	MVRCAccuracy=0.660227,	MLMLossWVC=1.886615,	MVRCLoss=2.475561,	
Rank[  3]Epoch[4] Batch [2700]	Speed: 28.00 samples/s ETA: 1 d 15 h 37 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.817 M: 0.007	Train-MLMAcc=0.614550,	MVRCAccuracy=0.660227,	MLMLossWVC=1.886615,	MVRCLoss=2.475561,	
Rank[  2]Epoch[4] Batch [2700]	Speed: 28.00 samples/s ETA: 1 d 15 h 37 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.818 M: 0.006	Train-MLMAcc=0.614550,	MVRCAccuracy=0.660227,	MLMLossWVC=1.886615,	MVRCLoss=2.475561,	
Rank[  2]Epoch[4] Batch [2800]	Speed: 27.72 samples/s ETA: 1 d 15 h 57 m	Data: 0.097 Tran: 0.008 F: 0.150 B: 0.297 O: 1.750 M: 0.007	Train-MLMAcc=0.614564,	MVRCAccuracy=0.660276,	MLMLossWVC=1.886043,	MVRCLoss=2.475582,	
Rank[  0]Epoch[4] Batch [2800]	Speed: 27.72 samples/s ETA: 1 d 15 h 57 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.292 O: 1.845 M: 0.007	Train-MLMAcc=0.614564,	MVRCAccuracy=0.660276,	MLMLossWVC=1.886043,	MVRCLoss=2.475582,	
Rank[  3]Epoch[4] Batch [2800]	Speed: 27.72 samples/s ETA: 1 d 15 h 57 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.839 M: 0.007	Train-MLMAcc=0.614564,	MVRCAccuracy=0.660276,	MLMLossWVC=1.886043,	MVRCLoss=2.475582,	
Rank[  1]Epoch[4] Batch [2800]	Speed: 27.72 samples/s ETA: 1 d 15 h 57 m	Data: 1.706 Tran: 0.008 F: 0.151 B: 0.294 O: 0.143 M: 0.007	Train-MLMAcc=0.614564,	MVRCAccuracy=0.660276,	MLMLossWVC=1.886043,	MVRCLoss=2.475582,	
Rank[  0]Epoch[4] Batch [2900]	Speed: 27.15 samples/s ETA: 1 d 16 h 43 m	Data: 0.009 Tran: 0.007 F: 0.170 B: 0.311 O: 1.838 M: 0.020	Train-MLMAcc=0.614411,	MVRCAccuracy=0.660300,	MLMLossWVC=1.886420,	MVRCLoss=2.475527,	
Rank[  1]Epoch[4] Batch [2900]	Speed: 27.15 samples/s ETA: 1 d 16 h 43 m	Data: 1.454 Tran: 0.008 F: 0.175 B: 0.315 O: 0.379 M: 0.024	Train-MLMAcc=0.614411,	MVRCAccuracy=0.660300,	MLMLossWVC=1.886420,	MVRCLoss=2.475527,	
Rank[  3]Epoch[4] Batch [2900]	Speed: 27.15 samples/s ETA: 1 d 16 h 43 m	Data: 0.009 Tran: 0.007 F: 0.169 B: 0.315 O: 1.831 M: 0.024	Train-MLMAcc=0.614411,	MVRCAccuracy=0.660300,	MLMLossWVC=1.886420,	MVRCLoss=2.475527,	
Rank[  2]Epoch[4] Batch [2900]	Speed: 27.15 samples/s ETA: 1 d 16 h 43 m	Data: 0.317 Tran: 0.008 F: 0.174 B: 0.309 O: 1.524 M: 0.023	Train-MLMAcc=0.614411,	MVRCAccuracy=0.660300,	MLMLossWVC=1.886420,	MVRCLoss=2.475527,	
Rank[  3]Epoch[4] Batch [3000]	Speed: 27.33 samples/s ETA: 1 d 16 h 24 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.297 O: 1.875 M: 0.005	Train-MLMAcc=0.614265,	MVRCAccuracy=0.660379,	MLMLossWVC=1.887174,	MVRCLoss=2.475503,	
Rank[  0]Epoch[4] Batch [3000]	Speed: 27.33 samples/s ETA: 1 d 16 h 24 m	Data: 0.355 Tran: 0.007 F: 0.150 B: 0.293 O: 1.530 M: 0.006	Train-MLMAcc=0.614265,	MVRCAccuracy=0.660379,	MLMLossWVC=1.887174,	MVRCLoss=2.475503,	
Rank[  1]Epoch[4] Batch [3000]	Speed: 27.33 samples/s ETA: 1 d 16 h 24 m	Data: 1.582 Tran: 0.006 F: 0.151 B: 0.295 O: 0.301 M: 0.006	Train-MLMAcc=0.614265,	MVRCAccuracy=0.660379,	MLMLossWVC=1.887174,	MVRCLoss=2.475503,	
Rank[  2]Epoch[4] Batch [3000]	Speed: 27.33 samples/s ETA: 1 d 16 h 24 m	Data: 0.228 Tran: 0.007 F: 0.150 B: 0.297 O: 1.654 M: 0.005	Train-MLMAcc=0.614265,	MVRCAccuracy=0.660379,	MLMLossWVC=1.887174,	MVRCLoss=2.475503,	
Rank[  0]Epoch[4] Batch [3100]	Speed: 26.84 samples/s ETA: 1 d 17 h  4 m	Data: 0.703 Tran: 0.007 F: 0.150 B: 0.294 O: 1.224 M: 0.005	Train-MLMAcc=0.614255,	MVRCAccuracy=0.660396,	MLMLossWVC=1.886885,	MVRCLoss=2.475519,	
Rank[  3]Epoch[4] Batch [3100]	Speed: 26.84 samples/s ETA: 1 d 17 h  4 m	Data: 0.314 Tran: 0.007 F: 0.149 B: 0.298 O: 1.610 M: 0.006	Train-MLMAcc=0.614255,	MVRCAccuracy=0.660396,	MLMLossWVC=1.886885,	MVRCLoss=2.475519,	
Rank[  1]Epoch[4] Batch [3100]	Speed: 26.84 samples/s ETA: 1 d 17 h  4 m	Data: 1.674 Tran: 0.006 F: 0.151 B: 0.294 O: 0.253 M: 0.005	Train-MLMAcc=0.614255,	MVRCAccuracy=0.660396,	MLMLossWVC=1.886885,	MVRCLoss=2.475519,	
Rank[  2]Epoch[4] Batch [3100]	Speed: 26.84 samples/s ETA: 1 d 17 h  4 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.914 M: 0.006	Train-MLMAcc=0.614255,	MVRCAccuracy=0.660396,	MLMLossWVC=1.886885,	MVRCLoss=2.475519,	
Rank[  0]Epoch[4] Batch [3200]	Speed: 27.53 samples/s ETA: 1 d 15 h 58 m	Data: 0.612 Tran: 0.007 F: 0.149 B: 0.292 O: 1.255 M: 0.009	Train-MLMAcc=0.614204,	MVRCAccuracy=0.660427,	MLMLossWVC=1.886929,	MVRCLoss=2.475575,	
Rank[  1]Epoch[4] Batch [3200]	Speed: 27.53 samples/s ETA: 1 d 15 h 58 m	Data: 1.644 Tran: 0.006 F: 0.150 B: 0.294 O: 0.223 M: 0.007	Train-MLMAcc=0.614204,	MVRCAccuracy=0.660427,	MLMLossWVC=1.886929,	MVRCLoss=2.475575,	
Rank[  3]Epoch[4] Batch [3200]	Speed: 27.53 samples/s ETA: 1 d 15 h 58 m	Data: 0.032 Tran: 0.007 F: 0.150 B: 0.298 O: 1.830 M: 0.007	Train-MLMAcc=0.614204,	MVRCAccuracy=0.660427,	MLMLossWVC=1.886929,	MVRCLoss=2.475575,	
Rank[  2]Epoch[4] Batch [3200]	Speed: 27.53 samples/s ETA: 1 d 15 h 58 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.857 M: 0.005	Train-MLMAcc=0.614204,	MVRCAccuracy=0.660427,	MLMLossWVC=1.886929,	MVRCLoss=2.475575,	
Rank[  1]Epoch[4] Batch [3300]	Speed: 27.88 samples/s ETA: 1 d 15 h 25 m	Data: 1.204 Tran: 0.006 F: 0.150 B: 0.295 O: 0.631 M: 0.008	Train-MLMAcc=0.614181,	MVRCAccuracy=0.660451,	MLMLossWVC=1.887135,	MVRCLoss=2.475574,	
Rank[  2]Epoch[4] Batch [3300]	Speed: 27.88 samples/s ETA: 1 d 15 h 25 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 1.832 M: 0.006	Train-MLMAcc=0.614181,	MVRCAccuracy=0.660451,	MLMLossWVC=1.887135,	MVRCLoss=2.475574,	
Rank[  0]Epoch[4] Batch [3300]	Speed: 27.88 samples/s ETA: 1 d 15 h 25 m	Data: 0.465 Tran: 0.007 F: 0.150 B: 0.292 O: 1.374 M: 0.007	Train-MLMAcc=0.614181,	MVRCAccuracy=0.660451,	MLMLossWVC=1.887135,	MVRCLoss=2.475574,	
Rank[  3]Epoch[4] Batch [3300]	Speed: 27.88 samples/s ETA: 1 d 15 h 25 m	Data: 0.575 Tran: 0.007 F: 0.150 B: 0.297 O: 1.259 M: 0.007	Train-MLMAcc=0.614181,	MVRCAccuracy=0.660451,	MLMLossWVC=1.887135,	MVRCLoss=2.475574,	
Rank[  0]Epoch[4] Batch [3400]	Speed: 27.50 samples/s ETA: 1 d 15 h 53 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.864 M: 0.007	Train-MLMAcc=0.614113,	MVRCAccuracy=0.660553,	MLMLossWVC=1.886941,	MVRCLoss=2.475483,	
Rank[  1]Epoch[4] Batch [3400]	Speed: 27.50 samples/s ETA: 1 d 15 h 53 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.294 O: 1.862 M: 0.005	Train-MLMAcc=0.614113,	MVRCAccuracy=0.660553,	MLMLossWVC=1.886941,	MVRCLoss=2.475483,	
Rank[  3]Epoch[4] Batch [3400]	Speed: 27.50 samples/s ETA: 1 d 15 h 53 m	Data: 1.813 Tran: 0.007 F: 0.151 B: 0.298 O: 0.051 M: 0.007	Train-MLMAcc=0.614113,	MVRCAccuracy=0.660553,	MLMLossWVC=1.886941,	MVRCLoss=2.475483,	
Rank[  2]Epoch[4] Batch [3400]	Speed: 27.50 samples/s ETA: 1 d 15 h 53 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.862 M: 0.006	Train-MLMAcc=0.614113,	MVRCAccuracy=0.660553,	MLMLossWVC=1.886941,	MVRCLoss=2.475483,	
Rank[  1]Epoch[4] Batch [3500]	Speed: 27.83 samples/s ETA: 1 d 15 h 20 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.828 M: 0.012	Train-MLMAcc=0.614161,	MVRCAccuracy=0.660610,	MLMLossWVC=1.887122,	MVRCLoss=2.475342,	
Rank[  0]Epoch[4] Batch [3500]	Speed: 27.83 samples/s ETA: 1 d 15 h 20 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.829 M: 0.012	Train-MLMAcc=0.614161,	MVRCAccuracy=0.660610,	MLMLossWVC=1.887122,	MVRCLoss=2.475342,	
Rank[  3]Epoch[4] Batch [3500]	Speed: 27.83 samples/s ETA: 1 d 15 h 20 m	Data: 1.781 Tran: 0.006 F: 0.150 B: 0.296 O: 0.053 M: 0.012	Train-MLMAcc=0.614161,	MVRCAccuracy=0.660610,	MLMLossWVC=1.887122,	MVRCLoss=2.475342,	
Rank[  2]Epoch[4] Batch [3500]	Speed: 27.83 samples/s ETA: 1 d 15 h 20 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.295 O: 1.834 M: 0.004	Train-MLMAcc=0.614161,	MVRCAccuracy=0.660610,	MLMLossWVC=1.887122,	MVRCLoss=2.475342,	
Rank[  3]Epoch[4] Batch [3600]	Speed: 27.43 samples/s ETA: 1 d 15 h 51 m	Data: 1.694 Tran: 0.007 F: 0.150 B: 0.296 O: 0.180 M: 0.005	Train-MLMAcc=0.614220,	MVRCAccuracy=0.660679,	MLMLossWVC=1.886747,	MVRCLoss=2.475421,	
Rank[  0]Epoch[4] Batch [3600]	Speed: 27.43 samples/s ETA: 1 d 15 h 51 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.871 M: 0.006	Train-MLMAcc=0.614220,	MVRCAccuracy=0.660679,	MLMLossWVC=1.886747,	MVRCLoss=2.475421,	
Rank[  2]Epoch[4] Batch [3600]	Speed: 27.43 samples/s ETA: 1 d 15 h 51 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.862 M: 0.006	Train-MLMAcc=0.614220,	MVRCAccuracy=0.660679,	MLMLossWVC=1.886747,	MVRCLoss=2.475421,	
Rank[  1]Epoch[4] Batch [3600]	Speed: 27.43 samples/s ETA: 1 d 15 h 51 m	Data: 0.136 Tran: 0.007 F: 0.151 B: 0.296 O: 1.735 M: 0.007	Train-MLMAcc=0.614220,	MVRCAccuracy=0.660679,	MLMLossWVC=1.886747,	MVRCLoss=2.475421,	
Rank[  3]Epoch[4] Batch [3700]	Speed: 27.67 samples/s ETA: 1 d 15 h 27 m	Data: 1.782 Tran: 0.007 F: 0.151 B: 0.296 O: 0.071 M: 0.005	Train-MLMAcc=0.614146,	MVRCAccuracy=0.660722,	MLMLossWVC=1.887266,	MVRCLoss=2.475307,	
Rank[  0]Epoch[4] Batch [3700]	Speed: 27.67 samples/s ETA: 1 d 15 h 27 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.852 M: 0.006	Train-MLMAcc=0.614146,	MVRCAccuracy=0.660722,	MLMLossWVC=1.887266,	MVRCLoss=2.475307,	
Rank[  2]Epoch[4] Batch [3700]	Speed: 27.67 samples/s ETA: 1 d 15 h 27 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.845 M: 0.004	Train-MLMAcc=0.614146,	MVRCAccuracy=0.660722,	MLMLossWVC=1.887266,	MVRCLoss=2.475307,	
Rank[  1]Epoch[4] Batch [3700]	Speed: 27.67 samples/s ETA: 1 d 15 h 27 m	Data: 0.557 Tran: 0.007 F: 0.150 B: 0.294 O: 1.297 M: 0.006	Train-MLMAcc=0.614146,	MVRCAccuracy=0.660722,	MLMLossWVC=1.887266,	MVRCLoss=2.475307,	
Rank[  0]Epoch[4] Batch [3800]	Speed: 27.59 samples/s ETA: 1 d 15 h 29 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.854 M: 0.006	Train-MLMAcc=0.614190,	MVRCAccuracy=0.660829,	MLMLossWVC=1.887164,	MVRCLoss=2.475189,	
Rank[  2]Epoch[4] Batch [3800]	Speed: 27.59 samples/s ETA: 1 d 15 h 29 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.852 M: 0.004	Train-MLMAcc=0.614190,	MVRCAccuracy=0.660829,	MLMLossWVC=1.887164,	MVRCLoss=2.475189,	
Rank[  3]Epoch[4] Batch [3800]	Speed: 27.59 samples/s ETA: 1 d 15 h 29 m	Data: 1.802 Tran: 0.006 F: 0.151 B: 0.297 O: 0.058 M: 0.005	Train-MLMAcc=0.614190,	MVRCAccuracy=0.660829,	MLMLossWVC=1.887164,	MVRCLoss=2.475189,	
Rank[  1]Epoch[4] Batch [3800]	Speed: 27.59 samples/s ETA: 1 d 15 h 29 m	Data: 0.454 Tran: 0.007 F: 0.150 B: 0.294 O: 1.410 M: 0.005	Train-MLMAcc=0.614190,	MVRCAccuracy=0.660829,	MLMLossWVC=1.887164,	MVRCLoss=2.475189,	
Rank[  3]Epoch[4] Batch [3900]	Speed: 27.91 samples/s ETA: 1 d 14 h 58 m	Data: 1.776 Tran: 0.006 F: 0.151 B: 0.297 O: 0.052 M: 0.009	Train-MLMAcc=0.614180,	MVRCAccuracy=0.660825,	MLMLossWVC=1.886773,	MVRCLoss=2.475103,	
Rank[  1]Epoch[4] Batch [3900]	Speed: 27.91 samples/s ETA: 1 d 14 h 58 m	Data: 0.201 Tran: 0.007 F: 0.149 B: 0.292 O: 1.633 M: 0.010	Train-MLMAcc=0.614180,	MVRCAccuracy=0.660825,	MLMLossWVC=1.886773,	MVRCLoss=2.475103,	
Rank[  2]Epoch[4] Batch [3900]	Speed: 27.91 samples/s ETA: 1 d 14 h 58 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.824 M: 0.007	Train-MLMAcc=0.614180,	MVRCAccuracy=0.660825,	MLMLossWVC=1.886773,	MVRCLoss=2.475103,	
Rank[  0]Epoch[4] Batch [3900]	Speed: 27.91 samples/s ETA: 1 d 14 h 58 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.825 M: 0.008	Train-MLMAcc=0.614180,	MVRCAccuracy=0.660825,	MLMLossWVC=1.886773,	MVRCLoss=2.475103,	
Rank[  3]Epoch[4] Batch [4000]	Speed: 27.47 samples/s ETA: 1 d 15 h 32 m	Data: 1.563 Tran: 0.006 F: 0.150 B: 0.296 O: 0.301 M: 0.012	Train-MLMAcc=0.614224,	MVRCAccuracy=0.660924,	MLMLossWVC=1.886368,	MVRCLoss=2.474829,	
Rank[  2]Epoch[4] Batch [4000]	Speed: 27.47 samples/s ETA: 1 d 15 h 32 m	Data: 0.200 Tran: 0.007 F: 0.151 B: 0.298 O: 1.665 M: 0.009	Train-MLMAcc=0.614224,	MVRCAccuracy=0.660924,	MLMLossWVC=1.886368,	MVRCLoss=2.474829,	
Rank[  1]Epoch[4] Batch [4000]	Speed: 27.47 samples/s ETA: 1 d 15 h 32 m	Data: 1.147 Tran: 0.007 F: 0.150 B: 0.294 O: 0.721 M: 0.011	Train-MLMAcc=0.614224,	MVRCAccuracy=0.660924,	MLMLossWVC=1.886368,	MVRCLoss=2.474829,	
Rank[  0]Epoch[4] Batch [4000]	Speed: 27.47 samples/s ETA: 1 d 15 h 32 m	Data: 0.016 Tran: 0.007 F: 0.150 B: 0.291 O: 1.856 M: 0.010	Train-MLMAcc=0.614224,	MVRCAccuracy=0.660924,	MLMLossWVC=1.886368,	MVRCLoss=2.474829,	
Rank[  3]Epoch[4] Batch [4100]	Speed: 28.09 samples/s ETA: 1 d 14 h 36 m	Data: 1.127 Tran: 0.007 F: 0.151 B: 0.299 O: 0.689 M: 0.006	Train-MLMAcc=0.614292,	MVRCAccuracy=0.660991,	MLMLossWVC=1.885155,	MVRCLoss=2.474699,	
Rank[  2]Epoch[4] Batch [4100]	Speed: 28.09 samples/s ETA: 1 d 14 h 36 m	Data: 0.647 Tran: 0.007 F: 0.149 B: 0.295 O: 1.172 M: 0.008	Train-MLMAcc=0.614292,	MVRCAccuracy=0.660991,	MLMLossWVC=1.885155,	MVRCLoss=2.474699,	
Rank[  1]Epoch[4] Batch [4100]	Speed: 28.09 samples/s ETA: 1 d 14 h 36 m	Data: 0.032 Tran: 0.007 F: 0.150 B: 0.295 O: 1.787 M: 0.007	Train-MLMAcc=0.614292,	MVRCAccuracy=0.660991,	MLMLossWVC=1.885155,	MVRCLoss=2.474699,	
Rank[  0]Epoch[4] Batch [4100]	Speed: 28.09 samples/s ETA: 1 d 14 h 36 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.815 M: 0.006	Train-MLMAcc=0.614292,	MVRCAccuracy=0.660991,	MLMLossWVC=1.885155,	MVRCLoss=2.474699,	
Rank[  1]Epoch[4] Batch [4200]	Speed: 27.41 samples/s ETA: 1 d 15 h 30 m	Data: 0.166 Tran: 0.007 F: 0.150 B: 0.295 O: 1.709 M: 0.007	Train-MLMAcc=0.614348,	MVRCAccuracy=0.661082,	MLMLossWVC=1.884698,	MVRCLoss=2.474595,	
Rank[  3]Epoch[4] Batch [4200]	Speed: 27.41 samples/s ETA: 1 d 15 h 30 m	Data: 1.717 Tran: 0.007 F: 0.151 B: 0.299 O: 0.151 M: 0.009	Train-MLMAcc=0.614348,	MVRCAccuracy=0.661082,	MLMLossWVC=1.884698,	MVRCLoss=2.474595,	
Rank[  0]Epoch[4] Batch [4200]	Speed: 27.41 samples/s ETA: 1 d 15 h 30 m	Data: 0.041 Tran: 0.007 F: 0.149 B: 0.292 O: 1.835 M: 0.010	Train-MLMAcc=0.614348,	MVRCAccuracy=0.661082,	MLMLossWVC=1.884698,	MVRCLoss=2.474595,	
Rank[  2]Epoch[4] Batch [4200]	Speed: 27.41 samples/s ETA: 1 d 15 h 30 m	Data: 0.095 Tran: 0.007 F: 0.150 B: 0.296 O: 1.778 M: 0.008	Train-MLMAcc=0.614348,	MVRCAccuracy=0.661082,	MLMLossWVC=1.884698,	MVRCLoss=2.474595,	
Rank[  3]Epoch[4] Batch [4300]	Speed: 27.37 samples/s ETA: 1 d 15 h 29 m	Data: 1.472 Tran: 0.007 F: 0.151 B: 0.300 O: 0.401 M: 0.006	Train-MLMAcc=0.614337,	MVRCAccuracy=0.661138,	MLMLossWVC=1.884573,	MVRCLoss=2.474531,	
Rank[  2]Epoch[4] Batch [4300]	Speed: 27.37 samples/s ETA: 1 d 15 h 29 m	Data: 0.348 Tran: 0.007 F: 0.150 B: 0.296 O: 1.530 M: 0.006	Train-MLMAcc=0.614337,	MVRCAccuracy=0.661138,	MLMLossWVC=1.884573,	MVRCLoss=2.474531,	
Rank[  1]Epoch[4] Batch [4300]	Speed: 27.37 samples/s ETA: 1 d 15 h 29 m	Data: 0.554 Tran: 0.007 F: 0.150 B: 0.294 O: 1.327 M: 0.006	Train-MLMAcc=0.614337,	MVRCAccuracy=0.661138,	MLMLossWVC=1.884573,	MVRCLoss=2.474531,	
Rank[  0]Epoch[4] Batch [4300]	Speed: 27.37 samples/s ETA: 1 d 15 h 29 m	Data: 0.108 Tran: 0.007 F: 0.150 B: 0.293 O: 1.773 M: 0.006	Train-MLMAcc=0.614337,	MVRCAccuracy=0.661138,	MLMLossWVC=1.884573,	MVRCLoss=2.474531,	
Rank[  1]Epoch[4] Batch [4400]	Speed: 25.29 samples/s ETA: 1 d 18 h 40 m	Data: 0.758 Tran: 0.008 F: 0.180 B: 0.324 O: 1.243 M: 0.014	Train-MLMAcc=0.614280,	MVRCAccuracy=0.661173,	MLMLossWVC=1.884811,	MVRCLoss=2.474302,	
Rank[  3]Epoch[4] Batch [4400]	Speed: 25.29 samples/s ETA: 1 d 18 h 40 m	Data: 0.849 Tran: 0.009 F: 0.172 B: 0.309 O: 1.173 M: 0.013	Train-MLMAcc=0.614280,	MVRCAccuracy=0.661173,	MLMLossWVC=1.884811,	MVRCLoss=2.474302,	
Rank[  0]Epoch[4] Batch [4400]	Speed: 25.29 samples/s ETA: 1 d 18 h 40 m	Data: 0.010 Tran: 0.007 F: 0.161 B: 0.295 O: 2.041 M: 0.013	Train-MLMAcc=0.614280,	MVRCAccuracy=0.661173,	MLMLossWVC=1.884811,	MVRCLoss=2.474302,	
Rank[  2]Epoch[4] Batch [4400]	Speed: 25.29 samples/s ETA: 1 d 18 h 40 m	Data: 0.947 Tran: 0.013 F: 0.199 B: 0.315 O: 1.041 M: 0.013	Train-MLMAcc=0.614280,	MVRCAccuracy=0.661173,	MLMLossWVC=1.884811,	MVRCLoss=2.474302,	
Rank[  0]Epoch[4] Batch [4500]	Speed: 27.82 samples/s ETA: 1 d 14 h 43 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.836 M: 0.005	Train-MLMAcc=0.614424,	MVRCAccuracy=0.661186,	MLMLossWVC=1.884096,	MVRCLoss=2.474196,	
Rank[  2]Epoch[4] Batch [4500]	Speed: 27.82 samples/s ETA: 1 d 14 h 43 m	Data: 0.473 Tran: 0.007 F: 0.151 B: 0.298 O: 1.366 M: 0.006	Train-MLMAcc=0.614424,	MVRCAccuracy=0.661186,	MLMLossWVC=1.884096,	MVRCLoss=2.474196,	
Rank[  3]Epoch[4] Batch [4500]	Speed: 27.82 samples/s ETA: 1 d 14 h 43 m	Data: 0.021 Tran: 0.007 F: 0.149 B: 0.298 O: 1.818 M: 0.006	Train-MLMAcc=0.614424,	MVRCAccuracy=0.661186,	MLMLossWVC=1.884096,	MVRCLoss=2.474196,	
Rank[  1]Epoch[4] Batch [4500]	Speed: 27.82 samples/s ETA: 1 d 14 h 43 m	Data: 1.324 Tran: 0.007 F: 0.151 B: 0.297 O: 0.515 M: 0.006	Train-MLMAcc=0.614424,	MVRCAccuracy=0.661186,	MLMLossWVC=1.884096,	MVRCLoss=2.474196,	
Rank[  3]Epoch[4] Batch [4600]	Speed: 27.16 samples/s ETA: 1 d 15 h 36 m	Data: 0.068 Tran: 0.007 F: 0.151 B: 0.300 O: 1.821 M: 0.009	Train-MLMAcc=0.614391,	MVRCAccuracy=0.661234,	MLMLossWVC=1.884199,	MVRCLoss=2.474100,	
Rank[  2]Epoch[4] Batch [4600]	Speed: 27.16 samples/s ETA: 1 d 15 h 36 m	Data: 0.063 Tran: 0.007 F: 0.150 B: 0.297 O: 1.831 M: 0.008	Train-MLMAcc=0.614391,	MVRCAccuracy=0.661234,	MLMLossWVC=1.884199,	MVRCLoss=2.474100,	
Rank[  1]Epoch[4] Batch [4600]	Speed: 27.16 samples/s ETA: 1 d 15 h 36 m	Data: 1.764 Tran: 0.007 F: 0.151 B: 0.294 O: 0.132 M: 0.007	Train-MLMAcc=0.614391,	MVRCAccuracy=0.661234,	MLMLossWVC=1.884199,	MVRCLoss=2.474100,	
Rank[  0]Epoch[4] Batch [4600]	Speed: 27.16 samples/s ETA: 1 d 15 h 36 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.891 M: 0.006	Train-MLMAcc=0.614391,	MVRCAccuracy=0.661234,	MLMLossWVC=1.884199,	MVRCLoss=2.474100,	
Rank[  0]Epoch[4] Batch [4700]	Speed: 27.38 samples/s ETA: 1 d 15 h 13 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.872 M: 0.007	Train-MLMAcc=0.614383,	MVRCAccuracy=0.661258,	MLMLossWVC=1.884239,	MVRCLoss=2.474075,	
Rank[  2]Epoch[4] Batch [4700]	Speed: 27.38 samples/s ETA: 1 d 15 h 13 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.868 M: 0.006	Train-MLMAcc=0.614383,	MVRCAccuracy=0.661258,	MLMLossWVC=1.884239,	MVRCLoss=2.474075,	
Rank[  3]Epoch[4] Batch [4700]	Speed: 27.38 samples/s ETA: 1 d 15 h 13 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.870 M: 0.006	Train-MLMAcc=0.614383,	MVRCAccuracy=0.661258,	MLMLossWVC=1.884239,	MVRCLoss=2.474075,	
Rank[  1]Epoch[4] Batch [4700]	Speed: 27.38 samples/s ETA: 1 d 15 h 13 m	Data: 1.824 Tran: 0.007 F: 0.151 B: 0.295 O: 0.053 M: 0.007	Train-MLMAcc=0.614383,	MVRCAccuracy=0.661258,	MLMLossWVC=1.884239,	MVRCLoss=2.474075,	
Rank[  2]Epoch[4] Batch [4800]	Speed: 27.78 samples/s ETA: 1 d 14 h 35 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.833 M: 0.007	Train-MLMAcc=0.614381,	MVRCAccuracy=0.661281,	MLMLossWVC=1.884186,	MVRCLoss=2.473869,	
Rank[  3]Epoch[4] Batch [4800]	Speed: 27.78 samples/s ETA: 1 d 14 h 35 m	Data: 0.023 Tran: 0.007 F: 0.150 B: 0.297 O: 1.817 M: 0.008	Train-MLMAcc=0.614381,	MVRCAccuracy=0.661281,	MLMLossWVC=1.884186,	MVRCLoss=2.473869,	
Rank[  1]Epoch[4] Batch [4800]	Speed: 27.78 samples/s ETA: 1 d 14 h 35 m	Data: 1.790 Tran: 0.007 F: 0.151 B: 0.294 O: 0.054 M: 0.008	Train-MLMAcc=0.614381,	MVRCAccuracy=0.661281,	MLMLossWVC=1.884186,	MVRCLoss=2.473869,	
Rank[  0]Epoch[4] Batch [4800]	Speed: 27.78 samples/s ETA: 1 d 14 h 35 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.840 M: 0.006	Train-MLMAcc=0.614381,	MVRCAccuracy=0.661281,	MLMLossWVC=1.884186,	MVRCLoss=2.473869,	
Rank[  2]Epoch[4] Batch [4900]	Speed: 27.23 samples/s ETA: 1 d 15 h 18 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.878 M: 0.008	Train-MLMAcc=0.614392,	MVRCAccuracy=0.661328,	MLMLossWVC=1.884054,	MVRCLoss=2.473821,	
Rank[  3]Epoch[4] Batch [4900]	Speed: 27.23 samples/s ETA: 1 d 15 h 18 m	Data: 0.075 Tran: 0.007 F: 0.150 B: 0.297 O: 1.812 M: 0.008	Train-MLMAcc=0.614392,	MVRCAccuracy=0.661328,	MLMLossWVC=1.884054,	MVRCLoss=2.473821,	
Rank[  1]Epoch[4] Batch [4900]	Speed: 27.23 samples/s ETA: 1 d 15 h 18 m	Data: 1.836 Tran: 0.007 F: 0.150 B: 0.292 O: 0.056 M: 0.008	Train-MLMAcc=0.614392,	MVRCAccuracy=0.661328,	MLMLossWVC=1.884054,	MVRCLoss=2.473821,	
Rank[  0]Epoch[4] Batch [4900]	Speed: 27.23 samples/s ETA: 1 d 15 h 18 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.886 M: 0.008	Train-MLMAcc=0.614392,	MVRCAccuracy=0.661328,	MLMLossWVC=1.884054,	MVRCLoss=2.473821,	
Rank[  1]Epoch[4] Batch [5000]	Speed: 27.07 samples/s ETA: 1 d 15 h 28 m	Data: 1.843 Tran: 0.007 F: 0.152 B: 0.296 O: 0.059 M: 0.007	Train-MLMAcc=0.614430,	MVRCAccuracy=0.661359,	MLMLossWVC=1.884119,	MVRCLoss=2.473729,	
Rank[  2]Epoch[4] Batch [5000]	Speed: 27.07 samples/s ETA: 1 d 15 h 28 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.889 M: 0.014	Train-MLMAcc=0.614430,	MVRCAccuracy=0.661359,	MLMLossWVC=1.884119,	MVRCLoss=2.473729,	
Rank[  3]Epoch[4] Batch [5000]	Speed: 27.07 samples/s ETA: 1 d 15 h 28 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 1.889 M: 0.014	Train-MLMAcc=0.614430,	MVRCAccuracy=0.661359,	MLMLossWVC=1.884119,	MVRCLoss=2.473729,	
Rank[  0]Epoch[4] Batch [5000]	Speed: 27.07 samples/s ETA: 1 d 15 h 28 m	Data: 0.013 Tran: 0.007 F: 0.149 B: 0.290 O: 1.892 M: 0.012	Train-MLMAcc=0.614430,	MVRCAccuracy=0.661359,	MLMLossWVC=1.884119,	MVRCLoss=2.473729,	
Rank[  1]Epoch[4] Batch [5100]	Speed: 27.47 samples/s ETA: 1 d 14 h 50 m	Data: 1.711 Tran: 0.007 F: 0.150 B: 0.293 O: 0.161 M: 0.007	Train-MLMAcc=0.614386,	MVRCAccuracy=0.661348,	MLMLossWVC=1.884503,	MVRCLoss=2.473658,	
Rank[  0]Epoch[4] Batch [5100]	Speed: 27.47 samples/s ETA: 1 d 14 h 50 m	Data: 0.119 Tran: 0.007 F: 0.150 B: 0.292 O: 1.755 M: 0.007	Train-MLMAcc=0.614386,	MVRCAccuracy=0.661348,	MLMLossWVC=1.884503,	MVRCLoss=2.473658,	
Rank[  2]Epoch[4] Batch [5100]	Speed: 27.47 samples/s ETA: 1 d 14 h 50 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.861 M: 0.007	Train-MLMAcc=0.614386,	MVRCAccuracy=0.661348,	MLMLossWVC=1.884503,	MVRCLoss=2.473658,	
Rank[  3]Epoch[4] Batch [5100]	Speed: 27.47 samples/s ETA: 1 d 14 h 50 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.863 M: 0.005	Train-MLMAcc=0.614386,	MVRCAccuracy=0.661348,	MLMLossWVC=1.884503,	MVRCLoss=2.473658,	
Rank[  0]Epoch[4] Batch [5200]	Speed: 27.72 samples/s ETA: 1 d 14 h 25 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.294 O: 1.842 M: 0.007	Train-MLMAcc=0.614487,	MVRCAccuracy=0.661415,	MLMLossWVC=1.884159,	MVRCLoss=2.473585,	
Rank[  2]Epoch[4] Batch [5200]	Speed: 27.72 samples/s ETA: 1 d 14 h 25 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.842 M: 0.006	Train-MLMAcc=0.614487,	MVRCAccuracy=0.661415,	MLMLossWVC=1.884159,	MVRCLoss=2.473585,	
Rank[  3]Epoch[4] Batch [5200]	Speed: 27.72 samples/s ETA: 1 d 14 h 25 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.839 M: 0.007	Train-MLMAcc=0.614487,	MVRCAccuracy=0.661415,	MLMLossWVC=1.884159,	MVRCLoss=2.473585,	
Rank[  1]Epoch[4] Batch [5200]	Speed: 27.72 samples/s ETA: 1 d 14 h 25 m	Data: 1.804 Tran: 0.006 F: 0.151 B: 0.297 O: 0.044 M: 0.007	Train-MLMAcc=0.614487,	MVRCAccuracy=0.661415,	MLMLossWVC=1.884159,	MVRCLoss=2.473585,	
Rank[  0]Epoch[4] Batch [5300]	Speed: 27.29 samples/s ETA: 1 d 14 h 57 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.878 M: 0.010	Train-MLMAcc=0.614423,	MVRCAccuracy=0.661436,	MLMLossWVC=1.884381,	MVRCLoss=2.473653,	
Rank[  3]Epoch[4] Batch [5300]	Speed: 27.29 samples/s ETA: 1 d 14 h 57 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.298 O: 1.872 M: 0.010	Train-MLMAcc=0.614423,	MVRCAccuracy=0.661436,	MLMLossWVC=1.884381,	MVRCLoss=2.473653,	
Rank[  2]Epoch[4] Batch [5300]	Speed: 27.29 samples/s ETA: 1 d 14 h 57 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.875 M: 0.007	Train-MLMAcc=0.614423,	MVRCAccuracy=0.661436,	MLMLossWVC=1.884381,	MVRCLoss=2.473653,	
Rank[  1]Epoch[4] Batch [5300]	Speed: 27.29 samples/s ETA: 1 d 14 h 57 m	Data: 1.832 Tran: 0.007 F: 0.151 B: 0.294 O: 0.052 M: 0.008	Train-MLMAcc=0.614423,	MVRCAccuracy=0.661436,	MLMLossWVC=1.884381,	MVRCLoss=2.473653,	
Rank[  3]Epoch[4] Batch [5400]	Speed: 27.87 samples/s ETA: 1 d 14 h  5 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.826 M: 0.006	Train-MLMAcc=0.614458,	MVRCAccuracy=0.661487,	MLMLossWVC=1.884122,	MVRCLoss=2.473672,	
Rank[  2]Epoch[4] Batch [5400]	Speed: 27.87 samples/s ETA: 1 d 14 h  5 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.828 M: 0.007	Train-MLMAcc=0.614458,	MVRCAccuracy=0.661487,	MLMLossWVC=1.884122,	MVRCLoss=2.473672,	
Rank[  0]Epoch[4] Batch [5400]	Speed: 27.87 samples/s ETA: 1 d 14 h  5 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.292 O: 1.831 M: 0.009	Train-MLMAcc=0.614458,	MVRCAccuracy=0.661487,	MLMLossWVC=1.884122,	MVRCLoss=2.473672,	
Rank[  1]Epoch[4] Batch [5400]	Speed: 27.87 samples/s ETA: 1 d 14 h  5 m	Data: 1.787 Tran: 0.006 F: 0.151 B: 0.293 O: 0.051 M: 0.008	Train-MLMAcc=0.614458,	MVRCAccuracy=0.661487,	MLMLossWVC=1.884122,	MVRCLoss=2.473672,	
Rank[  2]Epoch[4] Batch [5500]	Speed: 27.81 samples/s ETA: 1 d 14 h  6 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.832 M: 0.009	Train-MLMAcc=0.614458,	MVRCAccuracy=0.661560,	MLMLossWVC=1.884071,	MVRCLoss=2.473655,	
Rank[  1]Epoch[4] Batch [5500]	Speed: 27.81 samples/s ETA: 1 d 14 h  6 m	Data: 1.792 Tran: 0.006 F: 0.151 B: 0.294 O: 0.049 M: 0.008	Train-MLMAcc=0.614458,	MVRCAccuracy=0.661560,	MLMLossWVC=1.884071,	MVRCLoss=2.473655,	
Rank[  3]Epoch[4] Batch [5500]	Speed: 27.81 samples/s ETA: 1 d 14 h  6 m	Data: 0.015 Tran: 0.007 F: 0.150 B: 0.297 O: 1.824 M: 0.009	Train-MLMAcc=0.614458,	MVRCAccuracy=0.661560,	MLMLossWVC=1.884071,	MVRCLoss=2.473655,	
Rank[  0]Epoch[4] Batch [5500]	Speed: 27.81 samples/s ETA: 1 d 14 h  6 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.832 M: 0.010	Train-MLMAcc=0.614458,	MVRCAccuracy=0.661560,	MLMLossWVC=1.884071,	MVRCLoss=2.473655,	
Rank[  1]Epoch[4] Batch [5600]	Speed: 27.33 samples/s ETA: 1 d 14 h 42 m	Data: 1.829 Tran: 0.007 F: 0.150 B: 0.293 O: 0.052 M: 0.010	Train-MLMAcc=0.614519,	MVRCAccuracy=0.661552,	MLMLossWVC=1.883591,	MVRCLoss=2.473669,	
Rank[  2]Epoch[4] Batch [5600]	Speed: 27.33 samples/s ETA: 1 d 14 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.871 M: 0.009	Train-MLMAcc=0.614519,	MVRCAccuracy=0.661552,	MLMLossWVC=1.883591,	MVRCLoss=2.473669,	
Rank[  0]Epoch[4] Batch [5600]	Speed: 27.33 samples/s ETA: 1 d 14 h 42 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.290 O: 1.877 M: 0.009	Train-MLMAcc=0.614519,	MVRCAccuracy=0.661552,	MLMLossWVC=1.883591,	MVRCLoss=2.473669,	
Rank[  3]Epoch[4] Batch [5600]	Speed: 27.33 samples/s ETA: 1 d 14 h 42 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.869 M: 0.007	Train-MLMAcc=0.614519,	MVRCAccuracy=0.661552,	MLMLossWVC=1.883591,	MVRCLoss=2.473669,	
Rank[  2]Epoch[4] Batch [5700]	Speed: 27.86 samples/s ETA: 1 d 13 h 54 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 1.832 M: 0.007	Train-MLMAcc=0.614638,	MVRCAccuracy=0.661549,	MLMLossWVC=1.882954,	MVRCLoss=2.473647,	
Rank[  1]Epoch[4] Batch [5700]	Speed: 27.86 samples/s ETA: 1 d 13 h 54 m	Data: 1.787 Tran: 0.007 F: 0.150 B: 0.293 O: 0.051 M: 0.008	Train-MLMAcc=0.614638,	MVRCAccuracy=0.661549,	MLMLossWVC=1.882954,	MVRCLoss=2.473647,	
Rank[  3]Epoch[4] Batch [5700]	Speed: 27.86 samples/s ETA: 1 d 13 h 54 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.827 M: 0.007	Train-MLMAcc=0.614638,	MVRCAccuracy=0.661549,	MLMLossWVC=1.882954,	MVRCLoss=2.473647,	
Rank[  0]Epoch[4] Batch [5700]	Speed: 27.86 samples/s ETA: 1 d 13 h 54 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.292 O: 1.834 M: 0.006	Train-MLMAcc=0.614638,	MVRCAccuracy=0.661549,	MLMLossWVC=1.882954,	MVRCLoss=2.473647,	
Rank[  3]Epoch[4] Batch [5800]	Speed: 27.32 samples/s ETA: 1 d 14 h 35 m	Data: 0.086 Tran: 0.007 F: 0.150 B: 0.298 O: 1.793 M: 0.009	Train-MLMAcc=0.614568,	MVRCAccuracy=0.661585,	MLMLossWVC=1.883033,	MVRCLoss=2.473628,	
Rank[  2]Epoch[4] Batch [5800]	Speed: 27.32 samples/s ETA: 1 d 14 h 35 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.875 M: 0.006	Train-MLMAcc=0.614568,	MVRCAccuracy=0.661585,	MLMLossWVC=1.883033,	MVRCLoss=2.473628,	
Rank[  0]Epoch[4] Batch [5800]	Speed: 27.32 samples/s ETA: 1 d 14 h 35 m	Data: 0.012 Tran: 0.007 F: 0.150 B: 0.292 O: 1.874 M: 0.007	Train-MLMAcc=0.614568,	MVRCAccuracy=0.661585,	MLMLossWVC=1.883033,	MVRCLoss=2.473628,	
Rank[  1]Epoch[4] Batch [5800]	Speed: 27.32 samples/s ETA: 1 d 14 h 35 m	Data: 1.754 Tran: 0.007 F: 0.151 B: 0.294 O: 0.128 M: 0.008	Train-MLMAcc=0.614568,	MVRCAccuracy=0.661585,	MLMLossWVC=1.883033,	MVRCLoss=2.473628,	
Rank[  2]Epoch[4] Batch [5900]	Speed: 27.86 samples/s ETA: 1 d 13 h 46 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.827 M: 0.007	Train-MLMAcc=0.614555,	MVRCAccuracy=0.661644,	MLMLossWVC=1.883153,	MVRCLoss=2.473642,	
Rank[  0]Epoch[4] Batch [5900]	Speed: 27.86 samples/s ETA: 1 d 13 h 46 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.294 O: 1.829 M: 0.009	Train-MLMAcc=0.614555,	MVRCAccuracy=0.661644,	MLMLossWVC=1.883153,	MVRCLoss=2.473642,	
Rank[  1]Epoch[4] Batch [5900]	Speed: 27.86 samples/s ETA: 1 d 13 h 46 m	Data: 1.788 Tran: 0.007 F: 0.150 B: 0.292 O: 0.052 M: 0.007	Train-MLMAcc=0.614555,	MVRCAccuracy=0.661644,	MLMLossWVC=1.883153,	MVRCLoss=2.473642,	
Rank[  3]Epoch[4] Batch [5900]	Speed: 27.86 samples/s ETA: 1 d 13 h 46 m	Data: 0.012 Tran: 0.008 F: 0.150 B: 0.297 O: 1.822 M: 0.006	Train-MLMAcc=0.614555,	MVRCAccuracy=0.661644,	MLMLossWVC=1.883153,	MVRCLoss=2.473642,	
Rank[  1]Epoch[4] Batch [6000]	Speed: 27.72 samples/s ETA: 1 d 13 h 54 m	Data: 1.787 Tran: 0.007 F: 0.151 B: 0.293 O: 0.062 M: 0.007	Train-MLMAcc=0.614573,	MVRCAccuracy=0.661644,	MLMLossWVC=1.883156,	MVRCLoss=2.473619,	
Rank[  3]Epoch[4] Batch [6000]	Speed: 27.72 samples/s ETA: 1 d 13 h 54 m	Data: 0.013 Tran: 0.007 F: 0.150 B: 0.297 O: 1.836 M: 0.005	Train-MLMAcc=0.614573,	MVRCAccuracy=0.661644,	MLMLossWVC=1.883156,	MVRCLoss=2.473619,	
Rank[  0]Epoch[4] Batch [6000]	Speed: 27.72 samples/s ETA: 1 d 13 h 54 m	Data: 0.017 Tran: 0.008 F: 0.150 B: 0.293 O: 1.834 M: 0.007	Train-MLMAcc=0.614573,	MVRCAccuracy=0.661644,	MLMLossWVC=1.883156,	MVRCLoss=2.473619,	
Rank[  2]Epoch[4] Batch [6000]	Speed: 27.72 samples/s ETA: 1 d 13 h 54 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.294 O: 1.844 M: 0.008	Train-MLMAcc=0.614573,	MVRCAccuracy=0.661644,	MLMLossWVC=1.883156,	MVRCLoss=2.473619,	
Rank[  0]Epoch[4] Batch [6100]	Speed: 27.50 samples/s ETA: 1 d 14 h  8 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.292 O: 1.863 M: 0.008	Train-MLMAcc=0.614559,	MVRCAccuracy=0.661695,	MLMLossWVC=1.883027,	MVRCLoss=2.473534,	
Rank[  3]Epoch[4] Batch [6100]	Speed: 27.50 samples/s ETA: 1 d 14 h  8 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.300 O: 1.855 M: 0.006	Train-MLMAcc=0.614559,	MVRCAccuracy=0.661695,	MLMLossWVC=1.883027,	MVRCLoss=2.473534,	
Rank[  1]Epoch[4] Batch [6100]	Speed: 27.50 samples/s ETA: 1 d 14 h  8 m	Data: 1.820 Tran: 0.006 F: 0.150 B: 0.293 O: 0.048 M: 0.009	Train-MLMAcc=0.614559,	MVRCAccuracy=0.661695,	MLMLossWVC=1.883027,	MVRCLoss=2.473534,	
Rank[  2]Epoch[4] Batch [6100]	Speed: 27.50 samples/s ETA: 1 d 14 h  8 m	Data: 0.079 Tran: 0.006 F: 0.150 B: 0.295 O: 1.788 M: 0.008	Train-MLMAcc=0.614559,	MVRCAccuracy=0.661695,	MLMLossWVC=1.883027,	MVRCLoss=2.473534,	
Rank[  2]Epoch[4] Batch [6200]	Speed: 27.85 samples/s ETA: 1 d 13 h 35 m	Data: 0.126 Tran: 0.006 F: 0.149 B: 0.295 O: 1.714 M: 0.005	Train-MLMAcc=0.614558,	MVRCAccuracy=0.661729,	MLMLossWVC=1.882818,	MVRCLoss=2.473434,	
Rank[  0]Epoch[4] Batch [6200]	Speed: 27.85 samples/s ETA: 1 d 13 h 35 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.293 O: 1.833 M: 0.007	Train-MLMAcc=0.614558,	MVRCAccuracy=0.661729,	MLMLossWVC=1.882818,	MVRCLoss=2.473434,	
Rank[  1]Epoch[4] Batch [6200]	Speed: 27.85 samples/s ETA: 1 d 13 h 35 m	Data: 1.794 Tran: 0.006 F: 0.149 B: 0.291 O: 0.049 M: 0.007	Train-MLMAcc=0.614558,	MVRCAccuracy=0.661729,	MLMLossWVC=1.882818,	MVRCLoss=2.473434,	
Rank[  3]Epoch[4] Batch [6200]	Speed: 27.85 samples/s ETA: 1 d 13 h 35 m	Data: 0.024 Tran: 0.007 F: 0.149 B: 0.297 O: 1.815 M: 0.005	Train-MLMAcc=0.614558,	MVRCAccuracy=0.661729,	MLMLossWVC=1.882818,	MVRCLoss=2.473434,	
Rank[  3]Epoch[4] Batch [6300]	Speed: 27.62 samples/s ETA: 1 d 13 h 51 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.848 M: 0.007	Train-MLMAcc=0.614619,	MVRCAccuracy=0.661780,	MLMLossWVC=1.882387,	MVRCLoss=2.473393,	
Rank[  2]Epoch[4] Batch [6300]	Speed: 27.62 samples/s ETA: 1 d 13 h 51 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.849 M: 0.007	Train-MLMAcc=0.614619,	MVRCAccuracy=0.661780,	MLMLossWVC=1.882387,	MVRCLoss=2.473393,	
Rank[  0]Epoch[4] Batch [6300]	Speed: 27.62 samples/s ETA: 1 d 13 h 51 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.852 M: 0.010	Train-MLMAcc=0.614619,	MVRCAccuracy=0.661780,	MLMLossWVC=1.882387,	MVRCLoss=2.473393,	
Rank[  1]Epoch[4] Batch [6300]	Speed: 27.62 samples/s ETA: 1 d 13 h 51 m	Data: 1.806 Tran: 0.007 F: 0.150 B: 0.293 O: 0.053 M: 0.009	Train-MLMAcc=0.614619,	MVRCAccuracy=0.661780,	MLMLossWVC=1.882387,	MVRCLoss=2.473393,	
Rank[  1]Epoch[4] Batch [6400]	Speed: 28.02 samples/s ETA: 1 d 13 h 14 m	Data: 1.762 Tran: 0.007 F: 0.151 B: 0.296 O: 0.059 M: 0.009	Train-MLMAcc=0.614618,	MVRCAccuracy=0.661817,	MLMLossWVC=1.882132,	MVRCLoss=2.473211,	
Rank[  3]Epoch[4] Batch [6400]	Speed: 28.02 samples/s ETA: 1 d 13 h 14 m	Data: 0.030 Tran: 0.007 F: 0.150 B: 0.298 O: 1.791 M: 0.007	Train-MLMAcc=0.614618,	MVRCAccuracy=0.661817,	MLMLossWVC=1.882132,	MVRCLoss=2.473211,	
Rank[  0]Epoch[4] Batch [6400]	Speed: 28.02 samples/s ETA: 1 d 13 h 14 m	Data: 0.068 Tran: 0.007 F: 0.150 B: 0.292 O: 1.758 M: 0.007	Train-MLMAcc=0.614618,	MVRCAccuracy=0.661817,	MLMLossWVC=1.882132,	MVRCLoss=2.473211,	
Rank[  2]Epoch[4] Batch [6400]	Speed: 28.02 samples/s ETA: 1 d 13 h 14 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.296 O: 1.815 M: 0.008	Train-MLMAcc=0.614618,	MVRCAccuracy=0.661817,	MLMLossWVC=1.882132,	MVRCLoss=2.473211,	
Rank[  2]Epoch[4] Batch [6500]	Speed: 27.05 samples/s ETA: 1 d 14 h 31 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.895 M: 0.009	Train-MLMAcc=0.614684,	MVRCAccuracy=0.661843,	MLMLossWVC=1.881724,	MVRCLoss=2.473196,	
Rank[  1]Epoch[4] Batch [6500]	Speed: 27.05 samples/s ETA: 1 d 14 h 31 m	Data: 1.715 Tran: 0.007 F: 0.150 B: 0.291 O: 0.194 M: 0.008	Train-MLMAcc=0.614684,	MVRCAccuracy=0.661843,	MLMLossWVC=1.881724,	MVRCLoss=2.473196,	
Rank[  3]Epoch[4] Batch [6500]	Speed: 27.05 samples/s ETA: 1 d 14 h 31 m	Data: 0.107 Tran: 0.007 F: 0.150 B: 0.298 O: 1.794 M: 0.009	Train-MLMAcc=0.614684,	MVRCAccuracy=0.661843,	MLMLossWVC=1.881724,	MVRCLoss=2.473196,	
Rank[  0]Epoch[4] Batch [6500]	Speed: 27.05 samples/s ETA: 1 d 14 h 31 m	Data: 0.396 Tran: 0.007 F: 0.151 B: 0.293 O: 1.512 M: 0.007	Train-MLMAcc=0.614684,	MVRCAccuracy=0.661843,	MLMLossWVC=1.881724,	MVRCLoss=2.473196,	
Rank[  0]Epoch[4] Batch [6600]	Speed: 27.52 samples/s ETA: 1 d 13 h 47 m	Data: 1.071 Tran: 0.007 F: 0.150 B: 0.293 O: 0.796 M: 0.008	Train-MLMAcc=0.614686,	MVRCAccuracy=0.661851,	MLMLossWVC=1.881659,	MVRCLoss=2.473176,	
Rank[  3]Epoch[4] Batch [6600]	Speed: 27.52 samples/s ETA: 1 d 13 h 47 m	Data: 0.121 Tran: 0.007 F: 0.150 B: 0.298 O: 1.742 M: 0.008	Train-MLMAcc=0.614686,	MVRCAccuracy=0.661851,	MLMLossWVC=1.881659,	MVRCLoss=2.473176,	
Rank[  1]Epoch[4] Batch [6600]	Speed: 27.52 samples/s ETA: 1 d 13 h 47 m	Data: 0.875 Tran: 0.007 F: 0.150 B: 0.295 O: 0.991 M: 0.008	Train-MLMAcc=0.614686,	MVRCAccuracy=0.661851,	MLMLossWVC=1.881659,	MVRCLoss=2.473176,	
Rank[  2]Epoch[4] Batch [6600]	Speed: 27.52 samples/s ETA: 1 d 13 h 47 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.856 M: 0.005	Train-MLMAcc=0.614686,	MVRCAccuracy=0.661851,	MLMLossWVC=1.881659,	MVRCLoss=2.473176,	
Rank[  3]Epoch[4] Batch [6700]	Speed: 28.22 samples/s ETA: 1 d 12 h 47 m	Data: 0.947 Tran: 0.006 F: 0.150 B: 0.296 O: 0.861 M: 0.007	Train-MLMAcc=0.614741,	MVRCAccuracy=0.661914,	MLMLossWVC=1.881207,	MVRCLoss=2.473128,	
Rank[  1]Epoch[4] Batch [6700]	Speed: 28.22 samples/s ETA: 1 d 12 h 47 m	Data: 0.701 Tran: 0.006 F: 0.151 B: 0.297 O: 1.105 M: 0.007	Train-MLMAcc=0.614741,	MVRCAccuracy=0.661914,	MLMLossWVC=1.881207,	MVRCLoss=2.473128,	
Rank[  0]Epoch[4] Batch [6700]	Speed: 28.22 samples/s ETA: 1 d 12 h 47 m	Data: 1.507 Tran: 0.006 F: 0.150 B: 0.293 O: 0.304 M: 0.007	Train-MLMAcc=0.614741,	MVRCAccuracy=0.661914,	MLMLossWVC=1.881207,	MVRCLoss=2.473128,	
Rank[  2]Epoch[4] Batch [6700]	Speed: 28.22 samples/s ETA: 1 d 12 h 47 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.296 O: 1.802 M: 0.006	Train-MLMAcc=0.614741,	MVRCAccuracy=0.661914,	MLMLossWVC=1.881207,	MVRCLoss=2.473128,	
Rank[  1]Epoch[4] Batch [6800]	Speed: 27.39 samples/s ETA: 1 d 13 h 50 m	Data: 0.471 Tran: 0.007 F: 0.150 B: 0.295 O: 1.405 M: 0.009	Train-MLMAcc=0.614762,	MVRCAccuracy=0.661950,	MLMLossWVC=1.880854,	MVRCLoss=2.473018,	
Rank[  0]Epoch[4] Batch [6800]	Speed: 27.39 samples/s ETA: 1 d 13 h 50 m	Data: 0.148 Tran: 0.007 F: 0.150 B: 0.293 O: 1.731 M: 0.007	Train-MLMAcc=0.614762,	MVRCAccuracy=0.661950,	MLMLossWVC=1.880854,	MVRCLoss=2.473018,	
Rank[  2]Epoch[4] Batch [6800]	Speed: 27.39 samples/s ETA: 1 d 13 h 50 m	Data: 0.009 Tran: 0.007 F: 0.150 B: 0.298 O: 1.865 M: 0.007	Train-MLMAcc=0.614762,	MVRCAccuracy=0.661950,	MLMLossWVC=1.880854,	MVRCLoss=2.473018,	
Rank[  3]Epoch[4] Batch [6800]	Speed: 27.39 samples/s ETA: 1 d 13 h 50 m	Data: 1.739 Tran: 0.006 F: 0.150 B: 0.295 O: 0.138 M: 0.008	Train-MLMAcc=0.614762,	MVRCAccuracy=0.661950,	MLMLossWVC=1.880854,	MVRCLoss=2.473018,	
Rank[  0]Epoch[4] Batch [6900]	Speed: 27.83 samples/s ETA: 1 d 13 h 10 m	Data: 0.293 Tran: 0.007 F: 0.149 B: 0.291 O: 1.550 M: 0.009	Train-MLMAcc=0.614718,	MVRCAccuracy=0.661964,	MLMLossWVC=1.881121,	MVRCLoss=2.472946,	
Rank[  3]Epoch[4] Batch [6900]	Speed: 27.83 samples/s ETA: 1 d 13 h 10 m	Data: 1.739 Tran: 0.006 F: 0.151 B: 0.298 O: 0.099 M: 0.007	Train-MLMAcc=0.614718,	MVRCAccuracy=0.661964,	MLMLossWVC=1.881121,	MVRCLoss=2.472946,	
Rank[  2]Epoch[4] Batch [6900]	Speed: 27.83 samples/s ETA: 1 d 13 h 10 m	Data: 0.015 Tran: 0.007 F: 0.149 B: 0.296 O: 1.826 M: 0.006	Train-MLMAcc=0.614718,	MVRCAccuracy=0.661964,	MLMLossWVC=1.881121,	MVRCLoss=2.472946,	
Rank[  1]Epoch[4] Batch [6900]	Speed: 27.83 samples/s ETA: 1 d 13 h 10 m	Data: 0.304 Tran: 0.007 F: 0.150 B: 0.296 O: 1.534 M: 0.008	Train-MLMAcc=0.614718,	MVRCAccuracy=0.661964,	MLMLossWVC=1.881121,	MVRCLoss=2.472946,	
Rank[  0]Epoch[4] Batch [7000]	Speed: 25.77 samples/s ETA: 1 d 16 h  5 m	Data: 0.280 Tran: 0.007 F: 0.149 B: 0.291 O: 1.748 M: 0.008	Train-MLMAcc=0.614742,	MVRCAccuracy=0.661958,	MLMLossWVC=1.881059,	MVRCLoss=2.472952,	
Rank[  1]Epoch[4] Batch [7000]	Speed: 25.77 samples/s ETA: 1 d 16 h  5 m	Data: 0.440 Tran: 0.007 F: 0.150 B: 0.295 O: 1.584 M: 0.007	Train-MLMAcc=0.614742,	MVRCAccuracy=0.661958,	MLMLossWVC=1.881059,	MVRCLoss=2.472952,	
Rank[  2]Epoch[4] Batch [7000]	Speed: 25.77 samples/s ETA: 1 d 16 h  5 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 2.017 M: 0.005	Train-MLMAcc=0.614742,	MVRCAccuracy=0.661958,	MLMLossWVC=1.881059,	MVRCLoss=2.472952,	
Rank[  3]Epoch[4] Batch [7000]	Speed: 25.77 samples/s ETA: 1 d 16 h  5 m	Data: 1.972 Tran: 0.007 F: 0.151 B: 0.299 O: 0.047 M: 0.007	Train-MLMAcc=0.614742,	MVRCAccuracy=0.661958,	MLMLossWVC=1.881059,	MVRCLoss=2.472952,	
Rank[  2]Epoch[4] Batch [7100]	Speed: 25.15 samples/s ETA: 1 d 17 h  0 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 2.078 M: 0.005	Train-MLMAcc=0.614763,	MVRCAccuracy=0.662009,	MLMLossWVC=1.880861,	MVRCLoss=2.472907,	
Rank[  1]Epoch[4] Batch [7100]	Speed: 25.15 samples/s ETA: 1 d 17 h  0 m	Data: 0.683 Tran: 0.006 F: 0.150 B: 0.296 O: 1.403 M: 0.007	Train-MLMAcc=0.614763,	MVRCAccuracy=0.662009,	MLMLossWVC=1.880861,	MVRCLoss=2.472907,	
Rank[  0]Epoch[4] Batch [7100]	Speed: 25.15 samples/s ETA: 1 d 17 h  0 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 2.085 M: 0.005	Train-MLMAcc=0.614763,	MVRCAccuracy=0.662009,	MLMLossWVC=1.880861,	MVRCLoss=2.472907,	
Rank[  3]Epoch[4] Batch [7100]	Speed: 25.15 samples/s ETA: 1 d 17 h  0 m	Data: 2.036 Tran: 0.006 F: 0.150 B: 0.298 O: 0.048 M: 0.006	Train-MLMAcc=0.614763,	MVRCAccuracy=0.662009,	MLMLossWVC=1.880861,	MVRCLoss=2.472907,	
Rank[  1]Epoch[4] Batch [7200]	Speed: 25.80 samples/s ETA: 1 d 15 h 54 m	Data: 1.114 Tran: 0.006 F: 0.151 B: 0.297 O: 0.904 M: 0.008	Train-MLMAcc=0.614704,	MVRCAccuracy=0.662026,	MLMLossWVC=1.881091,	MVRCLoss=2.472834,	
Rank[  0]Epoch[4] Batch [7200]	Speed: 25.80 samples/s ETA: 1 d 15 h 54 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 2.017 M: 0.005	Train-MLMAcc=0.614704,	MVRCAccuracy=0.662026,	MLMLossWVC=1.881091,	MVRCLoss=2.472834,	
Rank[  2]Epoch[4] Batch [7200]	Speed: 25.80 samples/s ETA: 1 d 15 h 54 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 2.012 M: 0.008	Train-MLMAcc=0.614704,	MVRCAccuracy=0.662026,	MLMLossWVC=1.881091,	MVRCLoss=2.472834,	
Rank[  3]Epoch[4] Batch [7200]	Speed: 25.80 samples/s ETA: 1 d 15 h 54 m	Data: 1.963 Tran: 0.006 F: 0.151 B: 0.300 O: 0.052 M: 0.008	Train-MLMAcc=0.614704,	MVRCAccuracy=0.662026,	MLMLossWVC=1.881091,	MVRCLoss=2.472834,	
Rank[  0]Epoch[4] Batch [7300]	Speed: 24.96 samples/s ETA: 1 d 17 h 10 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.294 O: 2.099 M: 0.005	Train-MLMAcc=0.614744,	MVRCAccuracy=0.662060,	MLMLossWVC=1.880739,	MVRCLoss=2.472787,	
Rank[  1]Epoch[4] Batch [7300]	Speed: 24.96 samples/s ETA: 1 d 17 h 10 m	Data: 0.843 Tran: 0.007 F: 0.150 B: 0.295 O: 1.263 M: 0.006	Train-MLMAcc=0.614744,	MVRCAccuracy=0.662060,	MLMLossWVC=1.880739,	MVRCLoss=2.472787,	
Rank[  2]Epoch[4] Batch [7300]	Speed: 24.96 samples/s ETA: 1 d 17 h 10 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 2.096 M: 0.006	Train-MLMAcc=0.614744,	MVRCAccuracy=0.662060,	MLMLossWVC=1.880739,	MVRCLoss=2.472787,	
Rank[  3]Epoch[4] Batch [7300]	Speed: 24.96 samples/s ETA: 1 d 17 h 10 m	Data: 1.973 Tran: 0.007 F: 0.151 B: 0.298 O: 0.127 M: 0.006	Train-MLMAcc=0.614744,	MVRCAccuracy=0.662060,	MLMLossWVC=1.880739,	MVRCLoss=2.472787,	
Rank[  3]Epoch[4] Batch [7400]	Speed: 25.28 samples/s ETA: 1 d 16 h 34 m	Data: 2.019 Tran: 0.007 F: 0.151 B: 0.298 O: 0.047 M: 0.008	Train-MLMAcc=0.614822,	MVRCAccuracy=0.662073,	MLMLossWVC=1.880380,	MVRCLoss=2.472761,	
Rank[  0]Epoch[4] Batch [7400]	Speed: 25.28 samples/s ETA: 1 d 16 h 34 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.290 O: 2.068 M: 0.009	Train-MLMAcc=0.614822,	MVRCAccuracy=0.662073,	MLMLossWVC=1.880380,	MVRCLoss=2.472761,	
Rank[  1]Epoch[4] Batch [7400]	Speed: 25.28 samples/s ETA: 1 d 16 h 34 m	Data: 0.110 Tran: 0.007 F: 0.150 B: 0.294 O: 1.964 M: 0.007	Train-MLMAcc=0.614822,	MVRCAccuracy=0.662073,	MLMLossWVC=1.880380,	MVRCLoss=2.472761,	
Rank[  2]Epoch[4] Batch [7400]	Speed: 25.28 samples/s ETA: 1 d 16 h 34 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 2.065 M: 0.006	Train-MLMAcc=0.614822,	MVRCAccuracy=0.662073,	MLMLossWVC=1.880380,	MVRCLoss=2.472761,	
Rank[  3]Epoch[4] Batch [7500]	Speed: 25.92 samples/s ETA: 1 d 15 h 30 m	Data: 1.955 Tran: 0.007 F: 0.152 B: 0.299 O: 0.048 M: 0.007	Train-MLMAcc=0.614913,	MVRCAccuracy=0.662078,	MLMLossWVC=1.880073,	MVRCLoss=2.472746,	
Rank[  1]Epoch[4] Batch [7500]	Speed: 25.92 samples/s ETA: 1 d 15 h 30 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 2.000 M: 0.011	Train-MLMAcc=0.614913,	MVRCAccuracy=0.662078,	MLMLossWVC=1.880073,	MVRCLoss=2.472746,	
Rank[  2]Epoch[4] Batch [7500]	Speed: 25.92 samples/s ETA: 1 d 15 h 30 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.997 M: 0.009	Train-MLMAcc=0.614913,	MVRCAccuracy=0.662078,	MLMLossWVC=1.880073,	MVRCLoss=2.472746,	
Rank[  0]Epoch[4] Batch [7500]	Speed: 25.92 samples/s ETA: 1 d 15 h 30 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 2.003 M: 0.008	Train-MLMAcc=0.614913,	MVRCAccuracy=0.662078,	MLMLossWVC=1.880073,	MVRCLoss=2.472746,	
Rank[  3]Epoch[4] Batch [7600]	Speed: 25.48 samples/s ETA: 1 d 16 h  7 m	Data: 1.994 Tran: 0.007 F: 0.150 B: 0.298 O: 0.051 M: 0.010	Train-MLMAcc=0.614901,	MVRCAccuracy=0.662089,	MLMLossWVC=1.879918,	MVRCLoss=2.472670,	
Rank[  2]Epoch[4] Batch [7600]	Speed: 25.48 samples/s ETA: 1 d 16 h  7 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.326 O: 2.011 M: 0.009	Train-MLMAcc=0.614901,	MVRCAccuracy=0.662089,	MLMLossWVC=1.879918,	MVRCLoss=2.472670,	
Rank[  0]Epoch[4] Batch [7600]	Speed: 25.48 samples/s ETA: 1 d 16 h  7 m	Data: 0.010 Tran: 0.007 F: 0.149 B: 0.319 O: 2.015 M: 0.011	Train-MLMAcc=0.614901,	MVRCAccuracy=0.662089,	MLMLossWVC=1.879918,	MVRCLoss=2.472670,	
Rank[  1]Epoch[4] Batch [7600]	Speed: 25.48 samples/s ETA: 1 d 16 h  7 m	Data: 0.124 Tran: 0.007 F: 0.160 B: 0.298 O: 1.914 M: 0.007	Train-MLMAcc=0.614901,	MVRCAccuracy=0.662089,	MLMLossWVC=1.879918,	MVRCLoss=2.472670,	
Rank[  1]Epoch[4] Batch [7700]	Speed: 25.07 samples/s ETA: 1 d 16 h 42 m	Data: 0.146 Tran: 0.007 F: 0.150 B: 0.296 O: 1.947 M: 0.006	Train-MLMAcc=0.614885,	MVRCAccuracy=0.662123,	MLMLossWVC=1.880007,	MVRCLoss=2.472579,	
Rank[  3]Epoch[4] Batch [7700]	Speed: 25.07 samples/s ETA: 1 d 16 h 42 m	Data: 1.906 Tran: 0.007 F: 0.150 B: 0.297 O: 0.185 M: 0.007	Train-MLMAcc=0.614885,	MVRCAccuracy=0.662123,	MLMLossWVC=1.880007,	MVRCLoss=2.472579,	
Rank[  2]Epoch[4] Batch [7700]	Speed: 25.07 samples/s ETA: 1 d 16 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 2.084 M: 0.005	Train-MLMAcc=0.614885,	MVRCAccuracy=0.662123,	MLMLossWVC=1.880007,	MVRCLoss=2.472579,	
Rank[  0]Epoch[4] Batch [7700]	Speed: 25.07 samples/s ETA: 1 d 16 h 42 m	Data: 0.350 Tran: 0.007 F: 0.150 B: 0.293 O: 1.745 M: 0.007	Train-MLMAcc=0.614885,	MVRCAccuracy=0.662123,	MLMLossWVC=1.880007,	MVRCLoss=2.472579,	
Rank[  3]Epoch[4] Batch [7800]	Speed: 25.45 samples/s ETA: 1 d 16 h  2 m	Data: 1.346 Tran: 0.007 F: 0.151 B: 0.300 O: 0.704 M: 0.006	Train-MLMAcc=0.614866,	MVRCAccuracy=0.662143,	MLMLossWVC=1.880029,	MVRCLoss=2.472546,	
Rank[  0]Epoch[4] Batch [7800]	Speed: 25.45 samples/s ETA: 1 d 16 h  2 m	Data: 0.703 Tran: 0.007 F: 0.149 B: 0.290 O: 1.359 M: 0.006	Train-MLMAcc=0.614866,	MVRCAccuracy=0.662143,	MLMLossWVC=1.880029,	MVRCLoss=2.472546,	
Rank[  1]Epoch[4] Batch [7800]	Speed: 25.45 samples/s ETA: 1 d 16 h  2 m	Data: 0.046 Tran: 0.007 F: 0.150 B: 0.297 O: 2.008 M: 0.006	Train-MLMAcc=0.614866,	MVRCAccuracy=0.662143,	MLMLossWVC=1.880029,	MVRCLoss=2.472546,	
Rank[  2]Epoch[4] Batch [7800]	Speed: 25.45 samples/s ETA: 1 d 16 h  2 m	Data: 0.097 Tran: 0.007 F: 0.150 B: 0.298 O: 1.956 M: 0.006	Train-MLMAcc=0.614866,	MVRCAccuracy=0.662143,	MLMLossWVC=1.880029,	MVRCLoss=2.472546,	
Rank[  3]Epoch[4] Batch [7900]	Speed: 25.28 samples/s ETA: 1 d 16 h 13 m	Data: 1.530 Tran: 0.007 F: 0.150 B: 0.297 O: 0.538 M: 0.008	Train-MLMAcc=0.614904,	MVRCAccuracy=0.662191,	MLMLossWVC=1.879705,	MVRCLoss=2.472430,	
Rank[  1]Epoch[4] Batch [7900]	Speed: 25.28 samples/s ETA: 1 d 16 h 13 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.297 O: 2.060 M: 0.009	Train-MLMAcc=0.614904,	MVRCAccuracy=0.662191,	MLMLossWVC=1.879705,	MVRCLoss=2.472430,	
Rank[  0]Epoch[4] Batch [7900]	Speed: 25.28 samples/s ETA: 1 d 16 h 13 m	Data: 0.191 Tran: 0.007 F: 0.150 B: 0.291 O: 1.886 M: 0.006	Train-MLMAcc=0.614904,	MVRCAccuracy=0.662191,	MLMLossWVC=1.879705,	MVRCLoss=2.472430,	
Rank[  2]Epoch[4] Batch [7900]	Speed: 25.28 samples/s ETA: 1 d 16 h 13 m	Data: 0.503 Tran: 0.007 F: 0.150 B: 0.297 O: 1.565 M: 0.008	Train-MLMAcc=0.614904,	MVRCAccuracy=0.662191,	MLMLossWVC=1.879705,	MVRCLoss=2.472430,	
Rank[  0]Epoch[4] Batch [8000]	Speed: 25.42 samples/s ETA: 1 d 15 h 56 m	Data: 0.445 Tran: 0.007 F: 0.150 B: 0.292 O: 1.616 M: 0.007	Train-MLMAcc=0.614903,	MVRCAccuracy=0.662214,	MLMLossWVC=1.879600,	MVRCLoss=2.472373,	
Rank[  1]Epoch[4] Batch [8000]	Speed: 25.42 samples/s ETA: 1 d 15 h 56 m	Data: 0.042 Tran: 0.007 F: 0.150 B: 0.296 O: 2.013 M: 0.009	Train-MLMAcc=0.614903,	MVRCAccuracy=0.662214,	MLMLossWVC=1.879600,	MVRCLoss=2.472373,	
Rank[  3]Epoch[4] Batch [8000]	Speed: 25.42 samples/s ETA: 1 d 15 h 56 m	Data: 1.758 Tran: 0.007 F: 0.151 B: 0.298 O: 0.294 M: 0.009	Train-MLMAcc=0.614903,	MVRCAccuracy=0.662214,	MLMLossWVC=1.879600,	MVRCLoss=2.472373,	
Rank[  2]Epoch[4] Batch [8000]	Speed: 25.42 samples/s ETA: 1 d 15 h 56 m	Data: 1.315 Tran: 0.007 F: 0.150 B: 0.297 O: 0.738 M: 0.010	Train-MLMAcc=0.614903,	MVRCAccuracy=0.662214,	MLMLossWVC=1.879600,	MVRCLoss=2.472373,	
Rank[  0]Epoch[4] Batch [8100]	Speed: 25.23 samples/s ETA: 1 d 16 h 10 m	Data: 1.472 Tran: 0.006 F: 0.150 B: 0.292 O: 0.611 M: 0.005	Train-MLMAcc=0.614932,	MVRCAccuracy=0.662244,	MLMLossWVC=1.879623,	MVRCLoss=2.472283,	
Rank[  3]Epoch[4] Batch [8100]	Speed: 25.23 samples/s ETA: 1 d 16 h 10 m	Data: 1.187 Tran: 0.007 F: 0.150 B: 0.296 O: 0.892 M: 0.005	Train-MLMAcc=0.614932,	MVRCAccuracy=0.662244,	MLMLossWVC=1.879623,	MVRCLoss=2.472283,	
Rank[  1]Epoch[4] Batch [8100]	Speed: 25.23 samples/s ETA: 1 d 16 h 10 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 2.067 M: 0.005	Train-MLMAcc=0.614932,	MVRCAccuracy=0.662244,	MLMLossWVC=1.879623,	MVRCLoss=2.472283,	
Rank[  2]Epoch[4] Batch [8100]	Speed: 25.23 samples/s ETA: 1 d 16 h 10 m	Data: 0.274 Tran: 0.007 F: 0.150 B: 0.297 O: 1.803 M: 0.005	Train-MLMAcc=0.614932,	MVRCAccuracy=0.662244,	MLMLossWVC=1.879623,	MVRCLoss=2.472283,	
Rank[  0]Epoch[4] Batch [8200]	Speed: 24.85 samples/s ETA: 1 d 16 h 42 m	Data: 1.191 Tran: 0.008 F: 0.185 B: 0.307 O: 0.871 M: 0.011	Train-MLMAcc=0.615021,	MVRCAccuracy=0.662313,	MLMLossWVC=1.879141,	MVRCLoss=2.472145,	
Rank[  2]Epoch[4] Batch [8200]	Speed: 24.85 samples/s ETA: 1 d 16 h 42 m	Data: 0.009 Tran: 0.007 F: 0.154 B: 0.301 O: 2.092 M: 0.010	Train-MLMAcc=0.615021,	MVRCAccuracy=0.662313,	MLMLossWVC=1.879141,	MVRCLoss=2.472145,	
Rank[  3]Epoch[4] Batch [8200]	Speed: 24.85 samples/s ETA: 1 d 16 h 42 m	Data: 1.066 Tran: 0.011 F: 0.193 B: 0.308 O: 0.986 M: 0.010	Train-MLMAcc=0.615021,	MVRCAccuracy=0.662313,	MLMLossWVC=1.879141,	MVRCLoss=2.472145,	
Rank[  1]Epoch[4] Batch [8200]	Speed: 24.85 samples/s ETA: 1 d 16 h 42 m	Data: 0.074 Tran: 0.007 F: 0.156 B: 0.300 O: 2.028 M: 0.008	Train-MLMAcc=0.615021,	MVRCAccuracy=0.662313,	MLMLossWVC=1.879141,	MVRCLoss=2.472145,	
Rank[  3]Epoch[4] Batch [8300]	Speed: 24.89 samples/s ETA: 1 d 16 h 34 m	Data: 1.394 Tran: 0.010 F: 0.170 B: 0.303 O: 0.686 M: 0.007	Train-MLMAcc=0.614992,	MVRCAccuracy=0.662332,	MLMLossWVC=1.879430,	MVRCLoss=2.472082,	
Rank[  1]Epoch[4] Batch [8300]	Speed: 24.89 samples/s ETA: 1 d 16 h 34 m	Data: 0.264 Tran: 0.007 F: 0.153 B: 0.309 O: 1.828 M: 0.007	Train-MLMAcc=0.614992,	MVRCAccuracy=0.662332,	MLMLossWVC=1.879430,	MVRCLoss=2.472082,	
Rank[  0]Epoch[4] Batch [8300]	Speed: 24.89 samples/s ETA: 1 d 16 h 34 m	Data: 0.437 Tran: 0.007 F: 0.152 B: 0.292 O: 1.674 M: 0.007	Train-MLMAcc=0.614992,	MVRCAccuracy=0.662332,	MLMLossWVC=1.879430,	MVRCLoss=2.472082,	
Rank[  2]Epoch[4] Batch [8300]	Speed: 24.89 samples/s ETA: 1 d 16 h 34 m	Data: 0.009 Tran: 0.006 F: 0.151 B: 0.299 O: 2.099 M: 0.006	Train-MLMAcc=0.614992,	MVRCAccuracy=0.662332,	MLMLossWVC=1.879430,	MVRCLoss=2.472082,	
Rank[  3]Epoch[4] Batch [8400]	Speed: 25.50 samples/s ETA: 1 d 15 h 32 m	Data: 1.335 Tran: 0.008 F: 0.171 B: 0.303 O: 0.683 M: 0.007	Train-MLMAcc=0.614995,	MVRCAccuracy=0.662391,	MLMLossWVC=1.879322,	MVRCLoss=2.471979,	
Rank[  0]Epoch[4] Batch [8400]	Speed: 25.50 samples/s ETA: 1 d 15 h 32 m	Data: 0.255 Tran: 0.006 F: 0.149 B: 0.292 O: 1.797 M: 0.008	Train-MLMAcc=0.614995,	MVRCAccuracy=0.662391,	MLMLossWVC=1.879322,	MVRCLoss=2.471979,	
Rank[  1]Epoch[4] Batch [8400]	Speed: 25.50 samples/s ETA: 1 d 15 h 32 m	Data: 0.421 Tran: 0.007 F: 0.150 B: 0.296 O: 1.626 M: 0.008	Train-MLMAcc=0.614995,	MVRCAccuracy=0.662391,	MLMLossWVC=1.879322,	MVRCLoss=2.471979,	
Rank[  2]Epoch[4] Batch [8400]	Speed: 25.50 samples/s ETA: 1 d 15 h 32 m	Data: 0.008 Tran: 0.006 F: 0.149 B: 0.295 O: 2.044 M: 0.006	Train-MLMAcc=0.614995,	MVRCAccuracy=0.662391,	MLMLossWVC=1.879322,	MVRCLoss=2.471979,	
Rank[  2]Epoch[4] Batch [8500]	Speed: 25.07 samples/s ETA: 1 d 16 h  8 m	Data: 0.008 Tran: 0.007 F: 0.168 B: 0.312 O: 2.049 M: 0.007	Train-MLMAcc=0.615005,	MVRCAccuracy=0.662431,	MLMLossWVC=1.879130,	MVRCLoss=2.471885,	
Rank[  1]Epoch[4] Batch [8500]	Speed: 25.07 samples/s ETA: 1 d 16 h  8 m	Data: 0.070 Tran: 0.007 F: 0.169 B: 0.318 O: 1.979 M: 0.009	Train-MLMAcc=0.615005,	MVRCAccuracy=0.662431,	MLMLossWVC=1.879130,	MVRCLoss=2.471885,	
Rank[  0]Epoch[4] Batch [8500]	Speed: 25.07 samples/s ETA: 1 d 16 h  8 m	Data: 0.614 Tran: 0.006 F: 0.159 B: 0.308 O: 1.455 M: 0.009	Train-MLMAcc=0.615005,	MVRCAccuracy=0.662431,	MLMLossWVC=1.879130,	MVRCLoss=2.471885,	
Rank[  3]Epoch[4] Batch [8500]	Speed: 25.07 samples/s ETA: 1 d 16 h  8 m	Data: 1.332 Tran: 0.007 F: 0.169 B: 0.315 O: 0.720 M: 0.008	Train-MLMAcc=0.615005,	MVRCAccuracy=0.662431,	MLMLossWVC=1.879130,	MVRCLoss=2.471885,	
Rank[  3]Epoch[4] Batch [8600]	Speed: 24.92 samples/s ETA: 1 d 16 h 18 m	Data: 1.443 Tran: 0.007 F: 0.166 B: 0.308 O: 0.636 M: 0.007	Train-MLMAcc=0.614956,	MVRCAccuracy=0.662449,	MLMLossWVC=1.879229,	MVRCLoss=2.471804,	
Rank[  0]Epoch[4] Batch [8600]	Speed: 24.92 samples/s ETA: 1 d 16 h 18 m	Data: 0.467 Tran: 0.007 F: 0.159 B: 0.298 O: 1.628 M: 0.008	Train-MLMAcc=0.614956,	MVRCAccuracy=0.662449,	MLMLossWVC=1.879229,	MVRCLoss=2.471804,	
Rank[  1]Epoch[4] Batch [8600]	Speed: 24.92 samples/s ETA: 1 d 16 h 18 m	Data: 0.114 Tran: 0.007 F: 0.160 B: 0.319 O: 1.960 M: 0.007	Train-MLMAcc=0.614956,	MVRCAccuracy=0.662449,	MLMLossWVC=1.879229,	MVRCLoss=2.471804,	
Rank[  2]Epoch[4] Batch [8600]	Speed: 24.92 samples/s ETA: 1 d 16 h 18 m	Data: 0.008 Tran: 0.007 F: 0.159 B: 0.306 O: 2.080 M: 0.007	Train-MLMAcc=0.614956,	MVRCAccuracy=0.662449,	MLMLossWVC=1.879229,	MVRCLoss=2.471804,	
Rank[  1]Epoch[4] Batch [8700]	Speed: 24.71 samples/s ETA: 1 d 16 h 35 m	Data: 0.138 Tran: 0.008 F: 0.162 B: 0.311 O: 1.958 M: 0.011	Train-MLMAcc=0.614992,	MVRCAccuracy=0.662489,	MLMLossWVC=1.879041,	MVRCLoss=2.471765,	
Rank[  3]Epoch[4] Batch [8700]	Speed: 24.71 samples/s ETA: 1 d 16 h 35 m	Data: 0.649 Tran: 0.006 F: 0.158 B: 0.302 O: 1.462 M: 0.011	Train-MLMAcc=0.614992,	MVRCAccuracy=0.662489,	MLMLossWVC=1.879041,	MVRCLoss=2.471765,	
Rank[  0]Epoch[4] Batch [8700]	Speed: 24.71 samples/s ETA: 1 d 16 h 35 m	Data: 1.257 Tran: 0.008 F: 0.157 B: 0.316 O: 0.838 M: 0.013	Train-MLMAcc=0.614992,	MVRCAccuracy=0.662489,	MLMLossWVC=1.879041,	MVRCLoss=2.471765,	
Rank[  2]Epoch[4] Batch [8700]	Speed: 24.71 samples/s ETA: 1 d 16 h 35 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.313 O: 2.100 M: 0.010	Train-MLMAcc=0.614992,	MVRCAccuracy=0.662489,	MLMLossWVC=1.879041,	MVRCLoss=2.471765,	
Rank[  3]Epoch[4] Batch [8800]	Speed: 24.69 samples/s ETA: 1 d 16 h 32 m	Data: 1.075 Tran: 0.006 F: 0.151 B: 0.300 O: 1.047 M: 0.011	Train-MLMAcc=0.615004,	MVRCAccuracy=0.662511,	MLMLossWVC=1.878930,	MVRCLoss=2.471704,	
Rank[  0]Epoch[4] Batch [8800]	Speed: 24.69 samples/s ETA: 1 d 16 h 32 m	Data: 0.433 Tran: 0.008 F: 0.158 B: 0.293 O: 1.690 M: 0.009	Train-MLMAcc=0.615004,	MVRCAccuracy=0.662511,	MLMLossWVC=1.878930,	MVRCLoss=2.471704,	
Rank[  2]Epoch[4] Batch [8800]	Speed: 24.69 samples/s ETA: 1 d 16 h 32 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 2.119 M: 0.011	Train-MLMAcc=0.615004,	MVRCAccuracy=0.662511,	MLMLossWVC=1.878930,	MVRCLoss=2.471704,	
Rank[  1]Epoch[4] Batch [8800]	Speed: 24.69 samples/s ETA: 1 d 16 h 32 m	Data: 0.544 Tran: 0.008 F: 0.167 B: 0.306 O: 1.557 M: 0.008	Train-MLMAcc=0.615004,	MVRCAccuracy=0.662511,	MLMLossWVC=1.878930,	MVRCLoss=2.471704,	
Rank[  2]Epoch[4] Batch [8900]	Speed: 24.76 samples/s ETA: 1 d 16 h 20 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.299 O: 2.109 M: 0.007	Train-MLMAcc=0.615028,	MVRCAccuracy=0.662548,	MLMLossWVC=1.878651,	MVRCLoss=2.471693,	
Rank[  3]Epoch[4] Batch [8900]	Speed: 24.76 samples/s ETA: 1 d 16 h 20 m	Data: 0.542 Tran: 0.007 F: 0.154 B: 0.306 O: 1.565 M: 0.009	Train-MLMAcc=0.615028,	MVRCAccuracy=0.662548,	MLMLossWVC=1.878651,	MVRCLoss=2.471693,	
Rank[  1]Epoch[4] Batch [8900]	Speed: 24.76 samples/s ETA: 1 d 16 h 20 m	Data: 0.251 Tran: 0.007 F: 0.151 B: 0.297 O: 1.871 M: 0.007	Train-MLMAcc=0.615028,	MVRCAccuracy=0.662548,	MLMLossWVC=1.878651,	MVRCLoss=2.471693,	
Rank[  0]Epoch[4] Batch [8900]	Speed: 24.76 samples/s ETA: 1 d 16 h 20 m	Data: 1.263 Tran: 0.008 F: 0.163 B: 0.299 O: 0.841 M: 0.009	Train-MLMAcc=0.615028,	MVRCAccuracy=0.662548,	MLMLossWVC=1.878651,	MVRCLoss=2.471693,	
Rank[  2]Epoch[4] Batch [9000]	Speed: 25.13 samples/s ETA: 1 d 15 h 41 m	Data: 0.013 Tran: 0.007 F: 0.168 B: 0.305 O: 2.041 M: 0.009	Train-MLMAcc=0.615049,	MVRCAccuracy=0.662555,	MLMLossWVC=1.878465,	MVRCLoss=2.471596,	
Rank[  3]Epoch[4] Batch [9000]	Speed: 25.13 samples/s ETA: 1 d 15 h 41 m	Data: 0.159 Tran: 0.008 F: 0.159 B: 0.306 O: 1.901 M: 0.011	Train-MLMAcc=0.615049,	MVRCAccuracy=0.662555,	MLMLossWVC=1.878465,	MVRCLoss=2.471596,	
Rank[  1]Epoch[4] Batch [9000]	Speed: 25.13 samples/s ETA: 1 d 15 h 41 m	Data: 0.013 Tran: 0.007 F: 0.169 B: 0.303 O: 2.044 M: 0.009	Train-MLMAcc=0.615049,	MVRCAccuracy=0.662555,	MLMLossWVC=1.878465,	MVRCLoss=2.471596,	
Rank[  0]Epoch[4] Batch [9000]	Speed: 25.13 samples/s ETA: 1 d 15 h 41 m	Data: 1.842 Tran: 0.009 F: 0.181 B: 0.299 O: 0.204 M: 0.010	Train-MLMAcc=0.615049,	MVRCAccuracy=0.662555,	MLMLossWVC=1.878465,	MVRCLoss=2.471596,	
Rank[  1]Epoch[4] Batch [9100]	Speed: 25.75 samples/s ETA: 1 d 14 h 40 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 2.014 M: 0.010	Train-MLMAcc=0.615081,	MVRCAccuracy=0.662598,	MLMLossWVC=1.878278,	MVRCLoss=2.471521,	
Rank[  3]Epoch[4] Batch [9100]	Speed: 25.75 samples/s ETA: 1 d 14 h 40 m	Data: 0.110 Tran: 0.006 F: 0.150 B: 0.298 O: 1.909 M: 0.010	Train-MLMAcc=0.615081,	MVRCAccuracy=0.662598,	MLMLossWVC=1.878278,	MVRCLoss=2.471521,	
Rank[  2]Epoch[4] Batch [9100]	Speed: 25.75 samples/s ETA: 1 d 14 h 40 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 2.018 M: 0.008	Train-MLMAcc=0.615081,	MVRCAccuracy=0.662598,	MLMLossWVC=1.878278,	MVRCLoss=2.471521,	
Rank[  0]Epoch[4] Batch [9100]	Speed: 25.75 samples/s ETA: 1 d 14 h 40 m	Data: 1.835 Tran: 0.008 F: 0.173 B: 0.298 O: 0.163 M: 0.007	Train-MLMAcc=0.615081,	MVRCAccuracy=0.662598,	MLMLossWVC=1.878278,	MVRCLoss=2.471521,	
Rank[  1]Epoch[4] Batch [9200]	Speed: 25.30 samples/s ETA: 1 d 15 h 17 m	Data: 0.009 Tran: 0.007 F: 0.151 B: 0.298 O: 2.053 M: 0.008	Train-MLMAcc=0.615112,	MVRCAccuracy=0.662656,	MLMLossWVC=1.878153,	MVRCLoss=2.471360,	
Rank[  3]Epoch[4] Batch [9200]	Speed: 25.30 samples/s ETA: 1 d 15 h 17 m	Data: 0.043 Tran: 0.007 F: 0.151 B: 0.301 O: 2.013 M: 0.011	Train-MLMAcc=0.615112,	MVRCAccuracy=0.662656,	MLMLossWVC=1.878153,	MVRCLoss=2.471360,	
Rank[  0]Epoch[4] Batch [9200]	Speed: 25.30 samples/s ETA: 1 d 15 h 17 m	Data: 1.891 Tran: 0.009 F: 0.195 B: 0.318 O: 0.102 M: 0.010	Train-MLMAcc=0.615112,	MVRCAccuracy=0.662656,	MLMLossWVC=1.878153,	MVRCLoss=2.471360,	
Rank[  2]Epoch[4] Batch [9200]	Speed: 25.30 samples/s ETA: 1 d 15 h 17 m	Data: 0.025 Tran: 0.007 F: 0.151 B: 0.300 O: 2.034 M: 0.009	Train-MLMAcc=0.615112,	MVRCAccuracy=0.662656,	MLMLossWVC=1.878153,	MVRCLoss=2.471360,	
Rank[  2]Epoch[4] Batch [9300]	Speed: 25.03 samples/s ETA: 1 d 15 h 38 m	Data: 0.141 Tran: 0.007 F: 0.151 B: 0.298 O: 1.950 M: 0.007	Train-MLMAcc=0.615145,	MVRCAccuracy=0.662671,	MLMLossWVC=1.877948,	MVRCLoss=2.471264,	
Rank[  1]Epoch[4] Batch [9300]	Speed: 25.03 samples/s ETA: 1 d 15 h 38 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.298 O: 2.081 M: 0.008	Train-MLMAcc=0.615145,	MVRCAccuracy=0.662671,	MLMLossWVC=1.877948,	MVRCLoss=2.471264,	
Rank[  3]Epoch[4] Batch [9300]	Speed: 25.03 samples/s ETA: 1 d 15 h 38 m	Data: 0.820 Tran: 0.010 F: 0.181 B: 0.315 O: 1.221 M: 0.008	Train-MLMAcc=0.615145,	MVRCAccuracy=0.662671,	MLMLossWVC=1.877948,	MVRCLoss=2.471264,	
Rank[  0]Epoch[4] Batch [9300]	Speed: 25.03 samples/s ETA: 1 d 15 h 38 m	Data: 1.045 Tran: 0.007 F: 0.152 B: 0.293 O: 1.053 M: 0.006	Train-MLMAcc=0.615145,	MVRCAccuracy=0.662671,	MLMLossWVC=1.877948,	MVRCLoss=2.471264,	
Rank[  0]Epoch[4] Batch [9400]	Speed: 25.43 samples/s ETA: 1 d 14 h 56 m	Data: 1.578 Tran: 0.011 F: 0.186 B: 0.303 O: 0.430 M: 0.007	Train-MLMAcc=0.615161,	MVRCAccuracy=0.662687,	MLMLossWVC=1.877895,	MVRCLoss=2.471262,	
Rank[  3]Epoch[4] Batch [9400]	Speed: 25.43 samples/s ETA: 1 d 14 h 56 m	Data: 0.372 Tran: 0.007 F: 0.150 B: 0.297 O: 1.680 M: 0.008	Train-MLMAcc=0.615161,	MVRCAccuracy=0.662687,	MLMLossWVC=1.877895,	MVRCLoss=2.471262,	
Rank[  2]Epoch[4] Batch [9400]	Speed: 25.43 samples/s ETA: 1 d 14 h 56 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 2.046 M: 0.008	Train-MLMAcc=0.615161,	MVRCAccuracy=0.662687,	MLMLossWVC=1.877895,	MVRCLoss=2.471262,	
Rank[  1]Epoch[4] Batch [9400]	Speed: 25.43 samples/s ETA: 1 d 14 h 56 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 2.048 M: 0.008	Train-MLMAcc=0.615161,	MVRCAccuracy=0.662687,	MLMLossWVC=1.877895,	MVRCLoss=2.471262,	
Rank[  1]Epoch[4] Batch [9500]	Speed: 25.15 samples/s ETA: 1 d 15 h 18 m	Data: 0.010 Tran: 0.007 F: 0.158 B: 0.302 O: 2.051 M: 0.014	Train-MLMAcc=0.615227,	MVRCAccuracy=0.662721,	MLMLossWVC=1.877514,	MVRCLoss=2.471183,	
Rank[  2]Epoch[4] Batch [9500]	Speed: 25.15 samples/s ETA: 1 d 15 h 18 m	Data: 0.010 Tran: 0.007 F: 0.159 B: 0.309 O: 2.045 M: 0.013	Train-MLMAcc=0.615227,	MVRCAccuracy=0.662721,	MLMLossWVC=1.877514,	MVRCLoss=2.471183,	
Rank[  0]Epoch[4] Batch [9500]	Speed: 25.15 samples/s ETA: 1 d 15 h 18 m	Data: 1.990 Tran: 0.007 F: 0.161 B: 0.300 O: 0.071 M: 0.014	Train-MLMAcc=0.615227,	MVRCAccuracy=0.662721,	MLMLossWVC=1.877514,	MVRCLoss=2.471183,	
Rank[  3]Epoch[4] Batch [9500]	Speed: 25.15 samples/s ETA: 1 d 15 h 18 m	Data: 0.012 Tran: 0.007 F: 0.159 B: 0.309 O: 2.043 M: 0.012	Train-MLMAcc=0.615227,	MVRCAccuracy=0.662721,	MLMLossWVC=1.877514,	MVRCLoss=2.471183,	
Rank[  3]Epoch[4] Batch [9600]	Speed: 25.09 samples/s ETA: 1 d 15 h 19 m	Data: 0.012 Tran: 0.007 F: 0.153 B: 0.299 O: 2.072 M: 0.007	Train-MLMAcc=0.615254,	MVRCAccuracy=0.662726,	MLMLossWVC=1.877197,	MVRCLoss=2.471239,	
Rank[  2]Epoch[4] Batch [9600]	Speed: 25.09 samples/s ETA: 1 d 15 h 19 m	Data: 0.013 Tran: 0.007 F: 0.153 B: 0.297 O: 2.074 M: 0.006	Train-MLMAcc=0.615254,	MVRCAccuracy=0.662726,	MLMLossWVC=1.877197,	MVRCLoss=2.471239,	
Rank[  1]Epoch[4] Batch [9600]	Speed: 25.09 samples/s ETA: 1 d 15 h 19 m	Data: 0.010 Tran: 0.007 F: 0.153 B: 0.296 O: 2.077 M: 0.007	Train-MLMAcc=0.615254,	MVRCAccuracy=0.662726,	MLMLossWVC=1.877197,	MVRCLoss=2.471239,	
Rank[  0]Epoch[4] Batch [9600]	Speed: 25.09 samples/s ETA: 1 d 15 h 19 m	Data: 1.993 Tran: 0.008 F: 0.180 B: 0.306 O: 0.057 M: 0.005	Train-MLMAcc=0.615254,	MVRCAccuracy=0.662726,	MLMLossWVC=1.877197,	MVRCLoss=2.471239,	
Rank[  1]Epoch[4] Batch [9700]	Speed: 24.93 samples/s ETA: 1 d 15 h 30 m	Data: 0.064 Tran: 0.007 F: 0.166 B: 0.306 O: 2.018 M: 0.005	Train-MLMAcc=0.615274,	MVRCAccuracy=0.662737,	MLMLossWVC=1.876999,	MVRCLoss=2.471148,	
Rank[  3]Epoch[4] Batch [9700]	Speed: 24.93 samples/s ETA: 1 d 15 h 30 m	Data: 0.635 Tran: 0.007 F: 0.152 B: 0.301 O: 1.460 M: 0.010	Train-MLMAcc=0.615274,	MVRCAccuracy=0.662737,	MLMLossWVC=1.876999,	MVRCLoss=2.471148,	
Rank[  2]Epoch[4] Batch [9700]	Speed: 24.93 samples/s ETA: 1 d 15 h 30 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.302 O: 2.089 M: 0.010	Train-MLMAcc=0.615274,	MVRCAccuracy=0.662737,	MLMLossWVC=1.876999,	MVRCLoss=2.471148,	
Rank[  0]Epoch[4] Batch [9700]	Speed: 24.93 samples/s ETA: 1 d 15 h 30 m	Data: 1.538 Tran: 0.007 F: 0.165 B: 0.305 O: 0.541 M: 0.009	Train-MLMAcc=0.615274,	MVRCAccuracy=0.662737,	MLMLossWVC=1.876999,	MVRCLoss=2.471148,	
Rank[  3]Epoch[4] Batch [9800]	Speed: 22.79 samples/s ETA: 1 d 19 h  8 m	Data: 0.350 Tran: 0.011 F: 0.185 B: 0.342 O: 1.902 M: 0.015	Train-MLMAcc=0.615293,	MVRCAccuracy=0.662763,	MLMLossWVC=1.876890,	MVRCLoss=2.471044,	
Rank[  1]Epoch[4] Batch [9800]	Speed: 22.79 samples/s ETA: 1 d 19 h  8 m	Data: 0.056 Tran: 0.011 F: 0.174 B: 0.344 O: 2.206 M: 0.014	Train-MLMAcc=0.615293,	MVRCAccuracy=0.662763,	MLMLossWVC=1.876890,	MVRCLoss=2.471044,	
Rank[  2]Epoch[4] Batch [9800]	Speed: 22.79 samples/s ETA: 1 d 19 h  8 m	Data: 0.013 Tran: 0.010 F: 0.178 B: 0.339 O: 2.250 M: 0.015	Train-MLMAcc=0.615293,	MVRCAccuracy=0.662763,	MLMLossWVC=1.876890,	MVRCLoss=2.471044,	
Rank[  0]Epoch[4] Batch [9800]	Speed: 22.79 samples/s ETA: 1 d 19 h  8 m	Data: 1.841 Tran: 0.013 F: 0.228 B: 0.336 O: 0.370 M: 0.016	Train-MLMAcc=0.615293,	MVRCAccuracy=0.662763,	MLMLossWVC=1.876890,	MVRCLoss=2.471044,	
Rank[  3]Epoch[4] Batch [9900]	Speed: 22.08 samples/s ETA: 1 d 20 h 26 m	Data: 1.333 Tran: 0.009 F: 0.210 B: 0.374 O: 0.951 M: 0.018	Train-MLMAcc=0.615316,	MVRCAccuracy=0.662776,	MLMLossWVC=1.876871,	MVRCLoss=2.470961,	
Rank[  2]Epoch[4] Batch [9900]	Speed: 22.08 samples/s ETA: 1 d 20 h 26 m	Data: 0.015 Tran: 0.010 F: 0.206 B: 0.382 O: 2.264 M: 0.018	Train-MLMAcc=0.615316,	MVRCAccuracy=0.662776,	MLMLossWVC=1.876871,	MVRCLoss=2.470961,	
Rank[  1]Epoch[4] Batch [9900]	Speed: 22.08 samples/s ETA: 1 d 20 h 26 m	Data: 1.205 Tran: 0.011 F: 0.222 B: 0.374 O: 1.066 M: 0.017	Train-MLMAcc=0.615316,	MVRCAccuracy=0.662776,	MLMLossWVC=1.876871,	MVRCLoss=2.470961,	
Rank[  0]Epoch[4] Batch [9900]	Speed: 22.08 samples/s ETA: 1 d 20 h 26 m	Data: 0.972 Tran: 0.011 F: 0.264 B: 0.386 O: 1.244 M: 0.017	Train-MLMAcc=0.615316,	MVRCAccuracy=0.662776,	MLMLossWVC=1.876871,	MVRCLoss=2.470961,	
Rank[  1]Epoch[4] Batch [10000]	Speed: 24.86 samples/s ETA: 1 d 15 h 24 m	Data: 1.206 Tran: 0.007 F: 0.175 B: 0.304 O: 0.871 M: 0.009	Train-MLMAcc=0.615357,	MVRCAccuracy=0.662827,	MLMLossWVC=1.876595,	MVRCLoss=2.470912,	
Rank[  0]Epoch[4] Batch [10000]	Speed: 24.86 samples/s ETA: 1 d 15 h 24 m	Data: 0.479 Tran: 0.007 F: 0.150 B: 0.292 O: 1.635 M: 0.009	Train-MLMAcc=0.615357,	MVRCAccuracy=0.662827,	MLMLossWVC=1.876595,	MVRCLoss=2.470912,	
Rank[  3]Epoch[4] Batch [10000]	Speed: 24.86 samples/s ETA: 1 d 15 h 24 m	Data: 1.554 Tran: 0.006 F: 0.168 B: 0.302 O: 0.532 M: 0.010	Train-MLMAcc=0.615357,	MVRCAccuracy=0.662827,	MLMLossWVC=1.876595,	MVRCLoss=2.470912,	
Rank[  2]Epoch[4] Batch [10000]	Speed: 24.86 samples/s ETA: 1 d 15 h 24 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 2.103 M: 0.010	Train-MLMAcc=0.615357,	MVRCAccuracy=0.662827,	MLMLossWVC=1.876595,	MVRCLoss=2.470912,	
Rank[  2]Epoch[4] Batch [10100]	Speed: 24.89 samples/s ETA: 1 d 15 h 17 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 2.100 M: 0.010	Train-MLMAcc=0.615386,	MVRCAccuracy=0.662848,	MLMLossWVC=1.876448,	MVRCLoss=2.470799,	
Rank[  1]Epoch[4] Batch [10100]	Speed: 24.89 samples/s ETA: 1 d 15 h 17 m	Data: 1.297 Tran: 0.014 F: 0.170 B: 0.302 O: 0.778 M: 0.008	Train-MLMAcc=0.615386,	MVRCAccuracy=0.662848,	MLMLossWVC=1.876448,	MVRCLoss=2.470799,	
Rank[  3]Epoch[4] Batch [10100]	Speed: 24.89 samples/s ETA: 1 d 15 h 17 m	Data: 1.995 Tran: 0.007 F: 0.167 B: 0.303 O: 0.090 M: 0.007	Train-MLMAcc=0.615386,	MVRCAccuracy=0.662848,	MLMLossWVC=1.876448,	MVRCLoss=2.470799,	
Rank[  0]Epoch[4] Batch [10100]	Speed: 24.89 samples/s ETA: 1 d 15 h 17 m	Data: 0.428 Tran: 0.007 F: 0.150 B: 0.292 O: 1.685 M: 0.008	Train-MLMAcc=0.615386,	MVRCAccuracy=0.662848,	MLMLossWVC=1.876448,	MVRCLoss=2.470799,	
Rank[  2]Epoch[4] Batch [10200]	Speed: 25.26 samples/s ETA: 1 d 14 h 38 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.313 O: 2.046 M: 0.007	Train-MLMAcc=0.615412,	MVRCAccuracy=0.662863,	MLMLossWVC=1.876217,	MVRCLoss=2.470711,	
Rank[  0]Epoch[4] Batch [10200]	Speed: 25.26 samples/s ETA: 1 d 14 h 38 m	Data: 1.071 Tran: 0.007 F: 0.159 B: 0.294 O: 0.990 M: 0.011	Train-MLMAcc=0.615412,	MVRCAccuracy=0.662863,	MLMLossWVC=1.876217,	MVRCLoss=2.470711,	
Rank[  3]Epoch[4] Batch [10200]	Speed: 25.26 samples/s ETA: 1 d 14 h 38 m	Data: 1.950 Tran: 0.007 F: 0.152 B: 0.298 O: 0.114 M: 0.010	Train-MLMAcc=0.615412,	MVRCAccuracy=0.662863,	MLMLossWVC=1.876217,	MVRCLoss=2.470711,	
Rank[  1]Epoch[4] Batch [10200]	Speed: 25.26 samples/s ETA: 1 d 14 h 38 m	Data: 1.718 Tran: 0.007 F: 0.151 B: 0.294 O: 0.353 M: 0.009	Train-MLMAcc=0.615412,	MVRCAccuracy=0.662863,	MLMLossWVC=1.876217,	MVRCLoss=2.470711,	
Rank[  1]Epoch[4] Batch [10300]	Speed: 25.83 samples/s ETA: 1 d 13 h 42 m	Data: 1.674 Tran: 0.007 F: 0.154 B: 0.313 O: 0.316 M: 0.013	Train-MLMAcc=0.615455,	MVRCAccuracy=0.662897,	MLMLossWVC=1.875923,	MVRCLoss=2.470644,	
Rank[  0]Epoch[4] Batch [10300]	Speed: 25.83 samples/s ETA: 1 d 13 h 42 m	Data: 1.047 Tran: 0.007 F: 0.163 B: 0.312 O: 0.934 M: 0.013	Train-MLMAcc=0.615455,	MVRCAccuracy=0.662897,	MLMLossWVC=1.875923,	MVRCLoss=2.470644,	
Rank[  2]Epoch[4] Batch [10300]	Speed: 25.83 samples/s ETA: 1 d 13 h 42 m	Data: 0.008 Tran: 0.007 F: 0.156 B: 0.317 O: 1.980 M: 0.007	Train-MLMAcc=0.615455,	MVRCAccuracy=0.662897,	MLMLossWVC=1.875923,	MVRCLoss=2.470644,	
Rank[  3]Epoch[4] Batch [10300]	Speed: 25.83 samples/s ETA: 1 d 13 h 42 m	Data: 1.866 Tran: 0.007 F: 0.153 B: 0.314 O: 0.124 M: 0.013	Train-MLMAcc=0.615455,	MVRCAccuracy=0.662897,	MLMLossWVC=1.875923,	MVRCLoss=2.470644,	
Rank[  2]Epoch[4] Batch [10400]	Speed: 25.10 samples/s ETA: 1 d 14 h 44 m	Data: 0.011 Tran: 0.007 F: 0.153 B: 0.320 O: 2.052 M: 0.005	Train-MLMAcc=0.615462,	MVRCAccuracy=0.662935,	MLMLossWVC=1.875902,	MVRCLoss=2.470588,	
Rank[  3]Epoch[4] Batch [10400]	Speed: 25.10 samples/s ETA: 1 d 14 h 44 m	Data: 1.813 Tran: 0.007 F: 0.152 B: 0.320 O: 0.246 M: 0.011	Train-MLMAcc=0.615462,	MVRCAccuracy=0.662935,	MLMLossWVC=1.875902,	MVRCLoss=2.470588,	
Rank[  1]Epoch[4] Batch [10400]	Speed: 25.10 samples/s ETA: 1 d 14 h 44 m	Data: 1.657 Tran: 0.007 F: 0.158 B: 0.323 O: 0.395 M: 0.010	Train-MLMAcc=0.615462,	MVRCAccuracy=0.662935,	MLMLossWVC=1.875902,	MVRCLoss=2.470588,	
Rank[  0]Epoch[4] Batch [10400]	Speed: 25.10 samples/s ETA: 1 d 14 h 44 m	Data: 0.643 Tran: 0.007 F: 0.165 B: 0.319 O: 1.403 M: 0.011	Train-MLMAcc=0.615462,	MVRCAccuracy=0.662935,	MLMLossWVC=1.875902,	MVRCLoss=2.470588,	
Rank[  2]Epoch[4] Batch [10500]	Speed: 25.26 samples/s ETA: 1 d 14 h 25 m	Data: 0.010 Tran: 0.007 F: 0.155 B: 0.297 O: 2.050 M: 0.011	Train-MLMAcc=0.615520,	MVRCAccuracy=0.662968,	MLMLossWVC=1.875510,	MVRCLoss=2.470560,	
Rank[  1]Epoch[4] Batch [10500]	Speed: 25.26 samples/s ETA: 1 d 14 h 25 m	Data: 1.924 Tran: 0.007 F: 0.166 B: 0.325 O: 0.098 M: 0.010	Train-MLMAcc=0.615520,	MVRCAccuracy=0.662968,	MLMLossWVC=1.875510,	MVRCLoss=2.470560,	
Rank[  3]Epoch[4] Batch [10500]	Speed: 25.26 samples/s ETA: 1 d 14 h 25 m	Data: 0.532 Tran: 0.007 F: 0.156 B: 0.300 O: 1.525 M: 0.010	Train-MLMAcc=0.615520,	MVRCAccuracy=0.662968,	MLMLossWVC=1.875510,	MVRCLoss=2.470560,	
Rank[  0]Epoch[4] Batch [10500]	Speed: 25.26 samples/s ETA: 1 d 14 h 25 m	Data: 0.760 Tran: 0.007 F: 0.157 B: 0.295 O: 1.300 M: 0.012	Train-MLMAcc=0.615520,	MVRCAccuracy=0.662968,	MLMLossWVC=1.875510,	MVRCLoss=2.470560,	
Rank[  0]Epoch[4] Batch [10600]	Speed: 25.44 samples/s ETA: 1 d 14 h  5 m	Data: 0.035 Tran: 0.006 F: 0.151 B: 0.293 O: 2.017 M: 0.011	Train-MLMAcc=0.615518,	MVRCAccuracy=0.663005,	MLMLossWVC=1.875495,	MVRCLoss=2.470474,	
Rank[  3]Epoch[4] Batch [10600]	Speed: 25.44 samples/s ETA: 1 d 14 h  5 m	Data: 0.019 Tran: 0.007 F: 0.150 B: 0.295 O: 2.032 M: 0.011	Train-MLMAcc=0.615518,	MVRCAccuracy=0.663005,	MLMLossWVC=1.875495,	MVRCLoss=2.470474,	
Rank[  2]Epoch[4] Batch [10600]	Speed: 25.44 samples/s ETA: 1 d 14 h  5 m	Data: 0.008 Tran: 0.008 F: 0.152 B: 0.297 O: 2.043 M: 0.006	Train-MLMAcc=0.615518,	MVRCAccuracy=0.663005,	MLMLossWVC=1.875495,	MVRCLoss=2.470474,	
Rank[  1]Epoch[4] Batch [10600]	Speed: 25.44 samples/s ETA: 1 d 14 h  5 m	Data: 1.963 Tran: 0.008 F: 0.176 B: 0.303 O: 0.052 M: 0.010	Train-MLMAcc=0.615518,	MVRCAccuracy=0.663005,	MLMLossWVC=1.875495,	MVRCLoss=2.470474,	
Rank[  2]Epoch[4] Batch [10700]	Speed: 25.17 samples/s ETA: 1 d 14 h 25 m	Data: 0.010 Tran: 0.007 F: 0.151 B: 0.301 O: 2.060 M: 0.012	Train-MLMAcc=0.615525,	MVRCAccuracy=0.663035,	MLMLossWVC=1.875422,	MVRCLoss=2.470400,	
Rank[  3]Epoch[4] Batch [10700]	Speed: 25.17 samples/s ETA: 1 d 14 h 25 m	Data: 0.012 Tran: 0.007 F: 0.154 B: 0.302 O: 2.056 M: 0.009	Train-MLMAcc=0.615525,	MVRCAccuracy=0.663035,	MLMLossWVC=1.875422,	MVRCLoss=2.470400,	
Rank[  1]Epoch[4] Batch [10700]	Speed: 25.17 samples/s ETA: 1 d 14 h 25 m	Data: 1.966 Tran: 0.009 F: 0.181 B: 0.320 O: 0.055 M: 0.009	Train-MLMAcc=0.615525,	MVRCAccuracy=0.663035,	MLMLossWVC=1.875422,	MVRCLoss=2.470400,	
Rank[  0]Epoch[4] Batch [10700]	Speed: 25.17 samples/s ETA: 1 d 14 h 25 m	Data: 0.009 Tran: 0.007 F: 0.152 B: 0.298 O: 2.064 M: 0.010	Train-MLMAcc=0.615525,	MVRCAccuracy=0.663035,	MLMLossWVC=1.875422,	MVRCLoss=2.470400,	
Rank[  0]Epoch[4] Batch [10800]	Speed: 24.54 samples/s ETA: 1 d 15 h 20 m	Data: 0.008 Tran: 0.007 F: 0.158 B: 0.333 O: 2.092 M: 0.010	Train-MLMAcc=0.615519,	MVRCAccuracy=0.663065,	MLMLossWVC=1.875215,	MVRCLoss=2.470406,	
Rank[  1]Epoch[4] Batch [10800]	Speed: 24.54 samples/s ETA: 1 d 15 h 20 m	Data: 2.025 Tran: 0.008 F: 0.171 B: 0.330 O: 0.063 M: 0.009	Train-MLMAcc=0.615519,	MVRCAccuracy=0.663065,	MLMLossWVC=1.875215,	MVRCLoss=2.470406,	
Rank[  2]Epoch[4] Batch [10800]	Speed: 24.54 samples/s ETA: 1 d 15 h 20 m	Data: 0.011 Tran: 0.007 F: 0.155 B: 0.337 O: 2.087 M: 0.009	Train-MLMAcc=0.615519,	MVRCAccuracy=0.663065,	MLMLossWVC=1.875215,	MVRCLoss=2.470406,	
Rank[  3]Epoch[4] Batch [10800]	Speed: 24.54 samples/s ETA: 1 d 15 h 20 m	Data: 0.012 Tran: 0.007 F: 0.156 B: 0.340 O: 2.084 M: 0.008	Train-MLMAcc=0.615519,	MVRCAccuracy=0.663065,	MLMLossWVC=1.875215,	MVRCLoss=2.470406,	
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
New Best Val MLMAcc: 0.5910293459892273, Epoch: 4
New Best Val MLMAcc: 0.5910293459892273, Epoch: 4
New Best Val MLMAcc: 0.5910293459892273, Epoch: 4
New Best Val MLMAcc: 0.5910293459892273, Epoch: 4
Epoch[4] 	Val-MLMAcc=0.591029,	MVRCAccuracy=0.684640,	MLMLossWVC=2.021555,	MVRCLoss=2.480876,	
Epoch[4] 	Val-MLMAcc=0.591029,	MVRCAccuracy=0.684640,	MLMLossWVC=2.021555,	MVRCLoss=2.480876,	
Epoch[4] 	Val-MLMAcc=0.591029,	MVRCAccuracy=0.684640,	MLMLossWVC=2.021555,	MVRCLoss=2.480876,	
Epoch[4] 	Val-MLMAcc=0.591029,	MVRCAccuracy=0.684640,	MLMLossWVC=2.021555,	MVRCLoss=2.480876,	
Best Val MLMAcc: 0.5910293459892273, Epoch: 4
Best Val MLMAcc: 0.5910293459892273, Epoch: 4
PROGRESS: 50.00%
Best Val MLMAcc: 0.5910293459892273, Epoch: 4
PROGRESS: 50.00%
Best Val MLMAcc: 0.5910293459892273, Epoch: 4
PROGRESS: 50.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Save new best model to /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-best.model.
PROGRESS: 50.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Rank[  1]Epoch[5] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.616307,	MVRCAccuracy=0.678102,	MLMLossWVC=1.730885,	MVRCLoss=2.529798,	
Rank[  2]Epoch[5] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.616307,	MVRCAccuracy=0.678102,	MLMLossWVC=1.730885,	MVRCLoss=2.529798,	
Rank[  3]Epoch[5] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.616307,	MVRCAccuracy=0.678102,	MLMLossWVC=1.730885,	MVRCLoss=2.529798,	
Rank[  0]Epoch[5] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.616307,	MVRCAccuracy=0.678102,	MLMLossWVC=1.730885,	MVRCLoss=2.529798,	
Rank[  1]Epoch[5] Batch [100]	Speed: 25.58 samples/s ETA: 1 d 13 h 38 m	Data: 1.284 Tran: 0.011 F: 0.231 B: 0.442 O: 2.210 M: 0.012	Train-MLMAcc=0.619761,	MVRCAccuracy=0.665018,	MLMLossWVC=1.858559,	MVRCLoss=2.464628,	
Rank[  2]Epoch[5] Batch [100]	Speed: 25.58 samples/s ETA: 1 d 13 h 38 m	Data: 0.404 Tran: 0.011 F: 0.225 B: 0.445 O: 3.094 M: 0.012	Train-MLMAcc=0.619761,	MVRCAccuracy=0.665018,	MLMLossWVC=1.858559,	MVRCLoss=2.464628,	
Rank[  0]Epoch[5] Batch [100]	Speed: 25.58 samples/s ETA: 1 d 13 h 38 m	Data: 2.335 Tran: 0.011 F: 0.226 B: 0.439 O: 0.992 M: 0.012	Train-MLMAcc=0.619761,	MVRCAccuracy=0.665018,	MLMLossWVC=1.858559,	MVRCLoss=2.464628,	
Rank[  3]Epoch[5] Batch [100]	Speed: 25.58 samples/s ETA: 1 d 13 h 38 m	Data: 0.390 Tran: 0.011 F: 0.227 B: 0.446 O: 3.109 M: 0.008	Train-MLMAcc=0.619761,	MVRCAccuracy=0.665018,	MLMLossWVC=1.858559,	MVRCLoss=2.464628,	
Rank[  0]Epoch[5] Batch [200]	Speed: 25.85 samples/s ETA: 1 d 13 h 10 m	Data: 1.959 Tran: 0.007 F: 0.150 B: 0.290 O: 0.059 M: 0.010	Train-MLMAcc=0.619387,	MVRCAccuracy=0.666620,	MLMLossWVC=1.859957,	MVRCLoss=2.466672,	
Rank[  1]Epoch[5] Batch [200]	Speed: 25.85 samples/s ETA: 1 d 13 h 10 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.293 O: 2.008 M: 0.009	Train-MLMAcc=0.619387,	MVRCAccuracy=0.666620,	MLMLossWVC=1.859957,	MVRCLoss=2.466672,	
Rank[  2]Epoch[5] Batch [200]	Speed: 25.85 samples/s ETA: 1 d 13 h 10 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 2.006 M: 0.011	Train-MLMAcc=0.619387,	MVRCAccuracy=0.666620,	MLMLossWVC=1.859957,	MVRCLoss=2.466672,	
Rank[  3]Epoch[5] Batch [200]	Speed: 25.85 samples/s ETA: 1 d 13 h 10 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 2.007 M: 0.008	Train-MLMAcc=0.619387,	MVRCAccuracy=0.666620,	MLMLossWVC=1.859957,	MVRCLoss=2.466672,	
Rank[  1]Epoch[5] Batch [300]	Speed: 25.57 samples/s ETA: 1 d 13 h 30 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.295 O: 2.034 M: 0.008	Train-MLMAcc=0.619731,	MVRCAccuracy=0.666429,	MLMLossWVC=1.851204,	MVRCLoss=2.466460,	
Rank[  0]Epoch[5] Batch [300]	Speed: 25.57 samples/s ETA: 1 d 13 h 30 m	Data: 1.985 Tran: 0.006 F: 0.151 B: 0.292 O: 0.058 M: 0.009	Train-MLMAcc=0.619731,	MVRCAccuracy=0.666429,	MLMLossWVC=1.851204,	MVRCLoss=2.466460,	
Rank[  3]Epoch[5] Batch [300]	Speed: 25.57 samples/s ETA: 1 d 13 h 30 m	Data: 0.009 Tran: 0.007 F: 0.150 B: 0.296 O: 2.031 M: 0.009	Train-MLMAcc=0.619731,	MVRCAccuracy=0.666429,	MLMLossWVC=1.851204,	MVRCLoss=2.466460,	
Rank[  2]Epoch[5] Batch [300]	Speed: 25.57 samples/s ETA: 1 d 13 h 30 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.296 O: 2.031 M: 0.011	Train-MLMAcc=0.619731,	MVRCAccuracy=0.666429,	MLMLossWVC=1.851204,	MVRCLoss=2.466460,	
Rank[  0]Epoch[5] Batch [400]	Speed: 26.15 samples/s ETA: 1 d 12 h 36 m	Data: 1.927 Tran: 0.006 F: 0.150 B: 0.291 O: 0.067 M: 0.006	Train-MLMAcc=0.619513,	MVRCAccuracy=0.666277,	MLMLossWVC=1.853269,	MVRCLoss=2.465124,	
Rank[  1]Epoch[5] Batch [400]	Speed: 26.15 samples/s ETA: 1 d 12 h 36 m	Data: 0.086 Tran: 0.007 F: 0.150 B: 0.297 O: 1.901 M: 0.006	Train-MLMAcc=0.619513,	MVRCAccuracy=0.666277,	MLMLossWVC=1.853269,	MVRCLoss=2.465124,	
Rank[  3]Epoch[5] Batch [400]	Speed: 26.15 samples/s ETA: 1 d 12 h 36 m	Data: 0.355 Tran: 0.007 F: 0.149 B: 0.295 O: 1.636 M: 0.005	Train-MLMAcc=0.619513,	MVRCAccuracy=0.666277,	MLMLossWVC=1.853269,	MVRCLoss=2.465124,	
Rank[  2]Epoch[5] Batch [400]	Speed: 26.15 samples/s ETA: 1 d 12 h 36 m	Data: 0.065 Tran: 0.007 F: 0.149 B: 0.296 O: 1.926 M: 0.005	Train-MLMAcc=0.619513,	MVRCAccuracy=0.666277,	MLMLossWVC=1.853269,	MVRCLoss=2.465124,	
Rank[  3]Epoch[5] Batch [500]	Speed: 25.41 samples/s ETA: 1 d 13 h 36 m	Data: 1.512 Tran: 0.007 F: 0.150 B: 0.297 O: 0.546 M: 0.006	Train-MLMAcc=0.620019,	MVRCAccuracy=0.666327,	MLMLossWVC=1.850226,	MVRCLoss=2.464709,	
Rank[  2]Epoch[5] Batch [500]	Speed: 25.41 samples/s ETA: 1 d 13 h 36 m	Data: 0.096 Tran: 0.006 F: 0.149 B: 0.296 O: 1.966 M: 0.004	Train-MLMAcc=0.620019,	MVRCAccuracy=0.666327,	MLMLossWVC=1.850226,	MVRCLoss=2.464709,	
Rank[  0]Epoch[5] Batch [500]	Speed: 25.41 samples/s ETA: 1 d 13 h 36 m	Data: 1.272 Tran: 0.006 F: 0.150 B: 0.292 O: 0.792 M: 0.006	Train-MLMAcc=0.620019,	MVRCAccuracy=0.666327,	MLMLossWVC=1.850226,	MVRCLoss=2.464709,	
Rank[  1]Epoch[5] Batch [500]	Speed: 25.41 samples/s ETA: 1 d 13 h 36 m	Data: 0.281 Tran: 0.007 F: 0.150 B: 0.296 O: 1.777 M: 0.007	Train-MLMAcc=0.620019,	MVRCAccuracy=0.666327,	MLMLossWVC=1.850226,	MVRCLoss=2.464709,	
Rank[  3]Epoch[5] Batch [600]	Speed: 25.31 samples/s ETA: 1 d 13 h 40 m	Data: 1.530 Tran: 0.007 F: 0.150 B: 0.296 O: 0.537 M: 0.008	Train-MLMAcc=0.619678,	MVRCAccuracy=0.666605,	MLMLossWVC=1.849416,	MVRCLoss=2.463758,	
Rank[  0]Epoch[5] Batch [600]	Speed: 25.31 samples/s ETA: 1 d 13 h 40 m	Data: 0.857 Tran: 0.007 F: 0.150 B: 0.292 O: 1.216 M: 0.007	Train-MLMAcc=0.619678,	MVRCAccuracy=0.666605,	MLMLossWVC=1.849416,	MVRCLoss=2.463758,	
Rank[  1]Epoch[5] Batch [600]	Speed: 25.31 samples/s ETA: 1 d 13 h 40 m	Data: 0.039 Tran: 0.007 F: 0.150 B: 0.297 O: 2.026 M: 0.008	Train-MLMAcc=0.619678,	MVRCAccuracy=0.666605,	MLMLossWVC=1.849416,	MVRCLoss=2.463758,	
Rank[  2]Epoch[5] Batch [600]	Speed: 25.31 samples/s ETA: 1 d 13 h 40 m	Data: 0.012 Tran: 0.007 F: 0.150 B: 0.297 O: 2.054 M: 0.008	Train-MLMAcc=0.619678,	MVRCAccuracy=0.666605,	MLMLossWVC=1.849416,	MVRCLoss=2.463758,	
Rank[  3]Epoch[5] Batch [700]	Speed: 25.16 samples/s ETA: 1 d 13 h 50 m	Data: 1.960 Tran: 0.007 F: 0.151 B: 0.296 O: 0.123 M: 0.006	Train-MLMAcc=0.620853,	MVRCAccuracy=0.666331,	MLMLossWVC=1.841078,	MVRCLoss=2.463716,	
Rank[  2]Epoch[5] Batch [700]	Speed: 25.16 samples/s ETA: 1 d 13 h 50 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 2.077 M: 0.007	Train-MLMAcc=0.620853,	MVRCAccuracy=0.666331,	MLMLossWVC=1.841078,	MVRCLoss=2.463716,	
Rank[  0]Epoch[5] Batch [700]	Speed: 25.16 samples/s ETA: 1 d 13 h 50 m	Data: 0.109 Tran: 0.007 F: 0.149 B: 0.291 O: 1.979 M: 0.008	Train-MLMAcc=0.620853,	MVRCAccuracy=0.666331,	MLMLossWVC=1.841078,	MVRCLoss=2.463716,	
Rank[  1]Epoch[5] Batch [700]	Speed: 25.16 samples/s ETA: 1 d 13 h 50 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 2.076 M: 0.007	Train-MLMAcc=0.620853,	MVRCAccuracy=0.666331,	MLMLossWVC=1.841078,	MVRCLoss=2.463716,	
Rank[  3]Epoch[5] Batch [800]	Speed: 25.33 samples/s ETA: 1 d 13 h 30 m	Data: 1.709 Tran: 0.007 F: 0.150 B: 0.296 O: 0.359 M: 0.004	Train-MLMAcc=0.620786,	MVRCAccuracy=0.666328,	MLMLossWVC=1.842750,	MVRCLoss=2.463403,	
Rank[  0]Epoch[5] Batch [800]	Speed: 25.33 samples/s ETA: 1 d 13 h 30 m	Data: 0.315 Tran: 0.007 F: 0.150 B: 0.292 O: 1.756 M: 0.006	Train-MLMAcc=0.620786,	MVRCAccuracy=0.666328,	MLMLossWVC=1.842750,	MVRCLoss=2.463403,	
Rank[  2]Epoch[5] Batch [800]	Speed: 25.33 samples/s ETA: 1 d 13 h 30 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 2.058 M: 0.005	Train-MLMAcc=0.620786,	MVRCAccuracy=0.666328,	MLMLossWVC=1.842750,	MVRCLoss=2.463403,	
Rank[  1]Epoch[5] Batch [800]	Speed: 25.33 samples/s ETA: 1 d 13 h 30 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 2.060 M: 0.006	Train-MLMAcc=0.620786,	MVRCAccuracy=0.666328,	MLMLossWVC=1.842750,	MVRCLoss=2.463403,	
Rank[  3]Epoch[5] Batch [900]	Speed: 26.87 samples/s ETA: 1 d 11 h 17 m	Data: 1.680 Tran: 0.009 F: 0.170 B: 0.302 O: 0.212 M: 0.007	Train-MLMAcc=0.620759,	MVRCAccuracy=0.666134,	MLMLossWVC=1.842766,	MVRCLoss=2.463800,	
Rank[  1]Epoch[5] Batch [900]	Speed: 26.87 samples/s ETA: 1 d 11 h 17 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.295 O: 1.912 M: 0.008	Train-MLMAcc=0.620759,	MVRCAccuracy=0.666134,	MLMLossWVC=1.842766,	MVRCLoss=2.463800,	
Rank[  0]Epoch[5] Batch [900]	Speed: 26.87 samples/s ETA: 1 d 11 h 17 m	Data: 0.168 Tran: 0.007 F: 0.151 B: 0.293 O: 1.753 M: 0.009	Train-MLMAcc=0.620759,	MVRCAccuracy=0.666134,	MLMLossWVC=1.842766,	MVRCLoss=2.463800,	
Rank[  2]Epoch[5] Batch [900]	Speed: 26.87 samples/s ETA: 1 d 11 h 17 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.910 M: 0.009	Train-MLMAcc=0.620759,	MVRCAccuracy=0.666134,	MLMLossWVC=1.842766,	MVRCLoss=2.463800,	
Rank[  2]Epoch[5] Batch [1000]	Speed: 27.28 samples/s ETA: 1 d 10 h 42 m	Data: 0.009 Tran: 0.007 F: 0.154 B: 0.313 O: 1.855 M: 0.007	Train-MLMAcc=0.621059,	MVRCAccuracy=0.666463,	MLMLossWVC=1.840665,	MVRCLoss=2.463189,	
Rank[  0]Epoch[5] Batch [1000]	Speed: 27.28 samples/s ETA: 1 d 10 h 42 m	Data: 0.255 Tran: 0.007 F: 0.154 B: 0.307 O: 1.614 M: 0.008	Train-MLMAcc=0.621059,	MVRCAccuracy=0.666463,	MLMLossWVC=1.840665,	MVRCLoss=2.463189,	
Rank[  1]Epoch[5] Batch [1000]	Speed: 27.28 samples/s ETA: 1 d 10 h 42 m	Data: 0.009 Tran: 0.007 F: 0.155 B: 0.314 O: 1.852 M: 0.009	Train-MLMAcc=0.621059,	MVRCAccuracy=0.666463,	MLMLossWVC=1.840665,	MVRCLoss=2.463189,	
Rank[  3]Epoch[5] Batch [1000]	Speed: 27.28 samples/s ETA: 1 d 10 h 42 m	Data: 1.698 Tran: 0.009 F: 0.182 B: 0.320 O: 0.128 M: 0.007	Train-MLMAcc=0.621059,	MVRCAccuracy=0.666463,	MLMLossWVC=1.840665,	MVRCLoss=2.463189,	
Rank[  1]Epoch[5] Batch [1100]	Speed: 27.86 samples/s ETA: 1 d  9 h 55 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.291 O: 1.837 M: 0.005	Train-MLMAcc=0.620861,	MVRCAccuracy=0.666544,	MLMLossWVC=1.840622,	MVRCLoss=2.463485,	
Rank[  3]Epoch[5] Batch [1100]	Speed: 27.86 samples/s ETA: 1 d  9 h 55 m	Data: 1.789 Tran: 0.006 F: 0.150 B: 0.296 O: 0.048 M: 0.007	Train-MLMAcc=0.620861,	MVRCAccuracy=0.666544,	MLMLossWVC=1.840622,	MVRCLoss=2.463485,	
Rank[  0]Epoch[5] Batch [1100]	Speed: 27.86 samples/s ETA: 1 d  9 h 55 m	Data: 0.012 Tran: 0.007 F: 0.150 B: 0.293 O: 1.829 M: 0.007	Train-MLMAcc=0.620861,	MVRCAccuracy=0.666544,	MLMLossWVC=1.840622,	MVRCLoss=2.463485,	
Rank[  2]Epoch[5] Batch [1100]	Speed: 27.86 samples/s ETA: 1 d  9 h 55 m	Data: 0.012 Tran: 0.007 F: 0.149 B: 0.295 O: 1.827 M: 0.006	Train-MLMAcc=0.620861,	MVRCAccuracy=0.666544,	MLMLossWVC=1.840622,	MVRCLoss=2.463485,	
Rank[  1]Epoch[5] Batch [1200]	Speed: 27.74 samples/s ETA: 1 d  9 h 59 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.292 O: 1.844 M: 0.006	Train-MLMAcc=0.620903,	MVRCAccuracy=0.666506,	MLMLossWVC=1.840103,	MVRCLoss=2.463392,	
Rank[  2]Epoch[5] Batch [1200]	Speed: 27.74 samples/s ETA: 1 d  9 h 59 m	Data: 0.012 Tran: 0.007 F: 0.150 B: 0.297 O: 1.832 M: 0.007	Train-MLMAcc=0.620903,	MVRCAccuracy=0.666506,	MLMLossWVC=1.840103,	MVRCLoss=2.463392,	
Rank[  0]Epoch[5] Batch [1200]	Speed: 27.74 samples/s ETA: 1 d  9 h 59 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.843 M: 0.007	Train-MLMAcc=0.620903,	MVRCAccuracy=0.666506,	MLMLossWVC=1.840103,	MVRCLoss=2.463392,	
Rank[  3]Epoch[5] Batch [1200]	Speed: 27.74 samples/s ETA: 1 d  9 h 59 m	Data: 1.789 Tran: 0.007 F: 0.150 B: 0.295 O: 0.059 M: 0.006	Train-MLMAcc=0.620903,	MVRCAccuracy=0.666506,	MLMLossWVC=1.840103,	MVRCLoss=2.463392,	
Rank[  2]Epoch[5] Batch [1300]	Speed: 28.35 samples/s ETA: 1 d  9 h 12 m	Data: 0.026 Tran: 0.007 F: 0.150 B: 0.296 O: 1.767 M: 0.010	Train-MLMAcc=0.621102,	MVRCAccuracy=0.666568,	MLMLossWVC=1.839260,	MVRCLoss=2.463305,	
Rank[  3]Epoch[5] Batch [1300]	Speed: 28.35 samples/s ETA: 1 d  9 h 12 m	Data: 1.721 Tran: 0.007 F: 0.152 B: 0.299 O: 0.070 M: 0.008	Train-MLMAcc=0.621102,	MVRCAccuracy=0.666568,	MLMLossWVC=1.839260,	MVRCLoss=2.463305,	
Rank[  1]Epoch[5] Batch [1300]	Speed: 28.35 samples/s ETA: 1 d  9 h 12 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.790 M: 0.010	Train-MLMAcc=0.621102,	MVRCAccuracy=0.666568,	MLMLossWVC=1.839260,	MVRCLoss=2.463305,	
Rank[  0]Epoch[5] Batch [1300]	Speed: 28.35 samples/s ETA: 1 d  9 h 12 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.293 O: 1.790 M: 0.008	Train-MLMAcc=0.621102,	MVRCAccuracy=0.666568,	MLMLossWVC=1.839260,	MVRCLoss=2.463305,	
Rank[  0]Epoch[5] Batch [1400]	Speed: 28.18 samples/s ETA: 1 d  9 h 20 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.807 M: 0.007	Train-MLMAcc=0.621080,	MVRCAccuracy=0.666611,	MLMLossWVC=1.839502,	MVRCLoss=2.463154,	
Rank[  3]Epoch[5] Batch [1400]	Speed: 28.18 samples/s ETA: 1 d  9 h 20 m	Data: 0.830 Tran: 0.006 F: 0.150 B: 0.297 O: 0.980 M: 0.007	Train-MLMAcc=0.621080,	MVRCAccuracy=0.666611,	MLMLossWVC=1.839502,	MVRCLoss=2.463154,	
Rank[  1]Epoch[5] Batch [1400]	Speed: 28.18 samples/s ETA: 1 d  9 h 20 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.806 M: 0.005	Train-MLMAcc=0.621080,	MVRCAccuracy=0.666611,	MLMLossWVC=1.839502,	MVRCLoss=2.463154,	
Rank[  2]Epoch[5] Batch [1400]	Speed: 28.18 samples/s ETA: 1 d  9 h 20 m	Data: 0.938 Tran: 0.007 F: 0.150 B: 0.298 O: 0.870 M: 0.007	Train-MLMAcc=0.621080,	MVRCAccuracy=0.666611,	MLMLossWVC=1.839502,	MVRCLoss=2.463154,	
Rank[  2]Epoch[5] Batch [1500]	Speed: 28.20 samples/s ETA: 1 d  9 h 15 m	Data: 1.431 Tran: 0.007 F: 0.150 B: 0.296 O: 0.379 M: 0.006	Train-MLMAcc=0.621165,	MVRCAccuracy=0.666661,	MLMLossWVC=1.838604,	MVRCLoss=2.463763,	
Rank[  3]Epoch[5] Batch [1500]	Speed: 28.20 samples/s ETA: 1 d  9 h 15 m	Data: 0.339 Tran: 0.007 F: 0.149 B: 0.296 O: 1.474 M: 0.005	Train-MLMAcc=0.621165,	MVRCAccuracy=0.666661,	MLMLossWVC=1.838604,	MVRCLoss=2.463763,	
Rank[  1]Epoch[5] Batch [1500]	Speed: 28.20 samples/s ETA: 1 d  9 h 15 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.296 O: 1.803 M: 0.006	Train-MLMAcc=0.621165,	MVRCAccuracy=0.666661,	MLMLossWVC=1.838604,	MVRCLoss=2.463763,	
Rank[  0]Epoch[5] Batch [1500]	Speed: 28.20 samples/s ETA: 1 d  9 h 15 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.807 M: 0.005	Train-MLMAcc=0.621165,	MVRCAccuracy=0.666661,	MLMLossWVC=1.838604,	MVRCLoss=2.463763,	
Rank[  0]Epoch[5] Batch [1600]	Speed: 27.94 samples/s ETA: 1 d  9 h 30 m	Data: 0.064 Tran: 0.007 F: 0.150 B: 0.293 O: 1.769 M: 0.007	Train-MLMAcc=0.621024,	MVRCAccuracy=0.666611,	MLMLossWVC=1.838719,	MVRCLoss=2.463602,	
Rank[  1]Epoch[5] Batch [1600]	Speed: 27.94 samples/s ETA: 1 d  9 h 30 m	Data: 0.871 Tran: 0.007 F: 0.151 B: 0.298 O: 0.952 M: 0.011	Train-MLMAcc=0.621024,	MVRCAccuracy=0.666611,	MLMLossWVC=1.838719,	MVRCLoss=2.463602,	
Rank[  3]Epoch[5] Batch [1600]	Speed: 27.94 samples/s ETA: 1 d  9 h 30 m	Data: 1.257 Tran: 0.007 F: 0.151 B: 0.297 O: 0.569 M: 0.010	Train-MLMAcc=0.621024,	MVRCAccuracy=0.666611,	MLMLossWVC=1.838719,	MVRCLoss=2.463602,	
Rank[  2]Epoch[5] Batch [1600]	Speed: 27.94 samples/s ETA: 1 d  9 h 30 m	Data: 0.617 Tran: 0.006 F: 0.150 B: 0.296 O: 1.212 M: 0.008	Train-MLMAcc=0.621024,	MVRCAccuracy=0.666611,	MLMLossWVC=1.838719,	MVRCLoss=2.463602,	
Rank[  0]Epoch[5] Batch [1700]	Speed: 27.72 samples/s ETA: 1 d  9 h 42 m	Data: 0.027 Tran: 0.007 F: 0.150 B: 0.293 O: 1.825 M: 0.006	Train-MLMAcc=0.620905,	MVRCAccuracy=0.666660,	MLMLossWVC=1.839075,	MVRCLoss=2.463638,	
Rank[  2]Epoch[5] Batch [1700]	Speed: 27.72 samples/s ETA: 1 d  9 h 42 m	Data: 0.074 Tran: 0.007 F: 0.149 B: 0.296 O: 1.775 M: 0.008	Train-MLMAcc=0.620905,	MVRCAccuracy=0.666660,	MLMLossWVC=1.839075,	MVRCLoss=2.463638,	
Rank[  1]Epoch[5] Batch [1700]	Speed: 27.72 samples/s ETA: 1 d  9 h 42 m	Data: 0.974 Tran: 0.006 F: 0.151 B: 0.295 O: 0.875 M: 0.008	Train-MLMAcc=0.620905,	MVRCAccuracy=0.666660,	MLMLossWVC=1.839075,	MVRCLoss=2.463638,	
Rank[  3]Epoch[5] Batch [1700]	Speed: 27.72 samples/s ETA: 1 d  9 h 42 m	Data: 1.788 Tran: 0.007 F: 0.151 B: 0.298 O: 0.056 M: 0.008	Train-MLMAcc=0.620905,	MVRCAccuracy=0.666660,	MLMLossWVC=1.839075,	MVRCLoss=2.463638,	
Rank[  0]Epoch[5] Batch [1800]	Speed: 28.52 samples/s ETA: 1 d  8 h 41 m	Data: 0.296 Tran: 0.007 F: 0.150 B: 0.293 O: 1.492 M: 0.005	Train-MLMAcc=0.620863,	MVRCAccuracy=0.666715,	MLMLossWVC=1.839989,	MVRCLoss=2.463783,	
Rank[  3]Epoch[5] Batch [1800]	Speed: 28.52 samples/s ETA: 1 d  8 h 41 m	Data: 1.681 Tran: 0.006 F: 0.150 B: 0.297 O: 0.102 M: 0.007	Train-MLMAcc=0.620863,	MVRCAccuracy=0.666715,	MLMLossWVC=1.839989,	MVRCLoss=2.463783,	
Rank[  2]Epoch[5] Batch [1800]	Speed: 28.52 samples/s ETA: 1 d  8 h 41 m	Data: 0.135 Tran: 0.007 F: 0.150 B: 0.297 O: 1.648 M: 0.007	Train-MLMAcc=0.620863,	MVRCAccuracy=0.666715,	MLMLossWVC=1.839989,	MVRCLoss=2.463783,	
Rank[  1]Epoch[5] Batch [1800]	Speed: 28.52 samples/s ETA: 1 d  8 h 41 m	Data: 0.661 Tran: 0.007 F: 0.152 B: 0.297 O: 1.119 M: 0.007	Train-MLMAcc=0.620863,	MVRCAccuracy=0.666715,	MLMLossWVC=1.839989,	MVRCLoss=2.463783,	
Rank[  3]Epoch[5] Batch [1900]	Speed: 28.10 samples/s ETA: 1 d  9 h  7 m	Data: 1.686 Tran: 0.006 F: 0.150 B: 0.297 O: 0.131 M: 0.006	Train-MLMAcc=0.620885,	MVRCAccuracy=0.666800,	MLMLossWVC=1.839375,	MVRCLoss=2.463944,	
Rank[  2]Epoch[5] Batch [1900]	Speed: 28.10 samples/s ETA: 1 d  9 h  7 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.809 M: 0.006	Train-MLMAcc=0.620885,	MVRCAccuracy=0.666800,	MLMLossWVC=1.839375,	MVRCLoss=2.463944,	
Rank[  0]Epoch[5] Batch [1900]	Speed: 28.10 samples/s ETA: 1 d  9 h  7 m	Data: 0.281 Tran: 0.007 F: 0.150 B: 0.294 O: 1.538 M: 0.006	Train-MLMAcc=0.620885,	MVRCAccuracy=0.666800,	MLMLossWVC=1.839375,	MVRCLoss=2.463944,	
Rank[  1]Epoch[5] Batch [1900]	Speed: 28.10 samples/s ETA: 1 d  9 h  7 m	Data: 0.091 Tran: 0.007 F: 0.150 B: 0.295 O: 1.727 M: 0.007	Train-MLMAcc=0.620885,	MVRCAccuracy=0.666800,	MLMLossWVC=1.839375,	MVRCLoss=2.463944,	
Rank[  1]Epoch[5] Batch [2000]	Speed: 27.43 samples/s ETA: 1 d  9 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.865 M: 0.007	Train-MLMAcc=0.620610,	MVRCAccuracy=0.666808,	MLMLossWVC=1.840721,	MVRCLoss=2.463906,	
Rank[  3]Epoch[5] Batch [2000]	Speed: 27.43 samples/s ETA: 1 d  9 h 52 m	Data: 1.815 Tran: 0.007 F: 0.151 B: 0.297 O: 0.058 M: 0.006	Train-MLMAcc=0.620610,	MVRCAccuracy=0.666808,	MLMLossWVC=1.840721,	MVRCLoss=2.463906,	
Rank[  0]Epoch[5] Batch [2000]	Speed: 27.43 samples/s ETA: 1 d  9 h 52 m	Data: 0.096 Tran: 0.007 F: 0.150 B: 0.292 O: 1.783 M: 0.006	Train-MLMAcc=0.620610,	MVRCAccuracy=0.666808,	MLMLossWVC=1.840721,	MVRCLoss=2.463906,	
Rank[  2]Epoch[5] Batch [2000]	Speed: 27.43 samples/s ETA: 1 d  9 h 52 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.864 M: 0.005	Train-MLMAcc=0.620610,	MVRCAccuracy=0.666808,	MLMLossWVC=1.840721,	MVRCLoss=2.463906,	
Rank[  2]Epoch[5] Batch [2100]	Speed: 28.03 samples/s ETA: 1 d  9 h  4 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.296 O: 1.815 M: 0.007	Train-MLMAcc=0.620600,	MVRCAccuracy=0.666711,	MLMLossWVC=1.841445,	MVRCLoss=2.463857,	
Rank[  0]Epoch[5] Batch [2100]	Speed: 28.03 samples/s ETA: 1 d  9 h  4 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.293 O: 1.817 M: 0.006	Train-MLMAcc=0.620600,	MVRCAccuracy=0.666711,	MLMLossWVC=1.841445,	MVRCLoss=2.463857,	
Rank[  3]Epoch[5] Batch [2100]	Speed: 28.03 samples/s ETA: 1 d  9 h  4 m	Data: 1.771 Tran: 0.007 F: 0.150 B: 0.297 O: 0.050 M: 0.007	Train-MLMAcc=0.620600,	MVRCAccuracy=0.666711,	MLMLossWVC=1.841445,	MVRCLoss=2.463857,	
Rank[  1]Epoch[5] Batch [2100]	Speed: 28.03 samples/s ETA: 1 d  9 h  4 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.815 M: 0.007	Train-MLMAcc=0.620600,	MVRCAccuracy=0.666711,	MLMLossWVC=1.841445,	MVRCLoss=2.463857,	
Rank[  3]Epoch[5] Batch [2200]	Speed: 27.77 samples/s ETA: 1 d  9 h 19 m	Data: 1.774 Tran: 0.007 F: 0.150 B: 0.296 O: 0.069 M: 0.009	Train-MLMAcc=0.620520,	MVRCAccuracy=0.666797,	MLMLossWVC=1.842199,	MVRCLoss=2.463787,	
Rank[  2]Epoch[5] Batch [2200]	Speed: 27.77 samples/s ETA: 1 d  9 h 19 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.833 M: 0.009	Train-MLMAcc=0.620520,	MVRCAccuracy=0.666797,	MLMLossWVC=1.842199,	MVRCLoss=2.463787,	
Rank[  0]Epoch[5] Batch [2200]	Speed: 27.77 samples/s ETA: 1 d  9 h 19 m	Data: 0.028 Tran: 0.007 F: 0.149 B: 0.291 O: 1.820 M: 0.009	Train-MLMAcc=0.620520,	MVRCAccuracy=0.666797,	MLMLossWVC=1.842199,	MVRCLoss=2.463787,	
Rank[  1]Epoch[5] Batch [2200]	Speed: 27.77 samples/s ETA: 1 d  9 h 19 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.833 M: 0.008	Train-MLMAcc=0.620520,	MVRCAccuracy=0.666797,	MLMLossWVC=1.842199,	MVRCLoss=2.463787,	
Rank[  2]Epoch[5] Batch [2300]	Speed: 27.24 samples/s ETA: 1 d  9 h 54 m	Data: 0.020 Tran: 0.007 F: 0.149 B: 0.294 O: 1.868 M: 0.010	Train-MLMAcc=0.620821,	MVRCAccuracy=0.666850,	MLMLossWVC=1.840846,	MVRCLoss=2.463754,	
Rank[  0]Epoch[5] Batch [2300]	Speed: 27.24 samples/s ETA: 1 d  9 h 54 m	Data: 0.018 Tran: 0.007 F: 0.150 B: 0.291 O: 1.876 M: 0.007	Train-MLMAcc=0.620821,	MVRCAccuracy=0.666850,	MLMLossWVC=1.840846,	MVRCLoss=2.463754,	
Rank[  3]Epoch[5] Batch [2300]	Speed: 27.24 samples/s ETA: 1 d  9 h 54 m	Data: 1.809 Tran: 0.007 F: 0.151 B: 0.298 O: 0.074 M: 0.010	Train-MLMAcc=0.620821,	MVRCAccuracy=0.666850,	MLMLossWVC=1.840846,	MVRCLoss=2.463754,	
Rank[  1]Epoch[5] Batch [2300]	Speed: 27.24 samples/s ETA: 1 d  9 h 54 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.879 M: 0.009	Train-MLMAcc=0.620821,	MVRCAccuracy=0.666850,	MLMLossWVC=1.840846,	MVRCLoss=2.463754,	
Rank[  2]Epoch[5] Batch [2400]	Speed: 28.41 samples/s ETA: 1 d  8 h 26 m	Data: 0.051 Tran: 0.007 F: 0.149 B: 0.296 O: 1.743 M: 0.006	Train-MLMAcc=0.620919,	MVRCAccuracy=0.666842,	MLMLossWVC=1.840027,	MVRCLoss=2.463777,	
Rank[  3]Epoch[5] Batch [2400]	Speed: 28.41 samples/s ETA: 1 d  8 h 26 m	Data: 1.741 Tran: 0.007 F: 0.151 B: 0.297 O: 0.052 M: 0.005	Train-MLMAcc=0.620919,	MVRCAccuracy=0.666842,	MLMLossWVC=1.840027,	MVRCLoss=2.463777,	
Rank[  0]Epoch[5] Batch [2400]	Speed: 28.41 samples/s ETA: 1 d  8 h 26 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.790 M: 0.005	Train-MLMAcc=0.620919,	MVRCAccuracy=0.666842,	MLMLossWVC=1.840027,	MVRCLoss=2.463777,	
Rank[  1]Epoch[5] Batch [2400]	Speed: 28.41 samples/s ETA: 1 d  8 h 26 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.786 M: 0.006	Train-MLMAcc=0.620919,	MVRCAccuracy=0.666842,	MLMLossWVC=1.840027,	MVRCLoss=2.463777,	
Rank[  3]Epoch[5] Batch [2500]	Speed: 27.50 samples/s ETA: 1 d  9 h 27 m	Data: 1.814 Tran: 0.007 F: 0.150 B: 0.297 O: 0.051 M: 0.007	Train-MLMAcc=0.620565,	MVRCAccuracy=0.666866,	MLMLossWVC=1.841351,	MVRCLoss=2.463648,	
Rank[  0]Epoch[5] Batch [2500]	Speed: 27.50 samples/s ETA: 1 d  9 h 27 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.291 O: 1.864 M: 0.007	Train-MLMAcc=0.620565,	MVRCAccuracy=0.666866,	MLMLossWVC=1.841351,	MVRCLoss=2.463648,	
Rank[  2]Epoch[5] Batch [2500]	Speed: 27.50 samples/s ETA: 1 d  9 h 27 m	Data: 0.107 Tran: 0.007 F: 0.149 B: 0.295 O: 1.763 M: 0.007	Train-MLMAcc=0.620565,	MVRCAccuracy=0.666866,	MLMLossWVC=1.841351,	MVRCLoss=2.463648,	
Rank[  1]Epoch[5] Batch [2500]	Speed: 27.50 samples/s ETA: 1 d  9 h 27 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.864 M: 0.006	Train-MLMAcc=0.620565,	MVRCAccuracy=0.666866,	MLMLossWVC=1.841351,	MVRCLoss=2.463648,	
Rank[  0]Epoch[5] Batch [2600]	Speed: 27.93 samples/s ETA: 1 d  8 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.825 M: 0.008	Train-MLMAcc=0.620476,	MVRCAccuracy=0.666857,	MLMLossWVC=1.841724,	MVRCLoss=2.463683,	
Rank[  2]Epoch[5] Batch [2600]	Speed: 27.93 samples/s ETA: 1 d  8 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.823 M: 0.006	Train-MLMAcc=0.620476,	MVRCAccuracy=0.666857,	MLMLossWVC=1.841724,	MVRCLoss=2.463683,	
Rank[  1]Epoch[5] Batch [2600]	Speed: 27.93 samples/s ETA: 1 d  8 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.825 M: 0.007	Train-MLMAcc=0.620476,	MVRCAccuracy=0.666857,	MLMLossWVC=1.841724,	MVRCLoss=2.463683,	
Rank[  3]Epoch[5] Batch [2600]	Speed: 27.93 samples/s ETA: 1 d  8 h 52 m	Data: 1.778 Tran: 0.007 F: 0.150 B: 0.295 O: 0.055 M: 0.007	Train-MLMAcc=0.620476,	MVRCAccuracy=0.666857,	MLMLossWVC=1.841724,	MVRCLoss=2.463683,	
Rank[  0]Epoch[5] Batch [2700]	Speed: 28.01 samples/s ETA: 1 d  8 h 43 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.822 M: 0.007	Train-MLMAcc=0.620625,	MVRCAccuracy=0.666897,	MLMLossWVC=1.840771,	MVRCLoss=2.463486,	
Rank[  3]Epoch[5] Batch [2700]	Speed: 28.01 samples/s ETA: 1 d  8 h 43 m	Data: 1.769 Tran: 0.007 F: 0.150 B: 0.296 O: 0.053 M: 0.008	Train-MLMAcc=0.620625,	MVRCAccuracy=0.666897,	MLMLossWVC=1.840771,	MVRCLoss=2.463486,	
Rank[  2]Epoch[5] Batch [2700]	Speed: 28.01 samples/s ETA: 1 d  8 h 43 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.815 M: 0.006	Train-MLMAcc=0.620625,	MVRCAccuracy=0.666897,	MLMLossWVC=1.840771,	MVRCLoss=2.463486,	
Rank[  1]Epoch[5] Batch [2700]	Speed: 28.01 samples/s ETA: 1 d  8 h 43 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.819 M: 0.009	Train-MLMAcc=0.620625,	MVRCAccuracy=0.666897,	MLMLossWVC=1.840771,	MVRCLoss=2.463486,	
Rank[  3]Epoch[5] Batch [2800]	Speed: 28.01 samples/s ETA: 1 d  8 h 39 m	Data: 1.770 Tran: 0.007 F: 0.150 B: 0.295 O: 0.054 M: 0.007	Train-MLMAcc=0.620611,	MVRCAccuracy=0.666879,	MLMLossWVC=1.841221,	MVRCLoss=2.463373,	
Rank[  2]Epoch[5] Batch [2800]	Speed: 28.01 samples/s ETA: 1 d  8 h 39 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.296 O: 1.816 M: 0.006	Train-MLMAcc=0.620611,	MVRCAccuracy=0.666879,	MLMLossWVC=1.841221,	MVRCLoss=2.463373,	
Rank[  1]Epoch[5] Batch [2800]	Speed: 28.01 samples/s ETA: 1 d  8 h 39 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.819 M: 0.006	Train-MLMAcc=0.620611,	MVRCAccuracy=0.666879,	MLMLossWVC=1.841221,	MVRCLoss=2.463373,	
Rank[  0]Epoch[5] Batch [2800]	Speed: 28.01 samples/s ETA: 1 d  8 h 39 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.819 M: 0.007	Train-MLMAcc=0.620611,	MVRCAccuracy=0.666879,	MLMLossWVC=1.841221,	MVRCLoss=2.463373,	
Rank[  3]Epoch[5] Batch [2900]	Speed: 28.18 samples/s ETA: 1 d  8 h 23 m	Data: 1.756 Tran: 0.007 F: 0.151 B: 0.297 O: 0.052 M: 0.008	Train-MLMAcc=0.620661,	MVRCAccuracy=0.666900,	MLMLossWVC=1.840896,	MVRCLoss=2.463310,	
Rank[  0]Epoch[5] Batch [2900]	Speed: 28.18 samples/s ETA: 1 d  8 h 23 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.807 M: 0.007	Train-MLMAcc=0.620661,	MVRCAccuracy=0.666900,	MLMLossWVC=1.840896,	MVRCLoss=2.463310,	
Rank[  1]Epoch[5] Batch [2900]	Speed: 28.18 samples/s ETA: 1 d  8 h 23 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.802 M: 0.008	Train-MLMAcc=0.620661,	MVRCAccuracy=0.666900,	MLMLossWVC=1.840896,	MVRCLoss=2.463310,	
Rank[  2]Epoch[5] Batch [2900]	Speed: 28.18 samples/s ETA: 1 d  8 h 23 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.802 M: 0.006	Train-MLMAcc=0.620661,	MVRCAccuracy=0.666900,	MLMLossWVC=1.840896,	MVRCLoss=2.463310,	
Rank[  0]Epoch[5] Batch [3000]	Speed: 28.21 samples/s ETA: 1 d  8 h 18 m	Data: 0.266 Tran: 0.007 F: 0.149 B: 0.292 O: 1.547 M: 0.007	Train-MLMAcc=0.620676,	MVRCAccuracy=0.666900,	MLMLossWVC=1.840302,	MVRCLoss=2.463106,	
Rank[  3]Epoch[5] Batch [3000]	Speed: 28.21 samples/s ETA: 1 d  8 h 18 m	Data: 1.500 Tran: 0.007 F: 0.151 B: 0.298 O: 0.306 M: 0.006	Train-MLMAcc=0.620676,	MVRCAccuracy=0.666900,	MLMLossWVC=1.840302,	MVRCLoss=2.463106,	
Rank[  2]Epoch[5] Batch [3000]	Speed: 28.21 samples/s ETA: 1 d  8 h 18 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.799 M: 0.007	Train-MLMAcc=0.620676,	MVRCAccuracy=0.666900,	MLMLossWVC=1.840302,	MVRCLoss=2.463106,	
Rank[  1]Epoch[5] Batch [3000]	Speed: 28.21 samples/s ETA: 1 d  8 h 18 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.802 M: 0.005	Train-MLMAcc=0.620676,	MVRCAccuracy=0.666900,	MLMLossWVC=1.840302,	MVRCLoss=2.463106,	
Rank[  3]Epoch[5] Batch [3100]	Speed: 28.26 samples/s ETA: 1 d  8 h 11 m	Data: 0.895 Tran: 0.007 F: 0.151 B: 0.298 O: 0.907 M: 0.006	Train-MLMAcc=0.620893,	MVRCAccuracy=0.666953,	MLMLossWVC=1.839388,	MVRCLoss=2.462945,	
Rank[  1]Epoch[5] Batch [3100]	Speed: 28.26 samples/s ETA: 1 d  8 h 11 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.798 M: 0.007	Train-MLMAcc=0.620893,	MVRCAccuracy=0.666953,	MLMLossWVC=1.839388,	MVRCLoss=2.462945,	
Rank[  0]Epoch[5] Batch [3100]	Speed: 28.26 samples/s ETA: 1 d  8 h 11 m	Data: 0.865 Tran: 0.007 F: 0.150 B: 0.292 O: 0.943 M: 0.007	Train-MLMAcc=0.620893,	MVRCAccuracy=0.666953,	MLMLossWVC=1.839388,	MVRCLoss=2.462945,	
Rank[  2]Epoch[5] Batch [3100]	Speed: 28.26 samples/s ETA: 1 d  8 h 11 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.794 M: 0.006	Train-MLMAcc=0.620893,	MVRCAccuracy=0.666953,	MLMLossWVC=1.839388,	MVRCLoss=2.462945,	
Rank[  3]Epoch[5] Batch [3200]	Speed: 26.77 samples/s ETA: 1 d  9 h 54 m	Data: 1.468 Tran: 0.012 F: 0.192 B: 0.323 O: 0.388 M: 0.009	Train-MLMAcc=0.621008,	MVRCAccuracy=0.666991,	MLMLossWVC=1.838988,	MVRCLoss=2.462637,	
Rank[  0]Epoch[5] Batch [3200]	Speed: 26.77 samples/s ETA: 1 d  9 h 54 m	Data: 0.329 Tran: 0.008 F: 0.160 B: 0.300 O: 1.584 M: 0.008	Train-MLMAcc=0.621008,	MVRCAccuracy=0.666991,	MLMLossWVC=1.838988,	MVRCLoss=2.462637,	
Rank[  2]Epoch[5] Batch [3200]	Speed: 26.77 samples/s ETA: 1 d  9 h 54 m	Data: 0.017 Tran: 0.009 F: 0.158 B: 0.302 O: 1.897 M: 0.007	Train-MLMAcc=0.621008,	MVRCAccuracy=0.666991,	MLMLossWVC=1.838988,	MVRCLoss=2.462637,	
Rank[  1]Epoch[5] Batch [3200]	Speed: 26.77 samples/s ETA: 1 d  9 h 54 m	Data: 0.066 Tran: 0.008 F: 0.160 B: 0.303 O: 1.844 M: 0.010	Train-MLMAcc=0.621008,	MVRCAccuracy=0.666991,	MLMLossWVC=1.838988,	MVRCLoss=2.462637,	
Rank[  3]Epoch[5] Batch [3300]	Speed: 27.97 samples/s ETA: 1 d  8 h 23 m	Data: 1.309 Tran: 0.007 F: 0.150 B: 0.297 O: 0.517 M: 0.007	Train-MLMAcc=0.621092,	MVRCAccuracy=0.667057,	MLMLossWVC=1.838567,	MVRCLoss=2.462685,	
Rank[  2]Epoch[5] Batch [3300]	Speed: 27.97 samples/s ETA: 1 d  8 h 23 m	Data: 0.245 Tran: 0.007 F: 0.150 B: 0.297 O: 1.580 M: 0.008	Train-MLMAcc=0.621092,	MVRCAccuracy=0.667057,	MLMLossWVC=1.838567,	MVRCLoss=2.462685,	
Rank[  1]Epoch[5] Batch [3300]	Speed: 27.97 samples/s ETA: 1 d  8 h 23 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.822 M: 0.006	Train-MLMAcc=0.621092,	MVRCAccuracy=0.667057,	MLMLossWVC=1.838567,	MVRCLoss=2.462685,	
Rank[  0]Epoch[5] Batch [3300]	Speed: 27.97 samples/s ETA: 1 d  8 h 23 m	Data: 0.238 Tran: 0.007 F: 0.150 B: 0.292 O: 1.593 M: 0.007	Train-MLMAcc=0.621092,	MVRCAccuracy=0.667057,	MLMLossWVC=1.838567,	MVRCLoss=2.462685,	
Rank[  3]Epoch[5] Batch [3400]	Speed: 27.51 samples/s ETA: 1 d  8 h 51 m	Data: 1.283 Tran: 0.006 F: 0.151 B: 0.298 O: 0.581 M: 0.007	Train-MLMAcc=0.621057,	MVRCAccuracy=0.667128,	MLMLossWVC=1.838387,	MVRCLoss=2.462484,	
Rank[  1]Epoch[5] Batch [3400]	Speed: 27.51 samples/s ETA: 1 d  8 h 51 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.861 M: 0.006	Train-MLMAcc=0.621057,	MVRCAccuracy=0.667128,	MLMLossWVC=1.838387,	MVRCLoss=2.462484,	
Rank[  0]Epoch[5] Batch [3400]	Speed: 27.51 samples/s ETA: 1 d  8 h 51 m	Data: 0.453 Tran: 0.007 F: 0.149 B: 0.291 O: 1.418 M: 0.008	Train-MLMAcc=0.621057,	MVRCAccuracy=0.667128,	MLMLossWVC=1.838387,	MVRCLoss=2.462484,	
Rank[  2]Epoch[5] Batch [3400]	Speed: 27.51 samples/s ETA: 1 d  8 h 51 m	Data: 0.093 Tran: 0.007 F: 0.150 B: 0.298 O: 1.770 M: 0.008	Train-MLMAcc=0.621057,	MVRCAccuracy=0.667128,	MLMLossWVC=1.838387,	MVRCLoss=2.462484,	
Rank[  3]Epoch[5] Batch [3500]	Speed: 27.11 samples/s ETA: 1 d  9 h 16 m	Data: 1.648 Tran: 0.014 F: 0.198 B: 0.330 O: 0.159 M: 0.009	Train-MLMAcc=0.621228,	MVRCAccuracy=0.667160,	MLMLossWVC=1.837741,	MVRCLoss=2.462322,	
Rank[  1]Epoch[5] Batch [3500]	Speed: 27.11 samples/s ETA: 1 d  9 h 16 m	Data: 0.031 Tran: 0.007 F: 0.168 B: 0.319 O: 1.823 M: 0.010	Train-MLMAcc=0.621228,	MVRCAccuracy=0.667160,	MLMLossWVC=1.837741,	MVRCLoss=2.462322,	
Rank[  0]Epoch[5] Batch [3500]	Speed: 27.11 samples/s ETA: 1 d  9 h 16 m	Data: 0.010 Tran: 0.008 F: 0.169 B: 0.315 O: 1.848 M: 0.009	Train-MLMAcc=0.621228,	MVRCAccuracy=0.667160,	MLMLossWVC=1.837741,	MVRCLoss=2.462322,	
Rank[  2]Epoch[5] Batch [3500]	Speed: 27.11 samples/s ETA: 1 d  9 h 16 m	Data: 0.226 Tran: 0.007 F: 0.172 B: 0.325 O: 1.618 M: 0.010	Train-MLMAcc=0.621228,	MVRCAccuracy=0.667160,	MLMLossWVC=1.837741,	MVRCLoss=2.462322,	
Rank[  2]Epoch[5] Batch [3600]	Speed: 27.68 samples/s ETA: 1 d  8 h 31 m	Data: 0.442 Tran: 0.008 F: 0.169 B: 0.320 O: 1.361 M: 0.010	Train-MLMAcc=0.621163,	MVRCAccuracy=0.667226,	MLMLossWVC=1.838023,	MVRCLoss=2.462234,	
Rank[  3]Epoch[5] Batch [3600]	Speed: 27.68 samples/s ETA: 1 d  8 h 31 m	Data: 0.827 Tran: 0.007 F: 0.175 B: 0.318 O: 0.973 M: 0.010	Train-MLMAcc=0.621163,	MVRCAccuracy=0.667226,	MLMLossWVC=1.838023,	MVRCLoss=2.462234,	
Rank[  1]Epoch[5] Batch [3600]	Speed: 27.68 samples/s ETA: 1 d  8 h 31 m	Data: 0.701 Tran: 0.007 F: 0.173 B: 0.313 O: 1.106 M: 0.011	Train-MLMAcc=0.621163,	MVRCAccuracy=0.667226,	MLMLossWVC=1.838023,	MVRCLoss=2.462234,	
Rank[  0]Epoch[5] Batch [3600]	Speed: 27.68 samples/s ETA: 1 d  8 h 31 m	Data: 0.009 Tran: 0.009 F: 0.169 B: 0.315 O: 1.802 M: 0.007	Train-MLMAcc=0.621163,	MVRCAccuracy=0.667226,	MLMLossWVC=1.838023,	MVRCLoss=2.462234,	
Rank[  3]Epoch[5] Batch [3700]	Speed: 27.64 samples/s ETA: 1 d  8 h 31 m	Data: 0.418 Tran: 0.007 F: 0.150 B: 0.297 O: 1.435 M: 0.008	Train-MLMAcc=0.621010,	MVRCAccuracy=0.667256,	MLMLossWVC=1.838563,	MVRCLoss=2.462221,	
Rank[  2]Epoch[5] Batch [3700]	Speed: 27.64 samples/s ETA: 1 d  8 h 31 m	Data: 0.612 Tran: 0.007 F: 0.150 B: 0.297 O: 1.240 M: 0.009	Train-MLMAcc=0.621010,	MVRCAccuracy=0.667256,	MLMLossWVC=1.838563,	MVRCLoss=2.462221,	
Rank[  0]Epoch[5] Batch [3700]	Speed: 27.64 samples/s ETA: 1 d  8 h 31 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.294 O: 1.850 M: 0.006	Train-MLMAcc=0.621010,	MVRCAccuracy=0.667256,	MLMLossWVC=1.838563,	MVRCLoss=2.462221,	
Rank[  1]Epoch[5] Batch [3700]	Speed: 27.64 samples/s ETA: 1 d  8 h 31 m	Data: 0.945 Tran: 0.007 F: 0.150 B: 0.294 O: 0.909 M: 0.009	Train-MLMAcc=0.621010,	MVRCAccuracy=0.667256,	MLMLossWVC=1.838563,	MVRCLoss=2.462221,	
Rank[  1]Epoch[5] Batch [3800]	Speed: 26.54 samples/s ETA: 1 d  9 h 48 m	Data: 0.347 Tran: 0.011 F: 0.190 B: 0.324 O: 1.526 M: 0.011	Train-MLMAcc=0.620970,	MVRCAccuracy=0.667324,	MLMLossWVC=1.838619,	MVRCLoss=2.462144,	
Rank[  2]Epoch[5] Batch [3800]	Speed: 26.54 samples/s ETA: 1 d  9 h 48 m	Data: 0.957 Tran: 0.007 F: 0.167 B: 0.320 O: 0.946 M: 0.012	Train-MLMAcc=0.620970,	MVRCAccuracy=0.667324,	MLMLossWVC=1.838619,	MVRCLoss=2.462144,	
Rank[  3]Epoch[5] Batch [3800]	Speed: 26.54 samples/s ETA: 1 d  9 h 48 m	Data: 0.884 Tran: 0.008 F: 0.171 B: 0.311 O: 1.024 M: 0.012	Train-MLMAcc=0.620970,	MVRCAccuracy=0.667324,	MLMLossWVC=1.838619,	MVRCLoss=2.462144,	
Rank[  0]Epoch[5] Batch [3800]	Speed: 26.54 samples/s ETA: 1 d  9 h 48 m	Data: 0.011 Tran: 0.007 F: 0.162 B: 0.310 O: 1.908 M: 0.012	Train-MLMAcc=0.620970,	MVRCAccuracy=0.667324,	MLMLossWVC=1.838619,	MVRCLoss=2.462144,	
Rank[  0]Epoch[5] Batch [3900]	Speed: 27.96 samples/s ETA: 1 d  8 h  1 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.825 M: 0.007	Train-MLMAcc=0.620888,	MVRCAccuracy=0.667396,	MLMLossWVC=1.839109,	MVRCLoss=2.462194,	
Rank[  3]Epoch[5] Batch [3900]	Speed: 27.96 samples/s ETA: 1 d  8 h  1 m	Data: 0.556 Tran: 0.007 F: 0.151 B: 0.299 O: 1.267 M: 0.008	Train-MLMAcc=0.620888,	MVRCAccuracy=0.667396,	MLMLossWVC=1.839109,	MVRCLoss=2.462194,	
Rank[  2]Epoch[5] Batch [3900]	Speed: 27.96 samples/s ETA: 1 d  8 h  1 m	Data: 0.577 Tran: 0.007 F: 0.150 B: 0.297 O: 1.249 M: 0.009	Train-MLMAcc=0.620888,	MVRCAccuracy=0.667396,	MLMLossWVC=1.839109,	MVRCLoss=2.462194,	
Rank[  1]Epoch[5] Batch [3900]	Speed: 27.96 samples/s ETA: 1 d  8 h  1 m	Data: 0.680 Tran: 0.007 F: 0.151 B: 0.297 O: 1.145 M: 0.009	Train-MLMAcc=0.620888,	MVRCAccuracy=0.667396,	MLMLossWVC=1.839109,	MVRCLoss=2.462194,	
Rank[  3]Epoch[5] Batch [4000]	Speed: 27.95 samples/s ETA: 1 d  7 h 57 m	Data: 0.609 Tran: 0.006 F: 0.150 B: 0.299 O: 1.214 M: 0.010	Train-MLMAcc=0.621025,	MVRCAccuracy=0.667460,	MLMLossWVC=1.838484,	MVRCLoss=2.462095,	
Rank[  2]Epoch[5] Batch [4000]	Speed: 27.95 samples/s ETA: 1 d  7 h 57 m	Data: 0.208 Tran: 0.007 F: 0.149 B: 0.296 O: 1.618 M: 0.010	Train-MLMAcc=0.621025,	MVRCAccuracy=0.667460,	MLMLossWVC=1.838484,	MVRCLoss=2.462095,	
Rank[  1]Epoch[5] Batch [4000]	Speed: 27.95 samples/s ETA: 1 d  7 h 57 m	Data: 0.972 Tran: 0.007 F: 0.152 B: 0.298 O: 0.854 M: 0.007	Train-MLMAcc=0.621025,	MVRCAccuracy=0.667460,	MLMLossWVC=1.838484,	MVRCLoss=2.462095,	
Rank[  0]Epoch[5] Batch [4000]	Speed: 27.95 samples/s ETA: 1 d  7 h 57 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.825 M: 0.008	Train-MLMAcc=0.621025,	MVRCAccuracy=0.667460,	MLMLossWVC=1.838484,	MVRCLoss=2.462095,	
Rank[  3]Epoch[5] Batch [4100]	Speed: 27.21 samples/s ETA: 1 d  8 h 46 m	Data: 1.233 Tran: 0.010 F: 0.187 B: 0.318 O: 0.588 M: 0.015	Train-MLMAcc=0.621033,	MVRCAccuracy=0.667524,	MLMLossWVC=1.838647,	MVRCLoss=2.461831,	
Rank[  0]Epoch[5] Batch [4100]	Speed: 27.21 samples/s ETA: 1 d  8 h 46 m	Data: 0.009 Tran: 0.007 F: 0.158 B: 0.299 O: 1.862 M: 0.015	Train-MLMAcc=0.621033,	MVRCAccuracy=0.667524,	MLMLossWVC=1.838647,	MVRCLoss=2.461831,	
Rank[  1]Epoch[5] Batch [4100]	Speed: 27.21 samples/s ETA: 1 d  8 h 46 m	Data: 0.309 Tran: 0.007 F: 0.158 B: 0.302 O: 1.560 M: 0.014	Train-MLMAcc=0.621033,	MVRCAccuracy=0.667524,	MLMLossWVC=1.838647,	MVRCLoss=2.461831,	
Rank[  2]Epoch[5] Batch [4100]	Speed: 27.21 samples/s ETA: 1 d  8 h 46 m	Data: 0.236 Tran: 0.007 F: 0.160 B: 0.304 O: 1.629 M: 0.014	Train-MLMAcc=0.621033,	MVRCAccuracy=0.667524,	MLMLossWVC=1.838647,	MVRCLoss=2.461831,	
Rank[  3]Epoch[5] Batch [4200]	Speed: 28.04 samples/s ETA: 1 d  7 h 43 m	Data: 0.877 Tran: 0.006 F: 0.150 B: 0.299 O: 0.942 M: 0.007	Train-MLMAcc=0.621068,	MVRCAccuracy=0.667612,	MLMLossWVC=1.838464,	MVRCLoss=2.461587,	
Rank[  1]Epoch[5] Batch [4200]	Speed: 28.04 samples/s ETA: 1 d  7 h 43 m	Data: 0.557 Tran: 0.006 F: 0.150 B: 0.297 O: 1.264 M: 0.006	Train-MLMAcc=0.621068,	MVRCAccuracy=0.667612,	MLMLossWVC=1.838464,	MVRCLoss=2.461587,	
Rank[  2]Epoch[5] Batch [4200]	Speed: 28.04 samples/s ETA: 1 d  7 h 43 m	Data: 0.367 Tran: 0.007 F: 0.149 B: 0.295 O: 1.458 M: 0.006	Train-MLMAcc=0.621068,	MVRCAccuracy=0.667612,	MLMLossWVC=1.838464,	MVRCLoss=2.461587,	
Rank[  0]Epoch[5] Batch [4200]	Speed: 28.04 samples/s ETA: 1 d  7 h 43 m	Data: 0.418 Tran: 0.006 F: 0.150 B: 0.291 O: 1.410 M: 0.006	Train-MLMAcc=0.621068,	MVRCAccuracy=0.667612,	MLMLossWVC=1.838464,	MVRCLoss=2.461587,	
Rank[  1]Epoch[5] Batch [4300]	Speed: 27.95 samples/s ETA: 1 d  7 h 46 m	Data: 0.012 Tran: 0.007 F: 0.150 B: 0.297 O: 1.817 M: 0.006	Train-MLMAcc=0.620999,	MVRCAccuracy=0.667645,	MLMLossWVC=1.838617,	MVRCLoss=2.461531,	
Rank[  0]Epoch[5] Batch [4300]	Speed: 27.95 samples/s ETA: 1 d  7 h 46 m	Data: 0.451 Tran: 0.006 F: 0.150 B: 0.292 O: 1.383 M: 0.006	Train-MLMAcc=0.620999,	MVRCAccuracy=0.667645,	MLMLossWVC=1.838617,	MVRCLoss=2.461531,	
Rank[  2]Epoch[5] Batch [4300]	Speed: 27.95 samples/s ETA: 1 d  7 h 46 m	Data: 1.092 Tran: 0.007 F: 0.151 B: 0.299 O: 0.734 M: 0.007	Train-MLMAcc=0.620999,	MVRCAccuracy=0.667645,	MLMLossWVC=1.838617,	MVRCLoss=2.461531,	
Rank[  3]Epoch[5] Batch [4300]	Speed: 27.95 samples/s ETA: 1 d  7 h 46 m	Data: 0.532 Tran: 0.007 F: 0.150 B: 0.298 O: 1.296 M: 0.007	Train-MLMAcc=0.620999,	MVRCAccuracy=0.667645,	MLMLossWVC=1.838617,	MVRCLoss=2.461531,	
Rank[  3]Epoch[5] Batch [4400]	Speed: 27.63 samples/s ETA: 1 d  8 h  4 m	Data: 0.134 Tran: 0.007 F: 0.150 B: 0.297 O: 1.721 M: 0.007	Train-MLMAcc=0.621075,	MVRCAccuracy=0.667713,	MLMLossWVC=1.838780,	MVRCLoss=2.461367,	
Rank[  2]Epoch[5] Batch [4400]	Speed: 27.63 samples/s ETA: 1 d  8 h  4 m	Data: 0.347 Tran: 0.007 F: 0.149 B: 0.295 O: 1.512 M: 0.006	Train-MLMAcc=0.621075,	MVRCAccuracy=0.667713,	MLMLossWVC=1.838780,	MVRCLoss=2.461367,	
Rank[  1]Epoch[5] Batch [4400]	Speed: 27.63 samples/s ETA: 1 d  8 h  4 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.850 M: 0.006	Train-MLMAcc=0.621075,	MVRCAccuracy=0.667713,	MLMLossWVC=1.838780,	MVRCLoss=2.461367,	
Rank[  0]Epoch[5] Batch [4400]	Speed: 27.63 samples/s ETA: 1 d  8 h  4 m	Data: 1.503 Tran: 0.007 F: 0.150 B: 0.292 O: 0.356 M: 0.007	Train-MLMAcc=0.621075,	MVRCAccuracy=0.667713,	MLMLossWVC=1.838780,	MVRCLoss=2.461367,	
Rank[  2]Epoch[5] Batch [4500]	Speed: 27.92 samples/s ETA: 1 d  7 h 40 m	Data: 0.216 Tran: 0.006 F: 0.149 B: 0.295 O: 1.619 M: 0.006	Train-MLMAcc=0.621155,	MVRCAccuracy=0.667685,	MLMLossWVC=1.838157,	MVRCLoss=2.461449,	
Rank[  3]Epoch[5] Batch [4500]	Speed: 27.92 samples/s ETA: 1 d  7 h 40 m	Data: 0.084 Tran: 0.007 F: 0.150 B: 0.297 O: 1.746 M: 0.007	Train-MLMAcc=0.621155,	MVRCAccuracy=0.667685,	MLMLossWVC=1.838157,	MVRCLoss=2.461449,	
Rank[  0]Epoch[5] Batch [4500]	Speed: 27.92 samples/s ETA: 1 d  7 h 40 m	Data: 1.746 Tran: 0.006 F: 0.151 B: 0.292 O: 0.089 M: 0.007	Train-MLMAcc=0.621155,	MVRCAccuracy=0.667685,	MLMLossWVC=1.838157,	MVRCLoss=2.461449,	
Rank[  1]Epoch[5] Batch [4500]	Speed: 27.92 samples/s ETA: 1 d  7 h 40 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.828 M: 0.007	Train-MLMAcc=0.621155,	MVRCAccuracy=0.667685,	MLMLossWVC=1.838157,	MVRCLoss=2.461449,	
Rank[  2]Epoch[5] Batch [4600]	Speed: 27.97 samples/s ETA: 1 d  7 h 33 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.299 O: 1.817 M: 0.006	Train-MLMAcc=0.621232,	MVRCAccuracy=0.667739,	MLMLossWVC=1.837798,	MVRCLoss=2.461405,	
Rank[  3]Epoch[5] Batch [4600]	Speed: 27.97 samples/s ETA: 1 d  7 h 33 m	Data: 0.083 Tran: 0.007 F: 0.149 B: 0.296 O: 1.746 M: 0.006	Train-MLMAcc=0.621232,	MVRCAccuracy=0.667739,	MLMLossWVC=1.837798,	MVRCLoss=2.461405,	
Rank[  1]Epoch[5] Batch [4600]	Speed: 27.97 samples/s ETA: 1 d  7 h 33 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.823 M: 0.006	Train-MLMAcc=0.621232,	MVRCAccuracy=0.667739,	MLMLossWVC=1.837798,	MVRCLoss=2.461405,	
Rank[  0]Epoch[5] Batch [4600]	Speed: 27.97 samples/s ETA: 1 d  7 h 33 m	Data: 1.776 Tran: 0.006 F: 0.151 B: 0.291 O: 0.056 M: 0.006	Train-MLMAcc=0.621232,	MVRCAccuracy=0.667739,	MLMLossWVC=1.837798,	MVRCLoss=2.461405,	
Rank[  3]Epoch[5] Batch [4700]	Speed: 28.01 samples/s ETA: 1 d  7 h 27 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.813 M: 0.008	Train-MLMAcc=0.621187,	MVRCAccuracy=0.667789,	MLMLossWVC=1.837772,	MVRCLoss=2.461366,	
Rank[  0]Epoch[5] Batch [4700]	Speed: 28.01 samples/s ETA: 1 d  7 h 27 m	Data: 1.770 Tran: 0.006 F: 0.151 B: 0.292 O: 0.056 M: 0.009	Train-MLMAcc=0.621187,	MVRCAccuracy=0.667789,	MLMLossWVC=1.837772,	MVRCLoss=2.461366,	
Rank[  2]Epoch[5] Batch [4700]	Speed: 28.01 samples/s ETA: 1 d  7 h 27 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.817 M: 0.005	Train-MLMAcc=0.621187,	MVRCAccuracy=0.667789,	MLMLossWVC=1.837772,	MVRCLoss=2.461366,	
Rank[  1]Epoch[5] Batch [4700]	Speed: 28.01 samples/s ETA: 1 d  7 h 27 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.816 M: 0.009	Train-MLMAcc=0.621187,	MVRCAccuracy=0.667789,	MLMLossWVC=1.837772,	MVRCLoss=2.461366,	
Rank[  1]Epoch[5] Batch [4800]	Speed: 28.33 samples/s ETA: 1 d  7 h  2 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.294 O: 1.788 M: 0.010	Train-MLMAcc=0.621271,	MVRCAccuracy=0.667804,	MLMLossWVC=1.837355,	MVRCLoss=2.461230,	
Rank[  2]Epoch[5] Batch [4800]	Speed: 28.33 samples/s ETA: 1 d  7 h  2 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.786 M: 0.008	Train-MLMAcc=0.621271,	MVRCAccuracy=0.667804,	MLMLossWVC=1.837355,	MVRCLoss=2.461230,	
Rank[  3]Epoch[5] Batch [4800]	Speed: 28.33 samples/s ETA: 1 d  7 h  2 m	Data: 0.008 Tran: 0.008 F: 0.151 B: 0.298 O: 1.786 M: 0.007	Train-MLMAcc=0.621271,	MVRCAccuracy=0.667804,	MLMLossWVC=1.837355,	MVRCLoss=2.461230,	
Rank[  0]Epoch[5] Batch [4800]	Speed: 28.33 samples/s ETA: 1 d  7 h  2 m	Data: 1.740 Tran: 0.007 F: 0.150 B: 0.291 O: 0.060 M: 0.010	Train-MLMAcc=0.621271,	MVRCAccuracy=0.667804,	MLMLossWVC=1.837355,	MVRCLoss=2.461230,	
Rank[  3]Epoch[5] Batch [4900]	Speed: 26.91 samples/s ETA: 1 d  8 h 36 m	Data: 0.250 Tran: 0.007 F: 0.159 B: 0.306 O: 1.645 M: 0.009	Train-MLMAcc=0.621223,	MVRCAccuracy=0.667876,	MLMLossWVC=1.837353,	MVRCLoss=2.461225,	
Rank[  1]Epoch[5] Batch [4900]	Speed: 26.91 samples/s ETA: 1 d  8 h 36 m	Data: 0.012 Tran: 0.007 F: 0.157 B: 0.305 O: 1.883 M: 0.012	Train-MLMAcc=0.621223,	MVRCAccuracy=0.667876,	MLMLossWVC=1.837353,	MVRCLoss=2.461225,	
Rank[  0]Epoch[5] Batch [4900]	Speed: 26.91 samples/s ETA: 1 d  8 h 36 m	Data: 1.560 Tran: 0.007 F: 0.164 B: 0.328 O: 0.307 M: 0.011	Train-MLMAcc=0.621223,	MVRCAccuracy=0.667876,	MLMLossWVC=1.837353,	MVRCLoss=2.461225,	
Rank[  2]Epoch[5] Batch [4900]	Speed: 26.91 samples/s ETA: 1 d  8 h 36 m	Data: 0.012 Tran: 0.007 F: 0.158 B: 0.308 O: 1.881 M: 0.011	Train-MLMAcc=0.621223,	MVRCAccuracy=0.667876,	MLMLossWVC=1.837353,	MVRCLoss=2.461225,	
Rank[  0]Epoch[5] Batch [5000]	Speed: 28.26 samples/s ETA: 1 d  6 h 59 m	Data: 1.373 Tran: 0.007 F: 0.150 B: 0.292 O: 0.435 M: 0.008	Train-MLMAcc=0.621337,	MVRCAccuracy=0.667897,	MLMLossWVC=1.836765,	MVRCLoss=2.461133,	
Rank[  2]Epoch[5] Batch [5000]	Speed: 28.26 samples/s ETA: 1 d  6 h 59 m	Data: 0.011 Tran: 0.007 F: 0.150 B: 0.296 O: 1.792 M: 0.008	Train-MLMAcc=0.621337,	MVRCAccuracy=0.667897,	MLMLossWVC=1.836765,	MVRCLoss=2.461133,	
Rank[  3]Epoch[5] Batch [5000]	Speed: 28.26 samples/s ETA: 1 d  6 h 59 m	Data: 0.383 Tran: 0.007 F: 0.151 B: 0.299 O: 1.415 M: 0.009	Train-MLMAcc=0.621337,	MVRCAccuracy=0.667897,	MLMLossWVC=1.836765,	MVRCLoss=2.461133,	
Rank[  1]Epoch[5] Batch [5000]	Speed: 28.26 samples/s ETA: 1 d  6 h 59 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.797 M: 0.007	Train-MLMAcc=0.621337,	MVRCAccuracy=0.667897,	MLMLossWVC=1.836765,	MVRCLoss=2.461133,	
Rank[  0]Epoch[5] Batch [5100]	Speed: 28.38 samples/s ETA: 1 d  6 h 47 m	Data: 0.961 Tran: 0.007 F: 0.150 B: 0.293 O: 0.837 M: 0.007	Train-MLMAcc=0.621399,	MVRCAccuracy=0.667922,	MLMLossWVC=1.836643,	MVRCLoss=2.460997,	
Rank[  1]Epoch[5] Batch [5100]	Speed: 28.38 samples/s ETA: 1 d  6 h 47 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.787 M: 0.006	Train-MLMAcc=0.621399,	MVRCAccuracy=0.667922,	MLMLossWVC=1.836643,	MVRCLoss=2.460997,	
Rank[  2]Epoch[5] Batch [5100]	Speed: 28.38 samples/s ETA: 1 d  6 h 47 m	Data: 0.035 Tran: 0.007 F: 0.150 B: 0.298 O: 1.757 M: 0.007	Train-MLMAcc=0.621399,	MVRCAccuracy=0.667922,	MLMLossWVC=1.836643,	MVRCLoss=2.460997,	
Rank[  3]Epoch[5] Batch [5100]	Speed: 28.38 samples/s ETA: 1 d  6 h 47 m	Data: 0.791 Tran: 0.007 F: 0.150 B: 0.298 O: 1.003 M: 0.006	Train-MLMAcc=0.621399,	MVRCAccuracy=0.667922,	MLMLossWVC=1.836643,	MVRCLoss=2.460997,	
Rank[  2]Epoch[5] Batch [5200]	Speed: 27.59 samples/s ETA: 1 d  7 h 36 m	Data: 0.037 Tran: 0.007 F: 0.149 B: 0.296 O: 1.823 M: 0.007	Train-MLMAcc=0.621419,	MVRCAccuracy=0.667941,	MLMLossWVC=1.836508,	MVRCLoss=2.460845,	
Rank[  0]Epoch[5] Batch [5200]	Speed: 27.59 samples/s ETA: 1 d  7 h 36 m	Data: 1.242 Tran: 0.007 F: 0.150 B: 0.292 O: 0.622 M: 0.005	Train-MLMAcc=0.621419,	MVRCAccuracy=0.667941,	MLMLossWVC=1.836508,	MVRCLoss=2.460845,	
Rank[  3]Epoch[5] Batch [5200]	Speed: 27.59 samples/s ETA: 1 d  7 h 36 m	Data: 0.577 Tran: 0.006 F: 0.149 B: 0.297 O: 1.284 M: 0.006	Train-MLMAcc=0.621419,	MVRCAccuracy=0.667941,	MLMLossWVC=1.836508,	MVRCLoss=2.460845,	
Rank[  1]Epoch[5] Batch [5200]	Speed: 27.59 samples/s ETA: 1 d  7 h 36 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.298 O: 1.850 M: 0.006	Train-MLMAcc=0.621419,	MVRCAccuracy=0.667941,	MLMLossWVC=1.836508,	MVRCLoss=2.460845,	
Rank[  1]Epoch[5] Batch [5300]	Speed: 27.62 samples/s ETA: 1 d  7 h 30 m	Data: 0.013 Tran: 0.007 F: 0.166 B: 0.308 O: 1.803 M: 0.018	Train-MLMAcc=0.621509,	MVRCAccuracy=0.667991,	MLMLossWVC=1.836239,	MVRCLoss=2.460720,	
Rank[  3]Epoch[5] Batch [5300]	Speed: 27.62 samples/s ETA: 1 d  7 h 30 m	Data: 1.222 Tran: 0.007 F: 0.159 B: 0.311 O: 0.599 M: 0.019	Train-MLMAcc=0.621509,	MVRCAccuracy=0.667991,	MLMLossWVC=1.836239,	MVRCLoss=2.460720,	
Rank[  2]Epoch[5] Batch [5300]	Speed: 27.62 samples/s ETA: 1 d  7 h 30 m	Data: 0.238 Tran: 0.007 F: 0.166 B: 0.309 O: 1.576 M: 0.018	Train-MLMAcc=0.621509,	MVRCAccuracy=0.667991,	MLMLossWVC=1.836239,	MVRCLoss=2.460720,	
Rank[  0]Epoch[5] Batch [5300]	Speed: 27.62 samples/s ETA: 1 d  7 h 30 m	Data: 0.534 Tran: 0.008 F: 0.172 B: 0.299 O: 1.284 M: 0.018	Train-MLMAcc=0.621509,	MVRCAccuracy=0.667991,	MLMLossWVC=1.836239,	MVRCLoss=2.460720,	
Rank[  2]Epoch[5] Batch [5400]	Speed: 27.42 samples/s ETA: 1 d  7 h 40 m	Data: 0.451 Tran: 0.007 F: 0.150 B: 0.297 O: 1.422 M: 0.007	Train-MLMAcc=0.621481,	MVRCAccuracy=0.668016,	MLMLossWVC=1.836625,	MVRCLoss=2.460643,	
Rank[  3]Epoch[5] Batch [5400]	Speed: 27.42 samples/s ETA: 1 d  7 h 40 m	Data: 1.804 Tran: 0.006 F: 0.150 B: 0.296 O: 0.069 M: 0.007	Train-MLMAcc=0.621481,	MVRCAccuracy=0.668016,	MLMLossWVC=1.836625,	MVRCLoss=2.460643,	
Rank[  1]Epoch[5] Batch [5400]	Speed: 27.42 samples/s ETA: 1 d  7 h 40 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.866 M: 0.006	Train-MLMAcc=0.621481,	MVRCAccuracy=0.668016,	MLMLossWVC=1.836625,	MVRCLoss=2.460643,	
Rank[  0]Epoch[5] Batch [5400]	Speed: 27.42 samples/s ETA: 1 d  7 h 40 m	Data: 0.027 Tran: 0.007 F: 0.149 B: 0.291 O: 1.851 M: 0.008	Train-MLMAcc=0.621481,	MVRCAccuracy=0.668016,	MLMLossWVC=1.836625,	MVRCLoss=2.460643,	
Rank[  3]Epoch[5] Batch [5500]	Speed: 28.26 samples/s ETA: 1 d  6 h 40 m	Data: 1.441 Tran: 0.006 F: 0.150 B: 0.298 O: 0.360 M: 0.009	Train-MLMAcc=0.621509,	MVRCAccuracy=0.668071,	MLMLossWVC=1.836299,	MVRCLoss=2.460483,	
Rank[  0]Epoch[5] Batch [5500]	Speed: 28.26 samples/s ETA: 1 d  6 h 40 m	Data: 0.081 Tran: 0.007 F: 0.150 B: 0.293 O: 1.727 M: 0.007	Train-MLMAcc=0.621509,	MVRCAccuracy=0.668071,	MLMLossWVC=1.836299,	MVRCLoss=2.460483,	
Rank[  1]Epoch[5] Batch [5500]	Speed: 28.26 samples/s ETA: 1 d  6 h 40 m	Data: 0.173 Tran: 0.007 F: 0.150 B: 0.298 O: 1.628 M: 0.008	Train-MLMAcc=0.621509,	MVRCAccuracy=0.668071,	MLMLossWVC=1.836299,	MVRCLoss=2.460483,	
Rank[  2]Epoch[5] Batch [5500]	Speed: 28.26 samples/s ETA: 1 d  6 h 40 m	Data: 0.777 Tran: 0.007 F: 0.150 B: 0.298 O: 1.025 M: 0.008	Train-MLMAcc=0.621509,	MVRCAccuracy=0.668071,	MLMLossWVC=1.836299,	MVRCLoss=2.460483,	
Rank[  3]Epoch[5] Batch [5600]	Speed: 26.48 samples/s ETA: 1 d  8 h 39 m	Data: 1.065 Tran: 0.007 F: 0.170 B: 0.317 O: 0.841 M: 0.013	Train-MLMAcc=0.621509,	MVRCAccuracy=0.668065,	MLMLossWVC=1.836408,	MVRCLoss=2.460500,	
Rank[  1]Epoch[5] Batch [5600]	Speed: 26.48 samples/s ETA: 1 d  8 h 39 m	Data: 0.010 Tran: 0.007 F: 0.160 B: 0.315 O: 1.909 M: 0.013	Train-MLMAcc=0.621509,	MVRCAccuracy=0.668065,	MLMLossWVC=1.836408,	MVRCLoss=2.460500,	
Rank[  0]Epoch[5] Batch [5600]	Speed: 26.48 samples/s ETA: 1 d  8 h 39 m	Data: 0.120 Tran: 0.007 F: 0.162 B: 0.314 O: 1.800 M: 0.011	Train-MLMAcc=0.621509,	MVRCAccuracy=0.668065,	MLMLossWVC=1.836408,	MVRCLoss=2.460500,	
Rank[  2]Epoch[5] Batch [5600]	Speed: 26.48 samples/s ETA: 1 d  8 h 39 m	Data: 0.903 Tran: 0.007 F: 0.179 B: 0.327 O: 0.984 M: 0.013	Train-MLMAcc=0.621509,	MVRCAccuracy=0.668065,	MLMLossWVC=1.836408,	MVRCLoss=2.460500,	
Rank[  3]Epoch[5] Batch [5700]	Speed: 28.01 samples/s ETA: 1 d  6 h 49 m	Data: 0.034 Tran: 0.007 F: 0.150 B: 0.298 O: 1.789 M: 0.006	Train-MLMAcc=0.621573,	MVRCAccuracy=0.668096,	MLMLossWVC=1.836054,	MVRCLoss=2.460419,	
Rank[  2]Epoch[5] Batch [5700]	Speed: 28.01 samples/s ETA: 1 d  6 h 49 m	Data: 1.740 Tran: 0.006 F: 0.151 B: 0.299 O: 0.083 M: 0.006	Train-MLMAcc=0.621573,	MVRCAccuracy=0.668096,	MLMLossWVC=1.836054,	MVRCLoss=2.460419,	
Rank[  0]Epoch[5] Batch [5700]	Speed: 28.01 samples/s ETA: 1 d  6 h 49 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.820 M: 0.006	Train-MLMAcc=0.621573,	MVRCAccuracy=0.668096,	MLMLossWVC=1.836054,	MVRCLoss=2.460419,	
Rank[  1]Epoch[5] Batch [5700]	Speed: 28.01 samples/s ETA: 1 d  6 h 49 m	Data: 0.187 Tran: 0.007 F: 0.150 B: 0.297 O: 1.638 M: 0.006	Train-MLMAcc=0.621573,	MVRCAccuracy=0.668096,	MLMLossWVC=1.836054,	MVRCLoss=2.460419,	
Rank[  2]Epoch[5] Batch [5800]	Speed: 27.92 samples/s ETA: 1 d  6 h 51 m	Data: 1.544 Tran: 0.006 F: 0.150 B: 0.297 O: 0.287 M: 0.007	Train-MLMAcc=0.621605,	MVRCAccuracy=0.668081,	MLMLossWVC=1.835746,	MVRCLoss=2.460330,	
Rank[  3]Epoch[5] Batch [5800]	Speed: 27.92 samples/s ETA: 1 d  6 h 51 m	Data: 0.014 Tran: 0.007 F: 0.150 B: 0.300 O: 1.813 M: 0.007	Train-MLMAcc=0.621605,	MVRCAccuracy=0.668081,	MLMLossWVC=1.835746,	MVRCLoss=2.460330,	
Rank[  1]Epoch[5] Batch [5800]	Speed: 27.92 samples/s ETA: 1 d  6 h 51 m	Data: 0.403 Tran: 0.007 F: 0.150 B: 0.296 O: 1.428 M: 0.007	Train-MLMAcc=0.621605,	MVRCAccuracy=0.668081,	MLMLossWVC=1.835746,	MVRCLoss=2.460330,	
Rank[  0]Epoch[5] Batch [5800]	Speed: 27.92 samples/s ETA: 1 d  6 h 51 m	Data: 0.020 Tran: 0.007 F: 0.150 B: 0.293 O: 1.815 M: 0.006	Train-MLMAcc=0.621605,	MVRCAccuracy=0.668081,	MLMLossWVC=1.835746,	MVRCLoss=2.460330,	
Rank[  2]Epoch[5] Batch [5900]	Speed: 28.04 samples/s ETA: 1 d  6 h 39 m	Data: 1.756 Tran: 0.006 F: 0.150 B: 0.297 O: 0.061 M: 0.011	Train-MLMAcc=0.621619,	MVRCAccuracy=0.668133,	MLMLossWVC=1.835451,	MVRCLoss=2.460239,	
Rank[  1]Epoch[5] Batch [5900]	Speed: 28.04 samples/s ETA: 1 d  6 h 39 m	Data: 0.180 Tran: 0.007 F: 0.150 B: 0.295 O: 1.643 M: 0.007	Train-MLMAcc=0.621619,	MVRCAccuracy=0.668133,	MLMLossWVC=1.835451,	MVRCLoss=2.460239,	
Rank[  3]Epoch[5] Batch [5900]	Speed: 28.04 samples/s ETA: 1 d  6 h 39 m	Data: 0.011 Tran: 0.007 F: 0.150 B: 0.298 O: 1.807 M: 0.008	Train-MLMAcc=0.621619,	MVRCAccuracy=0.668133,	MLMLossWVC=1.835451,	MVRCLoss=2.460239,	
Rank[  0]Epoch[5] Batch [5900]	Speed: 28.04 samples/s ETA: 1 d  6 h 39 m	Data: 0.140 Tran: 0.007 F: 0.150 B: 0.294 O: 1.682 M: 0.010	Train-MLMAcc=0.621619,	MVRCAccuracy=0.668133,	MLMLossWVC=1.835451,	MVRCLoss=2.460239,	
Rank[  1]Epoch[5] Batch [6000]	Speed: 27.95 samples/s ETA: 1 d  6 h 41 m	Data: 0.247 Tran: 0.007 F: 0.149 B: 0.295 O: 1.581 M: 0.010	Train-MLMAcc=0.621574,	MVRCAccuracy=0.668148,	MLMLossWVC=1.835740,	MVRCLoss=2.460192,	
Rank[  0]Epoch[5] Batch [6000]	Speed: 27.95 samples/s ETA: 1 d  6 h 41 m	Data: 0.075 Tran: 0.007 F: 0.149 B: 0.292 O: 1.756 M: 0.010	Train-MLMAcc=0.621574,	MVRCAccuracy=0.668148,	MLMLossWVC=1.835740,	MVRCLoss=2.460192,	
Rank[  2]Epoch[5] Batch [6000]	Speed: 27.95 samples/s ETA: 1 d  6 h 41 m	Data: 1.761 Tran: 0.006 F: 0.150 B: 0.297 O: 0.065 M: 0.010	Train-MLMAcc=0.621574,	MVRCAccuracy=0.668148,	MLMLossWVC=1.835740,	MVRCLoss=2.460192,	
Rank[  3]Epoch[5] Batch [6000]	Speed: 27.95 samples/s ETA: 1 d  6 h 41 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.299 O: 1.820 M: 0.005	Train-MLMAcc=0.621574,	MVRCAccuracy=0.668148,	MLMLossWVC=1.835740,	MVRCLoss=2.460192,	
Rank[  1]Epoch[5] Batch [6100]	Speed: 26.70 samples/s ETA: 1 d  8 h  3 m	Data: 0.010 Tran: 0.007 F: 0.155 B: 0.305 O: 1.907 M: 0.011	Train-MLMAcc=0.621581,	MVRCAccuracy=0.668148,	MLMLossWVC=1.835468,	MVRCLoss=2.460174,	
Rank[  3]Epoch[5] Batch [6100]	Speed: 26.70 samples/s ETA: 1 d  8 h  3 m	Data: 0.017 Tran: 0.007 F: 0.156 B: 0.308 O: 1.898 M: 0.009	Train-MLMAcc=0.621581,	MVRCAccuracy=0.668148,	MLMLossWVC=1.835468,	MVRCLoss=2.460174,	
Rank[  0]Epoch[5] Batch [6100]	Speed: 26.70 samples/s ETA: 1 d  8 h  3 m	Data: 0.151 Tran: 0.007 F: 0.155 B: 0.297 O: 1.775 M: 0.011	Train-MLMAcc=0.621581,	MVRCAccuracy=0.668148,	MLMLossWVC=1.835468,	MVRCLoss=2.460174,	
Rank[  2]Epoch[5] Batch [6100]	Speed: 26.70 samples/s ETA: 1 d  8 h  3 m	Data: 1.768 Tran: 0.014 F: 0.179 B: 0.322 O: 0.101 M: 0.011	Train-MLMAcc=0.621581,	MVRCAccuracy=0.668148,	MLMLossWVC=1.835468,	MVRCLoss=2.460174,	
Rank[  2]Epoch[5] Batch [6200]	Speed: 27.53 samples/s ETA: 1 d  7 h  1 m	Data: 1.799 Tran: 0.007 F: 0.151 B: 0.296 O: 0.066 M: 0.005	Train-MLMAcc=0.621581,	MVRCAccuracy=0.668154,	MLMLossWVC=1.835369,	MVRCLoss=2.460070,	
Rank[  3]Epoch[5] Batch [6200]	Speed: 27.53 samples/s ETA: 1 d  7 h  1 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 1.855 M: 0.007	Train-MLMAcc=0.621581,	MVRCAccuracy=0.668154,	MLMLossWVC=1.835369,	MVRCLoss=2.460070,	
Rank[  0]Epoch[5] Batch [6200]	Speed: 27.53 samples/s ETA: 1 d  7 h  1 m	Data: 0.112 Tran: 0.007 F: 0.149 B: 0.291 O: 1.758 M: 0.007	Train-MLMAcc=0.621581,	MVRCAccuracy=0.668154,	MLMLossWVC=1.835369,	MVRCLoss=2.460070,	
Rank[  1]Epoch[5] Batch [6200]	Speed: 27.53 samples/s ETA: 1 d  7 h  1 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.856 M: 0.007	Train-MLMAcc=0.621581,	MVRCAccuracy=0.668154,	MLMLossWVC=1.835369,	MVRCLoss=2.460070,	
Rank[  2]Epoch[5] Batch [6300]	Speed: 27.73 samples/s ETA: 1 d  6 h 44 m	Data: 0.963 Tran: 0.007 F: 0.151 B: 0.298 O: 0.878 M: 0.010	Train-MLMAcc=0.621563,	MVRCAccuracy=0.668176,	MLMLossWVC=1.835235,	MVRCLoss=2.459977,	
Rank[  3]Epoch[5] Batch [6300]	Speed: 27.73 samples/s ETA: 1 d  6 h 44 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.299 O: 1.835 M: 0.007	Train-MLMAcc=0.621563,	MVRCAccuracy=0.668176,	MLMLossWVC=1.835235,	MVRCLoss=2.459977,	
Rank[  0]Epoch[5] Batch [6300]	Speed: 27.73 samples/s ETA: 1 d  6 h 44 m	Data: 0.928 Tran: 0.007 F: 0.150 B: 0.292 O: 0.918 M: 0.011	Train-MLMAcc=0.621563,	MVRCAccuracy=0.668176,	MLMLossWVC=1.835235,	MVRCLoss=2.459977,	
Rank[  1]Epoch[5] Batch [6300]	Speed: 27.73 samples/s ETA: 1 d  6 h 44 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.835 M: 0.010	Train-MLMAcc=0.621563,	MVRCAccuracy=0.668176,	MLMLossWVC=1.835235,	MVRCLoss=2.459977,	
Rank[  0]Epoch[5] Batch [6400]	Speed: 27.62 samples/s ETA: 1 d  6 h 48 m	Data: 0.348 Tran: 0.007 F: 0.150 B: 0.294 O: 1.511 M: 0.007	Train-MLMAcc=0.621514,	MVRCAccuracy=0.668209,	MLMLossWVC=1.835262,	MVRCLoss=2.459911,	
Rank[  3]Epoch[5] Batch [6400]	Speed: 27.62 samples/s ETA: 1 d  6 h 48 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.850 M: 0.006	Train-MLMAcc=0.621514,	MVRCAccuracy=0.668209,	MLMLossWVC=1.835262,	MVRCLoss=2.459911,	
Rank[  1]Epoch[5] Batch [6400]	Speed: 27.62 samples/s ETA: 1 d  6 h 48 m	Data: 0.158 Tran: 0.007 F: 0.150 B: 0.294 O: 1.700 M: 0.007	Train-MLMAcc=0.621514,	MVRCAccuracy=0.668209,	MLMLossWVC=1.835262,	MVRCLoss=2.459911,	
Rank[  2]Epoch[5] Batch [6400]	Speed: 27.62 samples/s ETA: 1 d  6 h 48 m	Data: 1.565 Tran: 0.007 F: 0.150 B: 0.296 O: 0.291 M: 0.007	Train-MLMAcc=0.621514,	MVRCAccuracy=0.668209,	MLMLossWVC=1.835262,	MVRCLoss=2.459911,	
Rank[  0]Epoch[5] Batch [6500]	Speed: 28.03 samples/s ETA: 1 d  6 h 17 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.820 M: 0.007	Train-MLMAcc=0.621525,	MVRCAccuracy=0.668239,	MLMLossWVC=1.835124,	MVRCLoss=2.459880,	
Rank[  2]Epoch[5] Batch [6500]	Speed: 28.03 samples/s ETA: 1 d  6 h 17 m	Data: 1.769 Tran: 0.007 F: 0.149 B: 0.293 O: 0.057 M: 0.007	Train-MLMAcc=0.621525,	MVRCAccuracy=0.668239,	MLMLossWVC=1.835124,	MVRCLoss=2.459880,	
Rank[  3]Epoch[5] Batch [6500]	Speed: 28.03 samples/s ETA: 1 d  6 h 17 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.299 O: 1.812 M: 0.005	Train-MLMAcc=0.621525,	MVRCAccuracy=0.668239,	MLMLossWVC=1.835124,	MVRCLoss=2.459880,	
Rank[  1]Epoch[5] Batch [6500]	Speed: 28.03 samples/s ETA: 1 d  6 h 17 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.295 O: 1.815 M: 0.007	Train-MLMAcc=0.621525,	MVRCAccuracy=0.668239,	MLMLossWVC=1.835124,	MVRCLoss=2.459880,	
Rank[  3]Epoch[5] Batch [6600]	Speed: 27.78 samples/s ETA: 1 d  6 h 29 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.837 M: 0.006	Train-MLMAcc=0.621500,	MVRCAccuracy=0.668259,	MLMLossWVC=1.835269,	MVRCLoss=2.459845,	
Rank[  2]Epoch[5] Batch [6600]	Speed: 27.78 samples/s ETA: 1 d  6 h 29 m	Data: 1.751 Tran: 0.007 F: 0.150 B: 0.295 O: 0.093 M: 0.008	Train-MLMAcc=0.621500,	MVRCAccuracy=0.668259,	MLMLossWVC=1.835269,	MVRCLoss=2.459845,	
Rank[  0]Epoch[5] Batch [6600]	Speed: 27.78 samples/s ETA: 1 d  6 h 29 m	Data: 0.049 Tran: 0.007 F: 0.150 B: 0.291 O: 1.799 M: 0.007	Train-MLMAcc=0.621500,	MVRCAccuracy=0.668259,	MLMLossWVC=1.835269,	MVRCLoss=2.459845,	
Rank[  1]Epoch[5] Batch [6600]	Speed: 27.78 samples/s ETA: 1 d  6 h 29 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.838 M: 0.007	Train-MLMAcc=0.621500,	MVRCAccuracy=0.668259,	MLMLossWVC=1.835269,	MVRCLoss=2.459845,	
Rank[  2]Epoch[5] Batch [6700]	Speed: 27.75 samples/s ETA: 1 d  6 h 27 m	Data: 1.789 Tran: 0.007 F: 0.150 B: 0.295 O: 0.056 M: 0.009	Train-MLMAcc=0.621534,	MVRCAccuracy=0.668298,	MLMLossWVC=1.835043,	MVRCLoss=2.459769,	
Rank[  1]Epoch[5] Batch [6700]	Speed: 27.75 samples/s ETA: 1 d  6 h 27 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.292 O: 1.843 M: 0.005	Train-MLMAcc=0.621534,	MVRCAccuracy=0.668298,	MLMLossWVC=1.835043,	MVRCLoss=2.459769,	
Rank[  0]Epoch[5] Batch [6700]	Speed: 27.75 samples/s ETA: 1 d  6 h 27 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.840 M: 0.009	Train-MLMAcc=0.621534,	MVRCAccuracy=0.668298,	MLMLossWVC=1.835043,	MVRCLoss=2.459769,	
Rank[  3]Epoch[5] Batch [6700]	Speed: 27.75 samples/s ETA: 1 d  6 h 27 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.833 M: 0.009	Train-MLMAcc=0.621534,	MVRCAccuracy=0.668298,	MLMLossWVC=1.835043,	MVRCLoss=2.459769,	
Rank[  2]Epoch[5] Batch [6800]	Speed: 27.89 samples/s ETA: 1 d  6 h 15 m	Data: 1.781 Tran: 0.006 F: 0.150 B: 0.296 O: 0.054 M: 0.007	Train-MLMAcc=0.621553,	MVRCAccuracy=0.668323,	MLMLossWVC=1.835109,	MVRCLoss=2.459786,	
Rank[  3]Epoch[5] Batch [6800]	Speed: 27.89 samples/s ETA: 1 d  6 h 15 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.827 M: 0.005	Train-MLMAcc=0.621553,	MVRCAccuracy=0.668323,	MLMLossWVC=1.835109,	MVRCLoss=2.459786,	
Rank[  0]Epoch[5] Batch [6800]	Speed: 27.89 samples/s ETA: 1 d  6 h 15 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.292 O: 1.832 M: 0.007	Train-MLMAcc=0.621553,	MVRCAccuracy=0.668323,	MLMLossWVC=1.835109,	MVRCLoss=2.459786,	
Rank[  1]Epoch[5] Batch [6800]	Speed: 27.89 samples/s ETA: 1 d  6 h 15 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.827 M: 0.007	Train-MLMAcc=0.621553,	MVRCAccuracy=0.668323,	MLMLossWVC=1.835109,	MVRCLoss=2.459786,	
Rank[  0]Epoch[5] Batch [6900]	Speed: 27.71 samples/s ETA: 1 d  6 h 22 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.290 O: 1.847 M: 0.007	Train-MLMAcc=0.621570,	MVRCAccuracy=0.668323,	MLMLossWVC=1.835193,	MVRCLoss=2.459761,	
Rank[  1]Epoch[5] Batch [6900]	Speed: 27.71 samples/s ETA: 1 d  6 h 22 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.841 M: 0.009	Train-MLMAcc=0.621570,	MVRCAccuracy=0.668323,	MLMLossWVC=1.835193,	MVRCLoss=2.459761,	
Rank[  2]Epoch[5] Batch [6900]	Speed: 27.71 samples/s ETA: 1 d  6 h 22 m	Data: 1.795 Tran: 0.007 F: 0.151 B: 0.297 O: 0.050 M: 0.007	Train-MLMAcc=0.621570,	MVRCAccuracy=0.668323,	MLMLossWVC=1.835193,	MVRCLoss=2.459761,	
Rank[  3]Epoch[5] Batch [6900]	Speed: 27.71 samples/s ETA: 1 d  6 h 22 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.842 M: 0.005	Train-MLMAcc=0.621570,	MVRCAccuracy=0.668323,	MLMLossWVC=1.835193,	MVRCLoss=2.459761,	
Rank[  3]Epoch[5] Batch [7000]	Speed: 27.40 samples/s ETA: 1 d  6 h 39 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.867 M: 0.007	Train-MLMAcc=0.621608,	MVRCAccuracy=0.668355,	MLMLossWVC=1.834991,	MVRCLoss=2.459629,	
Rank[  1]Epoch[5] Batch [7000]	Speed: 27.40 samples/s ETA: 1 d  6 h 39 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.295 O: 1.867 M: 0.007	Train-MLMAcc=0.621608,	MVRCAccuracy=0.668355,	MLMLossWVC=1.834991,	MVRCLoss=2.459629,	
Rank[  0]Epoch[5] Batch [7000]	Speed: 27.40 samples/s ETA: 1 d  6 h 39 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.869 M: 0.008	Train-MLMAcc=0.621608,	MVRCAccuracy=0.668355,	MLMLossWVC=1.834991,	MVRCLoss=2.459629,	
Rank[  2]Epoch[5] Batch [7000]	Speed: 27.40 samples/s ETA: 1 d  6 h 39 m	Data: 1.820 Tran: 0.007 F: 0.150 B: 0.295 O: 0.054 M: 0.008	Train-MLMAcc=0.621608,	MVRCAccuracy=0.668355,	MLMLossWVC=1.834991,	MVRCLoss=2.459629,	
Rank[  3]Epoch[5] Batch [7100]	Speed: 28.07 samples/s ETA: 1 d  5 h 52 m	Data: 0.010 Tran: 0.007 F: 0.150 B: 0.297 O: 1.810 M: 0.006	Train-MLMAcc=0.621627,	MVRCAccuracy=0.668380,	MLMLossWVC=1.834805,	MVRCLoss=2.459633,	
Rank[  0]Epoch[5] Batch [7100]	Speed: 28.07 samples/s ETA: 1 d  5 h 52 m	Data: 0.090 Tran: 0.007 F: 0.149 B: 0.290 O: 1.737 M: 0.006	Train-MLMAcc=0.621627,	MVRCAccuracy=0.668380,	MLMLossWVC=1.834805,	MVRCLoss=2.459633,	
Rank[  1]Epoch[5] Batch [7100]	Speed: 28.07 samples/s ETA: 1 d  5 h 52 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.816 M: 0.007	Train-MLMAcc=0.621627,	MVRCAccuracy=0.668380,	MLMLossWVC=1.834805,	MVRCLoss=2.459633,	
Rank[  2]Epoch[5] Batch [7100]	Speed: 28.07 samples/s ETA: 1 d  5 h 52 m	Data: 1.766 Tran: 0.007 F: 0.151 B: 0.296 O: 0.053 M: 0.006	Train-MLMAcc=0.621627,	MVRCAccuracy=0.668380,	MLMLossWVC=1.834805,	MVRCLoss=2.459633,	
Rank[  3]Epoch[5] Batch [7200]	Speed: 27.51 samples/s ETA: 1 d  6 h 24 m	Data: 0.028 Tran: 0.007 F: 0.150 B: 0.295 O: 1.840 M: 0.005	Train-MLMAcc=0.621679,	MVRCAccuracy=0.668417,	MLMLossWVC=1.834594,	MVRCLoss=2.459492,	
Rank[  0]Epoch[5] Batch [7200]	Speed: 27.51 samples/s ETA: 1 d  6 h 24 m	Data: 0.330 Tran: 0.007 F: 0.150 B: 0.291 O: 1.540 M: 0.008	Train-MLMAcc=0.621679,	MVRCAccuracy=0.668417,	MLMLossWVC=1.834594,	MVRCLoss=2.459492,	
Rank[  1]Epoch[5] Batch [7200]	Speed: 27.51 samples/s ETA: 1 d  6 h 24 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.293 O: 1.862 M: 0.007	Train-MLMAcc=0.621679,	MVRCAccuracy=0.668417,	MLMLossWVC=1.834594,	MVRCLoss=2.459492,	
Rank[  2]Epoch[5] Batch [7200]	Speed: 27.51 samples/s ETA: 1 d  6 h 24 m	Data: 1.786 Tran: 0.007 F: 0.151 B: 0.296 O: 0.078 M: 0.007	Train-MLMAcc=0.621679,	MVRCAccuracy=0.668417,	MLMLossWVC=1.834594,	MVRCLoss=2.459492,	
Rank[  3]Epoch[5] Batch [7300]	Speed: 27.65 samples/s ETA: 1 d  6 h 11 m	Data: 0.109 Tran: 0.007 F: 0.150 B: 0.297 O: 1.745 M: 0.006	Train-MLMAcc=0.621682,	MVRCAccuracy=0.668450,	MLMLossWVC=1.834571,	MVRCLoss=2.459411,	
Rank[  2]Epoch[5] Batch [7300]	Speed: 27.65 samples/s ETA: 1 d  6 h 11 m	Data: 1.802 Tran: 0.007 F: 0.150 B: 0.294 O: 0.056 M: 0.006	Train-MLMAcc=0.621682,	MVRCAccuracy=0.668450,	MLMLossWVC=1.834571,	MVRCLoss=2.459411,	
Rank[  1]Epoch[5] Batch [7300]	Speed: 27.65 samples/s ETA: 1 d  6 h 11 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.845 M: 0.008	Train-MLMAcc=0.621682,	MVRCAccuracy=0.668450,	MLMLossWVC=1.834571,	MVRCLoss=2.459411,	
Rank[  0]Epoch[5] Batch [7300]	Speed: 27.65 samples/s ETA: 1 d  6 h 11 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.291 O: 1.852 M: 0.006	Train-MLMAcc=0.621682,	MVRCAccuracy=0.668450,	MLMLossWVC=1.834571,	MVRCLoss=2.459411,	
Rank[  0]Epoch[5] Batch [7400]	Speed: 27.60 samples/s ETA: 1 d  6 h 11 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.857 M: 0.005	Train-MLMAcc=0.621654,	MVRCAccuracy=0.668494,	MLMLossWVC=1.834841,	MVRCLoss=2.459266,	
Rank[  3]Epoch[5] Batch [7400]	Speed: 27.60 samples/s ETA: 1 d  6 h 11 m	Data: 0.012 Tran: 0.007 F: 0.150 B: 0.298 O: 1.844 M: 0.006	Train-MLMAcc=0.621654,	MVRCAccuracy=0.668494,	MLMLossWVC=1.834841,	MVRCLoss=2.459266,	
Rank[  2]Epoch[5] Batch [7400]	Speed: 27.60 samples/s ETA: 1 d  6 h 11 m	Data: 1.385 Tran: 0.007 F: 0.151 B: 0.297 O: 0.472 M: 0.007	Train-MLMAcc=0.621654,	MVRCAccuracy=0.668494,	MLMLossWVC=1.834841,	MVRCLoss=2.459266,	
Rank[  1]Epoch[5] Batch [7400]	Speed: 27.60 samples/s ETA: 1 d  6 h 11 m	Data: 0.428 Tran: 0.007 F: 0.150 B: 0.296 O: 1.430 M: 0.007	Train-MLMAcc=0.621654,	MVRCAccuracy=0.668494,	MLMLossWVC=1.834841,	MVRCLoss=2.459266,	
Rank[  3]Epoch[5] Batch [7500]	Speed: 28.02 samples/s ETA: 1 d  5 h 40 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.300 O: 1.814 M: 0.006	Train-MLMAcc=0.621738,	MVRCAccuracy=0.668498,	MLMLossWVC=1.834616,	MVRCLoss=2.459143,	
Rank[  2]Epoch[5] Batch [7500]	Speed: 28.02 samples/s ETA: 1 d  5 h 40 m	Data: 1.329 Tran: 0.007 F: 0.151 B: 0.298 O: 0.493 M: 0.007	Train-MLMAcc=0.621738,	MVRCAccuracy=0.668498,	MLMLossWVC=1.834616,	MVRCLoss=2.459143,	
Rank[  1]Epoch[5] Batch [7500]	Speed: 28.02 samples/s ETA: 1 d  5 h 40 m	Data: 0.451 Tran: 0.007 F: 0.149 B: 0.293 O: 1.378 M: 0.005	Train-MLMAcc=0.621738,	MVRCAccuracy=0.668498,	MLMLossWVC=1.834616,	MVRCLoss=2.459143,	
Rank[  0]Epoch[5] Batch [7500]	Speed: 28.02 samples/s ETA: 1 d  5 h 40 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.291 O: 1.822 M: 0.007	Train-MLMAcc=0.621738,	MVRCAccuracy=0.668498,	MLMLossWVC=1.834616,	MVRCLoss=2.459143,	
Rank[  2]Epoch[5] Batch [7600]	Speed: 27.58 samples/s ETA: 1 d  6 h  4 m	Data: 1.799 Tran: 0.007 F: 0.151 B: 0.296 O: 0.060 M: 0.007	Train-MLMAcc=0.621791,	MVRCAccuracy=0.668536,	MLMLossWVC=1.834417,	MVRCLoss=2.459030,	
Rank[  3]Epoch[5] Batch [7600]	Speed: 27.58 samples/s ETA: 1 d  6 h  4 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.849 M: 0.009	Train-MLMAcc=0.621791,	MVRCAccuracy=0.668536,	MLMLossWVC=1.834417,	MVRCLoss=2.459030,	
Rank[  0]Epoch[5] Batch [7600]	Speed: 27.58 samples/s ETA: 1 d  6 h  4 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.852 M: 0.011	Train-MLMAcc=0.621791,	MVRCAccuracy=0.668536,	MLMLossWVC=1.834417,	MVRCLoss=2.459030,	
Rank[  1]Epoch[5] Batch [7600]	Speed: 27.58 samples/s ETA: 1 d  6 h  4 m	Data: 0.010 Tran: 0.007 F: 0.150 B: 0.296 O: 1.846 M: 0.010	Train-MLMAcc=0.621791,	MVRCAccuracy=0.668536,	MLMLossWVC=1.834417,	MVRCLoss=2.459030,	
Rank[  3]Epoch[5] Batch [7700]	Speed: 27.70 samples/s ETA: 1 d  5 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.299 O: 1.841 M: 0.005	Train-MLMAcc=0.621722,	MVRCAccuracy=0.668541,	MLMLossWVC=1.834795,	MVRCLoss=2.459029,	
Rank[  2]Epoch[5] Batch [7700]	Speed: 27.70 samples/s ETA: 1 d  5 h 52 m	Data: 1.689 Tran: 0.007 F: 0.150 B: 0.294 O: 0.164 M: 0.005	Train-MLMAcc=0.621722,	MVRCAccuracy=0.668541,	MLMLossWVC=1.834795,	MVRCLoss=2.459029,	
Rank[  1]Epoch[5] Batch [7700]	Speed: 27.70 samples/s ETA: 1 d  5 h 52 m	Data: 0.118 Tran: 0.007 F: 0.150 B: 0.297 O: 1.733 M: 0.005	Train-MLMAcc=0.621722,	MVRCAccuracy=0.668541,	MLMLossWVC=1.834795,	MVRCLoss=2.459029,	
Rank[  0]Epoch[5] Batch [7700]	Speed: 27.70 samples/s ETA: 1 d  5 h 52 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.848 M: 0.004	Train-MLMAcc=0.621722,	MVRCAccuracy=0.668541,	MLMLossWVC=1.834795,	MVRCLoss=2.459029,	
Rank[  3]Epoch[5] Batch [7800]	Speed: 27.79 samples/s ETA: 1 d  5 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.832 M: 0.008	Train-MLMAcc=0.621670,	MVRCAccuracy=0.668538,	MLMLossWVC=1.834948,	MVRCLoss=2.459054,	
Rank[  1]Epoch[5] Batch [7800]	Speed: 27.79 samples/s ETA: 1 d  5 h 42 m	Data: 0.054 Tran: 0.007 F: 0.151 B: 0.296 O: 1.789 M: 0.005	Train-MLMAcc=0.621670,	MVRCAccuracy=0.668538,	MLMLossWVC=1.834948,	MVRCLoss=2.459054,	
Rank[  0]Epoch[5] Batch [7800]	Speed: 27.79 samples/s ETA: 1 d  5 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.838 M: 0.009	Train-MLMAcc=0.621670,	MVRCAccuracy=0.668538,	MLMLossWVC=1.834948,	MVRCLoss=2.459054,	
Rank[  2]Epoch[5] Batch [7800]	Speed: 27.79 samples/s ETA: 1 d  5 h 42 m	Data: 1.740 Tran: 0.007 F: 0.151 B: 0.298 O: 0.097 M: 0.008	Train-MLMAcc=0.621670,	MVRCAccuracy=0.668538,	MLMLossWVC=1.834948,	MVRCLoss=2.459054,	
Rank[  3]Epoch[5] Batch [7900]	Speed: 27.95 samples/s ETA: 1 d  5 h 29 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 1.821 M: 0.007	Train-MLMAcc=0.621685,	MVRCAccuracy=0.668573,	MLMLossWVC=1.834847,	MVRCLoss=2.458947,	
Rank[  1]Epoch[5] Batch [7900]	Speed: 27.95 samples/s ETA: 1 d  5 h 29 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.824 M: 0.005	Train-MLMAcc=0.621685,	MVRCAccuracy=0.668573,	MLMLossWVC=1.834847,	MVRCLoss=2.458947,	
Rank[  0]Epoch[5] Batch [7900]	Speed: 27.95 samples/s ETA: 1 d  5 h 29 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.293 O: 1.825 M: 0.007	Train-MLMAcc=0.621685,	MVRCAccuracy=0.668573,	MLMLossWVC=1.834847,	MVRCLoss=2.458947,	
Rank[  2]Epoch[5] Batch [7900]	Speed: 27.95 samples/s ETA: 1 d  5 h 29 m	Data: 1.776 Tran: 0.007 F: 0.151 B: 0.296 O: 0.054 M: 0.007	Train-MLMAcc=0.621685,	MVRCAccuracy=0.668573,	MLMLossWVC=1.834847,	MVRCLoss=2.458947,	
Rank[  3]Epoch[5] Batch [8000]	Speed: 28.02 samples/s ETA: 1 d  5 h 21 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.301 O: 1.811 M: 0.007	Train-MLMAcc=0.621730,	MVRCAccuracy=0.668614,	MLMLossWVC=1.834815,	MVRCLoss=2.458850,	
Rank[  0]Epoch[5] Batch [8000]	Speed: 28.02 samples/s ETA: 1 d  5 h 21 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.822 M: 0.007	Train-MLMAcc=0.621730,	MVRCAccuracy=0.668614,	MLMLossWVC=1.834815,	MVRCLoss=2.458850,	
Rank[  1]Epoch[5] Batch [8000]	Speed: 28.02 samples/s ETA: 1 d  5 h 21 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.294 O: 1.818 M: 0.006	Train-MLMAcc=0.621730,	MVRCAccuracy=0.668614,	MLMLossWVC=1.834815,	MVRCLoss=2.458850,	
Rank[  2]Epoch[5] Batch [8000]	Speed: 28.02 samples/s ETA: 1 d  5 h 21 m	Data: 1.771 Tran: 0.007 F: 0.150 B: 0.294 O: 0.055 M: 0.007	Train-MLMAcc=0.621730,	MVRCAccuracy=0.668614,	MLMLossWVC=1.834815,	MVRCLoss=2.458850,	
Rank[  2]Epoch[5] Batch [8100]	Speed: 26.94 samples/s ETA: 1 d  6 h 27 m	Data: 1.780 Tran: 0.010 F: 0.194 B: 0.315 O: 0.064 M: 0.012	Train-MLMAcc=0.621750,	MVRCAccuracy=0.668648,	MLMLossWVC=1.834741,	MVRCLoss=2.458731,	
Rank[  1]Epoch[5] Batch [8100]	Speed: 26.94 samples/s ETA: 1 d  6 h 27 m	Data: 0.009 Tran: 0.007 F: 0.163 B: 0.308 O: 1.875 M: 0.013	Train-MLMAcc=0.621750,	MVRCAccuracy=0.668648,	MLMLossWVC=1.834741,	MVRCLoss=2.458731,	
Rank[  3]Epoch[5] Batch [8100]	Speed: 26.94 samples/s ETA: 1 d  6 h 27 m	Data: 0.009 Tran: 0.007 F: 0.161 B: 0.313 O: 1.873 M: 0.011	Train-MLMAcc=0.621750,	MVRCAccuracy=0.668648,	MLMLossWVC=1.834741,	MVRCLoss=2.458731,	
Rank[  0]Epoch[5] Batch [8100]	Speed: 26.94 samples/s ETA: 1 d  6 h 27 m	Data: 0.010 Tran: 0.007 F: 0.161 B: 0.307 O: 1.879 M: 0.010	Train-MLMAcc=0.621750,	MVRCAccuracy=0.668648,	MLMLossWVC=1.834741,	MVRCLoss=2.458731,	
Rank[  2]Epoch[5] Batch [8200]	Speed: 27.75 samples/s ETA: 1 d  5 h 30 m	Data: 1.159 Tran: 0.007 F: 0.151 B: 0.295 O: 0.684 M: 0.010	Train-MLMAcc=0.621758,	MVRCAccuracy=0.668692,	MLMLossWVC=1.834594,	MVRCLoss=2.458695,	
Rank[  3]Epoch[5] Batch [8200]	Speed: 27.75 samples/s ETA: 1 d  5 h 30 m	Data: 0.471 Tran: 0.007 F: 0.151 B: 0.300 O: 1.370 M: 0.007	Train-MLMAcc=0.621758,	MVRCAccuracy=0.668692,	MLMLossWVC=1.834594,	MVRCLoss=2.458695,	
Rank[  0]Epoch[5] Batch [8200]	Speed: 27.75 samples/s ETA: 1 d  5 h 30 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.841 M: 0.007	Train-MLMAcc=0.621758,	MVRCAccuracy=0.668692,	MLMLossWVC=1.834594,	MVRCLoss=2.458695,	
Rank[  1]Epoch[5] Batch [8200]	Speed: 27.75 samples/s ETA: 1 d  5 h 30 m	Data: 0.181 Tran: 0.007 F: 0.150 B: 0.295 O: 1.663 M: 0.010	Train-MLMAcc=0.621758,	MVRCAccuracy=0.668692,	MLMLossWVC=1.834594,	MVRCLoss=2.458695,	
Rank[  0]Epoch[5] Batch [8300]	Speed: 25.64 samples/s ETA: 1 d  7 h 51 m	Data: 0.140 Tran: 0.007 F: 0.178 B: 0.327 O: 1.830 M: 0.012	Train-MLMAcc=0.621790,	MVRCAccuracy=0.668699,	MLMLossWVC=1.834391,	MVRCLoss=2.458628,	
Rank[  1]Epoch[5] Batch [8300]	Speed: 25.64 samples/s ETA: 1 d  7 h 51 m	Data: 0.009 Tran: 0.007 F: 0.185 B: 0.330 O: 1.949 M: 0.013	Train-MLMAcc=0.621790,	MVRCAccuracy=0.668699,	MLMLossWVC=1.834391,	MVRCLoss=2.458628,	
Rank[  3]Epoch[5] Batch [8300]	Speed: 25.64 samples/s ETA: 1 d  7 h 51 m	Data: 1.518 Tran: 0.010 F: 0.226 B: 0.345 O: 0.383 M: 0.013	Train-MLMAcc=0.621790,	MVRCAccuracy=0.668699,	MLMLossWVC=1.834391,	MVRCLoss=2.458628,	
Rank[  2]Epoch[5] Batch [8300]	Speed: 25.64 samples/s ETA: 1 d  7 h 51 m	Data: 0.268 Tran: 0.007 F: 0.192 B: 0.328 O: 1.687 M: 0.012	Train-MLMAcc=0.621790,	MVRCAccuracy=0.668699,	MLMLossWVC=1.834391,	MVRCLoss=2.458628,	
Rank[  3]Epoch[5] Batch [8400]	Speed: 28.03 samples/s ETA: 1 d  5 h  4 m	Data: 1.766 Tran: 0.007 F: 0.152 B: 0.297 O: 0.053 M: 0.009	Train-MLMAcc=0.621770,	MVRCAccuracy=0.668698,	MLMLossWVC=1.834738,	MVRCLoss=2.458632,	
Rank[  0]Epoch[5] Batch [8400]	Speed: 28.03 samples/s ETA: 1 d  5 h  4 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.817 M: 0.008	Train-MLMAcc=0.621770,	MVRCAccuracy=0.668698,	MLMLossWVC=1.834738,	MVRCLoss=2.458632,	
Rank[  2]Epoch[5] Batch [8400]	Speed: 28.03 samples/s ETA: 1 d  5 h  4 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.814 M: 0.007	Train-MLMAcc=0.621770,	MVRCAccuracy=0.668698,	MLMLossWVC=1.834738,	MVRCLoss=2.458632,	
Rank[  1]Epoch[5] Batch [8400]	Speed: 28.03 samples/s ETA: 1 d  5 h  4 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.813 M: 0.007	Train-MLMAcc=0.621770,	MVRCAccuracy=0.668698,	MLMLossWVC=1.834738,	MVRCLoss=2.458632,	
Rank[  3]Epoch[5] Batch [8500]	Speed: 28.17 samples/s ETA: 1 d  4 h 52 m	Data: 1.750 Tran: 0.007 F: 0.151 B: 0.297 O: 0.062 M: 0.005	Train-MLMAcc=0.621756,	MVRCAccuracy=0.668729,	MLMLossWVC=1.834669,	MVRCLoss=2.458576,	
Rank[  2]Epoch[5] Batch [8500]	Speed: 28.17 samples/s ETA: 1 d  4 h 52 m	Data: 0.033 Tran: 0.007 F: 0.150 B: 0.297 O: 1.778 M: 0.006	Train-MLMAcc=0.621756,	MVRCAccuracy=0.668729,	MLMLossWVC=1.834669,	MVRCLoss=2.458576,	
Rank[  0]Epoch[5] Batch [8500]	Speed: 28.17 samples/s ETA: 1 d  4 h 52 m	Data: 0.488 Tran: 0.007 F: 0.150 B: 0.292 O: 1.329 M: 0.006	Train-MLMAcc=0.621756,	MVRCAccuracy=0.668729,	MLMLossWVC=1.834669,	MVRCLoss=2.458576,	
Rank[  1]Epoch[5] Batch [8500]	Speed: 28.17 samples/s ETA: 1 d  4 h 52 m	Data: 0.011 Tran: 0.007 F: 0.150 B: 0.297 O: 1.801 M: 0.006	Train-MLMAcc=0.621756,	MVRCAccuracy=0.668729,	MLMLossWVC=1.834669,	MVRCLoss=2.458576,	
Rank[  2]Epoch[5] Batch [8600]	Speed: 28.14 samples/s ETA: 1 d  4 h 50 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.297 O: 1.806 M: 0.006	Train-MLMAcc=0.621771,	MVRCAccuracy=0.668746,	MLMLossWVC=1.834505,	MVRCLoss=2.458576,	
Rank[  3]Epoch[5] Batch [8600]	Speed: 28.14 samples/s ETA: 1 d  4 h 50 m	Data: 1.565 Tran: 0.006 F: 0.150 B: 0.296 O: 0.246 M: 0.010	Train-MLMAcc=0.621771,	MVRCAccuracy=0.668746,	MLMLossWVC=1.834505,	MVRCLoss=2.458576,	
Rank[  0]Epoch[5] Batch [8600]	Speed: 28.14 samples/s ETA: 1 d  4 h 50 m	Data: 0.419 Tran: 0.007 F: 0.151 B: 0.293 O: 1.397 M: 0.008	Train-MLMAcc=0.621771,	MVRCAccuracy=0.668746,	MLMLossWVC=1.834505,	MVRCLoss=2.458576,	
Rank[  1]Epoch[5] Batch [8600]	Speed: 28.14 samples/s ETA: 1 d  4 h 50 m	Data: 0.158 Tran: 0.007 F: 0.150 B: 0.298 O: 1.650 M: 0.011	Train-MLMAcc=0.621771,	MVRCAccuracy=0.668746,	MLMLossWVC=1.834505,	MVRCLoss=2.458576,	
Rank[  0]Epoch[5] Batch [8700]	Speed: 27.07 samples/s ETA: 1 d  5 h 55 m	Data: 0.505 Tran: 0.007 F: 0.161 B: 0.310 O: 1.369 M: 0.010	Train-MLMAcc=0.621769,	MVRCAccuracy=0.668781,	MLMLossWVC=1.834509,	MVRCLoss=2.458519,	
Rank[  1]Epoch[5] Batch [8700]	Speed: 27.07 samples/s ETA: 1 d  5 h 55 m	Data: 0.011 Tran: 0.008 F: 0.160 B: 0.314 O: 1.858 M: 0.012	Train-MLMAcc=0.621769,	MVRCAccuracy=0.668781,	MLMLossWVC=1.834509,	MVRCLoss=2.458519,	
Rank[  3]Epoch[5] Batch [8700]	Speed: 27.07 samples/s ETA: 1 d  5 h 55 m	Data: 1.413 Tran: 0.012 F: 0.205 B: 0.324 O: 0.399 M: 0.009	Train-MLMAcc=0.621769,	MVRCAccuracy=0.668781,	MLMLossWVC=1.834509,	MVRCLoss=2.458519,	
Rank[  2]Epoch[5] Batch [8700]	Speed: 27.07 samples/s ETA: 1 d  5 h 55 m	Data: 0.205 Tran: 0.008 F: 0.159 B: 0.309 O: 1.671 M: 0.011	Train-MLMAcc=0.621769,	MVRCAccuracy=0.668781,	MLMLossWVC=1.834509,	MVRCLoss=2.458519,	
Rank[  0]Epoch[5] Batch [8800]	Speed: 27.31 samples/s ETA: 1 d  5 h 35 m	Data: 0.265 Tran: 0.007 F: 0.150 B: 0.291 O: 1.625 M: 0.005	Train-MLMAcc=0.621822,	MVRCAccuracy=0.668776,	MLMLossWVC=1.834336,	MVRCLoss=2.458528,	
Rank[  1]Epoch[5] Batch [8800]	Speed: 27.31 samples/s ETA: 1 d  5 h 35 m	Data: 0.036 Tran: 0.007 F: 0.150 B: 0.295 O: 1.849 M: 0.006	Train-MLMAcc=0.621822,	MVRCAccuracy=0.668776,	MLMLossWVC=1.834336,	MVRCLoss=2.458528,	
Rank[  2]Epoch[5] Batch [8800]	Speed: 27.31 samples/s ETA: 1 d  5 h 35 m	Data: 0.346 Tran: 0.006 F: 0.150 B: 0.297 O: 1.537 M: 0.006	Train-MLMAcc=0.621822,	MVRCAccuracy=0.668776,	MLMLossWVC=1.834336,	MVRCLoss=2.458528,	
Rank[  3]Epoch[5] Batch [8800]	Speed: 27.31 samples/s ETA: 1 d  5 h 35 m	Data: 1.496 Tran: 0.007 F: 0.150 B: 0.298 O: 0.386 M: 0.006	Train-MLMAcc=0.621822,	MVRCAccuracy=0.668776,	MLMLossWVC=1.834336,	MVRCLoss=2.458528,	
Rank[  2]Epoch[5] Batch [8900]	Speed: 28.25 samples/s ETA: 1 d  4 h 32 m	Data: 0.761 Tran: 0.006 F: 0.151 B: 0.298 O: 1.043 M: 0.005	Train-MLMAcc=0.621847,	MVRCAccuracy=0.668796,	MLMLossWVC=1.834202,	MVRCLoss=2.458440,	
Rank[  3]Epoch[5] Batch [8900]	Speed: 28.25 samples/s ETA: 1 d  4 h 32 m	Data: 1.194 Tran: 0.006 F: 0.149 B: 0.295 O: 0.611 M: 0.008	Train-MLMAcc=0.621847,	MVRCAccuracy=0.668796,	MLMLossWVC=1.834202,	MVRCLoss=2.458440,	
Rank[  0]Epoch[5] Batch [8900]	Speed: 28.25 samples/s ETA: 1 d  4 h 32 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.291 O: 1.802 M: 0.009	Train-MLMAcc=0.621847,	MVRCAccuracy=0.668796,	MLMLossWVC=1.834202,	MVRCLoss=2.458440,	
Rank[  1]Epoch[5] Batch [8900]	Speed: 28.25 samples/s ETA: 1 d  4 h 32 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.795 M: 0.009	Train-MLMAcc=0.621847,	MVRCAccuracy=0.668796,	MLMLossWVC=1.834202,	MVRCLoss=2.458440,	
Rank[  2]Epoch[5] Batch [9000]	Speed: 28.07 samples/s ETA: 1 d  4 h 39 m	Data: 1.297 Tran: 0.006 F: 0.152 B: 0.299 O: 0.517 M: 0.008	Train-MLMAcc=0.621805,	MVRCAccuracy=0.668818,	MLMLossWVC=1.834300,	MVRCLoss=2.458416,	
Rank[  3]Epoch[5] Batch [9000]	Speed: 28.07 samples/s ETA: 1 d  4 h 39 m	Data: 0.902 Tran: 0.006 F: 0.150 B: 0.298 O: 0.913 M: 0.011	Train-MLMAcc=0.621805,	MVRCAccuracy=0.668818,	MLMLossWVC=1.834300,	MVRCLoss=2.458416,	
Rank[  1]Epoch[5] Batch [9000]	Speed: 28.07 samples/s ETA: 1 d  4 h 39 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.809 M: 0.011	Train-MLMAcc=0.621805,	MVRCAccuracy=0.668818,	MLMLossWVC=1.834300,	MVRCLoss=2.458416,	
Rank[  0]Epoch[5] Batch [9000]	Speed: 28.07 samples/s ETA: 1 d  4 h 39 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.812 M: 0.010	Train-MLMAcc=0.621805,	MVRCAccuracy=0.668818,	MLMLossWVC=1.834300,	MVRCLoss=2.458416,	
Rank[  2]Epoch[5] Batch [9100]	Speed: 28.13 samples/s ETA: 1 d  4 h 32 m	Data: 0.624 Tran: 0.006 F: 0.150 B: 0.297 O: 1.183 M: 0.013	Train-MLMAcc=0.621819,	MVRCAccuracy=0.668861,	MLMLossWVC=1.834023,	MVRCLoss=2.458406,	
Rank[  3]Epoch[5] Batch [9100]	Speed: 28.13 samples/s ETA: 1 d  4 h 32 m	Data: 1.500 Tran: 0.007 F: 0.151 B: 0.300 O: 0.303 M: 0.013	Train-MLMAcc=0.621819,	MVRCAccuracy=0.668861,	MLMLossWVC=1.834023,	MVRCLoss=2.458406,	
Rank[  1]Epoch[5] Batch [9100]	Speed: 28.13 samples/s ETA: 1 d  4 h 32 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.801 M: 0.013	Train-MLMAcc=0.621819,	MVRCAccuracy=0.668861,	MLMLossWVC=1.834023,	MVRCLoss=2.458406,	
Rank[  0]Epoch[5] Batch [9100]	Speed: 28.13 samples/s ETA: 1 d  4 h 32 m	Data: 0.106 Tran: 0.007 F: 0.150 B: 0.291 O: 1.711 M: 0.008	Train-MLMAcc=0.621819,	MVRCAccuracy=0.668861,	MLMLossWVC=1.834023,	MVRCLoss=2.458406,	
Rank[  3]Epoch[5] Batch [9200]	Speed: 27.50 samples/s ETA: 1 d  5 h  7 m	Data: 0.659 Tran: 0.007 F: 0.150 B: 0.298 O: 1.208 M: 0.005	Train-MLMAcc=0.621828,	MVRCAccuracy=0.668879,	MLMLossWVC=1.833815,	MVRCLoss=2.458400,	
Rank[  2]Epoch[5] Batch [9200]	Speed: 27.50 samples/s ETA: 1 d  5 h  7 m	Data: 1.201 Tran: 0.006 F: 0.150 B: 0.296 O: 0.667 M: 0.006	Train-MLMAcc=0.621828,	MVRCAccuracy=0.668879,	MLMLossWVC=1.833815,	MVRCLoss=2.458400,	
Rank[  0]Epoch[5] Batch [9200]	Speed: 27.50 samples/s ETA: 1 d  5 h  7 m	Data: 0.119 Tran: 0.007 F: 0.149 B: 0.291 O: 1.755 M: 0.006	Train-MLMAcc=0.621828,	MVRCAccuracy=0.668879,	MLMLossWVC=1.833815,	MVRCLoss=2.458400,	
Rank[  1]Epoch[5] Batch [9200]	Speed: 27.50 samples/s ETA: 1 d  5 h  7 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.859 M: 0.007	Train-MLMAcc=0.621828,	MVRCAccuracy=0.668879,	MLMLossWVC=1.833815,	MVRCLoss=2.458400,	
Rank[  0]Epoch[5] Batch [9300]	Speed: 25.67 samples/s ETA: 1 d  7 h  7 m	Data: 0.016 Tran: 0.007 F: 0.185 B: 0.341 O: 1.927 M: 0.014	Train-MLMAcc=0.621836,	MVRCAccuracy=0.668911,	MLMLossWVC=1.833865,	MVRCLoss=2.458314,	
Rank[  2]Epoch[5] Batch [9300]	Speed: 25.67 samples/s ETA: 1 d  7 h  7 m	Data: 1.803 Tran: 0.008 F: 0.200 B: 0.326 O: 0.140 M: 0.013	Train-MLMAcc=0.621836,	MVRCAccuracy=0.668911,	MLMLossWVC=1.833865,	MVRCLoss=2.458314,	
Rank[  3]Epoch[5] Batch [9300]	Speed: 25.67 samples/s ETA: 1 d  7 h  7 m	Data: 0.077 Tran: 0.007 F: 0.186 B: 0.348 O: 1.858 M: 0.013	Train-MLMAcc=0.621836,	MVRCAccuracy=0.668911,	MLMLossWVC=1.833865,	MVRCLoss=2.458314,	
Rank[  1]Epoch[5] Batch [9300]	Speed: 25.67 samples/s ETA: 1 d  7 h  7 m	Data: 0.010 Tran: 0.007 F: 0.187 B: 0.346 O: 1.926 M: 0.013	Train-MLMAcc=0.621836,	MVRCAccuracy=0.668911,	MLMLossWVC=1.833865,	MVRCLoss=2.458314,	
Rank[  2]Epoch[5] Batch [9400]	Speed: 28.12 samples/s ETA: 1 d  4 h 21 m	Data: 0.980 Tran: 0.006 F: 0.150 B: 0.297 O: 0.831 M: 0.010	Train-MLMAcc=0.621849,	MVRCAccuracy=0.668950,	MLMLossWVC=1.833640,	MVRCLoss=2.458230,	
Rank[  3]Epoch[5] Batch [9400]	Speed: 28.12 samples/s ETA: 1 d  4 h 21 m	Data: 0.789 Tran: 0.007 F: 0.150 B: 0.298 O: 1.021 M: 0.010	Train-MLMAcc=0.621849,	MVRCAccuracy=0.668950,	MLMLossWVC=1.833640,	MVRCLoss=2.458230,	
Rank[  1]Epoch[5] Batch [9400]	Speed: 28.12 samples/s ETA: 1 d  4 h 21 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.809 M: 0.006	Train-MLMAcc=0.621849,	MVRCAccuracy=0.668950,	MLMLossWVC=1.833640,	MVRCLoss=2.458230,	
Rank[  0]Epoch[5] Batch [9400]	Speed: 28.12 samples/s ETA: 1 d  4 h 21 m	Data: 0.054 Tran: 0.007 F: 0.150 B: 0.293 O: 1.761 M: 0.010	Train-MLMAcc=0.621849,	MVRCAccuracy=0.668950,	MLMLossWVC=1.833640,	MVRCLoss=2.458230,	
Rank[  0]Epoch[5] Batch [9500]	Speed: 27.93 samples/s ETA: 1 d  4 h 28 m	Data: 0.011 Tran: 0.007 F: 0.149 B: 0.292 O: 1.825 M: 0.006	Train-MLMAcc=0.621855,	MVRCAccuracy=0.668971,	MLMLossWVC=1.833763,	MVRCLoss=2.458121,	
Rank[  3]Epoch[5] Batch [9500]	Speed: 27.93 samples/s ETA: 1 d  4 h 28 m	Data: 1.767 Tran: 0.007 F: 0.151 B: 0.298 O: 0.062 M: 0.005	Train-MLMAcc=0.621855,	MVRCAccuracy=0.668971,	MLMLossWVC=1.833763,	MVRCLoss=2.458121,	
Rank[  2]Epoch[5] Batch [9500]	Speed: 27.93 samples/s ETA: 1 d  4 h 28 m	Data: 0.023 Tran: 0.007 F: 0.151 B: 0.299 O: 1.805 M: 0.005	Train-MLMAcc=0.621855,	MVRCAccuracy=0.668971,	MLMLossWVC=1.833763,	MVRCLoss=2.458121,	
Rank[  1]Epoch[5] Batch [9500]	Speed: 27.93 samples/s ETA: 1 d  4 h 28 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.826 M: 0.005	Train-MLMAcc=0.621855,	MVRCAccuracy=0.668971,	MLMLossWVC=1.833763,	MVRCLoss=2.458121,	
Rank[  1]Epoch[5] Batch [9600]	Speed: 27.15 samples/s ETA: 1 d  5 h 14 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.296 O: 1.886 M: 0.008	Train-MLMAcc=0.621874,	MVRCAccuracy=0.668994,	MLMLossWVC=1.833714,	MVRCLoss=2.458090,	
Rank[  2]Epoch[5] Batch [9600]	Speed: 27.15 samples/s ETA: 1 d  5 h 14 m	Data: 0.007 Tran: 0.007 F: 0.151 B: 0.296 O: 1.889 M: 0.006	Train-MLMAcc=0.621874,	MVRCAccuracy=0.668994,	MLMLossWVC=1.833714,	MVRCLoss=2.458090,	
Rank[  3]Epoch[5] Batch [9600]	Speed: 27.15 samples/s ETA: 1 d  5 h 14 m	Data: 1.820 Tran: 0.008 F: 0.166 B: 0.303 O: 0.052 M: 0.007	Train-MLMAcc=0.621874,	MVRCAccuracy=0.668994,	MLMLossWVC=1.833714,	MVRCLoss=2.458090,	
Rank[  0]Epoch[5] Batch [9600]	Speed: 27.15 samples/s ETA: 1 d  5 h 14 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.290 O: 1.894 M: 0.008	Train-MLMAcc=0.621874,	MVRCAccuracy=0.668994,	MLMLossWVC=1.833714,	MVRCLoss=2.458090,	
Rank[  3]Epoch[5] Batch [9700]	Speed: 28.14 samples/s ETA: 1 d  4 h  8 m	Data: 1.765 Tran: 0.007 F: 0.150 B: 0.297 O: 0.049 M: 0.006	Train-MLMAcc=0.621828,	MVRCAccuracy=0.669027,	MLMLossWVC=1.834041,	MVRCLoss=2.458037,	
Rank[  0]Epoch[5] Batch [9700]	Speed: 28.14 samples/s ETA: 1 d  4 h  8 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.809 M: 0.006	Train-MLMAcc=0.621828,	MVRCAccuracy=0.669027,	MLMLossWVC=1.834041,	MVRCLoss=2.458037,	
Rank[  1]Epoch[5] Batch [9700]	Speed: 28.14 samples/s ETA: 1 d  4 h  8 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.808 M: 0.006	Train-MLMAcc=0.621828,	MVRCAccuracy=0.669027,	MLMLossWVC=1.834041,	MVRCLoss=2.458037,	
Rank[  2]Epoch[5] Batch [9700]	Speed: 28.14 samples/s ETA: 1 d  4 h  8 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.808 M: 0.006	Train-MLMAcc=0.621828,	MVRCAccuracy=0.669027,	MLMLossWVC=1.834041,	MVRCLoss=2.458037,	
Rank[  1]Epoch[5] Batch [9800]	Speed: 24.51 samples/s ETA: 1 d  8 h 14 m	Data: 0.019 Tran: 0.008 F: 0.191 B: 0.369 O: 2.005 M: 0.015	Train-MLMAcc=0.621888,	MVRCAccuracy=0.669050,	MLMLossWVC=1.833917,	MVRCLoss=2.457971,	
Rank[  2]Epoch[5] Batch [9800]	Speed: 24.51 samples/s ETA: 1 d  8 h 14 m	Data: 0.017 Tran: 0.008 F: 0.195 B: 0.367 O: 2.005 M: 0.016	Train-MLMAcc=0.621888,	MVRCAccuracy=0.669050,	MLMLossWVC=1.833917,	MVRCLoss=2.457971,	
Rank[  3]Epoch[5] Batch [9800]	Speed: 24.51 samples/s ETA: 1 d  8 h 14 m	Data: 1.872 Tran: 0.012 F: 0.245 B: 0.390 O: 0.074 M: 0.016	Train-MLMAcc=0.621888,	MVRCAccuracy=0.669050,	MLMLossWVC=1.833917,	MVRCLoss=2.457971,	
Rank[  0]Epoch[5] Batch [9800]	Speed: 24.51 samples/s ETA: 1 d  8 h 14 m	Data: 0.018 Tran: 0.010 F: 0.193 B: 0.368 O: 2.003 M: 0.016	Train-MLMAcc=0.621888,	MVRCAccuracy=0.669050,	MLMLossWVC=1.833917,	MVRCLoss=2.457971,	
Rank[  3]Epoch[5] Batch [9900]	Speed: 28.16 samples/s ETA: 1 d  4 h  0 m	Data: 1.761 Tran: 0.007 F: 0.151 B: 0.298 O: 0.049 M: 0.006	Train-MLMAcc=0.621888,	MVRCAccuracy=0.669073,	MLMLossWVC=1.833867,	MVRCLoss=2.457926,	
Rank[  0]Epoch[5] Batch [9900]	Speed: 28.16 samples/s ETA: 1 d  4 h  0 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.807 M: 0.007	Train-MLMAcc=0.621888,	MVRCAccuracy=0.669073,	MLMLossWVC=1.833867,	MVRCLoss=2.457926,	
Rank[  1]Epoch[5] Batch [9900]	Speed: 28.16 samples/s ETA: 1 d  4 h  0 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.293 O: 1.808 M: 0.007	Train-MLMAcc=0.621888,	MVRCAccuracy=0.669073,	MLMLossWVC=1.833867,	MVRCLoss=2.457926,	
Rank[  2]Epoch[5] Batch [9900]	Speed: 28.16 samples/s ETA: 1 d  4 h  0 m	Data: 0.153 Tran: 0.007 F: 0.149 B: 0.296 O: 1.658 M: 0.008	Train-MLMAcc=0.621888,	MVRCAccuracy=0.669073,	MLMLossWVC=1.833867,	MVRCLoss=2.457926,	
Rank[  0]Epoch[5] Batch [10000]	Speed: 28.29 samples/s ETA: 1 d  3 h 48 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.293 O: 1.797 M: 0.007	Train-MLMAcc=0.621982,	MVRCAccuracy=0.669090,	MLMLossWVC=1.833451,	MVRCLoss=2.457911,	
Rank[  2]Epoch[5] Batch [10000]	Speed: 28.29 samples/s ETA: 1 d  3 h 48 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.299 O: 1.792 M: 0.005	Train-MLMAcc=0.621982,	MVRCAccuracy=0.669090,	MLMLossWVC=1.833451,	MVRCLoss=2.457911,	
Rank[  1]Epoch[5] Batch [10000]	Speed: 28.29 samples/s ETA: 1 d  3 h 48 m	Data: 0.019 Tran: 0.007 F: 0.150 B: 0.294 O: 1.785 M: 0.007	Train-MLMAcc=0.621982,	MVRCAccuracy=0.669090,	MLMLossWVC=1.833451,	MVRCLoss=2.457911,	
Rank[  3]Epoch[5] Batch [10000]	Speed: 28.29 samples/s ETA: 1 d  3 h 48 m	Data: 1.739 Tran: 0.007 F: 0.151 B: 0.298 O: 0.060 M: 0.007	Train-MLMAcc=0.621982,	MVRCAccuracy=0.669090,	MLMLossWVC=1.833451,	MVRCLoss=2.457911,	
Rank[  2]Epoch[5] Batch [10100]	Speed: 27.90 samples/s ETA: 1 d  4 h  8 m	Data: 0.049 Tran: 0.007 F: 0.149 B: 0.295 O: 1.788 M: 0.005	Train-MLMAcc=0.621963,	MVRCAccuracy=0.669118,	MLMLossWVC=1.833477,	MVRCLoss=2.457802,	
Rank[  0]Epoch[5] Batch [10100]	Speed: 27.90 samples/s ETA: 1 d  4 h  8 m	Data: 0.023 Tran: 0.007 F: 0.150 B: 0.294 O: 1.811 M: 0.007	Train-MLMAcc=0.621963,	MVRCAccuracy=0.669118,	MLMLossWVC=1.833477,	MVRCLoss=2.457802,	
Rank[  3]Epoch[5] Batch [10100]	Speed: 27.90 samples/s ETA: 1 d  4 h  8 m	Data: 1.472 Tran: 0.007 F: 0.151 B: 0.298 O: 0.358 M: 0.007	Train-MLMAcc=0.621963,	MVRCAccuracy=0.669118,	MLMLossWVC=1.833477,	MVRCLoss=2.457802,	
Rank[  1]Epoch[5] Batch [10100]	Speed: 27.90 samples/s ETA: 1 d  4 h  8 m	Data: 0.303 Tran: 0.007 F: 0.151 B: 0.296 O: 1.530 M: 0.007	Train-MLMAcc=0.621963,	MVRCAccuracy=0.669118,	MLMLossWVC=1.833477,	MVRCLoss=2.457802,	
Rank[  1]Epoch[5] Batch [10200]	Speed: 28.14 samples/s ETA: 1 d  3 h 50 m	Data: 0.177 Tran: 0.007 F: 0.151 B: 0.297 O: 1.636 M: 0.006	Train-MLMAcc=0.621966,	MVRCAccuracy=0.669162,	MLMLossWVC=1.833503,	MVRCLoss=2.457680,	
Rank[  0]Epoch[5] Batch [10200]	Speed: 28.14 samples/s ETA: 1 d  3 h 50 m	Data: 0.121 Tran: 0.007 F: 0.149 B: 0.290 O: 1.701 M: 0.006	Train-MLMAcc=0.621966,	MVRCAccuracy=0.669162,	MLMLossWVC=1.833503,	MVRCLoss=2.457680,	
Rank[  3]Epoch[5] Batch [10200]	Speed: 28.14 samples/s ETA: 1 d  3 h 50 m	Data: 1.314 Tran: 0.007 F: 0.151 B: 0.298 O: 0.498 M: 0.006	Train-MLMAcc=0.621966,	MVRCAccuracy=0.669162,	MLMLossWVC=1.833503,	MVRCLoss=2.457680,	
Rank[  2]Epoch[5] Batch [10200]	Speed: 28.14 samples/s ETA: 1 d  3 h 50 m	Data: 0.446 Tran: 0.007 F: 0.149 B: 0.295 O: 1.370 M: 0.007	Train-MLMAcc=0.621966,	MVRCAccuracy=0.669162,	MLMLossWVC=1.833503,	MVRCLoss=2.457680,	
Rank[  0]Epoch[5] Batch [10300]	Speed: 27.86 samples/s ETA: 1 d  4 h  2 m	Data: 0.221 Tran: 0.007 F: 0.150 B: 0.292 O: 1.621 M: 0.006	Train-MLMAcc=0.622008,	MVRCAccuracy=0.669198,	MLMLossWVC=1.833330,	MVRCLoss=2.457610,	
Rank[  1]Epoch[5] Batch [10300]	Speed: 27.86 samples/s ETA: 1 d  4 h  2 m	Data: 0.007 Tran: 0.007 F: 0.149 B: 0.295 O: 1.832 M: 0.006	Train-MLMAcc=0.622008,	MVRCAccuracy=0.669198,	MLMLossWVC=1.833330,	MVRCLoss=2.457610,	
Rank[  2]Epoch[5] Batch [10300]	Speed: 27.86 samples/s ETA: 1 d  4 h  2 m	Data: 0.943 Tran: 0.007 F: 0.151 B: 0.298 O: 0.892 M: 0.006	Train-MLMAcc=0.622008,	MVRCAccuracy=0.669198,	MLMLossWVC=1.833330,	MVRCLoss=2.457610,	
Rank[  3]Epoch[5] Batch [10300]	Speed: 27.86 samples/s ETA: 1 d  4 h  2 m	Data: 0.852 Tran: 0.007 F: 0.151 B: 0.299 O: 0.982 M: 0.006	Train-MLMAcc=0.622008,	MVRCAccuracy=0.669198,	MLMLossWVC=1.833330,	MVRCLoss=2.457610,	
Rank[  2]Epoch[5] Batch [10400]	Speed: 28.20 samples/s ETA: 1 d  3 h 39 m	Data: 0.923 Tran: 0.007 F: 0.150 B: 0.295 O: 0.887 M: 0.008	Train-MLMAcc=0.622024,	MVRCAccuracy=0.669234,	MLMLossWVC=1.833341,	MVRCLoss=2.457500,	
Rank[  0]Epoch[5] Batch [10400]	Speed: 28.20 samples/s ETA: 1 d  3 h 39 m	Data: 0.512 Tran: 0.007 F: 0.150 B: 0.292 O: 1.303 M: 0.006	Train-MLMAcc=0.622024,	MVRCAccuracy=0.669234,	MLMLossWVC=1.833341,	MVRCLoss=2.457500,	
Rank[  1]Epoch[5] Batch [10400]	Speed: 28.20 samples/s ETA: 1 d  3 h 39 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.802 M: 0.008	Train-MLMAcc=0.622024,	MVRCAccuracy=0.669234,	MLMLossWVC=1.833341,	MVRCLoss=2.457500,	
Rank[  3]Epoch[5] Batch [10400]	Speed: 28.20 samples/s ETA: 1 d  3 h 39 m	Data: 0.856 Tran: 0.007 F: 0.151 B: 0.299 O: 0.949 M: 0.007	Train-MLMAcc=0.622024,	MVRCAccuracy=0.669234,	MLMLossWVC=1.833341,	MVRCLoss=2.457500,	
Rank[  2]Epoch[5] Batch [10500]	Speed: 27.73 samples/s ETA: 1 d  4 h  2 m	Data: 0.472 Tran: 0.007 F: 0.150 B: 0.297 O: 1.373 M: 0.008	Train-MLMAcc=0.622051,	MVRCAccuracy=0.669269,	MLMLossWVC=1.833241,	MVRCLoss=2.457438,	
Rank[  3]Epoch[5] Batch [10500]	Speed: 27.73 samples/s ETA: 1 d  4 h  2 m	Data: 0.584 Tran: 0.007 F: 0.151 B: 0.297 O: 1.262 M: 0.006	Train-MLMAcc=0.622051,	MVRCAccuracy=0.669269,	MLMLossWVC=1.833241,	MVRCLoss=2.457438,	
Rank[  1]Epoch[5] Batch [10500]	Speed: 27.73 samples/s ETA: 1 d  4 h  2 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.294 O: 1.842 M: 0.007	Train-MLMAcc=0.622051,	MVRCAccuracy=0.669269,	MLMLossWVC=1.833241,	MVRCLoss=2.457438,	
Rank[  0]Epoch[5] Batch [10500]	Speed: 27.73 samples/s ETA: 1 d  4 h  2 m	Data: 1.414 Tran: 0.007 F: 0.150 B: 0.293 O: 0.437 M: 0.007	Train-MLMAcc=0.622051,	MVRCAccuracy=0.669269,	MLMLossWVC=1.833241,	MVRCLoss=2.457438,	
Rank[  1]Epoch[5] Batch [10600]	Speed: 27.81 samples/s ETA: 1 d  3 h 54 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.834 M: 0.006	Train-MLMAcc=0.622046,	MVRCAccuracy=0.669306,	MLMLossWVC=1.833242,	MVRCLoss=2.457401,	
Rank[  0]Epoch[5] Batch [10600]	Speed: 27.81 samples/s ETA: 1 d  3 h 54 m	Data: 0.108 Tran: 0.008 F: 0.150 B: 0.293 O: 1.733 M: 0.008	Train-MLMAcc=0.622046,	MVRCAccuracy=0.669306,	MLMLossWVC=1.833242,	MVRCLoss=2.457401,	
Rank[  2]Epoch[5] Batch [10600]	Speed: 27.81 samples/s ETA: 1 d  3 h 54 m	Data: 0.749 Tran: 0.007 F: 0.150 B: 0.296 O: 1.088 M: 0.009	Train-MLMAcc=0.622046,	MVRCAccuracy=0.669306,	MLMLossWVC=1.833242,	MVRCLoss=2.457401,	
Rank[  3]Epoch[5] Batch [10600]	Speed: 27.81 samples/s ETA: 1 d  3 h 54 m	Data: 1.060 Tran: 0.007 F: 0.151 B: 0.298 O: 0.777 M: 0.008	Train-MLMAcc=0.622046,	MVRCAccuracy=0.669306,	MLMLossWVC=1.833242,	MVRCLoss=2.457401,	
Rank[  0]Epoch[5] Batch [10700]	Speed: 27.22 samples/s ETA: 1 d  4 h 26 m	Data: 0.044 Tran: 0.007 F: 0.153 B: 0.301 O: 1.837 M: 0.008	Train-MLMAcc=0.622055,	MVRCAccuracy=0.669322,	MLMLossWVC=1.833069,	MVRCLoss=2.457394,	
Rank[  1]Epoch[5] Batch [10700]	Speed: 27.22 samples/s ETA: 1 d  4 h 26 m	Data: 0.009 Tran: 0.007 F: 0.154 B: 0.305 O: 1.867 M: 0.008	Train-MLMAcc=0.622055,	MVRCAccuracy=0.669322,	MLMLossWVC=1.833069,	MVRCLoss=2.457394,	
Rank[  2]Epoch[5] Batch [10700]	Speed: 27.22 samples/s ETA: 1 d  4 h 26 m	Data: 0.500 Tran: 0.007 F: 0.153 B: 0.301 O: 1.382 M: 0.008	Train-MLMAcc=0.622055,	MVRCAccuracy=0.669322,	MLMLossWVC=1.833069,	MVRCLoss=2.457394,	
Rank[  3]Epoch[5] Batch [10700]	Speed: 27.22 samples/s ETA: 1 d  4 h 26 m	Data: 1.261 Tran: 0.011 F: 0.181 B: 0.312 O: 0.576 M: 0.008	Train-MLMAcc=0.622055,	MVRCAccuracy=0.669322,	MLMLossWVC=1.833069,	MVRCLoss=2.457394,	
Rank[  0]Epoch[5] Batch [10800]	Speed: 28.00 samples/s ETA: 1 d  3 h 35 m	Data: 0.314 Tran: 0.007 F: 0.152 B: 0.297 O: 1.505 M: 0.009	Train-MLMAcc=0.622058,	MVRCAccuracy=0.669355,	MLMLossWVC=1.833101,	MVRCLoss=2.457312,	
Rank[  3]Epoch[5] Batch [10800]	Speed: 28.00 samples/s ETA: 1 d  3 h 35 m	Data: 1.460 Tran: 0.006 F: 0.163 B: 0.303 O: 0.343 M: 0.009	Train-MLMAcc=0.622058,	MVRCAccuracy=0.669355,	MLMLossWVC=1.833101,	MVRCLoss=2.457312,	
Rank[  1]Epoch[5] Batch [10800]	Speed: 28.00 samples/s ETA: 1 d  3 h 35 m	Data: 0.009 Tran: 0.007 F: 0.153 B: 0.304 O: 1.804 M: 0.007	Train-MLMAcc=0.622058,	MVRCAccuracy=0.669355,	MLMLossWVC=1.833101,	MVRCLoss=2.457312,	
Rank[  2]Epoch[5] Batch [10800]	Speed: 28.00 samples/s ETA: 1 d  3 h 35 m	Data: 0.331 Tran: 0.006 F: 0.153 B: 0.304 O: 1.481 M: 0.008	Train-MLMAcc=0.622058,	MVRCAccuracy=0.669355,	MLMLossWVC=1.833101,	MVRCLoss=2.457312,	
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
New Best Val MLMAcc: 0.5998316407203674, Epoch: 5
New Best Val MLMAcc: 0.5998316407203674, Epoch: 5
New Best Val MLMAcc: 0.5998316407203674, Epoch: 5
New Best Val MLMAcc: 0.5998316407203674, Epoch: 5
Epoch[5] 	Val-MLMAcc=0.599832,	MVRCAccuracy=0.692660,	MLMLossWVC=1.953614,	MVRCLoss=2.462498,	
Epoch[5] 	Val-MLMAcc=0.599832,	MVRCAccuracy=0.692660,	MLMLossWVC=1.953614,	MVRCLoss=2.462498,	
Epoch[5] 	Val-MLMAcc=0.599832,	MVRCAccuracy=0.692660,	MLMLossWVC=1.953614,	MVRCLoss=2.462498,	
Epoch[5] 	Val-MLMAcc=0.599832,	MVRCAccuracy=0.692660,	MLMLossWVC=1.953614,	MVRCLoss=2.462498,	
Best Val MLMAcc: 0.5998316407203674, Epoch: 5
Best Val MLMAcc: 0.5998316407203674, Epoch: 5
PROGRESS: 60.00%
Best Val MLMAcc: 0.5998316407203674, Epoch: 5
PROGRESS: 60.00%
Best Val MLMAcc: 0.5998316407203674, Epoch: 5
PROGRESS: 60.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Save new best model to /gs/hs0/tgb-deepmt/bugliarello.e/checkpoints/conceptual_captions/vl-bert/./output/pretrain/vlbert/base_prec_withouttextonly_4x16G_fp32/train_train/vl-bert_base_res101_pretrain-best.model.
PROGRESS: 60.00%
creating new zip_bank
creating new zip_bank
creating new zip_bank
creating new zip_bank
Rank[  1]Epoch[6] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.595477,	MVRCAccuracy=0.680744,	MLMLossWVC=1.990002,	MVRCLoss=2.412416,	
Rank[  3]Epoch[6] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.595477,	MVRCAccuracy=0.680744,	MLMLossWVC=1.990002,	MVRCLoss=2.412416,	
Rank[  2]Epoch[6] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.595477,	MVRCAccuracy=0.680744,	MLMLossWVC=1.990002,	MVRCLoss=2.412416,	
Rank[  0]Epoch[6] Batch [0]	Speed: - samples/sec ETA: - d - h - m	Train-MLMAcc=0.595477,	MVRCAccuracy=0.680744,	MLMLossWVC=1.990002,	MVRCLoss=2.412416,	
Rank[  1]Epoch[6] Batch [100]	Speed: 28.38 samples/s ETA: 1 d  3 h  7 m	Data: 0.407 Tran: 0.011 F: 0.225 B: 0.442 O: 2.747 M: 0.010	Train-MLMAcc=0.627138,	MVRCAccuracy=0.671631,	MLMLossWVC=1.779132,	MVRCLoss=2.450068,	
Rank[  3]Epoch[6] Batch [100]	Speed: 28.38 samples/s ETA: 1 d  3 h  7 m	Data: 0.809 Tran: 0.010 F: 0.226 B: 0.449 O: 2.336 M: 0.012	Train-MLMAcc=0.627138,	MVRCAccuracy=0.671631,	MLMLossWVC=1.779132,	MVRCLoss=2.450068,	
Rank[  0]Epoch[6] Batch [100]	Speed: 28.38 samples/s ETA: 1 d  3 h  7 m	Data: 2.189 Tran: 0.010 F: 0.226 B: 0.439 O: 0.793 M: 0.011	Train-MLMAcc=0.627138,	MVRCAccuracy=0.671631,	MLMLossWVC=1.779132,	MVRCLoss=2.450068,	
Rank[  2]Epoch[6] Batch [100]	Speed: 28.38 samples/s ETA: 1 d  3 h  7 m	Data: 0.813 Tran: 0.010 F: 0.227 B: 0.447 O: 2.336 M: 0.010	Train-MLMAcc=0.627138,	MVRCAccuracy=0.671631,	MLMLossWVC=1.779132,	MVRCLoss=2.450068,	
Rank[  1]Epoch[6] Batch [200]	Speed: 28.10 samples/s ETA: 1 d  3 h 20 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.814 M: 0.007	Train-MLMAcc=0.625578,	MVRCAccuracy=0.672450,	MLMLossWVC=1.794923,	MVRCLoss=2.450787,	
Rank[  3]Epoch[6] Batch [200]	Speed: 28.10 samples/s ETA: 1 d  3 h 20 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.297 O: 1.807 M: 0.009	Train-MLMAcc=0.625578,	MVRCAccuracy=0.672450,	MLMLossWVC=1.794923,	MVRCLoss=2.450787,	
Rank[  0]Epoch[6] Batch [200]	Speed: 28.10 samples/s ETA: 1 d  3 h 20 m	Data: 1.762 Tran: 0.006 F: 0.152 B: 0.293 O: 0.054 M: 0.009	Train-MLMAcc=0.625578,	MVRCAccuracy=0.672450,	MLMLossWVC=1.794923,	MVRCLoss=2.450787,	
Rank[  2]Epoch[6] Batch [200]	Speed: 28.10 samples/s ETA: 1 d  3 h 20 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.295 O: 1.812 M: 0.006	Train-MLMAcc=0.625578,	MVRCAccuracy=0.672450,	MLMLossWVC=1.794923,	MVRCLoss=2.450787,	
Rank[  2]Epoch[6] Batch [300]	Speed: 28.12 samples/s ETA: 1 d  3 h 14 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.296 O: 1.807 M: 0.005	Train-MLMAcc=0.624144,	MVRCAccuracy=0.673334,	MLMLossWVC=1.803517,	MVRCLoss=2.448213,	
Rank[  1]Epoch[6] Batch [300]	Speed: 28.12 samples/s ETA: 1 d  3 h 14 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.804 M: 0.012	Train-MLMAcc=0.624144,	MVRCAccuracy=0.673334,	MLMLossWVC=1.803517,	MVRCLoss=2.448213,	
Rank[  3]Epoch[6] Batch [300]	Speed: 28.12 samples/s ETA: 1 d  3 h 14 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.801 M: 0.011	Train-MLMAcc=0.624144,	MVRCAccuracy=0.673334,	MLMLossWVC=1.803517,	MVRCLoss=2.448213,	
Rank[  0]Epoch[6] Batch [300]	Speed: 28.12 samples/s ETA: 1 d  3 h 14 m	Data: 1.760 Tran: 0.006 F: 0.151 B: 0.292 O: 0.054 M: 0.011	Train-MLMAcc=0.624144,	MVRCAccuracy=0.673334,	MLMLossWVC=1.803517,	MVRCLoss=2.448213,	
Rank[  3]Epoch[6] Batch [400]	Speed: 28.77 samples/s ETA: 1 d  2 h 34 m	Data: 0.027 Tran: 0.007 F: 0.150 B: 0.297 O: 1.735 M: 0.008	Train-MLMAcc=0.624891,	MVRCAccuracy=0.672526,	MLMLossWVC=1.800282,	MVRCLoss=2.450180,	
Rank[  0]Epoch[6] Batch [400]	Speed: 28.77 samples/s ETA: 1 d  2 h 34 m	Data: 1.699 Tran: 0.006 F: 0.152 B: 0.294 O: 0.065 M: 0.007	Train-MLMAcc=0.624891,	MVRCAccuracy=0.672526,	MLMLossWVC=1.800282,	MVRCLoss=2.450180,	
Rank[  1]Epoch[6] Batch [400]	Speed: 28.77 samples/s ETA: 1 d  2 h 34 m	Data: 0.021 Tran: 0.007 F: 0.150 B: 0.295 O: 1.743 M: 0.007	Train-MLMAcc=0.624891,	MVRCAccuracy=0.672526,	MLMLossWVC=1.800282,	MVRCLoss=2.450180,	
Rank[  2]Epoch[6] Batch [400]	Speed: 28.77 samples/s ETA: 1 d  2 h 34 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.754 M: 0.008	Train-MLMAcc=0.624891,	MVRCAccuracy=0.672526,	MLMLossWVC=1.800282,	MVRCLoss=2.450180,	
Rank[  0]Epoch[6] Batch [500]	Speed: 27.98 samples/s ETA: 1 d  3 h 15 m	Data: 1.626 Tran: 0.006 F: 0.151 B: 0.294 O: 0.205 M: 0.005	Train-MLMAcc=0.625340,	MVRCAccuracy=0.671860,	MLMLossWVC=1.801648,	MVRCLoss=2.450287,	
Rank[  3]Epoch[6] Batch [500]	Speed: 27.98 samples/s ETA: 1 d  3 h 15 m	Data: 0.078 Tran: 0.007 F: 0.148 B: 0.293 O: 1.754 M: 0.008	Train-MLMAcc=0.625340,	MVRCAccuracy=0.671860,	MLMLossWVC=1.801648,	MVRCLoss=2.450287,	
Rank[  1]Epoch[6] Batch [500]	Speed: 27.98 samples/s ETA: 1 d  3 h 15 m	Data: 0.161 Tran: 0.007 F: 0.150 B: 0.296 O: 1.667 M: 0.006	Train-MLMAcc=0.625340,	MVRCAccuracy=0.671860,	MLMLossWVC=1.801648,	MVRCLoss=2.450287,	
Rank[  2]Epoch[6] Batch [500]	Speed: 27.98 samples/s ETA: 1 d  3 h 15 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.819 M: 0.006	Train-MLMAcc=0.625340,	MVRCAccuracy=0.671860,	MLMLossWVC=1.801648,	MVRCLoss=2.450287,	
Rank[  3]Epoch[6] Batch [600]	Speed: 27.83 samples/s ETA: 1 d  3 h 20 m	Data: 0.066 Tran: 0.007 F: 0.150 B: 0.298 O: 1.772 M: 0.006	Train-MLMAcc=0.625066,	MVRCAccuracy=0.671796,	MLMLossWVC=1.803556,	MVRCLoss=2.450452,	
Rank[  0]Epoch[6] Batch [600]	Speed: 27.83 samples/s ETA: 1 d  3 h 20 m	Data: 1.245 Tran: 0.007 F: 0.150 B: 0.293 O: 0.597 M: 0.008	Train-MLMAcc=0.625066,	MVRCAccuracy=0.671796,	MLMLossWVC=1.803556,	MVRCLoss=2.450452,	
Rank[  2]Epoch[6] Batch [600]	Speed: 27.83 samples/s ETA: 1 d  3 h 20 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.828 M: 0.009	Train-MLMAcc=0.625066,	MVRCAccuracy=0.671796,	MLMLossWVC=1.803556,	MVRCLoss=2.450452,	
Rank[  1]Epoch[6] Batch [600]	Speed: 27.83 samples/s ETA: 1 d  3 h 20 m	Data: 0.554 Tran: 0.006 F: 0.151 B: 0.297 O: 1.281 M: 0.009	Train-MLMAcc=0.625066,	MVRCAccuracy=0.671796,	MLMLossWVC=1.803556,	MVRCLoss=2.450452,	
Rank[  1]Epoch[6] Batch [700]	Speed: 28.12 samples/s ETA: 1 d  3 h  0 m	Data: 0.230 Tran: 0.007 F: 0.151 B: 0.296 O: 1.586 M: 0.005	Train-MLMAcc=0.623809,	MVRCAccuracy=0.671862,	MLMLossWVC=1.808947,	MVRCLoss=2.450262,	
Rank[  3]Epoch[6] Batch [700]	Speed: 28.12 samples/s ETA: 1 d  3 h  0 m	Data: 0.039 Tran: 0.007 F: 0.150 B: 0.297 O: 1.774 M: 0.009	Train-MLMAcc=0.623809,	MVRCAccuracy=0.671862,	MLMLossWVC=1.808947,	MVRCLoss=2.450262,	
Rank[  0]Epoch[6] Batch [700]	Speed: 28.12 samples/s ETA: 1 d  3 h  0 m	Data: 1.542 Tran: 0.007 F: 0.150 B: 0.292 O: 0.276 M: 0.008	Train-MLMAcc=0.623809,	MVRCAccuracy=0.671862,	MLMLossWVC=1.808947,	MVRCLoss=2.450262,	
Rank[  2]Epoch[6] Batch [700]	Speed: 28.12 samples/s ETA: 1 d  3 h  0 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.808 M: 0.008	Train-MLMAcc=0.623809,	MVRCAccuracy=0.671862,	MLMLossWVC=1.808947,	MVRCLoss=2.450262,	
Rank[  0]Epoch[6] Batch [800]	Speed: 28.24 samples/s ETA: 1 d  2 h 49 m	Data: 1.748 Tran: 0.007 F: 0.150 B: 0.292 O: 0.057 M: 0.011	Train-MLMAcc=0.623647,	MVRCAccuracy=0.671966,	MLMLossWVC=1.809692,	MVRCLoss=2.449712,	
Rank[  3]Epoch[6] Batch [800]	Speed: 28.24 samples/s ETA: 1 d  2 h 49 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.795 M: 0.009	Train-MLMAcc=0.623647,	MVRCAccuracy=0.671966,	MLMLossWVC=1.809692,	MVRCLoss=2.449712,	
Rank[  1]Epoch[6] Batch [800]	Speed: 28.24 samples/s ETA: 1 d  2 h 49 m	Data: 0.011 Tran: 0.007 F: 0.150 B: 0.294 O: 1.794 M: 0.009	Train-MLMAcc=0.623647,	MVRCAccuracy=0.671966,	MLMLossWVC=1.809692,	MVRCLoss=2.449712,	
Rank[  2]Epoch[6] Batch [800]	Speed: 28.24 samples/s ETA: 1 d  2 h 49 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.296 O: 1.794 M: 0.010	Train-MLMAcc=0.623647,	MVRCAccuracy=0.671966,	MLMLossWVC=1.809692,	MVRCLoss=2.449712,	
Rank[  0]Epoch[6] Batch [900]	Speed: 27.87 samples/s ETA: 1 d  3 h  6 m	Data: 1.783 Tran: 0.007 F: 0.150 B: 0.291 O: 0.057 M: 0.006	Train-MLMAcc=0.623759,	MVRCAccuracy=0.672114,	MLMLossWVC=1.807781,	MVRCLoss=2.449476,	
Rank[  1]Epoch[6] Batch [900]	Speed: 27.87 samples/s ETA: 1 d  3 h  6 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.830 M: 0.006	Train-MLMAcc=0.623759,	MVRCAccuracy=0.672114,	MLMLossWVC=1.807781,	MVRCLoss=2.449476,	
Rank[  3]Epoch[6] Batch [900]	Speed: 27.87 samples/s ETA: 1 d  3 h  6 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.297 O: 1.827 M: 0.007	Train-MLMAcc=0.623759,	MVRCAccuracy=0.672114,	MLMLossWVC=1.807781,	MVRCLoss=2.449476,	
Rank[  2]Epoch[6] Batch [900]	Speed: 27.87 samples/s ETA: 1 d  3 h  6 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.295 O: 1.829 M: 0.006	Train-MLMAcc=0.623759,	MVRCAccuracy=0.672114,	MLMLossWVC=1.807781,	MVRCLoss=2.449476,	
Rank[  0]Epoch[6] Batch [1000]	Speed: 28.38 samples/s ETA: 1 d  2 h 33 m	Data: 1.737 Tran: 0.007 F: 0.150 B: 0.290 O: 0.059 M: 0.011	Train-MLMAcc=0.624011,	MVRCAccuracy=0.672093,	MLMLossWVC=1.809005,	MVRCLoss=2.449357,	
Rank[  3]Epoch[6] Batch [1000]	Speed: 28.38 samples/s ETA: 1 d  2 h 33 m	Data: 0.032 Tran: 0.007 F: 0.150 B: 0.297 O: 1.759 M: 0.009	Train-MLMAcc=0.624011,	MVRCAccuracy=0.672093,	MLMLossWVC=1.809005,	MVRCLoss=2.449357,	
Rank[  1]Epoch[6] Batch [1000]	Speed: 28.38 samples/s ETA: 1 d  2 h 33 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.295 O: 1.782 M: 0.011	Train-MLMAcc=0.624011,	MVRCAccuracy=0.672093,	MLMLossWVC=1.809005,	MVRCLoss=2.449357,	
Rank[  2]Epoch[6] Batch [1000]	Speed: 28.38 samples/s ETA: 1 d  2 h 33 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.781 M: 0.009	Train-MLMAcc=0.624011,	MVRCAccuracy=0.672093,	MLMLossWVC=1.809005,	MVRCLoss=2.449357,	
Rank[  3]Epoch[6] Batch [1100]	Speed: 28.45 samples/s ETA: 1 d  2 h 26 m	Data: 0.437 Tran: 0.007 F: 0.150 B: 0.297 O: 1.351 M: 0.008	Train-MLMAcc=0.624133,	MVRCAccuracy=0.672181,	MLMLossWVC=1.811871,	MVRCLoss=2.449465,	
Rank[  2]Epoch[6] Batch [1100]	Speed: 28.45 samples/s ETA: 1 d  2 h 26 m	Data: 0.031 Tran: 0.007 F: 0.150 B: 0.296 O: 1.758 M: 0.006	Train-MLMAcc=0.624133,	MVRCAccuracy=0.672181,	MLMLossWVC=1.811871,	MVRCLoss=2.449465,	
Rank[  1]Epoch[6] Batch [1100]	Speed: 28.45 samples/s ETA: 1 d  2 h 26 m	Data: 0.383 Tran: 0.007 F: 0.150 B: 0.295 O: 1.406 M: 0.008	Train-MLMAcc=0.624133,	MVRCAccuracy=0.672181,	MLMLossWVC=1.811871,	MVRCLoss=2.449465,	
Rank[  0]Epoch[6] Batch [1100]	Speed: 28.45 samples/s ETA: 1 d  2 h 26 m	Data: 1.286 Tran: 0.007 F: 0.151 B: 0.292 O: 0.508 M: 0.006	Train-MLMAcc=0.624133,	MVRCAccuracy=0.672181,	MLMLossWVC=1.811871,	MVRCLoss=2.449465,	
Rank[  2]Epoch[6] Batch [1200]	Speed: 28.08 samples/s ETA: 1 d  2 h 43 m	Data: 0.731 Tran: 0.007 F: 0.150 B: 0.296 O: 1.087 M: 0.008	Train-MLMAcc=0.624214,	MVRCAccuracy=0.672350,	MLMLossWVC=1.812315,	MVRCLoss=2.449849,	
Rank[  1]Epoch[6] Batch [1200]	Speed: 28.08 samples/s ETA: 1 d  2 h 43 m	Data: 0.499 Tran: 0.006 F: 0.151 B: 0.298 O: 1.317 M: 0.007	Train-MLMAcc=0.624214,	MVRCAccuracy=0.672350,	MLMLossWVC=1.812315,	MVRCLoss=2.449849,	
Rank[  3]Epoch[6] Batch [1200]	Speed: 28.08 samples/s ETA: 1 d  2 h 43 m	Data: 0.488 Tran: 0.007 F: 0.150 B: 0.297 O: 1.329 M: 0.008	Train-MLMAcc=0.624214,	MVRCAccuracy=0.672350,	MLMLossWVC=1.812315,	MVRCLoss=2.449849,	
Rank[  0]Epoch[6] Batch [1200]	Speed: 28.08 samples/s ETA: 1 d  2 h 43 m	Data: 0.500 Tran: 0.007 F: 0.149 B: 0.291 O: 1.323 M: 0.008	Train-MLMAcc=0.624214,	MVRCAccuracy=0.672350,	MLMLossWVC=1.812315,	MVRCLoss=2.449849,	
Rank[  3]Epoch[6] Batch [1300]	Speed: 27.88 samples/s ETA: 1 d  2 h 51 m	Data: 1.204 Tran: 0.007 F: 0.155 B: 0.328 O: 0.595 M: 0.005	Train-MLMAcc=0.624213,	MVRCAccuracy=0.672097,	MLMLossWVC=1.812191,	MVRCLoss=2.450588,	
Rank[  0]Epoch[6] Batch [1300]	Speed: 27.88 samples/s ETA: 1 d  2 h 51 m	Data: 0.567 Tran: 0.007 F: 0.158 B: 0.297 O: 1.260 M: 0.006	Train-MLMAcc=0.624213,	MVRCAccuracy=0.672097,	MLMLossWVC=1.812191,	MVRCLoss=2.450588,	
Rank[  1]Epoch[6] Batch [1300]	Speed: 27.88 samples/s ETA: 1 d  2 h 51 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.321 O: 1.802 M: 0.005	Train-MLMAcc=0.624213,	MVRCAccuracy=0.672097,	MLMLossWVC=1.812191,	MVRCLoss=2.450588,	
Rank[  2]Epoch[6] Batch [1300]	Speed: 27.88 samples/s ETA: 1 d  2 h 51 m	Data: 0.015 Tran: 0.007 F: 0.151 B: 0.325 O: 1.791 M: 0.006	Train-MLMAcc=0.624213,	MVRCAccuracy=0.672097,	MLMLossWVC=1.812191,	MVRCLoss=2.450588,	
Rank[  0]Epoch[6] Batch [1400]	Speed: 28.12 samples/s ETA: 1 d  2 h 33 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.809 M: 0.010	Train-MLMAcc=0.624307,	MVRCAccuracy=0.672186,	MLMLossWVC=1.812191,	MVRCLoss=2.450898,	
Rank[  1]Epoch[6] Batch [1400]	Speed: 28.12 samples/s ETA: 1 d  2 h 33 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.295 O: 1.806 M: 0.008	Train-MLMAcc=0.624307,	MVRCAccuracy=0.672186,	MLMLossWVC=1.812191,	MVRCLoss=2.450898,	
Rank[  2]Epoch[6] Batch [1400]	Speed: 28.12 samples/s ETA: 1 d  2 h 33 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.298 O: 1.805 M: 0.007	Train-MLMAcc=0.624307,	MVRCAccuracy=0.672186,	MLMLossWVC=1.812191,	MVRCLoss=2.450898,	
Rank[  3]Epoch[6] Batch [1400]	Speed: 28.12 samples/s ETA: 1 d  2 h 33 m	Data: 1.761 Tran: 0.007 F: 0.151 B: 0.296 O: 0.049 M: 0.010	Train-MLMAcc=0.624307,	MVRCAccuracy=0.672186,	MLMLossWVC=1.812191,	MVRCLoss=2.450898,	
Rank[  2]Epoch[6] Batch [1500]	Speed: 27.90 samples/s ETA: 1 d  2 h 42 m	Data: 0.148 Tran: 0.007 F: 0.150 B: 0.298 O: 1.683 M: 0.008	Train-MLMAcc=0.624515,	MVRCAccuracy=0.672327,	MLMLossWVC=1.810971,	MVRCLoss=2.450660,	
Rank[  0]Epoch[6] Batch [1500]	Speed: 27.90 samples/s ETA: 1 d  2 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.828 M: 0.007	Train-MLMAcc=0.624515,	MVRCAccuracy=0.672327,	MLMLossWVC=1.810971,	MVRCLoss=2.450660,	
Rank[  1]Epoch[6] Batch [1500]	Speed: 27.90 samples/s ETA: 1 d  2 h 42 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.295 O: 1.826 M: 0.007	Train-MLMAcc=0.624515,	MVRCAccuracy=0.672327,	MLMLossWVC=1.810971,	MVRCLoss=2.450660,	
Rank[  3]Epoch[6] Batch [1500]	Speed: 27.90 samples/s ETA: 1 d  2 h 42 m	Data: 1.779 Tran: 0.007 F: 0.150 B: 0.296 O: 0.054 M: 0.008	Train-MLMAcc=0.624515,	MVRCAccuracy=0.672327,	MLMLossWVC=1.810971,	MVRCLoss=2.450660,	
Rank[  0]Epoch[6] Batch [1600]	Speed: 28.27 samples/s ETA: 1 d  2 h 17 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.798 M: 0.008	Train-MLMAcc=0.624889,	MVRCAccuracy=0.672342,	MLMLossWVC=1.808626,	MVRCLoss=2.450725,	
Rank[  1]Epoch[6] Batch [1600]	Speed: 28.27 samples/s ETA: 1 d  2 h 17 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.297 O: 1.793 M: 0.008	Train-MLMAcc=0.624889,	MVRCAccuracy=0.672342,	MLMLossWVC=1.808626,	MVRCLoss=2.450725,	
Rank[  2]Epoch[6] Batch [1600]	Speed: 28.27 samples/s ETA: 1 d  2 h 17 m	Data: 0.163 Tran: 0.007 F: 0.149 B: 0.297 O: 1.639 M: 0.009	Train-MLMAcc=0.624889,	MVRCAccuracy=0.672342,	MLMLossWVC=1.808626,	MVRCLoss=2.450725,	
Rank[  3]Epoch[6] Batch [1600]	Speed: 28.27 samples/s ETA: 1 d  2 h 17 m	Data: 1.706 Tran: 0.007 F: 0.152 B: 0.300 O: 0.091 M: 0.007	Train-MLMAcc=0.624889,	MVRCAccuracy=0.672342,	MLMLossWVC=1.808626,	MVRCLoss=2.450725,	
Rank[  1]Epoch[6] Batch [1700]	Speed: 28.04 samples/s ETA: 1 d  2 h 26 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.815 M: 0.008	Train-MLMAcc=0.624968,	MVRCAccuracy=0.672317,	MLMLossWVC=1.807718,	MVRCLoss=2.450875,	
Rank[  2]Epoch[6] Batch [1700]	Speed: 28.04 samples/s ETA: 1 d  2 h 26 m	Data: 0.060 Tran: 0.007 F: 0.150 B: 0.297 O: 1.759 M: 0.008	Train-MLMAcc=0.624968,	MVRCAccuracy=0.672317,	MLMLossWVC=1.807718,	MVRCLoss=2.450875,	
Rank[  3]Epoch[6] Batch [1700]	Speed: 28.04 samples/s ETA: 1 d  2 h 26 m	Data: 1.761 Tran: 0.007 F: 0.151 B: 0.297 O: 0.060 M: 0.006	Train-MLMAcc=0.624968,	MVRCAccuracy=0.672317,	MLMLossWVC=1.807718,	MVRCLoss=2.450875,	
Rank[  0]Epoch[6] Batch [1700]	Speed: 28.04 samples/s ETA: 1 d  2 h 26 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.292 O: 1.818 M: 0.008	Train-MLMAcc=0.624968,	MVRCAccuracy=0.672317,	MLMLossWVC=1.807718,	MVRCLoss=2.450875,	
Rank[  2]Epoch[6] Batch [1800]	Speed: 28.34 samples/s ETA: 1 d  2 h  5 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.296 O: 1.788 M: 0.009	Train-MLMAcc=0.625191,	MVRCAccuracy=0.672302,	MLMLossWVC=1.806738,	MVRCLoss=2.451132,	
Rank[  3]Epoch[6] Batch [1800]	Speed: 28.34 samples/s ETA: 1 d  2 h  5 m	Data: 1.744 Tran: 0.007 F: 0.151 B: 0.298 O: 0.048 M: 0.009	Train-MLMAcc=0.625191,	MVRCAccuracy=0.672302,	MLMLossWVC=1.806738,	MVRCLoss=2.451132,	
Rank[  0]Epoch[6] Batch [1800]	Speed: 28.34 samples/s ETA: 1 d  2 h  5 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.790 M: 0.008	Train-MLMAcc=0.625191,	MVRCAccuracy=0.672302,	MLMLossWVC=1.806738,	MVRCLoss=2.451132,	
Rank[  1]Epoch[6] Batch [1800]	Speed: 28.34 samples/s ETA: 1 d  2 h  5 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.296 O: 1.790 M: 0.006	Train-MLMAcc=0.625191,	MVRCAccuracy=0.672302,	MLMLossWVC=1.806738,	MVRCLoss=2.451132,	
Rank[  0]Epoch[6] Batch [1900]	Speed: 25.22 samples/s ETA: 1 d  5 h 15 m	Data: 0.015 Tran: 0.007 F: 0.169 B: 0.323 O: 2.007 M: 0.015	Train-MLMAcc=0.625100,	MVRCAccuracy=0.672369,	MLMLossWVC=1.806971,	MVRCLoss=2.450747,	
Rank[  3]Epoch[6] Batch [1900]	Speed: 25.22 samples/s ETA: 1 d  5 h 15 m	Data: 1.859 Tran: 0.012 F: 0.221 B: 0.354 O: 0.076 M: 0.015	Train-MLMAcc=0.625100,	MVRCAccuracy=0.672369,	MLMLossWVC=1.806971,	MVRCLoss=2.450747,	
Rank[  1]Epoch[6] Batch [1900]	Speed: 25.22 samples/s ETA: 1 d  5 h 15 m	Data: 0.013 Tran: 0.008 F: 0.171 B: 0.327 O: 2.002 M: 0.014	Train-MLMAcc=0.625100,	MVRCAccuracy=0.672369,	MLMLossWVC=1.806971,	MVRCLoss=2.450747,	
Rank[  2]Epoch[6] Batch [1900]	Speed: 25.22 samples/s ETA: 1 d  5 h 15 m	Data: 0.015 Tran: 0.007 F: 0.170 B: 0.328 O: 2.001 M: 0.014	Train-MLMAcc=0.625100,	MVRCAccuracy=0.672369,	MLMLossWVC=1.806971,	MVRCLoss=2.450747,	
Rank[  2]Epoch[6] Batch [2000]	Speed: 26.86 samples/s ETA: 1 d  3 h 24 m	Data: 0.010 Tran: 0.007 F: 0.159 B: 0.308 O: 1.884 M: 0.014	Train-MLMAcc=0.625326,	MVRCAccuracy=0.672347,	MLMLossWVC=1.806117,	MVRCLoss=2.450609,	
Rank[  1]Epoch[6] Batch [2000]	Speed: 26.86 samples/s ETA: 1 d  3 h 24 m	Data: 0.224 Tran: 0.007 F: 0.159 B: 0.307 O: 1.670 M: 0.015	Train-MLMAcc=0.625326,	MVRCAccuracy=0.672347,	MLMLossWVC=1.806117,	MVRCLoss=2.450609,	
Rank[  3]Epoch[6] Batch [2000]	Speed: 26.86 samples/s ETA: 1 d  3 h 24 m	Data: 1.796 Tran: 0.007 F: 0.184 B: 0.323 O: 0.055 M: 0.016	Train-MLMAcc=0.625326,	MVRCAccuracy=0.672347,	MLMLossWVC=1.806117,	MVRCLoss=2.450609,	
Rank[  0]Epoch[6] Batch [2000]	Speed: 26.86 samples/s ETA: 1 d  3 h 24 m	Data: 0.010 Tran: 0.007 F: 0.159 B: 0.305 O: 1.885 M: 0.015	Train-MLMAcc=0.625326,	MVRCAccuracy=0.672347,	MLMLossWVC=1.806117,	MVRCLoss=2.450609,	
Rank[  3]Epoch[6] Batch [2100]	Speed: 28.25 samples/s ETA: 1 d  1 h 59 m	Data: 1.753 Tran: 0.007 F: 0.150 B: 0.297 O: 0.049 M: 0.009	Train-MLMAcc=0.625368,	MVRCAccuracy=0.672337,	MLMLossWVC=1.805532,	MVRCLoss=2.450660,	
Rank[  0]Epoch[6] Batch [2100]	Speed: 28.25 samples/s ETA: 1 d  1 h 59 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.291 O: 1.804 M: 0.004	Train-MLMAcc=0.625368,	MVRCAccuracy=0.672337,	MLMLossWVC=1.805532,	MVRCLoss=2.450660,	
Rank[  2]Epoch[6] Batch [2100]	Speed: 28.25 samples/s ETA: 1 d  1 h 59 m	Data: 0.021 Tran: 0.007 F: 0.150 B: 0.297 O: 1.781 M: 0.009	Train-MLMAcc=0.625368,	MVRCAccuracy=0.672337,	MLMLossWVC=1.805532,	MVRCLoss=2.450660,	
Rank[  1]Epoch[6] Batch [2100]	Speed: 28.25 samples/s ETA: 1 d  1 h 59 m	Data: 0.018 Tran: 0.007 F: 0.149 B: 0.293 O: 1.788 M: 0.009	Train-MLMAcc=0.625368,	MVRCAccuracy=0.672337,	MLMLossWVC=1.805532,	MVRCLoss=2.450660,	
Rank[  0]Epoch[6] Batch [2200]	Speed: 27.99 samples/s ETA: 1 d  2 h 10 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.290 O: 1.826 M: 0.005	Train-MLMAcc=0.625533,	MVRCAccuracy=0.672370,	MLMLossWVC=1.804632,	MVRCLoss=2.450579,	
Rank[  1]Epoch[6] Batch [2200]	Speed: 27.99 samples/s ETA: 1 d  2 h 10 m	Data: 0.011 Tran: 0.007 F: 0.150 B: 0.295 O: 1.813 M: 0.010	Train-MLMAcc=0.625533,	MVRCAccuracy=0.672370,	MLMLossWVC=1.804632,	MVRCLoss=2.450579,	
Rank[  3]Epoch[6] Batch [2200]	Speed: 27.99 samples/s ETA: 1 d  2 h 10 m	Data: 1.768 Tran: 0.007 F: 0.150 B: 0.296 O: 0.056 M: 0.009	Train-MLMAcc=0.625533,	MVRCAccuracy=0.672370,	MLMLossWVC=1.804632,	MVRCLoss=2.450579,	
Rank[  2]Epoch[6] Batch [2200]	Speed: 27.99 samples/s ETA: 1 d  2 h 10 m	Data: 0.328 Tran: 0.007 F: 0.150 B: 0.296 O: 1.495 M: 0.009	Train-MLMAcc=0.625533,	MVRCAccuracy=0.672370,	MLMLossWVC=1.804632,	MVRCLoss=2.450579,	
Rank[  3]Epoch[6] Batch [2300]	Speed: 28.01 samples/s ETA: 1 d  2 h  5 m	Data: 1.485 Tran: 0.007 F: 0.150 B: 0.297 O: 0.339 M: 0.005	Train-MLMAcc=0.625433,	MVRCAccuracy=0.672459,	MLMLossWVC=1.805092,	MVRCLoss=2.450315,	
Rank[  2]Epoch[6] Batch [2300]	Speed: 28.01 samples/s ETA: 1 d  2 h  5 m	Data: 0.104 Tran: 0.007 F: 0.150 B: 0.297 O: 1.719 M: 0.006	Train-MLMAcc=0.625433,	MVRCAccuracy=0.672459,	MLMLossWVC=1.805092,	MVRCLoss=2.450315,	
Rank[  0]Epoch[6] Batch [2300]	Speed: 28.01 samples/s ETA: 1 d  2 h  5 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.293 O: 1.820 M: 0.006	Train-MLMAcc=0.625433,	MVRCAccuracy=0.672459,	MLMLossWVC=1.805092,	MVRCLoss=2.450315,	
Rank[  1]Epoch[6] Batch [2300]	Speed: 28.01 samples/s ETA: 1 d  2 h  5 m	Data: 0.297 Tran: 0.007 F: 0.150 B: 0.295 O: 1.528 M: 0.006	Train-MLMAcc=0.625433,	MVRCAccuracy=0.672459,	MLMLossWVC=1.805092,	MVRCLoss=2.450315,	
Rank[  0]Epoch[6] Batch [2400]	Speed: 28.08 samples/s ETA: 1 d  1 h 57 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.294 O: 1.812 M: 0.006	Train-MLMAcc=0.625550,	MVRCAccuracy=0.672481,	MLMLossWVC=1.804203,	MVRCLoss=2.450138,	
Rank[  3]Epoch[6] Batch [2400]	Speed: 28.08 samples/s ETA: 1 d  1 h 57 m	Data: 1.494 Tran: 0.007 F: 0.150 B: 0.296 O: 0.323 M: 0.008	Train-MLMAcc=0.625550,	MVRCAccuracy=0.672481,	MLMLossWVC=1.804203,	MVRCLoss=2.450138,	
Rank[  1]Epoch[6] Batch [2400]	Speed: 28.08 samples/s ETA: 1 d  1 h 57 m	Data: 0.163 Tran: 0.007 F: 0.150 B: 0.294 O: 1.655 M: 0.008	Train-MLMAcc=0.625550,	MVRCAccuracy=0.672481,	MLMLossWVC=1.804203,	MVRCLoss=2.450138,	
Rank[  2]Epoch[6] Batch [2400]	Speed: 28.08 samples/s ETA: 1 d  1 h 57 m	Data: 0.278 Tran: 0.007 F: 0.150 B: 0.296 O: 1.539 M: 0.008	Train-MLMAcc=0.625550,	MVRCAccuracy=0.672481,	MLMLossWVC=1.804203,	MVRCLoss=2.450138,	
Rank[  3]Epoch[6] Batch [2500]	Speed: 28.08 samples/s ETA: 1 d  1 h 53 m	Data: 1.765 Tran: 0.006 F: 0.151 B: 0.298 O: 0.052 M: 0.007	Train-MLMAcc=0.625600,	MVRCAccuracy=0.672439,	MLMLossWVC=1.804316,	MVRCLoss=2.450072,	
Rank[  1]Epoch[6] Batch [2500]	Speed: 28.08 samples/s ETA: 1 d  1 h 53 m	Data: 0.007 Tran: 0.007 F: 0.150 B: 0.293 O: 1.815 M: 0.005	Train-MLMAcc=0.625600,	MVRCAccuracy=0.672439,	MLMLossWVC=1.804316,	MVRCLoss=2.450072,	
Rank[  0]Epoch[6] Batch [2500]	Speed: 28.08 samples/s ETA: 1 d  1 h 53 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.812 M: 0.007	Train-MLMAcc=0.625600,	MVRCAccuracy=0.672439,	MLMLossWVC=1.804316,	MVRCLoss=2.450072,	
Rank[  2]Epoch[6] Batch [2500]	Speed: 28.08 samples/s ETA: 1 d  1 h 53 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.297 O: 1.810 M: 0.006	Train-MLMAcc=0.625600,	MVRCAccuracy=0.672439,	MLMLossWVC=1.804316,	MVRCLoss=2.450072,	
Rank[  2]Epoch[6] Batch [2600]	Speed: 27.97 samples/s ETA: 1 d  1 h 56 m	Data: 0.019 Tran: 0.007 F: 0.151 B: 0.298 O: 1.807 M: 0.006	Train-MLMAcc=0.625732,	MVRCAccuracy=0.672497,	MLMLossWVC=1.803798,	MVRCLoss=2.450045,	
Rank[  3]Epoch[6] Batch [2600]	Speed: 27.97 samples/s ETA: 1 d  1 h 56 m	Data: 1.777 Tran: 0.007 F: 0.150 B: 0.297 O: 0.048 M: 0.008	Train-MLMAcc=0.625732,	MVRCAccuracy=0.672497,	MLMLossWVC=1.803798,	MVRCLoss=2.450045,	
Rank[  1]Epoch[6] Batch [2600]	Speed: 27.97 samples/s ETA: 1 d  1 h 56 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.821 M: 0.007	Train-MLMAcc=0.625732,	MVRCAccuracy=0.672497,	MLMLossWVC=1.803798,	MVRCLoss=2.450045,	
Rank[  0]Epoch[6] Batch [2600]	Speed: 27.97 samples/s ETA: 1 d  1 h 56 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.292 O: 1.821 M: 0.010	Train-MLMAcc=0.625732,	MVRCAccuracy=0.672497,	MLMLossWVC=1.803798,	MVRCLoss=2.450045,	
Rank[  1]Epoch[6] Batch [2700]	Speed: 27.82 samples/s ETA: 1 d  2 h  0 m	Data: 0.010 Tran: 0.007 F: 0.150 B: 0.294 O: 1.831 M: 0.007	Train-MLMAcc=0.625905,	MVRCAccuracy=0.672526,	MLMLossWVC=1.802741,	MVRCLoss=2.450211,	
Rank[  3]Epoch[6] Batch [2700]	Speed: 27.82 samples/s ETA: 1 d  2 h  0 m	Data: 1.754 Tran: 0.007 F: 0.150 B: 0.297 O: 0.086 M: 0.005	Train-MLMAcc=0.625905,	MVRCAccuracy=0.672526,	MLMLossWVC=1.802741,	MVRCLoss=2.450211,	
Rank[  0]Epoch[6] Batch [2700]	Speed: 27.82 samples/s ETA: 1 d  2 h  0 m	Data: 0.041 Tran: 0.007 F: 0.149 B: 0.291 O: 1.804 M: 0.006	Train-MLMAcc=0.625905,	MVRCAccuracy=0.672526,	MLMLossWVC=1.802741,	MVRCLoss=2.450211,	
Rank[  2]Epoch[6] Batch [2700]	Speed: 27.82 samples/s ETA: 1 d  2 h  0 m	Data: 0.034 Tran: 0.007 F: 0.150 B: 0.297 O: 1.804 M: 0.006	Train-MLMAcc=0.625905,	MVRCAccuracy=0.672526,	MLMLossWVC=1.802741,	MVRCLoss=2.450211,	
Rank[  3]Epoch[6] Batch [2800]	Speed: 28.12 samples/s ETA: 1 d  1 h 40 m	Data: 1.762 Tran: 0.007 F: 0.150 B: 0.297 O: 0.052 M: 0.007	Train-MLMAcc=0.625785,	MVRCAccuracy=0.672597,	MLMLossWVC=1.802878,	MVRCLoss=2.450214,	
Rank[  0]Epoch[6] Batch [2800]	Speed: 28.12 samples/s ETA: 1 d  1 h 40 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.808 M: 0.008	Train-MLMAcc=0.625785,	MVRCAccuracy=0.672597,	MLMLossWVC=1.802878,	MVRCLoss=2.450214,	
Rank[  1]Epoch[6] Batch [2800]	Speed: 28.12 samples/s ETA: 1 d  1 h 40 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.294 O: 1.809 M: 0.008	Train-MLMAcc=0.625785,	MVRCAccuracy=0.672597,	MLMLossWVC=1.802878,	MVRCLoss=2.450214,	
Rank[  2]Epoch[6] Batch [2800]	Speed: 28.12 samples/s ETA: 1 d  1 h 40 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.298 O: 1.806 M: 0.005	Train-MLMAcc=0.625785,	MVRCAccuracy=0.672597,	MLMLossWVC=1.802878,	MVRCLoss=2.450214,	
Rank[  2]Epoch[6] Batch [2900]	Speed: 28.15 samples/s ETA: 1 d  1 h 34 m	Data: 0.046 Tran: 0.007 F: 0.150 B: 0.297 O: 1.763 M: 0.010	Train-MLMAcc=0.625813,	MVRCAccuracy=0.672628,	MLMLossWVC=1.802991,	MVRCLoss=2.450234,	
Rank[  1]Epoch[6] Batch [2900]	Speed: 28.15 samples/s ETA: 1 d  1 h 34 m	Data: 0.013 Tran: 0.008 F: 0.151 B: 0.295 O: 1.797 M: 0.009	Train-MLMAcc=0.625813,	MVRCAccuracy=0.672628,	MLMLossWVC=1.802991,	MVRCLoss=2.450234,	
Rank[  3]Epoch[6] Batch [2900]	Speed: 28.15 samples/s ETA: 1 d  1 h 34 m	Data: 1.738 Tran: 0.007 F: 0.151 B: 0.298 O: 0.068 M: 0.011	Train-MLMAcc=0.625813,	MVRCAccuracy=0.672628,	MLMLossWVC=1.802991,	MVRCLoss=2.450234,	
Rank[  0]Epoch[6] Batch [2900]	Speed: 28.15 samples/s ETA: 1 d  1 h 34 m	Data: 0.008 Tran: 0.007 F: 0.150 B: 0.293 O: 1.808 M: 0.006	Train-MLMAcc=0.625813,	MVRCAccuracy=0.672628,	MLMLossWVC=1.802991,	MVRCLoss=2.450234,	
Rank[  3]Epoch[6] Batch [3000]	Speed: 28.07 samples/s ETA: 1 d  1 h 35 m	Data: 1.327 Tran: 0.006 F: 0.150 B: 0.298 O: 0.492 M: 0.006	Train-MLMAcc=0.625812,	MVRCAccuracy=0.672702,	MLMLossWVC=1.802941,	MVRCLoss=2.449878,	
Rank[  1]Epoch[6] Batch [3000]	Speed: 28.07 samples/s ETA: 1 d  1 h 35 m	Data: 0.035 Tran: 0.007 F: 0.150 B: 0.297 O: 1.784 M: 0.006	Train-MLMAcc=0.625812,	MVRCAccuracy=0.672702,	MLMLossWVC=1.802941,	MVRCLoss=2.449878,	
Rank[  0]Epoch[6] Batch [3000]	Speed: 28.07 samples/s ETA: 1 d  1 h 35 m	Data: 0.013 Tran: 0.007 F: 0.149 B: 0.293 O: 1.812 M: 0.006	Train-MLMAcc=0.625812,	MVRCAccuracy=0.672702,	MLMLossWVC=1.802941,	MVRCLoss=2.449878,	
Rank[  2]Epoch[6] Batch [3000]	Speed: 28.07 samples/s ETA: 1 d  1 h 35 m	Data: 0.542 Tran: 0.007 F: 0.151 B: 0.298 O: 1.275 M: 0.007	Train-MLMAcc=0.625812,	MVRCAccuracy=0.672702,	MLMLossWVC=1.802941,	MVRCLoss=2.449878,	
Rank[  2]Epoch[6] Batch [3100]	Speed: 28.16 samples/s ETA: 1 d  1 h 26 m	Data: 1.259 Tran: 0.007 F: 0.150 B: 0.295 O: 0.555 M: 0.006	Train-MLMAcc=0.625808,	MVRCAccuracy=0.672685,	MLMLossWVC=1.802959,	MVRCLoss=2.449995,	
Rank[  0]Epoch[6] Batch [3100]	Speed: 28.16 samples/s ETA: 1 d  1 h 26 m	Data: 0.009 Tran: 0.007 F: 0.150 B: 0.292 O: 1.809 M: 0.005	Train-MLMAcc=0.625808,	MVRCAccuracy=0.672685,	MLMLossWVC=1.802959,	MVRCLoss=2.449995,	
Rank[  3]Epoch[6] Batch [3100]	Speed: 28.16 samples/s ETA: 1 d  1 h 26 m	Data: 0.929 Tran: 0.007 F: 0.151 B: 0.299 O: 0.880 M: 0.007	Train-MLMAcc=0.625808,	MVRCAccuracy=0.672685,	MLMLossWVC=1.802959,	MVRCLoss=2.449995,	
Rank[  1]Epoch[6] Batch [3100]	Speed: 28.16 samples/s ETA: 1 d  1 h 26 m	Data: 0.406 Tran: 0.007 F: 0.149 B: 0.295 O: 1.408 M: 0.007	Train-MLMAcc=0.625808,	MVRCAccuracy=0.672685,	MLMLossWVC=1.802959,	MVRCLoss=2.449995,	
Rank[  2]Epoch[6] Batch [3200]	Speed: 27.64 samples/s ETA: 1 d  1 h 51 m	Data: 1.240 Tran: 0.007 F: 0.155 B: 0.304 O: 0.588 M: 0.020	Train-MLMAcc=0.625704,	MVRCAccuracy=0.672743,	MLMLossWVC=1.803737,	MVRCLoss=2.450123,	
Rank[  0]Epoch[6] Batch [3200]	Speed: 27.64 samples/s ETA: 1 d  1 h 51 m	Data: 0.012 Tran: 0.007 F: 0.164 B: 0.299 O: 1.812 M: 0.020	Train-MLMAcc=0.625704,	MVRCAccuracy=0.672743,	MLMLossWVC=1.803737,	MVRCLoss=2.450123,	
Rank[  1]Epoch[6] Batch [3200]	Speed: 27.64 samples/s ETA: 1 d  1 h 51 m	Data: 0.015 Tran: 0.007 F: 0.164 B: 0.300 O: 1.809 M: 0.020	Train-MLMAcc=0.625704,	MVRCAccuracy=0.672743,	MLMLossWVC=1.803737,	MVRCLoss=2.450123,	
Rank[  3]Epoch[6] Batch [3200]	Speed: 27.64 samples/s ETA: 1 d  1 h 51 m	Data: 1.365 Tran: 0.006 F: 0.169 B: 0.306 O: 0.447 M: 0.020	Train-MLMAcc=0.625704,	MVRCAccuracy=0.672743,	MLMLossWVC=1.803737,	MVRCLoss=2.450123,	
Rank[  0]Epoch[6] Batch [3300]	Speed: 27.88 samples/s ETA: 1 d  1 h 34 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.298 O: 1.823 M: 0.006	Train-MLMAcc=0.625896,	MVRCAccuracy=0.672705,	MLMLossWVC=1.803131,	MVRCLoss=2.450105,	
Rank[  3]Epoch[6] Batch [3300]	Speed: 27.88 samples/s ETA: 1 d  1 h 34 m	Data: 1.326 Tran: 0.007 F: 0.166 B: 0.308 O: 0.482 M: 0.006	Train-MLMAcc=0.625896,	MVRCAccuracy=0.672705,	MLMLossWVC=1.803131,	MVRCLoss=2.450105,	
Rank[  2]Epoch[6] Batch [3300]	Speed: 27.88 samples/s ETA: 1 d  1 h 34 m	Data: 0.404 Tran: 0.007 F: 0.162 B: 0.301 O: 1.414 M: 0.006	Train-MLMAcc=0.625896,	MVRCAccuracy=0.672705,	MLMLossWVC=1.803131,	MVRCLoss=2.450105,	
Rank[  1]Epoch[6] Batch [3300]	Speed: 27.88 samples/s ETA: 1 d  1 h 34 m	Data: 0.252 Tran: 0.007 F: 0.153 B: 0.300 O: 1.576 M: 0.007	Train-MLMAcc=0.625896,	MVRCAccuracy=0.672705,	MLMLossWVC=1.803131,	MVRCLoss=2.450105,	
Rank[  1]Epoch[6] Batch [3400]	Speed: 27.66 samples/s ETA: 1 d  1 h 42 m	Data: 0.794 Tran: 0.010 F: 0.175 B: 0.304 O: 1.019 M: 0.010	Train-MLMAcc=0.625913,	MVRCAccuracy=0.672749,	MLMLossWVC=1.803057,	MVRCLoss=2.450318,	
Rank[  0]Epoch[6] Batch [3400]	Speed: 27.66 samples/s ETA: 1 d  1 h 42 m	Data: 0.008 Tran: 0.007 F: 0.160 B: 0.296 O: 1.831 M: 0.010	Train-MLMAcc=0.625913,	MVRCAccuracy=0.672749,	MLMLossWVC=1.803057,	MVRCLoss=2.450318,	
Rank[  2]Epoch[6] Batch [3400]	Speed: 27.66 samples/s ETA: 1 d  1 h 42 m	Data: 0.009 Tran: 0.007 F: 0.160 B: 0.300 O: 1.830 M: 0.006	Train-MLMAcc=0.625913,	MVRCAccuracy=0.672749,	MLMLossWVC=1.803057,	MVRCLoss=2.450318,	
Rank[  3]Epoch[6] Batch [3400]	Speed: 27.66 samples/s ETA: 1 d  1 h 42 m	Data: 0.954 Tran: 0.007 F: 0.163 B: 0.314 O: 0.865 M: 0.009	Train-MLMAcc=0.625913,	MVRCAccuracy=0.672749,	MLMLossWVC=1.803057,	MVRCLoss=2.450318,	
Rank[  3]Epoch[6] Batch [3500]	Speed: 28.10 samples/s ETA: 1 d  1 h 14 m	Data: 0.781 Tran: 0.007 F: 0.156 B: 0.306 O: 1.021 M: 0.007	Train-MLMAcc=0.625814,	MVRCAccuracy=0.672806,	MLMLossWVC=1.803282,	MVRCLoss=2.450233,	
Rank[  1]Epoch[6] Batch [3500]	Speed: 28.10 samples/s ETA: 1 d  1 h 14 m	Data: 1.002 Tran: 0.007 F: 0.165 B: 0.303 O: 0.790 M: 0.008	Train-MLMAcc=0.625814,	MVRCAccuracy=0.672806,	MLMLossWVC=1.803282,	MVRCLoss=2.450233,	
Rank[  0]Epoch[6] Batch [3500]	Speed: 28.10 samples/s ETA: 1 d  1 h 14 m	Data: 0.008 Tran: 0.007 F: 0.153 B: 0.298 O: 1.804 M: 0.006	Train-MLMAcc=0.625814,	MVRCAccuracy=0.672806,	MLMLossWVC=1.803282,	MVRCLoss=2.450233,	
Rank[  2]Epoch[6] Batch [3500]	Speed: 28.10 samples/s ETA: 1 d  1 h 14 m	Data: 0.008 Tran: 0.007 F: 0.149 B: 0.304 O: 1.800 M: 0.008	Train-MLMAcc=0.625814,	MVRCAccuracy=0.672806,	MLMLossWVC=1.803282,	MVRCLoss=2.450233,	
Rank[  0]Epoch[6] Batch [3600]	Speed: 27.66 samples/s ETA: 1 d  1 h 34 m	Data: 0.009 Tran: 0.007 F: 0.157 B: 0.297 O: 1.831 M: 0.010	Train-MLMAcc=0.625769,	MVRCAccuracy=0.672835,	MLMLossWVC=1.803288,	MVRCLoss=2.449995,	
Rank[  1]Epoch[6] Batch [3600]	Speed: 27.66 samples/s ETA: 1 d  1 h 34 m	Data: 1.697 Tran: 0.007 F: 0.160 B: 0.302 O: 0.133 M: 0.012	Train-MLMAcc=0.625769,	MVRCAccuracy=0.672835,	MLMLossWVC=1.803288,	MVRCLoss=2.449995,	
Rank[  2]Epoch[6] Batch [3600]	Speed: 27.66 samples/s ETA: 1 d  1 h 34 m	Data: 0.009 Tran: 0.007 F: 0.158 B: 0.304 O: 1.820 M: 0.012	Train-MLMAcc=0.625769,	MVRCAccuracy=0.672835,	MLMLossWVC=1.803288,	MVRCLoss=2.449995,	
Rank[  3]Epoch[6] Batch [3600]	Speed: 27.66 samples/s ETA: 1 d  1 h 34 m	Data: 0.368 Tran: 0.007 F: 0.154 B: 0.300 O: 1.469 M: 0.015	Train-MLMAcc=0.625769,	MVRCAccuracy=0.672835,	MLMLossWVC=1.803288,	MVRCLoss=2.449995,	
Rank[  2]Epoch[6] Batch [3700]	Speed: 27.90 samples/s ETA: 1 d  1 h 17 m	Data: 0.010 Tran: 0.007 F: 0.152 B: 0.302 O: 1.802 M: 0.019	Train-MLMAcc=0.625718,	MVRCAccuracy=0.672830,	MLMLossWVC=1.803681,	MVRCLoss=2.450124,	
Rank[  1]Epoch[6] Batch [3700]	Speed: 27.90 samples/s ETA: 1 d  1 h 17 m	Data: 1.736 Tran: 0.008 F: 0.168 B: 0.303 O: 0.057 M: 0.020	Train-MLMAcc=0.625718,	MVRCAccuracy=0.672830,	MLMLossWVC=1.803681,	MVRCLoss=2.450124,	
Rank[  0]Epoch[6] Batch [3700]	Speed: 27.90 samples/s ETA: 1 d  1 h 17 m	Data: 0.010 Tran: 0.007 F: 0.152 B: 0.294 O: 1.813 M: 0.017	Train-MLMAcc=0.625718,	MVRCAccuracy=0.672830,	MLMLossWVC=1.803681,	MVRCLoss=2.450124,	
Rank[  3]Epoch[6] Batch [3700]	Speed: 27.90 samples/s ETA: 1 d  1 h 17 m	Data: 0.273 Tran: 0.007 F: 0.166 B: 0.300 O: 1.526 M: 0.020	Train-MLMAcc=0.625718,	MVRCAccuracy=0.672830,	MLMLossWVC=1.803681,	MVRCLoss=2.450124,	
Rank[  3]Epoch[6] Batch [3800]	Speed: 27.01 samples/s ETA: 1 d  2 h  4 m	Data: 0.387 Tran: 0.007 F: 0.153 B: 0.301 O: 1.512 M: 0.008	Train-MLMAcc=0.625912,	MVRCAccuracy=0.672884,	MLMLossWVC=1.802618,	MVRCLoss=2.450092,	
Rank[  2]Epoch[6] Batch [3800]	Speed: 27.01 samples/s ETA: 1 d  2 h  4 m	Data: 0.008 Tran: 0.007 F: 0.152 B: 0.299 O: 1.895 M: 0.007	Train-MLMAcc=0.625912,	MVRCAccuracy=0.672884,	MLMLossWVC=1.802618,	MVRCLoss=2.450092,	
Rank[  0]Epoch[6] Batch [3800]	Speed: 27.01 samples/s ETA: 1 d  2 h  4 m	Data: 0.035 Tran: 0.007 F: 0.152 B: 0.292 O: 1.876 M: 0.006	Train-MLMAcc=0.625912,	MVRCAccuracy=0.672884,	MLMLossWVC=1.802618,	MVRCLoss=2.450092,	
Rank[  1]Epoch[6] Batch [3800]	Speed: 27.01 samples/s ETA: 1 d  2 h  4 m	Data: 1.799 Tran: 0.010 F: 0.189 B: 0.301 O: 0.060 M: 0.008	Train-MLMAcc=0.625912,	MVRCAccuracy=0.672884,	MLMLossWVC=1.802618,	MVRCLoss=2.450092,	
Rank[  2]Epoch[6] Batch [3900]	Speed: 28.05 samples/s ETA: 1 d  1 h  2 m	Data: 0.023 Tran: 0.007 F: 0.155 B: 0.299 O: 1.787 M: 0.009	Train-MLMAcc=0.625883,	MVRCAccuracy=0.672870,	MLMLossWVC=1.802792,	MVRCLoss=2.450122,	
Rank[  1]Epoch[6] Batch [3900]	Speed: 28.05 samples/s ETA: 1 d  1 h  2 m	Data: 1.731 Tran: 0.008 F: 0.174 B: 0.302 O: 0.057 M: 0.008	Train-MLMAcc=0.625883,	MVRCAccuracy=0.672870,	MLMLossWVC=1.802792,	MVRCLoss=2.450122,	
Rank[  3]Epoch[6] Batch [3900]	Speed: 28.05 samples/s ETA: 1 d  1 h  2 m	Data: 0.008 Tran: 0.007 F: 0.154 B: 0.298 O: 1.803 M: 0.012	Train-MLMAcc=0.625883,	MVRCAccuracy=0.672870,	MLMLossWVC=1.802792,	MVRCLoss=2.450122,	
Rank[  0]Epoch[6] Batch [3900]	Speed: 28.05 samples/s ETA: 1 d  1 h  2 m	Data: 0.008 Tran: 0.007 F: 0.154 B: 0.294 O: 1.807 M: 0.011	Train-MLMAcc=0.625883,	MVRCAccuracy=0.672870,	MLMLossWVC=1.802792,	MVRCLoss=2.450122,	
Rank[  0]Epoch[6] Batch [4000]	Speed: 27.95 samples/s ETA: 1 d  1 h  3 m	Data: 0.035 Tran: 0.007 F: 0.151 B: 0.294 O: 1.792 M: 0.008	Train-MLMAcc=0.625881,	MVRCAccuracy=0.672873,	MLMLossWVC=1.802903,	MVRCLoss=2.450180,	
Rank[  3]Epoch[6] Batch [4000]	Speed: 27.95 samples/s ETA: 1 d  1 h  3 m	Data: 0.008 Tran: 0.007 F: 0.151 B: 0.301 O: 1.814 M: 0.006	Train-MLMAcc=0.625881,	MVRCAccuracy=0.672873,	MLMLossWVC=1.802903,	MVRCLoss=2.450180,	
Rank[  2]Epoch[6] Batch [4000]	Speed: 27.95 samples/s ETA: 1 d  1 h  3 m	Data: 0.008 Tran: 0.008 F: 0.150 B: 0.298 O: 1.816 M: 0.007	Train-MLMAcc=0.625881,	MVRCAccuracy=0.672873,	MLMLossWVC=1.802903,	MVRCLoss=2.450180,	
Rank[  1]Epoch[6] Batch [4000]	Speed: 27.95 samples/s ETA: 1 d  1 h  3 m	Data: 1.710 Tran: 0.008 F: 0.171 B: 0.303 O: 0.086 M: 0.007	Train-MLMAcc=0.625881,	MVRCAccuracy=0.672873,	MLMLossWVC=1.802903,	MVRCLoss=2.450180,	
